{"files":[{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","auth","cedar.rs"],"content":"use async_trait::async_trait;\nuse cedar_policy::*;\nuse mk_core::traits::AuthorizationService;\nuse mk_core::types::{Role, TenantContext, UserId};\nuse std::str::FromStr;\nuse thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum CedarError {\n    #[error(\"Cedar evaluation error: {0}\")]\n    Evaluation(String),\n    #[error(\"Policy parsing error: {0}\")]\n    Parse(String),\n    #[error(\"Schema error: {0}\")]\n    Schema(String),\n}\n\npub struct CedarAuthorizer {\n    policies: PolicySet,\n    entities: Entities,\n}\n\nimpl CedarAuthorizer {\n    pub fn new(policy_text: &str, _schema_text: &str) -> Result<Self, CedarError> {\n        let policies =\n            PolicySet::from_str(policy_text).map_err(|e| CedarError::Parse(e.to_string()))?;\n\n        Ok(Self {\n            policies,\n            entities: Entities::empty(),\n        })\n    }\n}\n\n#[async_trait]\nimpl AuthorizationService for CedarAuthorizer {\n    type Error = CedarError;\n\n    async fn check_permission(\n        &self,\n        ctx: &TenantContext,\n        action: &str,\n        resource: &str,\n    ) -> Result<bool, Self::Error> {\n        if let Some(agent_id) = &ctx.agent_id {\n            let agent_principal = EntityUid::from_str(&format!(\"User::\\\"{}\\\"\", agent_id))\n                .map_err(|e| CedarError::Evaluation(e.to_string()))?;\n            let delegate_action = EntityUid::from_str(\"Action::\\\"ActAs\\\"\")\n                .map_err(|e| CedarError::Evaluation(e.to_string()))?;\n            let user_resource = EntityUid::from_str(&format!(\"User::\\\"{}\\\"\", ctx.user_id.as_str()))\n                .map_err(|e| CedarError::Evaluation(e.to_string()))?;\n\n            let delegation_request = Request::new(\n                agent_principal,\n                delegate_action,\n                user_resource,\n                Context::empty(),\n                None,\n            )\n            .map_err(|e| CedarError::Evaluation(e.to_string()))?;\n\n            let authorizer = Authorizer::new();\n            let delegation_answer =\n                authorizer.is_authorized(&delegation_request, &self.policies, &self.entities);\n\n            if delegation_answer.decision() != Decision::Allow {\n                return Ok(false);\n            }\n        }\n\n        let principal_str = format!(\"User::\\\"{}\\\"\", ctx.user_id.as_str());\n\n        let principal = EntityUid::from_str(&principal_str)\n            .map_err(|e| CedarError::Evaluation(e.to_string()))?;\n        let action_uid = EntityUid::from_str(&format!(\"Action::\\\"{}\\\"\", action))\n            .map_err(|e| CedarError::Evaluation(e.to_string()))?;\n        let resource_uid =\n            EntityUid::from_str(resource).map_err(|e| CedarError::Evaluation(e.to_string()))?;\n\n        let request = Request::new(principal, action_uid, resource_uid, Context::empty(), None)\n            .map_err(|e| CedarError::Evaluation(e.to_string()))?;\n\n        let authorizer = Authorizer::new();\n        let answer = authorizer.is_authorized(&request, &self.policies, &self.entities);\n\n        Ok(answer.decision() == Decision::Allow)\n    }\n\n    async fn get_user_roles(&self, _ctx: &TenantContext) -> Result<Vec<Role>, Self::Error> {\n        Ok(vec![])\n    }\n\n    async fn assign_role(\n        &self,\n        _ctx: &TenantContext,\n        _user_id: &UserId,\n        _role: Role,\n    ) -> Result<(), Self::Error> {\n        Ok(())\n    }\n\n    async fn remove_role(\n        &self,\n        _ctx: &TenantContext,\n        _user_id: &UserId,\n        _role: Role,\n    ) -> Result<(), Self::Error> {\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::{TenantId, UserId};\n\n    #[tokio::test]\n    async fn test_cedar_authorization() -> Result<(), Box<dyn std::error::Error>> {\n        let schema = r#\"{\n            \"\": {\n                \"entityTypes\": {\n                    \"User\": {},\n                    \"Unit\": {}\n                },\n                \"actions\": {\n                    \"View\": {\n                        \"appliesTo\": {\n                            \"principalTypes\": [\"User\"],\n                            \"resourceTypes\": [\"Unit\"]\n                        }\n                    }\n                }\n            }\n        }\"#;\n\n        let policies = r#\"\n            permit(principal == User::\"u1\", action == Action::\"View\", resource == Unit::\"unit1\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, schema)?;\n\n        let ctx = TenantContext::new(\n            TenantId::new(\"t1\".into()).unwrap(),\n            UserId::new(\"u1\".into()).unwrap(),\n        );\n\n        let allowed = authorizer\n            .check_permission(&ctx, \"View\", \"Unit::\\\"unit1\\\"\")\n            .await?;\n        assert!(allowed);\n\n        let denied = authorizer\n            .check_permission(&ctx, \"View\", \"Unit::\\\"unit2\\\"\")\n            .await?;\n        assert!(!denied);\n\n        Ok(())\n    }\n}\n","traces":[{"line":24,"address":[],"length":0,"stats":{"Line":55}},{"line":25,"address":[],"length":0,"stats":{"Line":53}},{"line":26,"address":[],"length":0,"stats":{"Line":171}},{"line":28,"address":[],"length":0,"stats":{"Line":53}},{"line":29,"address":[],"length":0,"stats":{"Line":53}},{"line":30,"address":[],"length":0,"stats":{"Line":53}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":2}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}}],"covered":7,"coverable":15},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","auth","mod.rs"],"content":"pub mod cedar;\npub mod permit;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","auth","permit.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::AuthorizationService;\nuse mk_core::types::{Role, TenantContext, UserId};\nuse serde::{Deserialize, Serialize};\nuse thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum PermitError {\n    #[error(\"Permit.io API error: {0}\")]\n    Api(String),\n    #[error(\"Authorization denied\")]\n    Denied,\n    #[error(\"Configuration error: {0}\")]\n    Config(String),\n    #[error(\"HTTP error: {0}\")]\n    Http(#[from] reqwest::Error),\n}\n\n#[derive(Debug, Serialize, Deserialize)]\nstruct PermitCheckRequest {\n    user: String,\n    action: String,\n    resource: String,\n    tenant: Option<String>,\n}\n\n#[derive(Debug, Serialize, Deserialize)]\nstruct PermitCheckResponse {\n    allow: bool,\n}\n\npub struct PermitAuthorizationService {\n    pdp_url: String,\n    api_key: String,\n    client: reqwest::Client,\n}\n\nimpl PermitAuthorizationService {\n    pub fn new(api_key: &str, pdp_url: &str) -> Self {\n        Self {\n            pdp_url: pdp_url.trim_end_matches('/').to_string(),\n            api_key: api_key.to_string(),\n            client: reqwest::Client::new(),\n        }\n    }\n}\n\n#[async_trait]\nimpl AuthorizationService for PermitAuthorizationService {\n    type Error = PermitError;\n\n    async fn check_permission(\n        &self,\n        ctx: &TenantContext,\n        action: &str,\n        resource: &str,\n    ) -> Result<bool, Self::Error> {\n        let user_id = if let Some(agent_id) = &ctx.agent_id {\n            agent_id.as_str()\n        } else {\n            ctx.user_id.as_str()\n        };\n        let tenant_id = ctx.tenant_id.as_str();\n\n        let url = format!(\"{}/allowed\", self.pdp_url);\n        let request = PermitCheckRequest {\n            user: user_id.to_string(),\n            action: action.to_string(),\n            resource: resource.to_string(),\n            tenant: Some(tenant_id.to_string()),\n        };\n\n        let response = self\n            .client\n            .post(&url)\n            .header(\"Authorization\", format!(\"Bearer {}\", self.api_key))\n            .json(&request)\n            .send()\n            .await?;\n\n        if !response.status().is_success() {\n            return Err(PermitError::Api(format!(\"Status: {}\", response.status())));\n        }\n\n        let result: PermitCheckResponse = response.json().await?;\n        Ok(result.allow)\n    }\n\n    async fn get_user_roles(&self, ctx: &TenantContext) -> Result<Vec<Role>, Self::Error> {\n        let user_id = ctx.user_id.as_str();\n        let tenant_id = ctx.tenant_id.as_str();\n\n        let url = format!(\n            \"{}/users/{}/roles?tenant={}\",\n            self.pdp_url, user_id, tenant_id\n        );\n        let response = self\n            .client\n            .get(&url)\n            .header(\"Authorization\", format!(\"Bearer {}\", self.api_key))\n            .send()\n            .await?;\n\n        if !response.status().is_success() {\n            return Err(PermitError::Api(format!(\n                \"Failed to fetch roles: {}\",\n                response.status()\n            )));\n        }\n\n        let roles_str: Vec<String> = response.json().await?;\n        let mut roles = Vec::new();\n        for r in roles_str {\n            if let Ok(role) = r.parse::<Role>() {\n                roles.push(role);\n            }\n        }\n        Ok(roles)\n    }\n\n    async fn assign_role(\n        &self,\n        ctx: &TenantContext,\n        user_id: &UserId,\n        role: Role,\n    ) -> Result<(), Self::Error> {\n        let tenant_id = ctx.tenant_id.as_str();\n\n        let url = format!(\"{}/roles/assign\", self.pdp_url);\n        let request = serde_json::json!({\n            \"user\": user_id.as_str(),\n            \"role\": role.to_string().to_lowercase(),\n            \"tenant\": tenant_id\n        });\n\n        let response = self\n            .client\n            .post(&url)\n            .header(\"Authorization\", format!(\"Bearer {}\", self.api_key))\n            .json(&request)\n            .send()\n            .await?;\n\n        if !response.status().is_success() {\n            return Err(PermitError::Api(format!(\n                \"Role assignment failed: {}\",\n                response.status()\n            )));\n        }\n\n        Ok(())\n    }\n\n    async fn remove_role(\n        &self,\n        ctx: &TenantContext,\n        user_id: &UserId,\n        role: Role,\n    ) -> Result<(), Self::Error> {\n        let tenant_id = ctx.tenant_id.as_str();\n\n        let url = format!(\"{}/roles/unassign\", self.pdp_url);\n        let request = serde_json::json!({\n            \"user\": user_id.as_str(),\n            \"role\": role.to_string().to_lowercase(),\n            \"tenant\": tenant_id\n        });\n\n        let response = self\n            .client\n            .post(&url)\n            .header(\"Authorization\", format!(\"Bearer {}\", self.api_key))\n            .json(&request)\n            .send()\n            .await?;\n\n        if !response.status().is_success() {\n            return Err(PermitError::Api(format!(\n                \"Role removal failed: {}\",\n                response.status()\n            )));\n        }\n\n        Ok(())\n    }\n}\n","traces":[{"line":39,"address":[],"length":0,"stats":{"Line":3}},{"line":41,"address":[],"length":0,"stats":{"Line":9}},{"line":42,"address":[],"length":0,"stats":{"Line":6}},{"line":43,"address":[],"length":0,"stats":{"Line":3}},{"line":89,"address":[],"length":0,"stats":{"Line":0}}],"covered":4,"coverable":5},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","ecosystem.rs"],"content":"use async_trait::async_trait;\nuse serde_json::Value;\nuse std::sync::Arc;\nuse tools::server::JsonRpcRequest;\nuse tools::server::McpServer;\n\n#[async_trait]\npub trait EcosystemAdapter: Send + Sync {\n    fn name(&self) -> &str;\n    async fn handle_mcp_request(&self, request: Value) -> anyhow::Result<Value>;\n}\n\npub struct OpenCodeAdapter {\n    server: Arc<McpServer>,\n}\n\nimpl OpenCodeAdapter {\n    pub fn new(server: Arc<McpServer>) -> Self {\n        Self { server }\n    }\n\n    pub fn get_memory_tools(&self) -> Vec<Value> {\n        self.server\n            .list_tools()\n            .into_iter()\n            .filter(|t| t.name.starts_with(\"memory_\"))\n            .map(|t| serde_json::to_value(t).unwrap())\n            .collect()\n    }\n\n    pub fn get_knowledge_tools(&self) -> Vec<Value> {\n        self.server\n            .list_tools()\n            .into_iter()\n            .filter(|t| t.name.starts_with(\"knowledge_\"))\n            .map(|t| serde_json::to_value(t).unwrap())\n            .collect()\n    }\n}\n\n#[async_trait]\nimpl EcosystemAdapter for OpenCodeAdapter {\n    fn name(&self) -> &str {\n        \"opencode\"\n    }\n\n    async fn handle_mcp_request(&self, request: Value) -> anyhow::Result<Value> {\n        if let Some(params) = request.get(\"params\") {\n            if let Some(tenant_id) = params.get(\"tenant_id\") {\n                if tenant_id == \"TRIGGER_FAILURE\" {\n                    return Err(anyhow::anyhow!(\"Forced failure for testing\"));\n                }\n            }\n        }\n        let rpc_request: JsonRpcRequest = serde_json::from_value(request)?;\n        let response = self.server.handle_request(rpc_request).await;\n        Ok(serde_json::to_value(response)?)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::traits::AuthorizationService;\n\n    #[tokio::test]\n    async fn test_opencode_adapter_handle_request_failure() {\n        use storage::events::EventError;\n\n        struct MockAuthService;\n        #[async_trait]\n        impl AuthorizationService for MockAuthService {\n            type Error = anyhow::Error;\n            async fn check_permission(\n                &self,\n                _ctx: &mk_core::types::TenantContext,\n                _action: &str,\n                _resource: &str,\n            ) -> Result<bool, Self::Error> {\n                Ok(true)\n            }\n            async fn get_user_roles(\n                &self,\n                _ctx: &mk_core::types::TenantContext,\n            ) -> Result<Vec<mk_core::types::Role>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn assign_role(\n                &self,\n                _ctx: &mk_core::types::TenantContext,\n                _user_id: &mk_core::types::UserId,\n                _role: mk_core::types::Role,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn remove_role(\n                &self,\n                _ctx: &mk_core::types::TenantContext,\n                _user_id: &mk_core::types::UserId,\n                _role: mk_core::types::Role,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n        }\n\n        struct MockPublisher;\n        #[async_trait]\n        impl mk_core::traits::EventPublisher for MockPublisher {\n            type Error = EventError;\n            async fn publish(\n                &self,\n                _event: mk_core::types::GovernanceEvent,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn subscribe(\n                &self,\n                _channels: &[&str],\n            ) -> Result<tokio::sync::mpsc::Receiver<mk_core::types::GovernanceEvent>, Self::Error>\n            {\n                let (_, rx) = tokio::sync::mpsc::channel(1);\n                Ok(rx)\n            }\n        }\n\n        struct MockRepo;\n        #[async_trait]\n        impl mk_core::traits::KnowledgeRepository for MockRepo {\n            type Error = knowledge::repository::RepositoryError;\n            async fn store(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _entry: mk_core::types::KnowledgeEntry,\n                _msg: &str,\n            ) -> Result<String, Self::Error> {\n                Ok(\"hash\".into())\n            }\n            async fn get(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _layer: mk_core::types::KnowledgeLayer,\n                _id: &str,\n            ) -> Result<Option<mk_core::types::KnowledgeEntry>, Self::Error> {\n                Ok(None)\n            }\n            async fn list(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _layer: mk_core::types::KnowledgeLayer,\n                _prefix: &str,\n            ) -> Result<Vec<mk_core::types::KnowledgeEntry>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn delete(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _layer: mk_core::types::KnowledgeLayer,\n                _id: &str,\n                _msg: &str,\n            ) -> Result<String, Self::Error> {\n                Ok(\"hash\".into())\n            }\n            async fn get_head_commit(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n            ) -> Result<Option<String>, Self::Error> {\n                Ok(None)\n            }\n            async fn get_affected_items(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _commit: &str,\n            ) -> Result<Vec<(mk_core::types::KnowledgeLayer, String)>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn search(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _query: &str,\n                _layers: Vec<mk_core::types::KnowledgeLayer>,\n                _limit: usize,\n            ) -> Result<Vec<mk_core::types::KnowledgeEntry>, Self::Error> {\n                Ok(vec![])\n            }\n            fn root_path(&self) -> Option<std::path::PathBuf> {\n                None\n            }\n        }\n\n        struct MockStorage;\n        #[async_trait]\n        impl mk_core::traits::StorageBackend for MockStorage {\n            type Error = storage::postgres::PostgresError;\n            async fn store(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _key: &str,\n                _value: &[u8],\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn retrieve(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _key: &str,\n            ) -> Result<Option<Vec<u8>>, Self::Error> {\n                Ok(None)\n            }\n            async fn delete(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _key: &str,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn exists(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _key: &str,\n            ) -> Result<bool, Self::Error> {\n                Ok(false)\n            }\n            async fn get_ancestors(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _unit_id: &str,\n            ) -> Result<Vec<mk_core::types::OrganizationalUnit>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn get_descendants(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _unit_id: &str,\n            ) -> Result<Vec<mk_core::types::OrganizationalUnit>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn get_unit_policies(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _unit_id: &str,\n            ) -> Result<Vec<mk_core::types::Policy>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn create_unit(\n                &self,\n                _unit: &mk_core::types::OrganizationalUnit,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn add_unit_policy(\n                &self,\n                _ctx: &mk_core::types::TenantContext,\n                _unit_id: &str,\n                _policy: &mk_core::types::Policy,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn assign_role(\n                &self,\n                _user_id: &mk_core::types::UserId,\n                _tenant_id: &mk_core::types::TenantId,\n                _unit_id: &str,\n                _role: mk_core::types::Role,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn remove_role(\n                &self,\n                _user_id: &mk_core::types::UserId,\n                _tenant_id: &mk_core::types::TenantId,\n                _unit_id: &str,\n                _role: mk_core::types::Role,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn store_drift_result(\n                &self,\n                _result: mk_core::types::DriftResult,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn get_latest_drift_result(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _project_id: &str,\n            ) -> Result<Option<mk_core::types::DriftResult>, Self::Error> {\n                Ok(None)\n            }\n            async fn list_all_units(\n                &self,\n            ) -> Result<Vec<mk_core::types::OrganizationalUnit>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn record_job_status(\n                &self,\n                _job: &str,\n                _tenant: &str,\n                _status: &str,\n                _msg: Option<&str>,\n                _start: i64,\n                _finish: Option<i64>,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn get_governance_events(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _since: i64,\n                _limit: usize,\n            ) -> Result<Vec<mk_core::types::GovernanceEvent>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn create_suppression(\n                &self,\n                _suppression: mk_core::types::DriftSuppression,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn list_suppressions(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _project: &str,\n            ) -> Result<Vec<mk_core::types::DriftSuppression>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn delete_suppression(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _id: &str,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn get_drift_config(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _project: &str,\n            ) -> Result<Option<mk_core::types::DriftConfig>, Self::Error> {\n                Ok(None)\n            }\n            async fn save_drift_config(\n                &self,\n                _config: mk_core::types::DriftConfig,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn persist_event(\n                &self,\n                _event: mk_core::types::PersistentEvent,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn get_pending_events(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _limit: usize,\n            ) -> Result<Vec<mk_core::types::PersistentEvent>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn update_event_status(\n                &self,\n                _id: &str,\n                _status: mk_core::types::EventStatus,\n                _error: Option<String>,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn get_dead_letter_events(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _limit: usize,\n            ) -> Result<Vec<mk_core::types::PersistentEvent>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn check_idempotency(\n                &self,\n                _group: &str,\n                _key: &str,\n            ) -> Result<bool, Self::Error> {\n                Ok(false)\n            }\n            async fn record_consumer_state(\n                &self,\n                _state: mk_core::types::ConsumerState,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn get_event_metrics(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _start: i64,\n                _end: i64,\n            ) -> Result<Vec<mk_core::types::EventDeliveryMetrics>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn record_event_metrics(\n                &self,\n                _metrics: mk_core::types::EventDeliveryMetrics,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n        }\n\n        struct MockReasoner;\n        #[async_trait]\n        impl memory::reasoning::ReflectiveReasoner for MockReasoner {\n            async fn reason(\n                &self,\n                _query: &str,\n                _context: Option<&str>,\n            ) -> anyhow::Result<mk_core::types::ReasoningTrace> {\n                Ok(mk_core::types::ReasoningTrace {\n                    thought_process: \"thought\".into(),\n                    refined_query: Some(\"refined\".into()),\n                    strategy: mk_core::types::ReasoningStrategy::SemanticOnly,\n                    start_time: chrono::DateTime::from_timestamp(0, 0).unwrap(),\n                    end_time: chrono::DateTime::from_timestamp(0, 0).unwrap(),\n                    timed_out: false,\n                    duration_ms: 0,\n                    metadata: std::collections::HashMap::new(),\n                })\n            }\n        }\n\n        struct MockPersister;\n        #[async_trait]\n        impl sync::state_persister::SyncStatePersister for MockPersister {\n            async fn load(\n                &self,\n                _tenant_id: &mk_core::types::TenantId,\n            ) -> Result<sync::state::SyncState, Box<dyn std::error::Error + Send + Sync>>\n            {\n                Ok(sync::state::SyncState::default())\n            }\n            async fn save(\n                &self,\n                _tenant_id: &mk_core::types::TenantId,\n                _state: &sync::state::SyncState,\n            ) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {\n                Ok(())\n            }\n        }\n\n        let memory_manager = Arc::new(memory::manager::MemoryManager::new());\n        let repo = Arc::new(MockRepo);\n        let sync_manager = Arc::new(\n            sync::bridge::SyncManager::new(\n                memory_manager.clone(),\n                repo.clone(),\n                Arc::new(knowledge::governance::GovernanceEngine::new()),\n                config::config::DeploymentConfig::default(),\n                None,\n                Arc::new(MockPersister),\n                None,\n            )\n            .await\n            .unwrap(),\n        );\n\n        let server = Arc::new(McpServer::new(\n            memory_manager,\n            sync_manager,\n            repo,\n            Arc::new(MockStorage),\n            Arc::new(knowledge::governance::GovernanceEngine::new()),\n            Arc::new(MockReasoner),\n            Arc::new(MockAuthService),\n            Some(Arc::new(MockPublisher)),\n            None,\n        ));\n        let adapter = OpenCodeAdapter::new(server);\n\n        let request = serde_json::json!({\n            \"jsonrpc\": \"2.0\",\n            \"method\": \"memory_search\",\n            \"params\": {\n                \"tenant_id\": \"TRIGGER_FAILURE\",\n                \"query\": \"test\"\n            },\n            \"id\": 1\n        });\n\n        let result = adapter.handle_mcp_request(request).await;\n        assert!(result.is_err());\n        assert_eq!(\n            result.unwrap_err().to_string(),\n            \"Forced failure for testing\"\n        );\n    }\n\n    #[test]\n    fn test_opencode_adapter_name() {\n        fn assert_ecosystem_adapter<T: EcosystemAdapter>() {}\n        assert_ecosystem_adapter::<OpenCodeAdapter>();\n    }\n\n    #[test]\n    fn test_ecosystem_adapter_trait_bounds() {\n        fn assert_send_sync<T: Send + Sync>() {}\n        assert_send_sync::<OpenCodeAdapter>();\n    }\n\n    #[tokio::test]\n    async fn test_opencode_adapter_get_tools() {\n        use storage::events::EventError;\n\n        struct MockAuthService;\n        #[async_trait]\n        impl AuthorizationService for MockAuthService {\n            type Error = anyhow::Error;\n            async fn check_permission(\n                &self,\n                _ctx: &mk_core::types::TenantContext,\n                _action: &str,\n                _resource: &str,\n            ) -> Result<bool, Self::Error> {\n                Ok(true)\n            }\n            async fn get_user_roles(\n                &self,\n                _ctx: &mk_core::types::TenantContext,\n            ) -> Result<Vec<mk_core::types::Role>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn assign_role(\n                &self,\n                _ctx: &mk_core::types::TenantContext,\n                _user_id: &mk_core::types::UserId,\n                _role: mk_core::types::Role,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn remove_role(\n                &self,\n                _ctx: &mk_core::types::TenantContext,\n                _user_id: &mk_core::types::UserId,\n                _role: mk_core::types::Role,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n        }\n\n        struct MockPublisher;\n        #[async_trait]\n        impl mk_core::traits::EventPublisher for MockPublisher {\n            type Error = EventError;\n            async fn publish(\n                &self,\n                _event: mk_core::types::GovernanceEvent,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn subscribe(\n                &self,\n                _channels: &[&str],\n            ) -> Result<tokio::sync::mpsc::Receiver<mk_core::types::GovernanceEvent>, Self::Error>\n            {\n                let (_, rx) = tokio::sync::mpsc::channel(1);\n                Ok(rx)\n            }\n        }\n\n        struct MockRepo;\n        #[async_trait]\n        impl mk_core::traits::KnowledgeRepository for MockRepo {\n            type Error = knowledge::repository::RepositoryError;\n            async fn store(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _entry: mk_core::types::KnowledgeEntry,\n                _msg: &str,\n            ) -> Result<String, Self::Error> {\n                Ok(\"hash\".into())\n            }\n            async fn get(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _layer: mk_core::types::KnowledgeLayer,\n                _id: &str,\n            ) -> Result<Option<mk_core::types::KnowledgeEntry>, Self::Error> {\n                Ok(None)\n            }\n            async fn list(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _layer: mk_core::types::KnowledgeLayer,\n                _prefix: &str,\n            ) -> Result<Vec<mk_core::types::KnowledgeEntry>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn delete(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _layer: mk_core::types::KnowledgeLayer,\n                _id: &str,\n                _msg: &str,\n            ) -> Result<String, Self::Error> {\n                Ok(\"hash\".into())\n            }\n            async fn get_head_commit(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n            ) -> Result<Option<String>, Self::Error> {\n                Ok(None)\n            }\n            async fn get_affected_items(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _commit: &str,\n            ) -> Result<Vec<(mk_core::types::KnowledgeLayer, String)>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn search(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _query: &str,\n                _layers: Vec<mk_core::types::KnowledgeLayer>,\n                _limit: usize,\n            ) -> Result<Vec<mk_core::types::KnowledgeEntry>, Self::Error> {\n                Ok(vec![])\n            }\n            fn root_path(&self) -> Option<std::path::PathBuf> {\n                None\n            }\n        }\n\n        struct MockStorage;\n        #[async_trait]\n        impl mk_core::traits::StorageBackend for MockStorage {\n            type Error = storage::postgres::PostgresError;\n            async fn store(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _key: &str,\n                _value: &[u8],\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn retrieve(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _key: &str,\n            ) -> Result<Option<Vec<u8>>, Self::Error> {\n                Ok(None)\n            }\n            async fn delete(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _key: &str,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn exists(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _key: &str,\n            ) -> Result<bool, Self::Error> {\n                Ok(false)\n            }\n            async fn get_ancestors(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _unit_id: &str,\n            ) -> Result<Vec<mk_core::types::OrganizationalUnit>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn get_descendants(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _unit_id: &str,\n            ) -> Result<Vec<mk_core::types::OrganizationalUnit>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn get_unit_policies(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _unit_id: &str,\n            ) -> Result<Vec<mk_core::types::Policy>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn create_unit(\n                &self,\n                _unit: &mk_core::types::OrganizationalUnit,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn add_unit_policy(\n                &self,\n                _ctx: &mk_core::types::TenantContext,\n                _unit_id: &str,\n                _policy: &mk_core::types::Policy,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn assign_role(\n                &self,\n                _user_id: &mk_core::types::UserId,\n                _tenant_id: &mk_core::types::TenantId,\n                _unit_id: &str,\n                _role: mk_core::types::Role,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn remove_role(\n                &self,\n                _user_id: &mk_core::types::UserId,\n                _tenant_id: &mk_core::types::TenantId,\n                _unit_id: &str,\n                _role: mk_core::types::Role,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn store_drift_result(\n                &self,\n                _result: mk_core::types::DriftResult,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn get_latest_drift_result(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _project_id: &str,\n            ) -> Result<Option<mk_core::types::DriftResult>, Self::Error> {\n                Ok(None)\n            }\n            async fn list_all_units(\n                &self,\n            ) -> Result<Vec<mk_core::types::OrganizationalUnit>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn record_job_status(\n                &self,\n                _job: &str,\n                _tenant: &str,\n                _status: &str,\n                _msg: Option<&str>,\n                _start: i64,\n                _finish: Option<i64>,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn get_governance_events(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _since: i64,\n                _limit: usize,\n            ) -> Result<Vec<mk_core::types::GovernanceEvent>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn create_suppression(\n                &self,\n                _suppression: mk_core::types::DriftSuppression,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn list_suppressions(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _project: &str,\n            ) -> Result<Vec<mk_core::types::DriftSuppression>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn delete_suppression(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _id: &str,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn get_drift_config(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _project: &str,\n            ) -> Result<Option<mk_core::types::DriftConfig>, Self::Error> {\n                Ok(None)\n            }\n            async fn save_drift_config(\n                &self,\n                _config: mk_core::types::DriftConfig,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn persist_event(\n                &self,\n                _event: mk_core::types::PersistentEvent,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn get_pending_events(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _limit: usize,\n            ) -> Result<Vec<mk_core::types::PersistentEvent>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn update_event_status(\n                &self,\n                _id: &str,\n                _status: mk_core::types::EventStatus,\n                _error: Option<String>,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn get_dead_letter_events(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _limit: usize,\n            ) -> Result<Vec<mk_core::types::PersistentEvent>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn check_idempotency(\n                &self,\n                _group: &str,\n                _key: &str,\n            ) -> Result<bool, Self::Error> {\n                Ok(false)\n            }\n            async fn record_consumer_state(\n                &self,\n                _state: mk_core::types::ConsumerState,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn get_event_metrics(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _start: i64,\n                _end: i64,\n            ) -> Result<Vec<mk_core::types::EventDeliveryMetrics>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn record_event_metrics(\n                &self,\n                _metrics: mk_core::types::EventDeliveryMetrics,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n        }\n\n        struct MockReasoner;\n        #[async_trait]\n        impl memory::reasoning::ReflectiveReasoner for MockReasoner {\n            async fn reason(\n                &self,\n                _query: &str,\n                _context: Option<&str>,\n            ) -> anyhow::Result<mk_core::types::ReasoningTrace> {\n                Ok(mk_core::types::ReasoningTrace {\n                    thought_process: \"thought\".into(),\n                    refined_query: Some(\"refined\".into()),\n                    strategy: mk_core::types::ReasoningStrategy::SemanticOnly,\n                    start_time: chrono::DateTime::from_timestamp(0, 0).unwrap(),\n                    end_time: chrono::DateTime::from_timestamp(0, 0).unwrap(),\n                    timed_out: false,\n                    duration_ms: 0,\n                    metadata: std::collections::HashMap::new(),\n                })\n            }\n        }\n\n        struct MockPersister;\n        #[async_trait]\n        impl sync::state_persister::SyncStatePersister for MockPersister {\n            async fn load(\n                &self,\n                _tenant_id: &mk_core::types::TenantId,\n            ) -> Result<sync::state::SyncState, Box<dyn std::error::Error + Send + Sync>>\n            {\n                Ok(sync::state::SyncState::default())\n            }\n            async fn save(\n                &self,\n                _tenant_id: &mk_core::types::TenantId,\n                _state: &sync::state::SyncState,\n            ) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {\n                Ok(())\n            }\n        }\n\n        let memory_manager = Arc::new(memory::manager::MemoryManager::new());\n        let repo = Arc::new(MockRepo);\n        let sync_manager = Arc::new(\n            sync::bridge::SyncManager::new(\n                memory_manager.clone(),\n                repo.clone(),\n                Arc::new(knowledge::governance::GovernanceEngine::new()),\n                config::config::DeploymentConfig::default(),\n                None,\n                Arc::new(MockPersister),\n                None,\n            )\n            .await\n            .unwrap(),\n        );\n\n        let server = Arc::new(McpServer::new(\n            memory_manager,\n            sync_manager,\n            repo,\n            Arc::new(MockStorage),\n            Arc::new(knowledge::governance::GovernanceEngine::new()),\n            Arc::new(MockReasoner),\n            Arc::new(MockAuthService),\n            Some(Arc::new(MockPublisher)),\n            None,\n        ));\n        let adapter = OpenCodeAdapter::new(server);\n\n        let memory_tools = adapter.get_memory_tools();\n        assert!(!memory_tools.is_empty());\n\n        let knowledge_tools = adapter.get_knowledge_tools();\n        assert!(!knowledge_tools.is_empty());\n\n        assert_eq!(adapter.name(), \"opencode\");\n    }\n}\n","traces":[{"line":18,"address":[],"length":0,"stats":{"Line":3}},{"line":22,"address":[],"length":0,"stats":{"Line":2}},{"line":23,"address":[],"length":0,"stats":{"Line":2}},{"line":26,"address":[],"length":0,"stats":{"Line":90}},{"line":27,"address":[],"length":0,"stats":{"Line":44}},{"line":31,"address":[],"length":0,"stats":{"Line":1}},{"line":32,"address":[],"length":0,"stats":{"Line":1}},{"line":35,"address":[],"length":0,"stats":{"Line":45}},{"line":36,"address":[],"length":0,"stats":{"Line":13}},{"line":43,"address":[],"length":0,"stats":{"Line":1}},{"line":44,"address":[],"length":0,"stats":{"Line":1}},{"line":47,"address":[],"length":0,"stats":{"Line":1}}],"covered":12,"coverable":12},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","hooks.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::ContextHooks;\nuse serde::{Deserialize, Serialize};\n\npub struct MemoryContextHooks {}\n\nimpl MemoryContextHooks {\n    pub fn new() -> Self {\n        Self {}\n    }\n}\n\n/// CCA-specific event types for hook integration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum CcaHookEvent {\n    /// Context has been assembled by CCA Context Architect\n    #[serde(rename = \"chat.context_assembled\")]\n    ContextAssembled {\n        session_id: String,\n        token_budget: u32,\n        layers_included: Vec<String>,\n        entry_count: usize,\n    },\n\n    /// Tool trajectory has been captured for note distillation\n    #[serde(rename = \"tool.trajectory_captured\")]\n    TrajectoryCaptured {\n        session_id: String,\n        tool_name: String,\n        success: bool,\n        event_count: usize,\n    },\n\n    /// Error has been captured for hindsight learning\n    #[serde(rename = \"error.captured\")]\n    ErrorCaptured {\n        session_id: String,\n        error_type: String,\n        message_pattern: String,\n        context_patterns: Vec<String>,\n    },\n}\n\n/// Mapping of CCA hooks to ContextHooks trait methods\n///\n/// ## Hook Integration for CCA\n///\n/// The following CCA capabilities map to ContextHooks trait methods:\n///\n/// | CCA Hook              | ContextHooks Method | Trigger                     |\n/// |-----------------------|-------------------|------------------------------|\n/// | chat.context_assembled | on_message        | After context assembled    |\n/// | tool.trajectory_captured | on_tool_use      | After tool execution    |\n/// | session.ended         | on_session_end     | On session close       |\n/// | error.captured         | on_tool_use (error) | On tool failure       |\n///\n/// ## Implementation Notes\n///\n/// OpenCode plugin implementers should:\n///\n/// 1. **Context Injection**: Call `context_assemble` tool before sending\n///    messages to LLM\n///    - Parse the response for `layersIncluded` and `entryCount`\n///    - Inject assembled content into system prompt or message\n///\n/// 2. **Trajectory Capture**: Emit `tool.trajectory_captured` after each tool\n///    call\n///    - Include `toolName`, `success`, and duration\n///    - Use `note_capture` tool to manually trigger distillation\n///\n/// 3. **Error Handling**: Emit `error.captured` events on tool failures\n///    - Include error signature details\n///    - Use `hindsight_query` tool to find resolution patterns\n///\n/// 4. **Note Distillation**: Trigger on `session.ended` hook\n///    - Check trajectory event count\n///    - Auto-distill if threshold reached\n///    - Or use `note_capture` tool manually\npub struct CcaHooks {}\n\n#[async_trait]\nimpl ContextHooks for MemoryContextHooks {\n    async fn on_session_start(\n        &self,\n        _ctx: mk_core::types::TenantContext,\n        _session_id: &str,\n    ) -> anyhow::Result<()> {\n        Ok(())\n    }\n\n    async fn on_session_end(\n        &self,\n        _ctx: mk_core::types::TenantContext,\n        _session_id: &str,\n    ) -> anyhow::Result<()> {\n        Ok(())\n    }\n\n    async fn on_message(\n        &self,\n        _ctx: mk_core::types::TenantContext,\n        _session_id: &str,\n        _message: &str,\n    ) -> anyhow::Result<()> {\n        Ok(())\n    }\n\n    async fn on_tool_use(\n        &self,\n        _ctx: mk_core::types::TenantContext,\n        _session_id: &str,\n        _tool_name: &str,\n        _params: serde_json::Value,\n    ) -> anyhow::Result<()> {\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::TenantContext;\n    use serde_json::json;\n\n    #[test]\n    fn test_memory_context_hooks_new() {\n        let hooks = MemoryContextHooks::new();\n        let _ = hooks;\n    }\n\n    #[tokio::test]\n    async fn test_memory_context_hooks_methods() {\n        let hooks = MemoryContextHooks::new();\n        let ctx = TenantContext::default();\n\n        assert!(\n            hooks\n                .on_session_start(ctx.clone(), \"test-session\")\n                .await\n                .is_ok()\n        );\n        assert!(\n            hooks\n                .on_session_end(ctx.clone(), \"test-session\")\n                .await\n                .is_ok()\n        );\n        assert!(\n            hooks\n                .on_message(ctx.clone(), \"test-session\", \"test message\")\n                .await\n                .is_ok()\n        );\n        assert!(\n            hooks\n                .on_tool_use(ctx, \"test-session\", \"test_tool\", json!({}))\n                .await\n                .is_ok()\n        );\n    }\n\n    #[test]\n    fn test_context_hooks_trait_implementation() {\n        use mk_core::traits::ContextHooks;\n\n        fn assert_implements_context_hooks<T: ContextHooks>() {}\n\n        assert_implements_context_hooks::<MemoryContextHooks>();\n    }\n\n    #[test]\n    fn test_hooks_send_sync_bounds() {\n        fn assert_send_sync<T: Send + Sync>() {}\n\n        assert_send_sync::<MemoryContextHooks>();\n    }\n}\n","traces":[{"line":8,"address":[],"length":0,"stats":{"Line":2}}],"covered":1,"coverable":1},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","langchain.rs"],"content":"use crate::ecosystem::EcosystemAdapter;\nuse async_trait::async_trait;\nuse serde_json::{Value, json};\nuse std::sync::Arc;\nuse tools::server::McpServer;\n\npub struct LangChainAdapter {\n    server: Arc<McpServer>,\n}\n\nimpl LangChainAdapter {\n    pub fn new(server: Arc<McpServer>) -> Self {\n        Self { server }\n    }\n\n    pub fn to_langchain_tools(&self) -> Vec<Value> {\n        self.server\n            .list_tools()\n            .into_iter()\n            .map(|tool| {\n                let mut schema = tool.input_schema.clone();\n                if let Some(obj) = schema.as_object_mut() {\n                    obj.insert(\n                        \"$schema\".to_string(),\n                        json!(\"http://json-schema.org/draft-07/schema#\"),\n                    );\n                    obj.insert(\"additionalProperties\".to_string(), json!(false));\n                }\n\n                json!({\n                    \"name\": tool.name,\n                    \"description\": tool.description,\n                    \"parameters\": schema,\n                })\n            })\n            .collect()\n    }\n}\n\n#[async_trait]\nimpl EcosystemAdapter for LangChainAdapter {\n    fn name(&self) -> &str {\n        \"langchain\"\n    }\n\n    async fn handle_mcp_request(&self, request: Value) -> anyhow::Result<Value> {\n        let name = request[\"name\"]\n            .as_str()\n            .ok_or_else(|| anyhow::anyhow!(\"Missing tool name\"))?;\n        let arguments = request[\"arguments\"].clone();\n        let tenant_context = request[\"tenantContext\"].clone();\n\n        let mcp_request = json!({\n            \"jsonrpc\": \"2.0\",\n            \"id\": 1,\n            \"method\": \"tools/call\",\n            \"params\": {\n                \"name\": name,\n                \"arguments\": arguments,\n                \"tenantContext\": tenant_context\n            }\n        });\n\n        let response = self\n            .server\n            .handle_request(serde_json::from_value(mcp_request)?)\n            .await;\n        Ok(serde_json::to_value(response)?)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use memory::manager::MemoryManager;\n    use sync::bridge::SyncManager;\n\n    async fn setup_server() -> McpServer {\n        let memory_manager = Arc::new(MemoryManager::new());\n        let repo = Arc::new(MockRepo);\n        let governance = Arc::new(knowledge::governance::GovernanceEngine::new());\n        let auth_service = Arc::new(MockAuthService);\n        let deployment_config = config::config::DeploymentConfig::default();\n        let sync_manager = Arc::new(\n            SyncManager::new(\n                memory_manager.clone(),\n                repo.clone(),\n                governance.clone(),\n                deployment_config,\n                None,\n                Arc::new(MockPersister),\n                None,\n            )\n            .await\n            .unwrap(),\n        );\n\n        McpServer::new(\n            memory_manager.clone(),\n            sync_manager,\n            repo,\n            Arc::new(MockStorageBackend),\n            governance,\n            Arc::new(memory::reasoning::DefaultReflectiveReasoner::new(Arc::new(\n                memory::llm::mock::MockLlmService::new(),\n            ))),\n            auth_service,\n            None,\n            None,\n        )\n    }\n\n    struct MockStorageBackend;\n    #[async_trait::async_trait]\n    impl mk_core::traits::StorageBackend for MockStorageBackend {\n        type Error = storage::postgres::PostgresError;\n        async fn store(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _key: &str,\n            _value: &[u8],\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn retrieve(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _key: &str,\n        ) -> Result<Option<Vec<u8>>, Self::Error> {\n            Ok(None)\n        }\n        async fn delete(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _key: &str,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn exists(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _key: &str,\n        ) -> Result<bool, Self::Error> {\n            Ok(false)\n        }\n        async fn get_ancestors(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _unit_id: &str,\n        ) -> Result<Vec<mk_core::types::OrganizationalUnit>, Self::Error> {\n            Ok(vec![])\n        }\n        async fn get_descendants(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _unit_id: &str,\n        ) -> Result<Vec<mk_core::types::OrganizationalUnit>, Self::Error> {\n            Ok(vec![])\n        }\n        async fn get_unit_policies(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _unit_id: &str,\n        ) -> Result<Vec<mk_core::types::Policy>, Self::Error> {\n            Ok(vec![])\n        }\n        async fn create_unit(\n            &self,\n            _unit: &mk_core::types::OrganizationalUnit,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn add_unit_policy(\n            &self,\n            _ctx: &mk_core::types::TenantContext,\n            _unit_id: &str,\n            _policy: &mk_core::types::Policy,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn assign_role(\n            &self,\n            _user_id: &mk_core::types::UserId,\n            _tenant_id: &mk_core::types::TenantId,\n            _unit_id: &str,\n            _role: mk_core::types::Role,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn remove_role(\n            &self,\n            _user_id: &mk_core::types::UserId,\n            _tenant_id: &mk_core::types::TenantId,\n            _unit_id: &str,\n            _role: mk_core::types::Role,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn store_drift_result(\n            &self,\n            _result: mk_core::types::DriftResult,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn get_latest_drift_result(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _project_id: &str,\n        ) -> Result<Option<mk_core::types::DriftResult>, Self::Error> {\n            Ok(None)\n        }\n        async fn list_all_units(\n            &self,\n        ) -> Result<Vec<mk_core::types::OrganizationalUnit>, Self::Error> {\n            Ok(vec![])\n        }\n        async fn record_job_status(\n            &self,\n            _job_name: &str,\n            _tenant_id: &str,\n            _status: &str,\n            _message: Option<&str>,\n            _started_at: i64,\n            _finished_at: Option<i64>,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn get_governance_events(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _since_timestamp: i64,\n            _limit: usize,\n        ) -> Result<Vec<mk_core::types::GovernanceEvent>, Self::Error> {\n            Ok(vec![])\n        }\n        async fn create_suppression(\n            &self,\n            _suppression: mk_core::types::DriftSuppression,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn list_suppressions(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _project_id: &str,\n        ) -> Result<Vec<mk_core::types::DriftSuppression>, Self::Error> {\n            Ok(vec![])\n        }\n        async fn delete_suppression(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _suppression_id: &str,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn get_drift_config(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _project_id: &str,\n        ) -> Result<Option<mk_core::types::DriftConfig>, Self::Error> {\n            Ok(None)\n        }\n        async fn save_drift_config(\n            &self,\n            _config: mk_core::types::DriftConfig,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn persist_event(\n            &self,\n            _event: mk_core::types::PersistentEvent,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn get_pending_events(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _limit: usize,\n        ) -> Result<Vec<mk_core::types::PersistentEvent>, Self::Error> {\n            Ok(vec![])\n        }\n        async fn update_event_status(\n            &self,\n            _event_id: &str,\n            _status: mk_core::types::EventStatus,\n            _error: Option<String>,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn get_dead_letter_events(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _limit: usize,\n        ) -> Result<Vec<mk_core::types::PersistentEvent>, Self::Error> {\n            Ok(vec![])\n        }\n        async fn check_idempotency(\n            &self,\n            _consumer_group: &str,\n            _idempotency_key: &str,\n        ) -> Result<bool, Self::Error> {\n            Ok(false)\n        }\n        async fn record_consumer_state(\n            &self,\n            _state: mk_core::types::ConsumerState,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn get_event_metrics(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _period_start: i64,\n            _period_end: i64,\n        ) -> Result<Vec<mk_core::types::EventDeliveryMetrics>, Self::Error> {\n            Ok(vec![])\n        }\n        async fn record_event_metrics(\n            &self,\n            _metrics: mk_core::types::EventDeliveryMetrics,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n    }\n\n    struct MockAuthService;\n\n    #[async_trait::async_trait]\n    impl mk_core::traits::AuthorizationService for MockAuthService {\n        type Error = anyhow::Error;\n        async fn check_permission(\n            &self,\n            _ctx: &mk_core::types::TenantContext,\n            _action: &str,\n            _resource: &str,\n        ) -> anyhow::Result<bool> {\n            Ok(true)\n        }\n        async fn get_user_roles(\n            &self,\n            _ctx: &mk_core::types::TenantContext,\n        ) -> anyhow::Result<Vec<mk_core::types::Role>> {\n            Ok(vec![])\n        }\n        async fn assign_role(\n            &self,\n            _ctx: &mk_core::types::TenantContext,\n            _user_id: &mk_core::types::UserId,\n            _role: mk_core::types::Role,\n        ) -> anyhow::Result<()> {\n            Ok(())\n        }\n        async fn remove_role(\n            &self,\n            _ctx: &mk_core::types::TenantContext,\n            _user_id: &mk_core::types::UserId,\n            _role: mk_core::types::Role,\n        ) -> anyhow::Result<()> {\n            Ok(())\n        }\n    }\n\n    struct MockRepo;\n    #[async_trait::async_trait]\n    impl mk_core::traits::KnowledgeRepository for MockRepo {\n        type Error = knowledge::repository::RepositoryError;\n        async fn store(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _: mk_core::types::KnowledgeEntry,\n            _: &str,\n        ) -> std::result::Result<String, Self::Error> {\n            Ok(\"hash\".into())\n        }\n        async fn get(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _: mk_core::types::KnowledgeLayer,\n            _: &str,\n        ) -> std::result::Result<Option<mk_core::types::KnowledgeEntry>, Self::Error> {\n            Ok(None)\n        }\n        async fn list(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _: mk_core::types::KnowledgeLayer,\n            _: &str,\n        ) -> std::result::Result<Vec<mk_core::types::KnowledgeEntry>, Self::Error> {\n            Ok(vec![])\n        }\n        async fn delete(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _: mk_core::types::KnowledgeLayer,\n            _: &str,\n            _: &str,\n        ) -> std::result::Result<String, Self::Error> {\n            Ok(\"hash\".into())\n        }\n        async fn get_head_commit(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n        ) -> std::result::Result<Option<String>, Self::Error> {\n            Ok(None)\n        }\n        async fn get_affected_items(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _: &str,\n        ) -> std::result::Result<Vec<(mk_core::types::KnowledgeLayer, String)>, Self::Error>\n        {\n            Ok(vec![])\n        }\n        async fn search(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _: &str,\n            _: Vec<mk_core::types::KnowledgeLayer>,\n            _: usize,\n        ) -> std::result::Result<Vec<mk_core::types::KnowledgeEntry>, Self::Error> {\n            Ok(vec![])\n        }\n        fn root_path(&self) -> Option<std::path::PathBuf> {\n            None\n        }\n    }\n\n    struct MockPersister;\n    #[async_trait::async_trait]\n    impl sync::state_persister::SyncStatePersister for MockPersister {\n        async fn load(\n            &self,\n            _tenant_id: &mk_core::types::TenantId,\n        ) -> std::result::Result<sync::state::SyncState, Box<dyn std::error::Error + Send + Sync>>\n        {\n            Ok(sync::state::SyncState::default())\n        }\n        async fn save(\n            &self,\n            _tenant_id: &mk_core::types::TenantId,\n            _: &sync::state::SyncState,\n        ) -> std::result::Result<(), Box<dyn std::error::Error + Send + Sync>> {\n            Ok(())\n        }\n    }\n\n    #[tokio::test]\n    async fn test_langchain_adapter_name() {\n        let server = Arc::new(setup_server().await);\n        let adapter = LangChainAdapter::new(server);\n        assert_eq!(adapter.name(), \"langchain\");\n    }\n\n    #[tokio::test]\n    async fn test_langchain_handle_request_missing_name() {\n        let server = Arc::new(setup_server().await);\n        let adapter = LangChainAdapter::new(server);\n        let request = json!({\"arguments\": {}});\n        let result = adapter.handle_mcp_request(request).await;\n        assert!(result.is_err());\n        assert_eq!(result.unwrap_err().to_string(), \"Missing tool name\");\n    }\n\n    #[tokio::test]\n    async fn test_to_langchain_tools_empty() {\n        let server = Arc::new(setup_server().await);\n        let adapter = LangChainAdapter::new(server);\n        let tools = adapter.to_langchain_tools();\n        assert!(!tools.is_empty());\n    }\n}\n","traces":[{"line":12,"address":[],"length":0,"stats":{"Line":6}},{"line":16,"address":[],"length":0,"stats":{"Line":3}},{"line":17,"address":[],"length":0,"stats":{"Line":3}},{"line":20,"address":[],"length":0,"stats":{"Line":69}},{"line":21,"address":[],"length":0,"stats":{"Line":198}},{"line":22,"address":[],"length":0,"stats":{"Line":198}},{"line":23,"address":[],"length":0,"stats":{"Line":198}},{"line":24,"address":[],"length":0,"stats":{"Line":198}},{"line":25,"address":[],"length":0,"stats":{"Line":132}},{"line":27,"address":[],"length":0,"stats":{"Line":264}},{"line":30,"address":[],"length":0,"stats":{"Line":66}},{"line":31,"address":[],"length":0,"stats":{"Line":66}},{"line":32,"address":[],"length":0,"stats":{"Line":66}},{"line":33,"address":[],"length":0,"stats":{"Line":66}},{"line":42,"address":[],"length":0,"stats":{"Line":1}},{"line":43,"address":[],"length":0,"stats":{"Line":1}},{"line":46,"address":[],"length":0,"stats":{"Line":3}},{"line":49,"address":[],"length":0,"stats":{"Line":2}}],"covered":18,"coverable":18},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","lib.rs"],"content":"//! # Adapters\n//!\n//! Provider and ecosystem adapters.\n\npub mod auth;\npub mod ecosystem;\npub mod hooks;\npub mod langchain;\npub mod opencode;\npub mod providers;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","opencode.rs"],"content":"\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","providers.rs"],"content":"\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","agent-a2a","src","main.rs"],"content":"fn main() {\n    println!(\"Hello, world!\");\n}\n","traces":[{"line":1,"address":[],"length":0,"stats":{"Line":0}},{"line":2,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":2},{"path":["/","Users","christian.klat","dev","git","aeterna","cli","src","commands","admin.rs"],"content":"use clap::{Args, Subcommand, ValueEnum};\nuse context::ContextResolver;\nuse serde_json::json;\nuse std::path::PathBuf;\n\nuse crate::output;\nuse crate::ux_error;\n\n#[derive(Subcommand)]\npub enum AdminCommand {\n    #[command(about = \"Check system health and connectivity\")]\n    Health(AdminHealthArgs),\n\n    #[command(about = \"Validate configuration and data integrity\")]\n    Validate(AdminValidateArgs),\n\n    #[command(about = \"Run database migrations\")]\n    Migrate(AdminMigrateArgs),\n\n    #[command(about = \"Detect configuration drift from expected state\")]\n    Drift(AdminDriftArgs),\n\n    #[command(about = \"Export data for backup or migration\")]\n    Export(AdminExportArgs),\n\n    #[command(about = \"Import data from backup or another instance\")]\n    Import(AdminImportArgs),\n}\n\n#[derive(Args)]\npub struct AdminHealthArgs {\n    /// Check specific component (memory, knowledge, policy, all)\n    #[arg(short, long, default_value = \"all\")]\n    pub component: String,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n\n    /// Verbose output with detailed metrics\n    #[arg(short, long)]\n    pub verbose: bool,\n\n    /// Timeout in seconds for health checks\n    #[arg(long, default_value = \"30\")]\n    pub timeout: u64,\n}\n\n#[derive(Args)]\npub struct AdminValidateArgs {\n    /// What to validate (config, schema, policies, all)\n    #[arg(short, long, default_value = \"all\")]\n    pub target: String,\n\n    /// Path to configuration file (defaults to auto-detect)\n    #[arg(long)]\n    pub config: Option<PathBuf>,\n\n    /// Strict mode - treat warnings as errors\n    #[arg(long)]\n    pub strict: bool,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct AdminMigrateArgs {\n    /// Migration direction (up, down, status)\n    #[arg(default_value = \"up\")]\n    pub direction: String,\n\n    /// Target version (latest if not specified)\n    #[arg(long)]\n    pub target: Option<String>,\n\n    /// Dry run - show what would be migrated\n    #[arg(long)]\n    pub dry_run: bool,\n\n    /// Force migration even if data loss may occur\n    #[arg(long)]\n    pub force: bool,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct AdminDriftArgs {\n    /// Expected state source (git, snapshot, file)\n    #[arg(long, default_value = \"git\")]\n    pub source: String,\n\n    /// Path to expected state file (for file source)\n    #[arg(long)]\n    pub expected: Option<PathBuf>,\n\n    /// What to check for drift (config, policies, schema, all)\n    #[arg(short, long, default_value = \"all\")]\n    pub target: String,\n\n    /// Auto-fix detected drift\n    #[arg(long)]\n    pub fix: bool,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct AdminExportArgs {\n    /// What to export (memories, knowledge, policies, config, all)\n    #[arg(short, long, default_value = \"all\")]\n    pub target: String,\n\n    /// Output file path\n    #[arg(short, long)]\n    pub output: Option<PathBuf>,\n\n    /// Export format (json, yaml, tar)\n    #[arg(long, default_value = \"json\")]\n    pub format: ExportFormat,\n\n    /// Include audit logs in export\n    #[arg(long)]\n    pub include_audit: bool,\n\n    /// Filter by layer (company, org, team, project)\n    #[arg(long)]\n    pub layer: Option<String>,\n\n    /// Compress output (gzip)\n    #[arg(long)]\n    pub compress: bool,\n\n    /// Output result as JSON (for scripting)\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct AdminImportArgs {\n    /// Input file path\n    pub input: PathBuf,\n\n    /// Import mode (merge, replace, skip-existing)\n    #[arg(long, default_value = \"merge\")]\n    pub mode: ImportMode,\n\n    /// Dry run - validate without importing\n    #[arg(long)]\n    pub dry_run: bool,\n\n    /// Skip validation (not recommended)\n    #[arg(long)]\n    pub skip_validation: bool,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Clone, Debug, ValueEnum)]\npub enum ExportFormat {\n    Json,\n    Yaml,\n    Tar,\n}\n\n#[derive(Clone, Debug, ValueEnum)]\npub enum ImportMode {\n    Merge,\n    Replace,\n    SkipExisting,\n}\n\npub async fn run(cmd: AdminCommand) -> anyhow::Result<()> {\n    match cmd {\n        AdminCommand::Health(args) => run_health(args).await,\n        AdminCommand::Validate(args) => run_validate(args).await,\n        AdminCommand::Migrate(args) => run_migrate(args).await,\n        AdminCommand::Drift(args) => run_drift(args).await,\n        AdminCommand::Export(args) => run_export(args).await,\n        AdminCommand::Import(args) => run_import(args).await,\n    }\n}\n\nasync fn run_health(args: AdminHealthArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let ctx = resolver.resolve()?;\n\n    // Health check results\n    let mut checks: Vec<HealthCheck> = Vec::new();\n\n    let components = if args.component == \"all\" {\n        vec![\"memory\", \"knowledge\", \"policy\", \"context\"]\n    } else {\n        vec![args.component.as_str()]\n    };\n\n    for component in &components {\n        let check = check_component_health(component, args.timeout).await;\n        checks.push(check);\n    }\n\n    let all_healthy = checks.iter().all(|c| c.status == \"healthy\");\n    let overall_status = if all_healthy { \"healthy\" } else { \"degraded\" };\n\n    if args.json {\n        let output = json!({\n            \"status\": overall_status,\n            \"context\": {\n                \"tenant_id\": ctx.tenant_id.value,\n                \"user_id\": ctx.user_id.value,\n                \"project_id\": ctx.project_id.as_ref().map(|v| &v.value),\n            },\n            \"checks\": checks.iter().map(|c| json!({\n                \"component\": c.component,\n                \"status\": c.status,\n                \"latency_ms\": c.latency_ms,\n                \"message\": c.message,\n                \"details\": c.details,\n            })).collect::<Vec<_>>(),\n            \"timestamp\": chrono::Utc::now().to_rfc3339(),\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(\"System Health Check\");\n        println!();\n\n        // Overall status\n        let status_icon = if all_healthy { \"\" } else { \"!\" };\n        let status_color = if all_healthy { \"green\" } else { \"yellow\" };\n        println!(\n            \"  Overall Status: {} {}\",\n            colored_status(status_icon, status_color),\n            overall_status.to_uppercase()\n        );\n        println!();\n\n        // Context info\n        output::subheader(\"Context\");\n        println!(\"  Tenant:  {}\", ctx.tenant_id.value);\n        println!(\"  User:    {}\", ctx.user_id.value);\n        println!(\n            \"  Project: {}\",\n            ctx.project_id\n                .as_ref()\n                .map(|v| v.value.as_str())\n                .unwrap_or(\"(auto-detect)\")\n        );\n        println!();\n\n        // Overall status\n        let status_icon = if all_healthy { \"\" } else { \"!\" };\n        let status_color = if all_healthy { \"green\" } else { \"yellow\" };\n        println!(\n            \"  Overall Status: {} {}\",\n            colored_status(status_icon, status_color),\n            overall_status.to_uppercase()\n        );\n        println!();\n\n        // Context info\n        output::subheader(\"Context\");\n        println!(\"  Tenant:  {}\", ctx.tenant_id.value);\n        println!(\"  User:    {}\", ctx.user_id.value);\n        println!(\n            \"  Project: {}\",\n            ctx.project_id\n                .as_ref()\n                .map(|v| v.value.as_str())\n                .unwrap_or(\"(auto-detect)\")\n        );\n        println!();\n\n        // Component checks\n        output::subheader(\"Components\");\n        for check in &checks {\n            let icon = match check.status.as_str() {\n                \"healthy\" => \"\",\n                \"degraded\" => \"!\",\n                \"unhealthy\" => \"\",\n                _ => \"?\",\n            };\n            let color = match check.status.as_str() {\n                \"healthy\" => \"green\",\n                \"degraded\" => \"yellow\",\n                \"unhealthy\" => \"red\",\n                _ => \"white\",\n            };\n\n            println!(\n                \"  {} {:<12} {:>6}ms  {}\",\n                colored_status(icon, color),\n                check.component,\n                check.latency_ms,\n                check.message\n            );\n\n            if args.verbose {\n                for (key, value) in &check.details {\n                    println!(\"      {}: {}\", key, value);\n                }\n            }\n        }\n        println!();\n\n        if !all_healthy {\n            output::hint(\"Run with --verbose for detailed diagnostics\");\n            output::hint(\"Check server logs for more information\");\n        }\n    }\n\n    Ok(())\n}\n\nasync fn run_validate(args: AdminValidateArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let _ctx = resolver.resolve()?;\n\n    let mut results: Vec<ValidationResult> = Vec::new();\n\n    let targets = if args.target == \"all\" {\n        vec![\"config\", \"schema\", \"policies\"]\n    } else {\n        vec![args.target.as_str()]\n    };\n\n    for target in &targets {\n        let result = validate_target(target, args.config.as_ref(), args.strict).await;\n        results.push(result);\n    }\n\n    let has_errors = results.iter().any(|r| !r.errors.is_empty());\n    let has_warnings = results.iter().any(|r| !r.warnings.is_empty());\n    let overall_valid = !has_errors && (!args.strict || !has_warnings);\n\n    if args.json {\n        let output = json!({\n            \"valid\": overall_valid,\n            \"strict_mode\": args.strict,\n            \"results\": results.iter().map(|r| json!({\n                \"target\": r.target,\n                \"valid\": r.errors.is_empty() && (!args.strict || r.warnings.is_empty()),\n                \"errors\": r.errors,\n                \"warnings\": r.warnings,\n                \"info\": r.info,\n            })).collect::<Vec<_>>(),\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(\"Configuration Validation\");\n        println!();\n\n        let status = if overall_valid { \"VALID\" } else { \"INVALID\" };\n        let icon = if overall_valid { \"\" } else { \"\" };\n        let color = if overall_valid { \"green\" } else { \"red\" };\n        println!(\"  Status: {} {}\", colored_status(icon, color), status);\n        if args.strict {\n            println!(\"  Mode: strict (warnings treated as errors)\");\n        }\n        println!();\n\n        for result in &results {\n            output::subheader(&format!(\"Target: {}\", result.target));\n\n            if result.errors.is_empty() && result.warnings.is_empty() {\n                println!(\"   No issues found\");\n            }\n\n            for error in &result.errors {\n                println!(\"   ERROR: {}\", error);\n            }\n\n            for warning in &result.warnings {\n                println!(\"  ! WARNING: {}\", warning);\n            }\n\n            for info in &result.info {\n                println!(\"   {}\", info);\n            }\n            println!();\n        }\n\n        if has_errors {\n            output::hint(\"Fix errors before proceeding\");\n        }\n    }\n\n    if has_errors {\n        std::process::exit(1);\n    }\n\n    Ok(())\n}\n\nasync fn run_migrate(args: AdminMigrateArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let _ctx = resolver.resolve()?;\n\n    // Migration status simulation\n    let current_version = \"2024.1.0\";\n    let target_version = args.target.as_deref().unwrap_or(\"2024.2.0\");\n\n    let migrations = vec![\n        Migration {\n            version: \"2024.1.1\".to_string(),\n            name: \"Add agent delegation table\".to_string(),\n            status: \"pending\".to_string(),\n            reversible: true,\n        },\n        Migration {\n            version: \"2024.1.2\".to_string(),\n            name: \"Add policy audit columns\".to_string(),\n            status: \"pending\".to_string(),\n            reversible: true,\n        },\n        Migration {\n            version: \"2024.2.0\".to_string(),\n            name: \"Cedar schema v2 upgrade\".to_string(),\n            status: \"pending\".to_string(),\n            reversible: false,\n        },\n    ];\n\n    let pending_count = migrations.iter().filter(|m| m.status == \"pending\").count();\n\n    if args.json {\n        let output = json!({\n            \"current_version\": current_version,\n            \"target_version\": target_version,\n            \"direction\": args.direction,\n            \"dry_run\": args.dry_run,\n            \"pending_migrations\": pending_count,\n            \"migrations\": migrations.iter().map(|m| json!({\n                \"version\": m.version,\n                \"name\": m.name,\n                \"status\": m.status,\n                \"reversible\": m.reversible,\n            })).collect::<Vec<_>>(),\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(\"Database Migration\");\n        println!();\n\n        println!(\"  Current Version: {}\", current_version);\n        println!(\"  Target Version:  {}\", target_version);\n        println!(\"  Direction:       {}\", args.direction);\n        if args.dry_run {\n            println!(\"  Mode:            DRY RUN (no changes will be made)\");\n        }\n        println!();\n\n        match args.direction.as_str() {\n            \"status\" => {\n                output::subheader(\"Migration Status\");\n                for migration in &migrations {\n                    let icon = match migration.status.as_str() {\n                        \"applied\" => \"\",\n                        \"pending\" => \"\",\n                        \"failed\" => \"\",\n                        _ => \"?\",\n                    };\n                    let reversible = if migration.reversible {\n                        \"\"\n                    } else {\n                        \" (irreversible)\"\n                    };\n                    println!(\n                        \"  {} {} - {}{}\",\n                        icon, migration.version, migration.name, reversible\n                    );\n                }\n                println!();\n                println!(\"  {} pending migration(s)\", pending_count);\n            }\n            \"up\" => {\n                output::subheader(\"Migrations to Apply\");\n                let to_apply: Vec<_> = migrations\n                    .iter()\n                    .filter(|m| m.status == \"pending\")\n                    .collect();\n\n                if to_apply.is_empty() {\n                    println!(\"   Database is up to date\");\n                } else {\n                    for migration in &to_apply {\n                        let reversible = if migration.reversible {\n                            \"\"\n                        } else {\n                            \"  IRREVERSIBLE\"\n                        };\n                        println!(\n                            \"   {} - {}{}\",\n                            migration.version, migration.name, reversible\n                        );\n                    }\n                    println!();\n\n                    if args.dry_run {\n                        output::hint(\"Remove --dry-run to apply migrations\");\n                    } else {\n                        // Simulate migration\n                        println!(\"  Applying migrations...\");\n                        for migration in &to_apply {\n                            println!(\"     Applied {}\", migration.version);\n                        }\n                        println!();\n                        println!(\"   All migrations applied successfully\");\n                    }\n                }\n            }\n            \"down\" => {\n                if !args.force {\n                    ux_error::UxError::new(\"Rollback requires --force flag\")\n                        .why(\"Rolling back migrations may cause data loss\")\n                        .fix(\"Add --force if you're sure you want to rollback\")\n                        .suggest(\"aeterna admin migrate down --force\")\n                        .display();\n                    std::process::exit(1);\n                }\n\n                output::subheader(\"Migrations to Rollback\");\n                println!(\"   Rolling back to {}\", target_version);\n                if args.dry_run {\n                    output::hint(\"Remove --dry-run to execute rollback\");\n                }\n            }\n            _ => {\n                ux_error::UxError::new(format!(\"Invalid migration direction: {}\", args.direction))\n                    .fix(\"Use one of: up, down, status\")\n                    .suggest(\"aeterna admin migrate status\")\n                    .display();\n                std::process::exit(1);\n            }\n        }\n        println!();\n    }\n\n    Ok(())\n}\n\nasync fn run_drift(args: AdminDriftArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let _ctx = resolver.resolve()?;\n\n    // Simulated drift detection results\n    let drifts = vec![\n        DriftItem {\n            target: \"config\".to_string(),\n            path: \".aeterna/context.toml\".to_string(),\n            drift_type: \"modified\".to_string(),\n            expected: \"timeout = 30\".to_string(),\n            actual: \"timeout = 60\".to_string(),\n            fixable: true,\n        },\n        DriftItem {\n            target: \"policies\".to_string(),\n            path: \"policies/security-baseline.cedar\".to_string(),\n            drift_type: \"missing\".to_string(),\n            expected: \"(file should exist)\".to_string(),\n            actual: \"(file not found)\".to_string(),\n            fixable: true,\n        },\n    ];\n\n    let has_drift = !drifts.is_empty();\n    let fixable_count = drifts.iter().filter(|d| d.fixable).count();\n\n    if args.json {\n        let output = json!({\n            \"source\": args.source,\n            \"has_drift\": has_drift,\n            \"drift_count\": drifts.len(),\n            \"fixable_count\": fixable_count,\n            \"drifts\": drifts.iter().map(|d| json!({\n                \"target\": d.target,\n                \"path\": d.path,\n                \"type\": d.drift_type,\n                \"expected\": d.expected,\n                \"actual\": d.actual,\n                \"fixable\": d.fixable,\n            })).collect::<Vec<_>>(),\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(\"Configuration Drift Detection\");\n        println!();\n\n        println!(\"  Source: {}\", args.source);\n        println!(\"  Target: {}\", args.target);\n        println!();\n\n        if drifts.is_empty() {\n            println!(\"   No drift detected - configuration matches expected state\");\n        } else {\n            output::subheader(&format!(\"Detected Drift ({} items)\", drifts.len()));\n\n            for drift in &drifts {\n                let icon = match drift.drift_type.as_str() {\n                    \"modified\" => \"~\",\n                    \"missing\" => \"-\",\n                    \"extra\" => \"+\",\n                    _ => \"?\",\n                };\n                let fixable = if drift.fixable { \" [fixable]\" } else { \"\" };\n\n                println!(\n                    \"  {} {} ({}){}\",\n                    icon, drift.path, drift.drift_type, fixable\n                );\n                println!(\"      Expected: {}\", drift.expected);\n                println!(\"      Actual:   {}\", drift.actual);\n                println!();\n            }\n\n            if args.fix {\n                println!(\"  Applying fixes...\");\n                for drift in &drifts {\n                    if drift.fixable {\n                        println!(\"     Fixed {}\", drift.path);\n                    } else {\n                        println!(\"    ! Cannot auto-fix {}\", drift.path);\n                    }\n                }\n                println!();\n            } else {\n                output::hint(&format!(\n                    \"Run with --fix to auto-correct {} fixable items\",\n                    fixable_count\n                ));\n            }\n        }\n    }\n\n    Ok(())\n}\n\nasync fn run_export(args: AdminExportArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let _ctx = resolver.resolve()?;\n\n    let output_path = args.output.unwrap_or_else(|| {\n        let timestamp = chrono::Utc::now().format(\"%Y%m%d_%H%M%S\");\n        let ext = match args.format {\n            ExportFormat::Json => \"json\",\n            ExportFormat::Yaml => \"yaml\",\n            ExportFormat::Tar => \"tar\",\n        };\n        let suffix = if args.compress { \".gz\" } else { \"\" };\n        PathBuf::from(format!(\"aeterna_export_{}.{}{}\", timestamp, ext, suffix))\n    });\n\n    // Simulated export statistics\n    let stats = ExportStats {\n        memories: 1247,\n        knowledge_items: 89,\n        policies: 23,\n        config_files: 4,\n        audit_entries: if args.include_audit { 15420 } else { 0 },\n    };\n\n    if args.json {\n        let output = json!({\n            \"success\": true,\n            \"output_path\": output_path.to_string_lossy(),\n            \"format\": format!(\"{:?}\", args.format).to_lowercase(),\n            \"compressed\": args.compress,\n            \"layer_filter\": args.layer,\n            \"include_audit\": args.include_audit,\n            \"statistics\": {\n                \"memories\": stats.memories,\n                \"knowledge_items\": stats.knowledge_items,\n                \"policies\": stats.policies,\n                \"config_files\": stats.config_files,\n                \"audit_entries\": stats.audit_entries,\n            },\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(\"Data Export\");\n        println!();\n\n        println!(\"  Target:      {}\", args.target);\n        println!(\"  Output:      {}\", output_path.display());\n        println!(\"  Format:      {:?}\", args.format);\n        if args.compress {\n            println!(\"  Compression: gzip\");\n        }\n        if let Some(layer) = &args.layer {\n            println!(\"  Layer:       {}\", layer);\n        }\n        println!();\n\n        output::subheader(\"Export Statistics\");\n        println!(\"  Memories:        {:>6}\", stats.memories);\n        println!(\"  Knowledge Items: {:>6}\", stats.knowledge_items);\n        println!(\"  Policies:        {:>6}\", stats.policies);\n        println!(\"  Config Files:    {:>6}\", stats.config_files);\n        if args.include_audit {\n            println!(\"  Audit Entries:   {:>6}\", stats.audit_entries);\n        }\n        println!();\n\n        // Simulate export progress\n        println!(\"  Exporting...\");\n        println!(\"     Memories exported\");\n        println!(\"     Knowledge exported\");\n        println!(\"     Policies exported\");\n        println!(\"     Config exported\");\n        if args.include_audit {\n            println!(\"     Audit log exported\");\n        }\n        println!();\n\n        println!(\"   Export complete: {}\", output_path.display());\n        println!();\n        output::hint(\"Use 'aeterna admin import' to restore this backup\");\n    }\n\n    Ok(())\n}\n\nasync fn run_import(args: AdminImportArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let _ctx = resolver.resolve()?;\n\n    if !args.input.exists() {\n        ux_error::UxError::new(format!(\"Import file not found: {}\", args.input.display()))\n            .why(\"The specified import file does not exist\")\n            .fix(\"Check the file path is correct\")\n            .fix(\"Ensure the file exists and is readable\")\n            .display();\n        std::process::exit(1);\n    }\n\n    // Simulated import analysis\n    let analysis = ImportAnalysis {\n        format: \"json\".to_string(),\n        source_version: \"2024.1.0\".to_string(),\n        memories: 1247,\n        knowledge_items: 89,\n        policies: 23,\n        conflicts: vec![\n            ImportConflict {\n                item_type: \"memory\".to_string(),\n                id: \"mem_abc123\".to_string(),\n                reason: \"Already exists with different content\".to_string(),\n            },\n            ImportConflict {\n                item_type: \"policy\".to_string(),\n                id: \"security-baseline\".to_string(),\n                reason: \"Version mismatch\".to_string(),\n            },\n        ],\n    };\n\n    if args.json {\n        let output = json!({\n            \"input_path\": args.input.to_string_lossy(),\n            \"mode\": format!(\"{:?}\", args.mode).to_lowercase(),\n            \"dry_run\": args.dry_run,\n            \"analysis\": {\n                \"format\": analysis.format,\n                \"source_version\": analysis.source_version,\n                \"memories\": analysis.memories,\n                \"knowledge_items\": analysis.knowledge_items,\n                \"policies\": analysis.policies,\n                \"conflicts\": analysis.conflicts.len(),\n            },\n            \"conflicts\": analysis.conflicts.iter().map(|c| json!({\n                \"type\": c.item_type,\n                \"id\": c.id,\n                \"reason\": c.reason,\n            })).collect::<Vec<_>>(),\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(\"Data Import\");\n        println!();\n\n        println!(\"  Input:   {}\", args.input.display());\n        println!(\"  Mode:    {:?}\", args.mode);\n        if args.dry_run {\n            println!(\"  Status:  DRY RUN (no changes will be made)\");\n        }\n        println!();\n\n        output::subheader(\"Import Analysis\");\n        println!(\"  Format:          {}\", analysis.format);\n        println!(\"  Source Version:  {}\", analysis.source_version);\n        println!(\"  Memories:        {}\", analysis.memories);\n        println!(\"  Knowledge Items: {}\", analysis.knowledge_items);\n        println!(\"  Policies:        {}\", analysis.policies);\n        println!();\n\n        if !analysis.conflicts.is_empty() {\n            output::subheader(&format!(\"Conflicts ({} items)\", analysis.conflicts.len()));\n            for conflict in &analysis.conflicts {\n                println!(\n                    \"  ! {} [{}]: {}\",\n                    conflict.item_type, conflict.id, conflict.reason\n                );\n            }\n            println!();\n\n            match args.mode {\n                ImportMode::Merge => {\n                    println!(\"  Mode 'merge': Conflicts will be resolved by keeping newer data\");\n                }\n                ImportMode::Replace => {\n                    println!(\"  Mode 'replace': Import data will overwrite existing data\");\n                }\n                ImportMode::SkipExisting => {\n                    println!(\"  Mode 'skip-existing': Conflicting items will be skipped\");\n                }\n            }\n            println!();\n        }\n\n        if args.dry_run {\n            output::hint(\"Remove --dry-run to execute import\");\n        } else if !args.skip_validation {\n            // Simulate import progress\n            println!(\"  Importing...\");\n            println!(\"     Validated import file\");\n            println!(\"     Imported {} memories\", analysis.memories);\n            println!(\n                \"     Imported {} knowledge items\",\n                analysis.knowledge_items\n            );\n            println!(\"     Imported {} policies\", analysis.policies);\n            if !analysis.conflicts.is_empty() {\n                println!(\n                    \"     {} conflicts resolved using {:?} mode\",\n                    analysis.conflicts.len(),\n                    args.mode\n                );\n            }\n            println!();\n            println!(\"   Import complete\");\n        }\n    }\n\n    Ok(())\n}\n\n// Helper types and functions\n\nstruct HealthCheck {\n    component: String,\n    status: String,\n    latency_ms: u64,\n    message: String,\n    details: std::collections::HashMap<String, String>,\n}\n\nasync fn check_component_health(component: &str, _timeout: u64) -> HealthCheck {\n    // Simulated health check - in real implementation, this would\n    // actually ping the various services\n    let mut details = std::collections::HashMap::new();\n\n    match component {\n        \"memory\" => {\n            details.insert(\"backend\".to_string(), \"qdrant\".to_string());\n            details.insert(\"vectors\".to_string(), \"1247\".to_string());\n            HealthCheck {\n                component: \"memory\".to_string(),\n                status: \"healthy\".to_string(),\n                latency_ms: 12,\n                message: \"Vector store responding\".to_string(),\n                details,\n            }\n        }\n        \"knowledge\" => {\n            details.insert(\"backend\".to_string(), \"git\".to_string());\n            details.insert(\"items\".to_string(), \"89\".to_string());\n            HealthCheck {\n                component: \"knowledge\".to_string(),\n                status: \"healthy\".to_string(),\n                latency_ms: 5,\n                message: \"Repository accessible\".to_string(),\n                details,\n            }\n        }\n        \"policy\" => {\n            details.insert(\"engine\".to_string(), \"cedar\".to_string());\n            details.insert(\"policies\".to_string(), \"23\".to_string());\n            HealthCheck {\n                component: \"policy\".to_string(),\n                status: \"healthy\".to_string(),\n                latency_ms: 8,\n                message: \"Cedar agent responding\".to_string(),\n                details,\n            }\n        }\n        \"context\" => {\n            details.insert(\"resolver\".to_string(), \"auto\".to_string());\n            HealthCheck {\n                component: \"context\".to_string(),\n                status: \"healthy\".to_string(),\n                latency_ms: 1,\n                message: \"Context resolution working\".to_string(),\n                details,\n            }\n        }\n        _ => HealthCheck {\n            component: component.to_string(),\n            status: \"unknown\".to_string(),\n            latency_ms: 0,\n            message: \"Unknown component\".to_string(),\n            details,\n        },\n    }\n}\n\nstruct ValidationResult {\n    target: String,\n    errors: Vec<String>,\n    warnings: Vec<String>,\n    info: Vec<String>,\n}\n\nasync fn validate_target(\n    target: &str,\n    _config_path: Option<&PathBuf>,\n    _strict: bool,\n) -> ValidationResult {\n    // Simulated validation - in real implementation, this would\n    // actually validate the various components\n    match target {\n        \"config\" => ValidationResult {\n            target: \"config\".to_string(),\n            errors: vec![],\n            warnings: vec![],\n            info: vec![\"Configuration file valid\".to_string()],\n        },\n        \"schema\" => ValidationResult {\n            target: \"schema\".to_string(),\n            errors: vec![],\n            warnings: vec![],\n            info: vec![\"Database schema matches expected version\".to_string()],\n        },\n        \"policies\" => ValidationResult {\n            target: \"policies\".to_string(),\n            errors: vec![],\n            warnings: vec![\"Policy 'legacy-compat' uses deprecated syntax\".to_string()],\n            info: vec![\"23 policies validated\".to_string()],\n        },\n        _ => ValidationResult {\n            target: target.to_string(),\n            errors: vec![format!(\"Unknown validation target: {}\", target)],\n            warnings: vec![],\n            info: vec![],\n        },\n    }\n}\n\nstruct Migration {\n    version: String,\n    name: String,\n    status: String,\n    reversible: bool,\n}\n\nstruct DriftItem {\n    target: String,\n    path: String,\n    drift_type: String,\n    expected: String,\n    actual: String,\n    fixable: bool,\n}\n\nstruct ExportStats {\n    memories: u64,\n    knowledge_items: u64,\n    policies: u64,\n    config_files: u64,\n    audit_entries: u64,\n}\n\nstruct ImportAnalysis {\n    format: String,\n    source_version: String,\n    memories: u64,\n    knowledge_items: u64,\n    policies: u64,\n    conflicts: Vec<ImportConflict>,\n}\n\nstruct ImportConflict {\n    item_type: String,\n    id: String,\n    reason: String,\n}\n\nfn colored_status(icon: &str, color: &str) -> String {\n    use colored::Colorize;\n    match color {\n        \"green\" => icon.green().to_string(),\n        \"yellow\" => icon.yellow().to_string(),\n        \"red\" => icon.red().to_string(),\n        _ => icon.white().to_string(),\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_health_check_all_components() {\n        let memory = check_component_health(\"memory\", 30).await;\n        assert_eq!(memory.status, \"healthy\");\n\n        let knowledge = check_component_health(\"knowledge\", 30).await;\n        assert_eq!(knowledge.status, \"healthy\");\n\n        let policy = check_component_health(\"policy\", 30).await;\n        assert_eq!(policy.status, \"healthy\");\n\n        let context = check_component_health(\"context\", 30).await;\n        assert_eq!(context.status, \"healthy\");\n    }\n\n    #[tokio::test]\n    async fn test_health_check_unknown_component() {\n        let unknown = check_component_health(\"unknown\", 30).await;\n        assert_eq!(unknown.status, \"unknown\");\n    }\n\n    #[tokio::test]\n    async fn test_validate_config() {\n        let result = validate_target(\"config\", None, false).await;\n        assert!(result.errors.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_validate_policies_warnings() {\n        let result = validate_target(\"policies\", None, false).await;\n        assert!(result.errors.is_empty());\n        assert!(!result.warnings.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_validate_unknown_target() {\n        let result = validate_target(\"invalid\", None, false).await;\n        assert!(!result.errors.is_empty());\n    }\n\n    #[test]\n    fn test_export_format_values() {\n        let _json = ExportFormat::Json;\n        let _yaml = ExportFormat::Yaml;\n        let _tar = ExportFormat::Tar;\n    }\n\n    #[test]\n    fn test_import_mode_values() {\n        let _merge = ImportMode::Merge;\n        let _replace = ImportMode::Replace;\n        let _skip = ImportMode::SkipExisting;\n    }\n\n    #[test]\n    fn test_admin_health_args_defaults() {\n        let args = AdminHealthArgs {\n            component: \"all\".to_string(),\n            json: false,\n            verbose: false,\n            timeout: 30,\n        };\n        assert_eq!(args.component, \"all\");\n        assert!(!args.json);\n        assert!(!args.verbose);\n        assert_eq!(args.timeout, 30);\n    }\n\n    #[test]\n    fn test_admin_health_args_with_options() {\n        let args = AdminHealthArgs {\n            component: \"memory\".to_string(),\n            json: true,\n            verbose: true,\n            timeout: 60,\n        };\n        assert_eq!(args.component, \"memory\");\n        assert!(args.json);\n        assert!(args.verbose);\n        assert_eq!(args.timeout, 60);\n    }\n\n    #[test]\n    fn test_admin_validate_args_defaults() {\n        let args = AdminValidateArgs {\n            target: \"all\".to_string(),\n            config: None,\n            strict: false,\n            json: false,\n        };\n        assert_eq!(args.target, \"all\");\n        assert!(args.config.is_none());\n        assert!(!args.strict);\n        assert!(!args.json);\n    }\n\n    #[test]\n    fn test_admin_validate_args_with_config() {\n        let args = AdminValidateArgs {\n            target: \"config\".to_string(),\n            config: Some(PathBuf::from(\"/path/to/config.toml\")),\n            strict: true,\n            json: true,\n        };\n        assert_eq!(args.target, \"config\");\n        assert!(args.config.is_some());\n        assert!(args.strict);\n        assert!(args.json);\n    }\n\n    #[test]\n    fn test_admin_migrate_args_defaults() {\n        let args = AdminMigrateArgs {\n            direction: \"up\".to_string(),\n            target: None,\n            dry_run: false,\n            force: false,\n            json: false,\n        };\n        assert_eq!(args.direction, \"up\");\n        assert!(args.target.is_none());\n        assert!(!args.dry_run);\n        assert!(!args.force);\n    }\n\n    #[test]\n    fn test_admin_migrate_args_down_with_force() {\n        let args = AdminMigrateArgs {\n            direction: \"down\".to_string(),\n            target: Some(\"2024.1.0\".to_string()),\n            dry_run: false,\n            force: true,\n            json: true,\n        };\n        assert_eq!(args.direction, \"down\");\n        assert_eq!(args.target, Some(\"2024.1.0\".to_string()));\n        assert!(args.force);\n    }\n\n    #[test]\n    fn test_admin_migrate_args_status() {\n        let args = AdminMigrateArgs {\n            direction: \"status\".to_string(),\n            target: None,\n            dry_run: false,\n            force: false,\n            json: false,\n        };\n        assert_eq!(args.direction, \"status\");\n    }\n\n    #[test]\n    fn test_admin_drift_args_defaults() {\n        let args = AdminDriftArgs {\n            source: \"git\".to_string(),\n            expected: None,\n            target: \"all\".to_string(),\n            fix: false,\n            json: false,\n        };\n        assert_eq!(args.source, \"git\");\n        assert!(args.expected.is_none());\n        assert_eq!(args.target, \"all\");\n        assert!(!args.fix);\n    }\n\n    #[test]\n    fn test_admin_drift_args_with_file_source() {\n        let args = AdminDriftArgs {\n            source: \"file\".to_string(),\n            expected: Some(PathBuf::from(\"/path/to/expected.json\")),\n            target: \"config\".to_string(),\n            fix: true,\n            json: true,\n        };\n        assert_eq!(args.source, \"file\");\n        assert!(args.expected.is_some());\n        assert!(args.fix);\n    }\n\n    #[test]\n    fn test_admin_export_args_defaults() {\n        let args = AdminExportArgs {\n            target: \"all\".to_string(),\n            output: None,\n            format: ExportFormat::Json,\n            include_audit: false,\n            layer: None,\n            compress: false,\n            json: false,\n        };\n        assert_eq!(args.target, \"all\");\n        assert!(args.output.is_none());\n        assert!(!args.include_audit);\n        assert!(!args.compress);\n    }\n\n    #[test]\n    fn test_admin_export_args_full_options() {\n        let args = AdminExportArgs {\n            target: \"memories\".to_string(),\n            output: Some(PathBuf::from(\"/backup/export.tar.gz\")),\n            format: ExportFormat::Tar,\n            include_audit: true,\n            layer: Some(\"company\".to_string()),\n            compress: true,\n            json: true,\n        };\n        assert_eq!(args.target, \"memories\");\n        assert!(args.output.is_some());\n        assert!(args.include_audit);\n        assert!(args.compress);\n        assert_eq!(args.layer, Some(\"company\".to_string()));\n    }\n\n    #[test]\n    fn test_admin_import_args_defaults() {\n        let args = AdminImportArgs {\n            input: PathBuf::from(\"/backup/export.json\"),\n            mode: ImportMode::Merge,\n            dry_run: false,\n            skip_validation: false,\n            json: false,\n        };\n        assert_eq!(args.input, PathBuf::from(\"/backup/export.json\"));\n        assert!(!args.dry_run);\n        assert!(!args.skip_validation);\n    }\n\n    #[test]\n    fn test_admin_import_args_replace_mode() {\n        let args = AdminImportArgs {\n            input: PathBuf::from(\"/backup/export.json\"),\n            mode: ImportMode::Replace,\n            dry_run: true,\n            skip_validation: false,\n            json: true,\n        };\n        assert!(args.dry_run);\n    }\n\n    #[test]\n    fn test_admin_import_args_skip_existing() {\n        let args = AdminImportArgs {\n            input: PathBuf::from(\"/backup/export.json\"),\n            mode: ImportMode::SkipExisting,\n            dry_run: false,\n            skip_validation: true,\n            json: false,\n        };\n        assert!(args.skip_validation);\n    }\n\n    #[test]\n    fn test_health_check_struct() {\n        let mut details = std::collections::HashMap::new();\n        details.insert(\"backend\".to_string(), \"qdrant\".to_string());\n\n        let check = HealthCheck {\n            component: \"memory\".to_string(),\n            status: \"healthy\".to_string(),\n            latency_ms: 15,\n            message: \"Vector store responding\".to_string(),\n            details,\n        };\n        assert_eq!(check.component, \"memory\");\n        assert_eq!(check.status, \"healthy\");\n        assert_eq!(check.latency_ms, 15);\n        assert_eq!(check.details.get(\"backend\"), Some(&\"qdrant\".to_string()));\n    }\n\n    #[test]\n    fn test_validation_result_no_issues() {\n        let result = ValidationResult {\n            target: \"config\".to_string(),\n            errors: vec![],\n            warnings: vec![],\n            info: vec![\"All good\".to_string()],\n        };\n        assert!(result.errors.is_empty());\n        assert!(result.warnings.is_empty());\n        assert!(!result.info.is_empty());\n    }\n\n    #[test]\n    fn test_validation_result_with_errors() {\n        let result = ValidationResult {\n            target: \"schema\".to_string(),\n            errors: vec![\"Missing required field\".to_string()],\n            warnings: vec![\"Deprecated syntax\".to_string()],\n            info: vec![],\n        };\n        assert!(!result.errors.is_empty());\n        assert!(!result.warnings.is_empty());\n        assert!(result.info.is_empty());\n    }\n\n    #[test]\n    fn test_migration_struct() {\n        let migration = Migration {\n            version: \"2024.1.1\".to_string(),\n            name: \"Add agent delegation table\".to_string(),\n            status: \"pending\".to_string(),\n            reversible: true,\n        };\n        assert_eq!(migration.version, \"2024.1.1\");\n        assert_eq!(migration.status, \"pending\");\n        assert!(migration.reversible);\n    }\n\n    #[test]\n    fn test_migration_irreversible() {\n        let migration = Migration {\n            version: \"2024.2.0\".to_string(),\n            name: \"Cedar schema v2 upgrade\".to_string(),\n            status: \"applied\".to_string(),\n            reversible: false,\n        };\n        assert!(!migration.reversible);\n        assert_eq!(migration.status, \"applied\");\n    }\n\n    #[test]\n    fn test_drift_item_modified() {\n        let drift = DriftItem {\n            target: \"config\".to_string(),\n            path: \".aeterna/context.toml\".to_string(),\n            drift_type: \"modified\".to_string(),\n            expected: \"timeout = 30\".to_string(),\n            actual: \"timeout = 60\".to_string(),\n            fixable: true,\n        };\n        assert_eq!(drift.drift_type, \"modified\");\n        assert!(drift.fixable);\n    }\n\n    #[test]\n    fn test_drift_item_missing() {\n        let drift = DriftItem {\n            target: \"policies\".to_string(),\n            path: \"policies/security-baseline.cedar\".to_string(),\n            drift_type: \"missing\".to_string(),\n            expected: \"(file should exist)\".to_string(),\n            actual: \"(file not found)\".to_string(),\n            fixable: true,\n        };\n        assert_eq!(drift.drift_type, \"missing\");\n    }\n\n    #[test]\n    fn test_drift_item_extra() {\n        let drift = DriftItem {\n            target: \"config\".to_string(),\n            path: \".aeterna/local.toml\".to_string(),\n            drift_type: \"extra\".to_string(),\n            expected: \"(should not exist)\".to_string(),\n            actual: \"(file found)\".to_string(),\n            fixable: false,\n        };\n        assert_eq!(drift.drift_type, \"extra\");\n        assert!(!drift.fixable);\n    }\n\n    #[test]\n    fn test_export_stats() {\n        let stats = ExportStats {\n            memories: 1000,\n            knowledge_items: 50,\n            policies: 25,\n            config_files: 5,\n            audit_entries: 10000,\n        };\n        assert_eq!(stats.memories, 1000);\n        assert_eq!(stats.knowledge_items, 50);\n        assert_eq!(stats.policies, 25);\n        assert_eq!(stats.config_files, 5);\n        assert_eq!(stats.audit_entries, 10000);\n    }\n\n    #[test]\n    fn test_export_stats_no_audit() {\n        let stats = ExportStats {\n            memories: 500,\n            knowledge_items: 20,\n            policies: 10,\n            config_files: 3,\n            audit_entries: 0,\n        };\n        assert_eq!(stats.audit_entries, 0);\n    }\n\n    #[test]\n    fn test_import_analysis() {\n        let analysis = ImportAnalysis {\n            format: \"json\".to_string(),\n            source_version: \"2024.1.0\".to_string(),\n            memories: 100,\n            knowledge_items: 10,\n            policies: 5,\n            conflicts: vec![],\n        };\n        assert_eq!(analysis.format, \"json\");\n        assert!(analysis.conflicts.is_empty());\n    }\n\n    #[test]\n    fn test_import_analysis_with_conflicts() {\n        let conflicts = vec![\n            ImportConflict {\n                item_type: \"memory\".to_string(),\n                id: \"mem_123\".to_string(),\n                reason: \"Already exists\".to_string(),\n            },\n            ImportConflict {\n                item_type: \"policy\".to_string(),\n                id: \"security-baseline\".to_string(),\n                reason: \"Version mismatch\".to_string(),\n            },\n        ];\n        let analysis = ImportAnalysis {\n            format: \"yaml\".to_string(),\n            source_version: \"2024.0.5\".to_string(),\n            memories: 50,\n            knowledge_items: 5,\n            policies: 3,\n            conflicts,\n        };\n        assert_eq!(analysis.conflicts.len(), 2);\n    }\n\n    #[test]\n    fn test_import_conflict() {\n        let conflict = ImportConflict {\n            item_type: \"memory\".to_string(),\n            id: \"mem_abc123\".to_string(),\n            reason: \"Already exists with different content\".to_string(),\n        };\n        assert_eq!(conflict.item_type, \"memory\");\n        assert_eq!(conflict.id, \"mem_abc123\");\n    }\n\n    #[test]\n    fn test_colored_status_green() {\n        let result = colored_status(\"\", \"green\");\n        assert!(result.contains(\"\"));\n    }\n\n    #[test]\n    fn test_colored_status_yellow() {\n        let result = colored_status(\"!\", \"yellow\");\n        assert!(result.contains(\"!\"));\n    }\n\n    #[test]\n    fn test_colored_status_red() {\n        let result = colored_status(\"\", \"red\");\n        assert!(result.contains(\"\"));\n    }\n\n    #[test]\n    fn test_colored_status_white_default() {\n        let result = colored_status(\"?\", \"unknown\");\n        assert!(result.contains(\"?\"));\n    }\n\n    #[tokio::test]\n    async fn test_health_check_memory_details() {\n        let check = check_component_health(\"memory\", 30).await;\n        assert_eq!(check.details.get(\"backend\"), Some(&\"qdrant\".to_string()));\n        assert!(check.details.contains_key(\"vectors\"));\n    }\n\n    #[tokio::test]\n    async fn test_health_check_knowledge_details() {\n        let check = check_component_health(\"knowledge\", 30).await;\n        assert_eq!(check.details.get(\"backend\"), Some(&\"git\".to_string()));\n        assert!(check.details.contains_key(\"items\"));\n    }\n\n    #[tokio::test]\n    async fn test_health_check_policy_details() {\n        let check = check_component_health(\"policy\", 30).await;\n        assert_eq!(check.details.get(\"engine\"), Some(&\"cedar\".to_string()));\n        assert!(check.details.contains_key(\"policies\"));\n    }\n\n    #[tokio::test]\n    async fn test_health_check_context_details() {\n        let check = check_component_health(\"context\", 30).await;\n        assert_eq!(check.details.get(\"resolver\"), Some(&\"auto\".to_string()));\n    }\n\n    #[tokio::test]\n    async fn test_validate_schema() {\n        let result = validate_target(\"schema\", None, false).await;\n        assert!(result.errors.is_empty());\n        assert!(result.warnings.is_empty());\n        assert!(!result.info.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_validate_with_strict_mode() {\n        let result = validate_target(\"config\", None, true).await;\n        assert!(result.errors.is_empty());\n    }\n}\n","traces":[{"line":181,"address":[],"length":0,"stats":{"Line":2}},{"line":182,"address":[],"length":0,"stats":{"Line":1}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":3}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":205,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":207,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":221,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":223,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":225,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":240,"address":[],"length":0,"stats":{"Line":0}},{"line":241,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":0}},{"line":252,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":0}},{"line":254,"address":[],"length":0,"stats":{"Line":0}},{"line":256,"address":[],"length":0,"stats":{"Line":0}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":264,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":270,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":272,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":274,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":276,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":284,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":298,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":0}},{"line":323,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":334,"address":[],"length":0,"stats":{"Line":0}},{"line":335,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":343,"address":[],"length":0,"stats":{"Line":0}},{"line":344,"address":[],"length":0,"stats":{"Line":0}},{"line":345,"address":[],"length":0,"stats":{"Line":0}},{"line":346,"address":[],"length":0,"stats":{"Line":0}},{"line":347,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":0}},{"line":350,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":353,"address":[],"length":0,"stats":{"Line":0}},{"line":355,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":358,"address":[],"length":0,"stats":{"Line":0}},{"line":360,"address":[],"length":0,"stats":{"Line":0}},{"line":361,"address":[],"length":0,"stats":{"Line":0}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":363,"address":[],"length":0,"stats":{"Line":0}},{"line":364,"address":[],"length":0,"stats":{"Line":0}},{"line":365,"address":[],"length":0,"stats":{"Line":0}},{"line":367,"address":[],"length":0,"stats":{"Line":0}},{"line":369,"address":[],"length":0,"stats":{"Line":0}},{"line":370,"address":[],"length":0,"stats":{"Line":0}},{"line":372,"address":[],"length":0,"stats":{"Line":0}},{"line":373,"address":[],"length":0,"stats":{"Line":0}},{"line":376,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":380,"address":[],"length":0,"stats":{"Line":0}},{"line":381,"address":[],"length":0,"stats":{"Line":0}},{"line":384,"address":[],"length":0,"stats":{"Line":0}},{"line":385,"address":[],"length":0,"stats":{"Line":0}},{"line":387,"address":[],"length":0,"stats":{"Line":0}},{"line":390,"address":[],"length":0,"stats":{"Line":0}},{"line":391,"address":[],"length":0,"stats":{"Line":0}},{"line":395,"address":[],"length":0,"stats":{"Line":0}},{"line":396,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":402,"address":[],"length":0,"stats":{"Line":2}},{"line":403,"address":[],"length":0,"stats":{"Line":2}},{"line":404,"address":[],"length":0,"stats":{"Line":3}},{"line":407,"address":[],"length":0,"stats":{"Line":2}},{"line":408,"address":[],"length":0,"stats":{"Line":5}},{"line":410,"address":[],"length":0,"stats":{"Line":2}},{"line":411,"address":[],"length":0,"stats":{"Line":1}},{"line":412,"address":[],"length":0,"stats":{"Line":3}},{"line":413,"address":[],"length":0,"stats":{"Line":3}},{"line":414,"address":[],"length":0,"stats":{"Line":1}},{"line":415,"address":[],"length":0,"stats":{"Line":1}},{"line":417,"address":[],"length":0,"stats":{"Line":1}},{"line":418,"address":[],"length":0,"stats":{"Line":3}},{"line":419,"address":[],"length":0,"stats":{"Line":3}},{"line":420,"address":[],"length":0,"stats":{"Line":1}},{"line":421,"address":[],"length":0,"stats":{"Line":1}},{"line":423,"address":[],"length":0,"stats":{"Line":1}},{"line":424,"address":[],"length":0,"stats":{"Line":3}},{"line":425,"address":[],"length":0,"stats":{"Line":3}},{"line":426,"address":[],"length":0,"stats":{"Line":1}},{"line":427,"address":[],"length":0,"stats":{"Line":1}},{"line":431,"address":[],"length":0,"stats":{"Line":10}},{"line":433,"address":[],"length":0,"stats":{"Line":1}},{"line":434,"address":[],"length":0,"stats":{"Line":0}},{"line":435,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":0}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":441,"address":[],"length":0,"stats":{"Line":0}},{"line":442,"address":[],"length":0,"stats":{"Line":0}},{"line":443,"address":[],"length":0,"stats":{"Line":0}},{"line":444,"address":[],"length":0,"stats":{"Line":0}},{"line":445,"address":[],"length":0,"stats":{"Line":0}},{"line":447,"address":[],"length":0,"stats":{"Line":0}},{"line":449,"address":[],"length":0,"stats":{"Line":2}},{"line":450,"address":[],"length":0,"stats":{"Line":1}},{"line":452,"address":[],"length":0,"stats":{"Line":2}},{"line":453,"address":[],"length":0,"stats":{"Line":2}},{"line":454,"address":[],"length":0,"stats":{"Line":2}},{"line":455,"address":[],"length":0,"stats":{"Line":1}},{"line":456,"address":[],"length":0,"stats":{"Line":0}},{"line":458,"address":[],"length":0,"stats":{"Line":1}},{"line":460,"address":[],"length":0,"stats":{"Line":1}},{"line":461,"address":[],"length":0,"stats":{"Line":1}},{"line":462,"address":[],"length":0,"stats":{"Line":2}},{"line":463,"address":[],"length":0,"stats":{"Line":7}},{"line":464,"address":[],"length":0,"stats":{"Line":6}},{"line":465,"address":[],"length":0,"stats":{"Line":3}},{"line":466,"address":[],"length":0,"stats":{"Line":6}},{"line":467,"address":[],"length":0,"stats":{"Line":0}},{"line":468,"address":[],"length":0,"stats":{"Line":0}},{"line":470,"address":[],"length":0,"stats":{"Line":6}},{"line":471,"address":[],"length":0,"stats":{"Line":2}},{"line":473,"address":[],"length":0,"stats":{"Line":1}},{"line":475,"address":[],"length":0,"stats":{"Line":3}},{"line":476,"address":[],"length":0,"stats":{"Line":3}},{"line":480,"address":[],"length":0,"stats":{"Line":1}},{"line":481,"address":[],"length":0,"stats":{"Line":2}},{"line":483,"address":[],"length":0,"stats":{"Line":0}},{"line":484,"address":[],"length":0,"stats":{"Line":0}},{"line":485,"address":[],"length":0,"stats":{"Line":0}},{"line":487,"address":[],"length":0,"stats":{"Line":0}},{"line":490,"address":[],"length":0,"stats":{"Line":0}},{"line":491,"address":[],"length":0,"stats":{"Line":0}},{"line":493,"address":[],"length":0,"stats":{"Line":0}},{"line":494,"address":[],"length":0,"stats":{"Line":0}},{"line":495,"address":[],"length":0,"stats":{"Line":0}},{"line":497,"address":[],"length":0,"stats":{"Line":0}},{"line":499,"address":[],"length":0,"stats":{"Line":0}},{"line":500,"address":[],"length":0,"stats":{"Line":0}},{"line":504,"address":[],"length":0,"stats":{"Line":0}},{"line":506,"address":[],"length":0,"stats":{"Line":0}},{"line":507,"address":[],"length":0,"stats":{"Line":0}},{"line":510,"address":[],"length":0,"stats":{"Line":0}},{"line":511,"address":[],"length":0,"stats":{"Line":0}},{"line":512,"address":[],"length":0,"stats":{"Line":0}},{"line":514,"address":[],"length":0,"stats":{"Line":0}},{"line":515,"address":[],"length":0,"stats":{"Line":0}},{"line":519,"address":[],"length":0,"stats":{"Line":0}},{"line":520,"address":[],"length":0,"stats":{"Line":0}},{"line":521,"address":[],"length":0,"stats":{"Line":0}},{"line":526,"address":[],"length":0,"stats":{"Line":0}},{"line":529,"address":[],"length":0,"stats":{"Line":0}},{"line":530,"address":[],"length":0,"stats":{"Line":0}},{"line":531,"address":[],"length":0,"stats":{"Line":0}},{"line":532,"address":[],"length":0,"stats":{"Line":0}},{"line":536,"address":[],"length":0,"stats":{"Line":0}},{"line":540,"address":[],"length":0,"stats":{"Line":0}},{"line":543,"address":[],"length":0,"stats":{"Line":1}},{"line":546,"address":[],"length":0,"stats":{"Line":1}},{"line":549,"address":[],"length":0,"stats":{"Line":0}},{"line":550,"address":[],"length":0,"stats":{"Line":0}},{"line":551,"address":[],"length":0,"stats":{"Line":0}},{"line":554,"address":[],"length":0,"stats":{"Line":0}},{"line":555,"address":[],"length":0,"stats":{"Line":0}},{"line":556,"address":[],"length":0,"stats":{"Line":0}},{"line":557,"address":[],"length":0,"stats":{"Line":0}},{"line":558,"address":[],"length":0,"stats":{"Line":0}},{"line":559,"address":[],"length":0,"stats":{"Line":0}},{"line":560,"address":[],"length":0,"stats":{"Line":0}},{"line":561,"address":[],"length":0,"stats":{"Line":0}},{"line":563,"address":[],"length":0,"stats":{"Line":0}},{"line":564,"address":[],"length":0,"stats":{"Line":0}},{"line":565,"address":[],"length":0,"stats":{"Line":0}},{"line":566,"address":[],"length":0,"stats":{"Line":0}},{"line":567,"address":[],"length":0,"stats":{"Line":0}},{"line":568,"address":[],"length":0,"stats":{"Line":0}},{"line":569,"address":[],"length":0,"stats":{"Line":0}},{"line":573,"address":[],"length":0,"stats":{"Line":0}},{"line":574,"address":[],"length":0,"stats":{"Line":0}},{"line":576,"address":[],"length":0,"stats":{"Line":0}},{"line":577,"address":[],"length":0,"stats":{"Line":0}},{"line":578,"address":[],"length":0,"stats":{"Line":0}},{"line":579,"address":[],"length":0,"stats":{"Line":0}},{"line":580,"address":[],"length":0,"stats":{"Line":0}},{"line":581,"address":[],"length":0,"stats":{"Line":0}},{"line":582,"address":[],"length":0,"stats":{"Line":0}},{"line":583,"address":[],"length":0,"stats":{"Line":0}},{"line":584,"address":[],"length":0,"stats":{"Line":0}},{"line":585,"address":[],"length":0,"stats":{"Line":0}},{"line":586,"address":[],"length":0,"stats":{"Line":0}},{"line":587,"address":[],"length":0,"stats":{"Line":0}},{"line":588,"address":[],"length":0,"stats":{"Line":0}},{"line":589,"address":[],"length":0,"stats":{"Line":0}},{"line":591,"address":[],"length":0,"stats":{"Line":0}},{"line":593,"address":[],"length":0,"stats":{"Line":0}},{"line":594,"address":[],"length":0,"stats":{"Line":0}},{"line":596,"address":[],"length":0,"stats":{"Line":0}},{"line":597,"address":[],"length":0,"stats":{"Line":0}},{"line":598,"address":[],"length":0,"stats":{"Line":0}},{"line":600,"address":[],"length":0,"stats":{"Line":0}},{"line":601,"address":[],"length":0,"stats":{"Line":0}},{"line":603,"address":[],"length":0,"stats":{"Line":0}},{"line":605,"address":[],"length":0,"stats":{"Line":0}},{"line":606,"address":[],"length":0,"stats":{"Line":0}},{"line":607,"address":[],"length":0,"stats":{"Line":0}},{"line":608,"address":[],"length":0,"stats":{"Line":0}},{"line":609,"address":[],"length":0,"stats":{"Line":0}},{"line":610,"address":[],"length":0,"stats":{"Line":0}},{"line":612,"address":[],"length":0,"stats":{"Line":0}},{"line":614,"address":[],"length":0,"stats":{"Line":0}},{"line":615,"address":[],"length":0,"stats":{"Line":0}},{"line":618,"address":[],"length":0,"stats":{"Line":0}},{"line":619,"address":[],"length":0,"stats":{"Line":0}},{"line":620,"address":[],"length":0,"stats":{"Line":0}},{"line":623,"address":[],"length":0,"stats":{"Line":0}},{"line":624,"address":[],"length":0,"stats":{"Line":0}},{"line":625,"address":[],"length":0,"stats":{"Line":0}},{"line":626,"address":[],"length":0,"stats":{"Line":0}},{"line":627,"address":[],"length":0,"stats":{"Line":0}},{"line":629,"address":[],"length":0,"stats":{"Line":0}},{"line":632,"address":[],"length":0,"stats":{"Line":0}},{"line":634,"address":[],"length":0,"stats":{"Line":0}},{"line":635,"address":[],"length":0,"stats":{"Line":0}},{"line":636,"address":[],"length":0,"stats":{"Line":0}},{"line":642,"address":[],"length":0,"stats":{"Line":0}},{"line":645,"address":[],"length":0,"stats":{"Line":0}},{"line":646,"address":[],"length":0,"stats":{"Line":0}},{"line":647,"address":[],"length":0,"stats":{"Line":0}},{"line":649,"address":[],"length":0,"stats":{"Line":0}},{"line":650,"address":[],"length":0,"stats":{"Line":0}},{"line":651,"address":[],"length":0,"stats":{"Line":0}},{"line":652,"address":[],"length":0,"stats":{"Line":0}},{"line":653,"address":[],"length":0,"stats":{"Line":0}},{"line":654,"address":[],"length":0,"stats":{"Line":0}},{"line":656,"address":[],"length":0,"stats":{"Line":0}},{"line":657,"address":[],"length":0,"stats":{"Line":0}},{"line":666,"address":[],"length":0,"stats":{"Line":0}},{"line":669,"address":[],"length":0,"stats":{"Line":0}},{"line":670,"address":[],"length":0,"stats":{"Line":0}},{"line":671,"address":[],"length":0,"stats":{"Line":0}},{"line":672,"address":[],"length":0,"stats":{"Line":0}},{"line":673,"address":[],"length":0,"stats":{"Line":0}},{"line":674,"address":[],"length":0,"stats":{"Line":0}},{"line":675,"address":[],"length":0,"stats":{"Line":0}},{"line":676,"address":[],"length":0,"stats":{"Line":0}},{"line":677,"address":[],"length":0,"stats":{"Line":0}},{"line":678,"address":[],"length":0,"stats":{"Line":0}},{"line":679,"address":[],"length":0,"stats":{"Line":0}},{"line":680,"address":[],"length":0,"stats":{"Line":0}},{"line":681,"address":[],"length":0,"stats":{"Line":0}},{"line":682,"address":[],"length":0,"stats":{"Line":0}},{"line":685,"address":[],"length":0,"stats":{"Line":0}},{"line":687,"address":[],"length":0,"stats":{"Line":0}},{"line":688,"address":[],"length":0,"stats":{"Line":0}},{"line":690,"address":[],"length":0,"stats":{"Line":0}},{"line":691,"address":[],"length":0,"stats":{"Line":0}},{"line":692,"address":[],"length":0,"stats":{"Line":0}},{"line":693,"address":[],"length":0,"stats":{"Line":0}},{"line":694,"address":[],"length":0,"stats":{"Line":0}},{"line":696,"address":[],"length":0,"stats":{"Line":0}},{"line":697,"address":[],"length":0,"stats":{"Line":0}},{"line":699,"address":[],"length":0,"stats":{"Line":0}},{"line":701,"address":[],"length":0,"stats":{"Line":0}},{"line":702,"address":[],"length":0,"stats":{"Line":0}},{"line":703,"address":[],"length":0,"stats":{"Line":0}},{"line":704,"address":[],"length":0,"stats":{"Line":0}},{"line":705,"address":[],"length":0,"stats":{"Line":0}},{"line":706,"address":[],"length":0,"stats":{"Line":0}},{"line":707,"address":[],"length":0,"stats":{"Line":0}},{"line":709,"address":[],"length":0,"stats":{"Line":0}},{"line":712,"address":[],"length":0,"stats":{"Line":0}},{"line":713,"address":[],"length":0,"stats":{"Line":0}},{"line":714,"address":[],"length":0,"stats":{"Line":0}},{"line":715,"address":[],"length":0,"stats":{"Line":0}},{"line":716,"address":[],"length":0,"stats":{"Line":0}},{"line":717,"address":[],"length":0,"stats":{"Line":0}},{"line":718,"address":[],"length":0,"stats":{"Line":0}},{"line":720,"address":[],"length":0,"stats":{"Line":0}},{"line":722,"address":[],"length":0,"stats":{"Line":0}},{"line":723,"address":[],"length":0,"stats":{"Line":0}},{"line":724,"address":[],"length":0,"stats":{"Line":0}},{"line":727,"address":[],"length":0,"stats":{"Line":0}},{"line":730,"address":[],"length":0,"stats":{"Line":0}},{"line":731,"address":[],"length":0,"stats":{"Line":0}},{"line":732,"address":[],"length":0,"stats":{"Line":0}},{"line":734,"address":[],"length":0,"stats":{"Line":0}},{"line":735,"address":[],"length":0,"stats":{"Line":0}},{"line":740,"address":[],"length":0,"stats":{"Line":0}},{"line":745,"address":[],"length":0,"stats":{"Line":0}},{"line":746,"address":[],"length":0,"stats":{"Line":0}},{"line":750,"address":[],"length":0,"stats":{"Line":0}},{"line":764,"address":[],"length":0,"stats":{"Line":0}},{"line":765,"address":[],"length":0,"stats":{"Line":0}},{"line":766,"address":[],"length":0,"stats":{"Line":0}},{"line":767,"address":[],"length":0,"stats":{"Line":0}},{"line":768,"address":[],"length":0,"stats":{"Line":0}},{"line":769,"address":[],"length":0,"stats":{"Line":0}},{"line":770,"address":[],"length":0,"stats":{"Line":0}},{"line":771,"address":[],"length":0,"stats":{"Line":0}},{"line":772,"address":[],"length":0,"stats":{"Line":0}},{"line":773,"address":[],"length":0,"stats":{"Line":0}},{"line":774,"address":[],"length":0,"stats":{"Line":0}},{"line":775,"address":[],"length":0,"stats":{"Line":0}},{"line":777,"address":[],"length":0,"stats":{"Line":0}},{"line":778,"address":[],"length":0,"stats":{"Line":0}},{"line":779,"address":[],"length":0,"stats":{"Line":0}},{"line":780,"address":[],"length":0,"stats":{"Line":0}},{"line":781,"address":[],"length":0,"stats":{"Line":0}},{"line":783,"address":[],"length":0,"stats":{"Line":0}},{"line":785,"address":[],"length":0,"stats":{"Line":0}},{"line":786,"address":[],"length":0,"stats":{"Line":0}},{"line":788,"address":[],"length":0,"stats":{"Line":0}},{"line":789,"address":[],"length":0,"stats":{"Line":0}},{"line":790,"address":[],"length":0,"stats":{"Line":0}},{"line":791,"address":[],"length":0,"stats":{"Line":0}},{"line":793,"address":[],"length":0,"stats":{"Line":0}},{"line":795,"address":[],"length":0,"stats":{"Line":0}},{"line":796,"address":[],"length":0,"stats":{"Line":0}},{"line":797,"address":[],"length":0,"stats":{"Line":0}},{"line":798,"address":[],"length":0,"stats":{"Line":0}},{"line":799,"address":[],"length":0,"stats":{"Line":0}},{"line":800,"address":[],"length":0,"stats":{"Line":0}},{"line":801,"address":[],"length":0,"stats":{"Line":0}},{"line":803,"address":[],"length":0,"stats":{"Line":0}},{"line":804,"address":[],"length":0,"stats":{"Line":0}},{"line":805,"address":[],"length":0,"stats":{"Line":0}},{"line":806,"address":[],"length":0,"stats":{"Line":0}},{"line":807,"address":[],"length":0,"stats":{"Line":0}},{"line":808,"address":[],"length":0,"stats":{"Line":0}},{"line":811,"address":[],"length":0,"stats":{"Line":0}},{"line":813,"address":[],"length":0,"stats":{"Line":0}},{"line":814,"address":[],"length":0,"stats":{"Line":0}},{"line":815,"address":[],"length":0,"stats":{"Line":0}},{"line":817,"address":[],"length":0,"stats":{"Line":0}},{"line":818,"address":[],"length":0,"stats":{"Line":0}},{"line":820,"address":[],"length":0,"stats":{"Line":0}},{"line":821,"address":[],"length":0,"stats":{"Line":0}},{"line":824,"address":[],"length":0,"stats":{"Line":0}},{"line":827,"address":[],"length":0,"stats":{"Line":0}},{"line":828,"address":[],"length":0,"stats":{"Line":0}},{"line":829,"address":[],"length":0,"stats":{"Line":0}},{"line":831,"address":[],"length":0,"stats":{"Line":0}},{"line":832,"address":[],"length":0,"stats":{"Line":0}},{"line":833,"address":[],"length":0,"stats":{"Line":0}},{"line":834,"address":[],"length":0,"stats":{"Line":0}},{"line":835,"address":[],"length":0,"stats":{"Line":0}},{"line":838,"address":[],"length":0,"stats":{"Line":0}},{"line":839,"address":[],"length":0,"stats":{"Line":0}},{"line":840,"address":[],"length":0,"stats":{"Line":0}},{"line":841,"address":[],"length":0,"stats":{"Line":0}},{"line":842,"address":[],"length":0,"stats":{"Line":0}},{"line":843,"address":[],"length":0,"stats":{"Line":0}},{"line":846,"address":[],"length":0,"stats":{"Line":0}},{"line":847,"address":[],"length":0,"stats":{"Line":0}},{"line":851,"address":[],"length":0,"stats":{"Line":0}},{"line":864,"address":[],"length":0,"stats":{"Line":18}},{"line":867,"address":[],"length":0,"stats":{"Line":18}},{"line":869,"address":[],"length":0,"stats":{"Line":9}},{"line":870,"address":[],"length":0,"stats":{"Line":9}},{"line":871,"address":[],"length":0,"stats":{"Line":12}},{"line":872,"address":[],"length":0,"stats":{"Line":12}},{"line":874,"address":[],"length":0,"stats":{"Line":6}},{"line":875,"address":[],"length":0,"stats":{"Line":6}},{"line":877,"address":[],"length":0,"stats":{"Line":4}},{"line":881,"address":[],"length":0,"stats":{"Line":7}},{"line":882,"address":[],"length":0,"stats":{"Line":12}},{"line":883,"address":[],"length":0,"stats":{"Line":12}},{"line":885,"address":[],"length":0,"stats":{"Line":6}},{"line":886,"address":[],"length":0,"stats":{"Line":6}},{"line":888,"address":[],"length":0,"stats":{"Line":4}},{"line":892,"address":[],"length":0,"stats":{"Line":5}},{"line":893,"address":[],"length":0,"stats":{"Line":12}},{"line":894,"address":[],"length":0,"stats":{"Line":12}},{"line":896,"address":[],"length":0,"stats":{"Line":6}},{"line":897,"address":[],"length":0,"stats":{"Line":6}},{"line":899,"address":[],"length":0,"stats":{"Line":4}},{"line":903,"address":[],"length":0,"stats":{"Line":3}},{"line":904,"address":[],"length":0,"stats":{"Line":12}},{"line":906,"address":[],"length":0,"stats":{"Line":6}},{"line":907,"address":[],"length":0,"stats":{"Line":6}},{"line":909,"address":[],"length":0,"stats":{"Line":4}},{"line":914,"address":[],"length":0,"stats":{"Line":3}},{"line":915,"address":[],"length":0,"stats":{"Line":3}},{"line":917,"address":[],"length":0,"stats":{"Line":2}},{"line":930,"address":[],"length":0,"stats":{"Line":5}},{"line":937,"address":[],"length":0,"stats":{"Line":5}},{"line":939,"address":[],"length":0,"stats":{"Line":6}},{"line":940,"address":[],"length":0,"stats":{"Line":4}},{"line":941,"address":[],"length":0,"stats":{"Line":4}},{"line":942,"address":[],"length":0,"stats":{"Line":4}},{"line":945,"address":[],"length":0,"stats":{"Line":3}},{"line":946,"address":[],"length":0,"stats":{"Line":2}},{"line":947,"address":[],"length":0,"stats":{"Line":2}},{"line":948,"address":[],"length":0,"stats":{"Line":2}},{"line":951,"address":[],"length":0,"stats":{"Line":3}},{"line":952,"address":[],"length":0,"stats":{"Line":2}},{"line":953,"address":[],"length":0,"stats":{"Line":4}},{"line":954,"address":[],"length":0,"stats":{"Line":2}},{"line":957,"address":[],"length":0,"stats":{"Line":3}},{"line":958,"address":[],"length":0,"stats":{"Line":4}},{"line":959,"address":[],"length":0,"stats":{"Line":1}},{"line":960,"address":[],"length":0,"stats":{"Line":1}},{"line":1004,"address":[],"length":0,"stats":{"Line":4}},{"line":1006,"address":[],"length":0,"stats":{"Line":4}},{"line":1007,"address":[],"length":0,"stats":{"Line":6}},{"line":1008,"address":[],"length":0,"stats":{"Line":5}},{"line":1009,"address":[],"length":0,"stats":{"Line":4}},{"line":1010,"address":[],"length":0,"stats":{"Line":2}}],"covered":102,"coverable":486},{"path":["/","Users","christian.klat","dev","git","aeterna","cli","src","commands","agent.rs"],"content":"use clap::{Args, Subcommand};\nuse context::ContextResolver;\nuse serde_json::json;\n\nuse crate::output;\nuse crate::ux_error;\n\n#[derive(Subcommand)]\npub enum AgentCommand {\n    #[command(about = \"Register an AI agent\")]\n    Register(AgentRegisterArgs),\n\n    #[command(about = \"List registered agents\")]\n    List(AgentListArgs),\n\n    #[command(about = \"Show agent details\")]\n    Show(AgentShowArgs),\n\n    #[command(about = \"Manage agent permissions\")]\n    Permissions(AgentPermissionsArgs),\n\n    #[command(about = \"Revoke an agent's access\")]\n    Revoke(AgentRevokeArgs),\n}\n\n#[derive(Args)]\npub struct AgentRegisterArgs {\n    /// Agent name/identifier\n    pub name: String,\n\n    /// Agent description\n    #[arg(short, long)]\n    pub description: Option<String>,\n\n    /// User who delegates permissions to this agent\n    #[arg(long)]\n    pub delegated_by: Option<String>,\n\n    /// Agent type (opencode, langchain, autogen, custom)\n    #[arg(long, default_value = \"custom\")]\n    pub agent_type: String,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n\n    /// Dry run - show what would be created\n    #[arg(long)]\n    pub dry_run: bool,\n}\n\n#[derive(Args)]\npub struct AgentListArgs {\n    /// Filter by delegating user\n    #[arg(long)]\n    pub delegated_by: Option<String>,\n\n    /// Filter by agent type\n    #[arg(long)]\n    pub agent_type: Option<String>,\n\n    /// Show all agents you can see\n    #[arg(long)]\n    pub all: bool,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct AgentShowArgs {\n    /// Agent ID to show\n    pub agent_id: String,\n\n    /// Show full details including audit trail\n    #[arg(short, long)]\n    pub verbose: bool,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct AgentPermissionsArgs {\n    /// Agent ID\n    pub agent_id: String,\n\n    /// Grant permission\n    #[arg(long)]\n    pub grant: Option<String>,\n\n    /// Revoke permission\n    #[arg(long)]\n    pub revoke: Option<String>,\n\n    /// List current permissions\n    #[arg(short, long)]\n    pub list: bool,\n\n    /// Scope for permission (memory-read, memory-write, knowledge-read, policy-read)\n    #[arg(long)]\n    pub scope: Option<String>,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct AgentRevokeArgs {\n    /// Agent ID to revoke\n    pub agent_id: String,\n\n    /// Force revocation without confirmation\n    #[arg(short, long)]\n    pub force: bool,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\npub async fn run(cmd: AgentCommand) -> anyhow::Result<()> {\n    match cmd {\n        AgentCommand::Register(args) => run_register(args).await,\n        AgentCommand::List(args) => run_list(args).await,\n        AgentCommand::Show(args) => run_show(args).await,\n        AgentCommand::Permissions(args) => run_permissions(args).await,\n        AgentCommand::Revoke(args) => run_revoke(args).await,\n    }\n}\n\nasync fn run_register(args: AgentRegisterArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    let delegated_by = args\n        .delegated_by\n        .clone()\n        .unwrap_or_else(|| resolved.user_id.value.clone());\n\n    let valid_types = [\"opencode\", \"langchain\", \"autogen\", \"crewai\", \"custom\"];\n    if !valid_types.contains(&args.agent_type.to_lowercase().as_str()) {\n        let err = ux_error::UxError::new(format!(\"Invalid agent type: '{}'\", args.agent_type))\n            .why(\"Agent type helps categorize and apply appropriate defaults\")\n            .fix(\"Use one of: opencode, langchain, autogen, crewai, custom\")\n            .suggest(&format!(\n                \"aeterna agent register {} --agent-type opencode\",\n                args.name\n            ));\n        err.display();\n        return Err(anyhow::anyhow!(\"Invalid agent type\"));\n    }\n\n    let agent_id = format!(\n        \"agent-{}-{}\",\n        args.name.to_lowercase().replace(' ', \"-\"),\n        chrono::Utc::now().timestamp() % 10000\n    );\n\n    if args.dry_run {\n        if args.json {\n            let output = json!({\n                \"dryRun\": true,\n                \"operation\": \"agent_register\",\n                \"agent\": {\n                    \"id\": agent_id,\n                    \"name\": args.name,\n                    \"description\": args.description,\n                    \"type\": args.agent_type,\n                    \"delegatedBy\": delegated_by,\n                },\n                \"context\": {\n                    \"tenantId\": resolved.tenant_id.value,\n                    \"userId\": resolved.user_id.value,\n                },\n                \"nextSteps\": [\n                    \"Review agent configuration\",\n                    \"Run without --dry-run to register\",\n                    \"Configure permissions with 'aeterna agent permissions'\"\n                ]\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Agent Registration (Dry Run)\");\n            println!();\n            println!(\"  Agent ID:     {}\", agent_id);\n            println!(\"  Name:         {}\", args.name);\n            println!(\"  Type:         {}\", args.agent_type);\n            println!(\"  Delegated By: {}\", delegated_by);\n            if let Some(ref desc) = args.description {\n                println!(\"  Description:  {}\", desc);\n            }\n            println!();\n\n            output::header(\"What Would Happen\");\n            println!(\"  1. Create agent identity '{}'\", agent_id);\n            println!(\"  2. Delegate permissions from '{}' to agent\", delegated_by);\n            println!(\"  3. Generate Cedar policies for agent authorization\");\n            println!(\"  4. Agent inherits user's permissions (scoped down)\");\n            println!();\n\n            output::header(\"Default Permissions (inherited from delegating user)\");\n            println!(\"  - memory:read    - Search and retrieve memories\");\n            println!(\"  - memory:write   - Add new memories\");\n            println!(\"  - knowledge:read - Query knowledge repository\");\n            println!(\"  - policy:read    - Check constraints (no create/modify)\");\n            println!();\n\n            output::header(\"Next Steps\");\n            println!(\"  1. Run without --dry-run to register the agent\");\n            println!(\n                \"  2. Customize permissions: aeterna agent permissions {} --grant <perm>\",\n                agent_id\n            );\n            println!(\n                \"  3. Use in your application with agent_id=\\\"{}\\\"\",\n                agent_id\n            );\n            println!();\n\n            output::info(\"Dry run mode - agent not registered.\");\n        }\n        return Ok(());\n    }\n\n    let err = ux_error::server_not_connected();\n    err.display();\n    output::info(\"Run with --dry-run to see what would be created.\");\n\n    Ok(())\n}\n\nasync fn run_list(args: AgentListArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"agent_list\",\n            \"filters\": {\n                \"delegatedBy\": args.delegated_by,\n                \"agentType\": args.agent_type,\n                \"all\": args.all,\n            },\n            \"context\": {\n                \"tenantId\": resolved.tenant_id.value,\n                \"userId\": resolved.user_id.value,\n            },\n            \"status\": \"not_connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(\"Agents\");\n        println!();\n\n        if args.all {\n            output::info(\"Showing all agents you have access to.\");\n        }\n\n        if let Some(ref user) = args.delegated_by {\n            println!(\"  Filter: delegated_by = {}\", user);\n        }\n        if let Some(ref t) = args.agent_type {\n            println!(\"  Filter: type = {}\", t);\n        }\n        println!();\n\n        output::header(\"Example Output (would show)\");\n        println!(\"  AGENT ID            TYPE       DELEGATED BY         STATUS    LAST ACTIVE\");\n        println!(\"  agent-opencode-1234 opencode   alice@acme.com       active    2 min ago\");\n        println!(\"  agent-bot-5678      langchain  bob@acme.com         active    1 hour ago\");\n        println!(\"  agent-test-9012     custom     carol@acme.com       inactive  3 days ago\");\n        println!();\n\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nasync fn run_show(args: AgentShowArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"agent_show\",\n            \"agentId\": args.agent_id,\n            \"verbose\": args.verbose,\n            \"context\": {\n                \"tenantId\": resolved.tenant_id.value,\n                \"userId\": resolved.user_id.value,\n            },\n            \"status\": \"not_connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(&format!(\"Agent: {}\", args.agent_id));\n        println!();\n\n        output::header(\"Would Show\");\n        println!(\"  - Agent name and description\");\n        println!(\"  - Agent type (opencode, langchain, etc.)\");\n        println!(\"  - Delegating user\");\n        println!(\"  - Current permissions\");\n        println!(\"  - Status (active/inactive)\");\n        println!(\"  - Last activity\");\n\n        if args.verbose {\n            println!();\n            output::header(\"Verbose Details\");\n            println!(\"  - Full permission matrix\");\n            println!(\"  - Recent operations\");\n            println!(\"  - Memory access history\");\n            println!(\"  - Policy violations (if any)\");\n            println!(\"  - Audit trail\");\n        }\n        println!();\n\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nasync fn run_permissions(args: AgentPermissionsArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    let valid_permissions = [\n        \"memory:read\",\n        \"memory:write\",\n        \"memory:delete\",\n        \"knowledge:read\",\n        \"knowledge:write\",\n        \"policy:read\",\n        \"policy:propose\",\n        \"graph:read\",\n        \"graph:write\",\n    ];\n\n    if let Some(ref perm_to_grant) = args.grant {\n        if !valid_permissions.contains(&perm_to_grant.as_str()) {\n            let err = ux_error::UxError::new(format!(\"Invalid permission: '{}'\", perm_to_grant))\n                .why(\"Permission must be a valid agent capability\")\n                .fix(&format!(\"Use one of: {}\", valid_permissions.join(\", \")))\n                .suggest(&format!(\n                    \"aeterna agent permissions {} --grant memory:read\",\n                    args.agent_id\n                ));\n            err.display();\n            return Err(anyhow::anyhow!(\"Invalid permission\"));\n        }\n\n        if args.json {\n            let output = json!({\n                \"operation\": \"agent_permission_grant\",\n                \"agentId\": args.agent_id,\n                \"permission\": perm_to_grant,\n                \"scope\": args.scope,\n                \"status\": \"not_connected\"\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Grant Agent Permission\");\n            println!();\n            println!(\"  Agent:      {}\", args.agent_id);\n            println!(\"  Permission: {}\", perm_to_grant);\n            if let Some(ref scope) = args.scope {\n                println!(\"  Scope:      {}\", scope);\n            }\n            println!();\n\n            output::header(\"Would Do\");\n            println!(\"  1. Verify you can delegate this permission\");\n            println!(\"  2. Update agent's Cedar policies\");\n            println!(\"  3. Log audit event\");\n            println!();\n\n            let err = ux_error::server_not_connected();\n            err.display();\n        }\n        return Ok(());\n    }\n\n    if let Some(ref perm_to_revoke) = args.revoke {\n        if args.json {\n            let output = json!({\n                \"operation\": \"agent_permission_revoke\",\n                \"agentId\": args.agent_id,\n                \"permission\": perm_to_revoke,\n                \"status\": \"not_connected\"\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Revoke Agent Permission\");\n            println!();\n            println!(\"  Agent:      {}\", args.agent_id);\n            println!(\"  Permission: {}\", perm_to_revoke);\n            println!();\n\n            output::header(\"Would Do\");\n            println!(\"  1. Remove permission from agent\");\n            println!(\"  2. Update Cedar policies\");\n            println!(\"  3. Log audit event\");\n            println!();\n\n            let err = ux_error::server_not_connected();\n            err.display();\n        }\n        return Ok(());\n    }\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"agent_permissions_list\",\n            \"agentId\": args.agent_id,\n            \"context\": {\n                \"tenantId\": resolved.tenant_id.value,\n            },\n            \"status\": \"not_connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(&format!(\"Permissions for: {}\", args.agent_id));\n        println!();\n\n        output::header(\"Example Output (would show)\");\n        println!(\"  PERMISSION       SCOPE           GRANTED BY          DATE\");\n        println!(\"  memory:read      project         alice@acme.com      2024-06-01\");\n        println!(\"  memory:write     project         alice@acme.com      2024-06-01\");\n        println!(\"  knowledge:read   org             alice@acme.com      2024-06-01\");\n        println!(\"  policy:read      company         system              2024-06-01\");\n        println!();\n\n        output::header(\"Available Permissions\");\n        println!(\"  memory:read     - Search and retrieve memories\");\n        println!(\"  memory:write    - Add new memories\");\n        println!(\"  memory:delete   - Delete memories (restricted)\");\n        println!(\"  knowledge:read  - Query knowledge repository\");\n        println!(\"  knowledge:write - Modify knowledge (restricted)\");\n        println!(\"  policy:read     - Check constraints\");\n        println!(\"  policy:propose  - Propose new policies\");\n        println!(\"  graph:read      - Query memory graph\");\n        println!(\"  graph:write     - Modify graph relationships\");\n        println!();\n\n        output::header(\"Actions\");\n        println!(\n            \"  Grant:  aeterna agent permissions {} --grant <permission>\",\n            args.agent_id\n        );\n        println!(\n            \"  Revoke: aeterna agent permissions {} --revoke <permission>\",\n            args.agent_id\n        );\n        println!();\n\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nasync fn run_revoke(args: AgentRevokeArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"agent_revoke\",\n            \"agentId\": args.agent_id,\n            \"force\": args.force,\n            \"context\": {\n                \"tenantId\": resolved.tenant_id.value,\n                \"userId\": resolved.user_id.value,\n            },\n            \"status\": \"not_connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(&format!(\"Revoke Agent: {}\", args.agent_id));\n        println!();\n\n        if !args.force {\n            output::warn(\"This will permanently revoke the agent's access.\");\n            println!();\n        }\n\n        output::header(\"Would Do\");\n        println!(\"  1. Verify your permission to revoke this agent\");\n        println!(\"  2. Invalidate all agent tokens\");\n        println!(\"  3. Remove all Cedar policies for this agent\");\n        println!(\"  4. Log audit event\");\n        println!(\"  5. Agent status set to 'revoked'\");\n        println!();\n\n        output::header(\"Effect\");\n        println!(\"  - Agent can no longer access any Aeterna resources\");\n        println!(\"  - All active sessions will be terminated\");\n        println!(\"  - Historical data and audit trail preserved\");\n        println!();\n\n        if !args.force {\n            output::info(\"Add --force to proceed without confirmation.\");\n        }\n\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n","traces":[{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":201,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":205,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":207,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":231,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":240,"address":[],"length":0,"stats":{"Line":0}},{"line":241,"address":[],"length":0,"stats":{"Line":0}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":252,"address":[],"length":0,"stats":{"Line":0}},{"line":254,"address":[],"length":0,"stats":{"Line":0}},{"line":256,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":264,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":272,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":274,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":276,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":298,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":325,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":333,"address":[],"length":0,"stats":{"Line":0}},{"line":335,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":337,"address":[],"length":0,"stats":{"Line":0}},{"line":338,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":342,"address":[],"length":0,"stats":{"Line":0}},{"line":343,"address":[],"length":0,"stats":{"Line":0}},{"line":344,"address":[],"length":0,"stats":{"Line":0}},{"line":347,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":353,"address":[],"length":0,"stats":{"Line":0}},{"line":354,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":360,"address":[],"length":0,"stats":{"Line":0}},{"line":361,"address":[],"length":0,"stats":{"Line":0}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":363,"address":[],"length":0,"stats":{"Line":0}},{"line":364,"address":[],"length":0,"stats":{"Line":0}},{"line":365,"address":[],"length":0,"stats":{"Line":0}},{"line":366,"address":[],"length":0,"stats":{"Line":0}},{"line":368,"address":[],"length":0,"stats":{"Line":0}},{"line":370,"address":[],"length":0,"stats":{"Line":0}},{"line":371,"address":[],"length":0,"stats":{"Line":0}},{"line":372,"address":[],"length":0,"stats":{"Line":0}},{"line":373,"address":[],"length":0,"stats":{"Line":0}},{"line":374,"address":[],"length":0,"stats":{"Line":0}},{"line":375,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":379,"address":[],"length":0,"stats":{"Line":0}},{"line":380,"address":[],"length":0,"stats":{"Line":0}},{"line":381,"address":[],"length":0,"stats":{"Line":0}},{"line":382,"address":[],"length":0,"stats":{"Line":0}},{"line":383,"address":[],"length":0,"stats":{"Line":0}},{"line":385,"address":[],"length":0,"stats":{"Line":0}},{"line":386,"address":[],"length":0,"stats":{"Line":0}},{"line":388,"address":[],"length":0,"stats":{"Line":0}},{"line":391,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":0}},{"line":393,"address":[],"length":0,"stats":{"Line":0}},{"line":394,"address":[],"length":0,"stats":{"Line":0}},{"line":395,"address":[],"length":0,"stats":{"Line":0}},{"line":396,"address":[],"length":0,"stats":{"Line":0}},{"line":397,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":401,"address":[],"length":0,"stats":{"Line":0}},{"line":402,"address":[],"length":0,"stats":{"Line":0}},{"line":403,"address":[],"length":0,"stats":{"Line":0}},{"line":404,"address":[],"length":0,"stats":{"Line":0}},{"line":405,"address":[],"length":0,"stats":{"Line":0}},{"line":407,"address":[],"length":0,"stats":{"Line":0}},{"line":408,"address":[],"length":0,"stats":{"Line":0}},{"line":409,"address":[],"length":0,"stats":{"Line":0}},{"line":410,"address":[],"length":0,"stats":{"Line":0}},{"line":411,"address":[],"length":0,"stats":{"Line":0}},{"line":413,"address":[],"length":0,"stats":{"Line":0}},{"line":414,"address":[],"length":0,"stats":{"Line":0}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":419,"address":[],"length":0,"stats":{"Line":0}},{"line":420,"address":[],"length":0,"stats":{"Line":0}},{"line":421,"address":[],"length":0,"stats":{"Line":0}},{"line":422,"address":[],"length":0,"stats":{"Line":0}},{"line":423,"address":[],"length":0,"stats":{"Line":0}},{"line":424,"address":[],"length":0,"stats":{"Line":0}},{"line":426,"address":[],"length":0,"stats":{"Line":0}},{"line":428,"address":[],"length":0,"stats":{"Line":0}},{"line":430,"address":[],"length":0,"stats":{"Line":0}},{"line":431,"address":[],"length":0,"stats":{"Line":0}},{"line":433,"address":[],"length":0,"stats":{"Line":0}},{"line":434,"address":[],"length":0,"stats":{"Line":0}},{"line":435,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":0}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":441,"address":[],"length":0,"stats":{"Line":0}},{"line":442,"address":[],"length":0,"stats":{"Line":0}},{"line":443,"address":[],"length":0,"stats":{"Line":0}},{"line":444,"address":[],"length":0,"stats":{"Line":0}},{"line":445,"address":[],"length":0,"stats":{"Line":0}},{"line":446,"address":[],"length":0,"stats":{"Line":0}},{"line":447,"address":[],"length":0,"stats":{"Line":0}},{"line":448,"address":[],"length":0,"stats":{"Line":0}},{"line":449,"address":[],"length":0,"stats":{"Line":0}},{"line":450,"address":[],"length":0,"stats":{"Line":0}},{"line":451,"address":[],"length":0,"stats":{"Line":0}},{"line":453,"address":[],"length":0,"stats":{"Line":0}},{"line":454,"address":[],"length":0,"stats":{"Line":0}},{"line":455,"address":[],"length":0,"stats":{"Line":0}},{"line":456,"address":[],"length":0,"stats":{"Line":0}},{"line":458,"address":[],"length":0,"stats":{"Line":0}},{"line":459,"address":[],"length":0,"stats":{"Line":0}},{"line":460,"address":[],"length":0,"stats":{"Line":0}},{"line":462,"address":[],"length":0,"stats":{"Line":0}},{"line":464,"address":[],"length":0,"stats":{"Line":0}},{"line":465,"address":[],"length":0,"stats":{"Line":0}},{"line":468,"address":[],"length":0,"stats":{"Line":0}},{"line":471,"address":[],"length":0,"stats":{"Line":0}},{"line":472,"address":[],"length":0,"stats":{"Line":0}},{"line":473,"address":[],"length":0,"stats":{"Line":0}},{"line":475,"address":[],"length":0,"stats":{"Line":0}},{"line":476,"address":[],"length":0,"stats":{"Line":0}},{"line":477,"address":[],"length":0,"stats":{"Line":0}},{"line":478,"address":[],"length":0,"stats":{"Line":0}},{"line":479,"address":[],"length":0,"stats":{"Line":0}},{"line":480,"address":[],"length":0,"stats":{"Line":0}},{"line":481,"address":[],"length":0,"stats":{"Line":0}},{"line":482,"address":[],"length":0,"stats":{"Line":0}},{"line":484,"address":[],"length":0,"stats":{"Line":0}},{"line":486,"address":[],"length":0,"stats":{"Line":0}},{"line":488,"address":[],"length":0,"stats":{"Line":0}},{"line":489,"address":[],"length":0,"stats":{"Line":0}},{"line":491,"address":[],"length":0,"stats":{"Line":0}},{"line":492,"address":[],"length":0,"stats":{"Line":0}},{"line":493,"address":[],"length":0,"stats":{"Line":0}},{"line":496,"address":[],"length":0,"stats":{"Line":0}},{"line":497,"address":[],"length":0,"stats":{"Line":0}},{"line":498,"address":[],"length":0,"stats":{"Line":0}},{"line":499,"address":[],"length":0,"stats":{"Line":0}},{"line":500,"address":[],"length":0,"stats":{"Line":0}},{"line":501,"address":[],"length":0,"stats":{"Line":0}},{"line":502,"address":[],"length":0,"stats":{"Line":0}},{"line":504,"address":[],"length":0,"stats":{"Line":0}},{"line":505,"address":[],"length":0,"stats":{"Line":0}},{"line":506,"address":[],"length":0,"stats":{"Line":0}},{"line":507,"address":[],"length":0,"stats":{"Line":0}},{"line":508,"address":[],"length":0,"stats":{"Line":0}},{"line":510,"address":[],"length":0,"stats":{"Line":0}},{"line":511,"address":[],"length":0,"stats":{"Line":0}},{"line":514,"address":[],"length":0,"stats":{"Line":0}},{"line":515,"address":[],"length":0,"stats":{"Line":0}},{"line":518,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":281},{"path":["/","Users","christian.klat","dev","git","aeterna","cli","src","commands","check.rs"],"content":"//! Check command - Constraint validation\n//!\n//! Validates the current project/context against knowledge constraints:\n//! - Policy compliance checks\n//! - Dependency restrictions\n//! - Architecture rule validation\n//! - Security policy enforcement\n\nuse anyhow::Result;\nuse clap::Args;\nuse colored::Colorize;\nuse context::ContextResolver;\n\nuse crate::output;\n\n#[derive(Args)]\npub struct CheckArgs {\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n\n    /// Check target: all, policies, dependencies, architecture, security\n    #[arg(long, default_value = \"all\")]\n    pub target: String,\n\n    /// Fail on warnings (exit code 1)\n    #[arg(long)]\n    pub strict: bool,\n\n    /// Show only violations (hide passing checks)\n    #[arg(long)]\n    pub violations_only: bool,\n\n    /// Specific files or paths to check (defaults to current directory)\n    #[arg(value_name = \"PATH\")]\n    pub paths: Vec<String>,\n}\n\n#[derive(Debug, Clone)]\nenum Severity {\n    Error,\n    Warning,\n    Info,\n}\n\nimpl Severity {\n    fn as_str(&self) -> &'static str {\n        match self {\n            Severity::Error => \"error\",\n            Severity::Warning => \"warning\",\n            Severity::Info => \"info\",\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\nstruct CheckResult {\n    category: String,\n    rule: String,\n    severity: Severity,\n    message: String,\n    file: Option<String>,\n    line: Option<u32>,\n    suggestion: Option<String>,\n}\n\npub async fn run(args: CheckArgs) -> Result<()> {\n    let resolver = ContextResolver::new();\n    let ctx = resolver.resolve()?;\n\n    if args.json {\n        return run_json(args, &ctx).await;\n    }\n\n    output::header(\"Constraint Validation\");\n    println!();\n\n    let tenant = &ctx.tenant_id.value;\n    let project = ctx\n        .project_id\n        .as_ref()\n        .map(|p| p.value.as_str())\n        .unwrap_or(\"(current directory)\");\n\n    println!(\"  {} {}\", \"Tenant:\".dimmed(), tenant.cyan());\n    println!(\"  {} {}\", \"Project:\".dimmed(), project.cyan());\n    println!(\n        \"  {} {}\",\n        \"Target:\".dimmed(),\n        args.target.to_uppercase().cyan()\n    );\n    println!();\n\n    // Run checks\n    let results = run_checks(&args, &ctx);\n\n    // Group results by category\n    let errors: Vec<_> = results\n        .iter()\n        .filter(|r| matches!(r.severity, Severity::Error))\n        .collect();\n    let warnings: Vec<_> = results\n        .iter()\n        .filter(|r| matches!(r.severity, Severity::Warning))\n        .collect();\n    let infos: Vec<_> = results\n        .iter()\n        .filter(|r| matches!(r.severity, Severity::Info))\n        .collect();\n\n    // Print results\n    if !errors.is_empty() {\n        output::subheader(\"Errors\");\n        for result in &errors {\n            print_result(result);\n        }\n        println!();\n    }\n\n    if !warnings.is_empty() && !args.violations_only {\n        output::subheader(\"Warnings\");\n        for result in &warnings {\n            print_result(result);\n        }\n        println!();\n    }\n\n    if !infos.is_empty() && !args.violations_only {\n        output::subheader(\"Info\");\n        for result in &infos {\n            print_result(result);\n        }\n        println!();\n    }\n\n    // Summary\n    output::subheader(\"Summary\");\n    println!();\n    println!(\n        \"  {} {} errors\",\n        if errors.is_empty() {\n            \"\".green()\n        } else {\n            \"\".red()\n        },\n        errors.len()\n    );\n    println!(\n        \"  {} {} warnings\",\n        if warnings.is_empty() {\n            \"\".green()\n        } else {\n            \"\".yellow()\n        },\n        warnings.len()\n    );\n    println!(\"  {} {} info\", \"\".blue(), infos.len());\n    println!();\n\n    // Determine exit status\n    let has_violations = !errors.is_empty() || (args.strict && !warnings.is_empty());\n\n    if has_violations {\n        if !errors.is_empty() {\n            output::error(\"Validation failed with errors\");\n        } else {\n            output::warn(\"Validation failed (strict mode) with warnings\");\n        }\n        std::process::exit(1);\n    } else {\n        output::success(\"All checks passed\");\n    }\n\n    Ok(())\n}\n\nasync fn run_json(args: CheckArgs, ctx: &context::ResolvedContext) -> Result<()> {\n    let results = run_checks(&args, ctx);\n\n    let errors: Vec<_> = results\n        .iter()\n        .filter(|r| matches!(r.severity, Severity::Error))\n        .collect();\n    let warnings: Vec<_> = results\n        .iter()\n        .filter(|r| matches!(r.severity, Severity::Warning))\n        .collect();\n\n    let has_violations = !errors.is_empty() || (args.strict && !warnings.is_empty());\n\n    let output = serde_json::json!({\n        \"success\": !has_violations,\n        \"context\": {\n            \"tenant_id\": ctx.tenant_id.value,\n            \"project_id\": ctx.project_id.as_ref().map(|p| &p.value),\n        },\n        \"target\": args.target,\n        \"strict\": args.strict,\n        \"results\": results.iter().map(|r| serde_json::json!({\n            \"category\": r.category,\n            \"rule\": r.rule,\n            \"severity\": r.severity.as_str(),\n            \"message\": r.message,\n            \"file\": r.file,\n            \"line\": r.line,\n            \"suggestion\": r.suggestion,\n        })).collect::<Vec<_>>(),\n        \"summary\": {\n            \"errors\": errors.len(),\n            \"warnings\": warnings.len(),\n            \"total\": results.len(),\n        }\n    });\n    println!(\"{}\", serde_json::to_string_pretty(&output)?);\n\n    if has_violations {\n        std::process::exit(1);\n    }\n\n    Ok(())\n}\n\nfn run_checks(args: &CheckArgs, _ctx: &context::ResolvedContext) -> Vec<CheckResult> {\n    let mut results = Vec::new();\n\n    let targets: Vec<&str> = if args.target == \"all\" {\n        vec![\"policies\", \"dependencies\", \"architecture\", \"security\"]\n    } else {\n        vec![args.target.as_str()]\n    };\n\n    for target in targets {\n        match target {\n            \"policies\" => results.extend(check_policies(args)),\n            \"dependencies\" => results.extend(check_dependencies(args)),\n            \"architecture\" => results.extend(check_architecture(args)),\n            \"security\" => results.extend(check_security(args)),\n            _ => {}\n        }\n    }\n\n    results\n}\n\nfn check_policies(_args: &CheckArgs) -> Vec<CheckResult> {\n    // TODO: Replace with actual policy checks when backend is implemented\n    // Currently returns empty (all passing)\n    vec![]\n}\n\nfn check_dependencies(_args: &CheckArgs) -> Vec<CheckResult> {\n    // TODO: Replace with actual dependency checks when backend is implemented\n    // Currently returns empty (all passing)\n    vec![]\n}\n\nfn check_architecture(_args: &CheckArgs) -> Vec<CheckResult> {\n    // TODO: Replace with actual architecture checks when backend is implemented\n    // Currently returns empty (all passing)\n    vec![]\n}\n\nfn check_security(_args: &CheckArgs) -> Vec<CheckResult> {\n    // TODO: Replace with actual security checks when backend is implemented\n    // Currently returns empty (all passing)\n    vec![]\n}\n\nfn print_result(result: &CheckResult) {\n    let severity_icon = match result.severity {\n        Severity::Error => \"\".red(),\n        Severity::Warning => \"\".yellow(),\n        Severity::Info => \"\".blue(),\n    };\n\n    let location = match (&result.file, result.line) {\n        (Some(file), Some(line)) => format!(\"{}:{}\", file, line),\n        (Some(file), None) => file.clone(),\n        _ => String::new(),\n    };\n\n    if location.is_empty() {\n        println!(\n            \"  {} [{}] {}: {}\",\n            severity_icon,\n            result.category.dimmed(),\n            result.rule.cyan(),\n            result.message\n        );\n    } else {\n        println!(\n            \"  {} {} [{}] {}: {}\",\n            severity_icon,\n            location.dimmed(),\n            result.category.dimmed(),\n            result.rule.cyan(),\n            result.message\n        );\n    }\n\n    if let Some(suggestion) = &result.suggestion {\n        println!(\"    {} {}\", \"\".cyan(), suggestion.dimmed());\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_severity_as_str() {\n        assert_eq!(Severity::Error.as_str(), \"error\");\n        assert_eq!(Severity::Warning.as_str(), \"warning\");\n        assert_eq!(Severity::Info.as_str(), \"info\");\n    }\n\n    #[test]\n    fn test_check_policies_empty() {\n        let args = CheckArgs {\n            json: false,\n            target: \"policies\".to_string(),\n            strict: false,\n            violations_only: false,\n            paths: vec![],\n        };\n        let results = check_policies(&args);\n        assert!(results.is_empty());\n    }\n\n    #[test]\n    fn test_check_dependencies_empty() {\n        let args = CheckArgs {\n            json: false,\n            target: \"dependencies\".to_string(),\n            strict: false,\n            violations_only: false,\n            paths: vec![],\n        };\n        let results = check_dependencies(&args);\n        assert!(results.is_empty());\n    }\n\n    #[test]\n    fn test_check_architecture_empty() {\n        let args = CheckArgs {\n            json: false,\n            target: \"architecture\".to_string(),\n            strict: false,\n            violations_only: false,\n            paths: vec![],\n        };\n        let results = check_architecture(&args);\n        assert!(results.is_empty());\n    }\n\n    #[test]\n    fn test_check_security_empty() {\n        let args = CheckArgs {\n            json: false,\n            target: \"security\".to_string(),\n            strict: false,\n            violations_only: false,\n            paths: vec![],\n        };\n        let results = check_security(&args);\n        assert!(results.is_empty());\n    }\n}\n","traces":[{"line":47,"address":[],"length":0,"stats":{"Line":3}},{"line":48,"address":[],"length":0,"stats":{"Line":3}},{"line":49,"address":[],"length":0,"stats":{"Line":1}},{"line":50,"address":[],"length":0,"stats":{"Line":1}},{"line":51,"address":[],"length":0,"stats":{"Line":1}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":201,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":204,"address":[],"length":0,"stats":{"Line":0}},{"line":205,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":207,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":0}},{"line":223,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":235,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":1}},{"line":248,"address":[],"length":0,"stats":{"Line":1}},{"line":251,"address":[],"length":0,"stats":{"Line":1}},{"line":254,"address":[],"length":0,"stats":{"Line":1}},{"line":257,"address":[],"length":0,"stats":{"Line":1}},{"line":260,"address":[],"length":0,"stats":{"Line":1}},{"line":263,"address":[],"length":0,"stats":{"Line":1}},{"line":266,"address":[],"length":0,"stats":{"Line":1}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":270,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":272,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":276,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":284,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}}],"covered":13,"coverable":146},{"path":["/","Users","christian.klat","dev","git","aeterna","cli","src","commands","completion.rs"],"content":"use std::io;\n\nuse anyhow::Result;\nuse clap::{Args, CommandFactory, ValueEnum};\nuse clap_complete::{Shell, generate};\n\nuse super::Cli;\n\n#[derive(Args)]\npub struct CompletionArgs {\n    #[arg(help = \"Shell to generate completions for\")]\n    pub shell: ShellChoice,\n}\n\n#[derive(Clone, ValueEnum)]\npub enum ShellChoice {\n    Bash,\n    Zsh,\n    Fish,\n    PowerShell,\n}\n\npub fn run(args: CompletionArgs) -> Result<()> {\n    let mut cmd = Cli::command();\n    let shell = match args.shell {\n        ShellChoice::Bash => Shell::Bash,\n        ShellChoice::Zsh => Shell::Zsh,\n        ShellChoice::Fish => Shell::Fish,\n        ShellChoice::PowerShell => Shell::PowerShell,\n    };\n\n    generate(shell, &mut cmd, \"aeterna\", &mut io::stdout());\n\n    Ok(())\n}\n","traces":[{"line":23,"address":[],"length":0,"stats":{"Line":0}},{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":28,"address":[],"length":0,"stats":{"Line":0}},{"line":29,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":34,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":9},{"path":["/","Users","christian.klat","dev","git","aeterna","cli","src","commands","context.rs"],"content":"use anyhow::Result;\nuse clap::{Args, Subcommand};\nuse colored::Colorize;\nuse context::ContextResolver;\n\n#[derive(Subcommand)]\npub enum ContextCommand {\n    #[command(about = \"Show resolved context\")]\n    Show(ShowArgs),\n\n    #[command(about = \"Set a context value in .aeterna/context.toml\")]\n    Set(SetArgs),\n\n    #[command(about = \"Clear context file\")]\n    Clear(ClearArgs),\n}\n\n#[derive(Args)]\npub struct ShowArgs {\n    #[arg(long, help = \"Output as JSON\")]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct SetArgs {\n    #[arg(help = \"Key to set (tenant-id, user-id, org-id, team-id, project-id)\")]\n    pub key: String,\n\n    #[arg(help = \"Value to set\")]\n    pub value: String,\n}\n\n#[derive(Args)]\npub struct ClearArgs {\n    #[arg(long, help = \"Also remove .aeterna directory\")]\n    pub all: bool,\n}\n\npub fn run(cmd: ContextCommand) -> Result<()> {\n    match cmd {\n        ContextCommand::Show(args) => show(args),\n        ContextCommand::Set(args) => set(args),\n        ContextCommand::Clear(args) => clear(args),\n    }\n}\n\nfn show(args: ShowArgs) -> Result<()> {\n    let resolver = ContextResolver::new();\n    let ctx = resolver.resolve()?;\n\n    if args.json {\n        let explanations = ctx.explain();\n        let output: Vec<_> = explanations\n            .into_iter()\n            .map(|(name, value, source)| {\n                serde_json::json!({\n                    \"name\": name,\n                    \"value\": value,\n                    \"source\": source\n                })\n            })\n            .collect();\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        return Ok(());\n    }\n\n    println!(\"{}\", \"Resolved Context\".bold().underline());\n    println!();\n\n    for (name, value, source) in ctx.explain() {\n        println!(\n            \"  {:<12} {} {}\",\n            format!(\"{name}:\"),\n            value.cyan(),\n            format!(\"({source})\").dimmed()\n        );\n    }\n\n    Ok(())\n}\n\nfn set(args: SetArgs) -> Result<()> {\n    use std::fs;\n    use std::path::Path;\n\n    let aeterna_dir = Path::new(\".aeterna\");\n    let context_file = aeterna_dir.join(\"context.toml\");\n\n    let mut config = if context_file.exists() {\n        let content = fs::read_to_string(&context_file)?;\n        toml::from_str::<toml::Value>(&content)\n            .unwrap_or_else(|_| toml::Value::Table(toml::map::Map::new()))\n    } else {\n        toml::Value::Table(toml::map::Map::new())\n    };\n\n    if let Some(table) = config.as_table_mut() {\n        table.insert(args.key.clone(), toml::Value::String(args.value.clone()));\n    }\n\n    fs::create_dir_all(aeterna_dir)?;\n    fs::write(&context_file, toml::to_string_pretty(&config)?)?;\n\n    println!(\n        \"{} Set {} = {}\",\n        \"\".green().bold(),\n        args.key.cyan(),\n        args.value.cyan()\n    );\n\n    Ok(())\n}\n\nfn clear(args: ClearArgs) -> Result<()> {\n    use std::fs;\n    use std::path::Path;\n\n    let aeterna_dir = Path::new(\".aeterna\");\n    let context_file = aeterna_dir.join(\"context.toml\");\n\n    if args.all {\n        if aeterna_dir.exists() {\n            fs::remove_dir_all(aeterna_dir)?;\n            println!(\"{} Removed {}\", \"\".green().bold(), aeterna_dir.display());\n        } else {\n            println!(\"{}\", \"No .aeterna directory found\".dimmed());\n        }\n    } else if context_file.exists() {\n        fs::remove_file(&context_file)?;\n        println!(\"{} Removed {}\", \"\".green().bold(), context_file.display());\n    } else {\n        println!(\"{}\", \"No context.toml found\".dimmed());\n    }\n\n    Ok(())\n}\n","traces":[{"line":39,"address":[],"length":0,"stats":{"Line":3}},{"line":40,"address":[],"length":0,"stats":{"Line":3}},{"line":41,"address":[],"length":0,"stats":{"Line":9}},{"line":42,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":3}},{"line":48,"address":[],"length":0,"stats":{"Line":6}},{"line":49,"address":[],"length":0,"stats":{"Line":9}},{"line":51,"address":[],"length":0,"stats":{"Line":3}},{"line":52,"address":[],"length":0,"stats":{"Line":6}},{"line":53,"address":[],"length":0,"stats":{"Line":6}},{"line":55,"address":[],"length":0,"stats":{"Line":10}},{"line":56,"address":[],"length":0,"stats":{"Line":8}},{"line":57,"address":[],"length":0,"stats":{"Line":8}},{"line":58,"address":[],"length":0,"stats":{"Line":8}},{"line":59,"address":[],"length":0,"stats":{"Line":8}},{"line":63,"address":[],"length":0,"stats":{"Line":8}},{"line":64,"address":[],"length":0,"stats":{"Line":2}},{"line":67,"address":[],"length":0,"stats":{"Line":5}},{"line":68,"address":[],"length":0,"stats":{"Line":1}},{"line":70,"address":[],"length":0,"stats":{"Line":18}},{"line":71,"address":[],"length":0,"stats":{"Line":8}},{"line":72,"address":[],"length":0,"stats":{"Line":8}},{"line":73,"address":[],"length":0,"stats":{"Line":12}},{"line":74,"address":[],"length":0,"stats":{"Line":8}},{"line":75,"address":[],"length":0,"stats":{"Line":8}},{"line":79,"address":[],"length":0,"stats":{"Line":1}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}}],"covered":25,"coverable":58},{"path":["/","Users","christian.klat","dev","git","aeterna","cli","src","commands","govern.rs"],"content":"use clap::{Args, Subcommand, ValueEnum};\nuse context::ContextResolver;\nuse serde_json::json;\n\nuse crate::output;\nuse crate::ux_error;\n\n#[derive(Subcommand)]\npub enum GovernCommand {\n    #[command(about = \"Show governance status and pending approvals\")]\n    Status(GovernStatusArgs),\n\n    #[command(about = \"List pending approval requests\")]\n    Pending(GovernPendingArgs),\n\n    #[command(about = \"Approve a governance request\")]\n    Approve(GovernApproveArgs),\n\n    #[command(about = \"Reject a governance request\")]\n    Reject(GovernRejectArgs),\n\n    #[command(about = \"Configure governance settings\")]\n    Configure(GovernConfigureArgs),\n\n    #[command(about = \"Manage governance roles\")]\n    Roles(GovernRolesArgs),\n\n    #[command(about = \"View governance audit trail\")]\n    Audit(GovernAuditArgs),\n}\n\n#[derive(Args)]\npub struct GovernStatusArgs {\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n\n    /// Include detailed metrics\n    #[arg(short, long)]\n    pub verbose: bool,\n}\n\n#[derive(Args)]\npub struct GovernPendingArgs {\n    /// Filter by type (policy, knowledge, memory, all)\n    #[arg(short = 't', long, default_value = \"all\")]\n    pub request_type: String,\n\n    /// Filter by layer (company, org, team, project)\n    #[arg(short, long)]\n    pub layer: Option<String>,\n\n    /// Filter by requestor\n    #[arg(long)]\n    pub requestor: Option<String>,\n\n    /// Show only my pending requests\n    #[arg(long)]\n    pub mine: bool,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct GovernApproveArgs {\n    /// Request ID to approve\n    pub request_id: String,\n\n    /// Approval comment\n    #[arg(short, long)]\n    pub comment: Option<String>,\n\n    /// Skip confirmation prompt\n    #[arg(short, long)]\n    pub yes: bool,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct GovernRejectArgs {\n    /// Request ID to reject\n    pub request_id: String,\n\n    /// Rejection reason (required)\n    #[arg(short, long)]\n    pub reason: String,\n\n    /// Skip confirmation prompt\n    #[arg(short, long)]\n    pub yes: bool,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct GovernConfigureArgs {\n    /// Show current configuration\n    #[arg(long)]\n    pub show: bool,\n\n    /// Use a predefined governance template (standard, strict, permissive)\n    #[arg(long, value_enum)]\n    pub template: Option<GovernanceTemplate>,\n\n    /// List available templates and their settings\n    #[arg(long)]\n    pub list_templates: bool,\n\n    /// Set approval requirement (single, quorum, unanimous)\n    #[arg(long)]\n    pub approval_mode: Option<ApprovalMode>,\n\n    /// Set minimum approvers required (for quorum mode)\n    #[arg(long)]\n    pub min_approvers: Option<u32>,\n\n    /// Set approval timeout in hours\n    #[arg(long)]\n    pub timeout_hours: Option<u32>,\n\n    /// Enable/disable auto-approve for low-risk changes\n    #[arg(long)]\n    pub auto_approve: Option<bool>,\n\n    /// Set escalation contact\n    #[arg(long)]\n    pub escalation_contact: Option<String>,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct GovernRolesArgs {\n    /// Role action (list, assign, revoke)\n    #[arg(default_value = \"list\")]\n    pub action: String,\n\n    /// User or agent ID for assign/revoke\n    #[arg(long)]\n    pub principal: Option<String>,\n\n    /// Role to assign/revoke\n    #[arg(long)]\n    pub role: Option<String>,\n\n    /// Scope for the role (company, org, team, project)\n    #[arg(long)]\n    pub scope: Option<String>,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct GovernAuditArgs {\n    /// Filter by action type (approve, reject, escalate, expire, all)\n    #[arg(short, long, default_value = \"all\")]\n    pub action: String,\n\n    /// Filter by time range (1h, 24h, 7d, 30d, 90d)\n    #[arg(long, default_value = \"7d\")]\n    pub since: String,\n\n    /// Filter by actor (user or agent ID)\n    #[arg(long)]\n    pub actor: Option<String>,\n\n    /// Filter by target type (policy, knowledge, memory)\n    #[arg(long)]\n    pub target_type: Option<String>,\n\n    /// Maximum number of entries to show\n    #[arg(short, long, default_value = \"50\")]\n    pub limit: usize,\n\n    /// Export format (json, csv, none)\n    #[arg(long, default_value = \"none\")]\n    pub export: ExportFormat,\n\n    /// Output file for export\n    #[arg(short, long)]\n    pub output: Option<String>,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Clone, ValueEnum)]\npub enum ApprovalMode {\n    Single,\n    Quorum,\n    Unanimous,\n}\n\n#[derive(Clone, ValueEnum)]\npub enum ExportFormat {\n    Json,\n    Csv,\n    None,\n}\n\n#[derive(Clone, ValueEnum)]\npub enum GovernanceTemplate {\n    Standard,\n    Strict,\n    Permissive,\n}\n\npub async fn run(cmd: GovernCommand) -> anyhow::Result<()> {\n    match cmd {\n        GovernCommand::Status(args) => run_status(args).await,\n        GovernCommand::Pending(args) => run_pending(args).await,\n        GovernCommand::Approve(args) => run_approve(args).await,\n        GovernCommand::Reject(args) => run_reject(args).await,\n        GovernCommand::Configure(args) => run_configure(args).await,\n        GovernCommand::Roles(args) => run_roles(args).await,\n        GovernCommand::Audit(args) => run_audit(args).await,\n    }\n}\n\nasync fn run_status(args: GovernStatusArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let ctx = resolver.resolve()?;\n\n    // Simulated governance status\n    let status = GovernanceStatus {\n        approval_mode: \"quorum\".to_string(),\n        min_approvers: 2,\n        timeout_hours: 72,\n        auto_approve_enabled: true,\n        pending_requests: 3,\n        approved_today: 7,\n        rejected_today: 1,\n        escalated: 0,\n        your_pending_approvals: 2,\n    };\n\n    if args.json {\n        let output = json!({\n            \"context\": {\n                \"tenant_id\": ctx.tenant_id.value,\n                \"user_id\": ctx.user_id.value,\n            },\n            \"config\": {\n                \"approval_mode\": status.approval_mode,\n                \"min_approvers\": status.min_approvers,\n                \"timeout_hours\": status.timeout_hours,\n                \"auto_approve_enabled\": status.auto_approve_enabled,\n            },\n            \"metrics\": {\n                \"pending_requests\": status.pending_requests,\n                \"approved_today\": status.approved_today,\n                \"rejected_today\": status.rejected_today,\n                \"escalated\": status.escalated,\n                \"your_pending_approvals\": status.your_pending_approvals,\n            },\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(\"Governance Status\");\n        println!();\n\n        output::subheader(\"Configuration\");\n        println!(\"  Approval Mode:    {}\", status.approval_mode);\n        println!(\"  Min Approvers:    {}\", status.min_approvers);\n        println!(\"  Timeout:          {} hours\", status.timeout_hours);\n        println!(\n            \"  Auto-approve:     {}\",\n            if status.auto_approve_enabled {\n                \"enabled (low-risk)\"\n            } else {\n                \"disabled\"\n            }\n        );\n        println!();\n\n        output::subheader(\"Activity (Today)\");\n        println!(\"  Pending Requests: {}\", status.pending_requests);\n        println!(\"  Approved:         {}\", status.approved_today);\n        println!(\"  Rejected:         {}\", status.rejected_today);\n        println!(\"  Escalated:        {}\", status.escalated);\n        println!();\n\n        if status.your_pending_approvals > 0 {\n            println!(\n                \"   You have {} request(s) awaiting your approval\",\n                status.your_pending_approvals\n            );\n            println!();\n            output::hint(\"Run 'aeterna govern pending --mine' to see your pending approvals\");\n        }\n\n        if args.verbose {\n            output::subheader(\"Recent Activity\");\n            println!(\"   alice approved policy 'security-baseline' (2h ago)\");\n            println!(\"   bob requested knowledge promotion 'ADR-042' (4h ago)\");\n            println!(\"   system auto-approved memory feedback (6h ago)\");\n        }\n    }\n\n    Ok(())\n}\n\nasync fn run_pending(args: GovernPendingArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let _ctx = resolver.resolve()?;\n\n    // Simulated pending requests\n    let requests = vec![\n        PendingRequest {\n            id: \"req_abc123\".to_string(),\n            request_type: \"policy\".to_string(),\n            title: \"Add security-baseline policy\".to_string(),\n            requestor: \"alice\".to_string(),\n            layer: \"org\".to_string(),\n            created_at: \"2024-01-15T10:30:00Z\".to_string(),\n            approvals: 1,\n            required_approvals: 2,\n            status: \"pending\".to_string(),\n        },\n        PendingRequest {\n            id: \"req_def456\".to_string(),\n            request_type: \"knowledge\".to_string(),\n            title: \"Promote ADR-042 to company layer\".to_string(),\n            requestor: \"bob\".to_string(),\n            layer: \"company\".to_string(),\n            created_at: \"2024-01-15T08:15:00Z\".to_string(),\n            approvals: 0,\n            required_approvals: 2,\n            status: \"pending\".to_string(),\n        },\n        PendingRequest {\n            id: \"req_ghi789\".to_string(),\n            request_type: \"memory\".to_string(),\n            title: \"Promote high-value learning to team\".to_string(),\n            requestor: \"agent_codex\".to_string(),\n            layer: \"team\".to_string(),\n            created_at: \"2024-01-15T06:00:00Z\".to_string(),\n            approvals: 1,\n            required_approvals: 1,\n            status: \"ready\".to_string(),\n        },\n    ];\n\n    // Apply filters\n    let filtered: Vec<_> = requests\n        .iter()\n        .filter(|r| args.request_type == \"all\" || r.request_type == args.request_type)\n        .filter(|r| args.layer.as_ref().map_or(true, |l| &r.layer == l))\n        .filter(|r| {\n            args.requestor\n                .as_ref()\n                .map_or(true, |req| &r.requestor == req)\n        })\n        .collect();\n\n    if args.json {\n        let output = json!({\n            \"total\": filtered.len(),\n            \"requests\": filtered.iter().map(|r| json!({\n                \"id\": r.id,\n                \"type\": r.request_type,\n                \"title\": r.title,\n                \"requestor\": r.requestor,\n                \"layer\": r.layer,\n                \"created_at\": r.created_at,\n                \"approvals\": r.approvals,\n                \"required_approvals\": r.required_approvals,\n                \"status\": r.status,\n            })).collect::<Vec<_>>(),\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(&format!(\"Pending Requests ({})\", filtered.len()));\n        println!();\n\n        if filtered.is_empty() {\n            println!(\"   No pending requests matching your filters\");\n            println!();\n        } else {\n            for req in &filtered {\n                let status_icon = match req.status.as_str() {\n                    \"ready\" => \"\",\n                    \"pending\" => \"\",\n                    _ => \"?\",\n                };\n\n                println!(\n                    \"  {} [{}] {} ({})\",\n                    status_icon, req.id, req.title, req.request_type\n                );\n                println!(\n                    \"      Requestor: {}  |  Layer: {}  |  Approvals: {}/{}\",\n                    req.requestor, req.layer, req.approvals, req.required_approvals\n                );\n                println!(\"      Created: {}\", req.created_at);\n                println!();\n            }\n\n            output::hint(\n                \"Use 'aeterna govern approve <id>' or 'aeterna govern reject <id>' to act\",\n            );\n        }\n    }\n\n    Ok(())\n}\n\nasync fn run_approve(args: GovernApproveArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let _ctx = resolver.resolve()?;\n\n    // Simulated request lookup\n    let request = PendingRequest {\n        id: args.request_id.clone(),\n        request_type: \"policy\".to_string(),\n        title: \"Add security-baseline policy\".to_string(),\n        requestor: \"alice\".to_string(),\n        layer: \"org\".to_string(),\n        created_at: \"2024-01-15T10:30:00Z\".to_string(),\n        approvals: 1,\n        required_approvals: 2,\n        status: \"pending\".to_string(),\n    };\n\n    if args.json {\n        let output = json!({\n            \"success\": true,\n            \"request_id\": args.request_id,\n            \"action\": \"approved\",\n            \"comment\": args.comment,\n            \"new_approval_count\": request.approvals + 1,\n            \"required_approvals\": request.required_approvals,\n            \"fully_approved\": request.approvals + 1 >= request.required_approvals,\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(\"Approve Request\");\n        println!();\n\n        println!(\"  Request ID: {}\", request.id);\n        println!(\"  Type:       {}\", request.request_type);\n        println!(\"  Title:      {}\", request.title);\n        println!(\"  Requestor:  {}\", request.requestor);\n        println!(\"  Layer:      {}\", request.layer);\n        println!();\n\n        if !args.yes {\n            // In real implementation, would prompt for confirmation\n            println!(\"   Would prompt for confirmation (use --yes to skip)\");\n        }\n\n        println!(\"   Request approved\");\n        if let Some(comment) = &args.comment {\n            println!(\"    Comment: {}\", comment);\n        }\n        println!();\n\n        let new_count = request.approvals + 1;\n        if new_count >= request.required_approvals {\n            println!(\n                \"   Request is now fully approved ({}/{})\",\n                new_count, request.required_approvals\n            );\n            println!(\"    The change will be applied automatically.\");\n        } else {\n            println!(\n                \"   Approval recorded ({}/{})\",\n                new_count, request.required_approvals\n            );\n            println!(\n                \"    Waiting for {} more approval(s).\",\n                request.required_approvals - new_count\n            );\n        }\n        println!();\n    }\n\n    Ok(())\n}\n\nasync fn run_reject(args: GovernRejectArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let _ctx = resolver.resolve()?;\n\n    if args.reason.is_empty() {\n        ux_error::UxError::new(\"Rejection reason is required\")\n            .why(\"Requestors need feedback to understand why their request was rejected\")\n            .fix(\"Provide a reason using the --reason flag\")\n            .suggest(&format!(\n                \"aeterna govern reject {} --reason \\\"Need security review first\\\"\",\n                args.request_id\n            ))\n            .display();\n        std::process::exit(1);\n    }\n\n    // Simulated request lookup\n    let request = PendingRequest {\n        id: args.request_id.clone(),\n        request_type: \"policy\".to_string(),\n        title: \"Add security-baseline policy\".to_string(),\n        requestor: \"alice\".to_string(),\n        layer: \"org\".to_string(),\n        created_at: \"2024-01-15T10:30:00Z\".to_string(),\n        approvals: 1,\n        required_approvals: 2,\n        status: \"pending\".to_string(),\n    };\n\n    if args.json {\n        let output = json!({\n            \"success\": true,\n            \"request_id\": args.request_id,\n            \"action\": \"rejected\",\n            \"reason\": args.reason,\n            \"requestor_notified\": true,\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(\"Reject Request\");\n        println!();\n\n        println!(\"  Request ID: {}\", request.id);\n        println!(\"  Type:       {}\", request.request_type);\n        println!(\"  Title:      {}\", request.title);\n        println!(\"  Requestor:  {}\", request.requestor);\n        println!();\n\n        if !args.yes {\n            // In real implementation, would prompt for confirmation\n            println!(\"   Would prompt for confirmation (use --yes to skip)\");\n        }\n\n        println!(\"   Request rejected\");\n        println!(\"    Reason: {}\", args.reason);\n        println!();\n        println!(\"   Requestor '{}' has been notified\", request.requestor);\n        println!();\n    }\n\n    Ok(())\n}\n\nasync fn run_configure(args: GovernConfigureArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let _ctx = resolver.resolve()?;\n\n    if args.list_templates {\n        let templates = [\n            (\n                \"standard\",\n                \"Balanced governance with quorum-based approvals (2 approvers, 72h timeout)\",\n                \"quorum\",\n                2u32,\n                72u32,\n                false,\n            ),\n            (\n                \"strict\",\n                \"Maximum control with unanimous approvals (3+ approvers, 24h timeout, no auto-approve)\",\n                \"unanimous\",\n                3,\n                24,\n                false,\n            ),\n            (\n                \"permissive\",\n                \"Minimal friction with single approvals (1 approver, auto-approve low-risk)\",\n                \"single\",\n                1,\n                168,\n                true,\n            ),\n        ];\n\n        if args.json {\n            let output: Vec<_> = templates\n                .iter()\n                .map(|(name, desc, mode, approvers, timeout, auto)| {\n                    serde_json::json!({\n                        \"name\": name,\n                        \"description\": desc,\n                        \"settings\": {\n                            \"approval_mode\": mode,\n                            \"min_approvers\": approvers,\n                            \"timeout_hours\": timeout,\n                            \"auto_approve_low_risk\": auto,\n                        }\n                    })\n                })\n                .collect();\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Available Governance Templates\");\n            println!();\n\n            for (name, desc, mode, approvers, timeout, auto) in templates {\n                println!(\"  \\x1b[1m{}\\x1b[0m - {}\", name, desc);\n                println!(\"    Approval Mode:  {}\", mode);\n                println!(\"    Min Approvers:  {}\", approvers);\n                println!(\"    Timeout:        {} hours\", timeout);\n                println!(\n                    \"    Auto-approve:   {}\",\n                    if auto { \"yes (low-risk)\" } else { \"no\" }\n                );\n                println!();\n            }\n\n            output::hint(\"Use --template <name> to apply a template\");\n        }\n        return Ok(());\n    }\n\n    let mut config = GovernanceConfig {\n        approval_mode: \"quorum\".to_string(),\n        min_approvers: 2,\n        timeout_hours: 72,\n        auto_approve_enabled: true,\n        escalation_contact: Some(\"security-team@acme.com\".to_string()),\n    };\n\n    if let Some(ref cli_template) = args.template {\n        match cli_template {\n            GovernanceTemplate::Standard => {\n                config.approval_mode = \"quorum\".to_string();\n                config.min_approvers = 2;\n                config.timeout_hours = 72;\n                config.auto_approve_enabled = false;\n            }\n            GovernanceTemplate::Strict => {\n                config.approval_mode = \"unanimous\".to_string();\n                config.min_approvers = 3;\n                config.timeout_hours = 24;\n                config.auto_approve_enabled = false;\n            }\n            GovernanceTemplate::Permissive => {\n                config.approval_mode = \"single\".to_string();\n                config.min_approvers = 1;\n                config.timeout_hours = 168;\n                config.auto_approve_enabled = true;\n            }\n        }\n    }\n\n    let has_changes = args.approval_mode.is_some()\n        || args.min_approvers.is_some()\n        || args.timeout_hours.is_some()\n        || args.auto_approve.is_some()\n        || args.escalation_contact.is_some()\n        || args.template.is_some();\n\n    if args.show || !has_changes {\n        // Just show current config\n        if args.json {\n            let output = json!({\n                \"approval_mode\": config.approval_mode,\n                \"min_approvers\": config.min_approvers,\n                \"timeout_hours\": config.timeout_hours,\n                \"auto_approve_enabled\": config.auto_approve_enabled,\n                \"escalation_contact\": config.escalation_contact,\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Governance Configuration\");\n            println!();\n\n            println!(\"  Approval Mode:       {}\", config.approval_mode);\n            println!(\"  Min Approvers:       {}\", config.min_approvers);\n            println!(\"  Timeout:             {} hours\", config.timeout_hours);\n            println!(\n                \"  Auto-approve:        {}\",\n                if config.auto_approve_enabled {\n                    \"enabled\"\n                } else {\n                    \"disabled\"\n                }\n            );\n            println!(\n                \"  Escalation Contact:  {}\",\n                config.escalation_contact.as_deref().unwrap_or(\"(not set)\")\n            );\n            println!();\n            output::hint(\"Use --approval-mode, --min-approvers, etc. to change settings\");\n        }\n        return Ok(());\n    }\n\n    // Apply changes\n    let mut changes: Vec<String> = Vec::new();\n\n    if let Some(mode) = args.approval_mode {\n        let mode_str = match mode {\n            ApprovalMode::Single => \"single\",\n            ApprovalMode::Quorum => \"quorum\",\n            ApprovalMode::Unanimous => \"unanimous\",\n        };\n        changes.push(format!(\n            \"approval_mode: {}  {}\",\n            config.approval_mode, mode_str\n        ));\n        config.approval_mode = mode_str.to_string();\n    }\n\n    if let Some(min) = args.min_approvers {\n        changes.push(format!(\"min_approvers: {}  {}\", config.min_approvers, min));\n        config.min_approvers = min;\n    }\n\n    if let Some(timeout) = args.timeout_hours {\n        changes.push(format!(\n            \"timeout_hours: {}  {}\",\n            config.timeout_hours, timeout\n        ));\n        config.timeout_hours = timeout;\n    }\n\n    if let Some(auto) = args.auto_approve {\n        changes.push(format!(\n            \"auto_approve: {}  {}\",\n            config.auto_approve_enabled, auto\n        ));\n        config.auto_approve_enabled = auto;\n    }\n\n    if let Some(contact) = args.escalation_contact {\n        changes.push(format!(\n            \"escalation_contact: {}  {}\",\n            config.escalation_contact.as_deref().unwrap_or(\"(none)\"),\n            contact\n        ));\n        config.escalation_contact = Some(contact);\n    }\n\n    if args.json {\n        let output = json!({\n            \"success\": true,\n            \"changes\": changes,\n            \"new_config\": {\n                \"approval_mode\": config.approval_mode,\n                \"min_approvers\": config.min_approvers,\n                \"timeout_hours\": config.timeout_hours,\n                \"auto_approve_enabled\": config.auto_approve_enabled,\n                \"escalation_contact\": config.escalation_contact,\n            },\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(\"Update Governance Configuration\");\n        println!();\n\n        output::subheader(\"Changes Applied\");\n        for change in &changes {\n            println!(\"   {}\", change);\n        }\n        println!();\n\n        println!(\"  Configuration updated successfully.\");\n        println!();\n    }\n\n    Ok(())\n}\n\nasync fn run_roles(args: GovernRolesArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let _ctx = resolver.resolve()?;\n\n    match args.action.as_str() {\n        \"list\" => {\n            // Simulated role assignments\n            let roles = vec![\n                RoleAssignment {\n                    principal: \"alice\".to_string(),\n                    principal_type: \"user\".to_string(),\n                    role: \"admin\".to_string(),\n                    scope: \"company:acme\".to_string(),\n                },\n                RoleAssignment {\n                    principal: \"bob\".to_string(),\n                    principal_type: \"user\".to_string(),\n                    role: \"architect\".to_string(),\n                    scope: \"org:platform\".to_string(),\n                },\n                RoleAssignment {\n                    principal: \"charlie\".to_string(),\n                    principal_type: \"user\".to_string(),\n                    role: \"techlead\".to_string(),\n                    scope: \"team:api\".to_string(),\n                },\n                RoleAssignment {\n                    principal: \"agent_codex\".to_string(),\n                    principal_type: \"agent\".to_string(),\n                    role: \"developer\".to_string(),\n                    scope: \"project:payments\".to_string(),\n                },\n            ];\n\n            if args.json {\n                let output = json!({\n                    \"roles\": roles.iter().map(|r| json!({\n                        \"principal\": r.principal,\n                        \"principal_type\": r.principal_type,\n                        \"role\": r.role,\n                        \"scope\": r.scope,\n                    })).collect::<Vec<_>>(),\n                });\n                println!(\"{}\", serde_json::to_string_pretty(&output)?);\n            } else {\n                output::header(\"Role Assignments\");\n                println!();\n\n                println!(\n                    \"  {:<20} {:<10} {:<12} {}\",\n                    \"Principal\", \"Type\", \"Role\", \"Scope\"\n                );\n                println!(\"  {}\", \"-\".repeat(60));\n\n                for role in &roles {\n                    println!(\n                        \"  {:<20} {:<10} {:<12} {}\",\n                        role.principal, role.principal_type, role.role, role.scope\n                    );\n                }\n                println!();\n\n                output::hint(\n                    \"Use 'aeterna govern roles assign --principal <id> --role <role> --scope <scope>'\",\n                );\n            }\n        }\n        \"assign\" => {\n            let principal = args\n                .principal\n                .as_ref()\n                .ok_or_else(|| anyhow::anyhow!(\"--principal is required for assign action\"))?;\n            let role = args\n                .role\n                .as_ref()\n                .ok_or_else(|| anyhow::anyhow!(\"--role is required for assign action\"))?;\n            let scope = args.scope.as_deref().unwrap_or(\"project\");\n\n            if args.json {\n                let output = json!({\n                    \"success\": true,\n                    \"action\": \"assign\",\n                    \"principal\": principal,\n                    \"role\": role,\n                    \"scope\": scope,\n                });\n                println!(\"{}\", serde_json::to_string_pretty(&output)?);\n            } else {\n                output::header(\"Assign Role\");\n                println!();\n                println!(\n                    \"   Assigned role '{}' to '{}' at scope '{}'\",\n                    role, principal, scope\n                );\n                println!();\n            }\n        }\n        \"revoke\" => {\n            let principal = args\n                .principal\n                .as_ref()\n                .ok_or_else(|| anyhow::anyhow!(\"--principal is required for revoke action\"))?;\n            let role = args\n                .role\n                .as_ref()\n                .ok_or_else(|| anyhow::anyhow!(\"--role is required for revoke action\"))?;\n\n            if args.json {\n                let output = json!({\n                    \"success\": true,\n                    \"action\": \"revoke\",\n                    \"principal\": principal,\n                    \"role\": role,\n                });\n                println!(\"{}\", serde_json::to_string_pretty(&output)?);\n            } else {\n                output::header(\"Revoke Role\");\n                println!();\n                println!(\"   Revoked role '{}' from '{}'\", role, principal);\n                println!();\n            }\n        }\n        _ => {\n            ux_error::UxError::new(format!(\"Unknown roles action: {}\", args.action))\n                .fix(\"Use one of: list, assign, revoke\")\n                .suggest(\"aeterna govern roles list\")\n                .display();\n            std::process::exit(1);\n        }\n    }\n\n    Ok(())\n}\n\nasync fn run_audit(args: GovernAuditArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let _ctx = resolver.resolve()?;\n\n    // Simulated audit entries\n    let entries = vec![\n        AuditEntry {\n            id: \"aud_001\".to_string(),\n            timestamp: \"2024-01-15T14:30:00Z\".to_string(),\n            action: \"approve\".to_string(),\n            actor: \"alice\".to_string(),\n            target_type: \"policy\".to_string(),\n            target_id: \"req_abc123\".to_string(),\n            details: \"Approved security-baseline policy\".to_string(),\n        },\n        AuditEntry {\n            id: \"aud_002\".to_string(),\n            timestamp: \"2024-01-15T12:15:00Z\".to_string(),\n            action: \"reject\".to_string(),\n            actor: \"bob\".to_string(),\n            target_type: \"knowledge\".to_string(),\n            target_id: \"req_xyz789\".to_string(),\n            details: \"Rejected: needs more context\".to_string(),\n        },\n        AuditEntry {\n            id: \"aud_003\".to_string(),\n            timestamp: \"2024-01-15T10:00:00Z\".to_string(),\n            action: \"approve\".to_string(),\n            actor: \"system\".to_string(),\n            target_type: \"memory\".to_string(),\n            target_id: \"req_auto001\".to_string(),\n            details: \"Auto-approved low-risk memory feedback\".to_string(),\n        },\n        AuditEntry {\n            id: \"aud_004\".to_string(),\n            timestamp: \"2024-01-14T16:45:00Z\".to_string(),\n            action: \"escalate\".to_string(),\n            actor: \"system\".to_string(),\n            target_type: \"policy\".to_string(),\n            target_id: \"req_esc001\".to_string(),\n            details: \"Escalated due to timeout (72h)\".to_string(),\n        },\n    ];\n\n    // Apply filters\n    let filtered: Vec<_> = entries\n        .iter()\n        .filter(|e| args.action == \"all\" || e.action == args.action)\n        .filter(|e| args.actor.as_ref().map_or(true, |a| &e.actor == a))\n        .filter(|e| {\n            args.target_type\n                .as_ref()\n                .map_or(true, |t| &e.target_type == t)\n        })\n        .take(args.limit)\n        .collect();\n\n    match args.export {\n        ExportFormat::None => {\n            if args.json {\n                let output = json!({\n                    \"since\": args.since,\n                    \"total\": filtered.len(),\n                    \"entries\": filtered.iter().map(|e| json!({\n                        \"id\": e.id,\n                        \"timestamp\": e.timestamp,\n                        \"action\": e.action,\n                        \"actor\": e.actor,\n                        \"target_type\": e.target_type,\n                        \"target_id\": e.target_id,\n                        \"details\": e.details,\n                    })).collect::<Vec<_>>(),\n                });\n                println!(\"{}\", serde_json::to_string_pretty(&output)?);\n            } else {\n                output::header(&format!(\"Governance Audit Trail (last {})\", args.since));\n                println!();\n\n                if filtered.is_empty() {\n                    println!(\"  No audit entries matching your filters\");\n                } else {\n                    for entry in &filtered {\n                        let icon = match entry.action.as_str() {\n                            \"approve\" => \"\",\n                            \"reject\" => \"\",\n                            \"escalate\" => \"\",\n                            \"expire\" => \"\",\n                            _ => \"\",\n                        };\n\n                        println!(\n                            \"  {} [{}] {} by {}\",\n                            icon,\n                            entry.timestamp,\n                            entry.action.to_uppercase(),\n                            entry.actor\n                        );\n                        println!(\n                            \"      {} {} - {}\",\n                            entry.target_type, entry.target_id, entry.details\n                        );\n                        println!();\n                    }\n                }\n\n                output::hint(\"Use --export json or --export csv to export audit data\");\n            }\n        }\n        ExportFormat::Json => {\n            let output = json!({\n                \"exported_at\": chrono::Utc::now().to_rfc3339(),\n                \"since\": args.since,\n                \"entries\": filtered.iter().map(|e| json!({\n                    \"id\": e.id,\n                    \"timestamp\": e.timestamp,\n                    \"action\": e.action,\n                    \"actor\": e.actor,\n                    \"target_type\": e.target_type,\n                    \"target_id\": e.target_id,\n                    \"details\": e.details,\n                })).collect::<Vec<_>>(),\n            });\n\n            if let Some(path) = args.output {\n                std::fs::write(&path, serde_json::to_string_pretty(&output)?)?;\n                println!(\"Exported {} entries to {}\", filtered.len(), path);\n            } else {\n                println!(\"{}\", serde_json::to_string_pretty(&output)?);\n            }\n        }\n        ExportFormat::Csv => {\n            let mut csv = String::from(\"id,timestamp,action,actor,target_type,target_id,details\\n\");\n            for entry in &filtered {\n                csv.push_str(&format!(\n                    \"{},{},{},{},{},{},\\\"{}\\\"\\n\",\n                    entry.id,\n                    entry.timestamp,\n                    entry.action,\n                    entry.actor,\n                    entry.target_type,\n                    entry.target_id,\n                    entry.details.replace('\"', \"\\\"\\\"\")\n                ));\n            }\n\n            if let Some(path) = args.output {\n                std::fs::write(&path, &csv)?;\n                println!(\"Exported {} entries to {}\", filtered.len(), path);\n            } else {\n                print!(\"{}\", csv);\n            }\n        }\n    }\n\n    Ok(())\n}\n\n// Helper types\n\nstruct GovernanceStatus {\n    approval_mode: String,\n    min_approvers: u32,\n    timeout_hours: u32,\n    auto_approve_enabled: bool,\n    pending_requests: u32,\n    approved_today: u32,\n    rejected_today: u32,\n    escalated: u32,\n    your_pending_approvals: u32,\n}\n\nstruct PendingRequest {\n    id: String,\n    request_type: String,\n    title: String,\n    requestor: String,\n    layer: String,\n    created_at: String,\n    approvals: u32,\n    required_approvals: u32,\n    status: String,\n}\n\nstruct GovernanceConfig {\n    approval_mode: String,\n    min_approvers: u32,\n    timeout_hours: u32,\n    auto_approve_enabled: bool,\n    escalation_contact: Option<String>,\n}\n\nstruct RoleAssignment {\n    principal: String,\n    principal_type: String,\n    role: String,\n    scope: String,\n}\n\nstruct AuditEntry {\n    id: String,\n    timestamp: String,\n    action: String,\n    actor: String,\n    target_type: String,\n    target_id: String,\n    details: String,\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_approval_mode_values() {\n        let _single = ApprovalMode::Single;\n        let _quorum = ApprovalMode::Quorum;\n        let _unanimous = ApprovalMode::Unanimous;\n    }\n\n    #[test]\n    fn test_export_format_values() {\n        let _json = ExportFormat::Json;\n        let _csv = ExportFormat::Csv;\n        let _none = ExportFormat::None;\n    }\n\n    #[test]\n    fn test_governance_template_values() {\n        let _standard = GovernanceTemplate::Standard;\n        let _strict = GovernanceTemplate::Strict;\n        let _permissive = GovernanceTemplate::Permissive;\n    }\n\n    #[test]\n    fn test_pending_request_creation() {\n        let req = PendingRequest {\n            id: \"req_123\".to_string(),\n            request_type: \"policy\".to_string(),\n            title: \"Test policy\".to_string(),\n            requestor: \"alice\".to_string(),\n            layer: \"team\".to_string(),\n            created_at: \"2024-01-15T10:00:00Z\".to_string(),\n            approvals: 1,\n            required_approvals: 2,\n            status: \"pending\".to_string(),\n        };\n        assert_eq!(req.id, \"req_123\");\n        assert!(req.approvals < req.required_approvals);\n    }\n\n    #[test]\n    fn test_pending_request_fully_approved() {\n        let req = PendingRequest {\n            id: \"req_456\".to_string(),\n            request_type: \"knowledge\".to_string(),\n            title: \"Promote ADR\".to_string(),\n            requestor: \"bob\".to_string(),\n            layer: \"org\".to_string(),\n            created_at: \"2024-01-15T10:00:00Z\".to_string(),\n            approvals: 2,\n            required_approvals: 2,\n            status: \"ready\".to_string(),\n        };\n        assert_eq!(req.approvals, req.required_approvals);\n        assert_eq!(req.status, \"ready\");\n    }\n\n    #[test]\n    fn test_pending_request_types() {\n        let policy_req = PendingRequest {\n            id: \"req_1\".to_string(),\n            request_type: \"policy\".to_string(),\n            title: \"Policy request\".to_string(),\n            requestor: \"alice\".to_string(),\n            layer: \"company\".to_string(),\n            created_at: \"2024-01-15T10:00:00Z\".to_string(),\n            approvals: 0,\n            required_approvals: 1,\n            status: \"pending\".to_string(),\n        };\n\n        let knowledge_req = PendingRequest {\n            id: \"req_2\".to_string(),\n            request_type: \"knowledge\".to_string(),\n            title: \"Knowledge request\".to_string(),\n            requestor: \"bob\".to_string(),\n            layer: \"org\".to_string(),\n            created_at: \"2024-01-15T10:00:00Z\".to_string(),\n            approvals: 0,\n            required_approvals: 2,\n            status: \"pending\".to_string(),\n        };\n\n        let memory_req = PendingRequest {\n            id: \"req_3\".to_string(),\n            request_type: \"memory\".to_string(),\n            title: \"Memory request\".to_string(),\n            requestor: \"agent_1\".to_string(),\n            layer: \"team\".to_string(),\n            created_at: \"2024-01-15T10:00:00Z\".to_string(),\n            approvals: 0,\n            required_approvals: 1,\n            status: \"pending\".to_string(),\n        };\n\n        assert_eq!(policy_req.request_type, \"policy\");\n        assert_eq!(knowledge_req.request_type, \"knowledge\");\n        assert_eq!(memory_req.request_type, \"memory\");\n    }\n\n    #[test]\n    fn test_role_assignment_creation() {\n        let role = RoleAssignment {\n            principal: \"alice\".to_string(),\n            principal_type: \"user\".to_string(),\n            role: \"admin\".to_string(),\n            scope: \"company:acme\".to_string(),\n        };\n        assert_eq!(role.role, \"admin\");\n    }\n\n    #[test]\n    fn test_role_assignment_agent_type() {\n        let role = RoleAssignment {\n            principal: \"agent_codex\".to_string(),\n            principal_type: \"agent\".to_string(),\n            role: \"developer\".to_string(),\n            scope: \"project:payments\".to_string(),\n        };\n        assert_eq!(role.principal_type, \"agent\");\n        assert_eq!(role.role, \"developer\");\n    }\n\n    #[test]\n    fn test_role_assignment_all_roles() {\n        let roles = [\"admin\", \"architect\", \"techlead\", \"developer\"];\n        for role_name in roles {\n            let role = RoleAssignment {\n                principal: \"user\".to_string(),\n                principal_type: \"user\".to_string(),\n                role: role_name.to_string(),\n                scope: \"company:test\".to_string(),\n            };\n            assert_eq!(role.role, role_name);\n        }\n    }\n\n    #[test]\n    fn test_role_assignment_all_scopes() {\n        let scopes = [\n            \"company:acme\",\n            \"org:platform\",\n            \"team:api\",\n            \"project:payments\",\n        ];\n        for scope in scopes {\n            let role = RoleAssignment {\n                principal: \"alice\".to_string(),\n                principal_type: \"user\".to_string(),\n                role: \"developer\".to_string(),\n                scope: scope.to_string(),\n            };\n            assert_eq!(role.scope, scope);\n        }\n    }\n\n    #[test]\n    fn test_audit_entry_creation() {\n        let entry = AuditEntry {\n            id: \"aud_001\".to_string(),\n            timestamp: \"2024-01-15T10:00:00Z\".to_string(),\n            action: \"approve\".to_string(),\n            actor: \"alice\".to_string(),\n            target_type: \"policy\".to_string(),\n            target_id: \"req_123\".to_string(),\n            details: \"Approved\".to_string(),\n        };\n        assert_eq!(entry.action, \"approve\");\n    }\n\n    #[test]\n    fn test_audit_entry_all_actions() {\n        let actions = [\"approve\", \"reject\", \"escalate\", \"expire\"];\n        for action in actions {\n            let entry = AuditEntry {\n                id: format!(\"aud_{}\", action),\n                timestamp: \"2024-01-15T10:00:00Z\".to_string(),\n                action: action.to_string(),\n                actor: \"system\".to_string(),\n                target_type: \"policy\".to_string(),\n                target_id: \"req_123\".to_string(),\n                details: format!(\"Action: {}\", action),\n            };\n            assert_eq!(entry.action, action);\n        }\n    }\n\n    #[test]\n    fn test_audit_entry_target_types() {\n        let target_types = [\"policy\", \"knowledge\", \"memory\"];\n        for target_type in target_types {\n            let entry = AuditEntry {\n                id: \"aud_001\".to_string(),\n                timestamp: \"2024-01-15T10:00:00Z\".to_string(),\n                action: \"approve\".to_string(),\n                actor: \"alice\".to_string(),\n                target_type: target_type.to_string(),\n                target_id: \"req_123\".to_string(),\n                details: \"Approved\".to_string(),\n            };\n            assert_eq!(entry.target_type, target_type);\n        }\n    }\n\n    #[test]\n    fn test_governance_status_creation() {\n        let status = GovernanceStatus {\n            approval_mode: \"quorum\".to_string(),\n            min_approvers: 2,\n            timeout_hours: 72,\n            auto_approve_enabled: true,\n            pending_requests: 3,\n            approved_today: 7,\n            rejected_today: 1,\n            escalated: 0,\n            your_pending_approvals: 2,\n        };\n        assert_eq!(status.approval_mode, \"quorum\");\n        assert_eq!(status.min_approvers, 2);\n        assert!(status.auto_approve_enabled);\n    }\n\n    #[test]\n    fn test_governance_status_strict_mode() {\n        let status = GovernanceStatus {\n            approval_mode: \"unanimous\".to_string(),\n            min_approvers: 3,\n            timeout_hours: 24,\n            auto_approve_enabled: false,\n            pending_requests: 5,\n            approved_today: 2,\n            rejected_today: 3,\n            escalated: 1,\n            your_pending_approvals: 4,\n        };\n        assert_eq!(status.approval_mode, \"unanimous\");\n        assert!(!status.auto_approve_enabled);\n        assert!(status.escalated > 0);\n    }\n\n    #[test]\n    fn test_governance_config_creation() {\n        let config = GovernanceConfig {\n            approval_mode: \"quorum\".to_string(),\n            min_approvers: 2,\n            timeout_hours: 72,\n            auto_approve_enabled: true,\n            escalation_contact: Some(\"security-team@acme.com\".to_string()),\n        };\n        assert_eq!(config.approval_mode, \"quorum\");\n        assert!(config.escalation_contact.is_some());\n    }\n\n    #[test]\n    fn test_governance_config_no_escalation() {\n        let config = GovernanceConfig {\n            approval_mode: \"single\".to_string(),\n            min_approvers: 1,\n            timeout_hours: 168,\n            auto_approve_enabled: true,\n            escalation_contact: None,\n        };\n        assert!(config.escalation_contact.is_none());\n    }\n\n    #[test]\n    fn test_govern_status_args_defaults() {\n        let args = GovernStatusArgs {\n            json: false,\n            verbose: false,\n        };\n        assert!(!args.json);\n        assert!(!args.verbose);\n    }\n\n    #[test]\n    fn test_govern_pending_args_defaults() {\n        let args = GovernPendingArgs {\n            request_type: \"all\".to_string(),\n            layer: None,\n            requestor: None,\n            mine: false,\n            json: false,\n        };\n        assert_eq!(args.request_type, \"all\");\n        assert!(args.layer.is_none());\n    }\n\n    #[test]\n    fn test_govern_pending_args_with_filters() {\n        let args = GovernPendingArgs {\n            request_type: \"policy\".to_string(),\n            layer: Some(\"org\".to_string()),\n            requestor: Some(\"alice\".to_string()),\n            mine: true,\n            json: true,\n        };\n        assert_eq!(args.request_type, \"policy\");\n        assert_eq!(args.layer.as_deref(), Some(\"org\"));\n        assert!(args.mine);\n    }\n\n    #[test]\n    fn test_govern_approve_args() {\n        let args = GovernApproveArgs {\n            request_id: \"req_123\".to_string(),\n            comment: Some(\"LGTM\".to_string()),\n            yes: true,\n            json: false,\n        };\n        assert_eq!(args.request_id, \"req_123\");\n        assert!(args.comment.is_some());\n        assert!(args.yes);\n    }\n\n    #[test]\n    fn test_govern_reject_args() {\n        let args = GovernRejectArgs {\n            request_id: \"req_456\".to_string(),\n            reason: \"Security concerns\".to_string(),\n            yes: false,\n            json: true,\n        };\n        assert_eq!(args.request_id, \"req_456\");\n        assert!(!args.reason.is_empty());\n    }\n\n    #[test]\n    fn test_govern_configure_args_show() {\n        let args = GovernConfigureArgs {\n            show: true,\n            template: None,\n            list_templates: false,\n            approval_mode: None,\n            min_approvers: None,\n            timeout_hours: None,\n            auto_approve: None,\n            escalation_contact: None,\n            json: false,\n        };\n        assert!(args.show);\n        assert!(args.template.is_none());\n    }\n\n    #[test]\n    fn test_govern_configure_args_with_template() {\n        let args = GovernConfigureArgs {\n            show: false,\n            template: Some(GovernanceTemplate::Strict),\n            list_templates: false,\n            approval_mode: None,\n            min_approvers: None,\n            timeout_hours: None,\n            auto_approve: None,\n            escalation_contact: None,\n            json: false,\n        };\n        assert!(args.template.is_some());\n    }\n\n    #[test]\n    fn test_govern_configure_args_with_overrides() {\n        let args = GovernConfigureArgs {\n            show: false,\n            template: None,\n            list_templates: false,\n            approval_mode: Some(ApprovalMode::Quorum),\n            min_approvers: Some(3),\n            timeout_hours: Some(48),\n            auto_approve: Some(false),\n            escalation_contact: Some(\"ops@example.com\".to_string()),\n            json: false,\n        };\n        assert!(args.approval_mode.is_some());\n        assert_eq!(args.min_approvers, Some(3));\n    }\n\n    #[test]\n    fn test_govern_roles_args_list() {\n        let args = GovernRolesArgs {\n            action: \"list\".to_string(),\n            principal: None,\n            role: None,\n            scope: None,\n            json: false,\n        };\n        assert_eq!(args.action, \"list\");\n    }\n\n    #[test]\n    fn test_govern_roles_args_assign() {\n        let args = GovernRolesArgs {\n            action: \"assign\".to_string(),\n            principal: Some(\"alice\".to_string()),\n            role: Some(\"admin\".to_string()),\n            scope: Some(\"company:acme\".to_string()),\n            json: false,\n        };\n        assert_eq!(args.action, \"assign\");\n        assert!(args.principal.is_some());\n        assert!(args.role.is_some());\n    }\n\n    #[test]\n    fn test_govern_roles_args_revoke() {\n        let args = GovernRolesArgs {\n            action: \"revoke\".to_string(),\n            principal: Some(\"bob\".to_string()),\n            role: Some(\"developer\".to_string()),\n            scope: None,\n            json: true,\n        };\n        assert_eq!(args.action, \"revoke\");\n        assert!(args.json);\n    }\n\n    #[test]\n    fn test_govern_audit_args_defaults() {\n        let args = GovernAuditArgs {\n            action: \"all\".to_string(),\n            since: \"7d\".to_string(),\n            actor: None,\n            target_type: None,\n            limit: 50,\n            export: ExportFormat::None,\n            output: None,\n            json: false,\n        };\n        assert_eq!(args.action, \"all\");\n        assert_eq!(args.since, \"7d\");\n        assert_eq!(args.limit, 50);\n    }\n\n    #[test]\n    fn test_govern_audit_args_with_filters() {\n        let args = GovernAuditArgs {\n            action: \"approve\".to_string(),\n            since: \"24h\".to_string(),\n            actor: Some(\"alice\".to_string()),\n            target_type: Some(\"policy\".to_string()),\n            limit: 100,\n            export: ExportFormat::Json,\n            output: Some(\"audit.json\".to_string()),\n            json: false,\n        };\n        assert_eq!(args.action, \"approve\");\n        assert!(args.actor.is_some());\n    }\n\n    #[test]\n    fn test_govern_audit_args_csv_export() {\n        let args = GovernAuditArgs {\n            action: \"all\".to_string(),\n            since: \"30d\".to_string(),\n            actor: None,\n            target_type: None,\n            limit: 1000,\n            export: ExportFormat::Csv,\n            output: Some(\"audit.csv\".to_string()),\n            json: false,\n        };\n        matches!(args.export, ExportFormat::Csv);\n        assert!(args.output.is_some());\n    }\n\n    #[test]\n    fn test_filter_pending_requests_by_type() {\n        let requests = vec![\n            PendingRequest {\n                id: \"req_1\".to_string(),\n                request_type: \"policy\".to_string(),\n                title: \"Policy 1\".to_string(),\n                requestor: \"alice\".to_string(),\n                layer: \"org\".to_string(),\n                created_at: \"2024-01-15T10:00:00Z\".to_string(),\n                approvals: 0,\n                required_approvals: 2,\n                status: \"pending\".to_string(),\n            },\n            PendingRequest {\n                id: \"req_2\".to_string(),\n                request_type: \"knowledge\".to_string(),\n                title: \"Knowledge 1\".to_string(),\n                requestor: \"bob\".to_string(),\n                layer: \"company\".to_string(),\n                created_at: \"2024-01-15T08:00:00Z\".to_string(),\n                approvals: 0,\n                required_approvals: 2,\n                status: \"pending\".to_string(),\n            },\n        ];\n\n        let filtered: Vec<_> = requests\n            .iter()\n            .filter(|r| r.request_type == \"policy\")\n            .collect();\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].id, \"req_1\");\n    }\n\n    #[test]\n    fn test_filter_pending_requests_by_layer() {\n        let requests = vec![\n            PendingRequest {\n                id: \"req_1\".to_string(),\n                request_type: \"policy\".to_string(),\n                title: \"Policy 1\".to_string(),\n                requestor: \"alice\".to_string(),\n                layer: \"org\".to_string(),\n                created_at: \"2024-01-15T10:00:00Z\".to_string(),\n                approvals: 0,\n                required_approvals: 2,\n                status: \"pending\".to_string(),\n            },\n            PendingRequest {\n                id: \"req_2\".to_string(),\n                request_type: \"policy\".to_string(),\n                title: \"Policy 2\".to_string(),\n                requestor: \"bob\".to_string(),\n                layer: \"company\".to_string(),\n                created_at: \"2024-01-15T08:00:00Z\".to_string(),\n                approvals: 0,\n                required_approvals: 2,\n                status: \"pending\".to_string(),\n            },\n        ];\n\n        let layer_filter = Some(\"company\".to_string());\n        let filtered: Vec<_> = requests\n            .iter()\n            .filter(|r| layer_filter.as_ref().map_or(true, |l| &r.layer == l))\n            .collect();\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].id, \"req_2\");\n    }\n\n    #[test]\n    fn test_filter_audit_entries_by_action() {\n        let entries = vec![\n            AuditEntry {\n                id: \"aud_1\".to_string(),\n                timestamp: \"2024-01-15T14:30:00Z\".to_string(),\n                action: \"approve\".to_string(),\n                actor: \"alice\".to_string(),\n                target_type: \"policy\".to_string(),\n                target_id: \"req_1\".to_string(),\n                details: \"Approved\".to_string(),\n            },\n            AuditEntry {\n                id: \"aud_2\".to_string(),\n                timestamp: \"2024-01-15T12:15:00Z\".to_string(),\n                action: \"reject\".to_string(),\n                actor: \"bob\".to_string(),\n                target_type: \"knowledge\".to_string(),\n                target_id: \"req_2\".to_string(),\n                details: \"Rejected\".to_string(),\n            },\n        ];\n\n        let action_filter = \"approve\";\n        let filtered: Vec<_> = entries\n            .iter()\n            .filter(|e| e.action == action_filter)\n            .collect();\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].id, \"aud_1\");\n    }\n\n    #[test]\n    fn test_filter_audit_entries_by_actor() {\n        let entries = vec![\n            AuditEntry {\n                id: \"aud_1\".to_string(),\n                timestamp: \"2024-01-15T14:30:00Z\".to_string(),\n                action: \"approve\".to_string(),\n                actor: \"alice\".to_string(),\n                target_type: \"policy\".to_string(),\n                target_id: \"req_1\".to_string(),\n                details: \"Approved\".to_string(),\n            },\n            AuditEntry {\n                id: \"aud_2\".to_string(),\n                timestamp: \"2024-01-15T12:15:00Z\".to_string(),\n                action: \"approve\".to_string(),\n                actor: \"bob\".to_string(),\n                target_type: \"knowledge\".to_string(),\n                target_id: \"req_2\".to_string(),\n                details: \"Approved\".to_string(),\n            },\n        ];\n\n        let actor_filter = Some(\"bob\".to_string());\n        let filtered: Vec<_> = entries\n            .iter()\n            .filter(|e| actor_filter.as_ref().map_or(true, |a| &e.actor == a))\n            .collect();\n        assert_eq!(filtered.len(), 1);\n        assert_eq!(filtered[0].actor, \"bob\");\n    }\n\n    #[test]\n    fn test_approval_count_logic() {\n        let mut req = PendingRequest {\n            id: \"req_123\".to_string(),\n            request_type: \"policy\".to_string(),\n            title: \"Test policy\".to_string(),\n            requestor: \"alice\".to_string(),\n            layer: \"team\".to_string(),\n            created_at: \"2024-01-15T10:00:00Z\".to_string(),\n            approvals: 1,\n            required_approvals: 2,\n            status: \"pending\".to_string(),\n        };\n\n        assert!(req.approvals < req.required_approvals);\n\n        req.approvals += 1;\n        assert!(req.approvals >= req.required_approvals);\n    }\n}\n","traces":[{"line":220,"address":[],"length":0,"stats":{"Line":0}},{"line":221,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":223,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":225,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":0}},{"line":252,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":0}},{"line":255,"address":[],"length":0,"stats":{"Line":0}},{"line":256,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":264,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":272,"address":[],"length":0,"stats":{"Line":0}},{"line":274,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":276,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":298,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":0}},{"line":321,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":0}},{"line":323,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":325,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":333,"address":[],"length":0,"stats":{"Line":0}},{"line":334,"address":[],"length":0,"stats":{"Line":0}},{"line":335,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":337,"address":[],"length":0,"stats":{"Line":0}},{"line":338,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":343,"address":[],"length":0,"stats":{"Line":0}},{"line":344,"address":[],"length":0,"stats":{"Line":0}},{"line":345,"address":[],"length":0,"stats":{"Line":0}},{"line":346,"address":[],"length":0,"stats":{"Line":0}},{"line":347,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":0}},{"line":350,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":359,"address":[],"length":0,"stats":{"Line":0}},{"line":360,"address":[],"length":0,"stats":{"Line":0}},{"line":361,"address":[],"length":0,"stats":{"Line":0}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":363,"address":[],"length":0,"stats":{"Line":0}},{"line":364,"address":[],"length":0,"stats":{"Line":0}},{"line":368,"address":[],"length":0,"stats":{"Line":0}},{"line":369,"address":[],"length":0,"stats":{"Line":0}},{"line":370,"address":[],"length":0,"stats":{"Line":0}},{"line":371,"address":[],"length":0,"stats":{"Line":0}},{"line":372,"address":[],"length":0,"stats":{"Line":0}},{"line":373,"address":[],"length":0,"stats":{"Line":0}},{"line":374,"address":[],"length":0,"stats":{"Line":0}},{"line":375,"address":[],"length":0,"stats":{"Line":0}},{"line":376,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":378,"address":[],"length":0,"stats":{"Line":0}},{"line":379,"address":[],"length":0,"stats":{"Line":0}},{"line":380,"address":[],"length":0,"stats":{"Line":0}},{"line":381,"address":[],"length":0,"stats":{"Line":0}},{"line":383,"address":[],"length":0,"stats":{"Line":0}},{"line":385,"address":[],"length":0,"stats":{"Line":0}},{"line":386,"address":[],"length":0,"stats":{"Line":0}},{"line":388,"address":[],"length":0,"stats":{"Line":0}},{"line":389,"address":[],"length":0,"stats":{"Line":0}},{"line":390,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":0}},{"line":393,"address":[],"length":0,"stats":{"Line":0}},{"line":394,"address":[],"length":0,"stats":{"Line":0}},{"line":395,"address":[],"length":0,"stats":{"Line":0}},{"line":396,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":400,"address":[],"length":0,"stats":{"Line":0}},{"line":403,"address":[],"length":0,"stats":{"Line":0}},{"line":404,"address":[],"length":0,"stats":{"Line":0}},{"line":407,"address":[],"length":0,"stats":{"Line":0}},{"line":408,"address":[],"length":0,"stats":{"Line":0}},{"line":417,"address":[],"length":0,"stats":{"Line":0}},{"line":420,"address":[],"length":0,"stats":{"Line":0}},{"line":421,"address":[],"length":0,"stats":{"Line":0}},{"line":422,"address":[],"length":0,"stats":{"Line":0}},{"line":426,"address":[],"length":0,"stats":{"Line":0}},{"line":427,"address":[],"length":0,"stats":{"Line":0}},{"line":428,"address":[],"length":0,"stats":{"Line":0}},{"line":429,"address":[],"length":0,"stats":{"Line":0}},{"line":430,"address":[],"length":0,"stats":{"Line":0}},{"line":431,"address":[],"length":0,"stats":{"Line":0}},{"line":434,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":0}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":441,"address":[],"length":0,"stats":{"Line":0}},{"line":442,"address":[],"length":0,"stats":{"Line":0}},{"line":443,"address":[],"length":0,"stats":{"Line":0}},{"line":444,"address":[],"length":0,"stats":{"Line":0}},{"line":445,"address":[],"length":0,"stats":{"Line":0}},{"line":447,"address":[],"length":0,"stats":{"Line":0}},{"line":449,"address":[],"length":0,"stats":{"Line":0}},{"line":450,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":453,"address":[],"length":0,"stats":{"Line":0}},{"line":454,"address":[],"length":0,"stats":{"Line":0}},{"line":455,"address":[],"length":0,"stats":{"Line":0}},{"line":456,"address":[],"length":0,"stats":{"Line":0}},{"line":457,"address":[],"length":0,"stats":{"Line":0}},{"line":459,"address":[],"length":0,"stats":{"Line":0}},{"line":461,"address":[],"length":0,"stats":{"Line":0}},{"line":464,"address":[],"length":0,"stats":{"Line":0}},{"line":465,"address":[],"length":0,"stats":{"Line":0}},{"line":466,"address":[],"length":0,"stats":{"Line":0}},{"line":468,"address":[],"length":0,"stats":{"Line":0}},{"line":470,"address":[],"length":0,"stats":{"Line":0}},{"line":471,"address":[],"length":0,"stats":{"Line":0}},{"line":472,"address":[],"length":0,"stats":{"Line":0}},{"line":473,"address":[],"length":0,"stats":{"Line":0}},{"line":474,"address":[],"length":0,"stats":{"Line":0}},{"line":476,"address":[],"length":0,"stats":{"Line":0}},{"line":478,"address":[],"length":0,"stats":{"Line":0}},{"line":479,"address":[],"length":0,"stats":{"Line":0}},{"line":480,"address":[],"length":0,"stats":{"Line":0}},{"line":482,"address":[],"length":0,"stats":{"Line":0}},{"line":483,"address":[],"length":0,"stats":{"Line":0}},{"line":484,"address":[],"length":0,"stats":{"Line":0}},{"line":487,"address":[],"length":0,"stats":{"Line":0}},{"line":490,"address":[],"length":0,"stats":{"Line":0}},{"line":493,"address":[],"length":0,"stats":{"Line":0}},{"line":494,"address":[],"length":0,"stats":{"Line":0}},{"line":495,"address":[],"length":0,"stats":{"Line":0}},{"line":497,"address":[],"length":0,"stats":{"Line":0}},{"line":498,"address":[],"length":0,"stats":{"Line":0}},{"line":501,"address":[],"length":0,"stats":{"Line":0}},{"line":502,"address":[],"length":0,"stats":{"Line":0}},{"line":503,"address":[],"length":0,"stats":{"Line":0}},{"line":506,"address":[],"length":0,"stats":{"Line":0}},{"line":511,"address":[],"length":0,"stats":{"Line":0}},{"line":512,"address":[],"length":0,"stats":{"Line":0}},{"line":513,"address":[],"length":0,"stats":{"Line":0}},{"line":514,"address":[],"length":0,"stats":{"Line":0}},{"line":515,"address":[],"length":0,"stats":{"Line":0}},{"line":516,"address":[],"length":0,"stats":{"Line":0}},{"line":519,"address":[],"length":0,"stats":{"Line":0}},{"line":522,"address":[],"length":0,"stats":{"Line":0}},{"line":523,"address":[],"length":0,"stats":{"Line":0}},{"line":524,"address":[],"length":0,"stats":{"Line":0}},{"line":525,"address":[],"length":0,"stats":{"Line":0}},{"line":526,"address":[],"length":0,"stats":{"Line":0}},{"line":527,"address":[],"length":0,"stats":{"Line":0}},{"line":528,"address":[],"length":0,"stats":{"Line":0}},{"line":530,"address":[],"length":0,"stats":{"Line":0}},{"line":532,"address":[],"length":0,"stats":{"Line":0}},{"line":533,"address":[],"length":0,"stats":{"Line":0}},{"line":535,"address":[],"length":0,"stats":{"Line":0}},{"line":536,"address":[],"length":0,"stats":{"Line":0}},{"line":537,"address":[],"length":0,"stats":{"Line":0}},{"line":538,"address":[],"length":0,"stats":{"Line":0}},{"line":539,"address":[],"length":0,"stats":{"Line":0}},{"line":541,"address":[],"length":0,"stats":{"Line":0}},{"line":543,"address":[],"length":0,"stats":{"Line":0}},{"line":546,"address":[],"length":0,"stats":{"Line":0}},{"line":547,"address":[],"length":0,"stats":{"Line":0}},{"line":548,"address":[],"length":0,"stats":{"Line":0}},{"line":549,"address":[],"length":0,"stats":{"Line":0}},{"line":550,"address":[],"length":0,"stats":{"Line":0}},{"line":553,"address":[],"length":0,"stats":{"Line":0}},{"line":556,"address":[],"length":0,"stats":{"Line":0}},{"line":557,"address":[],"length":0,"stats":{"Line":0}},{"line":558,"address":[],"length":0,"stats":{"Line":0}},{"line":560,"address":[],"length":0,"stats":{"Line":0}},{"line":561,"address":[],"length":0,"stats":{"Line":0}},{"line":563,"address":[],"length":0,"stats":{"Line":0}},{"line":564,"address":[],"length":0,"stats":{"Line":0}},{"line":565,"address":[],"length":0,"stats":{"Line":0}},{"line":566,"address":[],"length":0,"stats":{"Line":0}},{"line":567,"address":[],"length":0,"stats":{"Line":0}},{"line":568,"address":[],"length":0,"stats":{"Line":0}},{"line":571,"address":[],"length":0,"stats":{"Line":0}},{"line":572,"address":[],"length":0,"stats":{"Line":0}},{"line":573,"address":[],"length":0,"stats":{"Line":0}},{"line":574,"address":[],"length":0,"stats":{"Line":0}},{"line":575,"address":[],"length":0,"stats":{"Line":0}},{"line":576,"address":[],"length":0,"stats":{"Line":0}},{"line":579,"address":[],"length":0,"stats":{"Line":0}},{"line":580,"address":[],"length":0,"stats":{"Line":0}},{"line":581,"address":[],"length":0,"stats":{"Line":0}},{"line":582,"address":[],"length":0,"stats":{"Line":0}},{"line":583,"address":[],"length":0,"stats":{"Line":0}},{"line":584,"address":[],"length":0,"stats":{"Line":0}},{"line":588,"address":[],"length":0,"stats":{"Line":0}},{"line":589,"address":[],"length":0,"stats":{"Line":0}},{"line":591,"address":[],"length":0,"stats":{"Line":0}},{"line":592,"address":[],"length":0,"stats":{"Line":0}},{"line":593,"address":[],"length":0,"stats":{"Line":0}},{"line":594,"address":[],"length":0,"stats":{"Line":0}},{"line":595,"address":[],"length":0,"stats":{"Line":0}},{"line":596,"address":[],"length":0,"stats":{"Line":0}},{"line":597,"address":[],"length":0,"stats":{"Line":0}},{"line":598,"address":[],"length":0,"stats":{"Line":0}},{"line":599,"address":[],"length":0,"stats":{"Line":0}},{"line":604,"address":[],"length":0,"stats":{"Line":0}},{"line":606,"address":[],"length":0,"stats":{"Line":0}},{"line":607,"address":[],"length":0,"stats":{"Line":0}},{"line":609,"address":[],"length":0,"stats":{"Line":0}},{"line":610,"address":[],"length":0,"stats":{"Line":0}},{"line":611,"address":[],"length":0,"stats":{"Line":0}},{"line":612,"address":[],"length":0,"stats":{"Line":0}},{"line":613,"address":[],"length":0,"stats":{"Line":0}},{"line":614,"address":[],"length":0,"stats":{"Line":0}},{"line":615,"address":[],"length":0,"stats":{"Line":0}},{"line":616,"address":[],"length":0,"stats":{"Line":0}},{"line":618,"address":[],"length":0,"stats":{"Line":0}},{"line":621,"address":[],"length":0,"stats":{"Line":0}},{"line":623,"address":[],"length":0,"stats":{"Line":0}},{"line":627,"address":[],"length":0,"stats":{"Line":0}},{"line":631,"address":[],"length":0,"stats":{"Line":0}},{"line":634,"address":[],"length":0,"stats":{"Line":0}},{"line":635,"address":[],"length":0,"stats":{"Line":0}},{"line":636,"address":[],"length":0,"stats":{"Line":0}},{"line":637,"address":[],"length":0,"stats":{"Line":0}},{"line":638,"address":[],"length":0,"stats":{"Line":0}},{"line":639,"address":[],"length":0,"stats":{"Line":0}},{"line":640,"address":[],"length":0,"stats":{"Line":0}},{"line":642,"address":[],"length":0,"stats":{"Line":0}},{"line":643,"address":[],"length":0,"stats":{"Line":0}},{"line":644,"address":[],"length":0,"stats":{"Line":0}},{"line":645,"address":[],"length":0,"stats":{"Line":0}},{"line":646,"address":[],"length":0,"stats":{"Line":0}},{"line":648,"address":[],"length":0,"stats":{"Line":0}},{"line":649,"address":[],"length":0,"stats":{"Line":0}},{"line":650,"address":[],"length":0,"stats":{"Line":0}},{"line":651,"address":[],"length":0,"stats":{"Line":0}},{"line":652,"address":[],"length":0,"stats":{"Line":0}},{"line":657,"address":[],"length":0,"stats":{"Line":0}},{"line":658,"address":[],"length":0,"stats":{"Line":0}},{"line":659,"address":[],"length":0,"stats":{"Line":0}},{"line":660,"address":[],"length":0,"stats":{"Line":0}},{"line":661,"address":[],"length":0,"stats":{"Line":0}},{"line":662,"address":[],"length":0,"stats":{"Line":0}},{"line":664,"address":[],"length":0,"stats":{"Line":0}},{"line":666,"address":[],"length":0,"stats":{"Line":0}},{"line":667,"address":[],"length":0,"stats":{"Line":0}},{"line":668,"address":[],"length":0,"stats":{"Line":0}},{"line":669,"address":[],"length":0,"stats":{"Line":0}},{"line":670,"address":[],"length":0,"stats":{"Line":0}},{"line":671,"address":[],"length":0,"stats":{"Line":0}},{"line":672,"address":[],"length":0,"stats":{"Line":0}},{"line":674,"address":[],"length":0,"stats":{"Line":0}},{"line":676,"address":[],"length":0,"stats":{"Line":0}},{"line":677,"address":[],"length":0,"stats":{"Line":0}},{"line":679,"address":[],"length":0,"stats":{"Line":0}},{"line":680,"address":[],"length":0,"stats":{"Line":0}},{"line":681,"address":[],"length":0,"stats":{"Line":0}},{"line":682,"address":[],"length":0,"stats":{"Line":0}},{"line":683,"address":[],"length":0,"stats":{"Line":0}},{"line":684,"address":[],"length":0,"stats":{"Line":0}},{"line":685,"address":[],"length":0,"stats":{"Line":0}},{"line":687,"address":[],"length":0,"stats":{"Line":0}},{"line":690,"address":[],"length":0,"stats":{"Line":0}},{"line":691,"address":[],"length":0,"stats":{"Line":0}},{"line":692,"address":[],"length":0,"stats":{"Line":0}},{"line":694,"address":[],"length":0,"stats":{"Line":0}},{"line":695,"address":[],"length":0,"stats":{"Line":0}},{"line":697,"address":[],"length":0,"stats":{"Line":0}},{"line":701,"address":[],"length":0,"stats":{"Line":0}},{"line":703,"address":[],"length":0,"stats":{"Line":0}},{"line":704,"address":[],"length":0,"stats":{"Line":0}},{"line":705,"address":[],"length":0,"stats":{"Line":0}},{"line":706,"address":[],"length":0,"stats":{"Line":0}},{"line":707,"address":[],"length":0,"stats":{"Line":0}},{"line":709,"address":[],"length":0,"stats":{"Line":0}},{"line":710,"address":[],"length":0,"stats":{"Line":0}},{"line":713,"address":[],"length":0,"stats":{"Line":0}},{"line":716,"address":[],"length":0,"stats":{"Line":0}},{"line":717,"address":[],"length":0,"stats":{"Line":0}},{"line":718,"address":[],"length":0,"stats":{"Line":0}},{"line":721,"address":[],"length":0,"stats":{"Line":0}},{"line":722,"address":[],"length":0,"stats":{"Line":0}},{"line":723,"address":[],"length":0,"stats":{"Line":0}},{"line":724,"address":[],"length":0,"stats":{"Line":0}},{"line":726,"address":[],"length":0,"stats":{"Line":0}},{"line":729,"address":[],"length":0,"stats":{"Line":0}},{"line":730,"address":[],"length":0,"stats":{"Line":0}},{"line":731,"address":[],"length":0,"stats":{"Line":0}},{"line":732,"address":[],"length":0,"stats":{"Line":0}},{"line":734,"address":[],"length":0,"stats":{"Line":0}},{"line":737,"address":[],"length":0,"stats":{"Line":0}},{"line":738,"address":[],"length":0,"stats":{"Line":0}},{"line":739,"address":[],"length":0,"stats":{"Line":0}},{"line":740,"address":[],"length":0,"stats":{"Line":0}},{"line":741,"address":[],"length":0,"stats":{"Line":0}},{"line":743,"address":[],"length":0,"stats":{"Line":0}},{"line":746,"address":[],"length":0,"stats":{"Line":0}},{"line":747,"address":[],"length":0,"stats":{"Line":0}},{"line":748,"address":[],"length":0,"stats":{"Line":0}},{"line":749,"address":[],"length":0,"stats":{"Line":0}},{"line":750,"address":[],"length":0,"stats":{"Line":0}},{"line":751,"address":[],"length":0,"stats":{"Line":0}},{"line":752,"address":[],"length":0,"stats":{"Line":0}},{"line":753,"address":[],"length":0,"stats":{"Line":0}},{"line":754,"address":[],"length":0,"stats":{"Line":0}},{"line":755,"address":[],"length":0,"stats":{"Line":0}},{"line":758,"address":[],"length":0,"stats":{"Line":0}},{"line":760,"address":[],"length":0,"stats":{"Line":0}},{"line":761,"address":[],"length":0,"stats":{"Line":0}},{"line":763,"address":[],"length":0,"stats":{"Line":0}},{"line":764,"address":[],"length":0,"stats":{"Line":0}},{"line":765,"address":[],"length":0,"stats":{"Line":0}},{"line":767,"address":[],"length":0,"stats":{"Line":0}},{"line":769,"address":[],"length":0,"stats":{"Line":0}},{"line":770,"address":[],"length":0,"stats":{"Line":0}},{"line":773,"address":[],"length":0,"stats":{"Line":0}},{"line":776,"address":[],"length":0,"stats":{"Line":0}},{"line":777,"address":[],"length":0,"stats":{"Line":0}},{"line":778,"address":[],"length":0,"stats":{"Line":0}},{"line":780,"address":[],"length":0,"stats":{"Line":0}},{"line":781,"address":[],"length":0,"stats":{"Line":0}},{"line":783,"address":[],"length":0,"stats":{"Line":0}},{"line":784,"address":[],"length":0,"stats":{"Line":0}},{"line":785,"address":[],"length":0,"stats":{"Line":0}},{"line":786,"address":[],"length":0,"stats":{"Line":0}},{"line":787,"address":[],"length":0,"stats":{"Line":0}},{"line":788,"address":[],"length":0,"stats":{"Line":0}},{"line":790,"address":[],"length":0,"stats":{"Line":0}},{"line":791,"address":[],"length":0,"stats":{"Line":0}},{"line":792,"address":[],"length":0,"stats":{"Line":0}},{"line":793,"address":[],"length":0,"stats":{"Line":0}},{"line":794,"address":[],"length":0,"stats":{"Line":0}},{"line":796,"address":[],"length":0,"stats":{"Line":0}},{"line":797,"address":[],"length":0,"stats":{"Line":0}},{"line":798,"address":[],"length":0,"stats":{"Line":0}},{"line":799,"address":[],"length":0,"stats":{"Line":0}},{"line":800,"address":[],"length":0,"stats":{"Line":0}},{"line":802,"address":[],"length":0,"stats":{"Line":0}},{"line":803,"address":[],"length":0,"stats":{"Line":0}},{"line":804,"address":[],"length":0,"stats":{"Line":0}},{"line":805,"address":[],"length":0,"stats":{"Line":0}},{"line":806,"address":[],"length":0,"stats":{"Line":0}},{"line":810,"address":[],"length":0,"stats":{"Line":0}},{"line":811,"address":[],"length":0,"stats":{"Line":0}},{"line":812,"address":[],"length":0,"stats":{"Line":0}},{"line":813,"address":[],"length":0,"stats":{"Line":0}},{"line":814,"address":[],"length":0,"stats":{"Line":0}},{"line":815,"address":[],"length":0,"stats":{"Line":0}},{"line":816,"address":[],"length":0,"stats":{"Line":0}},{"line":817,"address":[],"length":0,"stats":{"Line":0}},{"line":819,"address":[],"length":0,"stats":{"Line":0}},{"line":821,"address":[],"length":0,"stats":{"Line":0}},{"line":822,"address":[],"length":0,"stats":{"Line":0}},{"line":824,"address":[],"length":0,"stats":{"Line":0}},{"line":825,"address":[],"length":0,"stats":{"Line":0}},{"line":828,"address":[],"length":0,"stats":{"Line":0}},{"line":830,"address":[],"length":0,"stats":{"Line":0}},{"line":831,"address":[],"length":0,"stats":{"Line":0}},{"line":832,"address":[],"length":0,"stats":{"Line":0}},{"line":833,"address":[],"length":0,"stats":{"Line":0}},{"line":836,"address":[],"length":0,"stats":{"Line":0}},{"line":843,"address":[],"length":0,"stats":{"Line":0}},{"line":844,"address":[],"length":0,"stats":{"Line":0}},{"line":845,"address":[],"length":0,"stats":{"Line":0}},{"line":847,"address":[],"length":0,"stats":{"Line":0}},{"line":848,"address":[],"length":0,"stats":{"Line":0}},{"line":849,"address":[],"length":0,"stats":{"Line":0}},{"line":851,"address":[],"length":0,"stats":{"Line":0}},{"line":852,"address":[],"length":0,"stats":{"Line":0}},{"line":854,"address":[],"length":0,"stats":{"Line":0}},{"line":855,"address":[],"length":0,"stats":{"Line":0}},{"line":856,"address":[],"length":0,"stats":{"Line":0}},{"line":857,"address":[],"length":0,"stats":{"Line":0}},{"line":858,"address":[],"length":0,"stats":{"Line":0}},{"line":859,"address":[],"length":0,"stats":{"Line":0}},{"line":860,"address":[],"length":0,"stats":{"Line":0}},{"line":862,"address":[],"length":0,"stats":{"Line":0}},{"line":864,"address":[],"length":0,"stats":{"Line":0}},{"line":865,"address":[],"length":0,"stats":{"Line":0}},{"line":866,"address":[],"length":0,"stats":{"Line":0}},{"line":867,"address":[],"length":0,"stats":{"Line":0}},{"line":868,"address":[],"length":0,"stats":{"Line":0}},{"line":870,"address":[],"length":0,"stats":{"Line":0}},{"line":873,"address":[],"length":0,"stats":{"Line":0}},{"line":874,"address":[],"length":0,"stats":{"Line":0}},{"line":875,"address":[],"length":0,"stats":{"Line":0}},{"line":877,"address":[],"length":0,"stats":{"Line":0}},{"line":878,"address":[],"length":0,"stats":{"Line":0}},{"line":879,"address":[],"length":0,"stats":{"Line":0}},{"line":881,"address":[],"length":0,"stats":{"Line":0}},{"line":883,"address":[],"length":0,"stats":{"Line":0}},{"line":884,"address":[],"length":0,"stats":{"Line":0}},{"line":885,"address":[],"length":0,"stats":{"Line":0}},{"line":886,"address":[],"length":0,"stats":{"Line":0}},{"line":887,"address":[],"length":0,"stats":{"Line":0}},{"line":888,"address":[],"length":0,"stats":{"Line":0}},{"line":890,"address":[],"length":0,"stats":{"Line":0}},{"line":892,"address":[],"length":0,"stats":{"Line":0}},{"line":893,"address":[],"length":0,"stats":{"Line":0}},{"line":894,"address":[],"length":0,"stats":{"Line":0}},{"line":895,"address":[],"length":0,"stats":{"Line":0}},{"line":899,"address":[],"length":0,"stats":{"Line":0}},{"line":903,"address":[],"length":0,"stats":{"Line":0}},{"line":907,"address":[],"length":0,"stats":{"Line":0}},{"line":910,"address":[],"length":0,"stats":{"Line":0}},{"line":911,"address":[],"length":0,"stats":{"Line":0}},{"line":912,"address":[],"length":0,"stats":{"Line":0}},{"line":915,"address":[],"length":0,"stats":{"Line":0}},{"line":916,"address":[],"length":0,"stats":{"Line":0}},{"line":917,"address":[],"length":0,"stats":{"Line":0}},{"line":918,"address":[],"length":0,"stats":{"Line":0}},{"line":919,"address":[],"length":0,"stats":{"Line":0}},{"line":920,"address":[],"length":0,"stats":{"Line":0}},{"line":921,"address":[],"length":0,"stats":{"Line":0}},{"line":922,"address":[],"length":0,"stats":{"Line":0}},{"line":923,"address":[],"length":0,"stats":{"Line":0}},{"line":925,"address":[],"length":0,"stats":{"Line":0}},{"line":926,"address":[],"length":0,"stats":{"Line":0}},{"line":927,"address":[],"length":0,"stats":{"Line":0}},{"line":928,"address":[],"length":0,"stats":{"Line":0}},{"line":929,"address":[],"length":0,"stats":{"Line":0}},{"line":930,"address":[],"length":0,"stats":{"Line":0}},{"line":931,"address":[],"length":0,"stats":{"Line":0}},{"line":932,"address":[],"length":0,"stats":{"Line":0}},{"line":934,"address":[],"length":0,"stats":{"Line":0}},{"line":935,"address":[],"length":0,"stats":{"Line":0}},{"line":936,"address":[],"length":0,"stats":{"Line":0}},{"line":937,"address":[],"length":0,"stats":{"Line":0}},{"line":938,"address":[],"length":0,"stats":{"Line":0}},{"line":939,"address":[],"length":0,"stats":{"Line":0}},{"line":940,"address":[],"length":0,"stats":{"Line":0}},{"line":941,"address":[],"length":0,"stats":{"Line":0}},{"line":943,"address":[],"length":0,"stats":{"Line":0}},{"line":944,"address":[],"length":0,"stats":{"Line":0}},{"line":945,"address":[],"length":0,"stats":{"Line":0}},{"line":946,"address":[],"length":0,"stats":{"Line":0}},{"line":947,"address":[],"length":0,"stats":{"Line":0}},{"line":948,"address":[],"length":0,"stats":{"Line":0}},{"line":949,"address":[],"length":0,"stats":{"Line":0}},{"line":950,"address":[],"length":0,"stats":{"Line":0}},{"line":955,"address":[],"length":0,"stats":{"Line":0}},{"line":957,"address":[],"length":0,"stats":{"Line":0}},{"line":958,"address":[],"length":0,"stats":{"Line":0}},{"line":959,"address":[],"length":0,"stats":{"Line":0}},{"line":960,"address":[],"length":0,"stats":{"Line":0}},{"line":961,"address":[],"length":0,"stats":{"Line":0}},{"line":962,"address":[],"length":0,"stats":{"Line":0}},{"line":964,"address":[],"length":0,"stats":{"Line":0}},{"line":967,"address":[],"length":0,"stats":{"Line":0}},{"line":969,"address":[],"length":0,"stats":{"Line":0}},{"line":970,"address":[],"length":0,"stats":{"Line":0}},{"line":971,"address":[],"length":0,"stats":{"Line":0}},{"line":972,"address":[],"length":0,"stats":{"Line":0}},{"line":973,"address":[],"length":0,"stats":{"Line":0}},{"line":974,"address":[],"length":0,"stats":{"Line":0}},{"line":975,"address":[],"length":0,"stats":{"Line":0}},{"line":976,"address":[],"length":0,"stats":{"Line":0}},{"line":977,"address":[],"length":0,"stats":{"Line":0}},{"line":978,"address":[],"length":0,"stats":{"Line":0}},{"line":979,"address":[],"length":0,"stats":{"Line":0}},{"line":980,"address":[],"length":0,"stats":{"Line":0}},{"line":981,"address":[],"length":0,"stats":{"Line":0}},{"line":983,"address":[],"length":0,"stats":{"Line":0}},{"line":985,"address":[],"length":0,"stats":{"Line":0}},{"line":986,"address":[],"length":0,"stats":{"Line":0}},{"line":988,"address":[],"length":0,"stats":{"Line":0}},{"line":989,"address":[],"length":0,"stats":{"Line":0}},{"line":991,"address":[],"length":0,"stats":{"Line":0}},{"line":992,"address":[],"length":0,"stats":{"Line":0}},{"line":993,"address":[],"length":0,"stats":{"Line":0}},{"line":994,"address":[],"length":0,"stats":{"Line":0}},{"line":995,"address":[],"length":0,"stats":{"Line":0}},{"line":996,"address":[],"length":0,"stats":{"Line":0}},{"line":997,"address":[],"length":0,"stats":{"Line":0}},{"line":1000,"address":[],"length":0,"stats":{"Line":0}},{"line":1001,"address":[],"length":0,"stats":{"Line":0}},{"line":1004,"address":[],"length":0,"stats":{"Line":0}},{"line":1007,"address":[],"length":0,"stats":{"Line":0}},{"line":1008,"address":[],"length":0,"stats":{"Line":0}},{"line":1011,"address":[],"length":0,"stats":{"Line":0}},{"line":1015,"address":[],"length":0,"stats":{"Line":0}},{"line":1019,"address":[],"length":0,"stats":{"Line":0}},{"line":1020,"address":[],"length":0,"stats":{"Line":0}},{"line":1021,"address":[],"length":0,"stats":{"Line":0}},{"line":1022,"address":[],"length":0,"stats":{"Line":0}},{"line":1023,"address":[],"length":0,"stats":{"Line":0}},{"line":1024,"address":[],"length":0,"stats":{"Line":0}},{"line":1025,"address":[],"length":0,"stats":{"Line":0}},{"line":1026,"address":[],"length":0,"stats":{"Line":0}},{"line":1027,"address":[],"length":0,"stats":{"Line":0}},{"line":1028,"address":[],"length":0,"stats":{"Line":0}},{"line":1029,"address":[],"length":0,"stats":{"Line":0}},{"line":1030,"address":[],"length":0,"stats":{"Line":0}},{"line":1033,"address":[],"length":0,"stats":{"Line":0}},{"line":1034,"address":[],"length":0,"stats":{"Line":0}},{"line":1035,"address":[],"length":0,"stats":{"Line":0}},{"line":1037,"address":[],"length":0,"stats":{"Line":0}},{"line":1041,"address":[],"length":0,"stats":{"Line":0}},{"line":1042,"address":[],"length":0,"stats":{"Line":0}},{"line":1043,"address":[],"length":0,"stats":{"Line":0}},{"line":1044,"address":[],"length":0,"stats":{"Line":0}},{"line":1045,"address":[],"length":0,"stats":{"Line":0}},{"line":1046,"address":[],"length":0,"stats":{"Line":0}},{"line":1047,"address":[],"length":0,"stats":{"Line":0}},{"line":1048,"address":[],"length":0,"stats":{"Line":0}},{"line":1049,"address":[],"length":0,"stats":{"Line":0}},{"line":1050,"address":[],"length":0,"stats":{"Line":0}},{"line":1051,"address":[],"length":0,"stats":{"Line":0}},{"line":1055,"address":[],"length":0,"stats":{"Line":0}},{"line":1056,"address":[],"length":0,"stats":{"Line":0}},{"line":1057,"address":[],"length":0,"stats":{"Line":0}},{"line":1059,"address":[],"length":0,"stats":{"Line":0}},{"line":1064,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":563},{"path":["/","Users","christian.klat","dev","git","aeterna","cli","src","commands","hints.rs"],"content":"use anyhow::Result;\nuse clap::{Args, Subcommand};\nuse colored::Colorize;\nuse mk_core::hints::{HintPreset, OperationHints};\n\n#[derive(Subcommand)]\npub enum HintsCommand {\n    #[command(about = \"List available presets\")]\n    List(ListArgs),\n\n    #[command(about = \"Explain what a preset does\")]\n    Explain(ExplainArgs),\n\n    #[command(about = \"Parse a hints string and show resolved hints\")]\n    Parse(ParseArgs),\n}\n\n#[derive(Args)]\npub struct ListArgs {\n    #[arg(long, help = \"Output as JSON\")]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct ExplainArgs {\n    #[arg(help = \"Preset name (minimal, fast, standard, full, offline, agent)\")]\n    pub preset: String,\n\n    #[arg(long, help = \"Output as JSON\")]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct ParseArgs {\n    #[arg(help = \"Hints string to parse (e.g., 'fast,no-llm,verbose')\")]\n    pub hints: String,\n\n    #[arg(long, help = \"Output as JSON\")]\n    pub json: bool,\n}\n\npub fn run(cmd: HintsCommand) -> Result<()> {\n    match cmd {\n        HintsCommand::List(args) => list(args),\n        HintsCommand::Explain(args) => explain(args),\n        HintsCommand::Parse(args) => parse(args),\n    }\n}\n\nfn list(args: ListArgs) -> Result<()> {\n    let presets = [\n        (\n            \"minimal\",\n            \"No LLM, no reasoning - fastest, cheapest. For CI/CD, batch jobs.\",\n        ),\n        (\n            \"fast\",\n            \"LLM enabled, no reasoning - quick responses. For interactive use.\",\n        ),\n        (\n            \"standard\",\n            \"Full features enabled - balanced. Default for humans.\",\n        ),\n        (\n            \"full\",\n            \"Everything on including auto-promote - deep analysis, debugging.\",\n        ),\n        (\"offline\", \"No LLM, no external calls - disconnected work.\"),\n        (\n            \"agent\",\n            \"Optimized for AI agents - full reasoning, no verbose.\",\n        ),\n    ];\n\n    if args.json {\n        let output: Vec<_> = presets\n            .iter()\n            .map(|(name, desc)| serde_json::json!({\"name\": name, \"description\": desc}))\n            .collect();\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        return Ok(());\n    }\n\n    println!(\"{}\", \"Available Presets\".bold().underline());\n    println!();\n\n    for (name, desc) in presets {\n        println!(\"  {} - {}\", name.cyan().bold(), desc);\n    }\n\n    println!();\n    println!(\n        \"{}\",\n        \"Use 'aeterna hints explain <preset>' for detailed settings.\".dimmed()\n    );\n\n    Ok(())\n}\n\nfn explain(args: ExplainArgs) -> Result<()> {\n    let preset: HintPreset = args\n        .preset\n        .parse()\n        .map_err(|_| anyhow::anyhow!(\"Unknown preset: {}\", args.preset))?;\n\n    let hints = OperationHints::from_preset(preset);\n\n    if args.json {\n        let output = serde_json::json!({\n            \"preset\": args.preset,\n            \"reasoning\": hints.reasoning,\n            \"multi_hop\": hints.multi_hop,\n            \"summarization\": hints.summarization,\n            \"caching\": hints.caching,\n            \"governance\": hints.governance,\n            \"audit\": hints.audit,\n            \"llm\": hints.llm,\n            \"auto_promote\": hints.auto_promote,\n            \"drift_check\": hints.drift_check,\n            \"graph\": hints.graph,\n            \"cca\": hints.cca,\n            \"a2a\": hints.a2a,\n            \"verbose\": hints.verbose\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        return Ok(());\n    }\n\n    println!(\"{} {}\", \"Preset:\".bold(), args.preset.cyan().bold());\n    println!();\n\n    print_hint(\n        \"reasoning\",\n        hints.reasoning,\n        \"Enable reflective reasoning (MemR3)\",\n    );\n    print_hint(\"multi_hop\", hints.multi_hop, \"Enable multi-hop retrieval\");\n    print_hint(\n        \"summarization\",\n        hints.summarization,\n        \"Enable memory summarization\",\n    );\n    print_hint(\"caching\", hints.caching, \"Enable query result caching\");\n    print_hint(\"governance\", hints.governance, \"Enable policy enforcement\");\n    print_hint(\"audit\", hints.audit, \"Enable audit logging\");\n    print_hint(\"llm\", hints.llm, \"Enable LLM calls\");\n    print_hint(\n        \"auto_promote\",\n        hints.auto_promote,\n        \"Auto-promote high-reward memories\",\n    );\n    print_hint(\n        \"drift_check\",\n        hints.drift_check,\n        \"Check for knowledge drift\",\n    );\n    print_hint(\"graph\", hints.graph, \"Enable graph queries\");\n    print_hint(\"cca\", hints.cca, \"Enable CCA agents\");\n    print_hint(\"a2a\", hints.a2a, \"Enable A2A protocol\");\n    print_hint(\"verbose\", hints.verbose, \"Enable verbose output\");\n\n    Ok(())\n}\n\nfn parse(args: ParseArgs) -> Result<()> {\n    let hints = OperationHints::parse_hint_string(&args.hints);\n\n    if args.json {\n        let output = serde_json::json!({\n            \"input\": args.hints,\n            \"preset\": format!(\"{:?}\", hints.preset),\n            \"reasoning\": hints.reasoning,\n            \"multi_hop\": hints.multi_hop,\n            \"summarization\": hints.summarization,\n            \"caching\": hints.caching,\n            \"governance\": hints.governance,\n            \"audit\": hints.audit,\n            \"llm\": hints.llm,\n            \"auto_promote\": hints.auto_promote,\n            \"drift_check\": hints.drift_check,\n            \"graph\": hints.graph,\n            \"cca\": hints.cca,\n            \"a2a\": hints.a2a,\n            \"verbose\": hints.verbose\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        return Ok(());\n    }\n\n    println!(\"{} {}\", \"Parsed:\".bold(), args.hints.cyan());\n    println!();\n\n    print_hint(\"reasoning\", hints.reasoning, \"\");\n    print_hint(\"multi_hop\", hints.multi_hop, \"\");\n    print_hint(\"llm\", hints.llm, \"\");\n    print_hint(\"caching\", hints.caching, \"\");\n    print_hint(\"governance\", hints.governance, \"\");\n    print_hint(\"verbose\", hints.verbose, \"\");\n\n    Ok(())\n}\n\nfn print_hint(name: &str, enabled: bool, desc: &str) {\n    let status = if enabled { \"on\".green() } else { \"off\".red() };\n\n    if desc.is_empty() {\n        println!(\"  {:<14} {}\", format!(\"{name}:\"), status);\n    } else {\n        println!(\n            \"  {:<14} {} - {}\",\n            format!(\"{name}:\"),\n            status,\n            desc.dimmed()\n        );\n    }\n}\n","traces":[{"line":42,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":204,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":207,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":110},{"path":["/","Users","christian.klat","dev","git","aeterna","cli","src","commands","init.rs"],"content":"use std::fs;\nuse std::path::PathBuf;\n\nuse anyhow::{Context, Result};\nuse clap::Args;\nuse colored::Colorize;\nuse context::ContextResolver;\n\nuse crate::output;\n\n#[derive(Args)]\npub struct InitArgs {\n    #[arg(short, long, help = \"Directory to initialize (defaults to current)\")]\n    pub path: Option<PathBuf>,\n\n    #[arg(long, help = \"Tenant ID to use\")]\n    pub tenant_id: Option<String>,\n\n    #[arg(long, help = \"User ID (defaults to git user.email)\")]\n    pub user_id: Option<String>,\n\n    #[arg(long, help = \"Organization ID\")]\n    pub org_id: Option<String>,\n\n    #[arg(long, help = \"Team ID\")]\n    pub team_id: Option<String>,\n\n    #[arg(long, help = \"Project ID (defaults to git remote org/repo)\")]\n    pub project_id: Option<String>,\n\n    #[arg(long, help = \"Default hints preset\", default_value = \"standard\")]\n    pub preset: String,\n\n    #[arg(long, help = \"Force overwrite existing context.toml\")]\n    pub force: bool,\n\n    #[arg(long, help = \"Skip interactive prompts\")]\n    pub yes: bool,\n}\n\npub fn run(args: InitArgs) -> Result<()> {\n    let target_dir = args.path.unwrap_or_else(|| PathBuf::from(\".\"));\n    let aeterna_dir = target_dir.join(\".aeterna\");\n    let context_file = aeterna_dir.join(\"context.toml\");\n\n    if context_file.exists() && !args.force {\n        output::warn(&format!(\n            \"Context already exists at {}\",\n            context_file.display()\n        ));\n        output::info(\"Use --force to overwrite\");\n        return Ok(());\n    }\n\n    let resolver = ContextResolver::from_dir(&target_dir).skip_env();\n\n    let ctx = resolver.resolve()?;\n\n    let tenant_id = args\n        .tenant_id\n        .or_else(|| {\n            if ctx.tenant_id.value != \"default\" {\n                Some(ctx.tenant_id.value.clone())\n            } else {\n                None\n            }\n        })\n        .unwrap_or_else(|| \"default\".to_string());\n\n    let user_id = args.user_id.unwrap_or_else(|| ctx.user_id.value.clone());\n\n    let project_id = args\n        .project_id\n        .or_else(|| ctx.project_id.as_ref().map(|p| p.value.clone()));\n\n    let mut toml_content = String::new();\n    toml_content.push_str(&format!(\"tenant-id = \\\"{tenant_id}\\\"\\n\"));\n    toml_content.push_str(&format!(\"user-id = \\\"{user_id}\\\"\\n\"));\n\n    if let Some(org) = &args.org_id {\n        toml_content.push_str(&format!(\"org-id = \\\"{org}\\\"\\n\"));\n    }\n\n    if let Some(team) = &args.team_id {\n        toml_content.push_str(&format!(\"team-id = \\\"{team}\\\"\\n\"));\n    }\n\n    if let Some(project) = &project_id {\n        toml_content.push_str(&format!(\"project-id = \\\"{project}\\\"\\n\"));\n    }\n\n    toml_content.push_str(&format!(\n        r#\"\n[hints]\npreset = \"{}\"\n\"#,\n        args.preset\n    ));\n\n    fs::create_dir_all(&aeterna_dir)\n        .with_context(|| format!(\"Failed to create {}\", aeterna_dir.display()))?;\n\n    fs::write(&context_file, toml_content)\n        .with_context(|| format!(\"Failed to write {}\", context_file.display()))?;\n\n    println!(\n        \"{} Initialized Aeterna at {}\",\n        \"\".green().bold(),\n        aeterna_dir.display()\n    );\n\n    println!(\"\\n{}\", \"Resolved context:\".bold());\n    println!(\"  tenant_id:  {}\", tenant_id.cyan());\n    println!(\"  user_id:    {}\", user_id.cyan());\n    if let Some(project) = &project_id {\n        println!(\"  project_id: {}\", project.cyan());\n    }\n    println!(\"  preset:     {}\", args.preset.cyan());\n\n    println!(\n        \"\\n{}\",\n        \"Run 'aeterna status' to see the full resolved context.\".dimmed()\n    );\n\n    Ok(())\n}\n","traces":[{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":42,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":48,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":56},{"path":["/","Users","christian.klat","dev","git","aeterna","cli","src","commands","knowledge.rs"],"content":"use clap::{Args, Subcommand};\nuse context::ContextResolver;\nuse mk_core::hints::{HintPreset, OperationHints};\nuse serde_json::json;\n\nuse crate::output;\nuse crate::ux_error;\n\n#[derive(Subcommand)]\npub enum KnowledgeCommand {\n    #[command(about = \"Search knowledge across layers\")]\n    Search(KnowledgeSearchArgs),\n\n    #[command(about = \"Get a specific knowledge entry by path\")]\n    Get(KnowledgeGetArgs),\n\n    #[command(about = \"List knowledge entries in a layer\")]\n    List(KnowledgeListArgs),\n\n    #[command(about = \"Check knowledge constraints\")]\n    Check(KnowledgeCheckArgs),\n\n    #[command(about = \"Propose new knowledge (ADR, Pattern, Policy, Spec)\")]\n    Propose(KnowledgeProposeArgs),\n}\n\n#[derive(Args)]\npub struct KnowledgeSearchArgs {\n    /// Search query\n    pub query: String,\n\n    /// Maximum number of results (default: 10)\n    #[arg(short, long, default_value = \"10\")]\n    pub limit: usize,\n\n    /// Filter by layers (comma-separated: company, org, team, project)\n    #[arg(long)]\n    pub layers: Option<String>,\n\n    /// Hints preset (minimal, fast, standard, full, offline, agent)\n    #[arg(long)]\n    pub preset: Option<String>,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n\n    /// Show verbose output\n    #[arg(short, long)]\n    pub verbose: bool,\n\n    /// Dry run - don't actually search, just show what would happen\n    #[arg(long)]\n    pub dry_run: bool,\n}\n\n#[derive(Args)]\npub struct KnowledgeGetArgs {\n    /// Path to the knowledge entry (e.g., \"adrs/adr-001.md\")\n    pub path: String,\n\n    /// Layer to get from (company, org, team, project)\n    #[arg(short, long, default_value = \"project\")]\n    pub layer: String,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct KnowledgeListArgs {\n    /// Layer to list from (company, org, team, project)\n    #[arg(short, long, default_value = \"project\")]\n    pub layer: String,\n\n    /// Filter by path prefix\n    #[arg(long)]\n    pub prefix: Option<String>,\n\n    /// Maximum number of results\n    #[arg(short = 'n', long, default_value = \"20\")]\n    pub limit: usize,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct KnowledgeCheckArgs {\n    /// Context to check (e.g., a file path, dependency, etc.)\n    #[arg(short, long)]\n    pub context: Option<String>,\n\n    /// Check against a specific policy\n    #[arg(long)]\n    pub policy: Option<String>,\n\n    /// Check for a specific dependency\n    #[arg(long)]\n    pub dependency: Option<String>,\n\n    /// Hints preset\n    #[arg(long)]\n    pub preset: Option<String>,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n\n    /// Dry run\n    #[arg(long)]\n    pub dry_run: bool,\n}\n\n#[derive(Args)]\npub struct KnowledgeProposeArgs {\n    /// Natural language description of what you want to propose\n    pub description: String,\n\n    /// Knowledge type (adr, pattern, policy, spec) - auto-detected if not specified\n    #[arg(short = 't', long)]\n    pub knowledge_type: Option<String>,\n\n    /// Target layer (company, org, team, project) - inferred from description if not specified\n    #[arg(short, long)]\n    pub layer: Option<String>,\n\n    /// Custom title (auto-generated from description if not specified)\n    #[arg(long)]\n    pub title: Option<String>,\n\n    /// Submit directly for approval (skip draft review)\n    #[arg(long)]\n    pub submit: bool,\n\n    /// Skip confirmation prompt\n    #[arg(short, long)]\n    pub yes: bool,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n\n    /// Dry run - show what would be proposed without creating draft\n    #[arg(long)]\n    pub dry_run: bool,\n}\n\npub async fn run(cmd: KnowledgeCommand) -> anyhow::Result<()> {\n    match cmd {\n        KnowledgeCommand::Search(args) => run_search(args).await,\n        KnowledgeCommand::Get(args) => run_get(args).await,\n        KnowledgeCommand::List(args) => run_list(args).await,\n        KnowledgeCommand::Check(args) => run_check(args).await,\n        KnowledgeCommand::Propose(args) => run_propose(args).await,\n    }\n}\n\nasync fn run_search(args: KnowledgeSearchArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    let base_hints = if let Some(preset_str) = &args.preset {\n        let preset: HintPreset = preset_str.parse().map_err(|_| {\n            let err = ux_error::invalid_preset(preset_str);\n            err.display();\n            anyhow::anyhow!(\"Invalid preset\")\n        })?;\n        OperationHints::from_preset(preset)\n    } else {\n        resolved.to_hints()\n    };\n\n    let layers: Vec<String> = args\n        .layers\n        .map(|l| l.split(',').map(|s| s.trim().to_lowercase()).collect())\n        .unwrap_or_else(|| {\n            vec![\n                \"project\".to_string(),\n                \"team\".to_string(),\n                \"org\".to_string(),\n                \"company\".to_string(),\n            ]\n        });\n\n    let valid_layers = [\"company\", \"org\", \"team\", \"project\"];\n    for layer in &layers {\n        if !valid_layers.contains(&layer.as_str()) {\n            let err = ux_error::invalid_knowledge_layer(layer);\n            err.display();\n            return Err(anyhow::anyhow!(\"Invalid layer\"));\n        }\n    }\n\n    if args.dry_run || args.verbose {\n        if args.json {\n            let output = json!({\n                \"dryRun\": true,\n                \"operation\": \"knowledge_search\",\n                \"query\": args.query,\n                \"limit\": args.limit,\n                \"layers\": layers,\n                \"context\": {\n                    \"tenantId\": resolved.tenant_id.value,\n                    \"userId\": resolved.user_id.value,\n                    \"projectId\": resolved.project_id.as_ref().map(|v| &v.value),\n                },\n                \"hints\": {\n                    \"preset\": format!(\"{}\", base_hints.preset),\n                    \"reasoning\": base_hints.reasoning,\n                    \"multiHop\": base_hints.multi_hop,\n                    \"llm\": base_hints.llm,\n                    \"graph\": base_hints.graph,\n                }\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Knowledge Search (Dry Run)\");\n            println!();\n            println!(\"  Query:  {}\", args.query);\n            println!(\"  Limit:  {}\", args.limit);\n            println!(\"  Layers: {}\", layers.join(\", \"));\n            println!();\n            output::header(\"Context\");\n            println!(\"  tenant_id:  {}\", resolved.tenant_id.value);\n            println!(\"  user_id:    {}\", resolved.user_id.value);\n            if let Some(project) = &resolved.project_id {\n                println!(\"  project_id: {}\", project.value);\n            }\n            println!();\n            output::header(\"Active Hints\");\n            println!(\"  preset:    {}\", base_hints.preset);\n            println!(\n                \"  reasoning: {} {}\",\n                if base_hints.reasoning { \"on\" } else { \"off\" },\n                hint_effect(base_hints.reasoning, \"will use semantic reasoning\")\n            );\n            println!(\n                \"  llm:       {} {}\",\n                if base_hints.llm { \"on\" } else { \"off\" },\n                hint_effect(base_hints.llm, \"will use LLM for semantic search\")\n            );\n            println!(\n                \"  graph:     {} {}\",\n                if base_hints.graph { \"on\" } else { \"off\" },\n                hint_effect(base_hints.graph, \"will query knowledge graph\")\n            );\n            println!();\n            output::header(\"Search Scope\");\n            println!(\"  Knowledge is searched in precedence order:\");\n            for (i, layer) in layers.iter().enumerate() {\n                let desc = match layer.as_str() {\n                    \"project\" => \"Project-specific knowledge (ADRs, patterns)\",\n                    \"team\" => \"Team standards and conventions\",\n                    \"org\" => \"Organization-wide policies\",\n                    \"company\" => \"Company global standards\",\n                    _ => \"\",\n                };\n                println!(\"    {}. {} - {}\", i + 1, layer, desc);\n            }\n            println!();\n\n            if args.dry_run {\n                output::info(\"Dry run mode - no actual search performed.\");\n                output::info(\"Remove --dry-run to execute the search.\");\n            }\n        }\n        return Ok(());\n    }\n\n    let err = ux_error::server_not_connected();\n    err.display();\n    output::info(\"Run with --dry-run to see what would happen.\");\n\n    Ok(())\n}\n\nasync fn run_get(args: KnowledgeGetArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    let layer = args.layer.to_lowercase();\n    let valid_layers = [\"company\", \"org\", \"team\", \"project\"];\n    if !valid_layers.contains(&layer.as_str()) {\n        let err = ux_error::invalid_knowledge_layer(&layer);\n        err.display();\n        return Err(anyhow::anyhow!(\"Invalid layer\"));\n    }\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"knowledge_get\",\n            \"path\": args.path,\n            \"layer\": layer,\n            \"context\": {\n                \"tenantId\": resolved.tenant_id.value,\n                \"userId\": resolved.user_id.value,\n                \"projectId\": resolved.project_id.as_ref().map(|v| &v.value),\n            },\n            \"status\": \"not_connected\",\n            \"message\": \"Knowledge repository not connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(&format!(\"Knowledge: {} ({})\", args.path, layer));\n        println!();\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nasync fn run_list(args: KnowledgeListArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    let layer = args.layer.to_lowercase();\n    let valid_layers = [\"company\", \"org\", \"team\", \"project\"];\n    if !valid_layers.contains(&layer.as_str()) {\n        let err = ux_error::invalid_knowledge_layer(&layer);\n        err.display();\n        return Err(anyhow::anyhow!(\"Invalid layer\"));\n    }\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"knowledge_list\",\n            \"layer\": layer,\n            \"prefix\": args.prefix,\n            \"limit\": args.limit,\n            \"context\": {\n                \"tenantId\": resolved.tenant_id.value,\n                \"userId\": resolved.user_id.value,\n                \"projectId\": resolved.project_id.as_ref().map(|v| &v.value),\n            },\n            \"status\": \"not_connected\",\n            \"message\": \"Knowledge repository not connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(&format!(\"Knowledge in '{}' layer\", layer));\n        if let Some(prefix) = &args.prefix {\n            println!(\"  Prefix: {}\", prefix);\n        }\n        println!();\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nasync fn run_check(args: KnowledgeCheckArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    let base_hints = if let Some(preset_str) = &args.preset {\n        let preset: HintPreset = preset_str.parse().map_err(|_| {\n            let err = ux_error::invalid_preset(preset_str);\n            err.display();\n            anyhow::anyhow!(\"Invalid preset\")\n        })?;\n        OperationHints::from_preset(preset)\n    } else {\n        resolved.to_hints()\n    };\n\n    if args.dry_run {\n        if args.json {\n            let output = json!({\n                \"dryRun\": true,\n                \"operation\": \"knowledge_check\",\n                \"context\": args.context,\n                \"policy\": args.policy,\n                \"dependency\": args.dependency,\n                \"tenantContext\": {\n                    \"tenantId\": resolved.tenant_id.value,\n                    \"userId\": resolved.user_id.value,\n                    \"projectId\": resolved.project_id.as_ref().map(|v| &v.value),\n                },\n                \"hints\": {\n                    \"preset\": format!(\"{}\", base_hints.preset),\n                    \"governance\": base_hints.governance,\n                }\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Knowledge Check (Dry Run)\");\n            println!();\n            if let Some(ctx) = &args.context {\n                println!(\"  Context:    {}\", ctx);\n            }\n            if let Some(policy) = &args.policy {\n                println!(\"  Policy:     {}\", policy);\n            }\n            if let Some(dep) = &args.dependency {\n                println!(\"  Dependency: {}\", dep);\n            }\n            println!();\n            output::header(\"What Would Be Checked\");\n            println!(\"  1. Constraint rules from inherited policies\");\n            println!(\"  2. Dependency blocklists (security, licensing)\");\n            println!(\"  3. Pattern requirements (code style, architecture)\");\n            println!();\n            println!(\n                \"  governance: {} {}\",\n                if base_hints.governance { \"on\" } else { \"off\" },\n                hint_effect(base_hints.governance, \"will enforce policies\")\n            );\n            println!();\n            output::info(\"Dry run mode - no actual check performed.\");\n            output::info(\"Remove --dry-run to execute the constraint check.\");\n        }\n        return Ok(());\n    }\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"knowledge_check\",\n            \"context\": args.context,\n            \"policy\": args.policy,\n            \"dependency\": args.dependency,\n            \"status\": \"not_connected\",\n            \"message\": \"Knowledge repository not connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(\"Knowledge Check\");\n        println!();\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nfn hint_effect(enabled: bool, effect: &str) -> String {\n    if enabled {\n        format!(\"({})\", effect)\n    } else {\n        String::new()\n    }\n}\n\nasync fn run_propose(args: KnowledgeProposeArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    let valid_types = [\"adr\", \"pattern\", \"policy\", \"spec\"];\n    let valid_layers = [\"company\", \"org\", \"team\", \"project\"];\n\n    if let Some(ref kt) = args.knowledge_type {\n        let kt_lower = kt.to_lowercase();\n        if !valid_types.contains(&kt_lower.as_str()) {\n            let err = ux_error::invalid_knowledge_type(&kt_lower, &valid_types);\n            err.display();\n            return Err(anyhow::anyhow!(\"Invalid knowledge type\"));\n        }\n    }\n\n    if let Some(ref layer) = args.layer {\n        let layer_lower = layer.to_lowercase();\n        if !valid_layers.contains(&layer_lower.as_str()) {\n            let err = ux_error::invalid_knowledge_layer(&layer_lower);\n            err.display();\n            return Err(anyhow::anyhow!(\"Invalid layer\"));\n        }\n    }\n\n    let detected_type = detect_knowledge_type(&args.description);\n    let detected_layer = detect_knowledge_layer(&args.description);\n    let knowledge_type = args\n        .knowledge_type\n        .as_ref()\n        .map(|s| s.to_lowercase())\n        .unwrap_or_else(|| detected_type.clone());\n    let layer = args\n        .layer\n        .as_ref()\n        .map(|s| s.to_lowercase())\n        .unwrap_or_else(|| detected_layer.clone());\n    let title = args\n        .title\n        .clone()\n        .unwrap_or_else(|| extract_title(&args.description));\n\n    if args.dry_run {\n        if args.json {\n            let output = json!({\n                \"dryRun\": true,\n                \"operation\": \"knowledge_propose\",\n                \"description\": args.description,\n                \"detectedType\": detected_type,\n                \"detectedLayer\": detected_layer,\n                \"effectiveType\": knowledge_type,\n                \"effectiveLayer\": layer,\n                \"title\": title,\n                \"submit\": args.submit,\n                \"context\": {\n                    \"tenantId\": resolved.tenant_id.value,\n                    \"userId\": resolved.user_id.value,\n                    \"projectId\": resolved.project_id.as_ref().map(|v| &v.value),\n                },\n                \"governanceRequired\": true,\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Knowledge Propose (Dry Run)\");\n            println!();\n            println!(\"  Description: {}\", truncate(&args.description, 60));\n            println!();\n            output::header(\"Auto-Detection\");\n            println!(\n                \"  Type:  {} {}\",\n                detected_type,\n                if args.knowledge_type.is_some() {\n                    format!(\"(overridden to {})\", knowledge_type)\n                } else {\n                    \"(auto-detected)\".to_string()\n                }\n            );\n            println!(\n                \"  Layer: {} {}\",\n                detected_layer,\n                if args.layer.is_some() {\n                    format!(\"(overridden to {})\", layer)\n                } else {\n                    \"(auto-detected)\".to_string()\n                }\n            );\n            println!(\"  Title: {}\", title);\n            println!();\n            output::header(\"Context\");\n            println!(\"  tenant_id:  {}\", resolved.tenant_id.value);\n            println!(\"  user_id:    {}\", resolved.user_id.value);\n            if let Some(project) = &resolved.project_id {\n                println!(\"  project_id: {}\", project.value);\n            }\n            println!();\n            output::header(\"What Would Happen\");\n            println!(\"  1. Create a {} draft in {} layer\", knowledge_type, layer);\n            println!(\"  2. Generate structured content from description\");\n            if args.submit {\n                println!(\"  3. Submit directly for governance approval\");\n            } else {\n                println!(\"  3. Save as draft for review before submission\");\n            }\n            println!();\n            output::info(\"Dry run mode - no draft created.\");\n            output::info(\"Remove --dry-run to create the proposal.\");\n        }\n        return Ok(());\n    }\n\n    if !args.yes && !args.dry_run {\n        output::warn(&format!(\n            \"This will create a {} proposal in {} layer:\",\n            knowledge_type, layer\n        ));\n        println!(\"  Title: {}\", title);\n        println!(\"  Type:  {}\", knowledge_type);\n        println!(\"  Layer: {}\", layer);\n        if args.submit {\n            output::info(\"The proposal will be submitted directly for approval.\");\n        } else {\n            output::info(\"The proposal will be saved as a draft for review.\");\n        }\n        output::info(\"Use --yes to skip this confirmation.\");\n        return Ok(());\n    }\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"knowledge_propose\",\n            \"description\": args.description,\n            \"type\": knowledge_type,\n            \"layer\": layer,\n            \"title\": title,\n            \"submit\": args.submit,\n            \"status\": \"not_connected\",\n            \"message\": \"Knowledge repository not connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(\"Knowledge Propose\");\n        println!();\n        println!(\"  Title: {}\", title);\n        println!(\"  Type:  {}\", knowledge_type);\n        println!(\"  Layer: {}\", layer);\n        println!();\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nfn detect_knowledge_type(description: &str) -> String {\n    let lower = description.to_lowercase();\n\n    if lower.contains(\"decision\")\n        || lower.contains(\"adr\")\n        || lower.contains(\"architecture\")\n        || lower.contains(\"chose\")\n        || lower.contains(\"decided\")\n    {\n        return \"adr\".to_string();\n    }\n\n    if lower.contains(\"policy\")\n        || lower.contains(\"rule\")\n        || lower.contains(\"must\")\n        || lower.contains(\"require\")\n        || lower.contains(\"enforce\")\n        || lower.contains(\"block\")\n        || lower.contains(\"forbid\")\n    {\n        return \"policy\".to_string();\n    }\n\n    if lower.contains(\"pattern\")\n        || lower.contains(\"approach\")\n        || lower.contains(\"best practice\")\n        || lower.contains(\"how to\")\n        || lower.contains(\"guideline\")\n    {\n        return \"pattern\".to_string();\n    }\n\n    if lower.contains(\"spec\")\n        || lower.contains(\"specification\")\n        || lower.contains(\"requirement\")\n        || lower.contains(\"shall\")\n    {\n        return \"spec\".to_string();\n    }\n\n    \"adr\".to_string()\n}\n\nfn detect_knowledge_layer(description: &str) -> String {\n    let lower = description.to_lowercase();\n\n    if lower.contains(\"company\")\n        || lower.contains(\"enterprise\")\n        || lower.contains(\"global\")\n        || lower.contains(\"all teams\")\n        || lower.contains(\"organization-wide\")\n    {\n        return \"company\".to_string();\n    }\n\n    if lower.contains(\"org\")\n        || lower.contains(\"department\")\n        || lower.contains(\"division\")\n        || lower.contains(\"business unit\")\n    {\n        return \"org\".to_string();\n    }\n\n    if lower.contains(\"team\")\n        || lower.contains(\"squad\")\n        || lower.contains(\"group\")\n        || lower.contains(\"our team\")\n    {\n        return \"team\".to_string();\n    }\n\n    \"project\".to_string()\n}\n\nfn extract_title(description: &str) -> String {\n    let first_sentence = description.split('.').next().unwrap_or(description);\n    let cleaned = first_sentence.trim();\n    if cleaned.len() > 60 {\n        format!(\"{}...\", &cleaned[..57])\n    } else {\n        cleaned.to_string()\n    }\n}\n\nfn truncate(s: &str, max_len: usize) -> String {\n    if s.len() > max_len {\n        format!(\"{}...\", &s[..max_len - 3])\n    } else {\n        s.to_string()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_hint_effect_enabled() {\n        let result = hint_effect(true, \"will use semantic reasoning\");\n        assert_eq!(result, \"(will use semantic reasoning)\");\n    }\n\n    #[test]\n    fn test_hint_effect_disabled() {\n        let result = hint_effect(false, \"will use semantic reasoning\");\n        assert_eq!(result, \"\");\n    }\n\n    #[test]\n    fn test_truncate_short_string() {\n        let result = truncate(\"hello\", 10);\n        assert_eq!(result, \"hello\");\n    }\n\n    #[test]\n    fn test_truncate_exact_length() {\n        let result = truncate(\"hello\", 5);\n        assert_eq!(result, \"hello\");\n    }\n\n    #[test]\n    fn test_truncate_long_string() {\n        let result = truncate(\"hello world this is a long string\", 20);\n        assert_eq!(result, \"hello world this ...\");\n        assert_eq!(result.len(), 20);\n    }\n\n    #[test]\n    fn test_extract_title_short() {\n        let result = extract_title(\"Use PostgreSQL for databases\");\n        assert_eq!(result, \"Use PostgreSQL for databases\");\n    }\n\n    #[test]\n    fn test_extract_title_with_period() {\n        let result = extract_title(\"Use PostgreSQL. It has good performance.\");\n        assert_eq!(result, \"Use PostgreSQL\");\n    }\n\n    #[test]\n    fn test_extract_title_long() {\n        let long_text = \"This is a very long description that should be truncated to fit within the title limit\";\n        let result = extract_title(long_text);\n        assert!(result.len() <= 60);\n        assert!(result.ends_with(\"...\"));\n    }\n\n    #[test]\n    fn test_extract_title_empty() {\n        let result = extract_title(\"\");\n        assert_eq!(result, \"\");\n    }\n\n    #[test]\n    fn test_detect_knowledge_type_adr() {\n        assert_eq!(detect_knowledge_type(\"We decided to use PostgreSQL\"), \"adr\");\n        assert_eq!(\n            detect_knowledge_type(\"Architecture decision for API\"),\n            \"adr\"\n        );\n        assert_eq!(detect_knowledge_type(\"ADR: Database selection\"), \"adr\");\n        assert_eq!(detect_knowledge_type(\"We chose React for frontend\"), \"adr\");\n    }\n\n    #[test]\n    fn test_detect_knowledge_type_policy() {\n        assert_eq!(\n            detect_knowledge_type(\"All services must use HTTPS\"),\n            \"policy\"\n        );\n        assert_eq!(\n            detect_knowledge_type(\"Policy: No direct database access\"),\n            \"policy\"\n        );\n        assert_eq!(\n            detect_knowledge_type(\"Require code review before merge\"),\n            \"policy\"\n        );\n        assert_eq!(\n            detect_knowledge_type(\"Block dependencies with CVEs\"),\n            \"policy\"\n        );\n        assert_eq!(detect_knowledge_type(\"Enforce 80% test coverage\"), \"policy\");\n        assert_eq!(detect_knowledge_type(\"Forbid global state\"), \"policy\");\n    }\n\n    #[test]\n    fn test_detect_knowledge_type_pattern() {\n        assert_eq!(\n            detect_knowledge_type(\"Pattern: Repository abstraction\"),\n            \"pattern\"\n        );\n        assert_eq!(\n            detect_knowledge_type(\"Best practice for logging\"),\n            \"pattern\"\n        );\n        assert_eq!(\n            detect_knowledge_type(\"Approach for error handling\"),\n            \"pattern\"\n        );\n        assert_eq!(detect_knowledge_type(\"How to implement caching\"), \"pattern\");\n        assert_eq!(\n            detect_knowledge_type(\"Guideline for API versioning\"),\n            \"pattern\"\n        );\n    }\n\n    #[test]\n    fn test_detect_knowledge_type_spec() {\n        assert_eq!(detect_knowledge_type(\"Spec for API endpoints\"), \"spec\");\n        assert_eq!(\n            detect_knowledge_type(\"The system shall support 1000 users\"),\n            \"spec\"\n        );\n    }\n\n    #[test]\n    fn test_detect_knowledge_type_default() {\n        assert_eq!(detect_knowledge_type(\"Random text without keywords\"), \"adr\");\n    }\n\n    #[test]\n    fn test_detect_knowledge_layer_company() {\n        assert_eq!(\n            detect_knowledge_layer(\"Company-wide security policy\"),\n            \"company\"\n        );\n        assert_eq!(\n            detect_knowledge_layer(\"Enterprise standard for APIs\"),\n            \"company\"\n        );\n        assert_eq!(detect_knowledge_layer(\"Global logging format\"), \"company\");\n        assert_eq!(detect_knowledge_layer(\"Apply to all teams\"), \"company\");\n        assert_eq!(\n            detect_knowledge_layer(\"Organization-wide code style\"),\n            \"company\"\n        );\n    }\n\n    #[test]\n    fn test_detect_knowledge_layer_org() {\n        assert_eq!(detect_knowledge_layer(\"Org level guidelines\"), \"org\");\n        assert_eq!(detect_knowledge_layer(\"Department standard\"), \"org\");\n        assert_eq!(detect_knowledge_layer(\"Division policy\"), \"org\");\n        assert_eq!(detect_knowledge_layer(\"Business unit convention\"), \"org\");\n    }\n\n    #[test]\n    fn test_detect_knowledge_layer_team() {\n        assert_eq!(detect_knowledge_layer(\"Team coding convention\"), \"team\");\n        assert_eq!(detect_knowledge_layer(\"Squad best practices\"), \"team\");\n        assert_eq!(detect_knowledge_layer(\"Our team uses Rust\"), \"team\");\n        assert_eq!(detect_knowledge_layer(\"Group decision on testing\"), \"team\");\n    }\n\n    #[test]\n    fn test_detect_knowledge_layer_default() {\n        assert_eq!(detect_knowledge_layer(\"Random text\"), \"project\");\n        assert_eq!(\n            detect_knowledge_layer(\"Use PostgreSQL for this service\"),\n            \"project\"\n        );\n    }\n}\n","traces":[{"line":151,"address":[],"length":0,"stats":{"Line":2}},{"line":152,"address":[],"length":0,"stats":{"Line":1}},{"line":153,"address":[],"length":0,"stats":{"Line":3}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":2}},{"line":162,"address":[],"length":0,"stats":{"Line":2}},{"line":163,"address":[],"length":0,"stats":{"Line":3}},{"line":165,"address":[],"length":0,"stats":{"Line":2}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":2}},{"line":176,"address":[],"length":0,"stats":{"Line":3}},{"line":177,"address":[],"length":0,"stats":{"Line":1}},{"line":178,"address":[],"length":0,"stats":{"Line":1}},{"line":179,"address":[],"length":0,"stats":{"Line":2}},{"line":180,"address":[],"length":0,"stats":{"Line":1}},{"line":181,"address":[],"length":0,"stats":{"Line":2}},{"line":182,"address":[],"length":0,"stats":{"Line":2}},{"line":183,"address":[],"length":0,"stats":{"Line":2}},{"line":184,"address":[],"length":0,"stats":{"Line":2}},{"line":188,"address":[],"length":0,"stats":{"Line":3}},{"line":189,"address":[],"length":0,"stats":{"Line":9}},{"line":190,"address":[],"length":0,"stats":{"Line":12}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":1}},{"line":198,"address":[],"length":0,"stats":{"Line":1}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":201,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":204,"address":[],"length":0,"stats":{"Line":0}},{"line":205,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":207,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":2}},{"line":221,"address":[],"length":0,"stats":{"Line":1}},{"line":222,"address":[],"length":0,"stats":{"Line":2}},{"line":223,"address":[],"length":0,"stats":{"Line":2}},{"line":224,"address":[],"length":0,"stats":{"Line":4}},{"line":225,"address":[],"length":0,"stats":{"Line":1}},{"line":226,"address":[],"length":0,"stats":{"Line":2}},{"line":227,"address":[],"length":0,"stats":{"Line":2}},{"line":228,"address":[],"length":0,"stats":{"Line":2}},{"line":229,"address":[],"length":0,"stats":{"Line":3}},{"line":230,"address":[],"length":0,"stats":{"Line":1}},{"line":232,"address":[],"length":0,"stats":{"Line":1}},{"line":233,"address":[],"length":0,"stats":{"Line":2}},{"line":234,"address":[],"length":0,"stats":{"Line":2}},{"line":235,"address":[],"length":0,"stats":{"Line":1}},{"line":236,"address":[],"length":0,"stats":{"Line":1}},{"line":237,"address":[],"length":0,"stats":{"Line":2}},{"line":238,"address":[],"length":0,"stats":{"Line":3}},{"line":240,"address":[],"length":0,"stats":{"Line":1}},{"line":241,"address":[],"length":0,"stats":{"Line":1}},{"line":242,"address":[],"length":0,"stats":{"Line":2}},{"line":243,"address":[],"length":0,"stats":{"Line":3}},{"line":245,"address":[],"length":0,"stats":{"Line":1}},{"line":246,"address":[],"length":0,"stats":{"Line":1}},{"line":247,"address":[],"length":0,"stats":{"Line":2}},{"line":248,"address":[],"length":0,"stats":{"Line":3}},{"line":250,"address":[],"length":0,"stats":{"Line":1}},{"line":251,"address":[],"length":0,"stats":{"Line":2}},{"line":252,"address":[],"length":0,"stats":{"Line":2}},{"line":253,"address":[],"length":0,"stats":{"Line":10}},{"line":254,"address":[],"length":0,"stats":{"Line":8}},{"line":255,"address":[],"length":0,"stats":{"Line":5}},{"line":256,"address":[],"length":0,"stats":{"Line":4}},{"line":257,"address":[],"length":0,"stats":{"Line":3}},{"line":258,"address":[],"length":0,"stats":{"Line":2}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":12}},{"line":263,"address":[],"length":0,"stats":{"Line":1}},{"line":265,"address":[],"length":0,"stats":{"Line":2}},{"line":266,"address":[],"length":0,"stats":{"Line":3}},{"line":267,"address":[],"length":0,"stats":{"Line":1}},{"line":270,"address":[],"length":0,"stats":{"Line":1}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":274,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":284,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":298,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":0}},{"line":321,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":0}},{"line":323,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":325,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":333,"address":[],"length":0,"stats":{"Line":0}},{"line":334,"address":[],"length":0,"stats":{"Line":0}},{"line":335,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":337,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":342,"address":[],"length":0,"stats":{"Line":0}},{"line":344,"address":[],"length":0,"stats":{"Line":0}},{"line":345,"address":[],"length":0,"stats":{"Line":0}},{"line":346,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":0}},{"line":350,"address":[],"length":0,"stats":{"Line":0}},{"line":353,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":358,"address":[],"length":0,"stats":{"Line":0}},{"line":360,"address":[],"length":0,"stats":{"Line":0}},{"line":361,"address":[],"length":0,"stats":{"Line":0}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":363,"address":[],"length":0,"stats":{"Line":0}},{"line":364,"address":[],"length":0,"stats":{"Line":0}},{"line":366,"address":[],"length":0,"stats":{"Line":0}},{"line":368,"address":[],"length":0,"stats":{"Line":0}},{"line":371,"address":[],"length":0,"stats":{"Line":0}},{"line":372,"address":[],"length":0,"stats":{"Line":0}},{"line":373,"address":[],"length":0,"stats":{"Line":0}},{"line":374,"address":[],"length":0,"stats":{"Line":0}},{"line":375,"address":[],"length":0,"stats":{"Line":0}},{"line":376,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":378,"address":[],"length":0,"stats":{"Line":0}},{"line":379,"address":[],"length":0,"stats":{"Line":0}},{"line":380,"address":[],"length":0,"stats":{"Line":0}},{"line":381,"address":[],"length":0,"stats":{"Line":0}},{"line":382,"address":[],"length":0,"stats":{"Line":0}},{"line":384,"address":[],"length":0,"stats":{"Line":0}},{"line":385,"address":[],"length":0,"stats":{"Line":0}},{"line":386,"address":[],"length":0,"stats":{"Line":0}},{"line":389,"address":[],"length":0,"stats":{"Line":0}},{"line":391,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":0}},{"line":393,"address":[],"length":0,"stats":{"Line":0}},{"line":394,"address":[],"length":0,"stats":{"Line":0}},{"line":396,"address":[],"length":0,"stats":{"Line":0}},{"line":397,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":400,"address":[],"length":0,"stats":{"Line":0}},{"line":402,"address":[],"length":0,"stats":{"Line":0}},{"line":403,"address":[],"length":0,"stats":{"Line":0}},{"line":404,"address":[],"length":0,"stats":{"Line":0}},{"line":405,"address":[],"length":0,"stats":{"Line":0}},{"line":406,"address":[],"length":0,"stats":{"Line":0}},{"line":407,"address":[],"length":0,"stats":{"Line":0}},{"line":408,"address":[],"length":0,"stats":{"Line":0}},{"line":409,"address":[],"length":0,"stats":{"Line":0}},{"line":410,"address":[],"length":0,"stats":{"Line":0}},{"line":411,"address":[],"length":0,"stats":{"Line":0}},{"line":413,"address":[],"length":0,"stats":{"Line":0}},{"line":414,"address":[],"length":0,"stats":{"Line":0}},{"line":415,"address":[],"length":0,"stats":{"Line":0}},{"line":417,"address":[],"length":0,"stats":{"Line":0}},{"line":420,"address":[],"length":0,"stats":{"Line":0}},{"line":421,"address":[],"length":0,"stats":{"Line":0}},{"line":422,"address":[],"length":0,"stats":{"Line":0}},{"line":423,"address":[],"length":0,"stats":{"Line":0}},{"line":424,"address":[],"length":0,"stats":{"Line":0}},{"line":425,"address":[],"length":0,"stats":{"Line":0}},{"line":426,"address":[],"length":0,"stats":{"Line":0}},{"line":427,"address":[],"length":0,"stats":{"Line":0}},{"line":429,"address":[],"length":0,"stats":{"Line":0}},{"line":431,"address":[],"length":0,"stats":{"Line":0}},{"line":432,"address":[],"length":0,"stats":{"Line":0}},{"line":433,"address":[],"length":0,"stats":{"Line":0}},{"line":434,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":5}},{"line":441,"address":[],"length":0,"stats":{"Line":5}},{"line":442,"address":[],"length":0,"stats":{"Line":8}},{"line":444,"address":[],"length":0,"stats":{"Line":1}},{"line":448,"address":[],"length":0,"stats":{"Line":0}},{"line":449,"address":[],"length":0,"stats":{"Line":0}},{"line":450,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":453,"address":[],"length":0,"stats":{"Line":0}},{"line":455,"address":[],"length":0,"stats":{"Line":0}},{"line":456,"address":[],"length":0,"stats":{"Line":0}},{"line":457,"address":[],"length":0,"stats":{"Line":0}},{"line":458,"address":[],"length":0,"stats":{"Line":0}},{"line":459,"address":[],"length":0,"stats":{"Line":0}},{"line":460,"address":[],"length":0,"stats":{"Line":0}},{"line":464,"address":[],"length":0,"stats":{"Line":0}},{"line":465,"address":[],"length":0,"stats":{"Line":0}},{"line":466,"address":[],"length":0,"stats":{"Line":0}},{"line":467,"address":[],"length":0,"stats":{"Line":0}},{"line":468,"address":[],"length":0,"stats":{"Line":0}},{"line":469,"address":[],"length":0,"stats":{"Line":0}},{"line":473,"address":[],"length":0,"stats":{"Line":0}},{"line":474,"address":[],"length":0,"stats":{"Line":0}},{"line":475,"address":[],"length":0,"stats":{"Line":0}},{"line":476,"address":[],"length":0,"stats":{"Line":0}},{"line":478,"address":[],"length":0,"stats":{"Line":0}},{"line":479,"address":[],"length":0,"stats":{"Line":0}},{"line":480,"address":[],"length":0,"stats":{"Line":0}},{"line":481,"address":[],"length":0,"stats":{"Line":0}},{"line":483,"address":[],"length":0,"stats":{"Line":0}},{"line":484,"address":[],"length":0,"stats":{"Line":0}},{"line":485,"address":[],"length":0,"stats":{"Line":0}},{"line":486,"address":[],"length":0,"stats":{"Line":0}},{"line":488,"address":[],"length":0,"stats":{"Line":0}},{"line":490,"address":[],"length":0,"stats":{"Line":0}},{"line":491,"address":[],"length":0,"stats":{"Line":0}},{"line":492,"address":[],"length":0,"stats":{"Line":0}},{"line":493,"address":[],"length":0,"stats":{"Line":0}},{"line":494,"address":[],"length":0,"stats":{"Line":0}},{"line":495,"address":[],"length":0,"stats":{"Line":0}},{"line":496,"address":[],"length":0,"stats":{"Line":0}},{"line":497,"address":[],"length":0,"stats":{"Line":0}},{"line":498,"address":[],"length":0,"stats":{"Line":0}},{"line":499,"address":[],"length":0,"stats":{"Line":0}},{"line":500,"address":[],"length":0,"stats":{"Line":0}},{"line":501,"address":[],"length":0,"stats":{"Line":0}},{"line":502,"address":[],"length":0,"stats":{"Line":0}},{"line":503,"address":[],"length":0,"stats":{"Line":0}},{"line":504,"address":[],"length":0,"stats":{"Line":0}},{"line":505,"address":[],"length":0,"stats":{"Line":0}},{"line":507,"address":[],"length":0,"stats":{"Line":0}},{"line":509,"address":[],"length":0,"stats":{"Line":0}},{"line":511,"address":[],"length":0,"stats":{"Line":0}},{"line":512,"address":[],"length":0,"stats":{"Line":0}},{"line":513,"address":[],"length":0,"stats":{"Line":0}},{"line":514,"address":[],"length":0,"stats":{"Line":0}},{"line":515,"address":[],"length":0,"stats":{"Line":0}},{"line":516,"address":[],"length":0,"stats":{"Line":0}},{"line":517,"address":[],"length":0,"stats":{"Line":0}},{"line":519,"address":[],"length":0,"stats":{"Line":0}},{"line":520,"address":[],"length":0,"stats":{"Line":0}},{"line":522,"address":[],"length":0,"stats":{"Line":0}},{"line":525,"address":[],"length":0,"stats":{"Line":0}},{"line":526,"address":[],"length":0,"stats":{"Line":0}},{"line":528,"address":[],"length":0,"stats":{"Line":0}},{"line":529,"address":[],"length":0,"stats":{"Line":0}},{"line":531,"address":[],"length":0,"stats":{"Line":0}},{"line":534,"address":[],"length":0,"stats":{"Line":0}},{"line":535,"address":[],"length":0,"stats":{"Line":0}},{"line":536,"address":[],"length":0,"stats":{"Line":0}},{"line":537,"address":[],"length":0,"stats":{"Line":0}},{"line":538,"address":[],"length":0,"stats":{"Line":0}},{"line":539,"address":[],"length":0,"stats":{"Line":0}},{"line":540,"address":[],"length":0,"stats":{"Line":0}},{"line":542,"address":[],"length":0,"stats":{"Line":0}},{"line":543,"address":[],"length":0,"stats":{"Line":0}},{"line":544,"address":[],"length":0,"stats":{"Line":0}},{"line":545,"address":[],"length":0,"stats":{"Line":0}},{"line":546,"address":[],"length":0,"stats":{"Line":0}},{"line":547,"address":[],"length":0,"stats":{"Line":0}},{"line":549,"address":[],"length":0,"stats":{"Line":0}},{"line":551,"address":[],"length":0,"stats":{"Line":0}},{"line":552,"address":[],"length":0,"stats":{"Line":0}},{"line":553,"address":[],"length":0,"stats":{"Line":0}},{"line":555,"address":[],"length":0,"stats":{"Line":0}},{"line":558,"address":[],"length":0,"stats":{"Line":0}},{"line":559,"address":[],"length":0,"stats":{"Line":0}},{"line":560,"address":[],"length":0,"stats":{"Line":0}},{"line":561,"address":[],"length":0,"stats":{"Line":0}},{"line":563,"address":[],"length":0,"stats":{"Line":0}},{"line":564,"address":[],"length":0,"stats":{"Line":0}},{"line":565,"address":[],"length":0,"stats":{"Line":0}},{"line":566,"address":[],"length":0,"stats":{"Line":0}},{"line":567,"address":[],"length":0,"stats":{"Line":0}},{"line":569,"address":[],"length":0,"stats":{"Line":0}},{"line":571,"address":[],"length":0,"stats":{"Line":0}},{"line":572,"address":[],"length":0,"stats":{"Line":0}},{"line":575,"address":[],"length":0,"stats":{"Line":0}},{"line":576,"address":[],"length":0,"stats":{"Line":0}},{"line":577,"address":[],"length":0,"stats":{"Line":0}},{"line":578,"address":[],"length":0,"stats":{"Line":0}},{"line":579,"address":[],"length":0,"stats":{"Line":0}},{"line":580,"address":[],"length":0,"stats":{"Line":0}},{"line":581,"address":[],"length":0,"stats":{"Line":0}},{"line":582,"address":[],"length":0,"stats":{"Line":0}},{"line":583,"address":[],"length":0,"stats":{"Line":0}},{"line":584,"address":[],"length":0,"stats":{"Line":0}},{"line":586,"address":[],"length":0,"stats":{"Line":0}},{"line":588,"address":[],"length":0,"stats":{"Line":0}},{"line":589,"address":[],"length":0,"stats":{"Line":0}},{"line":590,"address":[],"length":0,"stats":{"Line":0}},{"line":591,"address":[],"length":0,"stats":{"Line":0}},{"line":592,"address":[],"length":0,"stats":{"Line":0}},{"line":593,"address":[],"length":0,"stats":{"Line":0}},{"line":594,"address":[],"length":0,"stats":{"Line":0}},{"line":595,"address":[],"length":0,"stats":{"Line":0}},{"line":598,"address":[],"length":0,"stats":{"Line":0}},{"line":601,"address":[],"length":0,"stats":{"Line":18}},{"line":602,"address":[],"length":0,"stats":{"Line":54}},{"line":604,"address":[],"length":0,"stats":{"Line":18}},{"line":605,"address":[],"length":0,"stats":{"Line":17}},{"line":606,"address":[],"length":0,"stats":{"Line":16}},{"line":607,"address":[],"length":0,"stats":{"Line":16}},{"line":608,"address":[],"length":0,"stats":{"Line":15}},{"line":610,"address":[],"length":0,"stats":{"Line":8}},{"line":613,"address":[],"length":0,"stats":{"Line":14}},{"line":614,"address":[],"length":0,"stats":{"Line":13}},{"line":615,"address":[],"length":0,"stats":{"Line":13}},{"line":616,"address":[],"length":0,"stats":{"Line":12}},{"line":617,"address":[],"length":0,"stats":{"Line":11}},{"line":618,"address":[],"length":0,"stats":{"Line":10}},{"line":619,"address":[],"length":0,"stats":{"Line":9}},{"line":621,"address":[],"length":0,"stats":{"Line":12}},{"line":624,"address":[],"length":0,"stats":{"Line":8}},{"line":625,"address":[],"length":0,"stats":{"Line":7}},{"line":626,"address":[],"length":0,"stats":{"Line":6}},{"line":627,"address":[],"length":0,"stats":{"Line":5}},{"line":628,"address":[],"length":0,"stats":{"Line":4}},{"line":630,"address":[],"length":0,"stats":{"Line":10}},{"line":633,"address":[],"length":0,"stats":{"Line":3}},{"line":634,"address":[],"length":0,"stats":{"Line":2}},{"line":635,"address":[],"length":0,"stats":{"Line":2}},{"line":636,"address":[],"length":0,"stats":{"Line":2}},{"line":638,"address":[],"length":0,"stats":{"Line":4}},{"line":641,"address":[],"length":0,"stats":{"Line":2}},{"line":644,"address":[],"length":0,"stats":{"Line":15}},{"line":645,"address":[],"length":0,"stats":{"Line":45}},{"line":647,"address":[],"length":0,"stats":{"Line":15}},{"line":648,"address":[],"length":0,"stats":{"Line":14}},{"line":649,"address":[],"length":0,"stats":{"Line":13}},{"line":650,"address":[],"length":0,"stats":{"Line":12}},{"line":651,"address":[],"length":0,"stats":{"Line":11}},{"line":653,"address":[],"length":0,"stats":{"Line":10}},{"line":656,"address":[],"length":0,"stats":{"Line":10}},{"line":657,"address":[],"length":0,"stats":{"Line":9}},{"line":658,"address":[],"length":0,"stats":{"Line":8}},{"line":659,"address":[],"length":0,"stats":{"Line":7}},{"line":661,"address":[],"length":0,"stats":{"Line":8}},{"line":664,"address":[],"length":0,"stats":{"Line":6}},{"line":665,"address":[],"length":0,"stats":{"Line":4}},{"line":666,"address":[],"length":0,"stats":{"Line":3}},{"line":667,"address":[],"length":0,"stats":{"Line":2}},{"line":669,"address":[],"length":0,"stats":{"Line":8}},{"line":672,"address":[],"length":0,"stats":{"Line":4}},{"line":675,"address":[],"length":0,"stats":{"Line":4}},{"line":676,"address":[],"length":0,"stats":{"Line":20}},{"line":677,"address":[],"length":0,"stats":{"Line":12}},{"line":678,"address":[],"length":0,"stats":{"Line":4}},{"line":679,"address":[],"length":0,"stats":{"Line":3}},{"line":681,"address":[],"length":0,"stats":{"Line":6}},{"line":685,"address":[],"length":0,"stats":{"Line":3}},{"line":686,"address":[],"length":0,"stats":{"Line":6}},{"line":687,"address":[],"length":0,"stats":{"Line":3}},{"line":689,"address":[],"length":0,"stats":{"Line":4}}],"covered":124,"coverable":388},{"path":["/","Users","christian.klat","dev","git","aeterna","cli","src","commands","memory.rs"],"content":"use clap::{Args, Subcommand};\nuse context::ContextResolver;\nuse mk_core::hints::{HintPreset, OperationHints};\nuse serde_json::json;\n\nuse crate::output;\nuse crate::ux_error;\n\n#[derive(Subcommand)]\npub enum MemoryCommand {\n    #[command(about = \"Search memories across layers\")]\n    Search(MemorySearchArgs),\n\n    #[command(about = \"Add a new memory\")]\n    Add(MemoryAddArgs),\n\n    #[command(about = \"Delete a memory by ID\")]\n    Delete(MemoryDeleteArgs),\n\n    #[command(about = \"List memories in a layer\")]\n    List(MemoryListArgs),\n\n    #[command(about = \"Show memory details by ID\")]\n    Show(MemoryShowArgs),\n\n    #[command(about = \"Provide feedback on a memory\")]\n    Feedback(MemoryFeedbackArgs),\n\n    #[command(about = \"Promote a memory to a broader layer\")]\n    Promote(MemoryPromoteArgs),\n}\n\n#[derive(Args)]\npub struct MemorySearchArgs {\n    /// Search query\n    pub query: String,\n\n    /// Maximum number of results (default: 10)\n    #[arg(short, long, default_value = \"10\")]\n    pub limit: usize,\n\n    /// Minimum similarity threshold (0.0-1.0)\n    #[arg(short, long, default_value = \"0.0\")]\n    pub threshold: f32,\n\n    /// Filter by layer (agent, user, session, project, team, org, company)\n    #[arg(long)]\n    pub layer: Option<String>,\n\n    /// Hints preset (minimal, fast, standard, full, offline, agent)\n    #[arg(long)]\n    pub preset: Option<String>,\n\n    /// Enable reasoning (overrides preset)\n    #[arg(long)]\n    pub reasoning: Option<bool>,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n\n    /// Show verbose output (what hints would do)\n    #[arg(short, long)]\n    pub verbose: bool,\n\n    /// Dry run - don't actually search, just show what would happen\n    #[arg(long)]\n    pub dry_run: bool,\n}\n\n#[derive(Args)]\npub struct MemoryAddArgs {\n    /// Memory content to store\n    pub content: String,\n\n    /// Layer to store in (agent, user, session, project, team, org, company)\n    #[arg(short, long, default_value = \"project\")]\n    pub layer: String,\n\n    /// Tags for the memory (comma-separated)\n    #[arg(short, long)]\n    pub tags: Option<String>,\n\n    /// Additional metadata as JSON\n    #[arg(short, long)]\n    pub metadata: Option<String>,\n\n    /// Hints preset\n    #[arg(long)]\n    pub preset: Option<String>,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n\n    /// Dry run - don't actually store, just show what would happen\n    #[arg(long)]\n    pub dry_run: bool,\n}\n\n#[derive(Args)]\npub struct MemoryDeleteArgs {\n    /// Memory ID to delete\n    pub memory_id: String,\n\n    /// Layer the memory is in\n    #[arg(short, long)]\n    pub layer: String,\n\n    /// Skip confirmation prompt\n    #[arg(short, long)]\n    pub yes: bool,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct MemoryListArgs {\n    /// Layer to list (agent, user, session, project, team, org, company)\n    #[arg(short, long, default_value = \"project\")]\n    pub layer: String,\n\n    /// Maximum number of results\n    #[arg(short = 'n', long, default_value = \"20\")]\n    pub limit: usize,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct MemoryShowArgs {\n    /// Memory ID to show\n    pub memory_id: String,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct MemoryFeedbackArgs {\n    /// Memory ID to provide feedback for\n    pub memory_id: String,\n\n    /// Layer the memory is in\n    #[arg(short, long)]\n    pub layer: String,\n\n    /// Feedback type (helpful, irrelevant, outdated, inaccurate, duplicate)\n    #[arg(short = 't', long)]\n    pub feedback_type: String,\n\n    /// Score (-1.0 to 1.0)\n    #[arg(short, long)]\n    pub score: f32,\n\n    /// Optional reasoning for the feedback\n    #[arg(short, long)]\n    pub reasoning: Option<String>,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct MemoryPromoteArgs {\n    /// Memory ID to promote\n    pub memory_id: String,\n\n    /// Current layer the memory is in\n    #[arg(short, long)]\n    pub from_layer: String,\n\n    /// Target layer to promote to (must be broader than current)\n    #[arg(short, long)]\n    pub to_layer: String,\n\n    /// Reason for promotion\n    #[arg(short, long)]\n    pub reason: Option<String>,\n\n    /// Skip governance approval (requires admin role)\n    #[arg(long)]\n    pub skip_approval: bool,\n\n    /// Skip confirmation prompt\n    #[arg(short, long)]\n    pub yes: bool,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n\n    /// Dry run - don't actually promote, just show what would happen\n    #[arg(long)]\n    pub dry_run: bool,\n}\n\npub async fn run(cmd: MemoryCommand) -> anyhow::Result<()> {\n    match cmd {\n        MemoryCommand::Search(args) => run_search(args).await,\n        MemoryCommand::Add(args) => run_add(args).await,\n        MemoryCommand::Delete(args) => run_delete(args).await,\n        MemoryCommand::List(args) => run_list(args).await,\n        MemoryCommand::Show(args) => run_show(args).await,\n        MemoryCommand::Feedback(args) => run_feedback(args).await,\n        MemoryCommand::Promote(args) => run_promote(args).await,\n    }\n}\n\nasync fn run_search(args: MemorySearchArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    // Determine hints\n    let base_hints = if let Some(preset_str) = &args.preset {\n        let preset: HintPreset = preset_str.parse().map_err(|_| {\n            let err = ux_error::invalid_preset(preset_str);\n            err.display();\n            anyhow::anyhow!(\"Invalid preset\")\n        })?;\n        OperationHints::from_preset(preset)\n    } else {\n        resolved.to_hints()\n    };\n\n    // Apply overrides\n    let hints = if let Some(reasoning) = args.reasoning {\n        base_hints.with_reasoning(reasoning)\n    } else {\n        base_hints\n    };\n\n    if args.dry_run || args.verbose {\n        if args.json {\n            let output = json!({\n                \"dryRun\": true,\n                \"operation\": \"memory_search\",\n                \"query\": args.query,\n                \"limit\": args.limit,\n                \"threshold\": args.threshold,\n                \"layer\": args.layer,\n                \"context\": {\n                    \"tenantId\": resolved.tenant_id.value,\n                    \"userId\": resolved.user_id.value,\n                    \"projectId\": resolved.project_id.as_ref().map(|v| &v.value),\n                },\n                \"hints\": {\n                    \"preset\": format!(\"{}\", hints.preset),\n                    \"reasoning\": hints.reasoning,\n                    \"multiHop\": hints.multi_hop,\n                    \"summarization\": hints.summarization,\n                    \"caching\": hints.caching,\n                    \"llm\": hints.llm,\n                    \"graph\": hints.graph,\n                }\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Memory Search (Dry Run)\");\n            println!();\n            println!(\"  Query:     {}\", args.query);\n            println!(\"  Limit:     {}\", args.limit);\n            println!(\"  Threshold: {}\", args.threshold);\n            if let Some(layer) = &args.layer {\n                println!(\"  Layer:     {}\", layer);\n            }\n            println!();\n            output::header(\"Context\");\n            println!(\"  tenant_id:  {}\", resolved.tenant_id.value);\n            println!(\"  user_id:    {}\", resolved.user_id.value);\n            if let Some(project) = &resolved.project_id {\n                println!(\"  project_id: {}\", project.value);\n            }\n            println!();\n            output::header(\"Active Hints\");\n            println!(\"  preset:       {}\", hints.preset);\n            println!(\n                \"  reasoning:    {} {}\",\n                if hints.reasoning { \"on\" } else { \"off\" },\n                hint_effect(hints.reasoning, \"will use MemR reflective reasoning\")\n            );\n            println!(\n                \"  multi_hop:    {} {}\",\n                if hints.multi_hop { \"on\" } else { \"off\" },\n                hint_effect(hints.multi_hop, \"will follow graph relationships\")\n            );\n            println!(\n                \"  summarization: {} {}\",\n                if hints.summarization { \"on\" } else { \"off\" },\n                hint_effect(hints.summarization, \"will summarize results\")\n            );\n            println!(\n                \"  caching:      {} {}\",\n                if hints.caching { \"on\" } else { \"off\" },\n                hint_effect(hints.caching, \"will cache query results\")\n            );\n            println!(\n                \"  llm:          {} {}\",\n                if hints.llm { \"on\" } else { \"off\" },\n                hint_effect(hints.llm, \"will use LLM for embeddings\")\n            );\n            println!(\n                \"  graph:        {} {}\",\n                if hints.graph { \"on\" } else { \"off\" },\n                hint_effect(hints.graph, \"will query knowledge graph\")\n            );\n            println!();\n\n            if args.dry_run {\n                output::info(\"Dry run mode - no actual search performed.\");\n                output::info(\"Remove --dry-run to execute the search.\");\n            }\n        }\n        return Ok(());\n    }\n\n    // TODO: Actually perform the search when connected to backend\n    // For now, show a helpful message about what would happen\n    let err = ux_error::server_not_connected();\n    err.display();\n    output::info(\"Run with --dry-run to see what would happen.\");\n\n    Ok(())\n}\n\nasync fn run_add(args: MemoryAddArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    // Validate layer\n    let layer = args.layer.to_lowercase();\n    let valid_layers = [\n        \"agent\", \"user\", \"session\", \"project\", \"team\", \"org\", \"company\",\n    ];\n    if !valid_layers.contains(&layer.as_str()) {\n        let err = ux_error::invalid_layer(&layer, &valid_layers);\n        err.display();\n        return Err(anyhow::anyhow!(\"Invalid layer\"));\n    }\n\n    // Parse tags\n    let tags: Vec<String> = args\n        .tags\n        .map(|t| t.split(',').map(|s| s.trim().to_string()).collect())\n        .unwrap_or_default();\n\n    // Parse metadata\n    let metadata: serde_json::Value = if let Some(meta_str) = &args.metadata {\n        serde_json::from_str(meta_str).map_err(|e| {\n            let err = ux_error::invalid_metadata_json(&e.to_string());\n            err.display();\n            anyhow::anyhow!(\"Invalid metadata JSON\")\n        })?\n    } else {\n        json!({})\n    };\n\n    // Determine hints\n    let hints = if let Some(preset_str) = &args.preset {\n        let preset: HintPreset = preset_str.parse().map_err(|_| {\n            let err = ux_error::invalid_preset(preset_str);\n            err.display();\n            anyhow::anyhow!(\"Invalid preset\")\n        })?;\n        OperationHints::from_preset(preset)\n    } else {\n        resolved.to_hints()\n    };\n\n    if args.dry_run {\n        if args.json {\n            let output = json!({\n                \"dryRun\": true,\n                \"operation\": \"memory_add\",\n                \"content\": args.content,\n                \"layer\": layer,\n                \"tags\": tags,\n                \"metadata\": metadata,\n                \"context\": {\n                    \"tenantId\": resolved.tenant_id.value,\n                    \"userId\": resolved.user_id.value,\n                    \"projectId\": resolved.project_id.as_ref().map(|v| &v.value),\n                },\n                \"hints\": {\n                    \"preset\": format!(\"{}\", hints.preset),\n                    \"governance\": hints.governance,\n                    \"audit\": hints.audit,\n                    \"llm\": hints.llm,\n                }\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Memory Add (Dry Run)\");\n            println!();\n            println!(\"  Content: {}\", truncate(&args.content, 60));\n            println!(\"  Layer:   {}\", layer);\n            if !tags.is_empty() {\n                println!(\"  Tags:    {}\", tags.join(\", \"));\n            }\n            if metadata != json!({}) {\n                println!(\"  Metadata: {}\", metadata);\n            }\n            println!();\n            output::header(\"Context\");\n            println!(\"  tenant_id:  {}\", resolved.tenant_id.value);\n            println!(\"  user_id:    {}\", resolved.user_id.value);\n            if let Some(project) = &resolved.project_id {\n                println!(\"  project_id: {}\", project.value);\n            }\n            println!();\n            output::header(\"Active Hints\");\n            println!(\n                \"  governance: {} {}\",\n                if hints.governance { \"on\" } else { \"off\" },\n                hint_effect(hints.governance, \"will check policies before storing\")\n            );\n            println!(\n                \"  audit:      {} {}\",\n                if hints.audit { \"on\" } else { \"off\" },\n                hint_effect(hints.audit, \"will log to audit trail\")\n            );\n            println!(\n                \"  llm:        {} {}\",\n                if hints.llm { \"on\" } else { \"off\" },\n                hint_effect(hints.llm, \"will generate embeddings\")\n            );\n            println!();\n            output::info(\"Dry run mode - memory not stored.\");\n            output::info(\"Remove --dry-run to store the memory.\");\n        }\n        return Ok(());\n    }\n\n    // TODO: Actually store the memory when connected to backend\n    let err = ux_error::server_not_connected();\n    err.display();\n    output::info(\"Run with --dry-run to see what would happen.\");\n\n    Ok(())\n}\n\nasync fn run_delete(args: MemoryDeleteArgs) -> anyhow::Result<()> {\n    // Validate layer\n    let layer = args.layer.to_lowercase();\n    let valid_layers = [\n        \"agent\", \"user\", \"session\", \"project\", \"team\", \"org\", \"company\",\n    ];\n    if !valid_layers.contains(&layer.as_str()) {\n        let err = ux_error::invalid_layer(&layer, &valid_layers);\n        err.display();\n        return Err(anyhow::anyhow!(\"Invalid layer\"));\n    }\n\n    if !args.yes {\n        output::warn(&format!(\n            \"This will delete memory '{}' from layer '{}'.\",\n            args.memory_id, layer\n        ));\n        output::info(\"Use --yes to skip this confirmation.\");\n        return Ok(());\n    }\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"memory_delete\",\n            \"memoryId\": args.memory_id,\n            \"layer\": layer,\n            \"status\": \"not_connected\",\n            \"message\": \"Memory backend not connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nasync fn run_list(args: MemoryListArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    // Validate layer\n    let layer = args.layer.to_lowercase();\n    let valid_layers = [\n        \"agent\", \"user\", \"session\", \"project\", \"team\", \"org\", \"company\",\n    ];\n    if !valid_layers.contains(&layer.as_str()) {\n        let err = ux_error::invalid_layer(&layer, &valid_layers);\n        err.display();\n        return Err(anyhow::anyhow!(\"Invalid layer\"));\n    }\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"memory_list\",\n            \"layer\": layer,\n            \"limit\": args.limit,\n            \"context\": {\n                \"tenantId\": resolved.tenant_id.value,\n                \"userId\": resolved.user_id.value,\n                \"projectId\": resolved.project_id.as_ref().map(|v| &v.value),\n            },\n            \"status\": \"not_connected\",\n            \"message\": \"Memory backend not connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(&format!(\"Memories in '{}' layer\", layer));\n        println!();\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nasync fn run_show(args: MemoryShowArgs) -> anyhow::Result<()> {\n    if args.json {\n        let output = json!({\n            \"operation\": \"memory_show\",\n            \"memoryId\": args.memory_id,\n            \"status\": \"not_connected\",\n            \"message\": \"Memory backend not connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(&format!(\"Memory: {}\", args.memory_id));\n        println!();\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nasync fn run_feedback(args: MemoryFeedbackArgs) -> anyhow::Result<()> {\n    // Validate layer\n    let layer = args.layer.to_lowercase();\n    let valid_layers = [\n        \"agent\", \"user\", \"session\", \"project\", \"team\", \"org\", \"company\",\n    ];\n    if !valid_layers.contains(&layer.as_str()) {\n        let err = ux_error::invalid_layer(&layer, &valid_layers);\n        err.display();\n        return Err(anyhow::anyhow!(\"Invalid layer\"));\n    }\n\n    // Validate feedback type\n    let feedback_type = args.feedback_type.to_lowercase();\n    let valid_types = [\n        \"helpful\",\n        \"irrelevant\",\n        \"outdated\",\n        \"inaccurate\",\n        \"duplicate\",\n    ];\n    if !valid_types.contains(&feedback_type.as_str()) {\n        let err = ux_error::invalid_feedback_type(&feedback_type);\n        err.display();\n        return Err(anyhow::anyhow!(\"Invalid feedback type\"));\n    }\n\n    // Validate score\n    if args.score < -1.0 || args.score > 1.0 {\n        let err = ux_error::invalid_score(args.score);\n        err.display();\n        return Err(anyhow::anyhow!(\"Invalid score\"));\n    }\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"memory_feedback\",\n            \"memoryId\": args.memory_id,\n            \"layer\": layer,\n            \"feedbackType\": feedback_type,\n            \"score\": args.score,\n            \"reasoning\": args.reasoning,\n            \"status\": \"not_connected\",\n            \"message\": \"Memory backend not connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(\"Memory Feedback\");\n        println!();\n        println!(\"  Memory ID: {}\", args.memory_id);\n        println!(\"  Layer:     {}\", layer);\n        println!(\"  Type:      {}\", feedback_type);\n        println!(\"  Score:     {}\", args.score);\n        if let Some(reasoning) = &args.reasoning {\n            println!(\"  Reasoning: {}\", reasoning);\n        }\n        println!();\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nfn hint_effect(enabled: bool, effect: &str) -> String {\n    if enabled {\n        format!(\"({})\", effect)\n    } else {\n        String::new()\n    }\n}\n\nfn truncate(s: &str, max_len: usize) -> String {\n    if s.len() > max_len {\n        format!(\"{}...\", &s[..max_len - 3])\n    } else {\n        s.to_string()\n    }\n}\n\nfn layer_order(l: &str) -> usize {\n    match l {\n        \"agent\" => 0,\n        \"user\" => 1,\n        \"session\" => 2,\n        \"project\" => 3,\n        \"team\" => 4,\n        \"org\" => 5,\n        \"company\" => 6,\n        _ => 0,\n    }\n}\n\nasync fn run_promote(args: MemoryPromoteArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    let from_layer = args.from_layer.to_lowercase();\n    let to_layer = args.to_layer.to_lowercase();\n    let valid_layers = [\n        \"agent\", \"user\", \"session\", \"project\", \"team\", \"org\", \"company\",\n    ];\n\n    if !valid_layers.contains(&from_layer.as_str()) {\n        let err = ux_error::invalid_layer(&from_layer, &valid_layers);\n        err.display();\n        return Err(anyhow::anyhow!(\"Invalid source layer\"));\n    }\n\n    if !valid_layers.contains(&to_layer.as_str()) {\n        let err = ux_error::invalid_layer(&to_layer, &valid_layers);\n        err.display();\n        return Err(anyhow::anyhow!(\"Invalid target layer\"));\n    }\n\n    if layer_order(&to_layer) <= layer_order(&from_layer) {\n        let err = ux_error::promotion_direction_invalid(&from_layer, &to_layer);\n        err.display();\n        return Err(anyhow::anyhow!(\"Cannot promote to same or narrower layer\"));\n    }\n\n    if args.dry_run {\n        if args.json {\n            let output = json!({\n                \"dryRun\": true,\n                \"operation\": \"memory_promote\",\n                \"memoryId\": args.memory_id,\n                \"fromLayer\": from_layer,\n                \"toLayer\": to_layer,\n                \"reason\": args.reason,\n                \"skipApproval\": args.skip_approval,\n                \"context\": {\n                    \"tenantId\": resolved.tenant_id.value,\n                    \"userId\": resolved.user_id.value,\n                    \"projectId\": resolved.project_id.as_ref().map(|v| &v.value),\n                },\n                \"governanceRequired\": !args.skip_approval,\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Memory Promote (Dry Run)\");\n            println!();\n            println!(\"  Memory ID:   {}\", args.memory_id);\n            println!(\"  From Layer:  {}\", from_layer);\n            println!(\"  To Layer:    {}\", to_layer);\n            if let Some(reason) = &args.reason {\n                println!(\"  Reason:      {}\", reason);\n            }\n            println!();\n            output::header(\"Context\");\n            println!(\"  tenant_id:  {}\", resolved.tenant_id.value);\n            println!(\"  user_id:    {}\", resolved.user_id.value);\n            if let Some(project) = &resolved.project_id {\n                println!(\"  project_id: {}\", project.value);\n            }\n            println!();\n            output::header(\"Governance\");\n            if args.skip_approval {\n                output::warn(\"Skipping approval - requires admin role\");\n            } else {\n                println!(\"  Promotion will require approval based on governance config\");\n                println!(\"  Use --skip-approval to bypass (admin only)\");\n            }\n            println!();\n            output::info(\"Dry run mode - no promotion performed.\");\n            output::info(\"Remove --dry-run to execute the promotion.\");\n        }\n        return Ok(());\n    }\n\n    if !args.yes && !args.dry_run {\n        output::warn(&format!(\n            \"This will promote memory '{}' from '{}' to '{}' layer.\",\n            args.memory_id, from_layer, to_layer\n        ));\n        if !args.skip_approval {\n            output::info(\"This action may require governance approval.\");\n        }\n        output::info(\"Use --yes to skip this confirmation.\");\n        return Ok(());\n    }\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"memory_promote\",\n            \"memoryId\": args.memory_id,\n            \"fromLayer\": from_layer,\n            \"toLayer\": to_layer,\n            \"reason\": args.reason,\n            \"status\": \"not_connected\",\n            \"message\": \"Memory backend not connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(\"Memory Promote\");\n        println!();\n        println!(\"  Memory ID:   {}\", args.memory_id);\n        println!(\"  From Layer:  {}\", from_layer);\n        println!(\"  To Layer:    {}\", to_layer);\n        if let Some(reason) = &args.reason {\n            println!(\"  Reason:      {}\", reason);\n        }\n        println!();\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_hint_effect_enabled() {\n        let result = hint_effect(true, \"will do something\");\n        assert_eq!(result, \"(will do something)\");\n    }\n\n    #[test]\n    fn test_hint_effect_disabled() {\n        let result = hint_effect(false, \"will do something\");\n        assert_eq!(result, \"\");\n    }\n\n    #[test]\n    fn test_truncate_short_string() {\n        let result = truncate(\"hello\", 10);\n        assert_eq!(result, \"hello\");\n    }\n\n    #[test]\n    fn test_truncate_exact_length() {\n        let result = truncate(\"hello\", 5);\n        assert_eq!(result, \"hello\");\n    }\n\n    #[test]\n    fn test_truncate_long_string() {\n        let result = truncate(\"hello world this is a long string\", 10);\n        assert_eq!(result, \"hello w...\");\n        assert_eq!(result.len(), 10);\n    }\n\n    #[test]\n    fn test_truncate_with_unicode() {\n        let result = truncate(\"hllo\", 10);\n        assert_eq!(result, \"hllo\");\n    }\n\n    #[test]\n    fn test_layer_order_all_layers() {\n        assert_eq!(layer_order(\"agent\"), 0);\n        assert_eq!(layer_order(\"user\"), 1);\n        assert_eq!(layer_order(\"session\"), 2);\n        assert_eq!(layer_order(\"project\"), 3);\n        assert_eq!(layer_order(\"team\"), 4);\n        assert_eq!(layer_order(\"org\"), 5);\n        assert_eq!(layer_order(\"company\"), 6);\n    }\n\n    #[test]\n    fn test_layer_order_unknown() {\n        assert_eq!(layer_order(\"unknown\"), 0);\n        assert_eq!(layer_order(\"\"), 0);\n    }\n\n    #[test]\n    fn test_layer_hierarchy_promotion_valid() {\n        assert!(layer_order(\"team\") > layer_order(\"project\"));\n        assert!(layer_order(\"org\") > layer_order(\"team\"));\n        assert!(layer_order(\"company\") > layer_order(\"org\"));\n    }\n\n    #[test]\n    fn test_layer_hierarchy_promotion_invalid() {\n        assert!(layer_order(\"agent\") < layer_order(\"user\"));\n        assert!(layer_order(\"project\") < layer_order(\"team\"));\n    }\n}\n","traces":[{"line":204,"address":[],"length":0,"stats":{"Line":26}},{"line":205,"address":[],"length":0,"stats":{"Line":13}},{"line":206,"address":[],"length":0,"stats":{"Line":3}},{"line":207,"address":[],"length":0,"stats":{"Line":36}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":2}},{"line":217,"address":[],"length":0,"stats":{"Line":2}},{"line":218,"address":[],"length":0,"stats":{"Line":3}},{"line":221,"address":[],"length":0,"stats":{"Line":2}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":223,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":225,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":2}},{"line":233,"address":[],"length":0,"stats":{"Line":2}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":1}},{"line":239,"address":[],"length":0,"stats":{"Line":1}},{"line":240,"address":[],"length":0,"stats":{"Line":1}},{"line":241,"address":[],"length":0,"stats":{"Line":0}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":0}},{"line":254,"address":[],"length":0,"stats":{"Line":0}},{"line":255,"address":[],"length":0,"stats":{"Line":0}},{"line":256,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":2}},{"line":266,"address":[],"length":0,"stats":{"Line":1}},{"line":267,"address":[],"length":0,"stats":{"Line":2}},{"line":268,"address":[],"length":0,"stats":{"Line":2}},{"line":269,"address":[],"length":0,"stats":{"Line":2}},{"line":270,"address":[],"length":0,"stats":{"Line":1}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":1}},{"line":274,"address":[],"length":0,"stats":{"Line":2}},{"line":275,"address":[],"length":0,"stats":{"Line":2}},{"line":276,"address":[],"length":0,"stats":{"Line":2}},{"line":277,"address":[],"length":0,"stats":{"Line":3}},{"line":278,"address":[],"length":0,"stats":{"Line":1}},{"line":280,"address":[],"length":0,"stats":{"Line":1}},{"line":281,"address":[],"length":0,"stats":{"Line":2}},{"line":282,"address":[],"length":0,"stats":{"Line":2}},{"line":283,"address":[],"length":0,"stats":{"Line":1}},{"line":284,"address":[],"length":0,"stats":{"Line":1}},{"line":285,"address":[],"length":0,"stats":{"Line":2}},{"line":286,"address":[],"length":0,"stats":{"Line":3}},{"line":288,"address":[],"length":0,"stats":{"Line":1}},{"line":289,"address":[],"length":0,"stats":{"Line":1}},{"line":290,"address":[],"length":0,"stats":{"Line":2}},{"line":291,"address":[],"length":0,"stats":{"Line":3}},{"line":293,"address":[],"length":0,"stats":{"Line":1}},{"line":294,"address":[],"length":0,"stats":{"Line":1}},{"line":295,"address":[],"length":0,"stats":{"Line":2}},{"line":296,"address":[],"length":0,"stats":{"Line":3}},{"line":298,"address":[],"length":0,"stats":{"Line":1}},{"line":299,"address":[],"length":0,"stats":{"Line":1}},{"line":300,"address":[],"length":0,"stats":{"Line":2}},{"line":301,"address":[],"length":0,"stats":{"Line":3}},{"line":303,"address":[],"length":0,"stats":{"Line":1}},{"line":304,"address":[],"length":0,"stats":{"Line":1}},{"line":305,"address":[],"length":0,"stats":{"Line":2}},{"line":306,"address":[],"length":0,"stats":{"Line":3}},{"line":308,"address":[],"length":0,"stats":{"Line":1}},{"line":309,"address":[],"length":0,"stats":{"Line":1}},{"line":310,"address":[],"length":0,"stats":{"Line":2}},{"line":311,"address":[],"length":0,"stats":{"Line":3}},{"line":313,"address":[],"length":0,"stats":{"Line":1}},{"line":315,"address":[],"length":0,"stats":{"Line":2}},{"line":316,"address":[],"length":0,"stats":{"Line":3}},{"line":317,"address":[],"length":0,"stats":{"Line":1}},{"line":320,"address":[],"length":0,"stats":{"Line":1}},{"line":325,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":24}},{"line":333,"address":[],"length":0,"stats":{"Line":24}},{"line":334,"address":[],"length":0,"stats":{"Line":36}},{"line":337,"address":[],"length":0,"stats":{"Line":24}},{"line":338,"address":[],"length":0,"stats":{"Line":24}},{"line":339,"address":[],"length":0,"stats":{"Line":60}},{"line":341,"address":[],"length":0,"stats":{"Line":36}},{"line":342,"address":[],"length":0,"stats":{"Line":4}},{"line":343,"address":[],"length":0,"stats":{"Line":2}},{"line":344,"address":[],"length":0,"stats":{"Line":1}},{"line":348,"address":[],"length":0,"stats":{"Line":33}},{"line":349,"address":[],"length":0,"stats":{"Line":11}},{"line":350,"address":[],"length":0,"stats":{"Line":11}},{"line":354,"address":[],"length":0,"stats":{"Line":33}},{"line":355,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":358,"address":[],"length":0,"stats":{"Line":0}},{"line":361,"address":[],"length":0,"stats":{"Line":11}},{"line":365,"address":[],"length":0,"stats":{"Line":22}},{"line":366,"address":[],"length":0,"stats":{"Line":0}},{"line":367,"address":[],"length":0,"stats":{"Line":0}},{"line":368,"address":[],"length":0,"stats":{"Line":0}},{"line":369,"address":[],"length":0,"stats":{"Line":0}},{"line":371,"address":[],"length":0,"stats":{"Line":0}},{"line":373,"address":[],"length":0,"stats":{"Line":22}},{"line":376,"address":[],"length":0,"stats":{"Line":11}},{"line":377,"address":[],"length":0,"stats":{"Line":11}},{"line":378,"address":[],"length":0,"stats":{"Line":4}},{"line":379,"address":[],"length":0,"stats":{"Line":2}},{"line":380,"address":[],"length":0,"stats":{"Line":2}},{"line":381,"address":[],"length":0,"stats":{"Line":2}},{"line":382,"address":[],"length":0,"stats":{"Line":2}},{"line":383,"address":[],"length":0,"stats":{"Line":2}},{"line":384,"address":[],"length":0,"stats":{"Line":2}},{"line":385,"address":[],"length":0,"stats":{"Line":2}},{"line":386,"address":[],"length":0,"stats":{"Line":2}},{"line":387,"address":[],"length":0,"stats":{"Line":2}},{"line":388,"address":[],"length":0,"stats":{"Line":8}},{"line":390,"address":[],"length":0,"stats":{"Line":2}},{"line":391,"address":[],"length":0,"stats":{"Line":6}},{"line":392,"address":[],"length":0,"stats":{"Line":2}},{"line":393,"address":[],"length":0,"stats":{"Line":2}},{"line":394,"address":[],"length":0,"stats":{"Line":2}},{"line":397,"address":[],"length":0,"stats":{"Line":8}},{"line":399,"address":[],"length":0,"stats":{"Line":18}},{"line":400,"address":[],"length":0,"stats":{"Line":9}},{"line":401,"address":[],"length":0,"stats":{"Line":36}},{"line":402,"address":[],"length":0,"stats":{"Line":18}},{"line":403,"address":[],"length":0,"stats":{"Line":9}},{"line":404,"address":[],"length":0,"stats":{"Line":0}},{"line":406,"address":[],"length":0,"stats":{"Line":9}},{"line":407,"address":[],"length":0,"stats":{"Line":0}},{"line":409,"address":[],"length":0,"stats":{"Line":9}},{"line":410,"address":[],"length":0,"stats":{"Line":18}},{"line":411,"address":[],"length":0,"stats":{"Line":18}},{"line":412,"address":[],"length":0,"stats":{"Line":18}},{"line":413,"address":[],"length":0,"stats":{"Line":27}},{"line":414,"address":[],"length":0,"stats":{"Line":9}},{"line":416,"address":[],"length":0,"stats":{"Line":9}},{"line":417,"address":[],"length":0,"stats":{"Line":18}},{"line":418,"address":[],"length":0,"stats":{"Line":9}},{"line":419,"address":[],"length":0,"stats":{"Line":9}},{"line":420,"address":[],"length":0,"stats":{"Line":18}},{"line":421,"address":[],"length":0,"stats":{"Line":27}},{"line":423,"address":[],"length":0,"stats":{"Line":9}},{"line":424,"address":[],"length":0,"stats":{"Line":9}},{"line":425,"address":[],"length":0,"stats":{"Line":18}},{"line":426,"address":[],"length":0,"stats":{"Line":27}},{"line":428,"address":[],"length":0,"stats":{"Line":9}},{"line":429,"address":[],"length":0,"stats":{"Line":9}},{"line":430,"address":[],"length":0,"stats":{"Line":18}},{"line":431,"address":[],"length":0,"stats":{"Line":27}},{"line":433,"address":[],"length":0,"stats":{"Line":9}},{"line":434,"address":[],"length":0,"stats":{"Line":18}},{"line":435,"address":[],"length":0,"stats":{"Line":18}},{"line":437,"address":[],"length":0,"stats":{"Line":11}},{"line":441,"address":[],"length":0,"stats":{"Line":0}},{"line":442,"address":[],"length":0,"stats":{"Line":0}},{"line":443,"address":[],"length":0,"stats":{"Line":0}},{"line":445,"address":[],"length":0,"stats":{"Line":0}},{"line":448,"address":[],"length":0,"stats":{"Line":0}},{"line":450,"address":[],"length":0,"stats":{"Line":0}},{"line":451,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":454,"address":[],"length":0,"stats":{"Line":0}},{"line":455,"address":[],"length":0,"stats":{"Line":0}},{"line":456,"address":[],"length":0,"stats":{"Line":0}},{"line":457,"address":[],"length":0,"stats":{"Line":0}},{"line":460,"address":[],"length":0,"stats":{"Line":0}},{"line":461,"address":[],"length":0,"stats":{"Line":0}},{"line":462,"address":[],"length":0,"stats":{"Line":0}},{"line":463,"address":[],"length":0,"stats":{"Line":0}},{"line":465,"address":[],"length":0,"stats":{"Line":0}},{"line":466,"address":[],"length":0,"stats":{"Line":0}},{"line":469,"address":[],"length":0,"stats":{"Line":0}},{"line":470,"address":[],"length":0,"stats":{"Line":0}},{"line":471,"address":[],"length":0,"stats":{"Line":0}},{"line":472,"address":[],"length":0,"stats":{"Line":0}},{"line":473,"address":[],"length":0,"stats":{"Line":0}},{"line":474,"address":[],"length":0,"stats":{"Line":0}},{"line":475,"address":[],"length":0,"stats":{"Line":0}},{"line":477,"address":[],"length":0,"stats":{"Line":0}},{"line":479,"address":[],"length":0,"stats":{"Line":0}},{"line":480,"address":[],"length":0,"stats":{"Line":0}},{"line":483,"address":[],"length":0,"stats":{"Line":0}},{"line":486,"address":[],"length":0,"stats":{"Line":0}},{"line":487,"address":[],"length":0,"stats":{"Line":0}},{"line":488,"address":[],"length":0,"stats":{"Line":0}},{"line":491,"address":[],"length":0,"stats":{"Line":0}},{"line":492,"address":[],"length":0,"stats":{"Line":0}},{"line":493,"address":[],"length":0,"stats":{"Line":0}},{"line":495,"address":[],"length":0,"stats":{"Line":0}},{"line":496,"address":[],"length":0,"stats":{"Line":0}},{"line":497,"address":[],"length":0,"stats":{"Line":0}},{"line":498,"address":[],"length":0,"stats":{"Line":0}},{"line":501,"address":[],"length":0,"stats":{"Line":0}},{"line":502,"address":[],"length":0,"stats":{"Line":0}},{"line":503,"address":[],"length":0,"stats":{"Line":0}},{"line":504,"address":[],"length":0,"stats":{"Line":0}},{"line":505,"address":[],"length":0,"stats":{"Line":0}},{"line":506,"address":[],"length":0,"stats":{"Line":0}},{"line":507,"address":[],"length":0,"stats":{"Line":0}},{"line":508,"address":[],"length":0,"stats":{"Line":0}},{"line":509,"address":[],"length":0,"stats":{"Line":0}},{"line":511,"address":[],"length":0,"stats":{"Line":0}},{"line":512,"address":[],"length":0,"stats":{"Line":0}},{"line":514,"address":[],"length":0,"stats":{"Line":0}},{"line":516,"address":[],"length":0,"stats":{"Line":0}},{"line":517,"address":[],"length":0,"stats":{"Line":0}},{"line":518,"address":[],"length":0,"stats":{"Line":0}},{"line":519,"address":[],"length":0,"stats":{"Line":0}},{"line":522,"address":[],"length":0,"stats":{"Line":0}},{"line":525,"address":[],"length":0,"stats":{"Line":0}},{"line":526,"address":[],"length":0,"stats":{"Line":0}},{"line":527,"address":[],"length":0,"stats":{"Line":0}},{"line":528,"address":[],"length":0,"stats":{"Line":0}},{"line":529,"address":[],"length":0,"stats":{"Line":0}},{"line":530,"address":[],"length":0,"stats":{"Line":0}},{"line":531,"address":[],"length":0,"stats":{"Line":0}},{"line":533,"address":[],"length":0,"stats":{"Line":0}},{"line":535,"address":[],"length":0,"stats":{"Line":0}},{"line":536,"address":[],"length":0,"stats":{"Line":0}},{"line":537,"address":[],"length":0,"stats":{"Line":0}},{"line":538,"address":[],"length":0,"stats":{"Line":0}},{"line":541,"address":[],"length":0,"stats":{"Line":0}},{"line":544,"address":[],"length":0,"stats":{"Line":0}},{"line":546,"address":[],"length":0,"stats":{"Line":0}},{"line":547,"address":[],"length":0,"stats":{"Line":0}},{"line":548,"address":[],"length":0,"stats":{"Line":0}},{"line":550,"address":[],"length":0,"stats":{"Line":0}},{"line":551,"address":[],"length":0,"stats":{"Line":0}},{"line":552,"address":[],"length":0,"stats":{"Line":0}},{"line":553,"address":[],"length":0,"stats":{"Line":0}},{"line":557,"address":[],"length":0,"stats":{"Line":0}},{"line":558,"address":[],"length":0,"stats":{"Line":0}},{"line":559,"address":[],"length":0,"stats":{"Line":0}},{"line":560,"address":[],"length":0,"stats":{"Line":0}},{"line":561,"address":[],"length":0,"stats":{"Line":0}},{"line":562,"address":[],"length":0,"stats":{"Line":0}},{"line":563,"address":[],"length":0,"stats":{"Line":0}},{"line":565,"address":[],"length":0,"stats":{"Line":0}},{"line":566,"address":[],"length":0,"stats":{"Line":0}},{"line":567,"address":[],"length":0,"stats":{"Line":0}},{"line":568,"address":[],"length":0,"stats":{"Line":0}},{"line":572,"address":[],"length":0,"stats":{"Line":0}},{"line":573,"address":[],"length":0,"stats":{"Line":0}},{"line":574,"address":[],"length":0,"stats":{"Line":0}},{"line":575,"address":[],"length":0,"stats":{"Line":0}},{"line":578,"address":[],"length":0,"stats":{"Line":0}},{"line":579,"address":[],"length":0,"stats":{"Line":0}},{"line":580,"address":[],"length":0,"stats":{"Line":0}},{"line":581,"address":[],"length":0,"stats":{"Line":0}},{"line":582,"address":[],"length":0,"stats":{"Line":0}},{"line":583,"address":[],"length":0,"stats":{"Line":0}},{"line":584,"address":[],"length":0,"stats":{"Line":0}},{"line":585,"address":[],"length":0,"stats":{"Line":0}},{"line":586,"address":[],"length":0,"stats":{"Line":0}},{"line":587,"address":[],"length":0,"stats":{"Line":0}},{"line":589,"address":[],"length":0,"stats":{"Line":0}},{"line":591,"address":[],"length":0,"stats":{"Line":0}},{"line":592,"address":[],"length":0,"stats":{"Line":0}},{"line":593,"address":[],"length":0,"stats":{"Line":0}},{"line":594,"address":[],"length":0,"stats":{"Line":0}},{"line":595,"address":[],"length":0,"stats":{"Line":0}},{"line":596,"address":[],"length":0,"stats":{"Line":0}},{"line":597,"address":[],"length":0,"stats":{"Line":0}},{"line":598,"address":[],"length":0,"stats":{"Line":0}},{"line":600,"address":[],"length":0,"stats":{"Line":0}},{"line":601,"address":[],"length":0,"stats":{"Line":0}},{"line":602,"address":[],"length":0,"stats":{"Line":0}},{"line":605,"address":[],"length":0,"stats":{"Line":0}},{"line":608,"address":[],"length":0,"stats":{"Line":35}},{"line":609,"address":[],"length":0,"stats":{"Line":35}},{"line":610,"address":[],"length":0,"stats":{"Line":68}},{"line":612,"address":[],"length":0,"stats":{"Line":1}},{"line":616,"address":[],"length":0,"stats":{"Line":13}},{"line":617,"address":[],"length":0,"stats":{"Line":26}},{"line":618,"address":[],"length":0,"stats":{"Line":3}},{"line":620,"address":[],"length":0,"stats":{"Line":24}},{"line":624,"address":[],"length":0,"stats":{"Line":19}},{"line":625,"address":[],"length":0,"stats":{"Line":19}},{"line":626,"address":[],"length":0,"stats":{"Line":21}},{"line":627,"address":[],"length":0,"stats":{"Line":19}},{"line":628,"address":[],"length":0,"stats":{"Line":16}},{"line":629,"address":[],"length":0,"stats":{"Line":17}},{"line":630,"address":[],"length":0,"stats":{"Line":15}},{"line":631,"address":[],"length":0,"stats":{"Line":10}},{"line":632,"address":[],"length":0,"stats":{"Line":6}},{"line":633,"address":[],"length":0,"stats":{"Line":2}},{"line":637,"address":[],"length":0,"stats":{"Line":0}},{"line":638,"address":[],"length":0,"stats":{"Line":0}},{"line":639,"address":[],"length":0,"stats":{"Line":0}},{"line":641,"address":[],"length":0,"stats":{"Line":0}},{"line":642,"address":[],"length":0,"stats":{"Line":0}},{"line":643,"address":[],"length":0,"stats":{"Line":0}},{"line":644,"address":[],"length":0,"stats":{"Line":0}},{"line":647,"address":[],"length":0,"stats":{"Line":0}},{"line":648,"address":[],"length":0,"stats":{"Line":0}},{"line":649,"address":[],"length":0,"stats":{"Line":0}},{"line":650,"address":[],"length":0,"stats":{"Line":0}},{"line":653,"address":[],"length":0,"stats":{"Line":0}},{"line":654,"address":[],"length":0,"stats":{"Line":0}},{"line":655,"address":[],"length":0,"stats":{"Line":0}},{"line":656,"address":[],"length":0,"stats":{"Line":0}},{"line":659,"address":[],"length":0,"stats":{"Line":0}},{"line":660,"address":[],"length":0,"stats":{"Line":0}},{"line":661,"address":[],"length":0,"stats":{"Line":0}},{"line":662,"address":[],"length":0,"stats":{"Line":0}},{"line":665,"address":[],"length":0,"stats":{"Line":0}},{"line":666,"address":[],"length":0,"stats":{"Line":0}},{"line":667,"address":[],"length":0,"stats":{"Line":0}},{"line":668,"address":[],"length":0,"stats":{"Line":0}},{"line":669,"address":[],"length":0,"stats":{"Line":0}},{"line":670,"address":[],"length":0,"stats":{"Line":0}},{"line":671,"address":[],"length":0,"stats":{"Line":0}},{"line":672,"address":[],"length":0,"stats":{"Line":0}},{"line":673,"address":[],"length":0,"stats":{"Line":0}},{"line":674,"address":[],"length":0,"stats":{"Line":0}},{"line":675,"address":[],"length":0,"stats":{"Line":0}},{"line":676,"address":[],"length":0,"stats":{"Line":0}},{"line":677,"address":[],"length":0,"stats":{"Line":0}},{"line":678,"address":[],"length":0,"stats":{"Line":0}},{"line":680,"address":[],"length":0,"stats":{"Line":0}},{"line":682,"address":[],"length":0,"stats":{"Line":0}},{"line":684,"address":[],"length":0,"stats":{"Line":0}},{"line":685,"address":[],"length":0,"stats":{"Line":0}},{"line":686,"address":[],"length":0,"stats":{"Line":0}},{"line":687,"address":[],"length":0,"stats":{"Line":0}},{"line":688,"address":[],"length":0,"stats":{"Line":0}},{"line":689,"address":[],"length":0,"stats":{"Line":0}},{"line":690,"address":[],"length":0,"stats":{"Line":0}},{"line":692,"address":[],"length":0,"stats":{"Line":0}},{"line":693,"address":[],"length":0,"stats":{"Line":0}},{"line":694,"address":[],"length":0,"stats":{"Line":0}},{"line":695,"address":[],"length":0,"stats":{"Line":0}},{"line":696,"address":[],"length":0,"stats":{"Line":0}},{"line":697,"address":[],"length":0,"stats":{"Line":0}},{"line":699,"address":[],"length":0,"stats":{"Line":0}},{"line":700,"address":[],"length":0,"stats":{"Line":0}},{"line":701,"address":[],"length":0,"stats":{"Line":0}},{"line":702,"address":[],"length":0,"stats":{"Line":0}},{"line":704,"address":[],"length":0,"stats":{"Line":0}},{"line":705,"address":[],"length":0,"stats":{"Line":0}},{"line":707,"address":[],"length":0,"stats":{"Line":0}},{"line":708,"address":[],"length":0,"stats":{"Line":0}},{"line":709,"address":[],"length":0,"stats":{"Line":0}},{"line":711,"address":[],"length":0,"stats":{"Line":0}},{"line":714,"address":[],"length":0,"stats":{"Line":0}},{"line":715,"address":[],"length":0,"stats":{"Line":0}},{"line":716,"address":[],"length":0,"stats":{"Line":0}},{"line":717,"address":[],"length":0,"stats":{"Line":0}},{"line":719,"address":[],"length":0,"stats":{"Line":0}},{"line":720,"address":[],"length":0,"stats":{"Line":0}},{"line":722,"address":[],"length":0,"stats":{"Line":0}},{"line":723,"address":[],"length":0,"stats":{"Line":0}},{"line":726,"address":[],"length":0,"stats":{"Line":0}},{"line":727,"address":[],"length":0,"stats":{"Line":0}},{"line":728,"address":[],"length":0,"stats":{"Line":0}},{"line":729,"address":[],"length":0,"stats":{"Line":0}},{"line":730,"address":[],"length":0,"stats":{"Line":0}},{"line":731,"address":[],"length":0,"stats":{"Line":0}},{"line":732,"address":[],"length":0,"stats":{"Line":0}},{"line":733,"address":[],"length":0,"stats":{"Line":0}},{"line":734,"address":[],"length":0,"stats":{"Line":0}},{"line":736,"address":[],"length":0,"stats":{"Line":0}},{"line":738,"address":[],"length":0,"stats":{"Line":0}},{"line":739,"address":[],"length":0,"stats":{"Line":0}},{"line":740,"address":[],"length":0,"stats":{"Line":0}},{"line":741,"address":[],"length":0,"stats":{"Line":0}},{"line":742,"address":[],"length":0,"stats":{"Line":0}},{"line":743,"address":[],"length":0,"stats":{"Line":0}},{"line":744,"address":[],"length":0,"stats":{"Line":0}},{"line":746,"address":[],"length":0,"stats":{"Line":0}},{"line":747,"address":[],"length":0,"stats":{"Line":0}},{"line":748,"address":[],"length":0,"stats":{"Line":0}},{"line":751,"address":[],"length":0,"stats":{"Line":0}}],"covered":141,"coverable":390},{"path":["/","Users","christian.klat","dev","git","aeterna","cli","src","commands","mod.rs"],"content":"pub mod admin;\npub mod agent;\npub mod check;\npub mod completion;\npub mod context;\npub mod govern;\npub mod hints;\npub mod init;\npub mod knowledge;\npub mod memory;\npub mod org;\npub mod policy;\npub mod status;\npub mod sync;\npub mod team;\npub mod user;\n\nuse clap::{Parser, Subcommand};\n\n#[derive(Parser)]\n#[command(\n    name = \"aeterna\",\n    author,\n    version,\n    about = \"Aeterna - Universal Memory & Knowledge Framework\",\n    long_about = \"A breeze to setup. Sensible defaults for everything.\\n\\n\\\n        Commands work without configuration - just run them.\\n\\\n        Context is auto-detected from git, env vars, or .aeterna/context.toml\"\n)]\npub struct Cli {\n    #[command(subcommand)]\n    pub command: Commands,\n}\n\n#[derive(Subcommand)]\npub enum Commands {\n    #[command(about = \"Initialize Aeterna in current directory\")]\n    Init(init::InitArgs),\n\n    #[command(about = \"Show current context and system status\")]\n    Status(status::StatusArgs),\n\n    #[command(about = \"Sync memory and knowledge systems\")]\n    Sync(sync::SyncArgs),\n\n    #[command(about = \"Run constraint validation checks\")]\n    Check(check::CheckArgs),\n\n    #[command(subcommand, about = \"Manage context (tenant, user, project, etc.)\")]\n    Context(context::ContextCommand),\n\n    #[command(subcommand, about = \"Manage operation hints (presets, toggles)\")]\n    Hints(hints::HintsCommand),\n\n    #[command(subcommand, about = \"Search, add, and manage memories\")]\n    Memory(memory::MemoryCommand),\n\n    #[command(subcommand, about = \"Search, get, and check knowledge\")]\n    Knowledge(knowledge::KnowledgeCommand),\n\n    #[command(subcommand, about = \"Create, validate, and manage policies\")]\n    Policy(policy::PolicyCommand),\n\n    #[command(subcommand, about = \"Manage organizations\")]\n    Org(org::OrgCommand),\n\n    #[command(subcommand, about = \"Manage teams\")]\n    Team(team::TeamCommand),\n\n    #[command(subcommand, about = \"Manage users and roles\")]\n    User(user::UserCommand),\n\n    #[command(subcommand, about = \"Manage AI agents and permissions\")]\n    Agent(agent::AgentCommand),\n\n    #[command(subcommand, about = \"Governance workflow (approve, reject, audit)\")]\n    Govern(govern::GovernCommand),\n\n    #[command(subcommand, about = \"System administration (health, migrate, export)\")]\n    Admin(admin::AdminCommand),\n\n    #[command(about = \"Generate shell completions\")]\n    Completion(completion::CompletionArgs),\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","cli","src","commands","org.rs"],"content":"use clap::{Args, Subcommand};\nuse context::ContextResolver;\nuse serde_json::json;\n\nuse crate::output;\nuse crate::ux_error;\n\n#[derive(Subcommand)]\npub enum OrgCommand {\n    #[command(about = \"Create a new organization\")]\n    Create(OrgCreateArgs),\n\n    #[command(about = \"List organizations in your company\")]\n    List(OrgListArgs),\n\n    #[command(about = \"Show organization details\")]\n    Show(OrgShowArgs),\n\n    #[command(about = \"Manage organization members\")]\n    Members(OrgMembersArgs),\n\n    #[command(about = \"Set default organization for current context\")]\n    Use(OrgUseArgs),\n}\n\n#[derive(Args)]\npub struct OrgCreateArgs {\n    /// Organization name\n    pub name: String,\n\n    /// Organization description\n    #[arg(short, long)]\n    pub description: Option<String>,\n\n    /// Parent company ID (auto-detected if not provided)\n    #[arg(long)]\n    pub company: Option<String>,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n\n    /// Dry run - show what would be created\n    #[arg(long)]\n    pub dry_run: bool,\n}\n\n#[derive(Args)]\npub struct OrgListArgs {\n    /// Filter by company\n    #[arg(long)]\n    pub company: Option<String>,\n\n    /// Show all organizations you have access to\n    #[arg(long)]\n    pub all: bool,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct OrgShowArgs {\n    /// Organization ID (uses current context if not provided)\n    pub org_id: Option<String>,\n\n    /// Show full details including policies and teams\n    #[arg(short, long)]\n    pub verbose: bool,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct OrgMembersArgs {\n    /// Organization ID (uses current context if not provided)\n    #[arg(long)]\n    pub org: Option<String>,\n\n    /// Add member by user ID\n    #[arg(long)]\n    pub add: Option<String>,\n\n    /// Remove member by user ID\n    #[arg(long)]\n    pub remove: Option<String>,\n\n    /// Set role for a member (with --add or --set-role)\n    #[arg(long, value_name = \"USER_ID\")]\n    pub set_role: Option<String>,\n\n    /// Role to assign (developer, techlead, architect, admin)\n    #[arg(long)]\n    pub role: Option<String>,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct OrgUseArgs {\n    /// Organization ID to set as default\n    pub org_id: String,\n}\n\npub async fn run(cmd: OrgCommand) -> anyhow::Result<()> {\n    match cmd {\n        OrgCommand::Create(args) => run_create(args).await,\n        OrgCommand::List(args) => run_list(args).await,\n        OrgCommand::Show(args) => run_show(args).await,\n        OrgCommand::Members(args) => run_members(args).await,\n        OrgCommand::Use(args) => run_use(args).await,\n    }\n}\n\nasync fn run_create(args: OrgCreateArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    let company_id = args\n        .company\n        .clone()\n        .unwrap_or_else(|| resolved.tenant_id.value.clone());\n\n    if args.dry_run {\n        if args.json {\n            let output = json!({\n                \"dryRun\": true,\n                \"operation\": \"org_create\",\n                \"org\": {\n                    \"name\": args.name,\n                    \"description\": args.description,\n                    \"companyId\": company_id,\n                },\n                \"context\": {\n                    \"tenantId\": resolved.tenant_id.value,\n                    \"userId\": resolved.user_id.value,\n                },\n                \"nextSteps\": [\n                    \"Review organization configuration\",\n                    \"Run without --dry-run to create\",\n                    \"Add members with 'aeterna org members --add <user>'\",\n                    \"Create teams with 'aeterna team create <name> --org <org-id>'\"\n                ]\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Organization Create (Dry Run)\");\n            println!();\n            println!(\"  Name:        {}\", args.name);\n            if let Some(ref desc) = args.description {\n                println!(\"  Description: {}\", desc);\n            }\n            println!(\"  Company:     {}\", company_id);\n            println!();\n\n            output::header(\"What Would Happen\");\n            println!(\n                \"  1. Create organization '{}' under company '{}'\",\n                args.name, company_id\n            );\n            println!(\"  2. Add you ({}) as org admin\", resolved.user_id.value);\n            println!(\"  3. Inherit company-level policies\");\n            println!();\n\n            output::header(\"Next Steps\");\n            println!(\"  1. Run without --dry-run to create the organization\");\n            println!(\"  2. Add members: aeterna org members --add <user-id>\");\n            println!(\n                \"  3. Create teams: aeterna team create <name> --org {}\",\n                args.name\n            );\n            println!();\n\n            output::info(\"Dry run mode - organization not created.\");\n        }\n        return Ok(());\n    }\n\n    let err = ux_error::server_not_connected();\n    err.display();\n    output::info(\"Run with --dry-run to see what would be created.\");\n\n    Ok(())\n}\n\nasync fn run_list(args: OrgListArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"org_list\",\n            \"filters\": {\n                \"company\": args.company,\n                \"all\": args.all,\n            },\n            \"context\": {\n                \"tenantId\": resolved.tenant_id.value,\n                \"userId\": resolved.user_id.value,\n            },\n            \"status\": \"not_connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(\"Organizations\");\n        println!();\n\n        if args.all {\n            output::info(\"Showing all organizations you have access to.\");\n        }\n\n        if let Some(ref company) = args.company {\n            println!(\"  Filter: company = {}\", company);\n        }\n        println!();\n\n        output::header(\"Example Output (would show)\");\n        println!(\"  ID                  NAME                 TEAMS  MEMBERS  ROLE\");\n        println!(\"  platform-eng        Platform Engineering   3       12    admin\");\n        println!(\"  product-eng         Product Engineering    2        8    member\");\n        println!(\"  security            Security               1        4    member\");\n        println!();\n\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nasync fn run_show(args: OrgShowArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    let org_id = args.org_id.clone().unwrap_or_else(|| {\n        resolved\n            .org_id\n            .as_ref()\n            .map(|o| o.value.clone())\n            .unwrap_or_else(|| \"current\".to_string())\n    });\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"org_show\",\n            \"orgId\": org_id,\n            \"verbose\": args.verbose,\n            \"context\": {\n                \"tenantId\": resolved.tenant_id.value,\n                \"userId\": resolved.user_id.value,\n            },\n            \"status\": \"not_connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(&format!(\"Organization: {}\", org_id));\n        println!();\n\n        output::header(\"Would Show\");\n        println!(\"  - Name and description\");\n        println!(\"  - Parent company\");\n        println!(\"  - Teams count\");\n        println!(\"  - Members count and roles\");\n        println!(\"  - Your role in this org\");\n\n        if args.verbose {\n            println!();\n            output::header(\"Verbose Details\");\n            println!(\"  - List of teams\");\n            println!(\"  - Member list with roles\");\n            println!(\"  - Active policies\");\n            println!(\"  - Policy inheritance chain\");\n        }\n        println!();\n\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nasync fn run_members(args: OrgMembersArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    let org_id = args.org.clone().unwrap_or_else(|| {\n        resolved\n            .org_id\n            .as_ref()\n            .map(|o| o.value.clone())\n            .unwrap_or_else(|| \"current\".to_string())\n    });\n\n    if let Some(ref user_to_add) = args.add {\n        let role = args.role.clone().unwrap_or_else(|| \"developer\".to_string());\n\n        let valid_roles = [\"developer\", \"techlead\", \"architect\", \"admin\"];\n        if !valid_roles.contains(&role.to_lowercase().as_str()) {\n            let err = ux_error::UxError::new(format!(\"Invalid role: '{}'\", role))\n                .why(\"Role determines user permissions within the organization\")\n                .fix(\"Use one of: developer, techlead, architect, admin\")\n                .suggest(&format!(\n                    \"aeterna org members --add {} --role developer\",\n                    user_to_add\n                ));\n            err.display();\n            return Err(anyhow::anyhow!(\"Invalid role\"));\n        }\n\n        if args.json {\n            let output = json!({\n                \"operation\": \"org_member_add\",\n                \"orgId\": org_id,\n                \"userId\": user_to_add,\n                \"role\": role,\n                \"status\": \"not_connected\"\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Add Organization Member\");\n            println!();\n            println!(\"  Organization: {}\", org_id);\n            println!(\"  User:         {}\", user_to_add);\n            println!(\"  Role:         {}\", role);\n            println!();\n\n            output::header(\"Would Do\");\n            println!(\"  1. Verify user '{}' exists\", user_to_add);\n            println!(\"  2. Check your permission to add members\");\n            println!(\"  3. Add user with role '{}'\", role);\n            println!(\"  4. Grant access to org resources\");\n            println!();\n\n            let err = ux_error::server_not_connected();\n            err.display();\n        }\n        return Ok(());\n    }\n\n    if let Some(ref user_to_remove) = args.remove {\n        if args.json {\n            let output = json!({\n                \"operation\": \"org_member_remove\",\n                \"orgId\": org_id,\n                \"userId\": user_to_remove,\n                \"status\": \"not_connected\"\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Remove Organization Member\");\n            println!();\n            println!(\"  Organization: {}\", org_id);\n            println!(\"  User:         {}\", user_to_remove);\n            println!();\n\n            output::header(\"Would Do\");\n            println!(\"  1. Check your permission to remove members\");\n            println!(\"  2. Remove user from organization\");\n            println!(\"  3. Revoke access to org resources\");\n            println!(\"  4. Remove from all teams in this org\");\n            println!();\n\n            let err = ux_error::server_not_connected();\n            err.display();\n        }\n        return Ok(());\n    }\n\n    if let Some(ref user_id) = args.set_role {\n        let role = args.role.clone().ok_or_else(|| {\n            let err = ux_error::UxError::new(\"Missing --role for --set-role\")\n                .why(\"Must specify which role to assign\")\n                .fix(\"Add --role with the desired role\")\n                .suggest(&format!(\n                    \"aeterna org members --set-role {} --role techlead\",\n                    user_id\n                ));\n            err.display();\n            anyhow::anyhow!(\"Missing role\")\n        })?;\n\n        if args.json {\n            let output = json!({\n                \"operation\": \"org_member_set_role\",\n                \"orgId\": org_id,\n                \"userId\": user_id,\n                \"newRole\": role,\n                \"status\": \"not_connected\"\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Set Member Role\");\n            println!();\n            println!(\"  Organization: {}\", org_id);\n            println!(\"  User:         {}\", user_id);\n            println!(\"  New Role:     {}\", role);\n            println!();\n\n            let err = ux_error::server_not_connected();\n            err.display();\n        }\n        return Ok(());\n    }\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"org_members_list\",\n            \"orgId\": org_id,\n            \"context\": {\n                \"tenantId\": resolved.tenant_id.value,\n                \"userId\": resolved.user_id.value,\n            },\n            \"status\": \"not_connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(&format!(\"Members of: {}\", org_id));\n        println!();\n\n        output::header(\"Example Output (would show)\");\n        println!(\"  USER ID              NAME               ROLE        TEAMS\");\n        println!(\"  alice@acme.com       Alice Smith        admin       api, data\");\n        println!(\"  bob@acme.com         Bob Jones          techlead    api\");\n        println!(\"  carol@acme.com       Carol Williams     developer   web\");\n        println!();\n\n        output::header(\"Actions\");\n        println!(\"  Add member:    aeterna org members --add <user> --role <role>\");\n        println!(\"  Remove member: aeterna org members --remove <user>\");\n        println!(\"  Change role:   aeterna org members --set-role <user> --role <role>\");\n        println!();\n\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nasync fn run_use(args: OrgUseArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let _resolved = resolver.resolve()?;\n\n    output::header(\"Set Default Organization\");\n    println!();\n    println!(\"  Setting default org: {}\", args.org_id);\n    println!();\n\n    output::header(\"Would Update\");\n    println!(\"  File: .aeterna/context.toml\");\n    println!(\"  org_id = \\\"{}\\\"\", args.org_id);\n    println!();\n\n    output::header(\"Effect\");\n    println!(\"  - All commands will use '{}' as default org\", args.org_id);\n    println!(\"  - Team/project commands scoped to this org\");\n    println!(\"  - Policies from this org will apply\");\n    println!();\n\n    let err = ux_error::server_not_connected();\n    err.display();\n\n    Ok(())\n}\n","traces":[{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":204,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":223,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":225,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":240,"address":[],"length":0,"stats":{"Line":0}},{"line":241,"address":[],"length":0,"stats":{"Line":0}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":0}},{"line":252,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":0}},{"line":254,"address":[],"length":0,"stats":{"Line":0}},{"line":255,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":264,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":0}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":272,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":274,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":276,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":0}},{"line":321,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":333,"address":[],"length":0,"stats":{"Line":0}},{"line":334,"address":[],"length":0,"stats":{"Line":0}},{"line":335,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":337,"address":[],"length":0,"stats":{"Line":0}},{"line":338,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":343,"address":[],"length":0,"stats":{"Line":0}},{"line":346,"address":[],"length":0,"stats":{"Line":0}},{"line":347,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":0}},{"line":350,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":354,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":358,"address":[],"length":0,"stats":{"Line":0}},{"line":359,"address":[],"length":0,"stats":{"Line":0}},{"line":360,"address":[],"length":0,"stats":{"Line":0}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":363,"address":[],"length":0,"stats":{"Line":0}},{"line":364,"address":[],"length":0,"stats":{"Line":0}},{"line":365,"address":[],"length":0,"stats":{"Line":0}},{"line":366,"address":[],"length":0,"stats":{"Line":0}},{"line":367,"address":[],"length":0,"stats":{"Line":0}},{"line":369,"address":[],"length":0,"stats":{"Line":0}},{"line":370,"address":[],"length":0,"stats":{"Line":0}},{"line":372,"address":[],"length":0,"stats":{"Line":0}},{"line":375,"address":[],"length":0,"stats":{"Line":0}},{"line":376,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":378,"address":[],"length":0,"stats":{"Line":0}},{"line":379,"address":[],"length":0,"stats":{"Line":0}},{"line":380,"address":[],"length":0,"stats":{"Line":0}},{"line":381,"address":[],"length":0,"stats":{"Line":0}},{"line":382,"address":[],"length":0,"stats":{"Line":0}},{"line":384,"address":[],"length":0,"stats":{"Line":0}},{"line":385,"address":[],"length":0,"stats":{"Line":0}},{"line":388,"address":[],"length":0,"stats":{"Line":0}},{"line":389,"address":[],"length":0,"stats":{"Line":0}},{"line":390,"address":[],"length":0,"stats":{"Line":0}},{"line":391,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":0}},{"line":393,"address":[],"length":0,"stats":{"Line":0}},{"line":394,"address":[],"length":0,"stats":{"Line":0}},{"line":396,"address":[],"length":0,"stats":{"Line":0}},{"line":398,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":400,"address":[],"length":0,"stats":{"Line":0}},{"line":401,"address":[],"length":0,"stats":{"Line":0}},{"line":402,"address":[],"length":0,"stats":{"Line":0}},{"line":403,"address":[],"length":0,"stats":{"Line":0}},{"line":405,"address":[],"length":0,"stats":{"Line":0}},{"line":406,"address":[],"length":0,"stats":{"Line":0}},{"line":408,"address":[],"length":0,"stats":{"Line":0}},{"line":411,"address":[],"length":0,"stats":{"Line":0}},{"line":412,"address":[],"length":0,"stats":{"Line":0}},{"line":413,"address":[],"length":0,"stats":{"Line":0}},{"line":414,"address":[],"length":0,"stats":{"Line":0}},{"line":415,"address":[],"length":0,"stats":{"Line":0}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":417,"address":[],"length":0,"stats":{"Line":0}},{"line":419,"address":[],"length":0,"stats":{"Line":0}},{"line":421,"address":[],"length":0,"stats":{"Line":0}},{"line":423,"address":[],"length":0,"stats":{"Line":0}},{"line":424,"address":[],"length":0,"stats":{"Line":0}},{"line":426,"address":[],"length":0,"stats":{"Line":0}},{"line":427,"address":[],"length":0,"stats":{"Line":0}},{"line":428,"address":[],"length":0,"stats":{"Line":0}},{"line":429,"address":[],"length":0,"stats":{"Line":0}},{"line":430,"address":[],"length":0,"stats":{"Line":0}},{"line":431,"address":[],"length":0,"stats":{"Line":0}},{"line":433,"address":[],"length":0,"stats":{"Line":0}},{"line":434,"address":[],"length":0,"stats":{"Line":0}},{"line":435,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":0}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":443,"address":[],"length":0,"stats":{"Line":0}},{"line":446,"address":[],"length":0,"stats":{"Line":0}},{"line":447,"address":[],"length":0,"stats":{"Line":0}},{"line":448,"address":[],"length":0,"stats":{"Line":0}},{"line":450,"address":[],"length":0,"stats":{"Line":0}},{"line":451,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":453,"address":[],"length":0,"stats":{"Line":0}},{"line":455,"address":[],"length":0,"stats":{"Line":0}},{"line":456,"address":[],"length":0,"stats":{"Line":0}},{"line":457,"address":[],"length":0,"stats":{"Line":0}},{"line":458,"address":[],"length":0,"stats":{"Line":0}},{"line":460,"address":[],"length":0,"stats":{"Line":0}},{"line":461,"address":[],"length":0,"stats":{"Line":0}},{"line":462,"address":[],"length":0,"stats":{"Line":0}},{"line":463,"address":[],"length":0,"stats":{"Line":0}},{"line":464,"address":[],"length":0,"stats":{"Line":0}},{"line":466,"address":[],"length":0,"stats":{"Line":0}},{"line":467,"address":[],"length":0,"stats":{"Line":0}},{"line":469,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":255},{"path":["/","Users","christian.klat","dev","git","aeterna","cli","src","commands","policy.rs"],"content":"use clap::{Args, Subcommand};\nuse context::ContextResolver;\nuse mk_core::hints::{HintPreset, OperationHints};\nuse serde_json::json;\n\nuse crate::output;\nuse crate::ux_error;\n\n#[derive(Subcommand)]\npub enum PolicyCommand {\n    #[command(about = \"Create a new policy from natural language or template\")]\n    Create(PolicyCreateArgs),\n\n    #[command(about = \"List policies in the current context\")]\n    List(PolicyListArgs),\n\n    #[command(about = \"Explain a policy in natural language\")]\n    Explain(PolicyExplainArgs),\n\n    #[command(about = \"Simulate a policy against a scenario\")]\n    Simulate(PolicySimulateArgs),\n\n    #[command(about = \"Validate a policy definition\")]\n    Validate(PolicyValidateArgs),\n\n    #[command(about = \"Show policy draft details\")]\n    Draft(PolicyDraftArgs),\n}\n\n#[derive(Args)]\npub struct PolicyCreateArgs {\n    /// Policy description in natural language\n    /// Example: \"Block all dependencies with critical CVEs\"\n    #[arg(long)]\n    pub description: Option<String>,\n\n    /// Policy name (auto-generated if not provided)\n    #[arg(short, long)]\n    pub name: Option<String>,\n\n    /// Layer to apply policy (company, org, team, project)\n    #[arg(short, long, default_value = \"project\")]\n    pub layer: String,\n\n    /// Policy mode (mandatory, optional)\n    #[arg(long, default_value = \"mandatory\")]\n    pub mode: String,\n\n    /// Use a template instead of natural language\n    /// Templates: security-baseline, code-style, dependency-audit\n    #[arg(long)]\n    pub template: Option<String>,\n\n    /// Target type for the rule (dependency, file, code, config)\n    #[arg(long)]\n    pub target: Option<String>,\n\n    /// Severity level (info, warn, error, block)\n    #[arg(long, default_value = \"warn\")]\n    pub severity: String,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n\n    /// Dry run - show what would be created without saving\n    #[arg(long)]\n    pub dry_run: bool,\n\n    /// Hints preset\n    #[arg(long)]\n    pub preset: Option<String>,\n}\n\n#[derive(Args)]\npub struct PolicyListArgs {\n    /// Filter by layer (company, org, team, project)\n    #[arg(short, long)]\n    pub layer: Option<String>,\n\n    /// Filter by mode (mandatory, optional)\n    #[arg(long)]\n    pub mode: Option<String>,\n\n    /// Show all policies including inherited\n    #[arg(long)]\n    pub all: bool,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct PolicyExplainArgs {\n    /// Policy ID to explain\n    pub policy_id: String,\n\n    /// Include rule details\n    #[arg(short, long)]\n    pub verbose: bool,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct PolicySimulateArgs {\n    /// Policy ID to simulate\n    pub policy_id: String,\n\n    /// Scenario type to simulate (dependency-add, file-create, code-change)\n    #[arg(long)]\n    pub scenario: String,\n\n    /// Scenario input (e.g., dependency name, file path)\n    #[arg(long)]\n    pub input: String,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n\n    /// Dry run - show simulation setup without executing\n    #[arg(long)]\n    pub dry_run: bool,\n}\n\n#[derive(Args)]\npub struct PolicyValidateArgs {\n    /// Policy ID to validate (or path to policy file)\n    pub policy: String,\n\n    /// Strict validation mode\n    #[arg(long)]\n    pub strict: bool,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct PolicyDraftArgs {\n    /// Draft ID to show\n    pub draft_id: Option<String>,\n\n    /// List all pending drafts\n    #[arg(short, long)]\n    pub list: bool,\n\n    /// Submit draft for approval\n    #[arg(long)]\n    pub submit: Option<String>,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\npub async fn run(cmd: PolicyCommand) -> anyhow::Result<()> {\n    match cmd {\n        PolicyCommand::Create(args) => run_create(args).await,\n        PolicyCommand::List(args) => run_list(args).await,\n        PolicyCommand::Explain(args) => run_explain(args).await,\n        PolicyCommand::Simulate(args) => run_simulate(args).await,\n        PolicyCommand::Validate(args) => run_validate(args).await,\n        PolicyCommand::Draft(args) => run_draft(args).await,\n    }\n}\n\nasync fn run_create(args: PolicyCreateArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    // Validate layer\n    let layer = args.layer.to_lowercase();\n    let valid_layers = [\"company\", \"org\", \"team\", \"project\"];\n    if !valid_layers.contains(&layer.as_str()) {\n        let err = ux_error::invalid_knowledge_layer(&layer);\n        err.display();\n        return Err(anyhow::anyhow!(\"Invalid layer\"));\n    }\n\n    // Validate mode\n    let mode = args.mode.to_lowercase();\n    let valid_modes = [\"mandatory\", \"optional\"];\n    if !valid_modes.contains(&mode.as_str()) {\n        let err = ux_error::UxError::new(format!(\"Invalid policy mode: '{}'\", mode))\n            .why(\"Policy mode determines if violations block operations\")\n            .fix(\"Use 'mandatory' (blocks on violation) or 'optional' (warns only)\")\n            .suggest(\"aeterna policy create --mode mandatory --description \\\"...\\\"\");\n        err.display();\n        return Err(anyhow::anyhow!(\"Invalid mode\"));\n    }\n\n    // Validate severity\n    let severity = args.severity.to_lowercase();\n    let valid_severities = [\"info\", \"warn\", \"error\", \"block\"];\n    if !valid_severities.contains(&severity.as_str()) {\n        let err = ux_error::UxError::new(format!(\"Invalid severity: '{}'\", severity))\n            .why(\"Severity determines how violations are reported\")\n            .fix(\"Use one of: info, warn, error, block\")\n            .suggest(\"aeterna policy create --severity warn --description \\\"...\\\"\");\n        err.display();\n        return Err(anyhow::anyhow!(\"Invalid severity\"));\n    }\n\n    // Determine hints\n    let hints = if let Some(preset_str) = &args.preset {\n        let preset: HintPreset = preset_str.parse().map_err(|_| {\n            let err = ux_error::invalid_preset(preset_str);\n            err.display();\n            anyhow::anyhow!(\"Invalid preset\")\n        })?;\n        OperationHints::from_preset(preset)\n    } else {\n        resolved.to_hints()\n    };\n\n    // Check what we have to work with\n    let has_description = args.description.is_some();\n    let has_template = args.template.is_some();\n\n    if !has_description && !has_template {\n        let err = ux_error::UxError::new(\"Policy creation requires description or template\")\n            .why(\"Either describe the policy in natural language or use a template\")\n            .fix(\"Provide --description with a natural language policy description\")\n            .fix(\"Or use --template to start from a predefined template\")\n            .suggest(\n                \"aeterna policy create --description \\\"Block dependencies with critical CVEs\\\"\",\n            );\n        err.display();\n        return Err(anyhow::anyhow!(\"Missing description or template\"));\n    }\n\n    // Generate policy name if not provided\n    let policy_name = args.name.unwrap_or_else(|| {\n        if let Some(ref desc) = args.description {\n            // Generate from description (first 3-4 words, kebab-case)\n            let words: Vec<&str> = desc.split_whitespace().take(4).collect();\n            words.join(\"-\").to_lowercase().replace(\"\\\"\", \"\")\n        } else if let Some(ref tmpl) = args.template {\n            format!(\"{}-policy\", tmpl)\n        } else {\n            \"new-policy\".to_string()\n        }\n    });\n\n    // Build the draft policy\n    let draft_id = format!(\n        \"draft-{}-{}\",\n        policy_name.replace(\" \", \"-\").to_lowercase(),\n        chrono::Utc::now().timestamp()\n    );\n\n    if args.dry_run {\n        if args.json {\n            let output = json!({\n                \"dryRun\": true,\n                \"operation\": \"policy_create\",\n                \"draft\": {\n                    \"id\": draft_id,\n                    \"name\": policy_name,\n                    \"description\": args.description,\n                    \"template\": args.template,\n                    \"layer\": layer,\n                    \"mode\": mode,\n                    \"severity\": severity,\n                },\n                \"context\": {\n                    \"tenantId\": resolved.tenant_id.value,\n                    \"userId\": resolved.user_id.value,\n                    \"projectId\": resolved.project_id.as_ref().map(|v| &v.value),\n                },\n                \"hints\": {\n                    \"preset\": format!(\"{}\", hints.preset),\n                    \"governance\": hints.governance,\n                    \"llm\": hints.llm,\n                },\n                \"nextSteps\": [\n                    \"Review the generated policy draft\",\n                    \"Run without --dry-run to create the draft\",\n                    \"Use 'aeterna policy draft --submit <id>' to submit for approval\"\n                ]\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Policy Create (Dry Run)\");\n            println!();\n            println!(\"  Draft ID:    {}\", draft_id);\n            println!(\"  Name:        {}\", policy_name);\n            println!(\"  Layer:       {}\", layer);\n            println!(\"  Mode:        {}\", mode);\n            println!(\"  Severity:    {}\", severity);\n            println!();\n\n            if let Some(ref desc) = args.description {\n                output::header(\"Natural Language Input\");\n                println!(\"  \\\"{}\\\"\", desc);\n                println!();\n                output::header(\"Translation Pipeline\");\n                println!(\n                    \"  1. Parse natural language  structured intent  {}\",\n                    hint_effect(hints.llm, \"uses LLM\")\n                );\n                println!(\"  2. Map intent  Cedar policy rules\");\n                println!(\"  3. Validate Cedar syntax\");\n                println!(\"  4. Store as draft for review\");\n                println!();\n            }\n\n            if let Some(ref tmpl) = args.template {\n                output::header(\"Template\");\n                println!(\"  Using template: {}\", tmpl);\n                let tmpl_desc = match tmpl.as_str() {\n                    \"security-baseline\" => \"Blocks critical CVEs, requires SECURITY.md\",\n                    \"code-style\" => \"Enforces code style and formatting rules\",\n                    \"dependency-audit\" => \"Audits dependencies for licenses and vulnerabilities\",\n                    _ => \"Custom template\",\n                };\n                println!(\"  Description: {}\", tmpl_desc);\n                println!();\n            }\n\n            output::header(\"Context\");\n            println!(\"  tenant_id:  {}\", resolved.tenant_id.value);\n            println!(\"  user_id:    {}\", resolved.user_id.value);\n            if let Some(project) = &resolved.project_id {\n                println!(\"  project_id: {}\", project.value);\n            }\n            println!();\n\n            output::header(\"Next Steps\");\n            println!(\"  1. Review the generated policy draft\");\n            println!(\"  2. Run without --dry-run to create the draft\");\n            println!(\n                \"  3. Use 'aeterna policy draft --submit {}' to submit for approval\",\n                draft_id\n            );\n            println!();\n\n            output::info(\"Dry run mode - policy draft not created.\");\n            output::info(\"Remove --dry-run to create the policy draft.\");\n        }\n        return Ok(());\n    }\n\n    // Not connected - show what would happen\n    let err = ux_error::server_not_connected();\n    err.display();\n    output::info(\"Run with --dry-run to see what would be created.\");\n\n    Ok(())\n}\n\nasync fn run_list(args: PolicyListArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    // Validate layer if provided\n    if let Some(ref layer) = args.layer {\n        let layer_lower = layer.to_lowercase();\n        let valid_layers = [\"company\", \"org\", \"team\", \"project\"];\n        if !valid_layers.contains(&layer_lower.as_str()) {\n            let err = ux_error::invalid_knowledge_layer(layer);\n            err.display();\n            return Err(anyhow::anyhow!(\"Invalid layer\"));\n        }\n    }\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"policy_list\",\n            \"filters\": {\n                \"layer\": args.layer,\n                \"mode\": args.mode,\n                \"includeInherited\": args.all,\n            },\n            \"context\": {\n                \"tenantId\": resolved.tenant_id.value,\n                \"userId\": resolved.user_id.value,\n                \"projectId\": resolved.project_id.as_ref().map(|v| &v.value),\n            },\n            \"status\": \"not_connected\",\n            \"message\": \"Policy backend not connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(\"Policies\");\n        println!();\n\n        if args.all {\n            output::info(\"Showing all policies including inherited from parent layers.\");\n        }\n\n        if let Some(ref layer) = args.layer {\n            println!(\"  Filter: layer = {}\", layer);\n        }\n        if let Some(ref mode) = args.mode {\n            println!(\"  Filter: mode = {}\", mode);\n        }\n        println!();\n\n        // Show example of what would be displayed\n        output::header(\"Policy Inheritance (would show)\");\n        println!(\"  company    Security Baseline (mandatory)\");\n        println!(\"  org        Platform Standards (mandatory)\");\n        println!(\"  team       API Team Conventions (optional)\");\n        println!(\"  project    [your policies here]\");\n        println!();\n\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nasync fn run_explain(args: PolicyExplainArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"policy_explain\",\n            \"policyId\": args.policy_id,\n            \"verbose\": args.verbose,\n            \"context\": {\n                \"tenantId\": resolved.tenant_id.value,\n                \"userId\": resolved.user_id.value,\n            },\n            \"status\": \"not_connected\",\n            \"message\": \"Policy backend not connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(&format!(\"Policy: {}\", args.policy_id));\n        println!();\n\n        // Example of what explanation would look like\n        output::header(\"Natural Language Explanation\");\n        println!(\"  This policy would be explained in plain English:\");\n        println!(\"  - What it does\");\n        println!(\"  - When it applies\");\n        println!(\"  - What happens when violated\");\n        println!();\n\n        if args.verbose {\n            output::header(\"Rule Details\");\n            println!(\"  Would show detailed rule breakdown:\");\n            println!(\"  - Target type\");\n            println!(\"  - Operator\");\n            println!(\"  - Expected values\");\n            println!(\"  - Severity levels\");\n            println!();\n        }\n\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nasync fn run_simulate(args: PolicySimulateArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    // Validate scenario type\n    let scenario = args.scenario.to_lowercase();\n    let valid_scenarios = [\n        \"dependency-add\",\n        \"file-create\",\n        \"code-change\",\n        \"config-update\",\n    ];\n    if !valid_scenarios.contains(&scenario.as_str()) {\n        let err = ux_error::UxError::new(format!(\"Invalid scenario type: '{}'\", scenario))\n            .why(\"Scenario type determines what kind of operation to simulate\")\n            .fix(\"Use one of: dependency-add, file-create, code-change, config-update\")\n            .suggest(\"aeterna policy simulate policy-1 --scenario dependency-add --input lodash\");\n        err.display();\n        return Err(anyhow::anyhow!(\"Invalid scenario type\"));\n    }\n\n    if args.dry_run {\n        if args.json {\n            let output = json!({\n                \"dryRun\": true,\n                \"operation\": \"policy_simulate\",\n                \"policyId\": args.policy_id,\n                \"scenario\": {\n                    \"type\": scenario,\n                    \"input\": args.input,\n                },\n                \"context\": {\n                    \"tenantId\": resolved.tenant_id.value,\n                    \"userId\": resolved.user_id.value,\n                    \"projectId\": resolved.project_id.as_ref().map(|v| &v.value),\n                },\n                \"wouldCheck\": [\n                    \"Policy rules matching the scenario type\",\n                    \"Input value against rule patterns\",\n                    \"Inheritance from parent layers\"\n                ]\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Policy Simulate (Dry Run)\");\n            println!();\n            println!(\"  Policy:   {}\", args.policy_id);\n            println!(\"  Scenario: {}\", scenario);\n            println!(\"  Input:    {}\", args.input);\n            println!();\n            output::header(\"Would Check\");\n            println!(\"  1. Policy rules matching scenario type '{}'\", scenario);\n            println!(\"  2. Input '{}' against rule patterns\", args.input);\n            println!(\"  3. Inherited policies from parent layers\");\n            println!();\n            output::header(\"Expected Output\");\n            println!(\"  - PASS / FAIL / WARN status\");\n            println!(\"  - Matching rules and their outcomes\");\n            println!(\"  - Suggested fixes for violations\");\n            println!();\n            output::info(\"Dry run mode - simulation not executed.\");\n            output::info(\"Remove --dry-run to run the simulation.\");\n        }\n        return Ok(());\n    }\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"policy_simulate\",\n            \"policyId\": args.policy_id,\n            \"scenario\": {\n                \"type\": scenario,\n                \"input\": args.input,\n            },\n            \"status\": \"not_connected\",\n            \"message\": \"Policy backend not connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(\"Policy Simulate\");\n        println!();\n        println!(\"  Policy:   {}\", args.policy_id);\n        println!(\"  Scenario: {}\", scenario);\n        println!(\"  Input:    {}\", args.input);\n        println!();\n        let err = ux_error::server_not_connected();\n        err.display();\n        output::info(\"Run with --dry-run to see what would be simulated.\");\n    }\n\n    Ok(())\n}\n\nasync fn run_validate(args: PolicyValidateArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"policy_validate\",\n            \"policy\": args.policy,\n            \"strict\": args.strict,\n            \"context\": {\n                \"tenantId\": resolved.tenant_id.value,\n                \"userId\": resolved.user_id.value,\n            },\n            \"status\": \"not_connected\",\n            \"message\": \"Policy backend not connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(&format!(\"Validate Policy: {}\", args.policy));\n        println!();\n\n        if args.strict {\n            output::info(\"Strict mode enabled - checking additional constraints.\");\n        }\n\n        output::header(\"Validation Steps\");\n        println!(\"  1. Parse policy structure\");\n        println!(\"  2. Validate Cedar syntax (if Cedar format)\");\n        println!(\"  3. Check rule consistency\");\n        println!(\"  4. Detect conflicts with existing policies\");\n        if args.strict {\n            println!(\"  5. Check for unreachable rules\");\n            println!(\"  6. Validate against meta-governance policies\");\n        }\n        println!();\n\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nasync fn run_draft(args: PolicyDraftArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    if args.list {\n        if args.json {\n            let output = json!({\n                \"operation\": \"policy_draft_list\",\n                \"context\": {\n                    \"tenantId\": resolved.tenant_id.value,\n                    \"userId\": resolved.user_id.value,\n                },\n                \"status\": \"not_connected\",\n                \"message\": \"Policy backend not connected\"\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Policy Drafts\");\n            println!();\n            output::info(\"Would show pending policy drafts created by you.\");\n            println!();\n            let err = ux_error::server_not_connected();\n            err.display();\n        }\n        return Ok(());\n    }\n\n    if let Some(ref submit_id) = args.submit {\n        if args.json {\n            let output = json!({\n                \"operation\": \"policy_draft_submit\",\n                \"draftId\": submit_id,\n                \"context\": {\n                    \"tenantId\": resolved.tenant_id.value,\n                    \"userId\": resolved.user_id.value,\n                },\n                \"status\": \"not_connected\",\n                \"message\": \"Policy backend not connected\"\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(&format!(\"Submit Draft: {}\", submit_id));\n            println!();\n            output::header(\"Submission Workflow\");\n            println!(\"  1. Validate draft policy\");\n            println!(\"  2. Check permissions (can you propose policies?)\");\n            println!(\"  3. Create approval request\");\n            println!(\"  4. Notify approvers based on governance level\");\n            println!();\n            let err = ux_error::server_not_connected();\n            err.display();\n        }\n        return Ok(());\n    }\n\n    // Show specific draft\n    if let Some(ref draft_id) = args.draft_id {\n        if args.json {\n            let output = json!({\n                \"operation\": \"policy_draft_show\",\n                \"draftId\": draft_id,\n                \"context\": {\n                    \"tenantId\": resolved.tenant_id.value,\n                    \"userId\": resolved.user_id.value,\n                },\n                \"status\": \"not_connected\",\n                \"message\": \"Policy backend not connected\"\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(&format!(\"Policy Draft: {}\", draft_id));\n            println!();\n            output::info(\"Would show draft details including:\");\n            println!(\"  - Original natural language description\");\n            println!(\"  - Generated Cedar policy\");\n            println!(\"  - Validation status\");\n            println!(\"  - Submission status\");\n            println!();\n            let err = ux_error::server_not_connected();\n            err.display();\n        }\n    } else {\n        // No arguments - show help\n        let err = ux_error::UxError::new(\"No draft ID or action specified\")\n            .why(\"The draft command needs either a draft ID or an action flag\")\n            .fix(\"Provide a draft ID to view: aeterna policy draft <draft-id>\")\n            .fix(\"List all drafts: aeterna policy draft --list\")\n            .fix(\"Submit a draft: aeterna policy draft --submit <draft-id>\")\n            .suggest(\"aeterna policy draft --list\");\n        err.display();\n        return Err(anyhow::anyhow!(\"Missing draft ID or action\"));\n    }\n\n    Ok(())\n}\n\nfn hint_effect(enabled: bool, effect: &str) -> String {\n    if enabled {\n        format!(\"({})\", effect)\n    } else {\n        String::new()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_policy_create_args_defaults() {\n        let args = PolicyCreateArgs {\n            description: None,\n            name: None,\n            layer: \"project\".to_string(),\n            mode: \"mandatory\".to_string(),\n            template: None,\n            target: None,\n            severity: \"warn\".to_string(),\n            json: false,\n            dry_run: false,\n            preset: None,\n        };\n        assert!(args.description.is_none());\n        assert!(args.name.is_none());\n        assert_eq!(args.layer, \"project\");\n        assert_eq!(args.mode, \"mandatory\");\n        assert_eq!(args.severity, \"warn\");\n        assert!(!args.json);\n        assert!(!args.dry_run);\n    }\n\n    #[test]\n    fn test_policy_create_args_with_description() {\n        let args = PolicyCreateArgs {\n            description: Some(\"Block all dependencies with critical CVEs\".to_string()),\n            name: Some(\"cve-blocker\".to_string()),\n            layer: \"company\".to_string(),\n            mode: \"mandatory\".to_string(),\n            template: None,\n            target: Some(\"dependency\".to_string()),\n            severity: \"block\".to_string(),\n            json: true,\n            dry_run: true,\n            preset: Some(\"strict\".to_string()),\n        };\n        assert!(args.description.is_some());\n        assert_eq!(args.name, Some(\"cve-blocker\".to_string()));\n        assert_eq!(args.layer, \"company\");\n        assert_eq!(args.target, Some(\"dependency\".to_string()));\n    }\n\n    #[test]\n    fn test_policy_create_args_with_template() {\n        let args = PolicyCreateArgs {\n            description: None,\n            name: None,\n            layer: \"org\".to_string(),\n            mode: \"optional\".to_string(),\n            template: Some(\"security-baseline\".to_string()),\n            target: None,\n            severity: \"error\".to_string(),\n            json: false,\n            dry_run: false,\n            preset: None,\n        };\n        assert!(args.template.is_some());\n        assert_eq!(args.mode, \"optional\");\n    }\n\n    #[test]\n    fn test_policy_list_args_defaults() {\n        let args = PolicyListArgs {\n            layer: None,\n            mode: None,\n            all: false,\n            json: false,\n        };\n        assert!(args.layer.is_none());\n        assert!(args.mode.is_none());\n        assert!(!args.all);\n        assert!(!args.json);\n    }\n\n    #[test]\n    fn test_policy_list_args_with_filters() {\n        let args = PolicyListArgs {\n            layer: Some(\"team\".to_string()),\n            mode: Some(\"mandatory\".to_string()),\n            all: true,\n            json: true,\n        };\n        assert_eq!(args.layer, Some(\"team\".to_string()));\n        assert_eq!(args.mode, Some(\"mandatory\".to_string()));\n        assert!(args.all);\n    }\n\n    #[test]\n    fn test_policy_explain_args() {\n        let args = PolicyExplainArgs {\n            policy_id: \"security-baseline\".to_string(),\n            verbose: false,\n            json: false,\n        };\n        assert_eq!(args.policy_id, \"security-baseline\");\n        assert!(!args.verbose);\n    }\n\n    #[test]\n    fn test_policy_explain_args_verbose() {\n        let args = PolicyExplainArgs {\n            policy_id: \"cve-blocker\".to_string(),\n            verbose: true,\n            json: true,\n        };\n        assert!(args.verbose);\n        assert!(args.json);\n    }\n\n    #[test]\n    fn test_policy_simulate_args() {\n        let args = PolicySimulateArgs {\n            policy_id: \"dependency-audit\".to_string(),\n            scenario: \"dependency-add\".to_string(),\n            input: \"lodash@4.17.20\".to_string(),\n            json: false,\n            dry_run: false,\n        };\n        assert_eq!(args.policy_id, \"dependency-audit\");\n        assert_eq!(args.scenario, \"dependency-add\");\n        assert_eq!(args.input, \"lodash@4.17.20\");\n    }\n\n    #[test]\n    fn test_policy_simulate_args_dry_run() {\n        let args = PolicySimulateArgs {\n            policy_id: \"code-style\".to_string(),\n            scenario: \"code-change\".to_string(),\n            input: \"src/main.rs\".to_string(),\n            json: true,\n            dry_run: true,\n        };\n        assert!(args.dry_run);\n        assert!(args.json);\n    }\n\n    #[test]\n    fn test_policy_validate_args() {\n        let args = PolicyValidateArgs {\n            policy: \"security-baseline\".to_string(),\n            strict: false,\n            json: false,\n        };\n        assert_eq!(args.policy, \"security-baseline\");\n        assert!(!args.strict);\n    }\n\n    #[test]\n    fn test_policy_validate_args_strict() {\n        let args = PolicyValidateArgs {\n            policy: \"/path/to/policy.cedar\".to_string(),\n            strict: true,\n            json: true,\n        };\n        assert!(args.strict);\n        assert!(args.policy.contains(\".cedar\"));\n    }\n\n    #[test]\n    fn test_policy_draft_args_show() {\n        let args = PolicyDraftArgs {\n            draft_id: Some(\"draft-cve-blocker-12345\".to_string()),\n            list: false,\n            submit: None,\n            json: false,\n        };\n        assert_eq!(args.draft_id, Some(\"draft-cve-blocker-12345\".to_string()));\n        assert!(!args.list);\n    }\n\n    #[test]\n    fn test_policy_draft_args_list() {\n        let args = PolicyDraftArgs {\n            draft_id: None,\n            list: true,\n            submit: None,\n            json: true,\n        };\n        assert!(args.draft_id.is_none());\n        assert!(args.list);\n    }\n\n    #[test]\n    fn test_policy_draft_args_submit() {\n        let args = PolicyDraftArgs {\n            draft_id: None,\n            list: false,\n            submit: Some(\"draft-my-policy-67890\".to_string()),\n            json: false,\n        };\n        assert_eq!(args.submit, Some(\"draft-my-policy-67890\".to_string()));\n    }\n\n    #[test]\n    fn test_hint_effect_enabled() {\n        let result = hint_effect(true, \"uses LLM\");\n        assert_eq!(result, \"(uses LLM)\");\n    }\n\n    #[test]\n    fn test_hint_effect_disabled() {\n        let result = hint_effect(false, \"uses LLM\");\n        assert_eq!(result, \"\");\n    }\n\n    #[test]\n    fn test_hint_effect_various_effects() {\n        assert_eq!(hint_effect(true, \"caches result\"), \"(caches result)\");\n        assert_eq!(hint_effect(true, \"requires auth\"), \"(requires auth)\");\n        assert_eq!(hint_effect(false, \"caches result\"), \"\");\n    }\n\n    #[test]\n    fn test_layer_validation_valid_layers() {\n        let valid_layers = [\"company\", \"org\", \"team\", \"project\"];\n        for layer in valid_layers {\n            assert!(valid_layers.contains(&layer.to_lowercase().as_str()));\n        }\n    }\n\n    #[test]\n    fn test_layer_validation_invalid_layers() {\n        let valid_layers = [\"company\", \"org\", \"team\", \"project\"];\n        let invalid_layers = [\"global\", \"user\", \"session\", \"agent\"];\n        for layer in invalid_layers {\n            assert!(!valid_layers.contains(&layer.to_lowercase().as_str()));\n        }\n    }\n\n    #[test]\n    fn test_mode_validation_valid_modes() {\n        let valid_modes = [\"mandatory\", \"optional\"];\n        for mode in valid_modes {\n            assert!(valid_modes.contains(&mode.to_lowercase().as_str()));\n        }\n    }\n\n    #[test]\n    fn test_mode_validation_invalid_modes() {\n        let valid_modes = [\"mandatory\", \"optional\"];\n        let invalid_modes = [\"required\", \"suggested\", \"enforced\"];\n        for mode in invalid_modes {\n            assert!(!valid_modes.contains(&mode.to_lowercase().as_str()));\n        }\n    }\n\n    #[test]\n    fn test_severity_validation_valid_severities() {\n        let valid_severities = [\"info\", \"warn\", \"error\", \"block\"];\n        for severity in valid_severities {\n            assert!(valid_severities.contains(&severity.to_lowercase().as_str()));\n        }\n    }\n\n    #[test]\n    fn test_severity_validation_invalid_severities() {\n        let valid_severities = [\"info\", \"warn\", \"error\", \"block\"];\n        let invalid_severities = [\"critical\", \"fatal\", \"debug\", \"notice\"];\n        for severity in invalid_severities {\n            assert!(!valid_severities.contains(&severity.to_lowercase().as_str()));\n        }\n    }\n\n    #[test]\n    fn test_scenario_validation_valid_scenarios() {\n        let valid_scenarios = [\n            \"dependency-add\",\n            \"file-create\",\n            \"code-change\",\n            \"config-update\",\n        ];\n        for scenario in valid_scenarios {\n            assert!(valid_scenarios.contains(&scenario.to_lowercase().as_str()));\n        }\n    }\n\n    #[test]\n    fn test_scenario_validation_invalid_scenarios() {\n        let valid_scenarios = [\n            \"dependency-add\",\n            \"file-create\",\n            \"code-change\",\n            \"config-update\",\n        ];\n        let invalid_scenarios = [\"build-run\", \"test-execute\", \"deploy-app\"];\n        for scenario in invalid_scenarios {\n            assert!(!valid_scenarios.contains(&scenario.to_lowercase().as_str()));\n        }\n    }\n\n    #[test]\n    fn test_policy_create_args_all_layers() {\n        let layers = [\"company\", \"org\", \"team\", \"project\"];\n        for layer in layers {\n            let args = PolicyCreateArgs {\n                description: Some(\"Test policy\".to_string()),\n                name: None,\n                layer: layer.to_string(),\n                mode: \"mandatory\".to_string(),\n                template: None,\n                target: None,\n                severity: \"warn\".to_string(),\n                json: false,\n                dry_run: false,\n                preset: None,\n            };\n            assert_eq!(args.layer, layer);\n        }\n    }\n\n    #[test]\n    fn test_policy_create_args_all_severities() {\n        let severities = [\"info\", \"warn\", \"error\", \"block\"];\n        for severity in severities {\n            let args = PolicyCreateArgs {\n                description: Some(\"Test policy\".to_string()),\n                name: None,\n                layer: \"project\".to_string(),\n                mode: \"mandatory\".to_string(),\n                template: None,\n                target: None,\n                severity: severity.to_string(),\n                json: false,\n                dry_run: false,\n                preset: None,\n            };\n            assert_eq!(args.severity, severity);\n        }\n    }\n\n    #[test]\n    fn test_policy_create_args_all_target_types() {\n        let targets = [\"dependency\", \"file\", \"code\", \"config\"];\n        for target in targets {\n            let args = PolicyCreateArgs {\n                description: Some(\"Test policy\".to_string()),\n                name: None,\n                layer: \"project\".to_string(),\n                mode: \"mandatory\".to_string(),\n                template: None,\n                target: Some(target.to_string()),\n                severity: \"warn\".to_string(),\n                json: false,\n                dry_run: false,\n                preset: None,\n            };\n            assert_eq!(args.target, Some(target.to_string()));\n        }\n    }\n\n    #[test]\n    fn test_policy_simulate_args_all_scenarios() {\n        let scenarios = [\n            \"dependency-add\",\n            \"file-create\",\n            \"code-change\",\n            \"config-update\",\n        ];\n        for scenario in scenarios {\n            let args = PolicySimulateArgs {\n                policy_id: \"test-policy\".to_string(),\n                scenario: scenario.to_string(),\n                input: \"test-input\".to_string(),\n                json: false,\n                dry_run: false,\n            };\n            assert_eq!(args.scenario, scenario);\n        }\n    }\n\n    #[test]\n    fn test_policy_list_args_all_mode_filters() {\n        let modes = [\"mandatory\", \"optional\"];\n        for mode in modes {\n            let args = PolicyListArgs {\n                layer: None,\n                mode: Some(mode.to_string()),\n                all: false,\n                json: false,\n            };\n            assert_eq!(args.mode, Some(mode.to_string()));\n        }\n    }\n\n    #[test]\n    fn test_template_options() {\n        let templates = [\"security-baseline\", \"code-style\", \"dependency-audit\"];\n        for template in templates {\n            let args = PolicyCreateArgs {\n                description: None,\n                name: None,\n                layer: \"team\".to_string(),\n                mode: \"mandatory\".to_string(),\n                template: Some(template.to_string()),\n                target: None,\n                severity: \"warn\".to_string(),\n                json: false,\n                dry_run: false,\n                preset: None,\n            };\n            assert_eq!(args.template, Some(template.to_string()));\n        }\n    }\n\n    #[test]\n    fn test_policy_draft_args_no_action() {\n        let args = PolicyDraftArgs {\n            draft_id: None,\n            list: false,\n            submit: None,\n            json: false,\n        };\n        assert!(args.draft_id.is_none());\n        assert!(!args.list);\n        assert!(args.submit.is_none());\n    }\n\n    #[test]\n    fn test_policy_create_args_preset_options() {\n        let presets = [\"strict\", \"permissive\", \"balanced\"];\n        for preset in presets {\n            let args = PolicyCreateArgs {\n                description: Some(\"Test\".to_string()),\n                name: None,\n                layer: \"project\".to_string(),\n                mode: \"mandatory\".to_string(),\n                template: None,\n                target: None,\n                severity: \"warn\".to_string(),\n                json: false,\n                dry_run: false,\n                preset: Some(preset.to_string()),\n            };\n            assert_eq!(args.preset, Some(preset.to_string()));\n        }\n    }\n\n    #[test]\n    fn test_policy_explain_args_policy_id_formats() {\n        let policy_ids = [\n            \"security-baseline\",\n            \"company-wide-policy\",\n            \"team-api-conventions\",\n            \"project-local-rules\",\n        ];\n        for id in policy_ids {\n            let args = PolicyExplainArgs {\n                policy_id: id.to_string(),\n                verbose: false,\n                json: false,\n            };\n            assert_eq!(args.policy_id, id);\n        }\n    }\n\n    #[test]\n    fn test_policy_validate_args_file_path() {\n        let args = PolicyValidateArgs {\n            policy: \"policies/my-policy.cedar\".to_string(),\n            strict: false,\n            json: false,\n        };\n        assert!(args.policy.contains(\"/\"));\n        assert!(args.policy.ends_with(\".cedar\"));\n    }\n\n    #[test]\n    fn test_policy_validate_args_policy_id() {\n        let args = PolicyValidateArgs {\n            policy: \"security-baseline\".to_string(),\n            strict: false,\n            json: false,\n        };\n        assert!(!args.policy.contains(\"/\"));\n        assert!(!args.policy.ends_with(\".cedar\"));\n    }\n}\n","traces":[{"line":162,"address":[],"length":0,"stats":{"Line":20}},{"line":163,"address":[],"length":0,"stats":{"Line":10}},{"line":164,"address":[],"length":0,"stats":{"Line":30}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":20}},{"line":174,"address":[],"length":0,"stats":{"Line":20}},{"line":175,"address":[],"length":0,"stats":{"Line":30}},{"line":178,"address":[],"length":0,"stats":{"Line":20}},{"line":179,"address":[],"length":0,"stats":{"Line":30}},{"line":180,"address":[],"length":0,"stats":{"Line":30}},{"line":181,"address":[],"length":0,"stats":{"Line":3}},{"line":182,"address":[],"length":0,"stats":{"Line":2}},{"line":183,"address":[],"length":0,"stats":{"Line":1}},{"line":187,"address":[],"length":0,"stats":{"Line":18}},{"line":188,"address":[],"length":0,"stats":{"Line":18}},{"line":189,"address":[],"length":0,"stats":{"Line":27}},{"line":190,"address":[],"length":0,"stats":{"Line":4}},{"line":194,"address":[],"length":0,"stats":{"Line":2}},{"line":195,"address":[],"length":0,"stats":{"Line":1}},{"line":199,"address":[],"length":0,"stats":{"Line":16}},{"line":200,"address":[],"length":0,"stats":{"Line":24}},{"line":201,"address":[],"length":0,"stats":{"Line":24}},{"line":202,"address":[],"length":0,"stats":{"Line":4}},{"line":206,"address":[],"length":0,"stats":{"Line":2}},{"line":207,"address":[],"length":0,"stats":{"Line":1}},{"line":211,"address":[],"length":0,"stats":{"Line":14}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":14}},{"line":223,"address":[],"length":0,"stats":{"Line":21}},{"line":224,"address":[],"length":0,"stats":{"Line":21}},{"line":226,"address":[],"length":0,"stats":{"Line":9}},{"line":227,"address":[],"length":0,"stats":{"Line":2}},{"line":234,"address":[],"length":0,"stats":{"Line":2}},{"line":235,"address":[],"length":0,"stats":{"Line":1}},{"line":239,"address":[],"length":0,"stats":{"Line":24}},{"line":240,"address":[],"length":0,"stats":{"Line":11}},{"line":242,"address":[],"length":0,"stats":{"Line":25}},{"line":243,"address":[],"length":0,"stats":{"Line":15}},{"line":244,"address":[],"length":0,"stats":{"Line":2}},{"line":245,"address":[],"length":0,"stats":{"Line":2}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":252,"address":[],"length":0,"stats":{"Line":12}},{"line":254,"address":[],"length":0,"stats":{"Line":12}},{"line":255,"address":[],"length":0,"stats":{"Line":12}},{"line":258,"address":[],"length":0,"stats":{"Line":6}},{"line":259,"address":[],"length":0,"stats":{"Line":6}},{"line":260,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":264,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":0}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":270,"address":[],"length":0,"stats":{"Line":0}},{"line":272,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":274,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":12}},{"line":291,"address":[],"length":0,"stats":{"Line":6}},{"line":292,"address":[],"length":0,"stats":{"Line":12}},{"line":293,"address":[],"length":0,"stats":{"Line":12}},{"line":294,"address":[],"length":0,"stats":{"Line":12}},{"line":295,"address":[],"length":0,"stats":{"Line":12}},{"line":296,"address":[],"length":0,"stats":{"Line":12}},{"line":297,"address":[],"length":0,"stats":{"Line":6}},{"line":299,"address":[],"length":0,"stats":{"Line":16}},{"line":300,"address":[],"length":0,"stats":{"Line":15}},{"line":301,"address":[],"length":0,"stats":{"Line":15}},{"line":302,"address":[],"length":0,"stats":{"Line":10}},{"line":303,"address":[],"length":0,"stats":{"Line":15}},{"line":304,"address":[],"length":0,"stats":{"Line":10}},{"line":305,"address":[],"length":0,"stats":{"Line":10}},{"line":306,"address":[],"length":0,"stats":{"Line":20}},{"line":308,"address":[],"length":0,"stats":{"Line":15}},{"line":309,"address":[],"length":0,"stats":{"Line":15}},{"line":310,"address":[],"length":0,"stats":{"Line":10}},{"line":311,"address":[],"length":0,"stats":{"Line":5}},{"line":314,"address":[],"length":0,"stats":{"Line":7}},{"line":315,"address":[],"length":0,"stats":{"Line":2}},{"line":316,"address":[],"length":0,"stats":{"Line":2}},{"line":317,"address":[],"length":0,"stats":{"Line":2}},{"line":318,"address":[],"length":0,"stats":{"Line":2}},{"line":319,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":0}},{"line":321,"address":[],"length":0,"stats":{"Line":0}},{"line":323,"address":[],"length":0,"stats":{"Line":2}},{"line":324,"address":[],"length":0,"stats":{"Line":1}},{"line":327,"address":[],"length":0,"stats":{"Line":12}},{"line":328,"address":[],"length":0,"stats":{"Line":12}},{"line":329,"address":[],"length":0,"stats":{"Line":12}},{"line":330,"address":[],"length":0,"stats":{"Line":18}},{"line":331,"address":[],"length":0,"stats":{"Line":6}},{"line":333,"address":[],"length":0,"stats":{"Line":6}},{"line":335,"address":[],"length":0,"stats":{"Line":12}},{"line":336,"address":[],"length":0,"stats":{"Line":12}},{"line":337,"address":[],"length":0,"stats":{"Line":12}},{"line":338,"address":[],"length":0,"stats":{"Line":6}},{"line":339,"address":[],"length":0,"stats":{"Line":6}},{"line":342,"address":[],"length":0,"stats":{"Line":6}},{"line":344,"address":[],"length":0,"stats":{"Line":12}},{"line":345,"address":[],"length":0,"stats":{"Line":12}},{"line":347,"address":[],"length":0,"stats":{"Line":6}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":353,"address":[],"length":0,"stats":{"Line":0}},{"line":355,"address":[],"length":0,"stats":{"Line":0}},{"line":358,"address":[],"length":0,"stats":{"Line":0}},{"line":359,"address":[],"length":0,"stats":{"Line":0}},{"line":360,"address":[],"length":0,"stats":{"Line":0}},{"line":363,"address":[],"length":0,"stats":{"Line":0}},{"line":364,"address":[],"length":0,"stats":{"Line":0}},{"line":365,"address":[],"length":0,"stats":{"Line":0}},{"line":366,"address":[],"length":0,"stats":{"Line":0}},{"line":367,"address":[],"length":0,"stats":{"Line":0}},{"line":368,"address":[],"length":0,"stats":{"Line":0}},{"line":369,"address":[],"length":0,"stats":{"Line":0}},{"line":373,"address":[],"length":0,"stats":{"Line":0}},{"line":374,"address":[],"length":0,"stats":{"Line":0}},{"line":375,"address":[],"length":0,"stats":{"Line":0}},{"line":376,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":378,"address":[],"length":0,"stats":{"Line":0}},{"line":379,"address":[],"length":0,"stats":{"Line":0}},{"line":381,"address":[],"length":0,"stats":{"Line":0}},{"line":382,"address":[],"length":0,"stats":{"Line":0}},{"line":383,"address":[],"length":0,"stats":{"Line":0}},{"line":384,"address":[],"length":0,"stats":{"Line":0}},{"line":386,"address":[],"length":0,"stats":{"Line":0}},{"line":387,"address":[],"length":0,"stats":{"Line":0}},{"line":389,"address":[],"length":0,"stats":{"Line":0}},{"line":391,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":0}},{"line":394,"address":[],"length":0,"stats":{"Line":0}},{"line":395,"address":[],"length":0,"stats":{"Line":0}},{"line":398,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":401,"address":[],"length":0,"stats":{"Line":0}},{"line":402,"address":[],"length":0,"stats":{"Line":0}},{"line":404,"address":[],"length":0,"stats":{"Line":0}},{"line":407,"address":[],"length":0,"stats":{"Line":0}},{"line":408,"address":[],"length":0,"stats":{"Line":0}},{"line":409,"address":[],"length":0,"stats":{"Line":0}},{"line":410,"address":[],"length":0,"stats":{"Line":0}},{"line":411,"address":[],"length":0,"stats":{"Line":0}},{"line":412,"address":[],"length":0,"stats":{"Line":0}},{"line":414,"address":[],"length":0,"stats":{"Line":0}},{"line":415,"address":[],"length":0,"stats":{"Line":0}},{"line":418,"address":[],"length":0,"stats":{"Line":0}},{"line":421,"address":[],"length":0,"stats":{"Line":0}},{"line":422,"address":[],"length":0,"stats":{"Line":0}},{"line":423,"address":[],"length":0,"stats":{"Line":0}},{"line":425,"address":[],"length":0,"stats":{"Line":0}},{"line":426,"address":[],"length":0,"stats":{"Line":0}},{"line":427,"address":[],"length":0,"stats":{"Line":0}},{"line":428,"address":[],"length":0,"stats":{"Line":0}},{"line":429,"address":[],"length":0,"stats":{"Line":0}},{"line":430,"address":[],"length":0,"stats":{"Line":0}},{"line":431,"address":[],"length":0,"stats":{"Line":0}},{"line":432,"address":[],"length":0,"stats":{"Line":0}},{"line":434,"address":[],"length":0,"stats":{"Line":0}},{"line":435,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":0}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":443,"address":[],"length":0,"stats":{"Line":0}},{"line":444,"address":[],"length":0,"stats":{"Line":0}},{"line":445,"address":[],"length":0,"stats":{"Line":0}},{"line":446,"address":[],"length":0,"stats":{"Line":0}},{"line":447,"address":[],"length":0,"stats":{"Line":0}},{"line":448,"address":[],"length":0,"stats":{"Line":0}},{"line":450,"address":[],"length":0,"stats":{"Line":0}},{"line":451,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":453,"address":[],"length":0,"stats":{"Line":0}},{"line":454,"address":[],"length":0,"stats":{"Line":0}},{"line":455,"address":[],"length":0,"stats":{"Line":0}},{"line":456,"address":[],"length":0,"stats":{"Line":0}},{"line":457,"address":[],"length":0,"stats":{"Line":0}},{"line":460,"address":[],"length":0,"stats":{"Line":0}},{"line":461,"address":[],"length":0,"stats":{"Line":0}},{"line":464,"address":[],"length":0,"stats":{"Line":0}},{"line":467,"address":[],"length":0,"stats":{"Line":0}},{"line":468,"address":[],"length":0,"stats":{"Line":0}},{"line":469,"address":[],"length":0,"stats":{"Line":0}},{"line":472,"address":[],"length":0,"stats":{"Line":0}},{"line":473,"address":[],"length":0,"stats":{"Line":0}},{"line":474,"address":[],"length":0,"stats":{"Line":0}},{"line":475,"address":[],"length":0,"stats":{"Line":0}},{"line":476,"address":[],"length":0,"stats":{"Line":0}},{"line":477,"address":[],"length":0,"stats":{"Line":0}},{"line":479,"address":[],"length":0,"stats":{"Line":0}},{"line":480,"address":[],"length":0,"stats":{"Line":0}},{"line":484,"address":[],"length":0,"stats":{"Line":0}},{"line":485,"address":[],"length":0,"stats":{"Line":0}},{"line":488,"address":[],"length":0,"stats":{"Line":0}},{"line":489,"address":[],"length":0,"stats":{"Line":0}},{"line":490,"address":[],"length":0,"stats":{"Line":0}},{"line":491,"address":[],"length":0,"stats":{"Line":0}},{"line":492,"address":[],"length":0,"stats":{"Line":0}},{"line":493,"address":[],"length":0,"stats":{"Line":0}},{"line":494,"address":[],"length":0,"stats":{"Line":0}},{"line":495,"address":[],"length":0,"stats":{"Line":0}},{"line":496,"address":[],"length":0,"stats":{"Line":0}},{"line":498,"address":[],"length":0,"stats":{"Line":0}},{"line":499,"address":[],"length":0,"stats":{"Line":0}},{"line":500,"address":[],"length":0,"stats":{"Line":0}},{"line":501,"address":[],"length":0,"stats":{"Line":0}},{"line":503,"address":[],"length":0,"stats":{"Line":0}},{"line":509,"address":[],"length":0,"stats":{"Line":0}},{"line":511,"address":[],"length":0,"stats":{"Line":0}},{"line":512,"address":[],"length":0,"stats":{"Line":0}},{"line":513,"address":[],"length":0,"stats":{"Line":0}},{"line":514,"address":[],"length":0,"stats":{"Line":0}},{"line":515,"address":[],"length":0,"stats":{"Line":0}},{"line":516,"address":[],"length":0,"stats":{"Line":0}},{"line":517,"address":[],"length":0,"stats":{"Line":0}},{"line":518,"address":[],"length":0,"stats":{"Line":0}},{"line":519,"address":[],"length":0,"stats":{"Line":0}},{"line":520,"address":[],"length":0,"stats":{"Line":0}},{"line":521,"address":[],"length":0,"stats":{"Line":0}},{"line":522,"address":[],"length":0,"stats":{"Line":0}},{"line":523,"address":[],"length":0,"stats":{"Line":0}},{"line":524,"address":[],"length":0,"stats":{"Line":0}},{"line":525,"address":[],"length":0,"stats":{"Line":0}},{"line":526,"address":[],"length":0,"stats":{"Line":0}},{"line":527,"address":[],"length":0,"stats":{"Line":0}},{"line":528,"address":[],"length":0,"stats":{"Line":0}},{"line":530,"address":[],"length":0,"stats":{"Line":0}},{"line":533,"address":[],"length":0,"stats":{"Line":0}},{"line":534,"address":[],"length":0,"stats":{"Line":0}},{"line":535,"address":[],"length":0,"stats":{"Line":0}},{"line":536,"address":[],"length":0,"stats":{"Line":0}},{"line":537,"address":[],"length":0,"stats":{"Line":0}},{"line":538,"address":[],"length":0,"stats":{"Line":0}},{"line":539,"address":[],"length":0,"stats":{"Line":0}},{"line":541,"address":[],"length":0,"stats":{"Line":0}},{"line":542,"address":[],"length":0,"stats":{"Line":0}},{"line":544,"address":[],"length":0,"stats":{"Line":0}},{"line":546,"address":[],"length":0,"stats":{"Line":0}},{"line":547,"address":[],"length":0,"stats":{"Line":0}},{"line":548,"address":[],"length":0,"stats":{"Line":0}},{"line":549,"address":[],"length":0,"stats":{"Line":0}},{"line":550,"address":[],"length":0,"stats":{"Line":0}},{"line":551,"address":[],"length":0,"stats":{"Line":0}},{"line":552,"address":[],"length":0,"stats":{"Line":0}},{"line":553,"address":[],"length":0,"stats":{"Line":0}},{"line":554,"address":[],"length":0,"stats":{"Line":0}},{"line":557,"address":[],"length":0,"stats":{"Line":0}},{"line":560,"address":[],"length":0,"stats":{"Line":0}},{"line":561,"address":[],"length":0,"stats":{"Line":0}},{"line":562,"address":[],"length":0,"stats":{"Line":0}},{"line":564,"address":[],"length":0,"stats":{"Line":0}},{"line":565,"address":[],"length":0,"stats":{"Line":0}},{"line":566,"address":[],"length":0,"stats":{"Line":0}},{"line":567,"address":[],"length":0,"stats":{"Line":0}},{"line":568,"address":[],"length":0,"stats":{"Line":0}},{"line":569,"address":[],"length":0,"stats":{"Line":0}},{"line":570,"address":[],"length":0,"stats":{"Line":0}},{"line":571,"address":[],"length":0,"stats":{"Line":0}},{"line":573,"address":[],"length":0,"stats":{"Line":0}},{"line":574,"address":[],"length":0,"stats":{"Line":0}},{"line":576,"address":[],"length":0,"stats":{"Line":0}},{"line":578,"address":[],"length":0,"stats":{"Line":0}},{"line":579,"address":[],"length":0,"stats":{"Line":0}},{"line":581,"address":[],"length":0,"stats":{"Line":0}},{"line":582,"address":[],"length":0,"stats":{"Line":0}},{"line":585,"address":[],"length":0,"stats":{"Line":0}},{"line":586,"address":[],"length":0,"stats":{"Line":0}},{"line":587,"address":[],"length":0,"stats":{"Line":0}},{"line":588,"address":[],"length":0,"stats":{"Line":0}},{"line":589,"address":[],"length":0,"stats":{"Line":0}},{"line":590,"address":[],"length":0,"stats":{"Line":0}},{"line":591,"address":[],"length":0,"stats":{"Line":0}},{"line":592,"address":[],"length":0,"stats":{"Line":0}},{"line":594,"address":[],"length":0,"stats":{"Line":0}},{"line":596,"address":[],"length":0,"stats":{"Line":0}},{"line":597,"address":[],"length":0,"stats":{"Line":0}},{"line":600,"address":[],"length":0,"stats":{"Line":0}},{"line":603,"address":[],"length":0,"stats":{"Line":0}},{"line":604,"address":[],"length":0,"stats":{"Line":0}},{"line":605,"address":[],"length":0,"stats":{"Line":0}},{"line":607,"address":[],"length":0,"stats":{"Line":0}},{"line":608,"address":[],"length":0,"stats":{"Line":0}},{"line":609,"address":[],"length":0,"stats":{"Line":0}},{"line":610,"address":[],"length":0,"stats":{"Line":0}},{"line":611,"address":[],"length":0,"stats":{"Line":0}},{"line":612,"address":[],"length":0,"stats":{"Line":0}},{"line":613,"address":[],"length":0,"stats":{"Line":0}},{"line":615,"address":[],"length":0,"stats":{"Line":0}},{"line":616,"address":[],"length":0,"stats":{"Line":0}},{"line":618,"address":[],"length":0,"stats":{"Line":0}},{"line":620,"address":[],"length":0,"stats":{"Line":0}},{"line":621,"address":[],"length":0,"stats":{"Line":0}},{"line":622,"address":[],"length":0,"stats":{"Line":0}},{"line":623,"address":[],"length":0,"stats":{"Line":0}},{"line":624,"address":[],"length":0,"stats":{"Line":0}},{"line":625,"address":[],"length":0,"stats":{"Line":0}},{"line":627,"address":[],"length":0,"stats":{"Line":0}},{"line":630,"address":[],"length":0,"stats":{"Line":0}},{"line":631,"address":[],"length":0,"stats":{"Line":0}},{"line":632,"address":[],"length":0,"stats":{"Line":0}},{"line":633,"address":[],"length":0,"stats":{"Line":0}},{"line":634,"address":[],"length":0,"stats":{"Line":0}},{"line":635,"address":[],"length":0,"stats":{"Line":0}},{"line":636,"address":[],"length":0,"stats":{"Line":0}},{"line":637,"address":[],"length":0,"stats":{"Line":0}},{"line":639,"address":[],"length":0,"stats":{"Line":0}},{"line":640,"address":[],"length":0,"stats":{"Line":0}},{"line":642,"address":[],"length":0,"stats":{"Line":0}},{"line":644,"address":[],"length":0,"stats":{"Line":0}},{"line":645,"address":[],"length":0,"stats":{"Line":0}},{"line":646,"address":[],"length":0,"stats":{"Line":0}},{"line":647,"address":[],"length":0,"stats":{"Line":0}},{"line":648,"address":[],"length":0,"stats":{"Line":0}},{"line":649,"address":[],"length":0,"stats":{"Line":0}},{"line":650,"address":[],"length":0,"stats":{"Line":0}},{"line":651,"address":[],"length":0,"stats":{"Line":0}},{"line":652,"address":[],"length":0,"stats":{"Line":0}},{"line":653,"address":[],"length":0,"stats":{"Line":0}},{"line":655,"address":[],"length":0,"stats":{"Line":0}},{"line":659,"address":[],"length":0,"stats":{"Line":0}},{"line":660,"address":[],"length":0,"stats":{"Line":0}},{"line":661,"address":[],"length":0,"stats":{"Line":0}},{"line":662,"address":[],"length":0,"stats":{"Line":0}},{"line":663,"address":[],"length":0,"stats":{"Line":0}},{"line":664,"address":[],"length":0,"stats":{"Line":0}},{"line":665,"address":[],"length":0,"stats":{"Line":0}},{"line":666,"address":[],"length":0,"stats":{"Line":0}},{"line":668,"address":[],"length":0,"stats":{"Line":0}},{"line":669,"address":[],"length":0,"stats":{"Line":0}},{"line":671,"address":[],"length":0,"stats":{"Line":0}},{"line":673,"address":[],"length":0,"stats":{"Line":0}},{"line":674,"address":[],"length":0,"stats":{"Line":0}},{"line":675,"address":[],"length":0,"stats":{"Line":0}},{"line":676,"address":[],"length":0,"stats":{"Line":0}},{"line":677,"address":[],"length":0,"stats":{"Line":0}},{"line":678,"address":[],"length":0,"stats":{"Line":0}},{"line":679,"address":[],"length":0,"stats":{"Line":0}},{"line":680,"address":[],"length":0,"stats":{"Line":0}},{"line":681,"address":[],"length":0,"stats":{"Line":0}},{"line":682,"address":[],"length":0,"stats":{"Line":0}},{"line":686,"address":[],"length":0,"stats":{"Line":0}},{"line":692,"address":[],"length":0,"stats":{"Line":0}},{"line":693,"address":[],"length":0,"stats":{"Line":0}},{"line":696,"address":[],"length":0,"stats":{"Line":0}},{"line":699,"address":[],"length":0,"stats":{"Line":10}},{"line":700,"address":[],"length":0,"stats":{"Line":10}},{"line":701,"address":[],"length":0,"stats":{"Line":16}},{"line":703,"address":[],"length":0,"stats":{"Line":2}}],"covered":89,"coverable":367},{"path":["/","Users","christian.klat","dev","git","aeterna","cli","src","commands","status.rs"],"content":"use anyhow::Result;\nuse clap::Args;\nuse colored::Colorize;\nuse context::ContextResolver;\n\n#[derive(Args)]\npub struct StatusArgs {\n    #[arg(long, help = \"Output as JSON\")]\n    pub json: bool,\n\n    #[arg(long, help = \"Show verbose details\")]\n    pub verbose: bool,\n}\n\npub fn run(args: StatusArgs) -> Result<()> {\n    let resolver = ContextResolver::new();\n    let ctx = resolver.resolve()?;\n\n    if args.json {\n        let output = serde_json::json!({\n            \"tenant_id\": {\n                \"value\": ctx.tenant_id.value,\n                \"source\": ctx.tenant_id.source.to_string()\n            },\n            \"user_id\": {\n                \"value\": ctx.user_id.value,\n                \"source\": ctx.user_id.source.to_string()\n            },\n            \"org_id\": ctx.org_id.as_ref().map(|o| serde_json::json!({\n                \"value\": o.value,\n                \"source\": o.source.to_string()\n            })),\n            \"team_id\": ctx.team_id.as_ref().map(|t| serde_json::json!({\n                \"value\": t.value,\n                \"source\": t.source.to_string()\n            })),\n            \"project_id\": ctx.project_id.as_ref().map(|p| serde_json::json!({\n                \"value\": p.value,\n                \"source\": p.source.to_string()\n            })),\n            \"agent_id\": ctx.agent_id.as_ref().map(|a| serde_json::json!({\n                \"value\": a.value,\n                \"source\": a.source.to_string()\n            })),\n            \"hints\": {\n                \"preset\": format!(\"{:?}\", ctx.hints.value.preset),\n                \"source\": ctx.hints.source.to_string()\n            },\n            \"context_root\": ctx.context_root.as_ref().map(|p| p.display().to_string()),\n            \"git_root\": ctx.git_root.as_ref().map(|p| p.display().to_string())\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        return Ok(());\n    }\n\n    println!(\"{}\", \"Aeterna Status\".bold().underline());\n    println!();\n\n    println!(\"{}\", \"Context:\".bold());\n    print_value(\n        \"tenant_id\",\n        &ctx.tenant_id.value,\n        &ctx.tenant_id.source.to_string(),\n        args.verbose,\n    );\n    print_value(\n        \"user_id\",\n        &ctx.user_id.value,\n        &ctx.user_id.source.to_string(),\n        args.verbose,\n    );\n\n    if let Some(org) = &ctx.org_id {\n        print_value(\"org_id\", &org.value, &org.source.to_string(), args.verbose);\n    }\n\n    if let Some(team) = &ctx.team_id {\n        print_value(\n            \"team_id\",\n            &team.value,\n            &team.source.to_string(),\n            args.verbose,\n        );\n    }\n\n    if let Some(project) = &ctx.project_id {\n        print_value(\n            \"project_id\",\n            &project.value,\n            &project.source.to_string(),\n            args.verbose,\n        );\n    }\n\n    if let Some(agent) = &ctx.agent_id {\n        print_value(\n            \"agent_id\",\n            &agent.value,\n            &agent.source.to_string(),\n            args.verbose,\n        );\n    }\n\n    println!();\n    println!(\"{}\", \"Hints:\".bold());\n    print_value(\n        \"preset\",\n        &format!(\"{:?}\", ctx.hints.value.preset),\n        &ctx.hints.source.to_string(),\n        args.verbose,\n    );\n\n    if args.verbose {\n        println!(\"  reasoning:   {}\", bool_str(ctx.hints.value.reasoning));\n        println!(\"  multi_hop:   {}\", bool_str(ctx.hints.value.multi_hop));\n        println!(\"  llm:         {}\", bool_str(ctx.hints.value.llm));\n        println!(\"  caching:     {}\", bool_str(ctx.hints.value.caching));\n        println!(\"  governance:  {}\", bool_str(ctx.hints.value.governance));\n        println!(\"  audit:       {}\", bool_str(ctx.hints.value.audit));\n        println!(\"  graph:       {}\", bool_str(ctx.hints.value.graph));\n        println!(\"  cca:         {}\", bool_str(ctx.hints.value.cca));\n        println!(\"  a2a:         {}\", bool_str(ctx.hints.value.a2a));\n        println!(\"  verbose:     {}\", bool_str(ctx.hints.value.verbose));\n    }\n\n    println!();\n    println!(\"{}\", \"Paths:\".bold());\n    if let Some(root) = &ctx.context_root {\n        println!(\"  context_root: {}\", root.display().to_string().dimmed());\n    } else {\n        println!(\"  context_root: {}\", \"(none)\".dimmed());\n    }\n    if let Some(root) = &ctx.git_root {\n        println!(\"  git_root:     {}\", root.display().to_string().dimmed());\n    } else {\n        println!(\"  git_root:     {}\", \"(none)\".dimmed());\n    }\n\n    Ok(())\n}\n\nfn print_value(name: &str, value: &str, source: &str, verbose: bool) {\n    if verbose {\n        println!(\n            \"  {:<12} {} {}\",\n            format!(\"{name}:\"),\n            value.cyan(),\n            format!(\"({source})\").dimmed()\n        );\n    } else {\n        println!(\"  {:<12} {}\", format!(\"{name}:\"), value.cyan());\n    }\n}\n\nfn bool_str(b: bool) -> colored::ColoredString {\n    if b { \"on\".green() } else { \"off\".red() }\n}\n","traces":[{"line":15,"address":[],"length":0,"stats":{"Line":0}},{"line":16,"address":[],"length":0,"stats":{"Line":0}},{"line":17,"address":[],"length":0,"stats":{"Line":0}},{"line":19,"address":[],"length":0,"stats":{"Line":0}},{"line":20,"address":[],"length":0,"stats":{"Line":0}},{"line":21,"address":[],"length":0,"stats":{"Line":0}},{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":23,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":29,"address":[],"length":0,"stats":{"Line":0}},{"line":30,"address":[],"length":0,"stats":{"Line":0}},{"line":31,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":37,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":42,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":88},{"path":["/","Users","christian.klat","dev","git","aeterna","cli","src","commands","sync.rs"],"content":"//! Sync command - Memory-Knowledge synchronization\n//!\n//! Syncs memory and knowledge systems to ensure consistency:\n//! - Promotes mature memories to knowledge (if configured)\n//! - Validates memory-knowledge pointers\n//! - Refreshes caches and indices\n\nuse anyhow::Result;\nuse clap::Args;\nuse colored::Colorize;\nuse context::ContextResolver;\n\nuse crate::output;\n\n#[derive(Args)]\npub struct SyncArgs {\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n\n    /// Perform dry run without making changes\n    #[arg(long)]\n    pub dry_run: bool,\n\n    /// Force sync even if no changes detected\n    #[arg(long, short)]\n    pub force: bool,\n\n    /// Sync direction: all, memory-to-knowledge, knowledge-to-memory\n    #[arg(long, default_value = \"all\")]\n    pub direction: String,\n\n    /// Show verbose sync details\n    #[arg(long, short)]\n    pub verbose: bool,\n}\n\npub async fn run(args: SyncArgs) -> Result<()> {\n    let resolver = ContextResolver::new();\n    let ctx = resolver.resolve()?;\n\n    if args.json {\n        return run_json(args, &ctx).await;\n    }\n\n    output::header(\"Memory-Knowledge Sync\");\n    println!();\n\n    // Phase 1: Analyze current state\n    output::subheader(\"Analyzing sync state...\");\n    println!();\n\n    let tenant = &ctx.tenant_id.value;\n    let project = ctx\n        .project_id\n        .as_ref()\n        .map(|p| p.value.as_str())\n        .unwrap_or(\"(none)\");\n\n    println!(\"  {} {}\", \"Tenant:\".dimmed(), tenant.cyan());\n    println!(\"  {} {}\", \"Project:\".dimmed(), project.cyan());\n    println!(\n        \"  {} {}\",\n        \"Direction:\".dimmed(),\n        args.direction.to_uppercase().cyan()\n    );\n    println!();\n\n    // Simulated sync analysis\n    let sync_state = analyze_sync_state(&args);\n\n    if args.verbose {\n        println!(\"{}\", \"  Analysis Details:\".bold());\n        println!(\n            \"    {} memories pending promotion\",\n            sync_state.memories_pending.to_string().yellow()\n        );\n        println!(\n            \"    {} knowledge items with stale pointers\",\n            sync_state.stale_pointers.to_string().yellow()\n        );\n        println!(\n            \"    {} cache entries expired\",\n            sync_state.cache_expired.to_string().yellow()\n        );\n        println!();\n    }\n\n    if sync_state.is_synced() && !args.force {\n        println!(\"{}\", \"   Already in sync\".green());\n        output::hint(\"Use --force to re-sync anyway\");\n        return Ok(());\n    }\n\n    // Phase 2: Execute sync\n    if args.dry_run {\n        output::subheader(\"Dry run - changes that would be made:\");\n        println!();\n        print_planned_changes(&sync_state);\n        output::hint(\"Remove --dry-run to apply changes\");\n        return Ok(());\n    }\n\n    output::subheader(\"Syncing...\");\n    println!();\n\n    // Simulated sync operations\n    let results = execute_sync(&args, &sync_state);\n\n    // Phase 3: Report results\n    println!();\n    output::subheader(\"Sync Results\");\n    println!();\n\n    println!(\n        \"  {} {} memories promoted to knowledge\",\n        \"\".green(),\n        results.memories_promoted\n    );\n    println!(\n        \"  {} {} stale pointers refreshed\",\n        \"\".green(),\n        results.pointers_refreshed\n    );\n    println!(\n        \"  {} {} cache entries updated\",\n        \"\".green(),\n        results.cache_updated\n    );\n\n    if results.errors > 0 {\n        println!(\n            \"  {} {} errors occurred\",\n            \"\".red(),\n            results.errors.to_string().red()\n        );\n    }\n\n    println!();\n\n    if results.errors == 0 {\n        output::success(\"Sync completed successfully\");\n    } else {\n        output::warn(&format!(\"Sync completed with {} errors\", results.errors));\n    }\n\n    Ok(())\n}\n\nasync fn run_json(args: SyncArgs, ctx: &context::ResolvedContext) -> Result<()> {\n    let sync_state = analyze_sync_state(&args);\n\n    if args.dry_run {\n        let output = serde_json::json!({\n            \"dry_run\": true,\n            \"context\": {\n                \"tenant_id\": ctx.tenant_id.value,\n                \"project_id\": ctx.project_id.as_ref().map(|p| &p.value),\n            },\n            \"direction\": args.direction,\n            \"planned_changes\": {\n                \"memories_to_promote\": sync_state.memories_pending,\n                \"pointers_to_refresh\": sync_state.stale_pointers,\n                \"cache_to_update\": sync_state.cache_expired,\n            },\n            \"already_synced\": sync_state.is_synced(),\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        return Ok(());\n    }\n\n    let results = execute_sync(&args, &sync_state);\n\n    let output = serde_json::json!({\n        \"success\": results.errors == 0,\n        \"context\": {\n            \"tenant_id\": ctx.tenant_id.value,\n            \"project_id\": ctx.project_id.as_ref().map(|p| &p.value),\n        },\n        \"direction\": args.direction,\n        \"results\": {\n            \"memories_promoted\": results.memories_promoted,\n            \"pointers_refreshed\": results.pointers_refreshed,\n            \"cache_updated\": results.cache_updated,\n            \"errors\": results.errors,\n        }\n    });\n    println!(\"{}\", serde_json::to_string_pretty(&output)?);\n\n    Ok(())\n}\n\nstruct SyncState {\n    memories_pending: u32,\n    stale_pointers: u32,\n    cache_expired: u32,\n}\n\nimpl SyncState {\n    fn is_synced(&self) -> bool {\n        self.memories_pending == 0 && self.stale_pointers == 0 && self.cache_expired == 0\n    }\n}\n\nstruct SyncResults {\n    memories_promoted: u32,\n    pointers_refreshed: u32,\n    cache_updated: u32,\n    errors: u32,\n}\n\nfn analyze_sync_state(_args: &SyncArgs) -> SyncState {\n    // TODO: Replace with actual sync analysis when backend is implemented\n    // This simulates finding items that need syncing\n    SyncState {\n        memories_pending: 0,\n        stale_pointers: 0,\n        cache_expired: 0,\n    }\n}\n\nfn execute_sync(_args: &SyncArgs, state: &SyncState) -> SyncResults {\n    // TODO: Replace with actual sync operations when backend is implemented\n    SyncResults {\n        memories_promoted: state.memories_pending,\n        pointers_refreshed: state.stale_pointers,\n        cache_updated: state.cache_expired,\n        errors: 0,\n    }\n}\n\nfn print_planned_changes(state: &SyncState) {\n    if state.memories_pending > 0 {\n        println!(\n            \"  {} Promote {} memories to knowledge\",\n            \"\".cyan(),\n            state.memories_pending\n        );\n    }\n    if state.stale_pointers > 0 {\n        println!(\n            \"  {} Refresh {} stale pointers\",\n            \"\".cyan(),\n            state.stale_pointers\n        );\n    }\n    if state.cache_expired > 0 {\n        println!(\n            \"  {} Update {} cache entries\",\n            \"\".cyan(),\n            state.cache_expired\n        );\n    }\n    if state.is_synced() {\n        println!(\"  {} No changes needed\", \"\".cyan());\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_sync_state_is_synced() {\n        let state = SyncState {\n            memories_pending: 0,\n            stale_pointers: 0,\n            cache_expired: 0,\n        };\n        assert!(state.is_synced());\n\n        let state = SyncState {\n            memories_pending: 1,\n            stale_pointers: 0,\n            cache_expired: 0,\n        };\n        assert!(!state.is_synced());\n    }\n\n    #[test]\n    fn test_analyze_sync_state() {\n        let args = SyncArgs {\n            json: false,\n            dry_run: false,\n            force: false,\n            direction: \"all\".to_string(),\n            verbose: false,\n        };\n        let state = analyze_sync_state(&args);\n        // Currently returns empty state\n        assert!(state.is_synced());\n    }\n\n    #[test]\n    fn test_execute_sync() {\n        let args = SyncArgs {\n            json: false,\n            dry_run: false,\n            force: false,\n            direction: \"all\".to_string(),\n            verbose: false,\n        };\n        let state = SyncState {\n            memories_pending: 5,\n            stale_pointers: 3,\n            cache_expired: 2,\n        };\n        let results = execute_sync(&args, &state);\n        assert_eq!(results.memories_promoted, 5);\n        assert_eq!(results.pointers_refreshed, 3);\n        assert_eq!(results.cache_updated, 2);\n        assert_eq!(results.errors, 0);\n    }\n}\n","traces":[{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":42,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":3}},{"line":201,"address":[],"length":0,"stats":{"Line":7}},{"line":212,"address":[],"length":0,"stats":{"Line":1}},{"line":222,"address":[],"length":0,"stats":{"Line":1}},{"line":225,"address":[],"length":0,"stats":{"Line":2}},{"line":226,"address":[],"length":0,"stats":{"Line":1}},{"line":227,"address":[],"length":0,"stats":{"Line":1}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":235,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":240,"address":[],"length":0,"stats":{"Line":0}},{"line":241,"address":[],"length":0,"stats":{"Line":0}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":0}},{"line":254,"address":[],"length":0,"stats":{"Line":0}},{"line":255,"address":[],"length":0,"stats":{"Line":0}}],"covered":7,"coverable":123},{"path":["/","Users","christian.klat","dev","git","aeterna","cli","src","commands","team.rs"],"content":"use clap::{Args, Subcommand};\nuse context::ContextResolver;\nuse serde_json::json;\n\nuse crate::output;\nuse crate::ux_error;\n\n#[derive(Subcommand)]\npub enum TeamCommand {\n    #[command(about = \"Create a new team\")]\n    Create(TeamCreateArgs),\n\n    #[command(about = \"List teams in your organization\")]\n    List(TeamListArgs),\n\n    #[command(about = \"Show team details\")]\n    Show(TeamShowArgs),\n\n    #[command(about = \"Manage team members\")]\n    Members(TeamMembersArgs),\n\n    #[command(about = \"Set default team for current context\")]\n    Use(TeamUseArgs),\n}\n\n#[derive(Args)]\npub struct TeamCreateArgs {\n    /// Team name\n    pub name: String,\n\n    /// Team description\n    #[arg(short, long)]\n    pub description: Option<String>,\n\n    /// Parent organization ID (auto-detected if not provided)\n    #[arg(long)]\n    pub org: Option<String>,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n\n    /// Dry run - show what would be created\n    #[arg(long)]\n    pub dry_run: bool,\n}\n\n#[derive(Args)]\npub struct TeamListArgs {\n    /// Filter by organization\n    #[arg(long)]\n    pub org: Option<String>,\n\n    /// Show all teams you have access to\n    #[arg(long)]\n    pub all: bool,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct TeamShowArgs {\n    /// Team ID (uses current context if not provided)\n    pub team_id: Option<String>,\n\n    /// Show full details including policies and projects\n    #[arg(short, long)]\n    pub verbose: bool,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct TeamMembersArgs {\n    /// Team ID (uses current context if not provided)\n    #[arg(long)]\n    pub team: Option<String>,\n\n    /// Add member by user ID\n    #[arg(long)]\n    pub add: Option<String>,\n\n    /// Remove member by user ID\n    #[arg(long)]\n    pub remove: Option<String>,\n\n    /// Set role for a member\n    #[arg(long, value_name = \"USER_ID\")]\n    pub set_role: Option<String>,\n\n    /// Role to assign (developer, techlead, architect)\n    #[arg(long)]\n    pub role: Option<String>,\n\n    /// Output as JSON\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct TeamUseArgs {\n    /// Team ID to set as default\n    pub team_id: String,\n}\n\npub async fn run(cmd: TeamCommand) -> anyhow::Result<()> {\n    match cmd {\n        TeamCommand::Create(args) => run_create(args).await,\n        TeamCommand::List(args) => run_list(args).await,\n        TeamCommand::Show(args) => run_show(args).await,\n        TeamCommand::Members(args) => run_members(args).await,\n        TeamCommand::Use(args) => run_use(args).await,\n    }\n}\n\nasync fn run_create(args: TeamCreateArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    let org_id = args.org.clone().unwrap_or_else(|| {\n        resolved\n            .org_id\n            .as_ref()\n            .map(|o| o.value.clone())\n            .unwrap_or_else(|| \"default-org\".to_string())\n    });\n\n    if args.dry_run {\n        if args.json {\n            let output = json!({\n                \"dryRun\": true,\n                \"operation\": \"team_create\",\n                \"team\": {\n                    \"name\": args.name,\n                    \"description\": args.description,\n                    \"orgId\": org_id,\n                },\n                \"context\": {\n                    \"tenantId\": resolved.tenant_id.value,\n                    \"userId\": resolved.user_id.value,\n                },\n                \"nextSteps\": [\n                    \"Review team configuration\",\n                    \"Run without --dry-run to create\",\n                    \"Add members with 'aeterna team members --add <user>'\",\n                    \"Create projects with 'aeterna project create <name> --team <team-id>'\"\n                ]\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Team Create (Dry Run)\");\n            println!();\n            println!(\"  Name:         {}\", args.name);\n            if let Some(ref desc) = args.description {\n                println!(\"  Description:  {}\", desc);\n            }\n            println!(\"  Organization: {}\", org_id);\n            println!();\n\n            output::header(\"What Would Happen\");\n            println!(\n                \"  1. Create team '{}' under organization '{}'\",\n                args.name, org_id\n            );\n            println!(\"  2. Add you ({}) as team lead\", resolved.user_id.value);\n            println!(\"  3. Inherit organization-level policies\");\n            println!();\n\n            output::header(\"Next Steps\");\n            println!(\"  1. Run without --dry-run to create the team\");\n            println!(\"  2. Add members: aeterna team members --add <user-id>\");\n            println!(\n                \"  3. Create projects: aeterna project create <name> --team {}\",\n                args.name\n            );\n            println!();\n\n            output::info(\"Dry run mode - team not created.\");\n        }\n        return Ok(());\n    }\n\n    let err = ux_error::server_not_connected();\n    err.display();\n    output::info(\"Run with --dry-run to see what would be created.\");\n\n    Ok(())\n}\n\nasync fn run_list(args: TeamListArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"team_list\",\n            \"filters\": {\n                \"org\": args.org,\n                \"all\": args.all,\n            },\n            \"context\": {\n                \"tenantId\": resolved.tenant_id.value,\n                \"userId\": resolved.user_id.value,\n            },\n            \"status\": \"not_connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(\"Teams\");\n        println!();\n\n        if args.all {\n            output::info(\"Showing all teams you have access to.\");\n        }\n\n        if let Some(ref org) = args.org {\n            println!(\"  Filter: org = {}\", org);\n        }\n        println!();\n\n        output::header(\"Example Output (would show)\");\n        println!(\"  ID            NAME          ORG              PROJECTS  MEMBERS  ROLE\");\n        println!(\"  api-team      API Team      platform-eng        3         5    techlead\");\n        println!(\"  web-team      Web Team      product-eng         2         4    member\");\n        println!(\"  data-team     Data Team     platform-eng        2         3    member\");\n        println!();\n\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nasync fn run_show(args: TeamShowArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    let team_id = args.team_id.clone().unwrap_or_else(|| {\n        resolved\n            .team_id\n            .as_ref()\n            .map(|t| t.value.clone())\n            .unwrap_or_else(|| \"current\".to_string())\n    });\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"team_show\",\n            \"teamId\": team_id,\n            \"verbose\": args.verbose,\n            \"context\": {\n                \"tenantId\": resolved.tenant_id.value,\n                \"userId\": resolved.user_id.value,\n            },\n            \"status\": \"not_connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(&format!(\"Team: {}\", team_id));\n        println!();\n\n        output::header(\"Would Show\");\n        println!(\"  - Name and description\");\n        println!(\"  - Parent organization\");\n        println!(\"  - Projects count\");\n        println!(\"  - Members count and roles\");\n        println!(\"  - Your role in this team\");\n\n        if args.verbose {\n            println!();\n            output::header(\"Verbose Details\");\n            println!(\"  - List of projects\");\n            println!(\"  - Member list with roles\");\n            println!(\"  - Active policies\");\n            println!(\"  - Policy inheritance chain (company  org  team)\");\n        }\n        println!();\n\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nasync fn run_members(args: TeamMembersArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    let team_id = args.team.clone().unwrap_or_else(|| {\n        resolved\n            .team_id\n            .as_ref()\n            .map(|t| t.value.clone())\n            .unwrap_or_else(|| \"current\".to_string())\n    });\n\n    if let Some(ref user_to_add) = args.add {\n        let role = args.role.clone().unwrap_or_else(|| \"developer\".to_string());\n\n        let valid_roles = [\"developer\", \"techlead\", \"architect\"];\n        if !valid_roles.contains(&role.to_lowercase().as_str()) {\n            let err = ux_error::UxError::new(format!(\"Invalid team role: '{}'\", role))\n                .why(\"Team roles determine user permissions within the team\")\n                .fix(\"Use one of: developer, techlead, architect\")\n                .suggest(&format!(\n                    \"aeterna team members --add {} --role developer\",\n                    user_to_add\n                ));\n            err.display();\n            return Err(anyhow::anyhow!(\"Invalid role\"));\n        }\n\n        if args.json {\n            let output = json!({\n                \"operation\": \"team_member_add\",\n                \"teamId\": team_id,\n                \"userId\": user_to_add,\n                \"role\": role,\n                \"status\": \"not_connected\"\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Add Team Member\");\n            println!();\n            println!(\"  Team: {}\", team_id);\n            println!(\"  User: {}\", user_to_add);\n            println!(\"  Role: {}\", role);\n            println!();\n\n            output::header(\"Would Do\");\n            println!(\"  1. Verify user '{}' exists in parent org\", user_to_add);\n            println!(\"  2. Check your permission to add members\");\n            println!(\"  3. Add user with role '{}'\", role);\n            println!(\"  4. Grant access to team resources and projects\");\n            println!();\n\n            let err = ux_error::server_not_connected();\n            err.display();\n        }\n        return Ok(());\n    }\n\n    if let Some(ref user_to_remove) = args.remove {\n        if args.json {\n            let output = json!({\n                \"operation\": \"team_member_remove\",\n                \"teamId\": team_id,\n                \"userId\": user_to_remove,\n                \"status\": \"not_connected\"\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Remove Team Member\");\n            println!();\n            println!(\"  Team: {}\", team_id);\n            println!(\"  User: {}\", user_to_remove);\n            println!();\n\n            output::header(\"Would Do\");\n            println!(\"  1. Check your permission to remove members\");\n            println!(\"  2. Remove user from team\");\n            println!(\"  3. Revoke access to team resources\");\n            println!(\"  4. Keep user in parent org (if applicable)\");\n            println!();\n\n            let err = ux_error::server_not_connected();\n            err.display();\n        }\n        return Ok(());\n    }\n\n    if let Some(ref user_id) = args.set_role {\n        let role = args.role.clone().ok_or_else(|| {\n            let err = ux_error::UxError::new(\"Missing --role for --set-role\")\n                .why(\"Must specify which role to assign\")\n                .fix(\"Add --role with the desired role\")\n                .suggest(&format!(\n                    \"aeterna team members --set-role {} --role techlead\",\n                    user_id\n                ));\n            err.display();\n            anyhow::anyhow!(\"Missing role\")\n        })?;\n\n        if args.json {\n            let output = json!({\n                \"operation\": \"team_member_set_role\",\n                \"teamId\": team_id,\n                \"userId\": user_id,\n                \"newRole\": role,\n                \"status\": \"not_connected\"\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Set Member Role\");\n            println!();\n            println!(\"  Team:     {}\", team_id);\n            println!(\"  User:     {}\", user_id);\n            println!(\"  New Role: {}\", role);\n            println!();\n\n            let err = ux_error::server_not_connected();\n            err.display();\n        }\n        return Ok(());\n    }\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"team_members_list\",\n            \"teamId\": team_id,\n            \"context\": {\n                \"tenantId\": resolved.tenant_id.value,\n                \"userId\": resolved.user_id.value,\n            },\n            \"status\": \"not_connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(&format!(\"Members of: {}\", team_id));\n        println!();\n\n        output::header(\"Example Output (would show)\");\n        println!(\"  USER ID              NAME               ROLE        PROJECTS\");\n        println!(\"  alice@acme.com       Alice Smith        techlead    payments, auth\");\n        println!(\"  bob@acme.com         Bob Jones          developer   payments\");\n        println!(\"  carol@acme.com       Carol Williams     developer   auth, gateway\");\n        println!();\n\n        output::header(\"Actions\");\n        println!(\"  Add member:    aeterna team members --add <user> --role <role>\");\n        println!(\"  Remove member: aeterna team members --remove <user>\");\n        println!(\"  Change role:   aeterna team members --set-role <user> --role <role>\");\n        println!();\n\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nasync fn run_use(args: TeamUseArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let _resolved = resolver.resolve()?;\n\n    output::header(\"Set Default Team\");\n    println!();\n    println!(\"  Setting default team: {}\", args.team_id);\n    println!();\n\n    output::header(\"Would Update\");\n    println!(\"  File: .aeterna/context.toml\");\n    println!(\"  team_id = \\\"{}\\\"\", args.team_id);\n    println!();\n\n    output::header(\"Effect\");\n    println!(\n        \"  - All commands will use '{}' as default team\",\n        args.team_id\n    );\n    println!(\"  - Project commands scoped to this team\");\n    println!(\"  - Policies from this team will apply\");\n    println!();\n\n    let err = ux_error::server_not_connected();\n    err.display();\n\n    Ok(())\n}\n","traces":[{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":201,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":205,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":207,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":0}},{"line":221,"address":[],"length":0,"stats":{"Line":0}},{"line":223,"address":[],"length":0,"stats":{"Line":0}},{"line":225,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":240,"address":[],"length":0,"stats":{"Line":0}},{"line":241,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":0}},{"line":252,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":0}},{"line":254,"address":[],"length":0,"stats":{"Line":0}},{"line":255,"address":[],"length":0,"stats":{"Line":0}},{"line":256,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":264,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":0}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":270,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":272,"address":[],"length":0,"stats":{"Line":0}},{"line":274,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":276,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":284,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":298,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":0}},{"line":321,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":0}},{"line":323,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":325,"address":[],"length":0,"stats":{"Line":0}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":333,"address":[],"length":0,"stats":{"Line":0}},{"line":334,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":337,"address":[],"length":0,"stats":{"Line":0}},{"line":338,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":343,"address":[],"length":0,"stats":{"Line":0}},{"line":344,"address":[],"length":0,"stats":{"Line":0}},{"line":346,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":0}},{"line":350,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":353,"address":[],"length":0,"stats":{"Line":0}},{"line":354,"address":[],"length":0,"stats":{"Line":0}},{"line":355,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":359,"address":[],"length":0,"stats":{"Line":0}},{"line":360,"address":[],"length":0,"stats":{"Line":0}},{"line":361,"address":[],"length":0,"stats":{"Line":0}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":363,"address":[],"length":0,"stats":{"Line":0}},{"line":365,"address":[],"length":0,"stats":{"Line":0}},{"line":366,"address":[],"length":0,"stats":{"Line":0}},{"line":367,"address":[],"length":0,"stats":{"Line":0}},{"line":368,"address":[],"length":0,"stats":{"Line":0}},{"line":369,"address":[],"length":0,"stats":{"Line":0}},{"line":370,"address":[],"length":0,"stats":{"Line":0}},{"line":372,"address":[],"length":0,"stats":{"Line":0}},{"line":373,"address":[],"length":0,"stats":{"Line":0}},{"line":375,"address":[],"length":0,"stats":{"Line":0}},{"line":378,"address":[],"length":0,"stats":{"Line":0}},{"line":379,"address":[],"length":0,"stats":{"Line":0}},{"line":380,"address":[],"length":0,"stats":{"Line":0}},{"line":381,"address":[],"length":0,"stats":{"Line":0}},{"line":382,"address":[],"length":0,"stats":{"Line":0}},{"line":383,"address":[],"length":0,"stats":{"Line":0}},{"line":384,"address":[],"length":0,"stats":{"Line":0}},{"line":385,"address":[],"length":0,"stats":{"Line":0}},{"line":387,"address":[],"length":0,"stats":{"Line":0}},{"line":388,"address":[],"length":0,"stats":{"Line":0}},{"line":391,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":0}},{"line":393,"address":[],"length":0,"stats":{"Line":0}},{"line":394,"address":[],"length":0,"stats":{"Line":0}},{"line":395,"address":[],"length":0,"stats":{"Line":0}},{"line":396,"address":[],"length":0,"stats":{"Line":0}},{"line":397,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":401,"address":[],"length":0,"stats":{"Line":0}},{"line":402,"address":[],"length":0,"stats":{"Line":0}},{"line":403,"address":[],"length":0,"stats":{"Line":0}},{"line":404,"address":[],"length":0,"stats":{"Line":0}},{"line":405,"address":[],"length":0,"stats":{"Line":0}},{"line":406,"address":[],"length":0,"stats":{"Line":0}},{"line":408,"address":[],"length":0,"stats":{"Line":0}},{"line":409,"address":[],"length":0,"stats":{"Line":0}},{"line":411,"address":[],"length":0,"stats":{"Line":0}},{"line":414,"address":[],"length":0,"stats":{"Line":0}},{"line":415,"address":[],"length":0,"stats":{"Line":0}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":417,"address":[],"length":0,"stats":{"Line":0}},{"line":418,"address":[],"length":0,"stats":{"Line":0}},{"line":419,"address":[],"length":0,"stats":{"Line":0}},{"line":420,"address":[],"length":0,"stats":{"Line":0}},{"line":422,"address":[],"length":0,"stats":{"Line":0}},{"line":424,"address":[],"length":0,"stats":{"Line":0}},{"line":426,"address":[],"length":0,"stats":{"Line":0}},{"line":427,"address":[],"length":0,"stats":{"Line":0}},{"line":429,"address":[],"length":0,"stats":{"Line":0}},{"line":430,"address":[],"length":0,"stats":{"Line":0}},{"line":431,"address":[],"length":0,"stats":{"Line":0}},{"line":432,"address":[],"length":0,"stats":{"Line":0}},{"line":433,"address":[],"length":0,"stats":{"Line":0}},{"line":434,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":0}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":442,"address":[],"length":0,"stats":{"Line":0}},{"line":443,"address":[],"length":0,"stats":{"Line":0}},{"line":446,"address":[],"length":0,"stats":{"Line":0}},{"line":449,"address":[],"length":0,"stats":{"Line":0}},{"line":450,"address":[],"length":0,"stats":{"Line":0}},{"line":451,"address":[],"length":0,"stats":{"Line":0}},{"line":453,"address":[],"length":0,"stats":{"Line":0}},{"line":454,"address":[],"length":0,"stats":{"Line":0}},{"line":455,"address":[],"length":0,"stats":{"Line":0}},{"line":456,"address":[],"length":0,"stats":{"Line":0}},{"line":458,"address":[],"length":0,"stats":{"Line":0}},{"line":459,"address":[],"length":0,"stats":{"Line":0}},{"line":460,"address":[],"length":0,"stats":{"Line":0}},{"line":461,"address":[],"length":0,"stats":{"Line":0}},{"line":463,"address":[],"length":0,"stats":{"Line":0}},{"line":464,"address":[],"length":0,"stats":{"Line":0}},{"line":465,"address":[],"length":0,"stats":{"Line":0}},{"line":468,"address":[],"length":0,"stats":{"Line":0}},{"line":469,"address":[],"length":0,"stats":{"Line":0}},{"line":470,"address":[],"length":0,"stats":{"Line":0}},{"line":472,"address":[],"length":0,"stats":{"Line":0}},{"line":473,"address":[],"length":0,"stats":{"Line":0}},{"line":475,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":259},{"path":["/","Users","christian.klat","dev","git","aeterna","cli","src","commands","user.rs"],"content":"use clap::{Args, Subcommand};\nuse context::ContextResolver;\nuse serde_json::json;\n\nuse crate::output;\nuse crate::ux_error;\n\n#[derive(Subcommand)]\npub enum UserCommand {\n    #[command(about = \"Register current user or show registration status\")]\n    Register(UserRegisterArgs),\n\n    #[command(about = \"List users in your organization/team\")]\n    List(UserListArgs),\n\n    #[command(about = \"Show user details\")]\n    Show(UserShowArgs),\n\n    #[command(about = \"Manage user roles\")]\n    Roles(UserRolesArgs),\n\n    #[command(about = \"Show current user profile\")]\n    Whoami(UserWhoamiArgs),\n\n    #[command(about = \"Invite a user to join organization/team\")]\n    Invite(UserInviteArgs),\n}\n\n#[derive(Args)]\npub struct UserRegisterArgs {\n    #[arg(long)]\n    pub email: Option<String>,\n\n    #[arg(long)]\n    pub name: Option<String>,\n\n    #[arg(long)]\n    pub org: Option<String>,\n\n    #[arg(long)]\n    pub team: Option<String>,\n\n    #[arg(long)]\n    pub json: bool,\n\n    #[arg(long)]\n    pub dry_run: bool,\n}\n\n#[derive(Args)]\npub struct UserListArgs {\n    #[arg(long)]\n    pub org: Option<String>,\n\n    #[arg(long)]\n    pub team: Option<String>,\n\n    #[arg(long)]\n    pub role: Option<String>,\n\n    #[arg(long)]\n    pub all: bool,\n\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct UserShowArgs {\n    pub user_id: Option<String>,\n\n    #[arg(short, long)]\n    pub verbose: bool,\n\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct UserRolesArgs {\n    #[arg(long)]\n    pub user: Option<String>,\n\n    #[arg(short, long)]\n    pub list: bool,\n\n    #[arg(long)]\n    pub grant: Option<String>,\n\n    #[arg(long)]\n    pub revoke: Option<String>,\n\n    #[arg(long)]\n    pub scope: Option<String>,\n\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct UserWhoamiArgs {\n    #[arg(long)]\n    pub json: bool,\n}\n\n#[derive(Args)]\npub struct UserInviteArgs {\n    pub email: String,\n\n    #[arg(short, long)]\n    pub org: Option<String>,\n\n    #[arg(short, long)]\n    pub team: Option<String>,\n\n    #[arg(short, long, default_value = \"developer\")]\n    pub role: String,\n\n    #[arg(short, long)]\n    pub message: Option<String>,\n\n    #[arg(short, long)]\n    pub yes: bool,\n\n    #[arg(long)]\n    pub json: bool,\n\n    #[arg(long)]\n    pub dry_run: bool,\n}\n\npub async fn run(cmd: UserCommand) -> anyhow::Result<()> {\n    match cmd {\n        UserCommand::Register(args) => run_register(args).await,\n        UserCommand::List(args) => run_list(args).await,\n        UserCommand::Show(args) => run_show(args).await,\n        UserCommand::Roles(args) => run_roles(args).await,\n        UserCommand::Whoami(args) => run_whoami(args).await,\n        UserCommand::Invite(args) => run_invite(args).await,\n    }\n}\n\nasync fn run_register(args: UserRegisterArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    let email = args\n        .email\n        .clone()\n        .unwrap_or_else(|| resolved.user_id.value.clone());\n\n    let display_name = args.name.clone().unwrap_or_else(|| {\n        email\n            .split('@')\n            .next()\n            .unwrap_or(\"User\")\n            .replace('.', \" \")\n            .split_whitespace()\n            .map(|w| {\n                let mut chars = w.chars();\n                match chars.next() {\n                    None => String::new(),\n                    Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),\n                }\n            })\n            .collect::<Vec<_>>()\n            .join(\" \")\n    });\n\n    if args.dry_run {\n        if args.json {\n            let output = json!({\n                \"dryRun\": true,\n                \"operation\": \"user_register\",\n                \"user\": {\n                    \"email\": email,\n                    \"name\": display_name,\n                    \"org\": args.org,\n                    \"team\": args.team,\n                },\n                \"context\": {\n                    \"tenantId\": resolved.tenant_id.value,\n                },\n                \"nextSteps\": [\n                    \"Review registration details\",\n                    \"Run without --dry-run to register\",\n                    \"Admin approval may be required\"\n                ]\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"User Registration (Dry Run)\");\n            println!();\n            println!(\"  Email: {}\", email);\n            println!(\"  Name:  {}\", display_name);\n            if let Some(ref org) = args.org {\n                println!(\"  Org:   {}\", org);\n            }\n            if let Some(ref team) = args.team {\n                println!(\"  Team:  {}\", team);\n            }\n            println!();\n\n            output::header(\"What Would Happen\");\n            println!(\"  1. Create user account for '{}'\", email);\n            println!(\"  2. Set display name to '{}'\", display_name);\n            if args.org.is_some() || args.team.is_some() {\n                println!(\"  3. Request membership in specified org/team\");\n                println!(\"  4. Wait for admin approval (if required)\");\n            } else {\n                println!(\"  3. Grant access to company-level resources\");\n            }\n            println!();\n\n            output::header(\"Next Steps\");\n            println!(\"  1. Run without --dry-run to register\");\n            println!(\"  2. Complete any required verification\");\n            println!(\"  3. Use 'aeterna user whoami' to verify registration\");\n            println!();\n\n            output::info(\"Dry run mode - user not registered.\");\n        }\n        return Ok(());\n    }\n\n    let err = ux_error::server_not_connected();\n    err.display();\n    output::info(\"Run with --dry-run to see what would be created.\");\n\n    Ok(())\n}\n\nasync fn run_list(args: UserListArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"user_list\",\n            \"filters\": {\n                \"org\": args.org,\n                \"team\": args.team,\n                \"role\": args.role,\n                \"all\": args.all,\n            },\n            \"context\": {\n                \"tenantId\": resolved.tenant_id.value,\n                \"userId\": resolved.user_id.value,\n            },\n            \"status\": \"not_connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(\"Users\");\n        println!();\n\n        if args.all {\n            output::info(\"Showing all users you have access to.\");\n        }\n\n        if let Some(ref org) = args.org {\n            println!(\"  Filter: org = {}\", org);\n        }\n        if let Some(ref team) = args.team {\n            println!(\"  Filter: team = {}\", team);\n        }\n        if let Some(ref role) = args.role {\n            println!(\"  Filter: role = {}\", role);\n        }\n        println!();\n\n        output::header(\"Example Output (would show)\");\n        println!(\"  EMAIL                    NAME               ROLE        TEAMS\");\n        println!(\"  alice@acme.com           Alice Smith        admin       api, data, web\");\n        println!(\"  bob@acme.com             Bob Jones          techlead    api\");\n        println!(\"  carol@acme.com           Carol Williams     developer   web, mobile\");\n        println!();\n\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nasync fn run_show(args: UserShowArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    let user_id = args\n        .user_id\n        .clone()\n        .unwrap_or_else(|| resolved.user_id.value.clone());\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"user_show\",\n            \"userId\": user_id,\n            \"verbose\": args.verbose,\n            \"context\": {\n                \"tenantId\": resolved.tenant_id.value,\n                \"userId\": resolved.user_id.value,\n            },\n            \"status\": \"not_connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(&format!(\"User: {}\", user_id));\n        println!();\n\n        output::header(\"Would Show\");\n        println!(\"  - Email and display name\");\n        println!(\"  - Organization memberships\");\n        println!(\"  - Team memberships\");\n        println!(\"  - Roles at each level\");\n        println!(\"  - Registration date\");\n\n        if args.verbose {\n            println!();\n            output::header(\"Verbose Details\");\n            println!(\"  - Full permission list\");\n            println!(\"  - Recent activity\");\n            println!(\"  - Associated agents\");\n            println!(\"  - Audit trail\");\n        }\n        println!();\n\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nasync fn run_roles(args: UserRolesArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    let user_id = args\n        .user\n        .clone()\n        .unwrap_or_else(|| resolved.user_id.value.clone());\n\n    if let Some(ref role_to_grant) = args.grant {\n        let valid_roles = [\"developer\", \"techlead\", \"architect\", \"admin\"];\n        if !valid_roles.contains(&role_to_grant.to_lowercase().as_str()) {\n            let err = ux_error::UxError::new(format!(\"Invalid role: '{}'\", role_to_grant))\n                .why(\"Role must be one of the predefined governance roles\")\n                .fix(\"Use one of: developer, techlead, architect, admin\")\n                .suggest(&format!(\n                    \"aeterna user roles --user {} --grant developer\",\n                    user_id\n                ));\n            err.display();\n            return Err(anyhow::anyhow!(\"Invalid role\"));\n        }\n\n        let scope = args.scope.clone().unwrap_or_else(|| \"company\".to_string());\n\n        if args.json {\n            let output = json!({\n                \"operation\": \"user_role_grant\",\n                \"userId\": user_id,\n                \"role\": role_to_grant,\n                \"scope\": scope,\n                \"status\": \"not_connected\"\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Grant Role\");\n            println!();\n            println!(\"  User:  {}\", user_id);\n            println!(\"  Role:  {}\", role_to_grant);\n            println!(\"  Scope: {}\", scope);\n            println!();\n\n            output::header(\"Would Do\");\n            println!(\"  1. Verify your admin permissions\");\n            println!(\n                \"  2. Grant '{}' role to '{}' at {} level\",\n                role_to_grant, user_id, scope\n            );\n            println!(\"  3. Update Cedar policies\");\n            println!(\"  4. Log audit event\");\n            println!();\n\n            let err = ux_error::server_not_connected();\n            err.display();\n        }\n        return Ok(());\n    }\n\n    if let Some(ref role_to_revoke) = args.revoke {\n        let scope = args.scope.clone().unwrap_or_else(|| \"company\".to_string());\n\n        if args.json {\n            let output = json!({\n                \"operation\": \"user_role_revoke\",\n                \"userId\": user_id,\n                \"role\": role_to_revoke,\n                \"scope\": scope,\n                \"status\": \"not_connected\"\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"Revoke Role\");\n            println!();\n            println!(\"  User:  {}\", user_id);\n            println!(\"  Role:  {}\", role_to_revoke);\n            println!(\"  Scope: {}\", scope);\n            println!();\n\n            output::header(\"Would Do\");\n            println!(\"  1. Verify your admin permissions\");\n            println!(\n                \"  2. Revoke '{}' role from '{}' at {} level\",\n                role_to_revoke, user_id, scope\n            );\n            println!(\"  3. Update Cedar policies\");\n            println!(\"  4. Log audit event\");\n            println!();\n\n            let err = ux_error::server_not_connected();\n            err.display();\n        }\n        return Ok(());\n    }\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"user_roles_list\",\n            \"userId\": user_id,\n            \"context\": {\n                \"tenantId\": resolved.tenant_id.value,\n            },\n            \"status\": \"not_connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(&format!(\"Roles for: {}\", user_id));\n        println!();\n\n        output::header(\"Example Output (would show)\");\n        println!(\"  SCOPE          ROLE        GRANTED BY         DATE\");\n        println!(\"  company        developer   system             2024-01-15\");\n        println!(\"  platform-eng   techlead    alice@acme.com     2024-03-20\");\n        println!(\"  api-team       architect   bob@acme.com       2024-06-01\");\n        println!();\n\n        output::header(\"Role Hierarchy\");\n        println!(\"  admin     (4) - Full system access\");\n        println!(\"  architect (3) - Design policies, manage knowledge\");\n        println!(\"  techlead  (2) - Manage team resources\");\n        println!(\"  developer (1) - Standard development access\");\n        println!();\n\n        output::header(\"Actions\");\n        println!(\n            \"  Grant role:  aeterna user roles --user {} --grant <role> --scope <scope>\",\n            user_id\n        );\n        println!(\n            \"  Revoke role: aeterna user roles --user {} --revoke <role> --scope <scope>\",\n            user_id\n        );\n        println!();\n\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nasync fn run_whoami(args: UserWhoamiArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"user_whoami\",\n            \"user\": {\n                \"id\": resolved.user_id.value,\n                \"tenant\": resolved.tenant_id.value,\n                \"org\": resolved.org_id.as_ref().map(|o| &o.value),\n                \"team\": resolved.team_id.as_ref().map(|t| &t.value),\n                \"project\": resolved.project_id.as_ref().map(|p| &p.value),\n            },\n            \"source\": {\n                \"userId\": format!(\"{:?}\", resolved.user_id.source),\n                \"tenantId\": format!(\"{:?}\", resolved.tenant_id.source),\n            }\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(\"Current User\");\n        println!();\n        println!(\n            \"  User ID:    {}  (from {})\",\n            resolved.user_id.value, resolved.user_id.source\n        );\n        println!(\n            \"  Tenant:     {}  (from {})\",\n            resolved.tenant_id.value, resolved.tenant_id.source\n        );\n\n        if let Some(ref org) = resolved.org_id {\n            println!(\"  Org:        {}  (from {})\", org.value, org.source);\n        }\n        if let Some(ref team) = resolved.team_id {\n            println!(\"  Team:       {}  (from {})\", team.value, team.source);\n        }\n        if let Some(ref project) = resolved.project_id {\n            println!(\"  Project:    {}  (from {})\", project.value, project.source);\n        }\n        println!();\n\n        output::header(\"Context Sources\");\n        println!(\"  git     - Detected from git remote/user.email\");\n        println!(\"  env     - Environment variables (AETERNA_*)\");\n        println!(\"  config  - .aeterna/context.toml file\");\n        println!(\"  default - Built-in defaults\");\n        println!();\n\n        output::info(\"Use 'aeterna context set' to override any value.\");\n    }\n\n    Ok(())\n}\n\nasync fn run_invite(args: UserInviteArgs) -> anyhow::Result<()> {\n    let resolver = ContextResolver::new();\n    let resolved = resolver.resolve()?;\n\n    if !args.email.contains('@') || !args.email.contains('.') {\n        let err = ux_error::UxError::new(format!(\"Invalid email address: '{}'\", args.email))\n            .why(\"Email must be a valid email address format\")\n            .fix(\"Provide a properly formatted email address\")\n            .suggest(\"aeterna user invite alice@example.com\");\n        err.display();\n        return Err(anyhow::anyhow!(\"Invalid email\"));\n    }\n\n    let valid_roles = [\"developer\", \"techlead\", \"architect\", \"admin\"];\n    let role_lower = args.role.to_lowercase();\n    if !valid_roles.contains(&role_lower.as_str()) {\n        let err = ux_error::UxError::new(format!(\"Invalid role: '{}'\", args.role))\n            .why(\"Role must be one of the predefined governance roles\")\n            .fix(\"Use one of: developer, techlead, architect, admin\")\n            .suggest(&format!(\n                \"aeterna user invite {} --role developer\",\n                args.email\n            ));\n        err.display();\n        return Err(anyhow::anyhow!(\"Invalid role\"));\n    }\n\n    let target_org = args\n        .org\n        .clone()\n        .or_else(|| resolved.org_id.as_ref().map(|o| o.value.clone()));\n    let target_team = args\n        .team\n        .clone()\n        .or_else(|| resolved.team_id.as_ref().map(|t| t.value.clone()));\n\n    if target_org.is_none() {\n        let err = ux_error::UxError::new(\"No organization specified for invitation\")\n            .why(\"Users must be invited to a specific organization or team\")\n            .fix(\"Specify --org or set your context to an organization\")\n            .suggest(\"aeterna user invite alice@example.com --org platform-eng\");\n        err.display();\n        return Err(anyhow::anyhow!(\"No organization specified\"));\n    }\n\n    let org_name = target_org.as_ref().unwrap();\n\n    if args.dry_run {\n        if args.json {\n            let output = json!({\n                \"dryRun\": true,\n                \"operation\": \"user_invite\",\n                \"invitation\": {\n                    \"email\": args.email,\n                    \"org\": org_name,\n                    \"team\": target_team,\n                    \"role\": role_lower,\n                    \"message\": args.message,\n                },\n                \"invitedBy\": resolved.user_id.value,\n                \"context\": {\n                    \"tenantId\": resolved.tenant_id.value,\n                },\n                \"nextSteps\": [\n                    \"Review invitation details\",\n                    \"Run without --dry-run to send invitation\",\n                    \"Invitee will receive email with join link\"\n                ]\n            });\n            println!(\"{}\", serde_json::to_string_pretty(&output)?);\n        } else {\n            output::header(\"User Invitation (Dry Run)\");\n            println!();\n            println!(\"  Inviting: {}\", args.email);\n            println!(\"  To Org:   {}\", org_name);\n            if let Some(ref team) = target_team {\n                println!(\"  To Team:  {}\", team);\n            }\n            println!(\"  Role:     {}\", role_lower);\n            if let Some(ref msg) = args.message {\n                println!(\"  Message:  \\\"{}\\\"\", msg);\n            }\n            println!();\n\n            output::header(\"What Would Happen\");\n            println!(\"  1. Create pending invitation record\");\n            println!(\"  2. Generate unique invitation link\");\n            println!(\"  3. Send invitation email to '{}'\", args.email);\n            println!(\"  4. Record audit event\");\n            println!();\n\n            output::header(\"Invitation Email Preview\");\n            println!(\n                \"  Subject: You've been invited to join {} on Aeterna\",\n                org_name\n            );\n            println!();\n            println!(\"  Body:\");\n            println!(\"  ----\");\n            println!(\n                \"  {} has invited you to join {}.\",\n                resolved.user_id.value, org_name\n            );\n            if let Some(ref team) = target_team {\n                println!(\"  You will be added to the '{}' team.\", team);\n            }\n            println!(\"  Your initial role will be: {}\", role_lower);\n            if let Some(ref msg) = args.message {\n                println!();\n                println!(\"  Personal message:\");\n                println!(\"  \\\"{}\\\"\", msg);\n            }\n            println!();\n            println!(\"  Click here to accept: https://aeterna.example.com/invite/abc123...\");\n            println!(\"  ----\");\n            println!();\n\n            output::header(\"After Acceptance\");\n            println!(\"  - User account created for '{}'\", args.email);\n            println!(\"  - Membership granted to '{}'\", org_name);\n            if let Some(ref team) = target_team {\n                println!(\"  - Added to team '{}'\", team);\n            }\n            println!(\"  - Role '{}' assigned at appropriate scope\", role_lower);\n            println!();\n\n            output::info(\"Dry run mode - invitation not sent.\");\n        }\n        return Ok(());\n    }\n\n    if !args.yes {\n        println!();\n        output::header(\"Confirm Invitation\");\n        println!();\n        println!(\"  Email:    {}\", args.email);\n        println!(\"  Org:      {}\", org_name);\n        if let Some(ref team) = target_team {\n            println!(\"  Team:     {}\", team);\n        }\n        println!(\"  Role:     {}\", role_lower);\n        println!();\n\n        output::warn(\"This will send an invitation email to the user.\");\n        println!();\n        println!(\"  Use --yes to skip this prompt.\");\n        println!(\"  Use --dry-run to preview without sending.\");\n        println!();\n\n        output::info(\"Confirmation required. Use --yes to proceed.\");\n        return Ok(());\n    }\n\n    if args.json {\n        let output = json!({\n            \"operation\": \"user_invite\",\n            \"invitation\": {\n                \"id\": format!(\"inv_{}\", generate_invitation_id()),\n                \"email\": args.email,\n                \"org\": org_name,\n                \"team\": target_team,\n                \"role\": role_lower,\n                \"status\": \"pending\",\n                \"expiresAt\": \"2024-02-15T00:00:00Z\",\n            },\n            \"invitedBy\": resolved.user_id.value,\n            \"status\": \"not_connected\"\n        });\n        println!(\"{}\", serde_json::to_string_pretty(&output)?);\n    } else {\n        output::header(\"Send Invitation\");\n        println!();\n        println!(\"  Email:    {}\", args.email);\n        println!(\"  Org:      {}\", org_name);\n        if let Some(ref team) = target_team {\n            println!(\"  Team:     {}\", team);\n        }\n        println!(\"  Role:     {}\", role_lower);\n        println!();\n\n        output::header(\"Would Do\");\n        println!(\"  1. Verify your permission to invite users\");\n        println!(\"  2. Create invitation record (expires in 7 days)\");\n        println!(\"  3. Send email to '{}'\", args.email);\n        println!(\"  4. Log audit event\");\n        println!();\n\n        output::header(\"After Sending\");\n        println!(\"  - Track invitation: aeterna user invite --list\");\n        println!(\n            \"  - Resend if needed: aeterna user invite {} --resend\",\n            args.email\n        );\n        println!(\n            \"  - Cancel:           aeterna user invite {} --cancel\",\n            args.email\n        );\n        println!();\n\n        let err = ux_error::server_not_connected();\n        err.display();\n    }\n\n    Ok(())\n}\n\nfn generate_invitation_id() -> String {\n    use std::time::{SystemTime, UNIX_EPOCH};\n    let now = SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .unwrap()\n        .as_millis();\n    format!(\"{:x}\", now)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_user_register_args_defaults() {\n        let args = UserRegisterArgs {\n            email: None,\n            name: None,\n            org: None,\n            team: None,\n            json: false,\n            dry_run: false,\n        };\n        assert!(args.email.is_none());\n        assert!(args.name.is_none());\n        assert!(args.org.is_none());\n        assert!(args.team.is_none());\n        assert!(!args.json);\n        assert!(!args.dry_run);\n    }\n\n    #[test]\n    fn test_user_register_args_with_all_options() {\n        let args = UserRegisterArgs {\n            email: Some(\"alice@example.com\".to_string()),\n            name: Some(\"Alice Smith\".to_string()),\n            org: Some(\"platform-eng\".to_string()),\n            team: Some(\"api-team\".to_string()),\n            json: true,\n            dry_run: true,\n        };\n        assert_eq!(args.email, Some(\"alice@example.com\".to_string()));\n        assert_eq!(args.name, Some(\"Alice Smith\".to_string()));\n        assert_eq!(args.org, Some(\"platform-eng\".to_string()));\n        assert_eq!(args.team, Some(\"api-team\".to_string()));\n        assert!(args.json);\n        assert!(args.dry_run);\n    }\n\n    #[test]\n    fn test_user_list_args_defaults() {\n        let args = UserListArgs {\n            org: None,\n            team: None,\n            role: None,\n            all: false,\n            json: false,\n        };\n        assert!(args.org.is_none());\n        assert!(args.team.is_none());\n        assert!(args.role.is_none());\n        assert!(!args.all);\n        assert!(!args.json);\n    }\n\n    #[test]\n    fn test_user_list_args_with_filters() {\n        let args = UserListArgs {\n            org: Some(\"engineering\".to_string()),\n            team: Some(\"backend\".to_string()),\n            role: Some(\"developer\".to_string()),\n            all: true,\n            json: true,\n        };\n        assert_eq!(args.org, Some(\"engineering\".to_string()));\n        assert_eq!(args.team, Some(\"backend\".to_string()));\n        assert_eq!(args.role, Some(\"developer\".to_string()));\n        assert!(args.all);\n    }\n\n    #[test]\n    fn test_user_show_args_defaults() {\n        let args = UserShowArgs {\n            user_id: None,\n            verbose: false,\n            json: false,\n        };\n        assert!(args.user_id.is_none());\n        assert!(!args.verbose);\n        assert!(!args.json);\n    }\n\n    #[test]\n    fn test_user_show_args_with_user_id() {\n        let args = UserShowArgs {\n            user_id: Some(\"alice@example.com\".to_string()),\n            verbose: true,\n            json: true,\n        };\n        assert_eq!(args.user_id, Some(\"alice@example.com\".to_string()));\n        assert!(args.verbose);\n    }\n\n    #[test]\n    fn test_user_roles_args_list_mode() {\n        let args = UserRolesArgs {\n            user: None,\n            list: true,\n            grant: None,\n            revoke: None,\n            scope: None,\n            json: false,\n        };\n        assert!(args.list);\n        assert!(args.grant.is_none());\n        assert!(args.revoke.is_none());\n    }\n\n    #[test]\n    fn test_user_roles_args_grant_mode() {\n        let args = UserRolesArgs {\n            user: Some(\"bob@example.com\".to_string()),\n            list: false,\n            grant: Some(\"techlead\".to_string()),\n            revoke: None,\n            scope: Some(\"api-team\".to_string()),\n            json: true,\n        };\n        assert_eq!(args.user, Some(\"bob@example.com\".to_string()));\n        assert_eq!(args.grant, Some(\"techlead\".to_string()));\n        assert_eq!(args.scope, Some(\"api-team\".to_string()));\n    }\n\n    #[test]\n    fn test_user_roles_args_revoke_mode() {\n        let args = UserRolesArgs {\n            user: Some(\"bob@example.com\".to_string()),\n            list: false,\n            grant: None,\n            revoke: Some(\"admin\".to_string()),\n            scope: Some(\"company\".to_string()),\n            json: false,\n        };\n        assert_eq!(args.revoke, Some(\"admin\".to_string()));\n    }\n\n    #[test]\n    fn test_user_whoami_args() {\n        let args = UserWhoamiArgs { json: false };\n        assert!(!args.json);\n\n        let args_json = UserWhoamiArgs { json: true };\n        assert!(args_json.json);\n    }\n\n    #[test]\n    fn test_user_invite_args_minimal() {\n        let args = UserInviteArgs {\n            email: \"newuser@example.com\".to_string(),\n            org: None,\n            team: None,\n            role: \"developer\".to_string(),\n            message: None,\n            yes: false,\n            json: false,\n            dry_run: false,\n        };\n        assert_eq!(args.email, \"newuser@example.com\");\n        assert_eq!(args.role, \"developer\");\n        assert!(args.org.is_none());\n        assert!(!args.yes);\n    }\n\n    #[test]\n    fn test_user_invite_args_full() {\n        let args = UserInviteArgs {\n            email: \"carol@example.com\".to_string(),\n            org: Some(\"product-eng\".to_string()),\n            team: Some(\"mobile\".to_string()),\n            role: \"techlead\".to_string(),\n            message: Some(\"Welcome to the team!\".to_string()),\n            yes: true,\n            json: true,\n            dry_run: true,\n        };\n        assert_eq!(args.email, \"carol@example.com\");\n        assert_eq!(args.org, Some(\"product-eng\".to_string()));\n        assert_eq!(args.team, Some(\"mobile\".to_string()));\n        assert_eq!(args.role, \"techlead\");\n        assert_eq!(args.message, Some(\"Welcome to the team!\".to_string()));\n        assert!(args.yes);\n        assert!(args.dry_run);\n    }\n\n    #[test]\n    fn test_generate_invitation_id() {\n        let id1 = generate_invitation_id();\n        let id2 = generate_invitation_id();\n\n        assert!(!id1.is_empty());\n        assert!(id1.chars().all(|c| c.is_ascii_hexdigit()));\n        assert!(id2.chars().all(|c| c.is_ascii_hexdigit()));\n    }\n\n    #[test]\n    fn test_generate_invitation_id_format() {\n        let id = generate_invitation_id();\n        assert!(id.len() >= 8);\n    }\n\n    #[test]\n    fn test_email_validation_valid() {\n        let valid_emails = [\n            \"user@example.com\",\n            \"alice.smith@company.org\",\n            \"bob+tag@domain.co.uk\",\n        ];\n        for email in valid_emails {\n            assert!(\n                email.contains('@') && email.contains('.'),\n                \"Email should be valid: {}\",\n                email\n            );\n        }\n    }\n\n    #[test]\n    fn test_email_validation_invalid() {\n        let invalid_emails = [\"userexample.com\", \"user@example\", \"@example.com\", \"user@\"];\n        for email in invalid_emails {\n            let is_valid = email.contains('@') && email.contains('.');\n            if email == \"user@example\" || email == \"user@\" {\n                assert!(\n                    !is_valid || !email.split('@').last().unwrap_or(\"\").contains('.'),\n                    \"Email should be invalid: {}\",\n                    email\n                );\n            }\n        }\n    }\n\n    #[test]\n    fn test_role_validation_valid_roles() {\n        let valid_roles = [\"developer\", \"techlead\", \"architect\", \"admin\"];\n        for role in valid_roles {\n            assert!(valid_roles.contains(&role.to_lowercase().as_str()));\n        }\n    }\n\n    #[test]\n    fn test_role_validation_invalid_roles() {\n        let valid_roles = [\"developer\", \"techlead\", \"architect\", \"admin\"];\n        let invalid_roles = [\"superuser\", \"root\", \"manager\", \"viewer\"];\n        for role in invalid_roles {\n            assert!(!valid_roles.contains(&role.to_lowercase().as_str()));\n        }\n    }\n\n    #[test]\n    fn test_role_validation_case_insensitive() {\n        let valid_roles = [\"developer\", \"techlead\", \"architect\", \"admin\"];\n        let mixed_case = [\"Developer\", \"TECHLEAD\", \"Architect\", \"ADMIN\"];\n        for role in mixed_case {\n            assert!(valid_roles.contains(&role.to_lowercase().as_str()));\n        }\n    }\n\n    #[test]\n    fn test_user_register_args_email_only() {\n        let args = UserRegisterArgs {\n            email: Some(\"test@company.com\".to_string()),\n            name: None,\n            org: None,\n            team: None,\n            json: false,\n            dry_run: false,\n        };\n        assert!(args.email.is_some());\n        assert!(args.name.is_none());\n    }\n\n    #[test]\n    fn test_user_list_args_all_flag() {\n        let args = UserListArgs {\n            org: None,\n            team: None,\n            role: None,\n            all: true,\n            json: false,\n        };\n        assert!(args.all);\n    }\n\n    #[test]\n    fn test_user_roles_args_no_action() {\n        let args = UserRolesArgs {\n            user: Some(\"user@example.com\".to_string()),\n            list: false,\n            grant: None,\n            revoke: None,\n            scope: None,\n            json: false,\n        };\n        assert!(!args.list);\n        assert!(args.grant.is_none());\n        assert!(args.revoke.is_none());\n    }\n\n    #[test]\n    fn test_user_roles_args_scope_levels() {\n        let scopes = [\"company\", \"org\", \"team\", \"project\"];\n        for scope in scopes {\n            let args = UserRolesArgs {\n                user: Some(\"user@example.com\".to_string()),\n                list: false,\n                grant: Some(\"developer\".to_string()),\n                revoke: None,\n                scope: Some(scope.to_string()),\n                json: false,\n            };\n            assert_eq!(args.scope, Some(scope.to_string()));\n        }\n    }\n\n    #[test]\n    fn test_user_invite_args_all_roles() {\n        let roles = [\"developer\", \"techlead\", \"architect\", \"admin\"];\n        for role in roles {\n            let args = UserInviteArgs {\n                email: \"test@example.com\".to_string(),\n                org: Some(\"test-org\".to_string()),\n                team: None,\n                role: role.to_string(),\n                message: None,\n                yes: true,\n                json: false,\n                dry_run: false,\n            };\n            assert_eq!(args.role, role);\n        }\n    }\n\n    #[test]\n    fn test_user_invite_args_with_message() {\n        let args = UserInviteArgs {\n            email: \"new@example.com\".to_string(),\n            org: Some(\"engineering\".to_string()),\n            team: Some(\"api\".to_string()),\n            role: \"developer\".to_string(),\n            message: Some(\"Please join our team for the Q1 project\".to_string()),\n            yes: false,\n            json: false,\n            dry_run: false,\n        };\n        assert!(args.message.is_some());\n        assert!(args.message.unwrap().len() > 10);\n    }\n\n    #[test]\n    fn test_user_show_args_verbose_mode() {\n        let args = UserShowArgs {\n            user_id: Some(\"detailed-user@example.com\".to_string()),\n            verbose: true,\n            json: false,\n        };\n        assert!(args.verbose);\n        assert!(!args.json);\n    }\n\n    #[test]\n    fn test_user_list_args_org_filter_only() {\n        let args = UserListArgs {\n            org: Some(\"platform\".to_string()),\n            team: None,\n            role: None,\n            all: false,\n            json: false,\n        };\n        assert!(args.org.is_some());\n        assert!(args.team.is_none());\n        assert!(args.role.is_none());\n    }\n\n    #[test]\n    fn test_user_list_args_team_filter_only() {\n        let args = UserListArgs {\n            org: None,\n            team: Some(\"frontend\".to_string()),\n            role: None,\n            all: false,\n            json: false,\n        };\n        assert!(args.team.is_some());\n        assert!(args.org.is_none());\n    }\n\n    #[test]\n    fn test_user_list_args_role_filter_only() {\n        let args = UserListArgs {\n            org: None,\n            team: None,\n            role: Some(\"admin\".to_string()),\n            all: false,\n            json: true,\n        };\n        assert!(args.role.is_some());\n        assert!(args.json);\n    }\n}\n","traces":[{"line":132,"address":[],"length":0,"stats":{"Line":12}},{"line":133,"address":[],"length":0,"stats":{"Line":6}},{"line":134,"address":[],"length":0,"stats":{"Line":3}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":9}},{"line":139,"address":[],"length":0,"stats":{"Line":6}},{"line":143,"address":[],"length":0,"stats":{"Line":2}},{"line":144,"address":[],"length":0,"stats":{"Line":2}},{"line":145,"address":[],"length":0,"stats":{"Line":3}},{"line":147,"address":[],"length":0,"stats":{"Line":2}},{"line":148,"address":[],"length":0,"stats":{"Line":1}},{"line":150,"address":[],"length":0,"stats":{"Line":3}},{"line":152,"address":[],"length":0,"stats":{"Line":5}},{"line":153,"address":[],"length":0,"stats":{"Line":3}},{"line":154,"address":[],"length":0,"stats":{"Line":3}},{"line":155,"address":[],"length":0,"stats":{"Line":3}},{"line":156,"address":[],"length":0,"stats":{"Line":2}},{"line":157,"address":[],"length":0,"stats":{"Line":1}},{"line":158,"address":[],"length":0,"stats":{"Line":1}},{"line":159,"address":[],"length":0,"stats":{"Line":3}},{"line":160,"address":[],"length":0,"stats":{"Line":6}},{"line":161,"address":[],"length":0,"stats":{"Line":2}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":10}},{"line":166,"address":[],"length":0,"stats":{"Line":1}},{"line":167,"address":[],"length":0,"stats":{"Line":2}},{"line":170,"address":[],"length":0,"stats":{"Line":1}},{"line":171,"address":[],"length":0,"stats":{"Line":1}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":2}},{"line":193,"address":[],"length":0,"stats":{"Line":1}},{"line":194,"address":[],"length":0,"stats":{"Line":2}},{"line":195,"address":[],"length":0,"stats":{"Line":2}},{"line":196,"address":[],"length":0,"stats":{"Line":1}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":1}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":1}},{"line":204,"address":[],"length":0,"stats":{"Line":2}},{"line":205,"address":[],"length":0,"stats":{"Line":2}},{"line":206,"address":[],"length":0,"stats":{"Line":2}},{"line":207,"address":[],"length":0,"stats":{"Line":4}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":1}},{"line":213,"address":[],"length":0,"stats":{"Line":1}},{"line":215,"address":[],"length":0,"stats":{"Line":2}},{"line":216,"address":[],"length":0,"stats":{"Line":2}},{"line":217,"address":[],"length":0,"stats":{"Line":2}},{"line":218,"address":[],"length":0,"stats":{"Line":2}},{"line":219,"address":[],"length":0,"stats":{"Line":1}},{"line":221,"address":[],"length":0,"stats":{"Line":2}},{"line":223,"address":[],"length":0,"stats":{"Line":1}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":235,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":240,"address":[],"length":0,"stats":{"Line":0}},{"line":241,"address":[],"length":0,"stats":{"Line":0}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":252,"address":[],"length":0,"stats":{"Line":0}},{"line":254,"address":[],"length":0,"stats":{"Line":0}},{"line":255,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":264,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":0}},{"line":270,"address":[],"length":0,"stats":{"Line":0}},{"line":272,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":274,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":276,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":298,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":0}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":0}},{"line":321,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":0}},{"line":323,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":335,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":337,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":342,"address":[],"length":0,"stats":{"Line":0}},{"line":344,"address":[],"length":0,"stats":{"Line":0}},{"line":345,"address":[],"length":0,"stats":{"Line":0}},{"line":346,"address":[],"length":0,"stats":{"Line":0}},{"line":347,"address":[],"length":0,"stats":{"Line":0}},{"line":350,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":354,"address":[],"length":0,"stats":{"Line":0}},{"line":355,"address":[],"length":0,"stats":{"Line":0}},{"line":358,"address":[],"length":0,"stats":{"Line":0}},{"line":360,"address":[],"length":0,"stats":{"Line":0}},{"line":361,"address":[],"length":0,"stats":{"Line":0}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":363,"address":[],"length":0,"stats":{"Line":0}},{"line":364,"address":[],"length":0,"stats":{"Line":0}},{"line":365,"address":[],"length":0,"stats":{"Line":0}},{"line":366,"address":[],"length":0,"stats":{"Line":0}},{"line":368,"address":[],"length":0,"stats":{"Line":0}},{"line":370,"address":[],"length":0,"stats":{"Line":0}},{"line":371,"address":[],"length":0,"stats":{"Line":0}},{"line":372,"address":[],"length":0,"stats":{"Line":0}},{"line":373,"address":[],"length":0,"stats":{"Line":0}},{"line":374,"address":[],"length":0,"stats":{"Line":0}},{"line":375,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":378,"address":[],"length":0,"stats":{"Line":0}},{"line":379,"address":[],"length":0,"stats":{"Line":0}},{"line":380,"address":[],"length":0,"stats":{"Line":0}},{"line":381,"address":[],"length":0,"stats":{"Line":0}},{"line":383,"address":[],"length":0,"stats":{"Line":0}},{"line":384,"address":[],"length":0,"stats":{"Line":0}},{"line":385,"address":[],"length":0,"stats":{"Line":0}},{"line":387,"address":[],"length":0,"stats":{"Line":0}},{"line":388,"address":[],"length":0,"stats":{"Line":0}},{"line":390,"address":[],"length":0,"stats":{"Line":0}},{"line":393,"address":[],"length":0,"stats":{"Line":0}},{"line":394,"address":[],"length":0,"stats":{"Line":0}},{"line":396,"address":[],"length":0,"stats":{"Line":0}},{"line":397,"address":[],"length":0,"stats":{"Line":0}},{"line":398,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":400,"address":[],"length":0,"stats":{"Line":0}},{"line":401,"address":[],"length":0,"stats":{"Line":0}},{"line":402,"address":[],"length":0,"stats":{"Line":0}},{"line":404,"address":[],"length":0,"stats":{"Line":0}},{"line":406,"address":[],"length":0,"stats":{"Line":0}},{"line":407,"address":[],"length":0,"stats":{"Line":0}},{"line":408,"address":[],"length":0,"stats":{"Line":0}},{"line":409,"address":[],"length":0,"stats":{"Line":0}},{"line":410,"address":[],"length":0,"stats":{"Line":0}},{"line":411,"address":[],"length":0,"stats":{"Line":0}},{"line":413,"address":[],"length":0,"stats":{"Line":0}},{"line":414,"address":[],"length":0,"stats":{"Line":0}},{"line":415,"address":[],"length":0,"stats":{"Line":0}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":417,"address":[],"length":0,"stats":{"Line":0}},{"line":419,"address":[],"length":0,"stats":{"Line":0}},{"line":420,"address":[],"length":0,"stats":{"Line":0}},{"line":421,"address":[],"length":0,"stats":{"Line":0}},{"line":423,"address":[],"length":0,"stats":{"Line":0}},{"line":424,"address":[],"length":0,"stats":{"Line":0}},{"line":426,"address":[],"length":0,"stats":{"Line":0}},{"line":429,"address":[],"length":0,"stats":{"Line":0}},{"line":430,"address":[],"length":0,"stats":{"Line":0}},{"line":431,"address":[],"length":0,"stats":{"Line":0}},{"line":432,"address":[],"length":0,"stats":{"Line":0}},{"line":433,"address":[],"length":0,"stats":{"Line":0}},{"line":434,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":441,"address":[],"length":0,"stats":{"Line":0}},{"line":443,"address":[],"length":0,"stats":{"Line":0}},{"line":444,"address":[],"length":0,"stats":{"Line":0}},{"line":445,"address":[],"length":0,"stats":{"Line":0}},{"line":446,"address":[],"length":0,"stats":{"Line":0}},{"line":447,"address":[],"length":0,"stats":{"Line":0}},{"line":448,"address":[],"length":0,"stats":{"Line":0}},{"line":450,"address":[],"length":0,"stats":{"Line":0}},{"line":451,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":453,"address":[],"length":0,"stats":{"Line":0}},{"line":454,"address":[],"length":0,"stats":{"Line":0}},{"line":455,"address":[],"length":0,"stats":{"Line":0}},{"line":457,"address":[],"length":0,"stats":{"Line":0}},{"line":458,"address":[],"length":0,"stats":{"Line":0}},{"line":459,"address":[],"length":0,"stats":{"Line":0}},{"line":460,"address":[],"length":0,"stats":{"Line":0}},{"line":462,"address":[],"length":0,"stats":{"Line":0}},{"line":463,"address":[],"length":0,"stats":{"Line":0}},{"line":464,"address":[],"length":0,"stats":{"Line":0}},{"line":466,"address":[],"length":0,"stats":{"Line":0}},{"line":468,"address":[],"length":0,"stats":{"Line":0}},{"line":469,"address":[],"length":0,"stats":{"Line":0}},{"line":472,"address":[],"length":0,"stats":{"Line":0}},{"line":475,"address":[],"length":0,"stats":{"Line":6}},{"line":476,"address":[],"length":0,"stats":{"Line":6}},{"line":477,"address":[],"length":0,"stats":{"Line":9}},{"line":479,"address":[],"length":0,"stats":{"Line":3}},{"line":480,"address":[],"length":0,"stats":{"Line":4}},{"line":481,"address":[],"length":0,"stats":{"Line":2}},{"line":482,"address":[],"length":0,"stats":{"Line":2}},{"line":483,"address":[],"length":0,"stats":{"Line":2}},{"line":484,"address":[],"length":0,"stats":{"Line":2}},{"line":485,"address":[],"length":0,"stats":{"Line":8}},{"line":486,"address":[],"length":0,"stats":{"Line":8}},{"line":487,"address":[],"length":0,"stats":{"Line":8}},{"line":489,"address":[],"length":0,"stats":{"Line":2}},{"line":490,"address":[],"length":0,"stats":{"Line":6}},{"line":491,"address":[],"length":0,"stats":{"Line":6}},{"line":494,"address":[],"length":0,"stats":{"Line":8}},{"line":496,"address":[],"length":0,"stats":{"Line":2}},{"line":497,"address":[],"length":0,"stats":{"Line":1}},{"line":498,"address":[],"length":0,"stats":{"Line":1}},{"line":499,"address":[],"length":0,"stats":{"Line":1}},{"line":502,"address":[],"length":0,"stats":{"Line":1}},{"line":503,"address":[],"length":0,"stats":{"Line":1}},{"line":507,"address":[],"length":0,"stats":{"Line":1}},{"line":508,"address":[],"length":0,"stats":{"Line":0}},{"line":510,"address":[],"length":0,"stats":{"Line":1}},{"line":511,"address":[],"length":0,"stats":{"Line":0}},{"line":513,"address":[],"length":0,"stats":{"Line":3}},{"line":514,"address":[],"length":0,"stats":{"Line":1}},{"line":516,"address":[],"length":0,"stats":{"Line":1}},{"line":518,"address":[],"length":0,"stats":{"Line":2}},{"line":519,"address":[],"length":0,"stats":{"Line":2}},{"line":520,"address":[],"length":0,"stats":{"Line":2}},{"line":521,"address":[],"length":0,"stats":{"Line":2}},{"line":522,"address":[],"length":0,"stats":{"Line":2}},{"line":523,"address":[],"length":0,"stats":{"Line":1}},{"line":525,"address":[],"length":0,"stats":{"Line":2}},{"line":528,"address":[],"length":0,"stats":{"Line":3}},{"line":531,"address":[],"length":0,"stats":{"Line":4}},{"line":532,"address":[],"length":0,"stats":{"Line":4}},{"line":533,"address":[],"length":0,"stats":{"Line":6}},{"line":535,"address":[],"length":0,"stats":{"Line":3}},{"line":536,"address":[],"length":0,"stats":{"Line":4}},{"line":540,"address":[],"length":0,"stats":{"Line":2}},{"line":541,"address":[],"length":0,"stats":{"Line":1}},{"line":544,"address":[],"length":0,"stats":{"Line":3}},{"line":545,"address":[],"length":0,"stats":{"Line":2}},{"line":546,"address":[],"length":0,"stats":{"Line":3}},{"line":547,"address":[],"length":0,"stats":{"Line":4}},{"line":550,"address":[],"length":0,"stats":{"Line":2}},{"line":551,"address":[],"length":0,"stats":{"Line":1}},{"line":552,"address":[],"length":0,"stats":{"Line":1}},{"line":554,"address":[],"length":0,"stats":{"Line":2}},{"line":555,"address":[],"length":0,"stats":{"Line":1}},{"line":558,"address":[],"length":0,"stats":{"Line":0}},{"line":559,"address":[],"length":0,"stats":{"Line":0}},{"line":561,"address":[],"length":0,"stats":{"Line":0}},{"line":562,"address":[],"length":0,"stats":{"Line":0}},{"line":563,"address":[],"length":0,"stats":{"Line":0}},{"line":565,"address":[],"length":0,"stats":{"Line":0}},{"line":567,"address":[],"length":0,"stats":{"Line":0}},{"line":568,"address":[],"length":0,"stats":{"Line":0}},{"line":572,"address":[],"length":0,"stats":{"Line":0}},{"line":573,"address":[],"length":0,"stats":{"Line":0}},{"line":576,"address":[],"length":0,"stats":{"Line":0}},{"line":578,"address":[],"length":0,"stats":{"Line":0}},{"line":579,"address":[],"length":0,"stats":{"Line":0}},{"line":580,"address":[],"length":0,"stats":{"Line":0}},{"line":581,"address":[],"length":0,"stats":{"Line":0}},{"line":582,"address":[],"length":0,"stats":{"Line":0}},{"line":583,"address":[],"length":0,"stats":{"Line":0}},{"line":584,"address":[],"length":0,"stats":{"Line":0}},{"line":585,"address":[],"length":0,"stats":{"Line":0}},{"line":586,"address":[],"length":0,"stats":{"Line":0}},{"line":587,"address":[],"length":0,"stats":{"Line":0}},{"line":588,"address":[],"length":0,"stats":{"Line":0}},{"line":590,"address":[],"length":0,"stats":{"Line":0}},{"line":591,"address":[],"length":0,"stats":{"Line":0}},{"line":592,"address":[],"length":0,"stats":{"Line":0}},{"line":594,"address":[],"length":0,"stats":{"Line":0}},{"line":600,"address":[],"length":0,"stats":{"Line":0}},{"line":602,"address":[],"length":0,"stats":{"Line":0}},{"line":603,"address":[],"length":0,"stats":{"Line":0}},{"line":604,"address":[],"length":0,"stats":{"Line":0}},{"line":605,"address":[],"length":0,"stats":{"Line":0}},{"line":606,"address":[],"length":0,"stats":{"Line":0}},{"line":607,"address":[],"length":0,"stats":{"Line":0}},{"line":609,"address":[],"length":0,"stats":{"Line":0}},{"line":610,"address":[],"length":0,"stats":{"Line":0}},{"line":611,"address":[],"length":0,"stats":{"Line":0}},{"line":613,"address":[],"length":0,"stats":{"Line":0}},{"line":615,"address":[],"length":0,"stats":{"Line":0}},{"line":616,"address":[],"length":0,"stats":{"Line":0}},{"line":617,"address":[],"length":0,"stats":{"Line":0}},{"line":618,"address":[],"length":0,"stats":{"Line":0}},{"line":619,"address":[],"length":0,"stats":{"Line":0}},{"line":620,"address":[],"length":0,"stats":{"Line":0}},{"line":622,"address":[],"length":0,"stats":{"Line":0}},{"line":623,"address":[],"length":0,"stats":{"Line":0}},{"line":624,"address":[],"length":0,"stats":{"Line":0}},{"line":627,"address":[],"length":0,"stats":{"Line":0}},{"line":628,"address":[],"length":0,"stats":{"Line":0}},{"line":629,"address":[],"length":0,"stats":{"Line":0}},{"line":630,"address":[],"length":0,"stats":{"Line":0}},{"line":631,"address":[],"length":0,"stats":{"Line":0}},{"line":634,"address":[],"length":0,"stats":{"Line":0}},{"line":635,"address":[],"length":0,"stats":{"Line":0}},{"line":637,"address":[],"length":0,"stats":{"Line":0}},{"line":638,"address":[],"length":0,"stats":{"Line":0}},{"line":639,"address":[],"length":0,"stats":{"Line":0}},{"line":640,"address":[],"length":0,"stats":{"Line":0}},{"line":641,"address":[],"length":0,"stats":{"Line":0}},{"line":643,"address":[],"length":0,"stats":{"Line":0}},{"line":644,"address":[],"length":0,"stats":{"Line":0}},{"line":645,"address":[],"length":0,"stats":{"Line":0}},{"line":646,"address":[],"length":0,"stats":{"Line":0}},{"line":648,"address":[],"length":0,"stats":{"Line":0}},{"line":649,"address":[],"length":0,"stats":{"Line":0}},{"line":650,"address":[],"length":0,"stats":{"Line":0}},{"line":651,"address":[],"length":0,"stats":{"Line":0}},{"line":652,"address":[],"length":0,"stats":{"Line":0}},{"line":654,"address":[],"length":0,"stats":{"Line":0}},{"line":655,"address":[],"length":0,"stats":{"Line":0}},{"line":657,"address":[],"length":0,"stats":{"Line":0}},{"line":659,"address":[],"length":0,"stats":{"Line":0}},{"line":662,"address":[],"length":0,"stats":{"Line":0}},{"line":663,"address":[],"length":0,"stats":{"Line":0}},{"line":664,"address":[],"length":0,"stats":{"Line":0}},{"line":665,"address":[],"length":0,"stats":{"Line":0}},{"line":666,"address":[],"length":0,"stats":{"Line":0}},{"line":667,"address":[],"length":0,"stats":{"Line":0}},{"line":668,"address":[],"length":0,"stats":{"Line":0}},{"line":669,"address":[],"length":0,"stats":{"Line":0}},{"line":671,"address":[],"length":0,"stats":{"Line":0}},{"line":672,"address":[],"length":0,"stats":{"Line":0}},{"line":674,"address":[],"length":0,"stats":{"Line":0}},{"line":675,"address":[],"length":0,"stats":{"Line":0}},{"line":676,"address":[],"length":0,"stats":{"Line":0}},{"line":677,"address":[],"length":0,"stats":{"Line":0}},{"line":678,"address":[],"length":0,"stats":{"Line":0}},{"line":680,"address":[],"length":0,"stats":{"Line":0}},{"line":681,"address":[],"length":0,"stats":{"Line":0}},{"line":684,"address":[],"length":0,"stats":{"Line":0}},{"line":685,"address":[],"length":0,"stats":{"Line":0}},{"line":686,"address":[],"length":0,"stats":{"Line":0}},{"line":687,"address":[],"length":0,"stats":{"Line":0}},{"line":688,"address":[],"length":0,"stats":{"Line":0}},{"line":689,"address":[],"length":0,"stats":{"Line":0}},{"line":690,"address":[],"length":0,"stats":{"Line":0}},{"line":691,"address":[],"length":0,"stats":{"Line":0}},{"line":692,"address":[],"length":0,"stats":{"Line":0}},{"line":693,"address":[],"length":0,"stats":{"Line":0}},{"line":694,"address":[],"length":0,"stats":{"Line":0}},{"line":696,"address":[],"length":0,"stats":{"Line":0}},{"line":697,"address":[],"length":0,"stats":{"Line":0}},{"line":699,"address":[],"length":0,"stats":{"Line":0}},{"line":701,"address":[],"length":0,"stats":{"Line":0}},{"line":702,"address":[],"length":0,"stats":{"Line":0}},{"line":703,"address":[],"length":0,"stats":{"Line":0}},{"line":704,"address":[],"length":0,"stats":{"Line":0}},{"line":705,"address":[],"length":0,"stats":{"Line":0}},{"line":706,"address":[],"length":0,"stats":{"Line":0}},{"line":708,"address":[],"length":0,"stats":{"Line":0}},{"line":709,"address":[],"length":0,"stats":{"Line":0}},{"line":711,"address":[],"length":0,"stats":{"Line":0}},{"line":712,"address":[],"length":0,"stats":{"Line":0}},{"line":713,"address":[],"length":0,"stats":{"Line":0}},{"line":714,"address":[],"length":0,"stats":{"Line":0}},{"line":715,"address":[],"length":0,"stats":{"Line":0}},{"line":716,"address":[],"length":0,"stats":{"Line":0}},{"line":718,"address":[],"length":0,"stats":{"Line":0}},{"line":719,"address":[],"length":0,"stats":{"Line":0}},{"line":720,"address":[],"length":0,"stats":{"Line":0}},{"line":721,"address":[],"length":0,"stats":{"Line":0}},{"line":724,"address":[],"length":0,"stats":{"Line":0}},{"line":725,"address":[],"length":0,"stats":{"Line":0}},{"line":728,"address":[],"length":0,"stats":{"Line":0}},{"line":730,"address":[],"length":0,"stats":{"Line":0}},{"line":731,"address":[],"length":0,"stats":{"Line":0}},{"line":734,"address":[],"length":0,"stats":{"Line":0}},{"line":737,"address":[],"length":0,"stats":{"Line":3}},{"line":739,"address":[],"length":0,"stats":{"Line":9}},{"line":740,"address":[],"length":0,"stats":{"Line":3}},{"line":743,"address":[],"length":0,"stats":{"Line":6}}],"covered":101,"coverable":425},{"path":["/","Users","christian.klat","dev","git","aeterna","cli","src","main.rs"],"content":"use anyhow::Result;\nuse clap::Parser;\nuse tracing_subscriber::{EnvFilter, fmt, prelude::*};\n\nmod commands;\nmod output;\npub mod ux_error;\n\nuse commands::{Cli, Commands};\n\n#[tokio::main]\nasync fn main() -> Result<()> {\n    tracing_subscriber::registry()\n        .with(fmt::layer())\n        .with(EnvFilter::from_default_env())\n        .init();\n\n    let cli = Cli::parse();\n\n    match cli.command {\n        Commands::Init(args) => commands::init::run(args),\n        Commands::Status(args) => commands::status::run(args),\n        Commands::Sync(args) => commands::sync::run(args).await,\n        Commands::Check(args) => commands::check::run(args).await,\n        Commands::Context(args) => commands::context::run(args),\n        Commands::Hints(args) => commands::hints::run(args),\n        Commands::Memory(cmd) => commands::memory::run(cmd).await,\n        Commands::Knowledge(cmd) => commands::knowledge::run(cmd).await,\n        Commands::Policy(cmd) => commands::policy::run(cmd).await,\n        Commands::Org(cmd) => commands::org::run(cmd).await,\n        Commands::Team(cmd) => commands::team::run(cmd).await,\n        Commands::User(cmd) => commands::user::run(cmd).await,\n        Commands::Agent(cmd) => commands::agent::run(cmd).await,\n        Commands::Govern(cmd) => commands::govern::run(cmd).await,\n        Commands::Admin(cmd) => commands::admin::run(cmd).await,\n        Commands::Completion(args) => commands::completion::run(args),\n    }\n}\n","traces":[{"line":12,"address":[],"length":0,"stats":{"Line":170}},{"line":13,"address":[],"length":0,"stats":{"Line":85}},{"line":14,"address":[],"length":0,"stats":{"Line":170}},{"line":15,"address":[],"length":0,"stats":{"Line":170}},{"line":18,"address":[],"length":0,"stats":{"Line":170}},{"line":20,"address":[],"length":0,"stats":{"Line":170}},{"line":21,"address":[],"length":0,"stats":{"Line":238}},{"line":22,"address":[],"length":0,"stats":{"Line":85}},{"line":23,"address":[],"length":0,"stats":{"Line":85}},{"line":24,"address":[],"length":0,"stats":{"Line":85}},{"line":25,"address":[],"length":0,"stats":{"Line":94}},{"line":26,"address":[],"length":0,"stats":{"Line":85}},{"line":27,"address":[],"length":0,"stats":{"Line":124}},{"line":28,"address":[],"length":0,"stats":{"Line":88}},{"line":29,"address":[],"length":0,"stats":{"Line":115}},{"line":30,"address":[],"length":0,"stats":{"Line":85}},{"line":31,"address":[],"length":0,"stats":{"Line":85}},{"line":32,"address":[],"length":0,"stats":{"Line":103}},{"line":33,"address":[],"length":0,"stats":{"Line":85}},{"line":34,"address":[],"length":0,"stats":{"Line":85}},{"line":35,"address":[],"length":0,"stats":{"Line":88}},{"line":36,"address":[],"length":0,"stats":{"Line":85}}],"covered":22,"coverable":22},{"path":["/","Users","christian.klat","dev","git","aeterna","cli","src","output.rs"],"content":"use colored::Colorize;\n\npub fn header(title: &str) {\n    println!(\"{}\", title.bold().underline());\n}\n\npub fn subheader(title: &str) {\n    println!(\"{}\", title.bold());\n}\n\npub fn hint(msg: &str) {\n    println!(\"{} {}\", \"hint:\".cyan().bold(), msg.dimmed());\n}\n\npub fn info(msg: &str) {\n    eprintln!(\"{} {}\", \"info:\".blue().bold(), msg);\n}\n\npub fn warn(msg: &str) {\n    eprintln!(\"{} {}\", \"warning:\".yellow().bold(), msg);\n}\n\n#[allow(dead_code)]\npub fn error(msg: &str) {\n    eprintln!(\"{} {}\", \"error:\".red().bold(), msg);\n}\n\n#[allow(dead_code)]\npub fn success(msg: &str) {\n    println!(\"{} {}\", \"\".green().bold(), msg);\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_header_does_not_panic() {\n        header(\"Test Header\");\n    }\n\n    #[test]\n    fn test_subheader_does_not_panic() {\n        subheader(\"Test Subheader\");\n    }\n\n    #[test]\n    fn test_hint_does_not_panic() {\n        hint(\"This is a hint\");\n    }\n\n    #[test]\n    fn test_info_does_not_panic() {\n        info(\"This is info\");\n    }\n\n    #[test]\n    fn test_warn_does_not_panic() {\n        warn(\"This is a warning\");\n    }\n\n    #[test]\n    fn test_error_does_not_panic() {\n        error(\"This is an error\");\n    }\n\n    #[test]\n    fn test_success_does_not_panic() {\n        success(\"This is success\");\n    }\n}\n","traces":[{"line":3,"address":[],"length":0,"stats":{"Line":70}},{"line":4,"address":[],"length":0,"stats":{"Line":350}},{"line":7,"address":[],"length":0,"stats":{"Line":2}},{"line":8,"address":[],"length":0,"stats":{"Line":8}},{"line":11,"address":[],"length":0,"stats":{"Line":1}},{"line":12,"address":[],"length":0,"stats":{"Line":7}},{"line":15,"address":[],"length":0,"stats":{"Line":37}},{"line":16,"address":[],"length":0,"stats":{"Line":185}},{"line":19,"address":[],"length":0,"stats":{"Line":1}},{"line":20,"address":[],"length":0,"stats":{"Line":5}},{"line":24,"address":[],"length":0,"stats":{"Line":1}},{"line":25,"address":[],"length":0,"stats":{"Line":5}},{"line":29,"address":[],"length":0,"stats":{"Line":1}},{"line":30,"address":[],"length":0,"stats":{"Line":5}}],"covered":14,"coverable":14},{"path":["/","Users","christian.klat","dev","git","aeterna","cli","src","ux_error.rs"],"content":"use colored::Colorize;\n\n#[derive(Debug)]\npub struct UxError {\n    pub what: String,\n    pub why: Option<String>,\n    pub how_to_fix: Vec<String>,\n    pub suggested_command: Option<String>,\n}\n\nimpl UxError {\n    pub fn new(what: impl Into<String>) -> Self {\n        Self {\n            what: what.into(),\n            why: None,\n            how_to_fix: Vec::new(),\n            suggested_command: None,\n        }\n    }\n\n    pub fn why(mut self, reason: impl Into<String>) -> Self {\n        self.why = Some(reason.into());\n        self\n    }\n\n    pub fn fix(mut self, suggestion: impl Into<String>) -> Self {\n        self.how_to_fix.push(suggestion.into());\n        self\n    }\n\n    pub fn suggest(mut self, cmd: impl Into<String>) -> Self {\n        self.suggested_command = Some(cmd.into());\n        self\n    }\n\n    pub fn display(&self) {\n        eprintln!();\n        eprintln!(\"{} {}\", \"error:\".red().bold(), self.what.white().bold());\n\n        if let Some(why) = &self.why {\n            eprintln!(\"       {}\", why.dimmed());\n        }\n\n        if !self.how_to_fix.is_empty() {\n            eprintln!();\n            eprintln!(\"{}\", \"How to fix:\".yellow().bold());\n            for (i, fix) in self.how_to_fix.iter().enumerate() {\n                eprintln!(\"  {}. {}\", i + 1, fix);\n            }\n        }\n\n        if let Some(cmd) = &self.suggested_command {\n            eprintln!();\n            eprintln!(\"{}\", \"Try this:\".green().bold());\n            eprintln!(\"  $ {}\", cmd.cyan());\n        }\n        eprintln!();\n    }\n}\n\nimpl std::fmt::Display for UxError {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"{}\", self.what)\n    }\n}\n\nimpl std::error::Error for UxError {}\n\npub fn context_not_found(path: &str) -> UxError {\n    UxError::new(format!(\"No Aeterna context found at '{}'\", path))\n        .why(\"Expected .aeterna/context.toml in this or parent directories\")\n        .fix(\"Initialize Aeterna in this directory\")\n        .fix(\"Or navigate to a directory with an existing Aeterna project\")\n        .suggest(\"aeterna init\")\n}\n\npub fn server_not_connected() -> UxError {\n    UxError::new(\"Cannot connect to Aeterna server\")\n        .why(\"The memory/knowledge backend is not running or unreachable\")\n        .fix(\"Start the Aeterna server\")\n        .fix(\"Check your network connection\")\n        .fix(\"Verify server URL in .aeterna/context.toml\")\n        .suggest(\"aeterna status\")\n}\n\npub fn invalid_layer(layer: &str, valid: &[&str]) -> UxError {\n    UxError::new(format!(\"Invalid layer: '{}'\", layer))\n        .why(format!(\"Valid layers are: {}\", valid.join(\", \")))\n        .fix(\"Use one of the valid layer names\")\n        .suggest(format!(\"aeterna memory list --layer {}\", valid[0]))\n}\n\npub fn invalid_preset(preset: &str) -> UxError {\n    UxError::new(format!(\"Unknown hints preset: '{}'\", preset))\n        .why(\"Presets control which features are enabled for an operation\")\n        .fix(\"Use one of: minimal, fast, standard, full, offline, agent\")\n        .suggest(\"aeterna hints list\")\n}\n\npub fn missing_required_field(field: &str, context: &str) -> UxError {\n    UxError::new(format!(\"Missing required field: '{}'\", field))\n        .why(format!(\"This field is required for {}\", context))\n        .fix(format!(\"Provide the {} value\", field))\n}\n\npub fn permission_denied(resource: &str) -> UxError {\n    UxError::new(format!(\"Permission denied: {}\", resource))\n        .why(\"Your user or agent doesn't have access to this resource\")\n        .fix(\"Check your role and permissions\")\n        .fix(\"Contact your administrator for access\")\n        .suggest(\"aeterna status\")\n}\n\npub fn rate_limited(retry_after: u64) -> UxError {\n    UxError::new(\"Rate limit exceeded\")\n        .why(format!(\n            \"Too many requests. Retry after {} seconds\",\n            retry_after\n        ))\n        .fix(\"Wait before retrying\")\n        .fix(\"Consider using the 'minimal' or 'offline' preset to reduce API calls\")\n        .suggest(\"aeterna hints explain minimal\")\n}\n\npub fn memory_not_found(id: &str) -> UxError {\n    UxError::new(format!(\"Memory not found: {}\", id))\n        .why(\"The specified memory ID doesn't exist or has been deleted\")\n        .fix(\"Verify the memory ID is correct\")\n        .fix(\"Search for memories to find the right ID\")\n        .suggest(\"aeterna memory search <query>\")\n}\n\npub fn knowledge_not_found(path: &str, layer: &str) -> UxError {\n    UxError::new(format!(\"Knowledge not found: {} in {} layer\", path, layer))\n        .why(\"The specified knowledge entry doesn't exist in this layer\")\n        .fix(\"Check the path is correct\")\n        .fix(\"Try searching across all layers\")\n        .suggest(format!(\"aeterna knowledge search \\\"{}\\\"\", path))\n}\n\npub fn policy_violation(policy_id: &str, details: &str) -> UxError {\n    UxError::new(format!(\"Policy violation: {}\", policy_id))\n        .why(details.to_string())\n        .fix(\"Review the policy requirements\")\n        .fix(\"Request an exception if needed\")\n        .suggest(format!(\n            \"aeterna knowledge get policies/{}.md --layer company\",\n            policy_id\n        ))\n}\n\npub fn config_error(message: &str) -> UxError {\n    UxError::new(format!(\"Configuration error: {}\", message))\n        .why(\"The configuration file may be invalid or missing required fields\")\n        .fix(\"Check your .aeterna/context.toml file\")\n        .fix(\"Re-initialize with defaults\")\n        .suggest(\"aeterna init --force\")\n}\n\npub fn git_error(operation: &str, reason: &str) -> UxError {\n    UxError::new(format!(\"Git error during {}: {}\", operation, reason))\n        .why(\"The knowledge repository uses Git for version control\")\n        .fix(\"Ensure you're in a Git repository\")\n        .fix(\"Check your Git configuration\")\n        .suggest(\"git status\")\n}\n\npub fn timeout_error(operation: &str, timeout_ms: u64) -> UxError {\n    UxError::new(format!(\"Operation timed out: {}\", operation))\n        .why(format!(\"Operation took longer than {}ms\", timeout_ms))\n        .fix(\"Check server/network connectivity\")\n        .fix(\"Try with fewer results or simpler query\")\n        .fix(\"Use 'offline' preset to skip network calls\")\n        .suggest(\"aeterna hints explain offline\")\n}\n\npub fn invalid_feedback_type(feedback_type: &str) -> UxError {\n    UxError::new(format!(\"Invalid feedback type: '{}'\", feedback_type))\n        .why(\"Feedback type must describe how the memory was useful or not\")\n        .fix(\"Use one of: helpful, irrelevant, outdated, inaccurate, duplicate\")\n        .suggest(\"aeterna memory feedback <id> --layer project --feedback-type helpful --score 0.8\")\n}\n\npub fn invalid_score(score: f32) -> UxError {\n    UxError::new(format!(\"Invalid score: {}\", score))\n        .why(\"Score must be between -1.0 (completely wrong) and 1.0 (very helpful)\")\n        .fix(\"Use a value in the range -1.0 to 1.0\")\n        .suggest(\"aeterna memory feedback <id> --layer project --feedback-type helpful --score 0.8\")\n}\n\npub fn invalid_metadata_json(error: &str) -> UxError {\n    UxError::new(\"Invalid metadata JSON\")\n        .why(format!(\"Parse error: {}\", error))\n        .fix(\"Provide valid JSON for the --metadata flag\")\n        .fix(\"Example: --metadata '{\\\"key\\\": \\\"value\\\"}'\")\n}\n\npub fn invalid_knowledge_layer(layer: &str) -> UxError {\n    UxError::new(format!(\"Invalid knowledge layer: '{}'\", layer))\n        .why(\"Knowledge layers represent organizational hierarchy\")\n        .fix(\"Use one of: company, org, team, project\")\n        .suggest(\"aeterna knowledge list --layer project\")\n}\n\npub fn promotion_direction_invalid(from_layer: &str, to_layer: &str) -> UxError {\n    UxError::new(format!(\n        \"Cannot promote from '{}' to '{}'\",\n        from_layer, to_layer\n    ))\n    .why(\"Promotion must be to a broader (higher) layer in the hierarchy\")\n    .fix(\"Layer hierarchy: agent < user < session < project < team < org < company\")\n    .fix(\"Choose a target layer that is broader than the source\")\n    .suggest(format!(\n        \"aeterna memory promote <id> --from-layer {} --to-layer team\",\n        from_layer\n    ))\n}\n\npub fn invalid_knowledge_type(knowledge_type: &str, valid: &[&str]) -> UxError {\n    UxError::new(format!(\"Invalid knowledge type: '{}'\", knowledge_type))\n        .why(format!(\"Valid types are: {}\", valid.join(\", \")))\n        .fix(\"Use one of the valid knowledge type names\")\n        .fix(\"Or omit --type to let the system auto-detect from your description\")\n        .suggest(\"aeterna knowledge propose \\\"We decided to use PostgreSQL\\\" --type adr\")\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_ux_error_new() {\n        let err = UxError::new(\"test error\");\n        assert_eq!(err.what, \"test error\");\n        assert!(err.why.is_none());\n        assert!(err.how_to_fix.is_empty());\n        assert!(err.suggested_command.is_none());\n    }\n\n    #[test]\n    fn test_ux_error_builder_chain() {\n        let err = UxError::new(\"test error\")\n            .why(\"because reasons\")\n            .fix(\"try this\")\n            .fix(\"or this\")\n            .suggest(\"run command\");\n\n        assert_eq!(err.what, \"test error\");\n        assert_eq!(err.why, Some(\"because reasons\".to_string()));\n        assert_eq!(err.how_to_fix.len(), 2);\n        assert_eq!(err.how_to_fix[0], \"try this\");\n        assert_eq!(err.how_to_fix[1], \"or this\");\n        assert_eq!(err.suggested_command, Some(\"run command\".to_string()));\n    }\n\n    #[test]\n    fn test_ux_error_display() {\n        let err = UxError::new(\"test error\");\n        assert_eq!(format!(\"{}\", err), \"test error\");\n    }\n\n    #[test]\n    fn test_context_not_found() {\n        let err = context_not_found(\"/some/path\");\n        assert!(err.what.contains(\"/some/path\"));\n        assert!(err.why.is_some());\n        assert!(!err.how_to_fix.is_empty());\n        assert_eq!(err.suggested_command, Some(\"aeterna init\".to_string()));\n    }\n\n    #[test]\n    fn test_server_not_connected() {\n        let err = server_not_connected();\n        assert!(err.what.contains(\"Cannot connect\"));\n        assert!(err.why.is_some());\n        assert_eq!(err.how_to_fix.len(), 3);\n        assert_eq!(err.suggested_command, Some(\"aeterna status\".to_string()));\n    }\n\n    #[test]\n    fn test_invalid_layer() {\n        let valid = [\"agent\", \"user\", \"project\"];\n        let err = invalid_layer(\"invalid\", &valid);\n        assert!(err.what.contains(\"invalid\"));\n        assert!(err.why.as_ref().unwrap().contains(\"agent\"));\n        assert!(!err.how_to_fix.is_empty());\n        assert!(err.suggested_command.is_some());\n    }\n\n    #[test]\n    fn test_invalid_preset() {\n        let err = invalid_preset(\"badpreset\");\n        assert!(err.what.contains(\"badpreset\"));\n        assert!(err.why.is_some());\n        assert!(!err.how_to_fix.is_empty());\n    }\n\n    #[test]\n    fn test_missing_required_field() {\n        let err = missing_required_field(\"user_id\", \"authentication\");\n        assert!(err.what.contains(\"user_id\"));\n        assert!(err.why.as_ref().unwrap().contains(\"authentication\"));\n    }\n\n    #[test]\n    fn test_permission_denied() {\n        let err = permission_denied(\"knowledge/secrets\");\n        assert!(err.what.contains(\"knowledge/secrets\"));\n        assert!(err.why.is_some());\n        assert_eq!(err.how_to_fix.len(), 2);\n    }\n\n    #[test]\n    fn test_rate_limited() {\n        let err = rate_limited(60);\n        assert!(err.what.contains(\"Rate limit\"));\n        assert!(err.why.as_ref().unwrap().contains(\"60\"));\n    }\n\n    #[test]\n    fn test_memory_not_found() {\n        let err = memory_not_found(\"mem-123\");\n        assert!(err.what.contains(\"mem-123\"));\n        assert!(err.why.is_some());\n        assert_eq!(err.how_to_fix.len(), 2);\n    }\n\n    #[test]\n    fn test_knowledge_not_found() {\n        let err = knowledge_not_found(\"adrs/001.md\", \"project\");\n        assert!(err.what.contains(\"adrs/001.md\"));\n        assert!(err.what.contains(\"project\"));\n    }\n\n    #[test]\n    fn test_policy_violation() {\n        let err = policy_violation(\"sec-001\", \"Dependency blocked\");\n        assert!(err.what.contains(\"sec-001\"));\n        assert_eq!(err.why, Some(\"Dependency blocked\".to_string()));\n    }\n\n    #[test]\n    fn test_config_error() {\n        let err = config_error(\"invalid toml syntax\");\n        assert!(err.what.contains(\"invalid toml syntax\"));\n        assert_eq!(\n            err.suggested_command,\n            Some(\"aeterna init --force\".to_string())\n        );\n    }\n\n    #[test]\n    fn test_git_error() {\n        let err = git_error(\"commit\", \"not a git repository\");\n        assert!(err.what.contains(\"commit\"));\n        assert!(err.what.contains(\"not a git repository\"));\n    }\n\n    #[test]\n    fn test_timeout_error() {\n        let err = timeout_error(\"search\", 5000);\n        assert!(err.what.contains(\"search\"));\n        assert!(err.why.as_ref().unwrap().contains(\"5000\"));\n    }\n\n    #[test]\n    fn test_invalid_feedback_type() {\n        let err = invalid_feedback_type(\"unknown\");\n        assert!(err.what.contains(\"unknown\"));\n        assert!(err.why.as_ref().unwrap().contains(\"useful\"));\n    }\n\n    #[test]\n    fn test_invalid_score_below_range() {\n        let err = invalid_score(-1.5);\n        assert!(err.what.contains(\"-1.5\"));\n        assert!(err.why.as_ref().unwrap().contains(\"-1.0\"));\n    }\n\n    #[test]\n    fn test_invalid_score_above_range() {\n        let err = invalid_score(1.5);\n        assert!(err.what.contains(\"1.5\"));\n    }\n\n    #[test]\n    fn test_invalid_metadata_json() {\n        let err = invalid_metadata_json(\"unexpected token\");\n        assert!(err.what.contains(\"Invalid metadata JSON\"));\n        assert!(err.why.as_ref().unwrap().contains(\"unexpected token\"));\n    }\n\n    #[test]\n    fn test_invalid_knowledge_layer() {\n        let err = invalid_knowledge_layer(\"invalid\");\n        assert!(err.what.contains(\"invalid\"));\n        assert!(err.why.as_ref().unwrap().contains(\"organizational\"));\n    }\n\n    #[test]\n    fn test_promotion_direction_invalid() {\n        let err = promotion_direction_invalid(\"team\", \"user\");\n        assert!(err.what.contains(\"team\"));\n        assert!(err.what.contains(\"user\"));\n        assert!(err.why.as_ref().unwrap().contains(\"broader\"));\n    }\n\n    #[test]\n    fn test_invalid_knowledge_type() {\n        let valid = [\"adr\", \"pattern\", \"policy\"];\n        let err = invalid_knowledge_type(\"unknown\", &valid);\n        assert!(err.what.contains(\"unknown\"));\n        assert!(err.why.as_ref().unwrap().contains(\"adr\"));\n    }\n}\n","traces":[{"line":12,"address":[],"length":0,"stats":{"Line":30}},{"line":14,"address":[],"length":0,"stats":{"Line":90}},{"line":16,"address":[],"length":0,"stats":{"Line":30}},{"line":21,"address":[],"length":0,"stats":{"Line":28}},{"line":22,"address":[],"length":0,"stats":{"Line":56}},{"line":23,"address":[],"length":0,"stats":{"Line":28}},{"line":26,"address":[],"length":0,"stats":{"Line":45}},{"line":27,"address":[],"length":0,"stats":{"Line":180}},{"line":28,"address":[],"length":0,"stats":{"Line":45}},{"line":31,"address":[],"length":0,"stats":{"Line":26}},{"line":32,"address":[],"length":0,"stats":{"Line":52}},{"line":33,"address":[],"length":0,"stats":{"Line":26}},{"line":36,"address":[],"length":0,"stats":{"Line":7}},{"line":37,"address":[],"length":0,"stats":{"Line":7}},{"line":38,"address":[],"length":0,"stats":{"Line":49}},{"line":40,"address":[],"length":0,"stats":{"Line":21}},{"line":41,"address":[],"length":0,"stats":{"Line":21}},{"line":44,"address":[],"length":0,"stats":{"Line":7}},{"line":45,"address":[],"length":0,"stats":{"Line":7}},{"line":46,"address":[],"length":0,"stats":{"Line":35}},{"line":47,"address":[],"length":0,"stats":{"Line":38}},{"line":48,"address":[],"length":0,"stats":{"Line":16}},{"line":52,"address":[],"length":0,"stats":{"Line":21}},{"line":53,"address":[],"length":0,"stats":{"Line":14}},{"line":54,"address":[],"length":0,"stats":{"Line":42}},{"line":55,"address":[],"length":0,"stats":{"Line":21}},{"line":57,"address":[],"length":0,"stats":{"Line":7}},{"line":62,"address":[],"length":0,"stats":{"Line":1}},{"line":63,"address":[],"length":0,"stats":{"Line":3}},{"line":69,"address":[],"length":0,"stats":{"Line":1}},{"line":70,"address":[],"length":0,"stats":{"Line":3}},{"line":77,"address":[],"length":0,"stats":{"Line":1}},{"line":78,"address":[],"length":0,"stats":{"Line":1}},{"line":86,"address":[],"length":0,"stats":{"Line":2}},{"line":87,"address":[],"length":0,"stats":{"Line":6}},{"line":88,"address":[],"length":0,"stats":{"Line":12}},{"line":90,"address":[],"length":0,"stats":{"Line":8}},{"line":93,"address":[],"length":0,"stats":{"Line":1}},{"line":94,"address":[],"length":0,"stats":{"Line":3}},{"line":100,"address":[],"length":0,"stats":{"Line":1}},{"line":101,"address":[],"length":0,"stats":{"Line":3}},{"line":102,"address":[],"length":0,"stats":{"Line":3}},{"line":103,"address":[],"length":0,"stats":{"Line":3}},{"line":106,"address":[],"length":0,"stats":{"Line":1}},{"line":107,"address":[],"length":0,"stats":{"Line":3}},{"line":114,"address":[],"length":0,"stats":{"Line":1}},{"line":115,"address":[],"length":0,"stats":{"Line":1}},{"line":116,"address":[],"length":0,"stats":{"Line":2}},{"line":117,"address":[],"length":0,"stats":{"Line":1}},{"line":125,"address":[],"length":0,"stats":{"Line":1}},{"line":126,"address":[],"length":0,"stats":{"Line":3}},{"line":133,"address":[],"length":0,"stats":{"Line":1}},{"line":134,"address":[],"length":0,"stats":{"Line":3}},{"line":138,"address":[],"length":0,"stats":{"Line":3}},{"line":141,"address":[],"length":0,"stats":{"Line":1}},{"line":142,"address":[],"length":0,"stats":{"Line":3}},{"line":143,"address":[],"length":0,"stats":{"Line":3}},{"line":146,"address":[],"length":0,"stats":{"Line":2}},{"line":147,"address":[],"length":0,"stats":{"Line":1}},{"line":152,"address":[],"length":0,"stats":{"Line":1}},{"line":153,"address":[],"length":0,"stats":{"Line":3}},{"line":160,"address":[],"length":0,"stats":{"Line":1}},{"line":161,"address":[],"length":0,"stats":{"Line":3}},{"line":168,"address":[],"length":0,"stats":{"Line":1}},{"line":169,"address":[],"length":0,"stats":{"Line":3}},{"line":170,"address":[],"length":0,"stats":{"Line":3}},{"line":177,"address":[],"length":0,"stats":{"Line":1}},{"line":178,"address":[],"length":0,"stats":{"Line":3}},{"line":184,"address":[],"length":0,"stats":{"Line":2}},{"line":185,"address":[],"length":0,"stats":{"Line":6}},{"line":191,"address":[],"length":0,"stats":{"Line":1}},{"line":192,"address":[],"length":0,"stats":{"Line":1}},{"line":193,"address":[],"length":0,"stats":{"Line":3}},{"line":198,"address":[],"length":0,"stats":{"Line":2}},{"line":199,"address":[],"length":0,"stats":{"Line":6}},{"line":205,"address":[],"length":0,"stats":{"Line":1}},{"line":206,"address":[],"length":0,"stats":{"Line":2}},{"line":207,"address":[],"length":0,"stats":{"Line":1}},{"line":213,"address":[],"length":0,"stats":{"Line":2}},{"line":214,"address":[],"length":0,"stats":{"Line":1}},{"line":219,"address":[],"length":0,"stats":{"Line":1}},{"line":220,"address":[],"length":0,"stats":{"Line":3}},{"line":221,"address":[],"length":0,"stats":{"Line":6}}],"covered":83,"coverable":83},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","backend.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","bridge.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","cca.rs"],"content":"use serde::{Deserialize, Serialize};\nuse validator::Validate;\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize, Default)]\n#[serde(rename_all = \"snake_case\")]\npub enum StalenessPolicy {\n    #[default]\n    ServeStaleWarn,\n    RegenerateBlocking,\n    RegenerateAsync,\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize, Default)]\n#[serde(rename_all = \"snake_case\")]\npub enum CaptureMode {\n    #[default]\n    All,\n    Sampled,\n    ErrorsOnly,\n    Disabled,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct CcaConfig {\n    #[serde(default)]\n    pub enabled: bool,\n\n    #[serde(default)]\n    pub context_architect: ContextArchitectConfig,\n\n    #[serde(default)]\n    pub note_taking: NoteTakingConfig,\n\n    #[serde(default)]\n    pub hindsight: HindsightConfig,\n\n    #[serde(default)]\n    pub meta_agent: MetaAgentConfig,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct ContextArchitectConfig {\n    #[serde(default)]\n    pub enabled: bool,\n\n    #[serde(default)]\n    pub default_token_budget: u32,\n\n    #[serde(default)]\n    pub layer_priorities: Vec<String>,\n\n    #[serde(default)]\n    pub min_relevance_score: f32,\n\n    #[serde(default)]\n    pub enable_caching: bool,\n\n    #[serde(default = \"default_cache_ttl_secs\")]\n    pub cache_ttl_secs: u64,\n\n    #[serde(default)]\n    pub staleness_policy: StalenessPolicy,\n\n    #[serde(default = \"default_assembly_timeout_ms\")]\n    pub assembly_timeout_ms: u64,\n\n    #[serde(default = \"default_enable_parallel_queries\")]\n    pub enable_parallel_queries: bool,\n\n    #[serde(default = \"default_enable_early_termination\")]\n    pub enable_early_termination: bool,\n}\n\nfn default_cache_ttl_secs() -> u64 {\n    300\n}\n\nfn default_assembly_timeout_ms() -> u64 {\n    100\n}\n\nfn default_enable_parallel_queries() -> bool {\n    true\n}\n\nfn default_enable_early_termination() -> bool {\n    true\n}\n\nimpl Default for ContextArchitectConfig {\n    fn default() -> Self {\n        Self {\n            enabled: true,\n            default_token_budget: 4000,\n            layer_priorities: vec![\n                \"session\".to_string(),\n                \"project\".to_string(),\n                \"team\".to_string(),\n                \"org\".to_string(),\n                \"company\".to_string(),\n            ],\n            min_relevance_score: 0.3,\n            enable_caching: true,\n            cache_ttl_secs: 300,\n            staleness_policy: StalenessPolicy::default(),\n            assembly_timeout_ms: default_assembly_timeout_ms(),\n            enable_parallel_queries: default_enable_parallel_queries(),\n            enable_early_termination: default_enable_early_termination(),\n        }\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct NoteTakingConfig {\n    #[serde(default)]\n    pub enabled: bool,\n\n    #[serde(default)]\n    pub auto_distill_threshold: usize,\n\n    #[serde(default)]\n    pub manual_trigger_enabled: bool,\n\n    #[serde(default)]\n    pub sensitive_patterns_enabled: bool,\n\n    #[serde(default)]\n    pub capture_mode: CaptureMode,\n\n    #[serde(default = \"default_sampling_rate\")]\n    pub sampling_rate: u32,\n\n    #[serde(default = \"default_overhead_budget_ms\")]\n    pub overhead_budget_ms: u64,\n\n    #[serde(default = \"default_queue_size\")]\n    pub queue_size: usize,\n\n    #[serde(default = \"default_batch_size\")]\n    pub batch_size: usize,\n\n    #[serde(default = \"default_batch_flush_ms\")]\n    pub batch_flush_ms: u64,\n}\n\nfn default_sampling_rate() -> u32 {\n    10\n}\n\nfn default_overhead_budget_ms() -> u64 {\n    5\n}\n\nfn default_queue_size() -> usize {\n    1000\n}\n\nfn default_batch_size() -> usize {\n    10\n}\n\nfn default_batch_flush_ms() -> u64 {\n    100\n}\n\nimpl Default for NoteTakingConfig {\n    fn default() -> Self {\n        Self {\n            enabled: true,\n            auto_distill_threshold: 10,\n            manual_trigger_enabled: true,\n            sensitive_patterns_enabled: true,\n            capture_mode: CaptureMode::default(),\n            sampling_rate: default_sampling_rate(),\n            overhead_budget_ms: default_overhead_budget_ms(),\n            queue_size: default_queue_size(),\n            batch_size: default_batch_size(),\n            batch_flush_ms: default_batch_flush_ms(),\n        }\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct HindsightConfig {\n    #[serde(default)]\n    pub enabled: bool,\n\n    #[serde(default)]\n    pub semantic_threshold: f32,\n\n    #[serde(default = \"default_max_results\")]\n    pub max_results: usize,\n\n    #[serde(default = \"default_promotion_threshold\")]\n    pub promotion_threshold: f32,\n\n    #[serde(default)]\n    pub auto_capture_enabled: bool,\n}\n\nfn default_max_results() -> usize {\n    5\n}\n\nfn default_promotion_threshold() -> f32 {\n    0.8\n}\n\nimpl Default for HindsightConfig {\n    fn default() -> Self {\n        Self {\n            enabled: true,\n            semantic_threshold: 0.8,\n            max_results: 5,\n            promotion_threshold: 0.8,\n            auto_capture_enabled: true,\n        }\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct MetaAgentConfig {\n    #[serde(default)]\n    pub enabled: bool,\n\n    #[serde(default = \"default_max_iterations\")]\n    pub max_iterations: u32,\n\n    #[serde(default = \"default_iteration_timeout_secs\")]\n    pub iteration_timeout_secs: u64,\n\n    #[serde(default = \"default_build_timeout_secs\")]\n    pub build_timeout_secs: u64,\n\n    #[serde(default = \"default_test_timeout_secs\")]\n    pub test_timeout_secs: u64,\n\n    #[serde(default)]\n    pub auto_escalate_on_failure: bool,\n}\n\nfn default_max_iterations() -> u32 {\n    3\n}\n\nfn default_iteration_timeout_secs() -> u64 {\n    300\n}\n\nfn default_build_timeout_secs() -> u64 {\n    120\n}\n\nfn default_test_timeout_secs() -> u64 {\n    60\n}\n\nimpl Default for MetaAgentConfig {\n    fn default() -> Self {\n        Self {\n            enabled: true,\n            max_iterations: 3,\n            iteration_timeout_secs: 300,\n            build_timeout_secs: 120,\n            test_timeout_secs: 60,\n            auto_escalate_on_failure: true,\n        }\n    }\n}\n\nimpl Default for CcaConfig {\n    fn default() -> Self {\n        Self {\n            enabled: true,\n            context_architect: ContextArchitectConfig::default(),\n            note_taking: NoteTakingConfig::default(),\n            hindsight: HindsightConfig::default(),\n            meta_agent: MetaAgentConfig::default(),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_cca_config_default() {\n        let config = CcaConfig::default();\n        assert_eq!(config.enabled, true);\n        assert_eq!(config.context_architect.default_token_budget, 4000);\n        assert_eq!(config.hindsight.max_results, 5);\n        assert_eq!(config.meta_agent.max_iterations, 3);\n    }\n\n    #[test]\n    fn test_context_architect_config_default() {\n        let config = ContextArchitectConfig::default();\n        assert_eq!(config.enabled, true);\n        assert_eq!(config.default_token_budget, 4000);\n        assert_eq!(config.min_relevance_score, 0.3);\n        assert!(config.layer_priorities.len() > 0);\n    }\n\n    #[test]\n    fn test_note_taking_config_default() {\n        let config = NoteTakingConfig::default();\n        assert_eq!(config.enabled, true);\n        assert_eq!(config.auto_distill_threshold, 10);\n        assert_eq!(config.manual_trigger_enabled, true);\n    }\n\n    #[test]\n    fn test_hindsight_config_default() {\n        let config = HindsightConfig::default();\n        assert_eq!(config.enabled, true);\n        assert_eq!(config.semantic_threshold, 0.8);\n        assert_eq!(config.max_results, 5);\n        assert_eq!(config.promotion_threshold, 0.8);\n    }\n\n    #[test]\n    fn test_meta_agent_config_default() {\n        let config = MetaAgentConfig::default();\n        assert_eq!(config.enabled, true);\n        assert_eq!(config.max_iterations, 3);\n        assert_eq!(config.iteration_timeout_secs, 300);\n        assert_eq!(config.build_timeout_secs, 120);\n        assert_eq!(config.test_timeout_secs, 60);\n    }\n\n    #[test]\n    fn test_cca_config_validation() {\n        let mut config = CcaConfig::default();\n        assert!(config.validate().is_ok());\n\n        config.context_architect.min_relevance_score = 2.0;\n        assert!(config.validate().is_ok());\n\n        config.context_architect.min_relevance_score = -1.0;\n        assert!(config.validate().is_ok());\n    }\n\n    #[test]\n    fn test_serialize_deserialize() {\n        let config = CcaConfig::default();\n        let serialized = serde_json::to_string(&config).unwrap();\n        let deserialized: CcaConfig = serde_json::from_str(&serialized).unwrap();\n        assert_eq!(config, deserialized);\n    }\n}\n","traces":[{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":27}},{"line":79,"address":[],"length":0,"stats":{"Line":27}},{"line":82,"address":[],"length":0,"stats":{"Line":27}},{"line":83,"address":[],"length":0,"stats":{"Line":27}},{"line":86,"address":[],"length":0,"stats":{"Line":27}},{"line":87,"address":[],"length":0,"stats":{"Line":27}},{"line":91,"address":[],"length":0,"stats":{"Line":27}},{"line":95,"address":[],"length":0,"stats":{"Line":54}},{"line":105,"address":[],"length":0,"stats":{"Line":54}},{"line":106,"address":[],"length":0,"stats":{"Line":54}},{"line":107,"address":[],"length":0,"stats":{"Line":27}},{"line":108,"address":[],"length":0,"stats":{"Line":27}},{"line":146,"address":[],"length":0,"stats":{"Line":36}},{"line":147,"address":[],"length":0,"stats":{"Line":36}},{"line":150,"address":[],"length":0,"stats":{"Line":36}},{"line":151,"address":[],"length":0,"stats":{"Line":36}},{"line":154,"address":[],"length":0,"stats":{"Line":36}},{"line":155,"address":[],"length":0,"stats":{"Line":36}},{"line":158,"address":[],"length":0,"stats":{"Line":36}},{"line":159,"address":[],"length":0,"stats":{"Line":36}},{"line":162,"address":[],"length":0,"stats":{"Line":36}},{"line":163,"address":[],"length":0,"stats":{"Line":36}},{"line":167,"address":[],"length":0,"stats":{"Line":36}},{"line":173,"address":[],"length":0,"stats":{"Line":72}},{"line":174,"address":[],"length":0,"stats":{"Line":72}},{"line":175,"address":[],"length":0,"stats":{"Line":72}},{"line":176,"address":[],"length":0,"stats":{"Line":72}},{"line":177,"address":[],"length":0,"stats":{"Line":36}},{"line":178,"address":[],"length":0,"stats":{"Line":36}},{"line":201,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":205,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":27}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":0}},{"line":254,"address":[],"length":0,"stats":{"Line":0}},{"line":255,"address":[],"length":0,"stats":{"Line":0}},{"line":259,"address":[],"length":0,"stats":{"Line":27}},{"line":272,"address":[],"length":0,"stats":{"Line":26}},{"line":275,"address":[],"length":0,"stats":{"Line":52}},{"line":276,"address":[],"length":0,"stats":{"Line":52}},{"line":277,"address":[],"length":0,"stats":{"Line":26}},{"line":278,"address":[],"length":0,"stats":{"Line":26}}],"covered":36,"coverable":50},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","config.rs"],"content":"//! # Configuration Structures\n//!\n//! This module defines all configuration structures for the Memory-Knowledge\n//! system.\n//!\n//! All configuration structures:\n//! - Use `serde` for serialization/deserialization\n//! - Use `validator` for input validation\n//! - Follow Microsoft Pragmatic Rust Guidelines\n//! - Include comprehensive M-CANONICAL-DOCS\n\nuse crate::cca::CcaConfig;\nuse serde::{Deserialize, Serialize};\nuse validator::Validate;\n\n/// Main configuration structure for the Memory-Knowledge system.\n///\n/// This is the top-level configuration that aggregates all subsystem\n/// configurations.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Provides centralized configuration for the entire Memory-Knowledge system,\n/// including storage providers, sync behavior, MCP tools, observability, and\n/// CCA.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::Config;\n///\n/// let config = Config::default();\n/// println!(\"PostgreSQL host: {}\", config.providers.postgres.host);\n/// ```\n///\n/// ## Fields\n/// - `providers`: Configuration for storage backends (PostgreSQL, Qdrant,\n///   Redis)\n/// - `sync`: Configuration for memory-knowledge synchronization\n/// - `tools`: Configuration for MCP server tools\n/// - `observability`: Configuration for metrics and tracing\n/// - `cca`: Configuration for CCA (Confucius Code Agent) capabilities\n///\n/// ## Validation\n/// All nested configurations must pass their own validation rules.\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, Default, PartialEq)]\npub struct Config {\n    /// Storage provider configurations (PostgreSQL, Qdrant, Redis)\n    #[serde(default)]\n    pub providers: ProviderConfig,\n\n    /// Memory-knowledge synchronization configuration\n    #[serde(default)]\n    pub sync: SyncConfig,\n\n    /// Memory system configuration\n    #[serde(default)]\n    pub memory: MemoryConfig,\n\n    /// MCP tool interface configuration\n    #[serde(default)]\n    pub tools: ToolConfig,\n\n    /// Observability configuration (metrics, tracing, logging)\n    #[serde(default)]\n    pub observability: ObservabilityConfig,\n\n    /// Deployment mode configuration (Local, Hybrid, Remote)\n    #[serde(default)]\n    pub deployment: DeploymentConfig,\n\n    /// Job coordination configuration (locks, timeouts, checkpoints)\n    #[serde(default)]\n    pub job: JobConfig,\n\n    /// CCA (Confucius Code Agent) capabilities configuration\n    #[serde(default)]\n    pub cca: CcaConfig,\n}\n\nimpl Config {\n    /// Detects environment settings for deployment mode.\n    ///\n    /// # M-CANONICAL-DOCS\n    ///\n    /// ## Purpose\n    /// Initializes configuration based on AETERNA_ environment variables.\n    pub fn detect_env() -> Self {\n        let mut config = Self::default();\n\n        if let Ok(url) = std::env::var(\"AETERNA_REMOTE_GOVERNANCE_URL\") {\n            config.deployment.remote_url = Some(url);\n            config.deployment.mode =\n                std::env::var(\"AETERNA_DEPLOYMENT_MODE\").unwrap_or_else(|_| \"hybrid\".to_string());\n        }\n\n        if std::env::var(\"AETERNA_THIN_CLIENT\").is_ok() {\n            config.deployment.mode = \"remote\".to_string();\n            config.sync.enabled = false;\n        }\n\n        config\n    }\n}\n\n/// Deployment mode configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages the deployment mode of the system (Local, Hybrid, or Remote).\n///\n/// ## Fields\n/// - `mode`: Deployment mode (default: \"local\")\n/// - `remote_url`: URL of the remote governance server (required for\n///   Hybrid/Remote)\n/// - `sync_enabled`: Enable synchronization in Hybrid mode (default: true)\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct DeploymentConfig {\n    /// Deployment mode\n    #[serde(default = \"default_deployment_mode\")]\n    #[validate(custom(function = \"validate_deployment_mode\"))]\n    pub mode: String,\n\n    /// URL of the remote governance server\n    #[serde(default)]\n    pub remote_url: Option<String>,\n\n    /// Enable synchronization in Hybrid mode\n    #[serde(default = \"default_deployment_sync_enabled\")]\n    pub sync_enabled: bool,\n}\n\nfn default_deployment_mode() -> String {\n    \"local\".to_string()\n}\n\nfn default_deployment_sync_enabled() -> bool {\n    true\n}\n\nfn validate_deployment_mode(value: &str) -> Result<(), validator::ValidationError> {\n    match value {\n        \"local\" | \"hybrid\" | \"remote\" => Ok(()),\n        _ => Err(validator::ValidationError::new(\"Invalid deployment mode\")),\n    }\n}\n\nimpl Default for DeploymentConfig {\n    fn default() -> Self {\n        Self {\n            mode: default_deployment_mode(),\n            remote_url: None,\n            sync_enabled: default_deployment_sync_enabled(),\n        }\n    }\n}\n\nimpl DeploymentConfig {\n    pub fn auto_detect() -> Self {\n        let mut config = Self::default();\n\n        if let Ok(mode) = std::env::var(\"AETERNA_DEPLOYMENT_MODE\") {\n            config.mode = mode;\n        }\n\n        if let Ok(url) = std::env::var(\"AETERNA_REMOTE_GOVERNANCE_URL\") {\n            config.remote_url = Some(url);\n            if config.mode == \"local\" {\n                config.mode = \"hybrid\".to_string();\n            }\n        }\n\n        if std::env::var(\"AETERNA_THIN_CLIENT\").is_ok() {\n            config.mode = \"remote\".to_string();\n            config.sync_enabled = false;\n        }\n\n        if let Ok(sync) = std::env::var(\"AETERNA_SYNC_ENABLED\") {\n            config.sync_enabled = sync.to_lowercase() == \"true\" || sync == \"1\";\n        }\n\n        config\n    }\n\n    pub fn is_local(&self) -> bool {\n        self.mode == \"local\"\n    }\n\n    pub fn is_hybrid(&self) -> bool {\n        self.mode == \"hybrid\"\n    }\n\n    pub fn is_remote(&self) -> bool {\n        self.mode == \"remote\"\n    }\n\n    pub fn requires_remote_url(&self) -> bool {\n        self.is_hybrid() || self.is_remote()\n    }\n\n    pub fn requires_local_engine(&self) -> bool {\n        self.is_local() || self.is_hybrid()\n    }\n}\n\n/// Configuration for storage providers.\n///\n/// Manages connection settings for all storage backends.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Centralizes connection configuration for all storage backends:\n/// - PostgreSQL: Primary data storage with pgvector extension\n/// - Qdrant: Vector similarity search\n/// - Redis: Caching layer\n/// - Graph: DuckDB-based knowledge graph\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::ProviderConfig;\n///\n/// let providers = ProviderConfig::default();\n/// assert_eq!(providers.postgres.host, \"localhost\");\n/// ```\n///\n/// ## Fields\n/// - `postgres`: PostgreSQL connection configuration\n/// - `qdrant`: Qdrant vector database configuration\n/// - `redis`: Redis caching configuration\n/// - `graph`: DuckDB graph store configuration\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, Default, PartialEq)]\npub struct ProviderConfig {\n    /// PostgreSQL connection configuration\n    #[serde(default)]\n    pub postgres: PostgresConfig,\n\n    /// Qdrant vector database configuration\n    #[serde(default)]\n    pub qdrant: QdrantConfig,\n\n    /// Redis caching configuration\n    #[serde(default)]\n    pub redis: RedisConfig,\n\n    /// DuckDB graph store configuration\n    #[serde(default)]\n    pub graph: GraphConfig,\n}\n\n/// PostgreSQL configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages connection settings for PostgreSQL, the primary data storage\n/// backend.\n///\n/// ## Fields\n/// - `host`: Database server hostname (default: \"localhost\")\n/// - `port`: Database server port (default: 5432)\n/// - `database`: Database name (required)\n/// - `username`: Database user (required)\n/// - `password`: Database password (required, should use environment variable)\n/// - `pool_size`: Maximum connections in pool (default: 10, range: 1-100)\n/// - `timeout_seconds`: Connection timeout (default: 30, range: 1-300)\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct PostgresConfig {\n    /// Database server hostname\n    #[serde(default = \"default_postgres_host\")]\n    #[validate(length(min = 1, max = 255))]\n    pub host: String,\n\n    /// Database server port\n    #[serde(default = \"default_postgres_port\")]\n    #[validate(range(min = 1, max = 65535))]\n    pub port: u16,\n\n    /// Database name\n    #[serde(default = \"default_postgres_database\")]\n    #[validate(length(min = 1, max = 63))]\n    pub database: String,\n\n    /// Database username\n    #[serde(default = \"default_postgres_username\")]\n    #[validate(length(min = 1, max = 63))]\n    pub username: String,\n\n    /// Database password\n    #[serde(default = \"default_postgres_password\")]\n    #[validate(length(min = 1))]\n    pub password: String,\n\n    /// Maximum connections in pool\n    #[serde(default = \"default_postgres_pool_size\")]\n    #[validate(range(min = 1, max = 100))]\n    pub pool_size: u32,\n\n    /// Connection timeout in seconds\n    #[serde(default = \"default_postgres_timeout\")]\n    #[validate(range(min = 1, max = 300))]\n    pub timeout_seconds: u64,\n}\n\nfn default_postgres_host() -> String {\n    \"localhost\".to_string()\n}\n\nfn default_postgres_port() -> u16 {\n    5432\n}\n\nfn default_postgres_database() -> String {\n    \"memory_knowledge\".to_string()\n}\n\nfn default_postgres_username() -> String {\n    \"postgres\".to_string()\n}\n\nfn default_postgres_password() -> String {\n    \"\".to_string()\n}\n\nfn default_postgres_pool_size() -> u32 {\n    10\n}\n\nfn default_postgres_timeout() -> u64 {\n    30\n}\n\nimpl Default for PostgresConfig {\n    fn default() -> Self {\n        Self {\n            host: default_postgres_host(),\n            port: default_postgres_port(),\n            database: default_postgres_database(),\n            username: default_postgres_username(),\n            password: default_postgres_password(),\n            pool_size: default_postgres_pool_size(),\n            timeout_seconds: default_postgres_timeout(),\n        }\n    }\n}\n\n/// Qdrant vector database configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages connection settings for Qdrant, used for vector similarity search.\n///\n/// ## Fields\n/// - `host`: Qdrant server hostname (default: \"localhost\")\n/// - `port`: Qdrant server port (default: 6333)\n/// - `collection`: Default collection name (required)\n/// - `timeout_seconds`: Request timeout (default: 30, range: 1-300)\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct QdrantConfig {\n    /// Qdrant server hostname\n    #[serde(default = \"default_qdrant_host\")]\n    #[validate(length(min = 1, max = 255))]\n    pub host: String,\n\n    /// Qdrant server port\n    #[serde(default = \"default_qdrant_port\")]\n    #[validate(range(min = 1, max = 65535))]\n    pub port: u16,\n\n    /// Default collection name\n    #[serde(default = \"default_qdrant_collection\")]\n    #[validate(length(min = 1, max = 255))]\n    pub collection: String,\n\n    /// Request timeout in seconds\n    #[serde(default = \"default_qdrant_timeout\")]\n    #[validate(range(min = 1, max = 300))]\n    pub timeout_seconds: u64,\n}\n\nfn default_qdrant_host() -> String {\n    \"localhost\".to_string()\n}\n\nfn default_qdrant_port() -> u16 {\n    6333\n}\n\nfn default_qdrant_collection() -> String {\n    \"memory_embeddings\".to_string()\n}\n\nfn default_qdrant_timeout() -> u64 {\n    30\n}\n\nimpl Default for QdrantConfig {\n    fn default() -> Self {\n        Self {\n            host: default_qdrant_host(),\n            port: default_qdrant_port(),\n            collection: default_qdrant_collection(),\n            timeout_seconds: default_qdrant_timeout(),\n        }\n    }\n}\n\n/// Redis configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages connection settings for Redis, used as a caching layer.\n///\n/// ## Fields\n/// - `host`: Redis server hostname (default: \"localhost\")\n/// - `port`: Redis server port (default: 6379)\n/// - `db`: Redis database number (default: 0, range: 0-15)\n/// - `pool_size`: Maximum connections in pool (default: 10, range: 1-100)\n/// - `timeout_seconds`: Connection timeout (default: 30, range: 1-300)\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct RedisConfig {\n    /// Redis server hostname\n    #[serde(default = \"default_redis_host\")]\n    #[validate(length(min = 1, max = 255))]\n    pub host: String,\n\n    /// Redis server port\n    #[serde(default = \"default_redis_port\")]\n    #[validate(range(min = 1, max = 65535))]\n    pub port: u16,\n\n    /// Redis database number\n    #[serde(default = \"default_redis_db\")]\n    #[validate(range(min = 0, max = 15))]\n    pub db: u8,\n\n    /// Maximum connections in pool\n    #[serde(default = \"default_redis_pool_size\")]\n    #[validate(range(min = 1, max = 100))]\n    pub pool_size: u32,\n\n    /// Connection timeout in seconds\n    #[serde(default = \"default_redis_timeout\")]\n    #[validate(range(min = 1, max = 300))]\n    pub timeout_seconds: u64,\n}\n\nfn default_redis_host() -> String {\n    \"localhost\".to_string()\n}\n\nfn default_redis_port() -> u16 {\n    6379\n}\n\nfn default_redis_db() -> u8 {\n    0\n}\n\nfn default_redis_pool_size() -> u32 {\n    10\n}\n\nfn default_redis_timeout() -> u64 {\n    30\n}\n\nimpl Default for RedisConfig {\n    fn default() -> Self {\n        Self {\n            host: default_redis_host(),\n            port: default_redis_port(),\n            db: default_redis_db(),\n            pool_size: default_redis_pool_size(),\n            timeout_seconds: default_redis_timeout(),\n        }\n    }\n}\n\n/// DuckDB Graph Store configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages configuration for the DuckDB-based knowledge graph storage layer.\n///\n/// ## Fields\n/// - `enabled`: Enable/disable graph store (default: true)\n/// - `database_path`: Path to DuckDB database file (default: \":memory:\")\n/// - `s3_bucket`: Optional S3 bucket for persistence\n/// - `s3_prefix`: Optional S3 key prefix\n/// - `s3_endpoint`: Optional S3 endpoint for MinIO/localstack\n/// - `s3_region`: S3 region (default: \"us-east-1\")\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct GraphConfig {\n    /// Enable/disable graph store\n    #[serde(default = \"default_graph_enabled\")]\n    pub enabled: bool,\n\n    /// Path to DuckDB database file (use \":memory:\" for in-memory)\n    #[serde(default = \"default_graph_path\")]\n    #[validate(length(min = 1, max = 255))]\n    pub database_path: String,\n\n    /// Optional S3 bucket for graph persistence\n    #[serde(default)]\n    pub s3_bucket: Option<String>,\n\n    /// Optional S3 key prefix\n    #[serde(default)]\n    pub s3_prefix: Option<String>,\n\n    /// Optional S3 endpoint (for MinIO or localstack)\n    #[serde(default)]\n    pub s3_endpoint: Option<String>,\n\n    /// S3 region\n    #[serde(default = \"default_graph_s3_region\")]\n    pub s3_region: String,\n\n    /// Alerting thresholds for write contention\n    #[serde(default)]\n    pub contention_alerts: ContentionAlertConfig,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct ContentionAlertConfig {\n    #[serde(default = \"default_queue_depth_warn\")]\n    #[validate(range(min = 1, max = 100))]\n    pub queue_depth_warn: u32,\n\n    #[serde(default = \"default_queue_depth_critical\")]\n    #[validate(range(min = 1, max = 100))]\n    pub queue_depth_critical: u32,\n\n    #[serde(default = \"default_wait_time_warn_ms\")]\n    #[validate(range(min = 100, max = 60000))]\n    pub wait_time_warn_ms: u64,\n\n    #[serde(default = \"default_wait_time_critical_ms\")]\n    #[validate(range(min = 100, max = 60000))]\n    pub wait_time_critical_ms: u64,\n\n    #[serde(default = \"default_timeout_rate_warn\")]\n    #[validate(range(min = 0.0, max = 100.0))]\n    pub timeout_rate_warn_percent: f64,\n\n    #[serde(default = \"default_timeout_rate_critical\")]\n    #[validate(range(min = 0.0, max = 100.0))]\n    pub timeout_rate_critical_percent: f64,\n}\n\nfn default_queue_depth_warn() -> u32 {\n    5\n}\nfn default_queue_depth_critical() -> u32 {\n    10\n}\nfn default_wait_time_warn_ms() -> u64 {\n    1000\n}\nfn default_wait_time_critical_ms() -> u64 {\n    3000\n}\nfn default_timeout_rate_warn() -> f64 {\n    5.0\n}\nfn default_timeout_rate_critical() -> f64 {\n    15.0\n}\n\nimpl Default for ContentionAlertConfig {\n    fn default() -> Self {\n        Self {\n            queue_depth_warn: default_queue_depth_warn(),\n            queue_depth_critical: default_queue_depth_critical(),\n            wait_time_warn_ms: default_wait_time_warn_ms(),\n            wait_time_critical_ms: default_wait_time_critical_ms(),\n            timeout_rate_warn_percent: default_timeout_rate_warn(),\n            timeout_rate_critical_percent: default_timeout_rate_critical(),\n        }\n    }\n}\n\nfn default_graph_enabled() -> bool {\n    true\n}\n\nfn default_graph_path() -> String {\n    \":memory:\".to_string()\n}\n\nfn default_graph_s3_region() -> String {\n    \"us-east-1\".to_string()\n}\n\nimpl Default for GraphConfig {\n    fn default() -> Self {\n        Self {\n            enabled: default_graph_enabled(),\n            database_path: default_graph_path(),\n            s3_bucket: None,\n            s3_prefix: None,\n            s3_endpoint: None,\n            s3_region: default_graph_s3_region(),\n            contention_alerts: ContentionAlertConfig::default(),\n        }\n    }\n}\n\n/// Synchronization configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages synchronization behavior between memory and knowledge systems.\n///\n/// ## Fields\n/// - `enabled`: Enable/disable automatic sync (default: true)\n/// - `sync_interval_seconds`: Sync interval (default: 60, range: 10-3600)\n/// - `batch_size`: Number of items per sync batch (default: 100, range: 1-1000)\n/// - `checkpoint_enabled`: Enable checkpointing for rollback (default: true)\n/// - `conflict_resolution`: Strategy for conflict resolution (default:\n///   \"prefer_knowledge\")\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct SyncConfig {\n    /// Enable/disable automatic synchronization\n    #[serde(default = \"default_sync_enabled\")]\n    pub enabled: bool,\n\n    /// Sync interval in seconds\n    #[serde(default = \"default_sync_interval\")]\n    #[validate(range(min = 10, max = 3600))]\n    pub sync_interval_seconds: u64,\n\n    /// Number of items per sync batch\n    #[serde(default = \"default_sync_batch_size\")]\n    #[validate(range(min = 1, max = 1000))]\n    pub batch_size: u32,\n\n    /// Enable checkpointing for rollback\n    #[serde(default = \"default_sync_checkpoint\")]\n    pub checkpoint_enabled: bool,\n\n    /// Conflict resolution strategy\n    #[serde(default = \"default_sync_conflict_resolution\")]\n    #[validate(custom(function = \"validate_conflict_resolution\"))]\n    pub conflict_resolution: String,\n}\n\nfn default_sync_enabled() -> bool {\n    true\n}\n\nfn default_sync_interval() -> u64 {\n    60\n}\n\nfn default_sync_batch_size() -> u32 {\n    100\n}\n\nfn default_sync_checkpoint() -> bool {\n    true\n}\n\nfn default_sync_conflict_resolution() -> String {\n    \"prefer_knowledge\".to_string()\n}\n\nfn validate_conflict_resolution(value: &str) -> Result<(), validator::ValidationError> {\n    match value {\n        \"prefer_knowledge\" | \"prefer_memory\" | \"manual\" => Ok(()),\n        _ => Err(validator::ValidationError::new(\n            \"Invalid conflict resolution strategy\",\n        )),\n    }\n}\n\nimpl Default for SyncConfig {\n    fn default() -> Self {\n        Self {\n            enabled: default_sync_enabled(),\n            sync_interval_seconds: default_sync_interval(),\n            batch_size: default_sync_batch_size(),\n            checkpoint_enabled: default_sync_checkpoint(),\n            conflict_resolution: default_sync_conflict_resolution(),\n        }\n    }\n}\n\n/// MCP tool interface configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages configuration for the MCP (Model Context Protocol) server interface.\n///\n/// ## Fields\n/// - `enabled`: Enable/disable MCP server (default: true)\n/// - `host`: Server hostname (default: \"localhost\")\n/// - `port`: Server port (default: 8080)\n/// - `api_key`: API key for authentication (optional)\n/// - `rate_limit_requests_per_minute`: Rate limit (default: 60, range: 1-1000)\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct ToolConfig {\n    /// Enable/disable MCP server\n    #[serde(default = \"default_tools_enabled\")]\n    pub enabled: bool,\n\n    /// Server hostname\n    #[serde(default = \"default_tools_host\")]\n    #[validate(length(min = 1, max = 255))]\n    pub host: String,\n\n    /// Server port\n    #[serde(default = \"default_tools_port\")]\n    #[validate(range(min = 1, max = 65535))]\n    pub port: u16,\n\n    /// API key for authentication\n    #[serde(default)]\n    pub api_key: Option<String>,\n\n    /// Rate limit: requests per minute\n    #[serde(default = \"default_tools_rate_limit\")]\n    #[validate(range(min = 1, max = 1000))]\n    pub rate_limit_requests_per_minute: u32,\n}\n\nfn default_tools_enabled() -> bool {\n    true\n}\n\nfn default_tools_host() -> String {\n    \"localhost\".to_string()\n}\n\nfn default_tools_port() -> u16 {\n    8080\n}\n\nfn default_tools_rate_limit() -> u32 {\n    60\n}\n\nimpl Default for ToolConfig {\n    fn default() -> Self {\n        Self {\n            enabled: default_tools_enabled(),\n            host: default_tools_host(),\n            port: default_tools_port(),\n            api_key: None,\n            rate_limit_requests_per_minute: default_tools_rate_limit(),\n        }\n    }\n}\n\n/// Observability configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages configuration for metrics, tracing, and logging.\n///\n/// ## Fields\n/// - `metrics_enabled`: Enable metrics collection (default: true)\n/// - `tracing_enabled`: Enable distributed tracing (default: true)\n/// - `logging_level`: Log level (default: \"info\")\n/// - `metrics_port`: Metrics server port (default: 9090)\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct ObservabilityConfig {\n    /// Enable metrics collection\n    #[serde(default = \"default_observability_metrics_enabled\")]\n    pub metrics_enabled: bool,\n\n    /// Enable distributed tracing\n    #[serde(default = \"default_observability_tracing_enabled\")]\n    pub tracing_enabled: bool,\n\n    /// Logging level\n    #[serde(default = \"default_observability_logging_level\")]\n    #[validate(custom(function = \"validate_logging_level\"))]\n    pub logging_level: String,\n\n    /// Metrics server port\n    #[serde(default = \"default_observability_metrics_port\")]\n    #[validate(range(min = 1, max = 65535))]\n    pub metrics_port: u16,\n}\n\nfn default_observability_metrics_enabled() -> bool {\n    true\n}\n\nfn default_observability_tracing_enabled() -> bool {\n    true\n}\n\nfn default_observability_logging_level() -> String {\n    \"info\".to_string()\n}\n\nfn default_observability_metrics_port() -> u16 {\n    9090\n}\n\nfn validate_logging_level(value: &str) -> Result<(), validator::ValidationError> {\n    match value {\n        \"trace\" | \"debug\" | \"info\" | \"warn\" | \"error\" => Ok(()),\n        _ => Err(validator::ValidationError::new(\"Invalid logging level\")),\n    }\n}\n\nimpl Default for ObservabilityConfig {\n    fn default() -> Self {\n        Self {\n            metrics_enabled: default_observability_metrics_enabled(),\n            tracing_enabled: default_observability_tracing_enabled(),\n            logging_level: default_observability_logging_level(),\n            metrics_port: default_observability_metrics_port(),\n        }\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct MemoryConfig {\n    #[serde(default = \"default_promotion_threshold\")]\n    #[validate(range(min = 0.0, max = 1.0))]\n    pub promotion_threshold: f32,\n\n    #[serde(default = \"default_decay_interval\")]\n    #[validate(range(min = 3600, max = 86400))]\n    pub decay_interval_secs: u64,\n\n    #[serde(default = \"default_decay_rate\")]\n    #[validate(range(min = 0.0, max = 0.5))]\n    pub decay_rate: f32,\n\n    #[serde(default = \"default_optimization_trigger_count\")]\n    #[validate(range(min = 10, max = 1000))]\n    pub optimization_trigger_count: usize,\n\n    #[serde(default)]\n    pub layer_summary_configs:\n        std::collections::HashMap<mk_core::types::MemoryLayer, mk_core::types::SummaryConfig>,\n\n    /// Configuration for reflective reasoning during memory search\n    #[serde(default)]\n    pub reasoning: ReasoningConfig,\n}\n\n/// Configuration for reflective reasoning during memory retrieval.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Controls the behavior of the reflective reasoning step that can be applied\n/// before memory search to improve retrieval quality through query refinement\n/// and strategy selection.\n///\n/// ## Fields\n/// - `enabled`: Enable/disable reasoning step (default: false)\n/// - `timeout_ms`: Maximum time for reasoning LLM call (default: 3000)\n/// - `bypass_simple_queries`: Skip reasoning for simple queries (default: true)\n/// - `simple_query_max_words`: Threshold for simple query detection (default: 5)\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct ReasoningConfig {\n    /// Enable/disable reflective reasoning during search\n    #[serde(default = \"default_reasoning_enabled\")]\n    pub enabled: bool,\n\n    /// Maximum time in milliseconds for reasoning LLM call\n    #[serde(default = \"default_reasoning_timeout_ms\")]\n    #[validate(range(min = 500, max = 30000))]\n    pub timeout_ms: u64,\n\n    /// Skip reasoning for simple queries (reduces latency and cost)\n    #[serde(default = \"default_reasoning_bypass_simple\")]\n    pub bypass_simple_queries: bool,\n\n    /// Maximum word count to consider a query \"simple\"\n    #[serde(default = \"default_reasoning_simple_max_words\")]\n    #[validate(range(min = 1, max = 20))]\n    pub simple_query_max_words: usize,\n\n    /// Multiplier for search limit when using Exhaustive strategy\n    #[serde(default = \"default_exhaustive_limit_multiplier\")]\n    #[validate(range(min = 1.0, max = 5.0))]\n    pub exhaustive_limit_multiplier: f32,\n\n    /// Multiplier for search limit when using Targeted strategy\n    #[serde(default = \"default_targeted_limit_multiplier\")]\n    #[validate(range(min = 0.5, max = 2.0))]\n    pub targeted_limit_multiplier: f32,\n\n    /// P95 latency threshold in ms for alerting (default: 2500, which is below 3000ms timeout)\n    #[serde(default = \"default_reasoning_p95_threshold_ms\")]\n    #[validate(range(min = 100, max = 30000))]\n    pub p95_latency_threshold_ms: u64,\n\n    /// Cache TTL in seconds for reasoning results (default: 3600)\n    #[serde(default = \"default_reasoning_cache_ttl_seconds\")]\n    #[validate(range(min = 60, max = 86400))]\n    pub cache_ttl_seconds: u64,\n\n    /// Enable caching of reasoning results (default: true)\n    #[serde(default = \"default_reasoning_cache_enabled\")]\n    pub cache_enabled: bool,\n\n    /// Maximum number of entries in reasoning cache (default: 10,000)\n    #[serde(default = \"default_reasoning_cache_max_entries\")]\n    #[validate(range(min = 100, max = 1000000))]\n    pub cache_max_entries: usize,\n\n    /// Enable circuit breaker for reasoning failures (default: true)\n    #[serde(default = \"default_circuit_breaker_enabled\")]\n    pub circuit_breaker_enabled: bool,\n\n    /// Circuit breaker failure threshold percentage (default: 5.0)\n    #[serde(default = \"default_circuit_breaker_failure_threshold_percent\")]\n    #[validate(range(min = 1.0, max = 100.0))]\n    pub circuit_breaker_failure_threshold_percent: f64,\n\n    /// Circuit breaker window duration in seconds (default: 300)\n    #[serde(default = \"default_circuit_breaker_window_secs\")]\n    #[validate(range(min = 30, max = 3600))]\n    pub circuit_breaker_window_secs: u64,\n\n    /// Minimum requests in window before circuit breaker can trip (default: 10)\n    #[serde(default = \"default_circuit_breaker_min_requests\")]\n    #[validate(range(min = 1, max = 1000))]\n    pub circuit_breaker_min_requests: u64,\n\n    /// Circuit breaker recovery timeout in seconds (default: 60)\n    #[serde(default = \"default_circuit_breaker_recovery_secs\")]\n    #[validate(range(min = 5, max = 600))]\n    pub circuit_breaker_recovery_secs: u64,\n\n    /// Max requests allowed in half-open state (default: 3)\n    #[serde(default = \"default_circuit_breaker_half_open_requests\")]\n    #[validate(range(min = 1, max = 10))]\n    pub circuit_breaker_half_open_requests: u64,\n\n    /// Maximum hop depth for multi-hop retrieval (default: 3)\n    #[serde(default = \"default_max_hop_depth\")]\n    #[validate(range(min = 1, max = 10))]\n    pub max_hop_depth: u32,\n\n    /// Relevance threshold for path continuation in multi-hop (default: 0.3)\n    #[serde(default = \"default_hop_relevance_threshold\")]\n    #[validate(range(min = 0.0, max = 1.0))]\n    pub hop_relevance_threshold: f32,\n\n    /// Maximum query budget for multi-hop retrieval (default: 50)\n    #[serde(default = \"default_max_query_budget\")]\n    #[validate(range(min = 1, max = 500))]\n    pub max_query_budget: u32,\n}\n\nfn default_reasoning_enabled() -> bool {\n    false\n}\n\nfn default_reasoning_timeout_ms() -> u64 {\n    3000\n}\n\nfn default_reasoning_bypass_simple() -> bool {\n    true\n}\n\nfn default_reasoning_simple_max_words() -> usize {\n    5\n}\n\nfn default_exhaustive_limit_multiplier() -> f32 {\n    2.0\n}\n\nfn default_targeted_limit_multiplier() -> f32 {\n    1.0\n}\n\nfn default_reasoning_p95_threshold_ms() -> u64 {\n    2500\n}\n\nfn default_reasoning_cache_ttl_seconds() -> u64 {\n    3600\n}\n\nfn default_reasoning_cache_enabled() -> bool {\n    true\n}\n\nfn default_reasoning_cache_max_entries() -> usize {\n    10000\n}\n\nfn default_circuit_breaker_enabled() -> bool {\n    true\n}\n\nfn default_circuit_breaker_failure_threshold_percent() -> f64 {\n    5.0\n}\n\nfn default_circuit_breaker_window_secs() -> u64 {\n    300\n}\n\nfn default_circuit_breaker_min_requests() -> u64 {\n    10\n}\n\nfn default_circuit_breaker_recovery_secs() -> u64 {\n    60\n}\n\nfn default_circuit_breaker_half_open_requests() -> u64 {\n    3\n}\n\nfn default_max_hop_depth() -> u32 {\n    3\n}\n\nfn default_hop_relevance_threshold() -> f32 {\n    0.3\n}\n\nfn default_max_query_budget() -> u32 {\n    50\n}\n\nimpl Default for ReasoningConfig {\n    fn default() -> Self {\n        Self {\n            enabled: default_reasoning_enabled(),\n            timeout_ms: default_reasoning_timeout_ms(),\n            bypass_simple_queries: default_reasoning_bypass_simple(),\n            simple_query_max_words: default_reasoning_simple_max_words(),\n            exhaustive_limit_multiplier: default_exhaustive_limit_multiplier(),\n            targeted_limit_multiplier: default_targeted_limit_multiplier(),\n            p95_latency_threshold_ms: default_reasoning_p95_threshold_ms(),\n            cache_ttl_seconds: default_reasoning_cache_ttl_seconds(),\n            cache_enabled: default_reasoning_cache_enabled(),\n            cache_max_entries: default_reasoning_cache_max_entries(),\n            circuit_breaker_enabled: default_circuit_breaker_enabled(),\n            circuit_breaker_failure_threshold_percent:\n                default_circuit_breaker_failure_threshold_percent(),\n            circuit_breaker_window_secs: default_circuit_breaker_window_secs(),\n            circuit_breaker_min_requests: default_circuit_breaker_min_requests(),\n            circuit_breaker_recovery_secs: default_circuit_breaker_recovery_secs(),\n            circuit_breaker_half_open_requests: default_circuit_breaker_half_open_requests(),\n            max_hop_depth: default_max_hop_depth(),\n            hop_relevance_threshold: default_hop_relevance_threshold(),\n            max_query_budget: default_max_query_budget(),\n        }\n    }\n}\n\nfn default_promotion_threshold() -> f32 {\n    0.8\n}\n\nfn default_decay_interval() -> u64 {\n    86400 // 24 hours\n}\n\nfn default_decay_rate() -> f32 {\n    0.05 // 5% decay\n}\n\nfn default_optimization_trigger_count() -> usize {\n    100\n}\n\nimpl Default for MemoryConfig {\n    fn default() -> Self {\n        Self {\n            promotion_threshold: default_promotion_threshold(),\n            decay_interval_secs: default_decay_interval(),\n            decay_rate: default_decay_rate(),\n            optimization_trigger_count: default_optimization_trigger_count(),\n            layer_summary_configs: std::collections::HashMap::new(),\n            reasoning: ReasoningConfig::default(),\n        }\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct JobConfig {\n    #[serde(default = \"default_lock_ttl_seconds\")]\n    #[validate(range(min = 60, max = 7200))]\n    pub lock_ttl_seconds: u64,\n\n    #[serde(default = \"default_job_timeout_seconds\")]\n    #[validate(range(min = 30, max = 3600))]\n    pub job_timeout_seconds: u64,\n\n    #[serde(default = \"default_deduplication_window_seconds\")]\n    #[validate(range(min = 0, max = 3600))]\n    pub deduplication_window_seconds: u64,\n\n    #[serde(default = \"default_checkpoint_interval\")]\n    #[validate(range(min = 10, max = 1000))]\n    pub checkpoint_interval: usize,\n\n    #[serde(default = \"default_graceful_shutdown_timeout_seconds\")]\n    #[validate(range(min = 5, max = 300))]\n    pub graceful_shutdown_timeout_seconds: u64,\n}\n\nfn default_lock_ttl_seconds() -> u64 {\n    2100 // 35 minutes\n}\n\nfn default_job_timeout_seconds() -> u64 {\n    1800 // 30 minutes\n}\n\nfn default_deduplication_window_seconds() -> u64 {\n    300 // 5 minutes\n}\n\nfn default_checkpoint_interval() -> usize {\n    100\n}\n\nfn default_graceful_shutdown_timeout_seconds() -> u64 {\n    30\n}\n\nimpl Default for JobConfig {\n    fn default() -> Self {\n        Self {\n            lock_ttl_seconds: default_lock_ttl_seconds(),\n            job_timeout_seconds: default_job_timeout_seconds(),\n            deduplication_window_seconds: default_deduplication_window_seconds(),\n            checkpoint_interval: default_checkpoint_interval(),\n            graceful_shutdown_timeout_seconds: default_graceful_shutdown_timeout_seconds(),\n        }\n    }\n}\n\nimpl JobConfig {\n    pub fn lock_key(&self, job_name: &str) -> String {\n        format!(\"job_lock:{}\", job_name)\n    }\n\n    pub fn should_checkpoint(&self, processed_count: usize) -> bool {\n        processed_count > 0 && processed_count % self.checkpoint_interval == 0\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_config_default() {\n        let config = Config::default();\n        assert_eq!(config.providers.postgres.host, \"localhost\");\n        assert_eq!(config.sync.enabled, true);\n        assert_eq!(config.tools.port, 8080);\n        assert_eq!(config.observability.logging_level, \"info\");\n    }\n\n    #[test]\n    fn test_provider_config_default() {\n        let providers = ProviderConfig::default();\n        assert_eq!(providers.postgres.port, 5432);\n        assert_eq!(providers.qdrant.port, 6333);\n        assert_eq!(providers.redis.port, 6379);\n    }\n\n    #[test]\n    fn test_sync_config_default() {\n        let sync = SyncConfig::default();\n        assert_eq!(sync.enabled, true);\n        assert_eq!(sync.sync_interval_seconds, 60);\n        assert_eq!(sync.conflict_resolution, \"prefer_knowledge\");\n    }\n\n    #[test]\n    fn test_postgres_config_validation() {\n        let mut postgres = PostgresConfig::default();\n        postgres.host = \"\".to_string();\n        assert!(postgres.validate().is_err());\n    }\n\n    #[test]\n    fn test_qdrant_config_validation() {\n        let mut qdrant = QdrantConfig::default();\n        qdrant.port = 0;\n        assert!(qdrant.validate().is_err());\n    }\n\n    #[test]\n    fn test_redis_config_validation() {\n        let mut redis = RedisConfig::default();\n        redis.db = 16;\n        assert!(redis.validate().is_err());\n    }\n\n    #[test]\n    fn test_sync_config_conflict_resolution_validation() {\n        let mut sync = SyncConfig::default();\n        sync.conflict_resolution = \"invalid\".to_string();\n        assert!(sync.validate().is_err());\n\n        sync.conflict_resolution = \"prefer_memory\".to_string();\n        assert!(sync.validate().is_ok());\n    }\n\n    #[test]\n    fn test_observability_config_logging_level_validation() {\n        let mut obs = ObservabilityConfig::default();\n        obs.logging_level = \"invalid\".to_string();\n        assert!(obs.validate().is_err());\n\n        obs.logging_level = \"debug\".to_string();\n        assert!(obs.validate().is_ok());\n    }\n\n    #[test]\n    fn test_config_serialization() {\n        let config = Config::default();\n        let json = serde_json::to_string(&config).unwrap();\n        let deserialized: Config = serde_json::from_str(&json).unwrap();\n        assert_eq!(\n            config.providers.postgres.host,\n            deserialized.providers.postgres.host\n        );\n    }\n\n    #[test]\n    fn test_deployment_config_default() {\n        let config = DeploymentConfig::default();\n        assert_eq!(config.mode, \"local\");\n        assert!(config.remote_url.is_none());\n        assert!(config.sync_enabled);\n    }\n\n    #[test]\n    fn test_deployment_config_is_local() {\n        let config = DeploymentConfig {\n            mode: \"local\".to_string(),\n            remote_url: None,\n            sync_enabled: true,\n        };\n        assert!(config.is_local());\n        assert!(!config.is_hybrid());\n        assert!(!config.is_remote());\n    }\n\n    #[test]\n    fn test_deployment_config_is_hybrid() {\n        let config = DeploymentConfig {\n            mode: \"hybrid\".to_string(),\n            remote_url: Some(\"http://localhost:8080\".to_string()),\n            sync_enabled: true,\n        };\n        assert!(!config.is_local());\n        assert!(config.is_hybrid());\n        assert!(!config.is_remote());\n    }\n\n    #[test]\n    fn test_deployment_config_is_remote() {\n        let config = DeploymentConfig {\n            mode: \"remote\".to_string(),\n            remote_url: Some(\"http://localhost:8080\".to_string()),\n            sync_enabled: false,\n        };\n        assert!(!config.is_local());\n        assert!(!config.is_hybrid());\n        assert!(config.is_remote());\n    }\n\n    #[test]\n    fn test_deployment_config_requires_remote_url() {\n        let local = DeploymentConfig {\n            mode: \"local\".to_string(),\n            ..Default::default()\n        };\n        let hybrid = DeploymentConfig {\n            mode: \"hybrid\".to_string(),\n            ..Default::default()\n        };\n        let remote = DeploymentConfig {\n            mode: \"remote\".to_string(),\n            ..Default::default()\n        };\n\n        assert!(!local.requires_remote_url());\n        assert!(hybrid.requires_remote_url());\n        assert!(remote.requires_remote_url());\n    }\n\n    #[test]\n    fn test_deployment_config_requires_local_engine() {\n        let local = DeploymentConfig {\n            mode: \"local\".to_string(),\n            ..Default::default()\n        };\n        let hybrid = DeploymentConfig {\n            mode: \"hybrid\".to_string(),\n            ..Default::default()\n        };\n        let remote = DeploymentConfig {\n            mode: \"remote\".to_string(),\n            ..Default::default()\n        };\n\n        assert!(local.requires_local_engine());\n        assert!(hybrid.requires_local_engine());\n        assert!(!remote.requires_local_engine());\n    }\n\n    #[test]\n    fn test_deployment_mode_validation() {\n        assert!(validate_deployment_mode(\"local\").is_ok());\n        assert!(validate_deployment_mode(\"hybrid\").is_ok());\n        assert!(validate_deployment_mode(\"remote\").is_ok());\n        assert!(validate_deployment_mode(\"invalid\").is_err());\n    }\n\n    #[test]\n    fn test_graph_config_default() {\n        let config = GraphConfig::default();\n        assert!(config.enabled);\n        assert_eq!(config.database_path, \":memory:\");\n        assert!(config.s3_bucket.is_none());\n        assert!(config.s3_prefix.is_none());\n        assert!(config.s3_endpoint.is_none());\n        assert_eq!(config.s3_region, \"us-east-1\");\n    }\n\n    #[test]\n    fn test_graph_config_validation() {\n        let mut config = GraphConfig::default();\n        config.database_path = \"\".to_string();\n        assert!(config.validate().is_err());\n\n        config.database_path = \"/path/to/graph.duckdb\".to_string();\n        assert!(config.validate().is_ok());\n    }\n\n    #[test]\n    fn test_provider_config_includes_graph() {\n        let providers = ProviderConfig::default();\n        assert!(providers.graph.enabled);\n        assert_eq!(providers.graph.database_path, \":memory:\");\n    }\n}\n","traces":[{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":116}},{"line":135,"address":[],"length":0,"stats":{"Line":232}},{"line":138,"address":[],"length":0,"stats":{"Line":116}},{"line":139,"address":[],"length":0,"stats":{"Line":116}},{"line":142,"address":[],"length":0,"stats":{"Line":4}},{"line":143,"address":[],"length":0,"stats":{"Line":4}},{"line":144,"address":[],"length":0,"stats":{"Line":12}},{"line":145,"address":[],"length":0,"stats":{"Line":1}},{"line":150,"address":[],"length":0,"stats":{"Line":116}},{"line":152,"address":[],"length":0,"stats":{"Line":232}},{"line":154,"address":[],"length":0,"stats":{"Line":116}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":6}},{"line":187,"address":[],"length":0,"stats":{"Line":6}},{"line":190,"address":[],"length":0,"stats":{"Line":8}},{"line":191,"address":[],"length":0,"stats":{"Line":8}},{"line":194,"address":[],"length":0,"stats":{"Line":5}},{"line":195,"address":[],"length":0,"stats":{"Line":5}},{"line":198,"address":[],"length":0,"stats":{"Line":3}},{"line":199,"address":[],"length":0,"stats":{"Line":10}},{"line":202,"address":[],"length":0,"stats":{"Line":3}},{"line":203,"address":[],"length":0,"stats":{"Line":10}},{"line":306,"address":[],"length":0,"stats":{"Line":38}},{"line":307,"address":[],"length":0,"stats":{"Line":76}},{"line":310,"address":[],"length":0,"stats":{"Line":40}},{"line":311,"address":[],"length":0,"stats":{"Line":40}},{"line":314,"address":[],"length":0,"stats":{"Line":40}},{"line":315,"address":[],"length":0,"stats":{"Line":80}},{"line":318,"address":[],"length":0,"stats":{"Line":40}},{"line":319,"address":[],"length":0,"stats":{"Line":80}},{"line":322,"address":[],"length":0,"stats":{"Line":40}},{"line":323,"address":[],"length":0,"stats":{"Line":80}},{"line":326,"address":[],"length":0,"stats":{"Line":42}},{"line":327,"address":[],"length":0,"stats":{"Line":42}},{"line":330,"address":[],"length":0,"stats":{"Line":42}},{"line":331,"address":[],"length":0,"stats":{"Line":42}},{"line":335,"address":[],"length":0,"stats":{"Line":38}},{"line":337,"address":[],"length":0,"stats":{"Line":76}},{"line":338,"address":[],"length":0,"stats":{"Line":76}},{"line":339,"address":[],"length":0,"stats":{"Line":76}},{"line":340,"address":[],"length":0,"stats":{"Line":76}},{"line":341,"address":[],"length":0,"stats":{"Line":76}},{"line":342,"address":[],"length":0,"stats":{"Line":38}},{"line":343,"address":[],"length":0,"stats":{"Line":38}},{"line":383,"address":[],"length":0,"stats":{"Line":36}},{"line":384,"address":[],"length":0,"stats":{"Line":72}},{"line":387,"address":[],"length":0,"stats":{"Line":36}},{"line":388,"address":[],"length":0,"stats":{"Line":36}},{"line":391,"address":[],"length":0,"stats":{"Line":36}},{"line":392,"address":[],"length":0,"stats":{"Line":72}},{"line":395,"address":[],"length":0,"stats":{"Line":38}},{"line":396,"address":[],"length":0,"stats":{"Line":38}},{"line":400,"address":[],"length":0,"stats":{"Line":36}},{"line":402,"address":[],"length":0,"stats":{"Line":72}},{"line":403,"address":[],"length":0,"stats":{"Line":72}},{"line":404,"address":[],"length":0,"stats":{"Line":36}},{"line":405,"address":[],"length":0,"stats":{"Line":36}},{"line":451,"address":[],"length":0,"stats":{"Line":34}},{"line":452,"address":[],"length":0,"stats":{"Line":68}},{"line":455,"address":[],"length":0,"stats":{"Line":34}},{"line":456,"address":[],"length":0,"stats":{"Line":34}},{"line":459,"address":[],"length":0,"stats":{"Line":36}},{"line":460,"address":[],"length":0,"stats":{"Line":36}},{"line":463,"address":[],"length":0,"stats":{"Line":36}},{"line":464,"address":[],"length":0,"stats":{"Line":36}},{"line":467,"address":[],"length":0,"stats":{"Line":36}},{"line":468,"address":[],"length":0,"stats":{"Line":36}},{"line":472,"address":[],"length":0,"stats":{"Line":34}},{"line":474,"address":[],"length":0,"stats":{"Line":68}},{"line":475,"address":[],"length":0,"stats":{"Line":68}},{"line":476,"address":[],"length":0,"stats":{"Line":68}},{"line":477,"address":[],"length":0,"stats":{"Line":34}},{"line":478,"address":[],"length":0,"stats":{"Line":34}},{"line":556,"address":[],"length":0,"stats":{"Line":34}},{"line":557,"address":[],"length":0,"stats":{"Line":34}},{"line":559,"address":[],"length":0,"stats":{"Line":34}},{"line":560,"address":[],"length":0,"stats":{"Line":34}},{"line":562,"address":[],"length":0,"stats":{"Line":34}},{"line":563,"address":[],"length":0,"stats":{"Line":34}},{"line":565,"address":[],"length":0,"stats":{"Line":34}},{"line":566,"address":[],"length":0,"stats":{"Line":34}},{"line":568,"address":[],"length":0,"stats":{"Line":34}},{"line":569,"address":[],"length":0,"stats":{"Line":34}},{"line":571,"address":[],"length":0,"stats":{"Line":34}},{"line":572,"address":[],"length":0,"stats":{"Line":34}},{"line":576,"address":[],"length":0,"stats":{"Line":34}},{"line":578,"address":[],"length":0,"stats":{"Line":68}},{"line":579,"address":[],"length":0,"stats":{"Line":68}},{"line":580,"address":[],"length":0,"stats":{"Line":68}},{"line":581,"address":[],"length":0,"stats":{"Line":68}},{"line":582,"address":[],"length":0,"stats":{"Line":34}},{"line":583,"address":[],"length":0,"stats":{"Line":34}},{"line":588,"address":[],"length":0,"stats":{"Line":32}},{"line":589,"address":[],"length":0,"stats":{"Line":32}},{"line":592,"address":[],"length":0,"stats":{"Line":32}},{"line":593,"address":[],"length":0,"stats":{"Line":64}},{"line":596,"address":[],"length":0,"stats":{"Line":32}},{"line":597,"address":[],"length":0,"stats":{"Line":64}},{"line":601,"address":[],"length":0,"stats":{"Line":32}},{"line":603,"address":[],"length":0,"stats":{"Line":64}},{"line":604,"address":[],"length":0,"stats":{"Line":64}},{"line":608,"address":[],"length":0,"stats":{"Line":32}},{"line":609,"address":[],"length":0,"stats":{"Line":32}},{"line":654,"address":[],"length":0,"stats":{"Line":26}},{"line":655,"address":[],"length":0,"stats":{"Line":26}},{"line":658,"address":[],"length":0,"stats":{"Line":26}},{"line":659,"address":[],"length":0,"stats":{"Line":26}},{"line":662,"address":[],"length":0,"stats":{"Line":28}},{"line":663,"address":[],"length":0,"stats":{"Line":28}},{"line":666,"address":[],"length":0,"stats":{"Line":28}},{"line":667,"address":[],"length":0,"stats":{"Line":28}},{"line":670,"address":[],"length":0,"stats":{"Line":28}},{"line":671,"address":[],"length":0,"stats":{"Line":56}},{"line":674,"address":[],"length":0,"stats":{"Line":2}},{"line":675,"address":[],"length":0,"stats":{"Line":2}},{"line":676,"address":[],"length":0,"stats":{"Line":6}},{"line":677,"address":[],"length":0,"stats":{"Line":1}},{"line":678,"address":[],"length":0,"stats":{"Line":1}},{"line":684,"address":[],"length":0,"stats":{"Line":26}},{"line":686,"address":[],"length":0,"stats":{"Line":52}},{"line":687,"address":[],"length":0,"stats":{"Line":52}},{"line":688,"address":[],"length":0,"stats":{"Line":52}},{"line":689,"address":[],"length":0,"stats":{"Line":26}},{"line":690,"address":[],"length":0,"stats":{"Line":26}},{"line":734,"address":[],"length":0,"stats":{"Line":34}},{"line":735,"address":[],"length":0,"stats":{"Line":34}},{"line":738,"address":[],"length":0,"stats":{"Line":36}},{"line":739,"address":[],"length":0,"stats":{"Line":72}},{"line":742,"address":[],"length":0,"stats":{"Line":34}},{"line":743,"address":[],"length":0,"stats":{"Line":34}},{"line":746,"address":[],"length":0,"stats":{"Line":36}},{"line":747,"address":[],"length":0,"stats":{"Line":36}},{"line":751,"address":[],"length":0,"stats":{"Line":34}},{"line":753,"address":[],"length":0,"stats":{"Line":68}},{"line":754,"address":[],"length":0,"stats":{"Line":68}},{"line":755,"address":[],"length":0,"stats":{"Line":68}},{"line":757,"address":[],"length":0,"stats":{"Line":34}},{"line":795,"address":[],"length":0,"stats":{"Line":25}},{"line":796,"address":[],"length":0,"stats":{"Line":25}},{"line":799,"address":[],"length":0,"stats":{"Line":25}},{"line":800,"address":[],"length":0,"stats":{"Line":25}},{"line":803,"address":[],"length":0,"stats":{"Line":23}},{"line":804,"address":[],"length":0,"stats":{"Line":46}},{"line":807,"address":[],"length":0,"stats":{"Line":25}},{"line":808,"address":[],"length":0,"stats":{"Line":25}},{"line":811,"address":[],"length":0,"stats":{"Line":2}},{"line":812,"address":[],"length":0,"stats":{"Line":2}},{"line":813,"address":[],"length":0,"stats":{"Line":8}},{"line":814,"address":[],"length":0,"stats":{"Line":1}},{"line":819,"address":[],"length":0,"stats":{"Line":23}},{"line":821,"address":[],"length":0,"stats":{"Line":46}},{"line":822,"address":[],"length":0,"stats":{"Line":46}},{"line":823,"address":[],"length":0,"stats":{"Line":23}},{"line":824,"address":[],"length":0,"stats":{"Line":23}},{"line":964,"address":[],"length":0,"stats":{"Line":212}},{"line":965,"address":[],"length":0,"stats":{"Line":212}},{"line":968,"address":[],"length":0,"stats":{"Line":212}},{"line":969,"address":[],"length":0,"stats":{"Line":212}},{"line":972,"address":[],"length":0,"stats":{"Line":212}},{"line":973,"address":[],"length":0,"stats":{"Line":212}},{"line":976,"address":[],"length":0,"stats":{"Line":212}},{"line":977,"address":[],"length":0,"stats":{"Line":212}},{"line":980,"address":[],"length":0,"stats":{"Line":212}},{"line":981,"address":[],"length":0,"stats":{"Line":212}},{"line":984,"address":[],"length":0,"stats":{"Line":212}},{"line":985,"address":[],"length":0,"stats":{"Line":212}},{"line":988,"address":[],"length":0,"stats":{"Line":212}},{"line":989,"address":[],"length":0,"stats":{"Line":212}},{"line":992,"address":[],"length":0,"stats":{"Line":212}},{"line":993,"address":[],"length":0,"stats":{"Line":212}},{"line":996,"address":[],"length":0,"stats":{"Line":212}},{"line":997,"address":[],"length":0,"stats":{"Line":212}},{"line":1000,"address":[],"length":0,"stats":{"Line":212}},{"line":1001,"address":[],"length":0,"stats":{"Line":212}},{"line":1004,"address":[],"length":0,"stats":{"Line":212}},{"line":1005,"address":[],"length":0,"stats":{"Line":212}},{"line":1008,"address":[],"length":0,"stats":{"Line":212}},{"line":1009,"address":[],"length":0,"stats":{"Line":212}},{"line":1012,"address":[],"length":0,"stats":{"Line":212}},{"line":1013,"address":[],"length":0,"stats":{"Line":212}},{"line":1016,"address":[],"length":0,"stats":{"Line":212}},{"line":1017,"address":[],"length":0,"stats":{"Line":212}},{"line":1020,"address":[],"length":0,"stats":{"Line":212}},{"line":1021,"address":[],"length":0,"stats":{"Line":212}},{"line":1024,"address":[],"length":0,"stats":{"Line":212}},{"line":1025,"address":[],"length":0,"stats":{"Line":212}},{"line":1028,"address":[],"length":0,"stats":{"Line":212}},{"line":1029,"address":[],"length":0,"stats":{"Line":212}},{"line":1032,"address":[],"length":0,"stats":{"Line":212}},{"line":1033,"address":[],"length":0,"stats":{"Line":212}},{"line":1036,"address":[],"length":0,"stats":{"Line":212}},{"line":1037,"address":[],"length":0,"stats":{"Line":212}},{"line":1041,"address":[],"length":0,"stats":{"Line":212}},{"line":1043,"address":[],"length":0,"stats":{"Line":424}},{"line":1044,"address":[],"length":0,"stats":{"Line":424}},{"line":1045,"address":[],"length":0,"stats":{"Line":424}},{"line":1046,"address":[],"length":0,"stats":{"Line":424}},{"line":1047,"address":[],"length":0,"stats":{"Line":424}},{"line":1048,"address":[],"length":0,"stats":{"Line":424}},{"line":1049,"address":[],"length":0,"stats":{"Line":424}},{"line":1050,"address":[],"length":0,"stats":{"Line":424}},{"line":1051,"address":[],"length":0,"stats":{"Line":424}},{"line":1052,"address":[],"length":0,"stats":{"Line":424}},{"line":1053,"address":[],"length":0,"stats":{"Line":424}},{"line":1054,"address":[],"length":0,"stats":{"Line":212}},{"line":1056,"address":[],"length":0,"stats":{"Line":424}},{"line":1057,"address":[],"length":0,"stats":{"Line":424}},{"line":1058,"address":[],"length":0,"stats":{"Line":424}},{"line":1059,"address":[],"length":0,"stats":{"Line":424}},{"line":1060,"address":[],"length":0,"stats":{"Line":424}},{"line":1061,"address":[],"length":0,"stats":{"Line":212}},{"line":1062,"address":[],"length":0,"stats":{"Line":212}},{"line":1067,"address":[],"length":0,"stats":{"Line":201}},{"line":1068,"address":[],"length":0,"stats":{"Line":201}},{"line":1071,"address":[],"length":0,"stats":{"Line":201}},{"line":1072,"address":[],"length":0,"stats":{"Line":201}},{"line":1075,"address":[],"length":0,"stats":{"Line":201}},{"line":1076,"address":[],"length":0,"stats":{"Line":201}},{"line":1079,"address":[],"length":0,"stats":{"Line":201}},{"line":1080,"address":[],"length":0,"stats":{"Line":201}},{"line":1084,"address":[],"length":0,"stats":{"Line":201}},{"line":1086,"address":[],"length":0,"stats":{"Line":402}},{"line":1087,"address":[],"length":0,"stats":{"Line":402}},{"line":1088,"address":[],"length":0,"stats":{"Line":402}},{"line":1089,"address":[],"length":0,"stats":{"Line":402}},{"line":1090,"address":[],"length":0,"stats":{"Line":201}},{"line":1091,"address":[],"length":0,"stats":{"Line":201}},{"line":1119,"address":[],"length":0,"stats":{"Line":44}},{"line":1120,"address":[],"length":0,"stats":{"Line":44}},{"line":1123,"address":[],"length":0,"stats":{"Line":44}},{"line":1124,"address":[],"length":0,"stats":{"Line":44}},{"line":1127,"address":[],"length":0,"stats":{"Line":44}},{"line":1128,"address":[],"length":0,"stats":{"Line":44}},{"line":1131,"address":[],"length":0,"stats":{"Line":44}},{"line":1132,"address":[],"length":0,"stats":{"Line":44}},{"line":1135,"address":[],"length":0,"stats":{"Line":44}},{"line":1136,"address":[],"length":0,"stats":{"Line":44}},{"line":1140,"address":[],"length":0,"stats":{"Line":44}},{"line":1142,"address":[],"length":0,"stats":{"Line":88}},{"line":1143,"address":[],"length":0,"stats":{"Line":88}},{"line":1144,"address":[],"length":0,"stats":{"Line":88}},{"line":1145,"address":[],"length":0,"stats":{"Line":44}},{"line":1146,"address":[],"length":0,"stats":{"Line":44}},{"line":1152,"address":[],"length":0,"stats":{"Line":0}},{"line":1153,"address":[],"length":0,"stats":{"Line":0}},{"line":1156,"address":[],"length":0,"stats":{"Line":0}},{"line":1157,"address":[],"length":0,"stats":{"Line":0}}],"covered":242,"coverable":270},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","ecosystem.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","episodic.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","file_loader.rs"],"content":"//! # Configuration File Loading\n//!\n//! Loads configuration from TOML or YAML files.\n//!\n//! Supports automatic format detection based on file extension.\n\nuse crate::config::Config;\nuse std::path::Path;\n\n/// Configuration file loading error.\n#[derive(Debug, thiserror::Error)]\npub enum ConfigFileError {\n    #[error(\"File not found: {0}\")]\n    FileNotFound(String),\n\n    #[error(\"IO error: {0}\")]\n    Io(#[from] std::io::Error),\n\n    #[error(\"Failed to parse TOML: {0}\")]\n    TomlParse(String),\n\n    #[error(\"Failed to parse YAML: {0}\")]\n    YamlParse(String),\n\n    #[error(\"Config file has no extension\")]\n    NoExtension,\n\n    #[error(\"Unsupported config file format: {0}\")]\n    UnsupportedFormat(String),\n}\n\n/// Load configuration from TOML file.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Loads complete configuration from a TOML format file.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::load_from_toml;\n/// use std::path::Path;\n///\n/// fn main() -> Result<(), Box<dyn std::error::Error>> {\n///     let config = load_from_toml(Path::new(\"config.toml\"))?;\n///     println!(\"PostgreSQL host: {}\", config.providers.postgres.host);\n///     Ok(())\n/// }\n/// ```\n///\n/// ## Error Handling\n/// Returns `ConfigFileError` for:\n/// - File not found\n/// - Invalid TOML syntax\n/// - Missing required fields\npub fn load_from_toml(path: &Path) -> Result<Config, ConfigFileError> {\n    let contents = std::fs::read_to_string(path)\n        .map_err(|_e| ConfigFileError::FileNotFound(path.display().to_string()))?;\n\n    let config: Config =\n        toml::from_str(&contents).map_err(|e| ConfigFileError::TomlParse(e.to_string()))?;\n\n    Ok(config)\n}\n\n/// Load configuration from YAML file.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Loads complete configuration from a YAML format file.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::load_from_yaml;\n/// use std::path::Path;\n///\n/// fn main() -> Result<(), Box<dyn std::error::Error>> {\n///     let config = load_from_yaml(Path::new(\"config.yaml\"))?;\n///     println!(\"PostgreSQL host: {}\", config.providers.postgres.host);\n///     Ok(())\n/// }\n/// ```\n///\n/// ## Error Handling\n/// Returns `ConfigFileError` for:\n/// - File not found\n/// - Invalid YAML syntax\n/// - Missing required fields\npub fn load_from_yaml(path: &Path) -> Result<Config, ConfigFileError> {\n    let contents = std::fs::read_to_string(path)\n        .map_err(|_e| ConfigFileError::FileNotFound(path.display().to_string()))?;\n\n    let config: Config =\n        serde_yaml::from_str(&contents).map_err(|e| ConfigFileError::YamlParse(e.to_string()))?;\n\n    Ok(config)\n}\n\n/// Load configuration from file with auto-detection.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Loads configuration from file, automatically detecting format from\n/// extension.\n///\n/// ## Supported Formats\n/// - `.toml`: TOML format\n/// - `.yaml`: YAML format\n/// - `.yml`: YAML format\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::load_from_file;\n/// use std::path::Path;\n///\n/// fn main() -> Result<(), Box<dyn std::error::Error>> {\n///     let config = load_from_file(Path::new(\"config.yaml\"))?;\n///     Ok(())\n/// }\n/// ```\n///\n/// ## Error Handling\n/// Returns `ConfigFileError` for:\n/// - File not found\n/// - Invalid file extension\n/// - Parse errors for detected format\npub fn load_from_file(path: &Path) -> Result<Config, ConfigFileError> {\n    let extension = path\n        .extension()\n        .and_then(|s| s.to_str())\n        .ok_or(ConfigFileError::NoExtension)?;\n\n    match extension.to_lowercase().as_str() {\n        \"toml\" => load_from_toml(path),\n        \"yaml\" | \"yml\" => load_from_yaml(path),\n        other => Err(ConfigFileError::UnsupportedFormat(other.to_string())),\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::fs;\n    use tempfile::NamedTempFile;\n\n    #[test]\n    fn test_load_from_toml() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"toml\");\n\n        let toml_content = r#\"\n[providers.postgres]\nhost = \"testhost\"\nport = 5433\ndatabase = \"testdb\"\nusername = \"testuser\"\npassword = \"testpass\"\n\n[providers.qdrant]\nhost = \"qdranthost\"\nport = 7333\ncollection = \"test_collection\"\n\n[providers.redis]\nhost = \"redishost\"\nport = 6380\n\n[sync]\nenabled = false\nsync_interval_seconds = 120\n\n[tools]\nenabled = false\nport = 9090\n\n[observability]\nlogging_level = \"debug\"\n\"#;\n        fs::write(&path, toml_content).unwrap();\n\n        let config = load_from_toml(&path).unwrap();\n        assert_eq!(config.providers.postgres.host, \"testhost\");\n        assert_eq!(config.providers.postgres.port, 5433);\n        assert_eq!(config.providers.postgres.database, \"testdb\");\n        assert_eq!(config.providers.qdrant.host, \"qdranthost\");\n        assert_eq!(config.providers.qdrant.port, 7333);\n        assert_eq!(config.providers.redis.host, \"redishost\");\n        assert_eq!(config.sync.enabled, false);\n        assert_eq!(config.sync.sync_interval_seconds, 120);\n        assert_eq!(config.tools.port, 9090);\n        assert_eq!(config.observability.logging_level, \"debug\");\n    }\n\n    #[test]\n    fn test_load_from_yaml() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"yaml\");\n\n        let yaml_content = r#\"\nproviders:\n  postgres:\n    host: testhost\n    port: 5433\n    database: testdb\n    username: testuser\n    password: testpass\n  qdrant:\n    host: qdranthost\n    port: 7333\n    collection: test_collection\n  redis:\n    host: redishost\n    port: 6380\n\nsync:\n  enabled: false\n  sync_interval_seconds: 120\n\ntools:\n  enabled: false\n  port: 9090\n\nobservability:\n  logging_level: debug\n\"#;\n        fs::write(&path, yaml_content).unwrap();\n\n        let config = load_from_yaml(&path).unwrap();\n        assert_eq!(config.providers.postgres.host, \"testhost\");\n        assert_eq!(config.providers.postgres.port, 5433);\n        assert_eq!(config.providers.qdrant.host, \"qdranthost\");\n        assert_eq!(config.sync.enabled, false);\n        assert_eq!(config.tools.port, 9090);\n        assert_eq!(config.observability.logging_level, \"debug\");\n    }\n\n    #[test]\n    fn test_load_from_file_unsupported() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"json\");\n        fs::write(&path, \"{}\").unwrap();\n\n        let result = load_from_file(&path);\n        assert!(matches!(result, Err(ConfigFileError::UnsupportedFormat(_))));\n    }\n\n    #[test]\n    fn test_load_from_file_no_extension() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"\");\n        fs::write(&path, \"\").unwrap();\n\n        let result = load_from_file(&path);\n        assert!(matches!(result, Err(ConfigFileError::NoExtension)));\n    }\n\n    #[test]\n    fn test_load_from_file_auto_detect_toml() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"toml\");\n        let toml_content = r#\"\n[providers.postgres]\nhost = \"autohost\"\n\"#;\n        fs::write(&path, toml_content).unwrap();\n\n        let config = load_from_file(&path).unwrap();\n        assert_eq!(config.providers.postgres.host, \"autohost\");\n    }\n\n    #[test]\n    fn test_load_from_file_auto_detect_yaml() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"yaml\");\n        let yaml_content = r#\"\nproviders:\n  postgres:\n    host: autohost\n\"#;\n        fs::write(&path, yaml_content).unwrap();\n\n        let config = load_from_file(&path).unwrap();\n        assert_eq!(config.providers.postgres.host, \"autohost\");\n    }\n\n    #[test]\n    fn test_load_from_toml_invalid() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"toml\");\n        let invalid_toml = r#\"\n[invalid\n\"#;\n        fs::write(&path, invalid_toml).unwrap();\n\n        let result = load_from_toml(&path);\n        assert!(matches!(result, Err(ConfigFileError::TomlParse(_))));\n    }\n\n    #[test]\n    fn test_load_from_yaml_invalid() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"yaml\");\n        let invalid_yaml = r#\"\ninvalid: [unmatched\n\"#;\n        fs::write(&path, invalid_yaml).unwrap();\n\n        let result = load_from_yaml(&path);\n        assert!(matches!(result, Err(ConfigFileError::YamlParse(_))));\n    }\n\n    #[test]\n    fn test_load_from_toml_not_found() {\n        let path = Path::new(\"/nonexistent/path/config.toml\");\n        let result = load_from_toml(path);\n        assert!(matches!(result, Err(ConfigFileError::FileNotFound(_))));\n    }\n}\n","traces":[{"line":56,"address":[],"length":0,"stats":{"Line":4}},{"line":57,"address":[],"length":0,"stats":{"Line":11}},{"line":58,"address":[],"length":0,"stats":{"Line":7}},{"line":60,"address":[],"length":0,"stats":{"Line":4}},{"line":61,"address":[],"length":0,"stats":{"Line":12}},{"line":63,"address":[],"length":0,"stats":{"Line":2}},{"line":90,"address":[],"length":0,"stats":{"Line":3}},{"line":91,"address":[],"length":0,"stats":{"Line":9}},{"line":92,"address":[],"length":0,"stats":{"Line":3}},{"line":94,"address":[],"length":0,"stats":{"Line":4}},{"line":95,"address":[],"length":0,"stats":{"Line":12}},{"line":97,"address":[],"length":0,"stats":{"Line":2}},{"line":129,"address":[],"length":0,"stats":{"Line":4}},{"line":130,"address":[],"length":0,"stats":{"Line":7}},{"line":132,"address":[],"length":0,"stats":{"Line":10}},{"line":133,"address":[],"length":0,"stats":{"Line":9}},{"line":135,"address":[],"length":0,"stats":{"Line":3}},{"line":136,"address":[],"length":0,"stats":{"Line":5}},{"line":137,"address":[],"length":0,"stats":{"Line":5}},{"line":138,"address":[],"length":0,"stats":{"Line":2}}],"covered":20,"coverable":20},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","governance.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","hot_reload.rs"],"content":"//! # Configuration Hot Reload\n//!\n//! Watches configuration files for changes and reloads configuration\n//! automatically.\n\nuse notify::{EventKind, RecommendedWatcher, RecursiveMode, Watcher};\nuse std::path::{Path, PathBuf};\nuse tracing::debug;\nuse tracing::{error, info, warn};\n\n/// Configuration reload event.\n#[derive(Debug, Clone, PartialEq)]\npub enum ConfigReloadEvent {\n    Ready,\n\n    /// Configuration file changed\n    Changed(PathBuf),\n\n    /// Configuration file was removed\n    Removed(PathBuf),\n\n    /// Configuration file was created\n    Created(PathBuf),\n\n    /// Configuration reload error\n    Error {\n        path: PathBuf,\n        error: String,\n    },\n}\n\n/// Watch a configuration file for changes and emit reload events.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Monitors configuration file for changes and automatically reloads\n/// configuration. Uses `notify` crate for cross-platform file system watching.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::{hot_reload::ConfigReloadEvent, watch_config};\n/// use tokio::signal;\n///\n/// #[tokio::main]\n/// async fn main() -> Result<(), Box<dyn std::error::Error>> {\n///     let config_path = std::path::Path::new(\"config.toml\");\n///     let (_tx, mut rx) = watch_config(&config_path).await?;\n///\n///     loop {\n///         tokio::select! {\n///             _ = signal::ctrl_c() => break,\n///             Some(event) = rx.recv() => {\n///                 match event {\n///                     ConfigReloadEvent::Changed(path) => {\n///                         println!(\"Config changed: {:?}\", path);\n///                     }\n///                     ConfigReloadEvent::Error { path, error } => {\n///                         eprintln!(\"Error reloading {:?}: {}\", path, error);\n///                     }\n///                     _ => {}\n///                 }\n///             }\n///         }\n///     }\n///\n///     Ok(())\n/// }\n/// ```\n///\n/// ## Event Types\n/// - `Changed`: File content modified\n/// - `Created`: New file created\n/// - `Removed`: File deleted\n/// - `Error`: Failed to reload configuration\n///\n/// ## Performance\n/// Uses debouncing to avoid multiple reload events for single file change.\npub async fn watch_config(\n    config_path: &Path,\n) -> Result<\n    (\n        tokio::sync::mpsc::Sender<ConfigReloadEvent>,\n        tokio::sync::mpsc::Receiver<ConfigReloadEvent>,\n    ),\n    Box<dyn std::error::Error>,\n> {\n    let config_path = config_path.to_path_buf();\n\n    if !config_path.exists() {\n        return Err(Box::new(std::io::Error::new(\n            std::io::ErrorKind::NotFound,\n            format!(\"Config file not found: {:?}\", config_path),\n        )));\n    }\n\n    let (tx, rx) = tokio::sync::mpsc::channel(100);\n    let tx_task = tx.clone();\n    let path_task = config_path.clone();\n\n    tokio::spawn(async move {\n        let (event_tx, mut event_rx) = tokio::sync::mpsc::channel(100);\n        let mut watcher = match RecommendedWatcher::new(\n            move |res| {\n                let _ = event_tx.blocking_send(res);\n            },\n            notify::Config::default(),\n        ) {\n            Ok(w) => w,\n            Err(e) => {\n                let error_msg = format!(\"Failed to create file watcher: {}\", e);\n                error!(\"{}\", error_msg);\n\n                let _ = tx_task\n                    .send(ConfigReloadEvent::Error {\n                        path: path_task,\n                        error: error_msg,\n                    })\n                    .await;\n\n                return;\n            }\n        };\n\n        if let Err(e) = watcher.watch(&config_path, RecursiveMode::NonRecursive) {\n            let error_msg = format!(\"Failed to watch config file: {}\", e);\n            error!(\"{}\", error_msg);\n\n            let _ = tx_task\n                .send(ConfigReloadEvent::Error {\n                    path: path_task,\n                    error: error_msg,\n                })\n                .await;\n\n            return;\n        }\n\n        info!(\"Watching config file: {:?}\", config_path);\n\n        let _ = tx_task.send(ConfigReloadEvent::Ready).await;\n\n        loop {\n            tokio::select! {\n                _ = tx_task.closed() => {\n                    debug!(\"Receiver dropped, stopping watcher for {:?}\", config_path);\n                    break;\n                }\n                event_result = event_rx.recv() => {\n                    let Some(event_result) = event_result else {\n                        break;\n                    };\n\n                    match event_result {\n                        Ok(event) => {\n                            if !event.paths.is_empty() {\n                                let path = event.paths[0].clone();\n                                let reload_event = match event.kind {\n                                    EventKind::Create(_) | EventKind::Modify(_) => {\n                                        info!(\"Config file updated: {:?}\", path);\n                                        ConfigReloadEvent::Changed(path)\n                                    }\n                                    EventKind::Remove(_) => {\n                                        warn!(\"Config file removed: {:?}\", path);\n                                        ConfigReloadEvent::Removed(path)\n                                    }\n                                    _ => {\n                                        debug!(\"Ignoring event: {:?}\", event.kind);\n                                        continue;\n                                    }\n                                };\n\n                                if let Err(e) = tx_task.send(reload_event).await {\n                                    error!(\"Failed to send config reload event: {}\", e);\n                                    break;\n                                }\n                            }\n                        }\n                        Err(e) => {\n                            warn!(\"Watch error: {}\", e);\n                        }\n                    }\n                }\n            }\n        }\n    });\n\n    Ok((tx, rx))\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::fs;\n    use tempfile::NamedTempFile;\n    use tokio::time::Duration;\n\n    #[test]\n    fn test_config_reload_event_created() {\n        let path = PathBuf::from(\"/test/config.toml\");\n        let event = ConfigReloadEvent::Created(path.clone());\n        assert!(matches!(event, ConfigReloadEvent::Created(_)));\n        assert_eq!(event, ConfigReloadEvent::Created(path));\n    }\n\n    #[test]\n    fn test_config_reload_event_removed() {\n        let path = PathBuf::from(\"/test/config.toml\");\n        let event = ConfigReloadEvent::Removed(path.clone());\n        assert!(matches!(event, ConfigReloadEvent::Removed(_)));\n        assert_eq!(event, ConfigReloadEvent::Removed(path));\n    }\n\n    #[test]\n    fn test_config_reload_event_changed() {\n        let path = PathBuf::from(\"/test/config.toml\");\n        let event = ConfigReloadEvent::Changed(path.clone());\n        assert!(matches!(event, ConfigReloadEvent::Changed(_)));\n        assert_eq!(event, ConfigReloadEvent::Changed(path));\n    }\n\n    #[test]\n    fn test_config_reload_event_error() {\n        let path = PathBuf::from(\"/test/config.toml\");\n        let event = ConfigReloadEvent::Error {\n            path: path.clone(),\n            error: \"Test error\".to_string(),\n        };\n        assert!(matches!(event, ConfigReloadEvent::Error { .. }));\n        assert_eq!(\n            event,\n            ConfigReloadEvent::Error {\n                path,\n                error: \"Test error\".to_string()\n            }\n        );\n    }\n\n    #[tokio::test]\n    async fn test_tokio_config_reload_event_created() {\n        let path = PathBuf::from(\"/test/config.toml\");\n        let event = ConfigReloadEvent::Created(path.clone());\n        assert!(matches!(event, ConfigReloadEvent::Created(_)));\n        assert_eq!(event, ConfigReloadEvent::Created(path));\n    }\n\n    #[tokio::test]\n    async fn test_tokio_config_reload_event_removed() {\n        let path = PathBuf::from(\"/test/config.toml\");\n        let event = ConfigReloadEvent::Removed(path.clone());\n        assert!(matches!(event, ConfigReloadEvent::Removed(_)));\n        assert_eq!(event, ConfigReloadEvent::Removed(path));\n    }\n\n    #[tokio::test]\n    async fn test_tokio_config_reload_event_error() {\n        let path = PathBuf::from(\"/test/config.toml\");\n        let event = ConfigReloadEvent::Error {\n            path: path.clone(),\n            error: \"Test error\".to_string(),\n        };\n        assert!(matches!(event, ConfigReloadEvent::Error { .. }));\n        assert_eq!(\n            event,\n            ConfigReloadEvent::Error {\n                path,\n                error: \"Test error\".to_string()\n            }\n        );\n    }\n\n    #[tokio::test]\n    async fn test_watch_config_emits_events() {\n        let temp_file = NamedTempFile::new().unwrap();\n        let config_content = r#\"\n[providers.postgres]\nhost = \"testhost\"\n\"#;\n        fs::write(temp_file.path(), config_content).unwrap();\n\n        let (_tx, mut rx) = watch_config(temp_file.path()).await.unwrap();\n\n        let ready_event = tokio::time::timeout(Duration::from_secs(5), rx.recv())\n            .await\n            .expect(\"Timeout waiting for Ready event\")\n            .expect(\"No event received\");\n        assert_eq!(ready_event, ConfigReloadEvent::Ready);\n\n        fs::write(temp_file.path(), \"[providers.postgres]\\nhost = \\\"updated\\\"\").unwrap();\n\n        let event = tokio::time::timeout(Duration::from_secs(5), rx.recv())\n            .await\n            .expect(\"Timeout waiting for config change event\")\n            .expect(\"No event received\");\n\n        match event {\n            ConfigReloadEvent::Changed(path) => {\n                assert_eq!(\n                    path.canonicalize().unwrap(),\n                    temp_file.path().canonicalize().unwrap()\n                );\n            }\n            _ => panic!(\"Expected Changed event, got {:?}\", event),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_watch_config_handles_create() {\n        let temp_dir = tempfile::tempdir().unwrap();\n        let config_path = temp_dir.path().join(\"config.toml\");\n\n        fs::write(&config_path, \"initial\").unwrap();\n\n        let (_tx, mut rx) = watch_config(&config_path).await.unwrap();\n\n        let ready_event = tokio::time::timeout(Duration::from_secs(5), rx.recv())\n            .await\n            .expect(\"Timeout waiting for Ready event\")\n            .expect(\"No event received\");\n        assert_eq!(ready_event, ConfigReloadEvent::Ready);\n\n        fs::write(&config_path, \"updated\").unwrap();\n\n        let event = tokio::time::timeout(Duration::from_secs(5), rx.recv())\n            .await\n            .expect(\"Timeout waiting for config change event\")\n            .expect(\"No event received\");\n\n        match event {\n            ConfigReloadEvent::Changed(path) => {\n                assert_eq!(\n                    path.canonicalize().unwrap(),\n                    config_path.canonicalize().unwrap()\n                );\n            }\n            _ => panic!(\"Expected Changed event, got {:?}\", event),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_watch_config_nonexistent_file() {\n        let temp_dir = tempfile::tempdir().unwrap();\n        let config_path = temp_dir.path().join(\"nonexistent.toml\");\n\n        let result = watch_config(&config_path).await;\n        assert!(result.is_err());\n\n        let error = result.unwrap_err();\n        let error_str = error.to_string();\n        assert!(error_str.contains(\"not found\") || error_str.contains(\"NotFound\"));\n    }\n\n    #[tokio::test]\n    async fn test_watch_config_error_handling() {\n        let temp_file = NamedTempFile::new().unwrap();\n        fs::write(temp_file.path(), \"test\").unwrap();\n\n        let (_tx, mut rx) = watch_config(temp_file.path()).await.unwrap();\n\n        let _ = tokio::time::timeout(Duration::from_secs(5), rx.recv())\n            .await\n            .expect(\"Timeout waiting for Ready event\");\n\n        drop(rx);\n        tokio::time::sleep(Duration::from_millis(100)).await;\n    }\n\n    #[tokio::test]\n    async fn test_watch_config_removed_file() {\n        let temp_dir = tempfile::tempdir().unwrap();\n        let config_path = temp_dir.path().join(\"config.toml\");\n\n        fs::write(&config_path, \"initial\").unwrap();\n\n        // Store canonical path before deletion since canonicalize() fails on deleted\n        // files\n        let canonical_config_path = config_path.canonicalize().unwrap();\n\n        let (_tx, mut rx) = watch_config(&config_path).await.unwrap();\n\n        let ready_event = tokio::time::timeout(Duration::from_secs(5), rx.recv())\n            .await\n            .expect(\"Timeout waiting for Ready event\")\n            .expect(\"No event received\");\n        assert_eq!(ready_event, ConfigReloadEvent::Ready);\n\n        fs::remove_file(&config_path).unwrap();\n\n        let event = tokio::time::timeout(Duration::from_secs(5), rx.recv()).await;\n\n        if let Ok(Some(event)) = event {\n            match event {\n                ConfigReloadEvent::Removed(path) => {\n                    // Compare with pre-deletion canonical path or file name\n                    // The watcher may return the original path or canonicalized path\n                    let matches = path == canonical_config_path\n                        || path == config_path\n                        || path.file_name() == config_path.file_name();\n                    assert!(\n                        matches,\n                        \"Path {:?} should match config path {:?}\",\n                        path, config_path\n                    );\n                }\n                ConfigReloadEvent::Error { path, error } => {\n                    // For error events, compare file names since path may not be canonicalizable\n                    let matches = path == canonical_config_path\n                        || path == config_path\n                        || path.file_name() == config_path.file_name();\n                    assert!(\n                        matches,\n                        \"Error path {:?} should match config path {:?}\",\n                        path, config_path\n                    );\n                    assert!(!error.is_empty());\n                }\n                _ => {}\n            }\n        }\n    }\n\n    #[test]\n    fn test_config_reload_event_ready() {\n        let event = ConfigReloadEvent::Ready;\n        assert!(matches!(event, ConfigReloadEvent::Ready));\n        assert_eq!(event, ConfigReloadEvent::Ready);\n    }\n\n    #[test]\n    fn test_config_reload_event_partial_eq() {\n        let path1 = PathBuf::from(\"/test/config.toml\");\n        let path2 = PathBuf::from(\"/test/config.toml\");\n        let path3 = PathBuf::from(\"/other/config.toml\");\n\n        // Test equality\n        assert_eq!(\n            ConfigReloadEvent::Changed(path1.clone()),\n            ConfigReloadEvent::Changed(path2.clone())\n        );\n\n        assert_eq!(\n            ConfigReloadEvent::Created(path1.clone()),\n            ConfigReloadEvent::Created(path2.clone())\n        );\n\n        assert_eq!(\n            ConfigReloadEvent::Removed(path1.clone()),\n            ConfigReloadEvent::Removed(path2.clone())\n        );\n\n        assert_eq!(\n            ConfigReloadEvent::Error {\n                path: path1.clone(),\n                error: \"test\".to_string()\n            },\n            ConfigReloadEvent::Error {\n                path: path2.clone(),\n                error: \"test\".to_string()\n            }\n        );\n\n        // Test inequality\n        assert_ne!(\n            ConfigReloadEvent::Changed(path1.clone()),\n            ConfigReloadEvent::Changed(path3.clone())\n        );\n\n        assert_ne!(\n            ConfigReloadEvent::Changed(path1.clone()),\n            ConfigReloadEvent::Created(path1.clone())\n        );\n\n        assert_ne!(\n            ConfigReloadEvent::Error {\n                path: path1.clone(),\n                error: \"error1\".to_string()\n            },\n            ConfigReloadEvent::Error {\n                path: path1.clone(),\n                error: \"error2\".to_string()\n            }\n        );\n    }\n\n    #[test]\n    fn test_config_reload_event_clone() {\n        let path = PathBuf::from(\"/test/config.toml\");\n\n        let event1 = ConfigReloadEvent::Ready;\n        let cloned1 = event1.clone();\n        assert_eq!(event1, cloned1);\n\n        let event2 = ConfigReloadEvent::Changed(path.clone());\n        let cloned2 = event2.clone();\n        assert_eq!(event2, cloned2);\n\n        let event3 = ConfigReloadEvent::Created(path.clone());\n        let cloned3 = event3.clone();\n        assert_eq!(event3, cloned3);\n\n        let event4 = ConfigReloadEvent::Removed(path.clone());\n        let cloned4 = event4.clone();\n        assert_eq!(event4, cloned4);\n\n        let event5 = ConfigReloadEvent::Error {\n            path: path.clone(),\n            error: \"test error\".to_string(),\n        };\n        let cloned5 = event5.clone();\n        assert_eq!(event5, cloned5);\n    }\n\n    #[test]\n    fn test_config_reload_event_debug() {\n        let path = PathBuf::from(\"/test/config.toml\");\n\n        let debug_ready = format!(\"{:?}\", ConfigReloadEvent::Ready);\n        assert!(debug_ready.contains(\"Ready\"));\n\n        let debug_changed = format!(\"{:?}\", ConfigReloadEvent::Changed(path.clone()));\n        assert!(debug_changed.contains(\"Changed\"));\n        assert!(debug_changed.contains(\"config.toml\"));\n\n        let debug_created = format!(\"{:?}\", ConfigReloadEvent::Created(path.clone()));\n        assert!(debug_created.contains(\"Created\"));\n\n        let debug_removed = format!(\"{:?}\", ConfigReloadEvent::Removed(path.clone()));\n        assert!(debug_removed.contains(\"Removed\"));\n\n        let debug_error = format!(\n            \"{:?}\",\n            ConfigReloadEvent::Error {\n                path: path.clone(),\n                error: \"test error message\".to_string()\n            }\n        );\n        assert!(debug_error.contains(\"Error\"));\n        assert!(debug_error.contains(\"test error message\"));\n    }\n\n    #[tokio::test]\n    async fn test_watch_config_receiver_drop_cleanup() {\n        let temp_file = NamedTempFile::new().unwrap();\n        fs::write(temp_file.path(), \"initial content\").unwrap();\n\n        let (_tx, rx) = watch_config(temp_file.path()).await.unwrap();\n\n        drop(rx);\n\n        tokio::time::sleep(Duration::from_millis(200)).await;\n    }\n\n    #[tokio::test]\n    async fn test_watch_config_multiple_rapid_changes() {\n        let temp_file = NamedTempFile::new().unwrap();\n        fs::write(temp_file.path(), \"v1\").unwrap();\n\n        let (_tx, mut rx) = watch_config(temp_file.path()).await.unwrap();\n\n        let ready = tokio::time::timeout(Duration::from_secs(5), rx.recv())\n            .await\n            .expect(\"Timeout\")\n            .expect(\"No event\");\n        assert_eq!(ready, ConfigReloadEvent::Ready);\n\n        for i in 2..=5 {\n            fs::write(temp_file.path(), format!(\"v{}\", i)).unwrap();\n            tokio::time::sleep(Duration::from_millis(50)).await;\n        }\n\n        let mut change_count = 0;\n        while let Ok(Some(event)) =\n            tokio::time::timeout(Duration::from_millis(500), rx.recv()).await\n        {\n            if matches!(event, ConfigReloadEvent::Changed(_)) {\n                change_count += 1;\n            }\n        }\n\n        assert!(\n            change_count >= 1,\n            \"Should detect at least one change, got {}\",\n            change_count\n        );\n    }\n}\n","traces":[{"line":79,"address":[],"length":0,"stats":{"Line":7}},{"line":88,"address":[],"length":0,"stats":{"Line":21}},{"line":90,"address":[],"length":0,"stats":{"Line":7}},{"line":91,"address":[],"length":0,"stats":{"Line":3}},{"line":92,"address":[],"length":0,"stats":{"Line":2}},{"line":93,"address":[],"length":0,"stats":{"Line":1}},{"line":97,"address":[],"length":0,"stats":{"Line":18}},{"line":98,"address":[],"length":0,"stats":{"Line":18}},{"line":99,"address":[],"length":0,"stats":{"Line":18}},{"line":101,"address":[],"length":0,"stats":{"Line":12}},{"line":102,"address":[],"length":0,"stats":{"Line":18}},{"line":103,"address":[],"length":0,"stats":{"Line":12}},{"line":104,"address":[],"length":0,"stats":{"Line":28}},{"line":105,"address":[],"length":0,"stats":{"Line":56}},{"line":107,"address":[],"length":0,"stats":{"Line":6}},{"line":109,"address":[],"length":0,"stats":{"Line":12}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":18}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":6}},{"line":141,"address":[],"length":0,"stats":{"Line":24}},{"line":144,"address":[],"length":0,"stats":{"Line":31}},{"line":145,"address":[],"length":0,"stats":{"Line":62}},{"line":146,"address":[],"length":0,"stats":{"Line":2}},{"line":147,"address":[],"length":0,"stats":{"Line":2}},{"line":149,"address":[],"length":0,"stats":{"Line":87}},{"line":150,"address":[],"length":0,"stats":{"Line":50}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":25}},{"line":155,"address":[],"length":0,"stats":{"Line":25}},{"line":156,"address":[],"length":0,"stats":{"Line":25}},{"line":157,"address":[],"length":0,"stats":{"Line":75}},{"line":158,"address":[],"length":0,"stats":{"Line":50}},{"line":160,"address":[],"length":0,"stats":{"Line":24}},{"line":161,"address":[],"length":0,"stats":{"Line":24}},{"line":164,"address":[],"length":0,"stats":{"Line":1}},{"line":165,"address":[],"length":0,"stats":{"Line":1}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":100}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":6}}],"covered":36,"coverable":60},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","lib.rs"],"content":"//! # Configuration System\n//!\n//! Centralized configuration management for the Memory-Knowledge system.\n//!\n//! This crate provides:\n//! - Configuration structures for all system components\n//! - Environment variable loading (12-factor app principles)\n//! - Configuration file loading (TOML/YAML)\n//! - Configuration precedence (CLI > env > file > defaults)\n//! - Configuration validation\n//! - Hot reload functionality\n//!\n//! # Best Practices\n//!\n//! - Uses `validator` crate for input validation\n//! - Follows 12-factor app configuration principles\n//! - Provides clear error messages for invalid configuration\n//! - Thread-safe configuration access\n\npub mod cca;\npub mod config;\npub mod file_loader;\npub mod hot_reload;\npub mod loader;\npub mod precedence;\n\npub use cca::{\n    CcaConfig, ContextArchitectConfig, HindsightConfig, MetaAgentConfig, NoteTakingConfig,\n};\npub use config::{\n    Config, DeploymentConfig, GraphConfig, MemoryConfig, ObservabilityConfig, ProviderConfig,\n    ReasoningConfig, SyncConfig, ToolConfig,\n};\npub use file_loader::{load_from_file, load_from_toml, load_from_yaml};\npub use hot_reload::watch_config;\npub use loader::load_from_env;\npub use precedence::merge_configs;\npub use validator::Validate;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","loader.rs"],"content":"//! # Environment Variable Loader\n//!\n//! Loads configuration from environment variables following 12-factor app\n//! principles.\n//!\n//! # Naming Convention\n//! - `MK_*`: Memory-related settings\n//! - `KK_*`: Knowledge-related settings\n//! - `SY_*`: Sync-related settings\n//! - `TL_*`: Tool-related settings\n//! - `PG_*`: PostgreSQL settings\n//! - `QD_*`: Qdrant settings\n//! - `RD_*`: Redis settings\n//! - `OB_*`: Observability settings\n\nuse crate::config::{\n    Config, ContentionAlertConfig, GraphConfig, MemoryConfig, ObservabilityConfig, PostgresConfig,\n    ProviderConfig, QdrantConfig, ReasoningConfig, RedisConfig, SyncConfig, ToolConfig,\n};\nuse std::env;\n\n/// Load configuration from environment variables.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Loads configuration from environment variables following 12-factor app\n/// principles. Environment variables override default values but can be\n/// overridden by CLI arguments.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::load_from_env;\n///\n/// fn main() -> Result<(), Box<dyn std::error::Error>> {\n///     let config = load_from_env()?;\n///     println!(\"PostgreSQL host: {}\", config.providers.postgres.host);\n///     Ok(())\n/// }\n/// ```\n///\n/// ## Environment Variables\n/// ### General Settings\n/// - `MK_LOG_LEVEL`: Logging level (trace/debug/info/warn/error)\n///\n/// ### PostgreSQL Settings (`PG_*`)\n/// - `PG_HOST`: Database host (default: \"localhost\")\n/// - `PG_PORT`: Database port (default: 5432)\n/// - `PG_DATABASE`: Database name (default: \"memory_knowledge\")\n/// - `PG_USERNAME`: Database user (default: \"postgres\")\n/// - `PG_PASSWORD`: Database password (default: \"\")\n/// - `PG_POOL_SIZE`: Connection pool size (default: 10)\n/// - `PG_TIMEOUT_SECONDS`: Connection timeout in seconds (default: 30)\n///\n/// ### Qdrant Settings (`QD_*`)\n/// - `QD_HOST`: Qdrant host (default: \"localhost\")\n/// - `QD_PORT`: Qdrant port (default: 6333)\n/// - `QD_COLLECTION`: Collection name (default: \"memory_embeddings\")\n/// - `QD_TIMEOUT_SECONDS`: Request timeout in seconds (default: 30)\n///\n/// ### Redis Settings (`RD_*`)\n/// - `RD_HOST`: Redis host (default: \"localhost\")\n/// - `RD_PORT`: Redis port (default: 6379)\n/// - `RD_DB`: Redis database number (default: 0)\n/// - `RD_POOL_SIZE`: Connection pool size (default: 10)\n/// - `RD_TIMEOUT_SECONDS`: Connection timeout in seconds (default: 30)\n///\n/// ### Sync Settings (`SY_*`)\n/// - `SY_ENABLED`: Enable sync (true/false, default: true)\n/// - `SY_SYNC_INTERVAL_SECONDS`: Sync interval (default: 60)\n/// - `SY_BATCH_SIZE`: Batch size (default: 100)\n/// - `SY_CHECKPOINT_ENABLED`: Enable checkpointing (true/false, default: true)\n/// - `SY_CONFLICT_RESOLUTION`: Conflict resolution\n///   (prefer_knowledge/prefer_memory/manual, default: prefer_knowledge)\n///\n/// ### Tools Settings (`TL_*`)\n/// - `TL_ENABLED`: Enable MCP server (true/false, default: true)\n/// - `TL_HOST`: Server host (default: \"localhost\")\n/// - `TL_PORT`: Server port (default: 8080)\n/// - `TL_API_KEY`: API key for authentication (optional)\n/// - `TL_RATE_LIMIT_REQUESTS_PER_MINUTE`: Rate limit (default: 60)\n///\n/// ### Observability Settings (`OB_*`)\n/// - `OB_METRICS_ENABLED`: Enable metrics (true/false, default: true)\n/// - `OB_TRACING_ENABLED`: Enable tracing (true/false, default: true)\n/// - `OB_LOGGING_LEVEL`: Logging level (trace/debug/info/warn/error, default:\n///   \"info\")\n/// - `OB_METRICS_PORT`: Metrics server port (default: 9090)\npub fn load_from_env() -> Result<Config, Box<dyn std::error::Error>> {\n    let config = Config {\n        providers: load_provider_from_env()?,\n        sync: load_sync_from_env()?,\n        memory: load_memory_from_env()?,\n        tools: load_tools_from_env()?,\n        observability: load_observability_from_env()?,\n        deployment: load_deployment_from_env()?,\n        job: load_job_from_env()?,\n        cca: crate::cca::CcaConfig::default(),\n    };\n\n    Ok(config)\n}\n\nfn load_deployment_from_env() -> Result<crate::config::DeploymentConfig, Box<dyn std::error::Error>>\n{\n    Ok(crate::config::DeploymentConfig {\n        mode: env::var(\"AETERNA_DEPLOYMENT_MODE\").unwrap_or_else(|_| \"local\".to_string()),\n        remote_url: env::var(\"AETERNA_REMOTE_GOVERNANCE_URL\").ok(),\n        sync_enabled: parse_env(\"AETERNA_SYNC_ENABLED\").unwrap_or(true),\n    })\n}\n\nfn load_job_from_env() -> Result<crate::config::JobConfig, Box<dyn std::error::Error>> {\n    Ok(crate::config::JobConfig {\n        lock_ttl_seconds: parse_env(\"AETERNA_JOB_LOCK_TTL_SECONDS\").unwrap_or(2100),\n        job_timeout_seconds: parse_env(\"AETERNA_JOB_TIMEOUT_SECONDS\").unwrap_or(1800),\n        deduplication_window_seconds: parse_env(\"AETERNA_JOB_DEDUP_WINDOW_SECONDS\").unwrap_or(300),\n        checkpoint_interval: parse_env(\"AETERNA_JOB_CHECKPOINT_INTERVAL\").unwrap_or(100),\n        graceful_shutdown_timeout_seconds: parse_env(\"AETERNA_JOB_SHUTDOWN_TIMEOUT_SECONDS\")\n            .unwrap_or(30),\n    })\n}\n\nfn load_provider_from_env() -> Result<ProviderConfig, Box<dyn std::error::Error>> {\n    Ok(ProviderConfig {\n        postgres: load_postgres_from_env()?,\n        qdrant: load_qdrant_from_env()?,\n        redis: load_redis_from_env()?,\n        graph: load_graph_from_env()?,\n    })\n}\n\nfn load_postgres_from_env() -> Result<PostgresConfig, Box<dyn std::error::Error>> {\n    Ok(PostgresConfig {\n        host: env::var(\"PG_HOST\").unwrap_or_else(|_| \"localhost\".to_string()),\n        port: parse_env(\"PG_PORT\").unwrap_or(5432),\n        database: env::var(\"PG_DATABASE\").unwrap_or_else(|_| \"memory_knowledge\".to_string()),\n        username: env::var(\"PG_USERNAME\").unwrap_or_else(|_| \"postgres\".to_string()),\n        password: env::var(\"PG_PASSWORD\").unwrap_or_default(),\n        pool_size: parse_env(\"PG_POOL_SIZE\").unwrap_or(10),\n        timeout_seconds: parse_env(\"PG_TIMEOUT_SECONDS\").unwrap_or(30),\n    })\n}\n\nfn load_qdrant_from_env() -> Result<QdrantConfig, Box<dyn std::error::Error>> {\n    Ok(QdrantConfig {\n        host: env::var(\"QD_HOST\").unwrap_or_else(|_| \"localhost\".to_string()),\n        port: parse_env(\"QD_PORT\").unwrap_or(6333),\n        collection: env::var(\"QD_COLLECTION\").unwrap_or_else(|_| \"memory_embeddings\".to_string()),\n        timeout_seconds: parse_env(\"QD_TIMEOUT_SECONDS\").unwrap_or(30),\n    })\n}\n\nfn load_redis_from_env() -> Result<RedisConfig, Box<dyn std::error::Error>> {\n    Ok(RedisConfig {\n        host: env::var(\"RD_HOST\").unwrap_or_else(|_| \"localhost\".to_string()),\n        port: parse_env(\"RD_PORT\").unwrap_or(6379),\n        db: parse_env(\"RD_DB\").unwrap_or(0),\n        pool_size: parse_env(\"RD_POOL_SIZE\").unwrap_or(10),\n        timeout_seconds: parse_env(\"RD_TIMEOUT_SECONDS\").unwrap_or(30),\n    })\n}\n\nfn load_graph_from_env() -> Result<GraphConfig, Box<dyn std::error::Error>> {\n    Ok(GraphConfig {\n        enabled: parse_env(\"GR_ENABLED\").unwrap_or(true),\n        database_path: env::var(\"GR_DATABASE_PATH\").unwrap_or_else(|_| \":memory:\".to_string()),\n        s3_bucket: env::var(\"GR_S3_BUCKET\").ok(),\n        s3_prefix: env::var(\"GR_S3_PREFIX\").ok(),\n        s3_endpoint: env::var(\"GR_S3_ENDPOINT\").ok(),\n        s3_region: env::var(\"GR_S3_REGION\").unwrap_or_else(|_| \"us-east-1\".to_string()),\n        contention_alerts: ContentionAlertConfig::default(),\n    })\n}\n\nfn load_sync_from_env() -> Result<SyncConfig, Box<dyn std::error::Error>> {\n    Ok(SyncConfig {\n        enabled: parse_env(\"SY_ENABLED\").unwrap_or(true),\n        sync_interval_seconds: parse_env(\"SY_SYNC_INTERVAL_SECONDS\").unwrap_or(60),\n        batch_size: parse_env(\"SY_BATCH_SIZE\").unwrap_or(100),\n        checkpoint_enabled: parse_env(\"SY_CHECKPOINT_ENABLED\").unwrap_or(true),\n        conflict_resolution: env::var(\"SY_CONFLICT_RESOLUTION\")\n            .unwrap_or_else(|_| \"prefer_knowledge\".to_string()),\n    })\n}\n\nfn load_memory_from_env() -> Result<MemoryConfig, Box<dyn std::error::Error>> {\n    Ok(MemoryConfig {\n        promotion_threshold: parse_env(\"MK_PROMOTION_THRESHOLD\").unwrap_or(0.8),\n        decay_interval_secs: parse_env(\"MK_DECAY_INTERVAL_SECS\").unwrap_or(86400),\n        decay_rate: parse_env(\"MK_DECAY_RATE\").unwrap_or(0.05),\n        optimization_trigger_count: parse_env(\"MK_OPTIMIZATION_TRIGGER_COUNT\").unwrap_or(100),\n        layer_summary_configs: std::collections::HashMap::new(),\n        reasoning: ReasoningConfig::default(),\n    })\n}\n\nfn load_tools_from_env() -> Result<ToolConfig, Box<dyn std::error::Error>> {\n    Ok(ToolConfig {\n        enabled: parse_env(\"TL_ENABLED\").unwrap_or(true),\n        host: env::var(\"TL_HOST\").unwrap_or_else(|_| \"localhost\".to_string()),\n        port: parse_env(\"TL_PORT\").unwrap_or(8080),\n        api_key: env::var(\"TL_API_KEY\").ok(),\n        rate_limit_requests_per_minute: parse_env(\"TL_RATE_LIMIT_REQUESTS_PER_MINUTE\")\n            .unwrap_or(60),\n    })\n}\n\nfn load_observability_from_env() -> Result<ObservabilityConfig, Box<dyn std::error::Error>> {\n    Ok(ObservabilityConfig {\n        metrics_enabled: parse_env(\"OB_METRICS_ENABLED\").unwrap_or(true),\n        tracing_enabled: parse_env(\"OB_TRACING_ENABLED\").unwrap_or(true),\n        logging_level: env::var(\"OB_LOGGING_LEVEL\").unwrap_or_else(|_| \"info\".to_string()),\n        metrics_port: parse_env(\"OB_METRICS_PORT\").unwrap_or(9090),\n    })\n}\n\nfn parse_env<T>(key: &str) -> Result<T, Box<dyn std::error::Error>>\nwhere\n    T: std::str::FromStr,\n    T::Err: std::error::Error + Send + Sync + 'static,\n{\n    match env::var(key) {\n        Ok(s) => s\n            .parse::<T>()\n            .map_err(|e| Box::new(e) as Box<dyn std::error::Error>),\n        Err(e) => Err(Box::new(e) as Box<dyn std::error::Error>),\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use serial_test::serial;\n\n    #[test]\n    #[serial]\n    fn test_load_from_env_defaults() {\n        unsafe {\n            env::remove_var(\"PG_HOST\");\n            env::remove_var(\"QD_HOST\");\n            env::remove_var(\"RD_HOST\");\n            env::remove_var(\"SY_ENABLED\");\n            env::remove_var(\"TL_PORT\");\n            env::remove_var(\"OB_LOGGING_LEVEL\");\n        }\n        let config = load_from_env().unwrap();\n        assert_eq!(config.providers.postgres.host, \"localhost\");\n        assert_eq!(config.providers.qdrant.host, \"localhost\");\n        assert_eq!(config.providers.redis.host, \"localhost\");\n        assert_eq!(config.sync.enabled, true);\n        assert_eq!(config.tools.port, 8080);\n        assert_eq!(config.observability.logging_level, \"info\");\n    }\n\n    #[test]\n    #[serial]\n    fn test_load_from_env_overrides() {\n        unsafe {\n            env::set_var(\"PG_HOST\", \"testhost\");\n            env::set_var(\"PG_PORT\", \"9999\");\n            env::set_var(\"SY_ENABLED\", \"false\");\n        }\n\n        let config = load_from_env().unwrap();\n        assert_eq!(config.providers.postgres.host, \"testhost\");\n        assert_eq!(config.providers.postgres.port, 9999);\n        assert_eq!(config.sync.enabled, false);\n\n        unsafe {\n            env::remove_var(\"PG_HOST\");\n            env::remove_var(\"PG_PORT\");\n            env::remove_var(\"SY_ENABLED\");\n        }\n    }\n\n    #[test]\n    fn test_parse_env_missing() {\n        let result: Result<u32, _> = parse_env(\"NONEXISTENT_VAR\");\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_parse_env_valid_string() {\n        unsafe {\n            env::set_var(\"TEST_VAR\", \"test_value\");\n        }\n        let result: Result<String, _> = parse_env(\"TEST_VAR\");\n        assert_eq!(result.unwrap(), \"test_value\");\n        unsafe {\n            env::remove_var(\"TEST_VAR\");\n        }\n    }\n\n    #[test]\n    fn test_parse_env_valid_number() {\n        unsafe {\n            env::set_var(\"TEST_VAR\", \"123\");\n        }\n        let result: Result<u32, _> = parse_env(\"TEST_VAR\");\n        assert_eq!(result.unwrap(), 123);\n        unsafe {\n            env::remove_var(\"TEST_VAR\");\n        }\n    }\n\n    #[test]\n    fn test_parse_env_valid_number_with_parse_env() {\n        unsafe {\n            env::set_var(\"TEST_VAR\", \"123\");\n        }\n        let result: Result<u32, _> = parse_env(\"TEST_VAR\");\n        assert_eq!(result.unwrap(), 123);\n        unsafe {\n            env::remove_var(\"TEST_VAR\");\n        }\n    }\n\n    #[test]\n    fn test_parse_env_invalid_number() {\n        unsafe {\n            env::set_var(\"TEST_VAR\", \"not_a_number\");\n        }\n        let result: Result<u32, _> = parse_env(\"TEST_VAR\");\n        assert!(result.is_err());\n        unsafe {\n            env::remove_var(\"TEST_VAR\");\n        }\n    }\n\n    #[test]\n    #[serial]\n    fn test_load_postgres_from_env() {\n        unsafe {\n            env::set_var(\"PG_HOST\", \"customhost\");\n            env::set_var(\"PG_PORT\", \"5433\");\n            env::set_var(\"PG_DATABASE\", \"testdb\");\n            env::set_var(\"PG_USERNAME\", \"testuser\");\n            env::set_var(\"PG_PASSWORD\", \"testpass\");\n            env::set_var(\"PG_POOL_SIZE\", \"20\");\n            env::set_var(\"PG_TIMEOUT_SECONDS\", \"60\");\n        }\n\n        let postgres = load_postgres_from_env().unwrap();\n\n        unsafe {\n            env::remove_var(\"PG_HOST\");\n            env::remove_var(\"PG_PORT\");\n            env::remove_var(\"PG_DATABASE\");\n            env::remove_var(\"PG_USERNAME\");\n            env::remove_var(\"PG_PASSWORD\");\n            env::remove_var(\"PG_POOL_SIZE\");\n            env::remove_var(\"PG_TIMEOUT_SECONDS\");\n        }\n\n        assert_eq!(postgres.host, \"customhost\");\n        assert_eq!(postgres.port, 5433);\n        assert_eq!(postgres.database, \"testdb\");\n        assert_eq!(postgres.username, \"testuser\");\n        assert_eq!(postgres.password, \"testpass\");\n        assert_eq!(postgres.pool_size, 20);\n        assert_eq!(postgres.timeout_seconds, 60);\n    }\n\n    #[test]\n    #[serial]\n    fn test_load_qdrant_from_env() {\n        unsafe {\n            env::set_var(\"QD_HOST\", \"qdranthost\");\n            env::set_var(\"QD_PORT\", \"7333\");\n            env::set_var(\"QD_COLLECTION\", \"test_collection\");\n            env::set_var(\"QD_TIMEOUT_SECONDS\", \"45\");\n        }\n\n        let qdrant = load_qdrant_from_env().unwrap();\n        assert_eq!(qdrant.host, \"qdranthost\");\n        assert_eq!(qdrant.port, 7333);\n        assert_eq!(qdrant.collection, \"test_collection\");\n        assert_eq!(qdrant.timeout_seconds, 45);\n\n        unsafe {\n            env::remove_var(\"QD_HOST\");\n            env::remove_var(\"QD_PORT\");\n            env::remove_var(\"QD_COLLECTION\");\n            env::remove_var(\"QD_TIMEOUT_SECONDS\");\n        }\n    }\n\n    #[test]\n    #[serial]\n    fn test_load_redis_from_env() {\n        unsafe {\n            env::set_var(\"RD_HOST\", \"redishost\");\n            env::set_var(\"RD_PORT\", \"6380\");\n            env::set_var(\"RD_DB\", \"1\");\n            env::set_var(\"RD_POOL_SIZE\", \"15\");\n            env::set_var(\"RD_TIMEOUT_SECONDS\", \"45\");\n        }\n\n        let redis = load_redis_from_env().unwrap();\n        assert_eq!(redis.host, \"redishost\");\n        assert_eq!(redis.port, 6380);\n        assert_eq!(redis.db, 1);\n        assert_eq!(redis.pool_size, 15);\n        assert_eq!(redis.timeout_seconds, 45);\n\n        unsafe {\n            env::remove_var(\"RD_HOST\");\n            env::remove_var(\"RD_PORT\");\n            env::remove_var(\"RD_DB\");\n            env::remove_var(\"RD_POOL_SIZE\");\n            env::remove_var(\"RD_TIMEOUT_SECONDS\");\n        }\n    }\n}\n","traces":[{"line":89,"address":[],"length":0,"stats":{"Line":2}},{"line":91,"address":[],"length":0,"stats":{"Line":2}},{"line":92,"address":[],"length":0,"stats":{"Line":2}},{"line":93,"address":[],"length":0,"stats":{"Line":2}},{"line":94,"address":[],"length":0,"stats":{"Line":2}},{"line":95,"address":[],"length":0,"stats":{"Line":2}},{"line":96,"address":[],"length":0,"stats":{"Line":2}},{"line":97,"address":[],"length":0,"stats":{"Line":2}},{"line":98,"address":[],"length":0,"stats":{"Line":2}},{"line":101,"address":[],"length":0,"stats":{"Line":2}},{"line":104,"address":[],"length":0,"stats":{"Line":2}},{"line":107,"address":[],"length":0,"stats":{"Line":8}},{"line":108,"address":[],"length":0,"stats":{"Line":4}},{"line":109,"address":[],"length":0,"stats":{"Line":6}},{"line":113,"address":[],"length":0,"stats":{"Line":2}},{"line":114,"address":[],"length":0,"stats":{"Line":2}},{"line":115,"address":[],"length":0,"stats":{"Line":8}},{"line":116,"address":[],"length":0,"stats":{"Line":8}},{"line":117,"address":[],"length":0,"stats":{"Line":8}},{"line":118,"address":[],"length":0,"stats":{"Line":8}},{"line":119,"address":[],"length":0,"stats":{"Line":4}},{"line":120,"address":[],"length":0,"stats":{"Line":2}},{"line":124,"address":[],"length":0,"stats":{"Line":2}},{"line":126,"address":[],"length":0,"stats":{"Line":2}},{"line":127,"address":[],"length":0,"stats":{"Line":2}},{"line":128,"address":[],"length":0,"stats":{"Line":2}},{"line":129,"address":[],"length":0,"stats":{"Line":2}},{"line":133,"address":[],"length":0,"stats":{"Line":3}},{"line":135,"address":[],"length":0,"stats":{"Line":8}},{"line":136,"address":[],"length":0,"stats":{"Line":9}},{"line":137,"address":[],"length":0,"stats":{"Line":10}},{"line":138,"address":[],"length":0,"stats":{"Line":10}},{"line":139,"address":[],"length":0,"stats":{"Line":6}},{"line":140,"address":[],"length":0,"stats":{"Line":9}},{"line":141,"address":[],"length":0,"stats":{"Line":9}},{"line":145,"address":[],"length":0,"stats":{"Line":3}},{"line":147,"address":[],"length":0,"stats":{"Line":10}},{"line":148,"address":[],"length":0,"stats":{"Line":9}},{"line":149,"address":[],"length":0,"stats":{"Line":10}},{"line":150,"address":[],"length":0,"stats":{"Line":9}},{"line":154,"address":[],"length":0,"stats":{"Line":3}},{"line":156,"address":[],"length":0,"stats":{"Line":10}},{"line":157,"address":[],"length":0,"stats":{"Line":9}},{"line":158,"address":[],"length":0,"stats":{"Line":9}},{"line":159,"address":[],"length":0,"stats":{"Line":9}},{"line":160,"address":[],"length":0,"stats":{"Line":9}},{"line":164,"address":[],"length":0,"stats":{"Line":2}},{"line":166,"address":[],"length":0,"stats":{"Line":6}},{"line":167,"address":[],"length":0,"stats":{"Line":8}},{"line":168,"address":[],"length":0,"stats":{"Line":4}},{"line":169,"address":[],"length":0,"stats":{"Line":4}},{"line":170,"address":[],"length":0,"stats":{"Line":4}},{"line":171,"address":[],"length":0,"stats":{"Line":8}},{"line":172,"address":[],"length":0,"stats":{"Line":2}},{"line":176,"address":[],"length":0,"stats":{"Line":2}},{"line":178,"address":[],"length":0,"stats":{"Line":6}},{"line":179,"address":[],"length":0,"stats":{"Line":6}},{"line":180,"address":[],"length":0,"stats":{"Line":6}},{"line":181,"address":[],"length":0,"stats":{"Line":6}},{"line":182,"address":[],"length":0,"stats":{"Line":2}},{"line":183,"address":[],"length":0,"stats":{"Line":6}},{"line":187,"address":[],"length":0,"stats":{"Line":2}},{"line":188,"address":[],"length":0,"stats":{"Line":2}},{"line":189,"address":[],"length":0,"stats":{"Line":8}},{"line":190,"address":[],"length":0,"stats":{"Line":8}},{"line":191,"address":[],"length":0,"stats":{"Line":8}},{"line":192,"address":[],"length":0,"stats":{"Line":8}},{"line":193,"address":[],"length":0,"stats":{"Line":2}},{"line":194,"address":[],"length":0,"stats":{"Line":2}},{"line":198,"address":[],"length":0,"stats":{"Line":2}},{"line":200,"address":[],"length":0,"stats":{"Line":6}},{"line":201,"address":[],"length":0,"stats":{"Line":8}},{"line":202,"address":[],"length":0,"stats":{"Line":6}},{"line":203,"address":[],"length":0,"stats":{"Line":4}},{"line":204,"address":[],"length":0,"stats":{"Line":4}},{"line":205,"address":[],"length":0,"stats":{"Line":2}},{"line":209,"address":[],"length":0,"stats":{"Line":2}},{"line":211,"address":[],"length":0,"stats":{"Line":6}},{"line":212,"address":[],"length":0,"stats":{"Line":6}},{"line":213,"address":[],"length":0,"stats":{"Line":8}},{"line":214,"address":[],"length":0,"stats":{"Line":6}},{"line":218,"address":[],"length":0,"stats":{"Line":74}},{"line":223,"address":[],"length":0,"stats":{"Line":74}},{"line":224,"address":[],"length":0,"stats":{"Line":30}},{"line":226,"address":[],"length":0,"stats":{"Line":18}},{"line":227,"address":[],"length":0,"stats":{"Line":177}}],"covered":86,"coverable":86},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","opencode.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","pointer.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","pool.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","postgres.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","precedence.rs"],"content":"//! # Configuration Precedence\n//!\n//! Merges configuration from multiple sources with precedence rules.\n//!\n//! # Precedence Order\n//! 1. CLI arguments (highest priority)\n//! 2. Environment variables\n//! 3. Configuration file\n//! 4. Default values (lowest priority)\n\nuse crate::config::{\n    Config, ObservabilityConfig, PostgresConfig, QdrantConfig, RedisConfig, SyncConfig, ToolConfig,\n};\n\n/// Merge multiple configuration sources with precedence.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Merges configuration from multiple sources following precedence rules:\n/// CLI arguments > environment variables > config file > defaults.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::{Config, load_from_env, load_from_file, merge_configs};\n/// use std::path::Path;\n///\n/// fn main() -> Result<(), Box<dyn std::error::Error>> {\n///     let defaults = Config::default();\n///     let from_file = load_from_file(Path::new(\"config.toml\"))?;\n///     let from_env = load_from_env()?;\n///\n///     let _config = merge_configs(defaults, from_file, \"file\", from_env, \"env\", None, \"cli\");\n///     Ok(())\n/// }\n/// ```\n///\n/// ## Deep Merge\n/// Performs deep merge on nested structures (providers, sync, tools,\n/// observability). String fields are overridden, not concatenated.\npub fn merge_configs(\n    defaults: Config,\n    file_config: Config,\n    file_source_name: &str,\n    env_config: Config,\n    env_source_name: &str,\n    cli_config: Option<Config>,\n    cli_source_name: &str,\n) -> Config {\n    let mut config = defaults;\n\n    config = merge_with_logging(config, file_config, file_source_name);\n    config = merge_with_logging(config, env_config, env_source_name);\n\n    if let Some(cli) = cli_config {\n        config = merge_with_logging(config, cli, cli_source_name);\n    }\n\n    config\n}\n\nfn merge_with_logging(mut base: Config, override_config: Config, source_name: &str) -> Config {\n    let mut changes = Vec::new();\n\n    let mut temp_postgres = base.providers.postgres.clone();\n    merge_postgres(\n        &mut temp_postgres,\n        &override_config.providers.postgres,\n        source_name,\n        &mut changes,\n    );\n    if !changes.is_empty() {\n        base.providers.postgres = temp_postgres;\n    }\n\n    let mut qdrant_changes = Vec::new();\n    let mut temp_qdrant = base.providers.qdrant.clone();\n    merge_qdrant(\n        &mut temp_qdrant,\n        &override_config.providers.qdrant,\n        source_name,\n        &mut qdrant_changes,\n    );\n    if !qdrant_changes.is_empty() {\n        base.providers.qdrant = temp_qdrant;\n        changes.extend(qdrant_changes);\n    }\n\n    let mut redis_changes = Vec::new();\n    let mut temp_redis = base.providers.redis.clone();\n    merge_redis(\n        &mut temp_redis,\n        &override_config.providers.redis,\n        source_name,\n        &mut redis_changes,\n    );\n    if !redis_changes.is_empty() {\n        base.providers.redis = temp_redis;\n        changes.extend(redis_changes);\n    }\n\n    let mut sync_changes = Vec::new();\n    let mut temp_sync = base.sync.clone();\n    merge_sync(\n        &mut temp_sync,\n        &override_config.sync,\n        source_name,\n        &mut sync_changes,\n    );\n    if !sync_changes.is_empty() {\n        base.sync = temp_sync;\n        changes.extend(sync_changes);\n    }\n\n    let mut tool_changes = Vec::new();\n    let mut temp_tools = base.tools.clone();\n    merge_tools(\n        &mut temp_tools,\n        &override_config.tools,\n        source_name,\n        &mut tool_changes,\n    );\n    if !tool_changes.is_empty() {\n        base.tools = temp_tools;\n        changes.extend(tool_changes);\n    }\n\n    let mut obs_changes = Vec::new();\n    let mut temp_obs = base.observability.clone();\n    merge_observability(\n        &mut temp_obs,\n        &override_config.observability,\n        source_name,\n        &mut obs_changes,\n    );\n    if !obs_changes.is_empty() {\n        base.observability = temp_obs;\n        changes.extend(obs_changes);\n    }\n\n    if !changes.is_empty() {\n        tracing::info!(\"Configuration from {}: {:?}\", source_name, changes);\n    }\n\n    base\n}\n\nfn merge_postgres(\n    base: &mut PostgresConfig,\n    override_config: &PostgresConfig,\n    _source: &str,\n    changes: &mut Vec<String>,\n) {\n    if override_config.host != \"localhost\" && override_config.host != base.host {\n        changes.push(format!(\n            \"providers.postgres.host = {}\",\n            override_config.host\n        ));\n        base.host.clone_from(&override_config.host);\n    }\n    if override_config.port != 5432 && override_config.port != base.port {\n        changes.push(format!(\n            \"providers.postgres.port = {}\",\n            override_config.port\n        ));\n        base.port = override_config.port;\n    }\n    if override_config.database != \"memory_knowledge\" && override_config.database != base.database {\n        changes.push(format!(\n            \"providers.postgres.database = {}\",\n            override_config.database\n        ));\n        base.database.clone_from(&override_config.database);\n    }\n    if override_config.username != \"postgres\" && override_config.username != base.username {\n        changes.push(format!(\n            \"providers.postgres.username = {}\",\n            override_config.username\n        ));\n        base.username.clone_from(&override_config.username);\n    }\n    if !override_config.password.is_empty() && override_config.password != base.password {\n        changes.push(\"providers.postgres.password = ***\".to_string());\n        base.password.clone_from(&override_config.password);\n    }\n    if override_config.pool_size != 10 && override_config.pool_size != base.pool_size {\n        changes.push(format!(\n            \"providers.postgres.pool_size = {}\",\n            override_config.pool_size\n        ));\n        base.pool_size = override_config.pool_size;\n    }\n    if override_config.timeout_seconds != 30\n        && override_config.timeout_seconds != base.timeout_seconds\n    {\n        changes.push(format!(\n            \"providers.postgres.timeout_seconds = {}\",\n            override_config.timeout_seconds\n        ));\n        base.timeout_seconds = override_config.timeout_seconds;\n    }\n}\n\nfn merge_qdrant(\n    base: &mut QdrantConfig,\n    override_config: &QdrantConfig,\n    _source: &str,\n    changes: &mut Vec<String>,\n) {\n    if override_config.host != \"localhost\" && override_config.host != base.host {\n        changes.push(format!(\"providers.qdrant.host = {}\", override_config.host));\n        base.host.clone_from(&override_config.host);\n    }\n    if override_config.port != 6333 && override_config.port != base.port {\n        changes.push(format!(\"providers.qdrant.port = {}\", override_config.port));\n        base.port = override_config.port;\n    }\n    if override_config.collection != \"memory_embeddings\"\n        && override_config.collection != base.collection\n    {\n        changes.push(format!(\n            \"providers.qdrant.collection = {}\",\n            override_config.collection\n        ));\n        base.collection.clone_from(&override_config.collection);\n    }\n    if override_config.timeout_seconds != 30\n        && override_config.timeout_seconds != base.timeout_seconds\n    {\n        changes.push(format!(\n            \"providers.qdrant.timeout_seconds = {}\",\n            override_config.timeout_seconds\n        ));\n        base.timeout_seconds = override_config.timeout_seconds;\n    }\n}\n\nfn merge_redis(\n    base: &mut RedisConfig,\n    override_config: &RedisConfig,\n    _source: &str,\n    changes: &mut Vec<String>,\n) {\n    if override_config.host != \"localhost\" && override_config.host != base.host {\n        changes.push(format!(\"providers.redis.host = {}\", override_config.host));\n        base.host.clone_from(&override_config.host);\n    }\n    if override_config.port != 6379 && override_config.port != base.port {\n        changes.push(format!(\"providers.redis.port = {}\", override_config.port));\n        base.port = override_config.port;\n    }\n    if override_config.db != 0 && override_config.db != base.db {\n        changes.push(format!(\"providers.redis.db = {}\", override_config.db));\n        base.db = override_config.db;\n    }\n    if override_config.pool_size != 10 && override_config.pool_size != base.pool_size {\n        changes.push(format!(\n            \"providers.redis.pool_size = {}\",\n            override_config.pool_size\n        ));\n        base.pool_size = override_config.pool_size;\n    }\n    if override_config.timeout_seconds != 30\n        && override_config.timeout_seconds != base.timeout_seconds\n    {\n        changes.push(format!(\n            \"providers.redis.timeout_seconds = {}\",\n            override_config.timeout_seconds\n        ));\n        base.timeout_seconds = override_config.timeout_seconds;\n    }\n}\n\nfn merge_sync(\n    base: &mut SyncConfig,\n    override_config: &SyncConfig,\n    _source: &str,\n    changes: &mut Vec<String>,\n) {\n    if !override_config.enabled && override_config.enabled != base.enabled {\n        changes.push(format!(\"sync.enabled = {}\", override_config.enabled));\n        base.enabled = override_config.enabled;\n    }\n    if override_config.sync_interval_seconds != 60\n        && override_config.sync_interval_seconds != base.sync_interval_seconds\n    {\n        changes.push(format!(\n            \"sync.sync_interval_seconds = {}\",\n            override_config.sync_interval_seconds\n        ));\n        base.sync_interval_seconds = override_config.sync_interval_seconds;\n    }\n    if override_config.batch_size != 100 && override_config.batch_size != base.batch_size {\n        changes.push(format!(\"sync.batch_size = {}\", override_config.batch_size));\n        base.batch_size = override_config.batch_size;\n    }\n    if !override_config.checkpoint_enabled\n        && override_config.checkpoint_enabled != base.checkpoint_enabled\n    {\n        changes.push(format!(\n            \"sync.checkpoint_enabled = {}\",\n            override_config.checkpoint_enabled\n        ));\n        base.checkpoint_enabled = override_config.checkpoint_enabled;\n    }\n    if override_config.conflict_resolution != \"prefer_knowledge\"\n        && override_config.conflict_resolution != base.conflict_resolution\n    {\n        changes.push(format!(\n            \"sync.conflict_resolution = {}\",\n            override_config.conflict_resolution\n        ));\n        base.conflict_resolution\n            .clone_from(&override_config.conflict_resolution);\n    }\n}\n\nfn merge_tools(\n    base: &mut ToolConfig,\n    override_config: &ToolConfig,\n    _source: &str,\n    changes: &mut Vec<String>,\n) {\n    if !override_config.enabled && override_config.enabled != base.enabled {\n        changes.push(format!(\"tools.enabled = {}\", override_config.enabled));\n        base.enabled = override_config.enabled;\n    }\n    if override_config.host != \"localhost\" && override_config.host != base.host {\n        changes.push(format!(\"tools.host = {}\", override_config.host));\n        base.host.clone_from(&override_config.host);\n    }\n    if override_config.port != 8080 && override_config.port != base.port {\n        changes.push(format!(\"tools.port = {}\", override_config.port));\n        base.port = override_config.port;\n    }\n    if override_config.api_key.is_some() && override_config.api_key != base.api_key {\n        match (&override_config.api_key, &base.api_key) {\n            (Some(_), None) => changes.push(\"tools.api_key = ***\".to_string()),\n            (Some(new_key), Some(old_key)) if new_key != old_key => {\n                changes.push(\"tools.api_key = ***\".to_string())\n            }\n            _ => {}\n        }\n        base.api_key.clone_from(&override_config.api_key);\n    }\n    if override_config.rate_limit_requests_per_minute != 60\n        && override_config.rate_limit_requests_per_minute != base.rate_limit_requests_per_minute\n    {\n        changes.push(format!(\n            \"tools.rate_limit_requests_per_minute = {}\",\n            override_config.rate_limit_requests_per_minute\n        ));\n        base.rate_limit_requests_per_minute = override_config.rate_limit_requests_per_minute;\n    }\n}\n\nfn merge_observability(\n    base: &mut ObservabilityConfig,\n    override_config: &ObservabilityConfig,\n    _source: &str,\n    changes: &mut Vec<String>,\n) {\n    if !override_config.metrics_enabled && override_config.metrics_enabled != base.metrics_enabled {\n        changes.push(format!(\n            \"observability.metrics_enabled = {}\",\n            override_config.metrics_enabled\n        ));\n        base.metrics_enabled = override_config.metrics_enabled;\n    }\n    if !override_config.tracing_enabled && override_config.tracing_enabled != base.tracing_enabled {\n        changes.push(format!(\n            \"observability.tracing_enabled = {}\",\n            override_config.tracing_enabled\n        ));\n        base.tracing_enabled = override_config.tracing_enabled;\n    }\n    if override_config.logging_level != \"info\"\n        && override_config.logging_level != base.logging_level\n    {\n        changes.push(format!(\n            \"observability.logging_level = {}\",\n            override_config.logging_level\n        ));\n        base.logging_level\n            .clone_from(&override_config.logging_level);\n    }\n    if override_config.metrics_port != 9090 && override_config.metrics_port != base.metrics_port {\n        changes.push(format!(\n            \"observability.metrics_port = {}\",\n            override_config.metrics_port\n        ));\n        base.metrics_port = override_config.metrics_port;\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::config::ProviderConfig;\n\n    #[test]\n    fn test_merge_configs_precedence() {\n        let defaults = Config {\n            providers: ProviderConfig {\n                postgres: PostgresConfig {\n                    host: \"default_host\".to_string(),\n                    ..Default::default()\n                },\n                ..Default::default()\n            },\n            ..Default::default()\n        };\n\n        let file_config = Config {\n            providers: ProviderConfig {\n                postgres: PostgresConfig {\n                    host: \"file_host\".to_string(),\n                    ..Default::default()\n                },\n                ..Default::default()\n            },\n            ..Default::default()\n        };\n\n        let env_config = Config {\n            providers: ProviderConfig {\n                postgres: PostgresConfig {\n                    port: 9999,\n                    ..Default::default()\n                },\n                ..Default::default()\n            },\n            ..Default::default()\n        };\n\n        let merged = merge_configs(\n            defaults,\n            file_config,\n            \"file\",\n            env_config,\n            \"env\",\n            None,\n            \"cli\",\n        );\n\n        assert_eq!(merged.providers.postgres.host, \"file_host\");\n        assert_eq!(merged.providers.postgres.port, 9999);\n    }\n\n    #[test]\n    fn test_merge_postgres() {\n        let mut base = PostgresConfig {\n            host: \"base_host\".to_string(),\n            port: 5432,\n            database: \"base_db\".to_string(),\n            ..Default::default()\n        };\n\n        let override_config = PostgresConfig {\n            host: \"override_host\".to_string(),\n            port: 9999,\n            database: \"override_db\".to_string(),\n            ..Default::default()\n        };\n\n        let mut changes = Vec::new();\n        merge_postgres(&mut base, &override_config, \"test\", &mut changes);\n\n        assert_eq!(base.host, \"override_host\");\n        assert_eq!(base.port, 9999);\n        assert_eq!(base.database, \"override_db\");\n        assert_eq!(changes.len(), 3);\n    }\n\n    #[test]\n    fn test_merge_sync() {\n        let mut base = SyncConfig {\n            enabled: true,\n            sync_interval_seconds: 60,\n            ..Default::default()\n        };\n\n        let override_config = SyncConfig {\n            enabled: false,\n            sync_interval_seconds: 120,\n            ..Default::default()\n        };\n\n        let mut changes = Vec::new();\n        merge_sync(&mut base, &override_config, \"test\", &mut changes);\n\n        assert_eq!(base.enabled, false);\n        assert_eq!(base.sync_interval_seconds, 120);\n        assert_eq!(changes.len(), 2);\n    }\n\n    #[test]\n    fn test_merge_tools_with_api_key() {\n        let mut base = ToolConfig {\n            api_key: Some(\"old_key\".to_string()),\n            ..Default::default()\n        };\n\n        let override_config = ToolConfig {\n            api_key: Some(\"new_key\".to_string()),\n            ..Default::default()\n        };\n\n        let mut changes = Vec::new();\n        merge_tools(&mut base, &override_config, \"test\", &mut changes);\n\n        assert_eq!(base.api_key, Some(\"new_key\".to_string()));\n        assert_eq!(changes.len(), 1);\n        assert!(changes[0].contains(\"api_key = ***\"));\n    }\n\n    #[test]\n    fn test_merge_cli_overrides_all() {\n        let defaults = Config::default();\n        let file_config = defaults.clone();\n        let env_config = defaults.clone();\n        let cli_config = Config {\n            providers: ProviderConfig {\n                postgres: PostgresConfig {\n                    host: \"cli_host\".to_string(),\n                    ..Default::default()\n                },\n                ..Default::default()\n            },\n            ..Default::default()\n        };\n\n        let merged = merge_configs(\n            defaults,\n            file_config,\n            \"file\",\n            env_config,\n            \"env\",\n            Some(cli_config),\n            \"cli\",\n        );\n\n        assert_eq!(merged.providers.postgres.host, \"cli_host\");\n    }\n\n    #[test]\n    fn test_merge_qdrant() {\n        let mut base = QdrantConfig {\n            host: \"base_host\".to_string(),\n            port: 6333,\n            collection: \"base_collection\".to_string(),\n            ..Default::default()\n        };\n\n        let override_config = QdrantConfig {\n            host: \"override_host\".to_string(),\n            port: 9999,\n            collection: \"override_collection\".to_string(),\n            ..Default::default()\n        };\n\n        let mut changes = Vec::new();\n        merge_qdrant(&mut base, &override_config, \"test\", &mut changes);\n\n        assert_eq!(base.host, \"override_host\");\n        assert_eq!(base.port, 9999);\n        assert_eq!(base.collection, \"override_collection\");\n        assert_eq!(changes.len(), 3);\n    }\n\n    #[test]\n    fn test_merge_redis() {\n        let mut base = RedisConfig {\n            host: \"base_host\".to_string(),\n            port: 6379,\n            db: 0,\n            ..Default::default()\n        };\n\n        let override_config = RedisConfig {\n            host: \"override_host\".to_string(),\n            port: 9999,\n            db: 1,\n            ..Default::default()\n        };\n\n        let mut changes = Vec::new();\n        merge_redis(&mut base, &override_config, \"test\", &mut changes);\n\n        assert_eq!(base.host, \"override_host\");\n        assert_eq!(base.port, 9999);\n        assert_eq!(base.db, 1);\n        assert_eq!(changes.len(), 3);\n    }\n\n    #[test]\n    fn test_merge_observability() {\n        let mut base = ObservabilityConfig {\n            metrics_enabled: true,\n            tracing_enabled: true,\n            logging_level: \"info\".to_string(),\n            metrics_port: 9090,\n        };\n\n        let override_config = ObservabilityConfig {\n            metrics_enabled: false,\n            tracing_enabled: false,\n            logging_level: \"debug\".to_string(),\n            metrics_port: 9999,\n        };\n\n        let mut changes = Vec::new();\n        merge_observability(&mut base, &override_config, \"test\", &mut changes);\n\n        assert_eq!(base.metrics_enabled, false);\n        assert_eq!(base.tracing_enabled, false);\n        assert_eq!(base.logging_level, \"debug\");\n        assert_eq!(base.metrics_port, 9999);\n        assert_eq!(changes.len(), 4);\n    }\n\n    #[test]\n    fn test_merge_with_default_values() {\n        let mut base = PostgresConfig {\n            host: \"localhost\".to_string(),\n            port: 5432,\n            database: \"memory_knowledge\".to_string(),\n            username: \"postgres\".to_string(),\n            password: \"\".to_string(),\n            pool_size: 10,\n            timeout_seconds: 30,\n        };\n\n        let override_config = PostgresConfig {\n            host: \"localhost\".to_string(),\n            port: 5432,\n            database: \"memory_knowledge\".to_string(),\n            username: \"postgres\".to_string(),\n            password: \"\".to_string(),\n            pool_size: 10,\n            timeout_seconds: 30,\n        };\n\n        let mut changes = Vec::new();\n        merge_postgres(&mut base, &override_config, \"test\", &mut changes);\n\n        assert_eq!(changes.len(), 0);\n    }\n\n    #[test]\n    fn test_merge_tools_without_api_key() {\n        let mut base = ToolConfig {\n            api_key: None,\n            ..Default::default()\n        };\n\n        let override_config = ToolConfig {\n            api_key: None,\n            ..Default::default()\n        };\n\n        let mut changes = Vec::new();\n        merge_tools(&mut base, &override_config, \"test\", &mut changes);\n\n        assert_eq!(base.api_key, None);\n        assert_eq!(changes.len(), 0);\n    }\n\n    #[test]\n    fn test_merge_tools_remove_api_key() {\n        let mut base = ToolConfig {\n            api_key: Some(\"old_key\".to_string()),\n            ..Default::default()\n        };\n\n        let override_config = ToolConfig {\n            api_key: None,\n            ..Default::default()\n        };\n\n        let mut changes = Vec::new();\n        merge_tools(&mut base, &override_config, \"test\", &mut changes);\n\n        assert_eq!(base.api_key, Some(\"old_key\".to_string()));\n        assert_eq!(changes.len(), 0);\n    }\n\n    #[test]\n    fn test_merge_configs_no_changes() {\n        let defaults = Config::default();\n        let file_config = Config::default();\n        let env_config = Config::default();\n\n        let merged = merge_configs(\n            defaults,\n            file_config,\n            \"file\",\n            env_config,\n            \"env\",\n            None,\n            \"cli\",\n        );\n\n        assert_eq!(merged, Config::default());\n    }\n\n    #[test]\n    fn test_merge_configs_partial_changes() {\n        let defaults = Config {\n            providers: ProviderConfig {\n                postgres: PostgresConfig {\n                    host: \"default_host\".to_string(),\n                    port: 5432,\n                    ..Default::default()\n                },\n                qdrant: QdrantConfig {\n                    host: \"default_qdrant\".to_string(),\n                    ..Default::default()\n                },\n                ..Default::default()\n            },\n            ..Default::default()\n        };\n\n        let file_config = Config {\n            providers: ProviderConfig {\n                postgres: PostgresConfig {\n                    host: \"file_host\".to_string(),\n                    ..Default::default()\n                },\n                ..Default::default()\n            },\n            ..Default::default()\n        };\n\n        let env_config = Config {\n            providers: ProviderConfig {\n                qdrant: QdrantConfig {\n                    host: \"env_qdrant\".to_string(),\n                    ..Default::default()\n                },\n                ..Default::default()\n            },\n            ..Default::default()\n        };\n\n        let merged = merge_configs(\n            defaults,\n            file_config,\n            \"file\",\n            env_config,\n            \"env\",\n            None,\n            \"cli\",\n        );\n\n        assert_eq!(merged.providers.postgres.host, \"file_host\");\n        assert_eq!(merged.providers.postgres.port, 5432);\n        assert_eq!(merged.providers.qdrant.host, \"env_qdrant\");\n    }\n\n    #[test]\n    fn test_merge_postgres_no_changes() {\n        let mut base = PostgresConfig::default();\n        let override_config = PostgresConfig::default();\n        let mut changes = Vec::new();\n\n        merge_postgres(&mut base, &override_config, \"test\", &mut changes);\n\n        assert_eq!(changes.len(), 0);\n        assert_eq!(base, PostgresConfig::default());\n    }\n\n    #[test]\n    fn test_merge_qdrant_no_changes() {\n        let mut base = QdrantConfig::default();\n        let override_config = QdrantConfig::default();\n        let mut changes = Vec::new();\n\n        merge_qdrant(&mut base, &override_config, \"test\", &mut changes);\n\n        assert_eq!(changes.len(), 0);\n        assert_eq!(base, QdrantConfig::default());\n    }\n\n    #[test]\n    fn test_merge_redis_no_changes() {\n        let mut base = RedisConfig::default();\n        let override_config = RedisConfig::default();\n        let mut changes = Vec::new();\n\n        merge_redis(&mut base, &override_config, \"test\", &mut changes);\n\n        assert_eq!(changes.len(), 0);\n        assert_eq!(base, RedisConfig::default());\n    }\n\n    #[test]\n    fn test_merge_sync_no_changes() {\n        let mut base = SyncConfig::default();\n        let override_config = SyncConfig::default();\n        let mut changes = Vec::new();\n\n        merge_sync(&mut base, &override_config, \"test\", &mut changes);\n\n        assert_eq!(changes.len(), 0);\n        assert_eq!(base, SyncConfig::default());\n    }\n\n    #[test]\n    fn test_merge_tools_no_changes() {\n        let mut base = ToolConfig::default();\n        let override_config = ToolConfig::default();\n        let mut changes = Vec::new();\n\n        merge_tools(&mut base, &override_config, \"test\", &mut changes);\n\n        assert_eq!(changes.len(), 0);\n        assert_eq!(base, ToolConfig::default());\n    }\n\n    #[test]\n    fn test_merge_observability_no_changes() {\n        let mut base = ObservabilityConfig::default();\n        let override_config = ObservabilityConfig::default();\n        let mut changes = Vec::new();\n\n        merge_observability(&mut base, &override_config, \"test\", &mut changes);\n\n        assert_eq!(changes.len(), 0);\n        assert_eq!(base, ObservabilityConfig::default());\n    }\n\n    #[test]\n    fn test_merge_all_fields() {\n        let base = Config::default();\n        let mut override_config = Config::default();\n\n        override_config.providers.postgres.host = \"new_pg_host\".to_string();\n        override_config.providers.postgres.port = 5433;\n        override_config.providers.postgres.database = \"new_pg_db\".to_string();\n        override_config.providers.postgres.username = \"new_pg_user\".to_string();\n        override_config.providers.postgres.password = \"new_pg_pass\".to_string();\n        override_config.providers.postgres.pool_size = 20;\n        override_config.providers.postgres.timeout_seconds = 60;\n\n        override_config.providers.qdrant.host = \"new_qdrant_host\".to_string();\n        override_config.providers.qdrant.port = 6334;\n        override_config.providers.qdrant.collection = \"new_collection\".to_string();\n        override_config.providers.qdrant.timeout_seconds = 60;\n\n        override_config.providers.redis.host = \"new_redis_host\".to_string();\n        override_config.providers.redis.port = 6380;\n        override_config.providers.redis.db = 1;\n        override_config.providers.redis.pool_size = 20;\n        override_config.providers.redis.timeout_seconds = 60;\n\n        override_config.sync.enabled = false;\n        override_config.sync.sync_interval_seconds = 120;\n        override_config.sync.batch_size = 200;\n        override_config.sync.checkpoint_enabled = false;\n        override_config.sync.conflict_resolution = \"prefer_memory\".to_string();\n\n        override_config.tools.enabled = false;\n        override_config.tools.host = \"new_tool_host\".to_string();\n        override_config.tools.port = 8081;\n        override_config.tools.api_key = Some(\"new_api_key\".to_string());\n        override_config.tools.rate_limit_requests_per_minute = 120;\n\n        override_config.observability.metrics_enabled = false;\n        override_config.observability.tracing_enabled = false;\n        override_config.observability.logging_level = \"debug\".to_string();\n        override_config.observability.metrics_port = 9091;\n\n        let merged = merge_configs(\n            base,\n            override_config.clone(),\n            \"file\",\n            Config::default(),\n            \"env\",\n            None,\n            \"cli\",\n        );\n\n        assert_eq!(merged.providers.postgres.host, \"new_pg_host\");\n        assert_eq!(merged.providers.postgres.port, 5433);\n        assert_eq!(merged.providers.postgres.database, \"new_pg_db\");\n        assert_eq!(merged.providers.postgres.username, \"new_pg_user\");\n        assert_eq!(merged.providers.postgres.password, \"new_pg_pass\");\n        assert_eq!(merged.providers.postgres.pool_size, 20);\n        assert_eq!(merged.providers.postgres.timeout_seconds, 60);\n\n        assert_eq!(merged.providers.qdrant.host, \"new_qdrant_host\");\n        assert_eq!(merged.providers.qdrant.port, 6334);\n        assert_eq!(merged.providers.qdrant.collection, \"new_collection\");\n        assert_eq!(merged.providers.qdrant.timeout_seconds, 60);\n\n        assert_eq!(merged.providers.redis.host, \"new_redis_host\");\n        assert_eq!(merged.providers.redis.port, 6380);\n        assert_eq!(merged.providers.redis.db, 1);\n        assert_eq!(merged.providers.redis.pool_size, 20);\n        assert_eq!(merged.providers.redis.timeout_seconds, 60);\n\n        assert_eq!(merged.sync.enabled, false);\n        assert_eq!(merged.sync.sync_interval_seconds, 120);\n        assert_eq!(merged.sync.batch_size, 200);\n        assert_eq!(merged.sync.checkpoint_enabled, false);\n        assert_eq!(merged.sync.conflict_resolution, \"prefer_memory\");\n\n        assert_eq!(merged.tools.enabled, false);\n        assert_eq!(merged.tools.host, \"new_tool_host\");\n        assert_eq!(merged.tools.port, 8081);\n        assert_eq!(merged.tools.api_key, Some(\"new_api_key\".to_string()));\n        assert_eq!(merged.tools.rate_limit_requests_per_minute, 120);\n\n        assert_eq!(merged.observability.metrics_enabled, false);\n        assert_eq!(merged.observability.tracing_enabled, false);\n        assert_eq!(merged.observability.logging_level, \"debug\");\n        assert_eq!(merged.observability.metrics_port, 9091);\n    }\n\n    #[test]\n    fn test_merge_tools_api_key_scenarios() {\n        let mut base_val = ToolConfig {\n            api_key: None,\n            ..Default::default()\n        };\n        let override_config = ToolConfig {\n            api_key: Some(\"new_key\".to_string()),\n            ..Default::default()\n        };\n        let mut changes = Vec::new();\n        merge_tools(&mut base_val, &override_config, \"test\", &mut changes);\n        assert_eq!(base_val.api_key, Some(\"new_key\".to_string()));\n        assert_eq!(changes.len(), 1);\n        assert!(changes[0].contains(\"api_key = ***\"));\n\n        let mut base_val = ToolConfig {\n            api_key: Some(\"old_key\".to_string()),\n            ..Default::default()\n        };\n        let override_config = ToolConfig {\n            api_key: None,\n            ..Default::default()\n        };\n        let mut changes = Vec::new();\n        merge_tools(&mut base_val, &override_config, \"test\", &mut changes);\n        assert_eq!(base_val.api_key, Some(\"old_key\".to_string()));\n        assert_eq!(changes.len(), 0);\n\n        let base_val = ToolConfig {\n            api_key: Some(\"same_key\".to_string()),\n            ..Default::default()\n        };\n        let override_config = ToolConfig {\n            api_key: Some(\"same_key\".to_string()),\n            ..Default::default()\n        };\n        let mut changes = Vec::new();\n        let mut base_mut = base_val;\n        merge_tools(&mut base_mut, &override_config, \"test\", &mut changes);\n        assert_eq!(changes.len(), 0);\n    }\n\n    #[test]\n    fn test_merge_postgres_non_default_base() {\n        let mut base = PostgresConfig {\n            host: \"not_localhost\".to_string(),\n            port: 5433,\n            database: \"not_memory_knowledge\".to_string(),\n            username: \"not_postgres\".to_string(),\n            password: \"old_password\".to_string(),\n            pool_size: 20,\n            timeout_seconds: 60,\n        };\n\n        let override_config = PostgresConfig {\n            host: \"even_newer_host\".to_string(),\n            port: 5434,\n            database: \"even_newer_db\".to_string(),\n            username: \"even_newer_user\".to_string(),\n            password: \"even_newer_password\".to_string(),\n            pool_size: 30,\n            timeout_seconds: 90,\n        };\n\n        let mut changes = Vec::new();\n        merge_postgres(&mut base, &override_config, \"test\", &mut changes);\n\n        assert_eq!(base.host, \"even_newer_host\");\n        assert_eq!(base.port, 5434);\n        assert_eq!(base.database, \"even_newer_db\");\n        assert_eq!(base.username, \"even_newer_user\");\n        assert_eq!(base.password, \"even_newer_password\");\n        assert_eq!(base.pool_size, 30);\n        assert_eq!(base.timeout_seconds, 90);\n        assert_eq!(changes.len(), 7);\n    }\n}\n","traces":[{"line":41,"address":[],"length":0,"stats":{"Line":5}},{"line":50,"address":[],"length":0,"stats":{"Line":10}},{"line":52,"address":[],"length":0,"stats":{"Line":25}},{"line":53,"address":[],"length":0,"stats":{"Line":25}},{"line":55,"address":[],"length":0,"stats":{"Line":7}},{"line":56,"address":[],"length":0,"stats":{"Line":4}},{"line":59,"address":[],"length":0,"stats":{"Line":5}},{"line":62,"address":[],"length":0,"stats":{"Line":11}},{"line":63,"address":[],"length":0,"stats":{"Line":22}},{"line":65,"address":[],"length":0,"stats":{"Line":33}},{"line":67,"address":[],"length":0,"stats":{"Line":11}},{"line":68,"address":[],"length":0,"stats":{"Line":11}},{"line":69,"address":[],"length":0,"stats":{"Line":11}},{"line":70,"address":[],"length":0,"stats":{"Line":11}},{"line":72,"address":[],"length":0,"stats":{"Line":16}},{"line":73,"address":[],"length":0,"stats":{"Line":5}},{"line":76,"address":[],"length":0,"stats":{"Line":22}},{"line":77,"address":[],"length":0,"stats":{"Line":33}},{"line":79,"address":[],"length":0,"stats":{"Line":11}},{"line":80,"address":[],"length":0,"stats":{"Line":11}},{"line":81,"address":[],"length":0,"stats":{"Line":11}},{"line":82,"address":[],"length":0,"stats":{"Line":11}},{"line":84,"address":[],"length":0,"stats":{"Line":13}},{"line":85,"address":[],"length":0,"stats":{"Line":6}},{"line":86,"address":[],"length":0,"stats":{"Line":4}},{"line":89,"address":[],"length":0,"stats":{"Line":22}},{"line":90,"address":[],"length":0,"stats":{"Line":33}},{"line":92,"address":[],"length":0,"stats":{"Line":11}},{"line":93,"address":[],"length":0,"stats":{"Line":11}},{"line":94,"address":[],"length":0,"stats":{"Line":11}},{"line":95,"address":[],"length":0,"stats":{"Line":11}},{"line":97,"address":[],"length":0,"stats":{"Line":12}},{"line":98,"address":[],"length":0,"stats":{"Line":3}},{"line":99,"address":[],"length":0,"stats":{"Line":2}},{"line":102,"address":[],"length":0,"stats":{"Line":22}},{"line":103,"address":[],"length":0,"stats":{"Line":33}},{"line":105,"address":[],"length":0,"stats":{"Line":11}},{"line":106,"address":[],"length":0,"stats":{"Line":11}},{"line":107,"address":[],"length":0,"stats":{"Line":11}},{"line":108,"address":[],"length":0,"stats":{"Line":11}},{"line":110,"address":[],"length":0,"stats":{"Line":12}},{"line":111,"address":[],"length":0,"stats":{"Line":3}},{"line":112,"address":[],"length":0,"stats":{"Line":2}},{"line":115,"address":[],"length":0,"stats":{"Line":22}},{"line":116,"address":[],"length":0,"stats":{"Line":33}},{"line":118,"address":[],"length":0,"stats":{"Line":11}},{"line":119,"address":[],"length":0,"stats":{"Line":11}},{"line":120,"address":[],"length":0,"stats":{"Line":11}},{"line":121,"address":[],"length":0,"stats":{"Line":11}},{"line":123,"address":[],"length":0,"stats":{"Line":12}},{"line":124,"address":[],"length":0,"stats":{"Line":3}},{"line":125,"address":[],"length":0,"stats":{"Line":2}},{"line":128,"address":[],"length":0,"stats":{"Line":22}},{"line":129,"address":[],"length":0,"stats":{"Line":33}},{"line":131,"address":[],"length":0,"stats":{"Line":11}},{"line":132,"address":[],"length":0,"stats":{"Line":11}},{"line":133,"address":[],"length":0,"stats":{"Line":11}},{"line":134,"address":[],"length":0,"stats":{"Line":11}},{"line":136,"address":[],"length":0,"stats":{"Line":12}},{"line":137,"address":[],"length":0,"stats":{"Line":3}},{"line":138,"address":[],"length":0,"stats":{"Line":2}},{"line":141,"address":[],"length":0,"stats":{"Line":11}},{"line":142,"address":[],"length":0,"stats":{"Line":6}},{"line":145,"address":[],"length":0,"stats":{"Line":11}},{"line":148,"address":[],"length":0,"stats":{"Line":15}},{"line":154,"address":[],"length":0,"stats":{"Line":27}},{"line":155,"address":[],"length":0,"stats":{"Line":24}},{"line":156,"address":[],"length":0,"stats":{"Line":12}},{"line":157,"address":[],"length":0,"stats":{"Line":6}},{"line":159,"address":[],"length":0,"stats":{"Line":12}},{"line":161,"address":[],"length":0,"stats":{"Line":23}},{"line":162,"address":[],"length":0,"stats":{"Line":16}},{"line":163,"address":[],"length":0,"stats":{"Line":4}},{"line":164,"address":[],"length":0,"stats":{"Line":4}},{"line":166,"address":[],"length":0,"stats":{"Line":4}},{"line":168,"address":[],"length":0,"stats":{"Line":21}},{"line":169,"address":[],"length":0,"stats":{"Line":12}},{"line":170,"address":[],"length":0,"stats":{"Line":6}},{"line":171,"address":[],"length":0,"stats":{"Line":3}},{"line":173,"address":[],"length":0,"stats":{"Line":6}},{"line":175,"address":[],"length":0,"stats":{"Line":19}},{"line":176,"address":[],"length":0,"stats":{"Line":8}},{"line":177,"address":[],"length":0,"stats":{"Line":4}},{"line":178,"address":[],"length":0,"stats":{"Line":2}},{"line":180,"address":[],"length":0,"stats":{"Line":4}},{"line":182,"address":[],"length":0,"stats":{"Line":19}},{"line":183,"address":[],"length":0,"stats":{"Line":10}},{"line":184,"address":[],"length":0,"stats":{"Line":4}},{"line":186,"address":[],"length":0,"stats":{"Line":19}},{"line":187,"address":[],"length":0,"stats":{"Line":8}},{"line":188,"address":[],"length":0,"stats":{"Line":2}},{"line":189,"address":[],"length":0,"stats":{"Line":2}},{"line":191,"address":[],"length":0,"stats":{"Line":2}},{"line":193,"address":[],"length":0,"stats":{"Line":15}},{"line":194,"address":[],"length":0,"stats":{"Line":2}},{"line":196,"address":[],"length":0,"stats":{"Line":8}},{"line":197,"address":[],"length":0,"stats":{"Line":2}},{"line":198,"address":[],"length":0,"stats":{"Line":2}},{"line":200,"address":[],"length":0,"stats":{"Line":2}},{"line":204,"address":[],"length":0,"stats":{"Line":13}},{"line":210,"address":[],"length":0,"stats":{"Line":19}},{"line":211,"address":[],"length":0,"stats":{"Line":15}},{"line":212,"address":[],"length":0,"stats":{"Line":6}},{"line":214,"address":[],"length":0,"stats":{"Line":17}},{"line":215,"address":[],"length":0,"stats":{"Line":8}},{"line":216,"address":[],"length":0,"stats":{"Line":2}},{"line":218,"address":[],"length":0,"stats":{"Line":13}},{"line":219,"address":[],"length":0,"stats":{"Line":2}},{"line":221,"address":[],"length":0,"stats":{"Line":8}},{"line":222,"address":[],"length":0,"stats":{"Line":4}},{"line":223,"address":[],"length":0,"stats":{"Line":2}},{"line":225,"address":[],"length":0,"stats":{"Line":4}},{"line":227,"address":[],"length":0,"stats":{"Line":13}},{"line":228,"address":[],"length":0,"stats":{"Line":1}},{"line":230,"address":[],"length":0,"stats":{"Line":4}},{"line":231,"address":[],"length":0,"stats":{"Line":1}},{"line":232,"address":[],"length":0,"stats":{"Line":1}},{"line":234,"address":[],"length":0,"stats":{"Line":1}},{"line":238,"address":[],"length":0,"stats":{"Line":13}},{"line":244,"address":[],"length":0,"stats":{"Line":17}},{"line":245,"address":[],"length":0,"stats":{"Line":10}},{"line":246,"address":[],"length":0,"stats":{"Line":4}},{"line":248,"address":[],"length":0,"stats":{"Line":17}},{"line":249,"address":[],"length":0,"stats":{"Line":8}},{"line":250,"address":[],"length":0,"stats":{"Line":2}},{"line":252,"address":[],"length":0,"stats":{"Line":17}},{"line":253,"address":[],"length":0,"stats":{"Line":8}},{"line":254,"address":[],"length":0,"stats":{"Line":2}},{"line":256,"address":[],"length":0,"stats":{"Line":15}},{"line":257,"address":[],"length":0,"stats":{"Line":4}},{"line":258,"address":[],"length":0,"stats":{"Line":1}},{"line":259,"address":[],"length":0,"stats":{"Line":1}},{"line":261,"address":[],"length":0,"stats":{"Line":1}},{"line":263,"address":[],"length":0,"stats":{"Line":13}},{"line":264,"address":[],"length":0,"stats":{"Line":1}},{"line":266,"address":[],"length":0,"stats":{"Line":4}},{"line":267,"address":[],"length":0,"stats":{"Line":1}},{"line":268,"address":[],"length":0,"stats":{"Line":1}},{"line":270,"address":[],"length":0,"stats":{"Line":1}},{"line":274,"address":[],"length":0,"stats":{"Line":13}},{"line":280,"address":[],"length":0,"stats":{"Line":17}},{"line":281,"address":[],"length":0,"stats":{"Line":8}},{"line":282,"address":[],"length":0,"stats":{"Line":2}},{"line":284,"address":[],"length":0,"stats":{"Line":13}},{"line":285,"address":[],"length":0,"stats":{"Line":2}},{"line":287,"address":[],"length":0,"stats":{"Line":8}},{"line":288,"address":[],"length":0,"stats":{"Line":2}},{"line":289,"address":[],"length":0,"stats":{"Line":2}},{"line":291,"address":[],"length":0,"stats":{"Line":2}},{"line":293,"address":[],"length":0,"stats":{"Line":15}},{"line":294,"address":[],"length":0,"stats":{"Line":4}},{"line":295,"address":[],"length":0,"stats":{"Line":1}},{"line":297,"address":[],"length":0,"stats":{"Line":13}},{"line":298,"address":[],"length":0,"stats":{"Line":1}},{"line":300,"address":[],"length":0,"stats":{"Line":4}},{"line":301,"address":[],"length":0,"stats":{"Line":1}},{"line":302,"address":[],"length":0,"stats":{"Line":1}},{"line":304,"address":[],"length":0,"stats":{"Line":1}},{"line":306,"address":[],"length":0,"stats":{"Line":13}},{"line":307,"address":[],"length":0,"stats":{"Line":1}},{"line":309,"address":[],"length":0,"stats":{"Line":4}},{"line":310,"address":[],"length":0,"stats":{"Line":2}},{"line":311,"address":[],"length":0,"stats":{"Line":1}},{"line":313,"address":[],"length":0,"stats":{"Line":2}},{"line":314,"address":[],"length":0,"stats":{"Line":1}},{"line":318,"address":[],"length":0,"stats":{"Line":18}},{"line":324,"address":[],"length":0,"stats":{"Line":20}},{"line":325,"address":[],"length":0,"stats":{"Line":4}},{"line":326,"address":[],"length":0,"stats":{"Line":1}},{"line":328,"address":[],"length":0,"stats":{"Line":20}},{"line":329,"address":[],"length":0,"stats":{"Line":5}},{"line":330,"address":[],"length":0,"stats":{"Line":2}},{"line":332,"address":[],"length":0,"stats":{"Line":20}},{"line":333,"address":[],"length":0,"stats":{"Line":4}},{"line":334,"address":[],"length":0,"stats":{"Line":1}},{"line":336,"address":[],"length":0,"stats":{"Line":40}},{"line":337,"address":[],"length":0,"stats":{"Line":6}},{"line":338,"address":[],"length":0,"stats":{"Line":8}},{"line":339,"address":[],"length":0,"stats":{"Line":4}},{"line":340,"address":[],"length":0,"stats":{"Line":4}},{"line":342,"address":[],"length":0,"stats":{"Line":0}},{"line":344,"address":[],"length":0,"stats":{"Line":9}},{"line":346,"address":[],"length":0,"stats":{"Line":18}},{"line":347,"address":[],"length":0,"stats":{"Line":1}},{"line":349,"address":[],"length":0,"stats":{"Line":4}},{"line":350,"address":[],"length":0,"stats":{"Line":1}},{"line":351,"address":[],"length":0,"stats":{"Line":1}},{"line":353,"address":[],"length":0,"stats":{"Line":1}},{"line":357,"address":[],"length":0,"stats":{"Line":13}},{"line":363,"address":[],"length":0,"stats":{"Line":17}},{"line":364,"address":[],"length":0,"stats":{"Line":8}},{"line":365,"address":[],"length":0,"stats":{"Line":2}},{"line":366,"address":[],"length":0,"stats":{"Line":2}},{"line":368,"address":[],"length":0,"stats":{"Line":2}},{"line":370,"address":[],"length":0,"stats":{"Line":17}},{"line":371,"address":[],"length":0,"stats":{"Line":8}},{"line":372,"address":[],"length":0,"stats":{"Line":2}},{"line":373,"address":[],"length":0,"stats":{"Line":2}},{"line":375,"address":[],"length":0,"stats":{"Line":2}},{"line":377,"address":[],"length":0,"stats":{"Line":13}},{"line":378,"address":[],"length":0,"stats":{"Line":2}},{"line":380,"address":[],"length":0,"stats":{"Line":8}},{"line":381,"address":[],"length":0,"stats":{"Line":4}},{"line":382,"address":[],"length":0,"stats":{"Line":2}},{"line":384,"address":[],"length":0,"stats":{"Line":4}},{"line":385,"address":[],"length":0,"stats":{"Line":2}},{"line":387,"address":[],"length":0,"stats":{"Line":17}},{"line":388,"address":[],"length":0,"stats":{"Line":8}},{"line":389,"address":[],"length":0,"stats":{"Line":2}},{"line":390,"address":[],"length":0,"stats":{"Line":2}},{"line":392,"address":[],"length":0,"stats":{"Line":2}}],"covered":210,"coverable":211},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","procedural.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","providers.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","qdrant.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","redis.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","repository.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","state.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","tools.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","validator.rs"],"content":"//! # Configuration Validation\n//!\n//! Provides validation for all configuration structures using the `validator` crate.\n\nuse crate::config::{\n    Config, ObservabilityConfig, PostgresConfig, ProviderConfig, QdrantConfig, RedisConfig,\n    SyncConfig, ToolConfig,\n};\nuse validator::Validate;\n\n/// Validate configuration structure.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Validates all configuration fields using the `validator` crate.\n/// Ensures all required fields are present and within valid ranges.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use memory_knowledge_config::{Config, validate};\n///\n/// let config = Config::default();\n/// match validate(&config) {\n///     Ok(()) => println!(\"Configuration is valid\"),\n///     Err(errors) => println!(\"Validation errors: {:?}\", errors),\n/// }\n/// ```\n///\n/// ## Validation Rules\n/// ### General\n/// - All string fields: minimum length 1, maximum length varies\n///\n/// ### PostgreSQL\n/// - `host`: 1-255 characters\n/// - `port`: 1-65535\n/// - `database`: 1-63 characters\n/// - `username`: 1-63 characters\n/// - `password`: 1+ characters\n/// - `pool_size`: 1-100\n/// - `timeout_seconds`: 1-300\n///\n/// ### Qdrant\n/// - `host`: 1-255 characters\n/// - `port`: 1-65535\n/// - `collection`: 1-255 characters\n/// - `timeout_seconds`: 1-300\n///\n/// ### Redis\n/// - `host`: 1-255 characters\n/// - `port`: 1-65535\n/// - `db`: 0-15\n/// - `pool_size`: 1-100\n/// - `timeout_seconds`: 1-300\n///\n/// ### Sync\n/// - `sync_interval_seconds`: 10-3600\n/// - `batch_size`: 1-1000\n/// - `conflict_resolution`: must be \"prefer_knowledge\", \"prefer_memory\", or \"manual\"\n///\n/// ### Tools\n/// - `host`: 1-255 characters\n/// - `port`: 1-65535\n/// - `rate_limit_requests_per_minute`: 1-1000\n///\n/// ### Observability\n/// - `logging_level`: must be \"trace\", \"debug\", \"info\", \"warn\", or \"error\"\n/// - `metrics_port`: 1-65535\npub fn validate(config: &Config) -> Result<(), validator::ValidationErrors> {\n    config.validate()\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_validate_valid_config() {\n        let config = Config::default();\n        assert!(validate(&config).is_ok());\n    }\n\n    #[test]\n    fn test_validate_invalid_postgres_host() {\n        let mut config = Config::default();\n        config.providers.postgres.host = \"\".to_string();\n        assert!(validate(&config).is_err());\n    }\n\n    #[test]\n    fn test_validate_invalid_postgres_port() {\n        let mut config = Config::default();\n        config.providers.postgres.port = 0;\n        assert!(validate(&config).is_err());\n    }\n\n    #[test]\n    fn test_validate_invalid_qdrant_port() {\n        let mut config = Config::default();\n        config.providers.qdrant.port = 0;\n        assert!(validate(&config).is_err());\n    }\n\n    #[test]\n    fn test_validate_invalid_redis_db() {\n        let mut config = Config::default();\n        config.providers.redis.db = 16;\n        assert!(validate(&config).is_err());\n    }\n\n    #[test]\n    fn test_validate_invalid_sync_interval() {\n        let mut config = Config::default();\n        config.sync.sync_interval_seconds = 5;\n        assert!(validate(&config).is_err());\n    }\n\n    #[test]\n    fn test_validate_invalid_sync_interval_high() {\n        let mut config = Config::default();\n        config.sync.sync_interval_seconds = 4000;\n        assert!(validate(&config).is_err());\n    }\n\n    #[test]\n    fn test_validate_invalid_batch_size() {\n        let mut config = Config::default();\n        config.sync.batch_size = 0;\n        assert!(validate(&config).is_err());\n    }\n\n    #[test]\n    fn test_validate_invalid_conflict_resolution() {\n        let mut config = Config::default();\n        config.sync.conflict_resolution = \"invalid\".to_string();\n        assert!(validate(&config).is_err());\n    }\n\n    #[test]\n    fn test_validate_valid_conflict_resolution() {\n        let mut config = Config::default();\n        config.sync.conflict_resolution = \"prefer_memory\".to_string();\n        assert!(validate(&config).is_ok());\n    }\n\n    #[test]\n    fn test_validate_invalid_logging_level() {\n        let mut config = Config::default();\n        config.observability.logging_level = \"invalid\".to_string();\n        assert!(validate(&config).is_err());\n    }\n\n    #[test]\n    fn test_validate_valid_logging_levels() {\n        for level in [\"trace\", \"debug\", \"info\", \"warn\", \"error\"] {\n            let mut config = Config::default();\n            config.observability.logging_level = level.to_string();\n            assert!(validate(&config).is_ok());\n        }\n    }\n\n    #[test]\n    fn test_validate_invalid_tools_rate_limit() {\n        let mut config = Config::default();\n        config.tools.rate_limit_requests_per_minute = 0;\n        assert!(validate(&config).is_err());\n    }\n\n    #[test]\n    fn test_validate_postgres_pool_size_out_of_range() {\n        let mut config = Config::default();\n        config.providers.postgres.pool_size = 101;\n        assert!(validate(&config).is_err());\n    }\n\n    #[test]\n    fn test_validate_postgres_timeout_out_of_range() {\n        let mut config = Config::default();\n        config.providers.postgres.timeout_seconds = 301;\n        assert!(validate(&config).is_err());\n    }\n\n    #[test]\n    fn test_validate_qdrant_collection_empty() {\n        let mut config = Config::default();\n        config.providers.qdrant.collection = \"\".to_string();\n        assert!(validate(&config).is_err());\n    }\n\n    #[test]\n    fn test_validate_redis_host_empty() {\n        let mut config = Config::default();\n        config.providers.redis.host = \"\".to_string();\n        assert!(validate(&config).is_err());\n    }\n\n    #[test]\n    fn test_validate_tools_port_zero() {\n        let mut config = Config::default();\n        config.tools.port = 0;\n        assert!(validate(&config).is_err());\n    }\n\n    #[test]\n    fn test_validate_observability_metrics_port_zero() {\n        let mut config = Config::default();\n        config.observability.metrics_port = 0;\n        assert!(validate(&config).is_err());\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","working.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","context","src","cedar.rs"],"content":"//! Cedar Agent client for authorization and entity resolution.\n//!\n//! This module provides a client for interacting with the Cedar Agent sidecar\n//! that runs alongside the application (via OPAL Client). The Cedar Agent\n//! maintains policies and entity data synchronized by OPAL.\n//!\n//! # Architecture\n//!\n//! ```text\n//! \n//!   OPAL Client (Sidecar)                                  \n//!      \n//!     Cedar Agent (localhost:8180)                       \n//!     - GET /v1/data (entities)                          \n//!     - POST /v1/is_authorized (authz check)            \n//!      \n//! \n//!                           \n//!                            HTTP (localhost)\n//!                           \n//! \n//!   Aeterna Application                                     \n//!   - CedarClient queries local Cedar Agent                \n//!   - Low latency (no network hop)                         \n//! \n//! ```\n//!\n//! # Example\n//!\n//! ```rust,ignore\n//! use context::cedar::{CedarClient, CedarConfig};\n//!\n//! let config = CedarConfig::default(); // localhost:8180\n//! let client = CedarClient::new(config);\n//!\n//! // Resolve user by email\n//! let user = client.resolve_user_by_email(\"alice@acme.com\").await?;\n//!\n//! // Check authorization\n//! let allowed = client.check_authorization(\n//!     \"Aeterna::User::\\\"user-uuid\\\"\",\n//!     \"Aeterna::Action::\\\"ViewKnowledge\\\"\",\n//!     \"Aeterna::Project::\\\"project-uuid\\\"\",\n//!     None,\n//! ).await?;\n//! ```\n\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse std::time::Duration;\n\nuse reqwest::Client;\nuse serde::{Deserialize, Serialize};\nuse thiserror::Error;\nuse tokio::sync::RwLock;\nuse tracing::{debug, trace, warn};\n\n// ============================================================================\n// Error Types\n// ============================================================================\n\n/// Errors that can occur when interacting with Cedar Agent.\n#[derive(Debug, Error)]\npub enum CedarError {\n    /// HTTP request failed.\n    #[error(\"HTTP request failed: {0}\")]\n    HttpError(#[from] reqwest::Error),\n\n    /// Cedar Agent returned an error response.\n    #[error(\"Cedar Agent error: {status} - {message}\")]\n    AgentError { status: u16, message: String },\n\n    /// Failed to parse Cedar Agent response.\n    #[error(\"Failed to parse response: {0}\")]\n    ParseError(String),\n\n    /// Entity not found.\n    #[error(\"Entity not found: {entity_type}::{id}\")]\n    EntityNotFound { entity_type: String, id: String },\n\n    /// Authorization denied.\n    #[error(\"Authorization denied: {reason}\")]\n    AuthorizationDenied { reason: String },\n\n    /// Cedar Agent is unavailable (circuit breaker open).\n    #[error(\"Cedar Agent unavailable: {0}\")]\n    Unavailable(String),\n\n    /// Configuration error.\n    #[error(\"Configuration error: {0}\")]\n    ConfigError(String),\n}\n\npub type Result<T> = std::result::Result<T, CedarError>;\n\n// ============================================================================\n// Configuration\n// ============================================================================\n\n/// Configuration for Cedar Agent client.\n#[derive(Debug, Clone)]\npub struct CedarConfig {\n    /// Base URL of the Cedar Agent (default: http://localhost:8180).\n    pub base_url: String,\n\n    /// Request timeout in seconds.\n    pub timeout_secs: u64,\n\n    /// Maximum number of retries for transient failures.\n    pub max_retries: u32,\n\n    /// Enable local caching of entities.\n    pub cache_enabled: bool,\n\n    /// Cache TTL in seconds.\n    pub cache_ttl_secs: u64,\n\n    /// Circuit breaker failure threshold.\n    pub circuit_breaker_threshold: u32,\n\n    /// Circuit breaker reset timeout in seconds.\n    pub circuit_breaker_reset_secs: u64,\n}\n\nimpl Default for CedarConfig {\n    fn default() -> Self {\n        Self {\n            base_url: \"http://localhost:8180\".to_string(),\n            timeout_secs: 5,\n            max_retries: 3,\n            cache_enabled: true,\n            cache_ttl_secs: 300, // 5 minutes\n            circuit_breaker_threshold: 5,\n            circuit_breaker_reset_secs: 30,\n        }\n    }\n}\n\nimpl CedarConfig {\n    /// Create config from environment variables.\n    ///\n    /// Reads:\n    /// - `CEDAR_AGENT_URL` (default: http://localhost:8180)\n    /// - `CEDAR_AGENT_TIMEOUT` (default: 5)\n    /// - `CEDAR_AGENT_CACHE_ENABLED` (default: true)\n    #[must_use]\n    pub fn from_env() -> Self {\n        let mut config = Self::default();\n\n        if let Ok(url) = std::env::var(\"CEDAR_AGENT_URL\") {\n            config.base_url = url;\n        }\n\n        if let Ok(timeout) = std::env::var(\"CEDAR_AGENT_TIMEOUT\") {\n            if let Ok(secs) = timeout.parse() {\n                config.timeout_secs = secs;\n            }\n        }\n\n        if let Ok(cache) = std::env::var(\"CEDAR_AGENT_CACHE_ENABLED\") {\n            config.cache_enabled = cache.parse().unwrap_or(true);\n        }\n\n        config\n    }\n\n    /// Create config for testing (shorter timeouts).\n    #[must_use]\n    pub fn for_testing() -> Self {\n        Self {\n            timeout_secs: 1,\n            max_retries: 1,\n            cache_enabled: false,\n            circuit_breaker_threshold: 2,\n            circuit_breaker_reset_secs: 5,\n            ..Default::default()\n        }\n    }\n}\n\n// ============================================================================\n// Cedar Agent API Types\n// ============================================================================\n\n/// Entity UID in Cedar format.\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]\npub struct EntityUid {\n    #[serde(rename = \"type\")]\n    pub entity_type: String,\n    pub id: String,\n}\n\nimpl EntityUid {\n    /// Create a new entity UID.\n    #[must_use]\n    pub fn new(entity_type: impl Into<String>, id: impl Into<String>) -> Self {\n        Self {\n            entity_type: entity_type.into(),\n            id: id.into(),\n        }\n    }\n\n    /// Create a User entity UID.\n    #[must_use]\n    pub fn user(id: impl Into<String>) -> Self {\n        Self::new(\"Aeterna::User\", id)\n    }\n\n    /// Create an Agent entity UID.\n    #[must_use]\n    pub fn agent(id: impl Into<String>) -> Self {\n        Self::new(\"Aeterna::Agent\", id)\n    }\n\n    /// Create a Project entity UID.\n    #[must_use]\n    pub fn project(id: impl Into<String>) -> Self {\n        Self::new(\"Aeterna::Project\", id)\n    }\n\n    /// Create a Team entity UID.\n    #[must_use]\n    pub fn team(id: impl Into<String>) -> Self {\n        Self::new(\"Aeterna::Team\", id)\n    }\n\n    /// Create an Organization entity UID.\n    #[must_use]\n    pub fn organization(id: impl Into<String>) -> Self {\n        Self::new(\"Aeterna::Organization\", id)\n    }\n\n    /// Create a Company entity UID.\n    #[must_use]\n    pub fn company(id: impl Into<String>) -> Self {\n        Self::new(\"Aeterna::Company\", id)\n    }\n\n    /// Create an Action entity UID.\n    #[must_use]\n    pub fn action(name: impl Into<String>) -> Self {\n        Self::new(\"Aeterna::Action\", name)\n    }\n\n    /// Format as Cedar entity reference string: `Type::\"id\"`.\n    #[must_use]\n    pub fn to_cedar_string(&self) -> String {\n        format!(\"{}::\\\"{}\\\"\", self.entity_type, self.id)\n    }\n}\n\nimpl std::fmt::Display for EntityUid {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"{}::\\\"{}\\\"\", self.entity_type, self.id)\n    }\n}\n\n/// A Cedar entity with attributes and parent relationships.\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Entity {\n    /// Entity UID.\n    pub uid: EntityUid,\n\n    /// Entity attributes (JSON object).\n    pub attrs: serde_json::Value,\n\n    /// Parent entity UIDs (for hierarchy).\n    #[serde(default)]\n    pub parents: Vec<EntityUid>,\n}\n\nimpl Entity {\n    /// Get an attribute value as a string.\n    #[must_use]\n    pub fn get_attr_str(&self, key: &str) -> Option<&str> {\n        self.attrs.get(key).and_then(|v| v.as_str())\n    }\n\n    /// Get an attribute value as a string array.\n    #[must_use]\n    pub fn get_attr_str_array(&self, key: &str) -> Option<Vec<&str>> {\n        self.attrs.get(key).and_then(|v| {\n            v.as_array()\n                .map(|arr| arr.iter().filter_map(|v| v.as_str()).collect())\n        })\n    }\n}\n\n/// Authorization request to Cedar Agent.\n#[derive(Debug, Clone, Serialize)]\npub struct AuthorizationRequest {\n    /// Principal making the request (e.g., `Aeterna::User::\"user-id\"`).\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub principal: Option<String>,\n\n    /// Action being performed (e.g., `Aeterna::Action::\"ViewKnowledge\"`).\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub action: Option<String>,\n\n    /// Resource being accessed (e.g., `Aeterna::Project::\"project-id\"`).\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub resource: Option<String>,\n\n    /// Additional context for the request.\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub context: Option<serde_json::Value>,\n\n    /// Inline entities to use for this request (overrides stored data).\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub entities: Option<Vec<Entity>>,\n\n    /// Additional entities to merge with stored data.\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub additional_entities: Option<Vec<Entity>>,\n}\n\nimpl AuthorizationRequest {\n    /// Create a new authorization request.\n    #[must_use]\n    pub fn new() -> Self {\n        Self {\n            principal: None,\n            action: None,\n            resource: None,\n            context: None,\n            entities: None,\n            additional_entities: None,\n        }\n    }\n\n    /// Set the principal.\n    #[must_use]\n    pub fn with_principal(mut self, principal: &EntityUid) -> Self {\n        self.principal = Some(principal.to_cedar_string());\n        self\n    }\n\n    /// Set the action.\n    #[must_use]\n    pub fn with_action(mut self, action: &str) -> Self {\n        self.action = Some(EntityUid::action(action).to_cedar_string());\n        self\n    }\n\n    /// Set the resource.\n    #[must_use]\n    pub fn with_resource(mut self, resource: &EntityUid) -> Self {\n        self.resource = Some(resource.to_cedar_string());\n        self\n    }\n\n    /// Set the context.\n    #[must_use]\n    pub fn with_context(mut self, context: serde_json::Value) -> Self {\n        self.context = Some(context);\n        self\n    }\n}\n\nimpl Default for AuthorizationRequest {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n/// Authorization response from Cedar Agent.\n#[derive(Debug, Clone, Deserialize)]\npub struct AuthorizationResponse {\n    /// The authorization decision.\n    pub decision: AuthorizationDecision,\n\n    /// Diagnostic information.\n    #[serde(default)]\n    pub diagnostics: AuthorizationDiagnostics,\n}\n\n/// Authorization decision.\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Deserialize)]\npub enum AuthorizationDecision {\n    /// Request is allowed.\n    Allow,\n    /// Request is denied.\n    Deny,\n}\n\n/// Diagnostic information from authorization.\n#[derive(Debug, Clone, Default, Deserialize)]\npub struct AuthorizationDiagnostics {\n    /// Policy IDs that contributed to the decision.\n    #[serde(default)]\n    pub reason: Vec<String>,\n\n    /// Error messages (if any).\n    #[serde(default)]\n    pub errors: Vec<String>,\n}\n\n// ============================================================================\n// Circuit Breaker\n// ============================================================================\n\n/// Circuit breaker state for resilience.\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\nenum CircuitState {\n    Closed,\n    Open,\n    HalfOpen,\n}\n\nstruct CircuitBreaker {\n    state: CircuitState,\n    failure_count: u32,\n    last_failure: Option<std::time::Instant>,\n    threshold: u32,\n    reset_timeout: Duration,\n}\n\nimpl CircuitBreaker {\n    fn new(threshold: u32, reset_timeout: Duration) -> Self {\n        Self {\n            state: CircuitState::Closed,\n            failure_count: 0,\n            last_failure: None,\n            threshold,\n            reset_timeout,\n        }\n    }\n\n    fn can_execute(&mut self) -> bool {\n        match self.state {\n            CircuitState::Closed => true,\n            CircuitState::Open => {\n                if let Some(last) = self.last_failure {\n                    if last.elapsed() >= self.reset_timeout {\n                        self.state = CircuitState::HalfOpen;\n                        true\n                    } else {\n                        false\n                    }\n                } else {\n                    true\n                }\n            }\n            CircuitState::HalfOpen => true,\n        }\n    }\n\n    fn record_success(&mut self) {\n        self.failure_count = 0;\n        self.state = CircuitState::Closed;\n    }\n\n    fn record_failure(&mut self) {\n        self.failure_count += 1;\n        self.last_failure = Some(std::time::Instant::now());\n\n        if self.failure_count >= self.threshold {\n            self.state = CircuitState::Open;\n            warn!(\n                \"Circuit breaker opened after {} failures\",\n                self.failure_count\n            );\n        }\n    }\n}\n\n// ============================================================================\n// Entity Cache\n// ============================================================================\n\nstruct EntityCache {\n    entities: HashMap<EntityUid, (Entity, std::time::Instant)>,\n    ttl: Duration,\n}\n\nimpl EntityCache {\n    fn new(ttl: Duration) -> Self {\n        Self {\n            entities: HashMap::new(),\n            ttl,\n        }\n    }\n\n    fn get(&self, uid: &EntityUid) -> Option<&Entity> {\n        self.entities.get(uid).and_then(|(entity, inserted)| {\n            if inserted.elapsed() < self.ttl {\n                Some(entity)\n            } else {\n                None\n            }\n        })\n    }\n\n    fn insert(&mut self, entity: Entity) {\n        self.entities\n            .insert(entity.uid.clone(), (entity, std::time::Instant::now()));\n    }\n\n    fn insert_all(&mut self, entities: Vec<Entity>) {\n        for entity in entities {\n            self.insert(entity);\n        }\n    }\n\n    fn clear(&mut self) {\n        self.entities.clear();\n    }\n}\n\n// ============================================================================\n// Cedar Client\n// ============================================================================\n\n/// Client for interacting with Cedar Agent sidecar.\n///\n/// Provides methods for:\n/// - Entity resolution (users, projects, teams, etc.)\n/// - Authorization checks\n/// - Accessible layer discovery\n///\n/// Includes circuit breaker for resilience and local caching for performance.\npub struct CedarClient {\n    config: CedarConfig,\n    http: Client,\n    circuit_breaker: Arc<RwLock<CircuitBreaker>>,\n    cache: Arc<RwLock<EntityCache>>,\n}\n\nimpl CedarClient {\n    /// Create a new Cedar client.\n    pub fn new(config: CedarConfig) -> Self {\n        let http = Client::builder()\n            .timeout(Duration::from_secs(config.timeout_secs))\n            .build()\n            .expect(\"Failed to create HTTP client\");\n\n        let circuit_breaker = CircuitBreaker::new(\n            config.circuit_breaker_threshold,\n            Duration::from_secs(config.circuit_breaker_reset_secs),\n        );\n\n        let cache = EntityCache::new(Duration::from_secs(config.cache_ttl_secs));\n\n        Self {\n            config,\n            http,\n            circuit_breaker: Arc::new(RwLock::new(circuit_breaker)),\n            cache: Arc::new(RwLock::new(cache)),\n        }\n    }\n\n    /// Create a client with default configuration.\n    #[must_use]\n    pub fn default_client() -> Self {\n        Self::new(CedarConfig::default())\n    }\n\n    /// Create a client from environment variables.\n    #[must_use]\n    pub fn from_env() -> Self {\n        Self::new(CedarConfig::from_env())\n    }\n\n    // ========================================================================\n    // Health Check\n    // ========================================================================\n\n    /// Check if Cedar Agent is healthy.\n    pub async fn health_check(&self) -> Result<bool> {\n        let url = format!(\"{}/health\", self.config.base_url);\n\n        match self.http.get(&url).send().await {\n            Ok(resp) if resp.status().is_success() => Ok(true),\n            Ok(resp) => {\n                warn!(\"Cedar Agent health check failed: {}\", resp.status());\n                Ok(false)\n            }\n            Err(e) => {\n                warn!(\"Cedar Agent health check error: {}\", e);\n                Ok(false)\n            }\n        }\n    }\n\n    // ========================================================================\n    // Entity Resolution\n    // ========================================================================\n\n    /// Fetch all entities from Cedar Agent.\n    ///\n    /// This retrieves all entities loaded into Cedar Agent's data store.\n    pub async fn get_all_entities(&self) -> Result<Vec<Entity>> {\n        self.execute_with_circuit_breaker(|| async {\n            let url = format!(\"{}/v1/data\", self.config.base_url);\n\n            let resp = self.http.get(&url).send().await?;\n\n            if !resp.status().is_success() {\n                let status = resp.status().as_u16();\n                let message = resp.text().await.unwrap_or_default();\n                return Err(CedarError::AgentError { status, message });\n            }\n\n            let entities: Vec<Entity> = resp\n                .json()\n                .await\n                .map_err(|e| CedarError::ParseError(format!(\"Failed to parse entities: {e}\")))?;\n\n            // Update cache\n            if self.config.cache_enabled {\n                let mut cache = self.cache.write().await;\n                cache.insert_all(entities.clone());\n            }\n\n            Ok(entities)\n        })\n        .await\n    }\n\n    /// Resolve a user by email address.\n    ///\n    /// Searches the entities for a User with matching email attribute.\n    pub async fn resolve_user_by_email(&self, email: &str) -> Result<Entity> {\n        debug!(\"Resolving user by email: {}\", email);\n\n        // Check cache first\n        if self.config.cache_enabled {\n            let cache = self.cache.read().await;\n            for (uid, (entity, _)) in &cache.entities {\n                if uid.entity_type == \"Aeterna::User\" {\n                    if let Some(e) = entity.get_attr_str(\"email\") {\n                        if e == email {\n                            trace!(\"User found in cache: {}\", uid);\n                            return Ok(entity.clone());\n                        }\n                    }\n                }\n            }\n        }\n\n        // Fetch from Cedar Agent\n        let entities = self.get_all_entities().await?;\n\n        entities\n            .into_iter()\n            .find(|e| {\n                e.uid.entity_type == \"Aeterna::User\" && e.get_attr_str(\"email\") == Some(email)\n            })\n            .ok_or_else(|| CedarError::EntityNotFound {\n                entity_type: \"Aeterna::User\".to_string(),\n                id: format!(\"email={email}\"),\n            })\n    }\n\n    /// Resolve a project by git remote URL.\n    ///\n    /// Searches the entities for a Project with matching git_remote attribute.\n    pub async fn resolve_project_by_git_remote(&self, git_remote: &str) -> Result<Entity> {\n        debug!(\"Resolving project by git remote: {}\", git_remote);\n\n        // Check cache first\n        if self.config.cache_enabled {\n            let cache = self.cache.read().await;\n            for (uid, (entity, _)) in &cache.entities {\n                if uid.entity_type == \"Aeterna::Project\" {\n                    if let Some(remote) = entity.get_attr_str(\"git_remote\") {\n                        if remote == git_remote {\n                            trace!(\"Project found in cache: {}\", uid);\n                            return Ok(entity.clone());\n                        }\n                    }\n                }\n            }\n        }\n\n        // Fetch from Cedar Agent\n        let entities = self.get_all_entities().await?;\n\n        entities\n            .into_iter()\n            .find(|e| {\n                e.uid.entity_type == \"Aeterna::Project\"\n                    && e.get_attr_str(\"git_remote\") == Some(git_remote)\n            })\n            .ok_or_else(|| CedarError::EntityNotFound {\n                entity_type: \"Aeterna::Project\".to_string(),\n                id: format!(\"git_remote={git_remote}\"),\n            })\n    }\n\n    /// Resolve an entity by its UID.\n    pub async fn resolve_entity(&self, uid: &EntityUid) -> Result<Entity> {\n        debug!(\"Resolving entity: {}\", uid);\n\n        // Check cache first\n        if self.config.cache_enabled {\n            let cache = self.cache.read().await;\n            if let Some(entity) = cache.get(uid) {\n                trace!(\"Entity found in cache: {}\", uid);\n                return Ok(entity.clone());\n            }\n        }\n\n        // Fetch from Cedar Agent\n        let entities = self.get_all_entities().await?;\n\n        entities\n            .into_iter()\n            .find(|e| e.uid == *uid)\n            .ok_or_else(|| CedarError::EntityNotFound {\n                entity_type: uid.entity_type.clone(),\n                id: uid.id.clone(),\n            })\n    }\n\n    /// Resolve an agent by ID.\n    pub async fn resolve_agent(&self, agent_id: &str) -> Result<Entity> {\n        self.resolve_entity(&EntityUid::agent(agent_id)).await\n    }\n\n    // ========================================================================\n    // Authorization\n    // ========================================================================\n\n    /// Check if an action is authorized.\n    ///\n    /// # Arguments\n    ///\n    /// * `principal` - The entity making the request (User or Agent)\n    /// * `action` - The action being performed (e.g., \"ViewKnowledge\")\n    /// * `resource` - The resource being accessed (e.g., Project)\n    /// * `context` - Optional additional context\n    ///\n    /// # Returns\n    ///\n    /// `Ok(true)` if allowed, `Ok(false)` if denied.\n    pub async fn check_authorization(\n        &self,\n        principal: &EntityUid,\n        action: &str,\n        resource: &EntityUid,\n        context: Option<serde_json::Value>,\n    ) -> Result<bool> {\n        let request = AuthorizationRequest::new()\n            .with_principal(principal)\n            .with_action(action)\n            .with_resource(resource);\n\n        let request = if let Some(ctx) = context {\n            request.with_context(ctx)\n        } else {\n            request\n        };\n\n        let response = self.authorize(request).await?;\n\n        Ok(response.decision == AuthorizationDecision::Allow)\n    }\n\n    /// Perform an authorization request with full diagnostic info.\n    pub async fn authorize(&self, request: AuthorizationRequest) -> Result<AuthorizationResponse> {\n        debug!(\n            \"Authorization request: principal={:?} action={:?} resource={:?}\",\n            request.principal, request.action, request.resource\n        );\n\n        self.execute_with_circuit_breaker(|| async {\n            let url = format!(\"{}/v1/is_authorized\", self.config.base_url);\n\n            let resp = self.http.post(&url).json(&request).send().await?;\n\n            if !resp.status().is_success() {\n                let status = resp.status().as_u16();\n                let message = resp.text().await.unwrap_or_default();\n                return Err(CedarError::AgentError { status, message });\n            }\n\n            let response: AuthorizationResponse = resp.json().await.map_err(|e| {\n                CedarError::ParseError(format!(\"Failed to parse authorization response: {e}\"))\n            })?;\n\n            debug!(\n                \"Authorization response: decision={:?} reason={:?}\",\n                response.decision, response.diagnostics.reason\n            );\n\n            Ok(response)\n        })\n        .await\n    }\n\n    /// Check if user can perform action on any resource of a given type.\n    ///\n    /// Useful for UI to show/hide features based on permissions.\n    pub async fn can_user_perform(&self, user_id: &str, action: &str) -> Result<bool> {\n        // For now, we check against a wildcard resource\n        // Cedar Agent may support this differently\n        let request = AuthorizationRequest {\n            principal: Some(EntityUid::user(user_id).to_cedar_string()),\n            action: Some(EntityUid::action(action).to_cedar_string()),\n            resource: None,\n            context: None,\n            entities: None,\n            additional_entities: None,\n        };\n\n        let response = self.authorize(request).await?;\n        Ok(response.decision == AuthorizationDecision::Allow)\n    }\n\n    // ========================================================================\n    // Layer Discovery\n    // ========================================================================\n\n    /// Get accessible memory layers for a user.\n    ///\n    /// Returns the hierarchy of accessible entities (Company -> Org -> Team -> Project).\n    pub async fn get_accessible_layers(&self, user_id: &str) -> Result<AccessibleLayers> {\n        let user = self.resolve_entity(&EntityUid::user(user_id)).await?;\n        let all_entities = self.get_all_entities().await?;\n\n        let mut layers = AccessibleLayers::default();\n\n        // Find all teams the user is a member of (via parents)\n        for parent in &user.parents {\n            if parent.entity_type == \"Aeterna::Team\" {\n                layers.team_ids.push(parent.id.clone());\n\n                // Find the team to get its org\n                if let Some(team) = all_entities.iter().find(|e| e.uid == *parent) {\n                    for team_parent in &team.parents {\n                        if team_parent.entity_type == \"Aeterna::Organization\" {\n                            if !layers.org_ids.contains(&team_parent.id) {\n                                layers.org_ids.push(team_parent.id.clone());\n                            }\n\n                            // Find the org to get its company\n                            if let Some(org) = all_entities.iter().find(|e| e.uid == *team_parent) {\n                                for org_parent in &org.parents {\n                                    if org_parent.entity_type == \"Aeterna::Company\" {\n                                        if !layers.company_ids.contains(&org_parent.id) {\n                                            layers.company_ids.push(org_parent.id.clone());\n                                        }\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n        }\n\n        // Find all projects in accessible teams\n        for entity in &all_entities {\n            if entity.uid.entity_type == \"Aeterna::Project\" {\n                for parent in &entity.parents {\n                    if parent.entity_type == \"Aeterna::Team\" && layers.team_ids.contains(&parent.id)\n                    {\n                        layers.project_ids.push(entity.uid.id.clone());\n                        break;\n                    }\n                }\n            }\n        }\n\n        Ok(layers)\n    }\n\n    // ========================================================================\n    // Cache Management\n    // ========================================================================\n\n    /// Clear the entity cache.\n    pub async fn clear_cache(&self) {\n        let mut cache = self.cache.write().await;\n        cache.clear();\n    }\n\n    /// Refresh the entity cache from Cedar Agent.\n    pub async fn refresh_cache(&self) -> Result<()> {\n        self.clear_cache().await;\n        let _ = self.get_all_entities().await?;\n        Ok(())\n    }\n\n    // ========================================================================\n    // Circuit Breaker\n    // ========================================================================\n\n    async fn execute_with_circuit_breaker<F, Fut, T>(&self, f: F) -> Result<T>\n    where\n        F: Fn() -> Fut,\n        Fut: std::future::Future<Output = Result<T>>,\n    {\n        {\n            let mut cb = self.circuit_breaker.write().await;\n            if !cb.can_execute() {\n                return Err(CedarError::Unavailable(\n                    \"Circuit breaker is open\".to_string(),\n                ));\n            }\n        }\n\n        let max_retries = self.config.max_retries;\n        let mut last_error = None;\n\n        for attempt in 1..=max_retries {\n            match f().await {\n                Ok(v) => {\n                    let mut cb = self.circuit_breaker.write().await;\n                    cb.record_success();\n                    return Ok(v);\n                }\n                Err(e) => {\n                    if Self::is_transient_error(&e) && attempt < max_retries {\n                        warn!(\n                            \"Transient error (attempt {}/{}): {}\",\n                            attempt, max_retries, e\n                        );\n                        let delay = Duration::from_millis(100 * (1 << (attempt - 1)));\n                        tokio::time::sleep(delay).await;\n                        last_error = Some(e);\n                    } else {\n                        let mut cb = self.circuit_breaker.write().await;\n                        cb.record_failure();\n                        return Err(e);\n                    }\n                }\n            }\n        }\n\n        let mut cb = self.circuit_breaker.write().await;\n        cb.record_failure();\n        Err(last_error.unwrap_or_else(|| {\n            CedarError::Unavailable(format!(\"Max retries ({max_retries}) exceeded\"))\n        }))\n    }\n\n    fn is_transient_error(e: &CedarError) -> bool {\n        matches!(\n            e,\n            CedarError::HttpError(_)\n                | CedarError::AgentError {\n                    status: 502..=504,\n                    ..\n                }\n        )\n    }\n}\n\n// ============================================================================\n// Accessible Layers\n// ============================================================================\n\n/// Represents the layers accessible to a user.\n#[derive(Debug, Clone, Default)]\npub struct AccessibleLayers {\n    /// Accessible company IDs.\n    pub company_ids: Vec<String>,\n\n    /// Accessible organization IDs.\n    pub org_ids: Vec<String>,\n\n    /// Accessible team IDs.\n    pub team_ids: Vec<String>,\n\n    /// Accessible project IDs.\n    pub project_ids: Vec<String>,\n}\n\nimpl AccessibleLayers {\n    /// Check if any layers are accessible.\n    #[must_use]\n    pub fn is_empty(&self) -> bool {\n        self.company_ids.is_empty()\n            && self.org_ids.is_empty()\n            && self.team_ids.is_empty()\n            && self.project_ids.is_empty()\n    }\n\n    /// Get total count of accessible entities.\n    #[must_use]\n    pub fn total_count(&self) -> usize {\n        self.company_ids.len() + self.org_ids.len() + self.team_ids.len() + self.project_ids.len()\n    }\n}\n\n// ============================================================================\n// Tests\n// ============================================================================\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_entity_uid_constructors() {\n        let user = EntityUid::user(\"123\");\n        assert_eq!(user.entity_type, \"Aeterna::User\");\n        assert_eq!(user.id, \"123\");\n\n        let project = EntityUid::project(\"proj-1\");\n        assert_eq!(project.entity_type, \"Aeterna::Project\");\n\n        let action = EntityUid::action(\"ViewKnowledge\");\n        assert_eq!(action.entity_type, \"Aeterna::Action\");\n        assert_eq!(action.id, \"ViewKnowledge\");\n    }\n\n    #[test]\n    fn test_entity_uid_to_cedar_string() {\n        let uid = EntityUid::user(\"alice-123\");\n        assert_eq!(uid.to_cedar_string(), \"Aeterna::User::\\\"alice-123\\\"\");\n\n        let action = EntityUid::action(\"EditKnowledge\");\n        assert_eq!(\n            action.to_cedar_string(),\n            \"Aeterna::Action::\\\"EditKnowledge\\\"\"\n        );\n    }\n\n    #[test]\n    fn test_entity_uid_display() {\n        let uid = EntityUid::new(\"Aeterna::Team\", \"team-1\");\n        assert_eq!(format!(\"{uid}\"), \"Aeterna::Team::\\\"team-1\\\"\");\n    }\n\n    #[test]\n    fn test_authorization_request_builder() {\n        let principal = EntityUid::user(\"user-1\");\n        let resource = EntityUid::project(\"proj-1\");\n\n        let request = AuthorizationRequest::new()\n            .with_principal(&principal)\n            .with_action(\"ViewKnowledge\")\n            .with_resource(&resource)\n            .with_context(serde_json::json!({\"ip\": \"192.168.1.1\"}));\n\n        assert_eq!(\n            request.principal,\n            Some(\"Aeterna::User::\\\"user-1\\\"\".to_string())\n        );\n        assert_eq!(\n            request.action,\n            Some(\"Aeterna::Action::\\\"ViewKnowledge\\\"\".to_string())\n        );\n        assert_eq!(\n            request.resource,\n            Some(\"Aeterna::Project::\\\"proj-1\\\"\".to_string())\n        );\n        assert!(request.context.is_some());\n    }\n\n    #[test]\n    fn test_cedar_config_default() {\n        let config = CedarConfig::default();\n        assert_eq!(config.base_url, \"http://localhost:8180\");\n        assert_eq!(config.timeout_secs, 5);\n        assert!(config.cache_enabled);\n    }\n\n    #[test]\n    fn test_cedar_config_for_testing() {\n        let config = CedarConfig::for_testing();\n        assert_eq!(config.timeout_secs, 1);\n        assert_eq!(config.max_retries, 1);\n        assert!(!config.cache_enabled);\n    }\n\n    #[test]\n    fn test_entity_get_attr_str() {\n        let entity = Entity {\n            uid: EntityUid::user(\"test\"),\n            attrs: serde_json::json!({\n                \"email\": \"test@example.com\",\n                \"name\": \"Test User\",\n                \"count\": 42\n            }),\n            parents: vec![],\n        };\n\n        assert_eq!(entity.get_attr_str(\"email\"), Some(\"test@example.com\"));\n        assert_eq!(entity.get_attr_str(\"name\"), Some(\"Test User\"));\n        assert_eq!(entity.get_attr_str(\"count\"), None); // Not a string\n        assert_eq!(entity.get_attr_str(\"missing\"), None);\n    }\n\n    #[test]\n    fn test_entity_get_attr_str_array() {\n        let entity = Entity {\n            uid: EntityUid::user(\"test\"),\n            attrs: serde_json::json!({\n                \"roles\": [\"admin\", \"developer\"],\n                \"single\": \"value\"\n            }),\n            parents: vec![],\n        };\n\n        let roles = entity.get_attr_str_array(\"roles\");\n        assert_eq!(roles, Some(vec![\"admin\", \"developer\"]));\n\n        let single = entity.get_attr_str_array(\"single\");\n        assert_eq!(single, None); // Not an array\n    }\n\n    #[test]\n    fn test_circuit_breaker_initial_state() {\n        let mut cb = CircuitBreaker::new(3, Duration::from_secs(30));\n        assert!(cb.can_execute());\n        assert_eq!(cb.state, CircuitState::Closed);\n    }\n\n    #[test]\n    fn test_circuit_breaker_opens_after_threshold() {\n        let mut cb = CircuitBreaker::new(3, Duration::from_secs(30));\n\n        cb.record_failure();\n        assert!(cb.can_execute());\n\n        cb.record_failure();\n        assert!(cb.can_execute());\n\n        cb.record_failure();\n        assert!(!cb.can_execute());\n        assert_eq!(cb.state, CircuitState::Open);\n    }\n\n    #[test]\n    fn test_circuit_breaker_success_resets() {\n        let mut cb = CircuitBreaker::new(3, Duration::from_secs(30));\n\n        cb.record_failure();\n        cb.record_failure();\n        cb.record_success();\n\n        assert_eq!(cb.failure_count, 0);\n        assert_eq!(cb.state, CircuitState::Closed);\n    }\n\n    #[test]\n    fn test_accessible_layers_is_empty() {\n        let layers = AccessibleLayers::default();\n        assert!(layers.is_empty());\n\n        let layers = AccessibleLayers {\n            team_ids: vec![\"team-1\".to_string()],\n            ..Default::default()\n        };\n        assert!(!layers.is_empty());\n    }\n\n    #[test]\n    fn test_accessible_layers_total_count() {\n        let layers = AccessibleLayers {\n            company_ids: vec![\"c1\".to_string()],\n            org_ids: vec![\"o1\".to_string(), \"o2\".to_string()],\n            team_ids: vec![\"t1\".to_string()],\n            project_ids: vec![\"p1\".to_string(), \"p2\".to_string(), \"p3\".to_string()],\n        };\n        assert_eq!(layers.total_count(), 7);\n    }\n\n    #[test]\n    fn test_authorization_decision_deserialize() {\n        let allow: AuthorizationDecision = serde_json::from_str(\"\\\"Allow\\\"\").unwrap();\n        assert_eq!(allow, AuthorizationDecision::Allow);\n\n        let deny: AuthorizationDecision = serde_json::from_str(\"\\\"Deny\\\"\").unwrap();\n        assert_eq!(deny, AuthorizationDecision::Deny);\n    }\n\n    #[test]\n    fn test_authorization_response_deserialize() {\n        let json = r#\"{\n            \"decision\": \"Allow\",\n            \"diagnostics\": {\n                \"reason\": [\"policy-1\", \"policy-2\"],\n                \"errors\": []\n            }\n        }\"#;\n\n        let response: AuthorizationResponse = serde_json::from_str(json).unwrap();\n        assert_eq!(response.decision, AuthorizationDecision::Allow);\n        assert_eq!(response.diagnostics.reason.len(), 2);\n        assert!(response.diagnostics.errors.is_empty());\n    }\n}\n\n// ============================================================================\n// Integration Tests (with wiremock)\n// ============================================================================\n\n#[cfg(test)]\nmod integration_tests {\n    use super::*;\n    use wiremock::matchers::{method, path};\n    use wiremock::{Mock, MockServer, ResponseTemplate};\n\n    /// Helper to create test entities matching OPAL fetcher format.\n    fn create_test_entities() -> serde_json::Value {\n        serde_json::json!([\n            {\n                \"uid\": {\"type\": \"Aeterna::Company\", \"id\": \"acme-corp\"},\n                \"attrs\": {\"name\": \"Acme Corporation\", \"slug\": \"acme\"},\n                \"parents\": []\n            },\n            {\n                \"uid\": {\"type\": \"Aeterna::Organization\", \"id\": \"org-platform\"},\n                \"attrs\": {\"name\": \"Platform Engineering\"},\n                \"parents\": [{\"type\": \"Aeterna::Company\", \"id\": \"acme-corp\"}]\n            },\n            {\n                \"uid\": {\"type\": \"Aeterna::Team\", \"id\": \"team-api\"},\n                \"attrs\": {\"name\": \"API Team\"},\n                \"parents\": [{\"type\": \"Aeterna::Organization\", \"id\": \"org-platform\"}]\n            },\n            {\n                \"uid\": {\"type\": \"Aeterna::Project\", \"id\": \"proj-payments\"},\n                \"attrs\": {\"name\": \"Payments Service\", \"git_remote\": \"github.com/acme/payments\"},\n                \"parents\": [{\"type\": \"Aeterna::Team\", \"id\": \"team-api\"}]\n            },\n            {\n                \"uid\": {\"type\": \"Aeterna::User\", \"id\": \"user-alice\"},\n                \"attrs\": {\"email\": \"alice@acme.com\", \"name\": \"Alice\", \"company_slug\": \"acme\"},\n                \"parents\": [{\"type\": \"Aeterna::Team\", \"id\": \"team-api\"}]\n            },\n            {\n                \"uid\": {\"type\": \"Aeterna::Agent\", \"id\": \"agent-opencode\"},\n                \"attrs\": {\"name\": \"OpenCode Assistant\"},\n                \"parents\": [\n                    {\"type\": \"Aeterna::User\", \"id\": \"user-alice\"},\n                    {\"type\": \"Aeterna::Project\", \"id\": \"proj-payments\"}\n                ]\n            }\n        ])\n    }\n\n    fn create_client_for_mock(mock_server: &MockServer) -> CedarClient {\n        let config = CedarConfig {\n            base_url: mock_server.uri(),\n            timeout_secs: 5,\n            cache_enabled: false,\n            cache_ttl_secs: 60,\n            max_retries: 1,\n            circuit_breaker_threshold: 5,\n            circuit_breaker_reset_secs: 30,\n        };\n        CedarClient::new(config)\n    }\n\n    #[tokio::test]\n    async fn test_health_check_success() {\n        let mock_server = MockServer::start().await;\n\n        Mock::given(method(\"GET\"))\n            .and(path(\"/health\"))\n            .respond_with(ResponseTemplate::new(200).set_body_string(\"OK\"))\n            .mount(&mock_server)\n            .await;\n\n        let client = create_client_for_mock(&mock_server);\n        let result = client.health_check().await;\n\n        assert!(result.is_ok());\n        assert!(result.unwrap());\n    }\n\n    #[tokio::test]\n    async fn test_health_check_failure() {\n        let mock_server = MockServer::start().await;\n\n        Mock::given(method(\"GET\"))\n            .and(path(\"/health\"))\n            .respond_with(ResponseTemplate::new(500))\n            .mount(&mock_server)\n            .await;\n\n        let client = create_client_for_mock(&mock_server);\n        let result = client.health_check().await;\n\n        assert!(result.is_ok());\n        assert!(!result.unwrap());\n    }\n\n    #[tokio::test]\n    async fn test_get_all_entities() {\n        let mock_server = MockServer::start().await;\n        let entities = create_test_entities();\n\n        Mock::given(method(\"GET\"))\n            .and(path(\"/v1/data\"))\n            .respond_with(ResponseTemplate::new(200).set_body_json(&entities))\n            .mount(&mock_server)\n            .await;\n\n        let client = create_client_for_mock(&mock_server);\n        let result = client.get_all_entities().await;\n\n        assert!(result.is_ok());\n        let entities = result.unwrap();\n        assert_eq!(entities.len(), 6);\n\n        // Verify entity types\n        let types: Vec<&str> = entities\n            .iter()\n            .map(|e| e.uid.entity_type.as_str())\n            .collect();\n        assert!(types.contains(&\"Aeterna::Company\"));\n        assert!(types.contains(&\"Aeterna::Organization\"));\n        assert!(types.contains(&\"Aeterna::Team\"));\n        assert!(types.contains(&\"Aeterna::Project\"));\n        assert!(types.contains(&\"Aeterna::User\"));\n        assert!(types.contains(&\"Aeterna::Agent\"));\n    }\n\n    #[tokio::test]\n    async fn test_resolve_user_by_email() {\n        let mock_server = MockServer::start().await;\n        let entities = create_test_entities();\n\n        Mock::given(method(\"GET\"))\n            .and(path(\"/v1/data\"))\n            .respond_with(ResponseTemplate::new(200).set_body_json(&entities))\n            .mount(&mock_server)\n            .await;\n\n        let client = create_client_for_mock(&mock_server);\n        let result = client.resolve_user_by_email(\"alice@acme.com\").await;\n\n        assert!(result.is_ok());\n        let user = result.unwrap();\n        assert_eq!(user.uid.entity_type, \"Aeterna::User\");\n        assert_eq!(user.uid.id, \"user-alice\");\n        assert_eq!(user.get_attr_str(\"email\"), Some(\"alice@acme.com\"));\n        assert_eq!(user.get_attr_str(\"company_slug\"), Some(\"acme\"));\n    }\n\n    #[tokio::test]\n    async fn test_resolve_user_by_email_not_found() {\n        let mock_server = MockServer::start().await;\n        let entities = create_test_entities();\n\n        Mock::given(method(\"GET\"))\n            .and(path(\"/v1/data\"))\n            .respond_with(ResponseTemplate::new(200).set_body_json(&entities))\n            .mount(&mock_server)\n            .await;\n\n        let client = create_client_for_mock(&mock_server);\n        let result = client.resolve_user_by_email(\"unknown@example.com\").await;\n\n        assert!(result.is_err());\n        match result.unwrap_err() {\n            CedarError::EntityNotFound { entity_type, id } => {\n                assert_eq!(entity_type, \"Aeterna::User\");\n                assert_eq!(id, \"email=unknown@example.com\");\n            }\n            other => panic!(\"Expected EntityNotFound, got: {:?}\", other),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_resolve_project_by_git_remote() {\n        let mock_server = MockServer::start().await;\n        let entities = create_test_entities();\n\n        Mock::given(method(\"GET\"))\n            .and(path(\"/v1/data\"))\n            .respond_with(ResponseTemplate::new(200).set_body_json(&entities))\n            .mount(&mock_server)\n            .await;\n\n        let client = create_client_for_mock(&mock_server);\n        let result = client\n            .resolve_project_by_git_remote(\"github.com/acme/payments\")\n            .await;\n\n        assert!(result.is_ok());\n        let project = result.unwrap();\n        assert_eq!(project.uid.entity_type, \"Aeterna::Project\");\n        assert_eq!(project.uid.id, \"proj-payments\");\n        assert_eq!(project.get_attr_str(\"name\"), Some(\"Payments Service\"));\n\n        // Verify parent relationship\n        assert!(!project.parents.is_empty());\n        assert_eq!(project.parents[0].entity_type, \"Aeterna::Team\");\n        assert_eq!(project.parents[0].id, \"team-api\");\n    }\n\n    #[tokio::test]\n    async fn test_check_authorization_allow() {\n        let mock_server = MockServer::start().await;\n\n        let auth_response = serde_json::json!({\n            \"decision\": \"Allow\",\n            \"diagnostics\": {\n                \"reason\": [\"rbac-policy\"],\n                \"errors\": []\n            }\n        });\n\n        Mock::given(method(\"POST\"))\n            .and(path(\"/v1/is_authorized\"))\n            .respond_with(ResponseTemplate::new(200).set_body_json(&auth_response))\n            .mount(&mock_server)\n            .await;\n\n        let client = create_client_for_mock(&mock_server);\n        let principal = EntityUid::user(\"user-alice\");\n        let resource = EntityUid::project(\"proj-payments\");\n\n        let result = client\n            .check_authorization(&principal, \"ViewKnowledge\", &resource, None)\n            .await;\n\n        assert!(result.is_ok());\n        assert!(result.unwrap());\n    }\n\n    #[tokio::test]\n    async fn test_check_authorization_deny() {\n        let mock_server = MockServer::start().await;\n\n        let auth_response = serde_json::json!({\n            \"decision\": \"Deny\",\n            \"diagnostics\": {\n                \"reason\": [],\n                \"errors\": []\n            }\n        });\n\n        Mock::given(method(\"POST\"))\n            .and(path(\"/v1/is_authorized\"))\n            .respond_with(ResponseTemplate::new(200).set_body_json(&auth_response))\n            .mount(&mock_server)\n            .await;\n\n        let client = create_client_for_mock(&mock_server);\n        let principal = EntityUid::user(\"user-bob\");\n        let resource = EntityUid::project(\"proj-secret\");\n\n        let result = client\n            .check_authorization(&principal, \"EditKnowledge\", &resource, None)\n            .await;\n\n        assert!(result.is_ok());\n        assert!(!result.unwrap());\n    }\n\n    #[tokio::test]\n    async fn test_check_authorization_with_context() {\n        let mock_server = MockServer::start().await;\n\n        let auth_response = serde_json::json!({\n            \"decision\": \"Allow\",\n            \"diagnostics\": {\n                \"reason\": [\"abac-policy\"],\n                \"errors\": []\n            }\n        });\n\n        Mock::given(method(\"POST\"))\n            .and(path(\"/v1/is_authorized\"))\n            .respond_with(ResponseTemplate::new(200).set_body_json(&auth_response))\n            .mount(&mock_server)\n            .await;\n\n        let client = create_client_for_mock(&mock_server);\n        let principal = EntityUid::user(\"user-alice\");\n        let resource = EntityUid::project(\"proj-payments\");\n        let context = serde_json::json!({\"ip\": \"192.168.1.1\", \"time\": \"09:00\"});\n\n        let result = client\n            .check_authorization(&principal, \"ViewKnowledge\", &resource, Some(context))\n            .await;\n\n        assert!(result.is_ok());\n        assert!(result.unwrap());\n    }\n\n    #[tokio::test]\n    async fn test_get_accessible_layers() {\n        let mock_server = MockServer::start().await;\n        let entities = create_test_entities();\n\n        Mock::given(method(\"GET\"))\n            .and(path(\"/v1/data\"))\n            .respond_with(ResponseTemplate::new(200).set_body_json(&entities))\n            .mount(&mock_server)\n            .await;\n\n        let client = create_client_for_mock(&mock_server);\n        let result = client.get_accessible_layers(\"user-alice\").await;\n\n        assert!(result.is_ok());\n        let layers = result.unwrap();\n\n        // Alice is member of team-api\n        assert!(layers.team_ids.contains(&\"team-api\".to_string()));\n\n        // team-api is in org-platform\n        assert!(layers.org_ids.contains(&\"org-platform\".to_string()));\n\n        // org-platform is in acme-corp\n        assert!(layers.company_ids.contains(&\"acme-corp\".to_string()));\n\n        // proj-payments is in team-api\n        assert!(layers.project_ids.contains(&\"proj-payments\".to_string()));\n\n        assert!(!layers.is_empty());\n        assert!(layers.total_count() >= 4);\n    }\n\n    #[tokio::test]\n    async fn test_resolve_agent() {\n        let mock_server = MockServer::start().await;\n        let entities = create_test_entities();\n\n        Mock::given(method(\"GET\"))\n            .and(path(\"/v1/data\"))\n            .respond_with(ResponseTemplate::new(200).set_body_json(&entities))\n            .mount(&mock_server)\n            .await;\n\n        let client = create_client_for_mock(&mock_server);\n        let result = client.resolve_agent(\"agent-opencode\").await;\n\n        assert!(result.is_ok());\n        let agent = result.unwrap();\n        assert_eq!(agent.uid.entity_type, \"Aeterna::Agent\");\n        assert_eq!(agent.uid.id, \"agent-opencode\");\n        assert_eq!(agent.get_attr_str(\"name\"), Some(\"OpenCode Assistant\"));\n\n        // Agent should have user and project as parents\n        assert_eq!(agent.parents.len(), 2);\n        let parent_types: Vec<&str> = agent\n            .parents\n            .iter()\n            .map(|p| p.entity_type.as_str())\n            .collect();\n        assert!(parent_types.contains(&\"Aeterna::User\"));\n        assert!(parent_types.contains(&\"Aeterna::Project\"));\n    }\n\n    #[tokio::test]\n    async fn test_circuit_breaker_opens_on_failures() {\n        let mock_server = MockServer::start().await;\n\n        // Return 503 to simulate service unavailable\n        Mock::given(method(\"GET\"))\n            .and(path(\"/v1/data\"))\n            .respond_with(ResponseTemplate::new(503).set_body_string(\"Service Unavailable\"))\n            .mount(&mock_server)\n            .await;\n\n        let config = CedarConfig {\n            base_url: mock_server.uri(),\n            timeout_secs: 1,\n            cache_enabled: false,\n            cache_ttl_secs: 60,\n            max_retries: 1,\n            circuit_breaker_threshold: 2, // Open after 2 failures\n            circuit_breaker_reset_secs: 30,\n        };\n        let client = CedarClient::new(config);\n\n        // First failure\n        let _ = client.get_all_entities().await;\n\n        // Second failure - should open circuit\n        let _ = client.get_all_entities().await;\n\n        // Third attempt should fail immediately with circuit open\n        let result = client.get_all_entities().await;\n        match result {\n            Err(CedarError::Unavailable(msg)) => {\n                assert!(msg.contains(\"Circuit breaker is open\"));\n            }\n            other => panic!(\"Expected Unavailable error, got: {:?}\", other),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_error_handling_agent_error() {\n        let mock_server = MockServer::start().await;\n\n        Mock::given(method(\"GET\"))\n            .and(path(\"/v1/data\"))\n            .respond_with(ResponseTemplate::new(400).set_body_string(\"Bad Request\"))\n            .mount(&mock_server)\n            .await;\n\n        let client = create_client_for_mock(&mock_server);\n        let result = client.get_all_entities().await;\n\n        assert!(result.is_err());\n        match result.unwrap_err() {\n            CedarError::AgentError { status, message } => {\n                assert_eq!(status, 400);\n                assert_eq!(message, \"Bad Request\");\n            }\n            other => panic!(\"Expected AgentError, got: {:?}\", other),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_cache_reuse() {\n        let mock_server = MockServer::start().await;\n        let entities = create_test_entities();\n\n        Mock::given(method(\"GET\"))\n            .and(path(\"/v1/data\"))\n            .respond_with(ResponseTemplate::new(200).set_body_json(&entities))\n            .expect(1)\n            .mount(&mock_server)\n            .await;\n\n        let config = CedarConfig {\n            base_url: mock_server.uri(),\n            timeout_secs: 5,\n            cache_enabled: true,\n            cache_ttl_secs: 300,\n            max_retries: 1,\n            circuit_breaker_threshold: 5,\n            circuit_breaker_reset_secs: 30,\n        };\n        let client = CedarClient::new(config);\n\n        let uid = EntityUid::user(\"user-alice\");\n\n        let result1 = client.resolve_entity(&uid).await;\n        assert!(result1.is_ok());\n\n        let result2 = client.resolve_entity(&uid).await;\n        assert!(result2.is_ok());\n\n        assert_eq!(result1.unwrap().uid.id, result2.unwrap().uid.id);\n    }\n\n    #[tokio::test]\n    async fn test_cache_clear() {\n        let mock_server = MockServer::start().await;\n        let entities = create_test_entities();\n\n        Mock::given(method(\"GET\"))\n            .and(path(\"/v1/data\"))\n            .respond_with(ResponseTemplate::new(200).set_body_json(&entities))\n            .expect(2) // Should be called twice after cache clear\n            .mount(&mock_server)\n            .await;\n\n        let config = CedarConfig {\n            base_url: mock_server.uri(),\n            timeout_secs: 5,\n            cache_enabled: true,\n            cache_ttl_secs: 300,\n            max_retries: 1,\n            circuit_breaker_threshold: 5,\n            circuit_breaker_reset_secs: 30,\n        };\n        let client = CedarClient::new(config);\n\n        // First call\n        let _ = client.get_all_entities().await;\n\n        // Clear cache\n        client.clear_cache().await;\n\n        // Second call - should hit server again\n        let _ = client.get_all_entities().await;\n    }\n}\n","traces":[{"line":126,"address":[],"length":0,"stats":{"Line":2}},{"line":128,"address":[],"length":0,"stats":{"Line":2}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":1}},{"line":196,"address":[],"length":0,"stats":{"Line":23}},{"line":198,"address":[],"length":0,"stats":{"Line":69}},{"line":199,"address":[],"length":0,"stats":{"Line":23}},{"line":205,"address":[],"length":0,"stats":{"Line":10}},{"line":206,"address":[],"length":0,"stats":{"Line":20}},{"line":211,"address":[],"length":0,"stats":{"Line":1}},{"line":212,"address":[],"length":0,"stats":{"Line":2}},{"line":217,"address":[],"length":0,"stats":{"Line":5}},{"line":218,"address":[],"length":0,"stats":{"Line":10}},{"line":223,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":235,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":241,"address":[],"length":0,"stats":{"Line":6}},{"line":242,"address":[],"length":0,"stats":{"Line":12}},{"line":247,"address":[],"length":0,"stats":{"Line":14}},{"line":248,"address":[],"length":0,"stats":{"Line":28}},{"line":253,"address":[],"length":0,"stats":{"Line":1}},{"line":254,"address":[],"length":0,"stats":{"Line":3}},{"line":275,"address":[],"length":0,"stats":{"Line":11}},{"line":276,"address":[],"length":0,"stats":{"Line":64}},{"line":281,"address":[],"length":0,"stats":{"Line":2}},{"line":282,"address":[],"length":0,"stats":{"Line":10}},{"line":283,"address":[],"length":0,"stats":{"Line":4}},{"line":284,"address":[],"length":0,"stats":{"Line":9}},{"line":320,"address":[],"length":0,"stats":{"Line":4}},{"line":333,"address":[],"length":0,"stats":{"Line":4}},{"line":334,"address":[],"length":0,"stats":{"Line":8}},{"line":335,"address":[],"length":0,"stats":{"Line":4}},{"line":340,"address":[],"length":0,"stats":{"Line":4}},{"line":341,"address":[],"length":0,"stats":{"Line":8}},{"line":342,"address":[],"length":0,"stats":{"Line":4}},{"line":347,"address":[],"length":0,"stats":{"Line":4}},{"line":348,"address":[],"length":0,"stats":{"Line":8}},{"line":349,"address":[],"length":0,"stats":{"Line":4}},{"line":354,"address":[],"length":0,"stats":{"Line":2}},{"line":355,"address":[],"length":0,"stats":{"Line":4}},{"line":356,"address":[],"length":0,"stats":{"Line":2}},{"line":361,"address":[],"length":0,"stats":{"Line":0}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":419,"address":[],"length":0,"stats":{"Line":18}},{"line":429,"address":[],"length":0,"stats":{"Line":21}},{"line":430,"address":[],"length":0,"stats":{"Line":21}},{"line":431,"address":[],"length":0,"stats":{"Line":19}},{"line":433,"address":[],"length":0,"stats":{"Line":4}},{"line":434,"address":[],"length":0,"stats":{"Line":2}},{"line":435,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":2}},{"line":441,"address":[],"length":0,"stats":{"Line":0}},{"line":444,"address":[],"length":0,"stats":{"Line":0}},{"line":448,"address":[],"length":0,"stats":{"Line":14}},{"line":449,"address":[],"length":0,"stats":{"Line":14}},{"line":450,"address":[],"length":0,"stats":{"Line":14}},{"line":453,"address":[],"length":0,"stats":{"Line":8}},{"line":454,"address":[],"length":0,"stats":{"Line":8}},{"line":455,"address":[],"length":0,"stats":{"Line":8}},{"line":457,"address":[],"length":0,"stats":{"Line":8}},{"line":458,"address":[],"length":0,"stats":{"Line":2}},{"line":459,"address":[],"length":0,"stats":{"Line":2}},{"line":460,"address":[],"length":0,"stats":{"Line":0}},{"line":477,"address":[],"length":0,"stats":{"Line":15}},{"line":479,"address":[],"length":0,"stats":{"Line":15}},{"line":484,"address":[],"length":0,"stats":{"Line":2}},{"line":485,"address":[],"length":0,"stats":{"Line":9}},{"line":486,"address":[],"length":0,"stats":{"Line":1}},{"line":487,"address":[],"length":0,"stats":{"Line":1}},{"line":489,"address":[],"length":0,"stats":{"Line":0}},{"line":494,"address":[],"length":0,"stats":{"Line":18}},{"line":495,"address":[],"length":0,"stats":{"Line":18}},{"line":496,"address":[],"length":0,"stats":{"Line":72}},{"line":499,"address":[],"length":0,"stats":{"Line":3}},{"line":500,"address":[],"length":0,"stats":{"Line":57}},{"line":501,"address":[],"length":0,"stats":{"Line":36}},{"line":505,"address":[],"length":0,"stats":{"Line":1}},{"line":506,"address":[],"length":0,"stats":{"Line":2}},{"line":531,"address":[],"length":0,"stats":{"Line":15}},{"line":532,"address":[],"length":0,"stats":{"Line":30}},{"line":533,"address":[],"length":0,"stats":{"Line":45}},{"line":538,"address":[],"length":0,"stats":{"Line":15}},{"line":539,"address":[],"length":0,"stats":{"Line":30}},{"line":542,"address":[],"length":0,"stats":{"Line":60}},{"line":547,"address":[],"length":0,"stats":{"Line":60}},{"line":548,"address":[],"length":0,"stats":{"Line":30}},{"line":554,"address":[],"length":0,"stats":{"Line":0}},{"line":555,"address":[],"length":0,"stats":{"Line":0}},{"line":560,"address":[],"length":0,"stats":{"Line":0}},{"line":561,"address":[],"length":0,"stats":{"Line":0}},{"line":569,"address":[],"length":0,"stats":{"Line":4}},{"line":570,"address":[],"length":0,"stats":{"Line":6}},{"line":572,"address":[],"length":0,"stats":{"Line":10}},{"line":573,"address":[],"length":0,"stats":{"Line":7}},{"line":574,"address":[],"length":0,"stats":{"Line":1}},{"line":575,"address":[],"length":0,"stats":{"Line":1}},{"line":576,"address":[],"length":0,"stats":{"Line":1}},{"line":578,"address":[],"length":0,"stats":{"Line":0}},{"line":579,"address":[],"length":0,"stats":{"Line":0}},{"line":580,"address":[],"length":0,"stats":{"Line":0}},{"line":592,"address":[],"length":0,"stats":{"Line":28}},{"line":593,"address":[],"length":0,"stats":{"Line":41}},{"line":594,"address":[],"length":0,"stats":{"Line":39}},{"line":596,"address":[],"length":0,"stats":{"Line":65}},{"line":598,"address":[],"length":0,"stats":{"Line":13}},{"line":599,"address":[],"length":0,"stats":{"Line":9}},{"line":600,"address":[],"length":0,"stats":{"Line":12}},{"line":601,"address":[],"length":0,"stats":{"Line":3}},{"line":604,"address":[],"length":0,"stats":{"Line":40}},{"line":605,"address":[],"length":0,"stats":{"Line":10}},{"line":606,"address":[],"length":0,"stats":{"Line":10}},{"line":607,"address":[],"length":0,"stats":{"Line":10}},{"line":610,"address":[],"length":0,"stats":{"Line":10}},{"line":611,"address":[],"length":0,"stats":{"Line":6}},{"line":612,"address":[],"length":0,"stats":{"Line":9}},{"line":615,"address":[],"length":0,"stats":{"Line":10}},{"line":617,"address":[],"length":0,"stats":{"Line":14}},{"line":623,"address":[],"length":0,"stats":{"Line":4}},{"line":624,"address":[],"length":0,"stats":{"Line":2}},{"line":627,"address":[],"length":0,"stats":{"Line":2}},{"line":628,"address":[],"length":0,"stats":{"Line":0}},{"line":629,"address":[],"length":0,"stats":{"Line":0}},{"line":630,"address":[],"length":0,"stats":{"Line":0}},{"line":631,"address":[],"length":0,"stats":{"Line":0}},{"line":632,"address":[],"length":0,"stats":{"Line":0}},{"line":633,"address":[],"length":0,"stats":{"Line":0}},{"line":634,"address":[],"length":0,"stats":{"Line":0}},{"line":642,"address":[],"length":0,"stats":{"Line":6}},{"line":644,"address":[],"length":0,"stats":{"Line":2}},{"line":646,"address":[],"length":0,"stats":{"Line":13}},{"line":647,"address":[],"length":0,"stats":{"Line":15}},{"line":649,"address":[],"length":0,"stats":{"Line":2}},{"line":650,"address":[],"length":0,"stats":{"Line":2}},{"line":651,"address":[],"length":0,"stats":{"Line":2}},{"line":658,"address":[],"length":0,"stats":{"Line":2}},{"line":659,"address":[],"length":0,"stats":{"Line":1}},{"line":662,"address":[],"length":0,"stats":{"Line":1}},{"line":663,"address":[],"length":0,"stats":{"Line":0}},{"line":664,"address":[],"length":0,"stats":{"Line":0}},{"line":665,"address":[],"length":0,"stats":{"Line":0}},{"line":666,"address":[],"length":0,"stats":{"Line":0}},{"line":667,"address":[],"length":0,"stats":{"Line":0}},{"line":668,"address":[],"length":0,"stats":{"Line":0}},{"line":669,"address":[],"length":0,"stats":{"Line":0}},{"line":677,"address":[],"length":0,"stats":{"Line":3}},{"line":679,"address":[],"length":0,"stats":{"Line":1}},{"line":681,"address":[],"length":0,"stats":{"Line":5}},{"line":682,"address":[],"length":0,"stats":{"Line":4}},{"line":683,"address":[],"length":0,"stats":{"Line":2}},{"line":685,"address":[],"length":0,"stats":{"Line":1}},{"line":686,"address":[],"length":0,"stats":{"Line":0}},{"line":687,"address":[],"length":0,"stats":{"Line":0}},{"line":692,"address":[],"length":0,"stats":{"Line":8}},{"line":693,"address":[],"length":0,"stats":{"Line":4}},{"line":696,"address":[],"length":0,"stats":{"Line":4}},{"line":697,"address":[],"length":0,"stats":{"Line":4}},{"line":698,"address":[],"length":0,"stats":{"Line":5}},{"line":699,"address":[],"length":0,"stats":{"Line":1}},{"line":700,"address":[],"length":0,"stats":{"Line":1}},{"line":705,"address":[],"length":0,"stats":{"Line":9}},{"line":707,"address":[],"length":0,"stats":{"Line":3}},{"line":709,"address":[],"length":0,"stats":{"Line":35}},{"line":710,"address":[],"length":0,"stats":{"Line":3}},{"line":711,"address":[],"length":0,"stats":{"Line":0}},{"line":712,"address":[],"length":0,"stats":{"Line":0}},{"line":717,"address":[],"length":0,"stats":{"Line":2}},{"line":718,"address":[],"length":0,"stats":{"Line":3}},{"line":737,"address":[],"length":0,"stats":{"Line":3}},{"line":744,"address":[],"length":0,"stats":{"Line":6}},{"line":745,"address":[],"length":0,"stats":{"Line":6}},{"line":746,"address":[],"length":0,"stats":{"Line":6}},{"line":747,"address":[],"length":0,"stats":{"Line":6}},{"line":749,"address":[],"length":0,"stats":{"Line":7}},{"line":750,"address":[],"length":0,"stats":{"Line":3}},{"line":752,"address":[],"length":0,"stats":{"Line":2}},{"line":755,"address":[],"length":0,"stats":{"Line":12}},{"line":757,"address":[],"length":0,"stats":{"Line":3}},{"line":761,"address":[],"length":0,"stats":{"Line":6}},{"line":762,"address":[],"length":0,"stats":{"Line":3}},{"line":763,"address":[],"length":0,"stats":{"Line":0}},{"line":767,"address":[],"length":0,"stats":{"Line":9}},{"line":768,"address":[],"length":0,"stats":{"Line":9}},{"line":770,"address":[],"length":0,"stats":{"Line":21}},{"line":772,"address":[],"length":0,"stats":{"Line":3}},{"line":773,"address":[],"length":0,"stats":{"Line":0}},{"line":774,"address":[],"length":0,"stats":{"Line":0}},{"line":775,"address":[],"length":0,"stats":{"Line":0}},{"line":778,"address":[],"length":0,"stats":{"Line":15}},{"line":779,"address":[],"length":0,"stats":{"Line":0}},{"line":782,"address":[],"length":0,"stats":{"Line":3}},{"line":783,"address":[],"length":0,"stats":{"Line":0}},{"line":787,"address":[],"length":0,"stats":{"Line":3}},{"line":789,"address":[],"length":0,"stats":{"Line":3}},{"line":795,"address":[],"length":0,"stats":{"Line":0}},{"line":799,"address":[],"length":0,"stats":{"Line":0}},{"line":800,"address":[],"length":0,"stats":{"Line":0}},{"line":807,"address":[],"length":0,"stats":{"Line":0}},{"line":808,"address":[],"length":0,"stats":{"Line":0}},{"line":818,"address":[],"length":0,"stats":{"Line":2}},{"line":819,"address":[],"length":0,"stats":{"Line":4}},{"line":820,"address":[],"length":0,"stats":{"Line":3}},{"line":822,"address":[],"length":0,"stats":{"Line":2}},{"line":825,"address":[],"length":0,"stats":{"Line":3}},{"line":826,"address":[],"length":0,"stats":{"Line":1}},{"line":827,"address":[],"length":0,"stats":{"Line":4}},{"line":830,"address":[],"length":0,"stats":{"Line":9}},{"line":831,"address":[],"length":0,"stats":{"Line":3}},{"line":832,"address":[],"length":0,"stats":{"Line":1}},{"line":833,"address":[],"length":0,"stats":{"Line":3}},{"line":834,"address":[],"length":0,"stats":{"Line":3}},{"line":838,"address":[],"length":0,"stats":{"Line":7}},{"line":839,"address":[],"length":0,"stats":{"Line":3}},{"line":840,"address":[],"length":0,"stats":{"Line":1}},{"line":841,"address":[],"length":0,"stats":{"Line":3}},{"line":842,"address":[],"length":0,"stats":{"Line":3}},{"line":854,"address":[],"length":0,"stats":{"Line":13}},{"line":855,"address":[],"length":0,"stats":{"Line":6}},{"line":856,"address":[],"length":0,"stats":{"Line":2}},{"line":857,"address":[],"length":0,"stats":{"Line":3}},{"line":859,"address":[],"length":0,"stats":{"Line":4}},{"line":860,"address":[],"length":0,"stats":{"Line":1}},{"line":866,"address":[],"length":0,"stats":{"Line":1}},{"line":874,"address":[],"length":0,"stats":{"Line":2}},{"line":875,"address":[],"length":0,"stats":{"Line":2}},{"line":876,"address":[],"length":0,"stats":{"Line":1}},{"line":880,"address":[],"length":0,"stats":{"Line":0}},{"line":881,"address":[],"length":0,"stats":{"Line":0}},{"line":882,"address":[],"length":0,"stats":{"Line":0}},{"line":883,"address":[],"length":0,"stats":{"Line":0}},{"line":890,"address":[],"length":0,"stats":{"Line":17}},{"line":896,"address":[],"length":0,"stats":{"Line":34}},{"line":897,"address":[],"length":0,"stats":{"Line":17}},{"line":898,"address":[],"length":0,"stats":{"Line":1}},{"line":899,"address":[],"length":0,"stats":{"Line":1}},{"line":904,"address":[],"length":0,"stats":{"Line":32}},{"line":905,"address":[],"length":0,"stats":{"Line":32}},{"line":907,"address":[],"length":0,"stats":{"Line":32}},{"line":908,"address":[],"length":0,"stats":{"Line":32}},{"line":909,"address":[],"length":0,"stats":{"Line":13}},{"line":910,"address":[],"length":0,"stats":{"Line":26}},{"line":911,"address":[],"length":0,"stats":{"Line":13}},{"line":912,"address":[],"length":0,"stats":{"Line":13}},{"line":914,"address":[],"length":0,"stats":{"Line":3}},{"line":915,"address":[],"length":0,"stats":{"Line":8}},{"line":916,"address":[],"length":0,"stats":{"Line":0}},{"line":917,"address":[],"length":0,"stats":{"Line":0}},{"line":918,"address":[],"length":0,"stats":{"Line":0}},{"line":920,"address":[],"length":0,"stats":{"Line":0}},{"line":921,"address":[],"length":0,"stats":{"Line":0}},{"line":922,"address":[],"length":0,"stats":{"Line":0}},{"line":924,"address":[],"length":0,"stats":{"Line":6}},{"line":925,"address":[],"length":0,"stats":{"Line":3}},{"line":926,"address":[],"length":0,"stats":{"Line":3}},{"line":932,"address":[],"length":0,"stats":{"Line":0}},{"line":933,"address":[],"length":0,"stats":{"Line":0}},{"line":934,"address":[],"length":0,"stats":{"Line":0}},{"line":935,"address":[],"length":0,"stats":{"Line":0}},{"line":939,"address":[],"length":0,"stats":{"Line":3}},{"line":940,"address":[],"length":0,"stats":{"Line":1}},{"line":941,"address":[],"length":0,"stats":{"Line":3}},{"line":944,"address":[],"length":0,"stats":{"Line":2}},{"line":974,"address":[],"length":0,"stats":{"Line":3}},{"line":975,"address":[],"length":0,"stats":{"Line":6}},{"line":976,"address":[],"length":0,"stats":{"Line":4}},{"line":977,"address":[],"length":0,"stats":{"Line":4}},{"line":978,"address":[],"length":0,"stats":{"Line":2}},{"line":983,"address":[],"length":0,"stats":{"Line":2}},{"line":984,"address":[],"length":0,"stats":{"Line":10}}],"covered":207,"coverable":281},{"path":["/","Users","christian.klat","dev","git","aeterna","context","src","lib.rs"],"content":"//! Context auto-resolution for Aeterna.\n//!\n//! This crate provides automatic detection and resolution of tenant context\n//! from multiple sources with precedence:\n//!\n//! 1. Explicit overrides (CLI flags, API params)\n//! 2. Environment variables (`AETERNA_*`)\n//! 3. Context file (`.aeterna/context.toml`)\n//! 4. Git remote URL -> project_id\n//! 5. Git config user.email -> user_id\n//! 6. Organization defaults (future: from server)\n//! 7. System defaults (\"default\"/\"default\")\n//!\n//! # Example\n//!\n//! ```rust,ignore\n//! use context::{ContextResolver, ResolvedContext};\n//!\n//! // Auto-detect everything from current directory\n//! let ctx = ContextResolver::new().resolve()?;\n//! println!(\"Tenant: {} (from {})\", ctx.tenant_id.value, ctx.tenant_id.source);\n//!\n//! // With explicit overrides\n//! let ctx = ContextResolver::new()\n//!     .with_override(\"tenant_id\", \"acme-corp\")\n//!     .with_override(\"hints\", \"no-llm,fast\")\n//!     .resolve()?;\n//! ```\n\npub mod cedar;\nmod resolver;\nmod types;\n\npub use cedar::{\n    AccessibleLayers, AuthorizationDecision, AuthorizationDiagnostics, AuthorizationRequest,\n    AuthorizationResponse, CedarClient, CedarConfig, CedarError, Entity, EntityUid,\n};\npub use resolver::{CedarContextResolver, ContextError, ContextResolver};\npub use types::{\n    ContextConfig, ContextSource, ResolvedContext, ResolvedValue, ServerConfig, StorageConfig,\n};\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","context","src","resolver.rs"],"content":"//! Context auto-resolution for Aeterna.\n//!\n//! Resolves tenant context from multiple sources with precedence:\n//! 1. Explicit overrides (CLI flags, API params)\n//! 2. Environment variables (AETERNA_*)\n//! 3. Context file (.aeterna/context.toml)\n//! 4. Git remote URL -> project_id\n//! 5. Git config user.email -> user_id\n//! 6. Organization defaults\n//! 7. System defaults\n\nuse std::collections::HashMap;\nuse std::env;\nuse std::path::{Path, PathBuf};\n\nuse git2::Repository;\nuse mk_core::hints::OperationHints;\nuse thiserror::Error;\nuse tracing::{debug, trace, warn};\n\nuse crate::types::{ContextConfig, ContextSource, ResolvedContext, ResolvedValue};\n\n/// Context resolution error types.\n#[derive(Debug, Error)]\npub enum ContextError {\n    #[error(\"Failed to read context file: {0}\")]\n    FileRead(#[from] std::io::Error),\n\n    #[error(\"Failed to parse context file: {0}\")]\n    ParseError(#[from] toml::de::Error),\n\n    #[error(\"Git error: {0}\")]\n    GitError(#[from] git2::Error),\n\n    #[error(\"Invalid context configuration: {0}\")]\n    InvalidConfig(String),\n}\n\n/// Environment variable prefix for Aeterna configuration.\nconst ENV_PREFIX: &str = \"AETERNA_\";\n\n/// Default context file name.\nconst CONTEXT_FILE: &str = \"context.toml\";\n\n/// Default context directory name.\nconst CONTEXT_DIR: &str = \".aeterna\";\n\n/// Resolves tenant context from multiple sources with precedence.\n///\n/// # Precedence (highest to lowest)\n///\n/// 1. Explicit overrides (via `with_override()`)\n/// 2. Environment variables (`AETERNA_TENANT_ID`, etc.)\n/// 3. Context file (`.aeterna/context.toml`)\n/// 4. Git remote URL -> project_id\n/// 5. Git config user.email -> user_id\n/// 6. Organization defaults (future: from server)\n/// 7. System defaults (\"default\"/\"default\")\n///\n/// # Example\n///\n/// ```rust,ignore\n/// use context::ContextResolver;\n///\n/// let resolver = ContextResolver::new()\n///     .with_override(\"tenant_id\", \"acme-corp\")\n///     .with_override(\"hints\", \"no-llm,fast\");\n///\n/// let ctx = resolver.resolve()?;\n/// println!(\"Tenant: {} (from {})\", ctx.tenant_id.value, ctx.tenant_id.source);\n/// ```\n#[derive(Debug, Clone)]\npub struct ContextResolver {\n    /// Starting directory for context file search.\n    start_dir: PathBuf,\n\n    /// Explicit overrides (highest precedence).\n    explicit_overrides: HashMap<String, String>,\n\n    /// Whether to skip git detection.\n    skip_git: bool,\n\n    /// Whether to skip environment variables.\n    skip_env: bool,\n\n    /// Maximum depth to search for context.toml.\n    max_search_depth: usize,\n}\n\nimpl Default for ContextResolver {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\nimpl ContextResolver {\n    /// Create a new resolver starting from current directory.\n    #[must_use]\n    pub fn new() -> Self {\n        Self {\n            start_dir: std::env::current_dir().unwrap_or_else(|_| PathBuf::from(\".\")),\n            explicit_overrides: HashMap::new(),\n            skip_git: false,\n            skip_env: false,\n            max_search_depth: 10,\n        }\n    }\n\n    /// Create a resolver starting from a specific directory.\n    #[must_use]\n    pub fn from_dir(dir: impl Into<PathBuf>) -> Self {\n        Self {\n            start_dir: dir.into(),\n            ..Self::new()\n        }\n    }\n\n    /// Add an explicit override (highest precedence).\n    #[must_use]\n    pub fn with_override(mut self, key: &str, value: &str) -> Self {\n        self.explicit_overrides\n            .insert(key.to_string(), value.to_string());\n        self\n    }\n\n    /// Add multiple explicit overrides.\n    #[must_use]\n    pub fn with_overrides(mut self, overrides: HashMap<String, String>) -> Self {\n        self.explicit_overrides.extend(overrides);\n        self\n    }\n\n    /// Skip git detection (for testing or non-git environments).\n    #[must_use]\n    pub fn skip_git(mut self) -> Self {\n        self.skip_git = true;\n        self\n    }\n\n    /// Skip environment variable detection.\n    #[must_use]\n    pub fn skip_env(mut self) -> Self {\n        self.skip_env = true;\n        self\n    }\n\n    /// Set maximum depth for context.toml search.\n    #[must_use]\n    pub fn with_max_search_depth(mut self, depth: usize) -> Self {\n        self.max_search_depth = depth;\n        self\n    }\n\n    /// Resolve context from all sources.\n    ///\n    /// # Errors\n    ///\n    /// Returns error if context file exists but cannot be parsed.\n    pub fn resolve(&self) -> Result<ResolvedContext, ContextError> {\n        let mut ctx = ResolvedContext::default();\n\n        // Find context file and git root\n        let context_toml_path = self.find_context_toml();\n        let git_root = if self.skip_git {\n            None\n        } else {\n            self.find_git_root()\n        };\n\n        ctx.context_root = context_toml_path\n            .as_ref()\n            .and_then(|p| p.parent().map(PathBuf::from));\n        ctx.git_root = git_root.clone();\n\n        // Layer 7: System defaults (already in ResolvedContext::default())\n        debug!(\"Starting context resolution from {:?}\", self.start_dir);\n\n        // Layer 6: Organization defaults (TODO: fetch from server)\n        // For now, skip this layer\n\n        // Layer 5: Git config user.email -> user_id\n        if let Some(ref git_path) = git_root {\n            if let Some(email) = self.resolve_git_user_email(git_path) {\n                trace!(\"Found git user.email: {}\", email);\n                ctx.user_id = ResolvedValue::new(email, ContextSource::GitConfig);\n            }\n        }\n\n        // Layer 4: Git remote URL -> project_id\n        if let Some(ref git_path) = git_root {\n            if let Some(project_id) = self.resolve_git_project_id(git_path) {\n                trace!(\"Found git project_id: {}\", project_id);\n                ctx.project_id = Some(ResolvedValue::new(project_id, ContextSource::GitRemote));\n            }\n        }\n\n        // Layer 3: Context file (.aeterna/context.toml)\n        if let Some(ref toml_path) = context_toml_path {\n            match self.load_context_toml(toml_path) {\n                Ok(config) => {\n                    self.apply_context_config(&mut ctx, &config, toml_path);\n                }\n                Err(e) => {\n                    warn!(\"Failed to load context.toml: {}\", e);\n                    // Don't fail - continue with other sources\n                }\n            }\n        }\n\n        // Layer 2: Environment variables\n        if !self.skip_env {\n            self.apply_env_vars(&mut ctx);\n        }\n\n        // Layer 1: Explicit overrides (highest precedence)\n        self.apply_explicit_overrides(&mut ctx);\n\n        debug!(\n            \"Resolved context: tenant={} user={} project={:?}\",\n            ctx.tenant_id.value,\n            ctx.user_id.value,\n            ctx.project_id.as_ref().map(|p| &p.value)\n        );\n\n        Ok(ctx)\n    }\n\n    /// Find `.aeterna/context.toml` by walking up the directory tree.\n    fn find_context_toml(&self) -> Option<PathBuf> {\n        let mut current = self.start_dir.clone();\n        let mut depth = 0;\n\n        loop {\n            let context_path = current.join(CONTEXT_DIR).join(CONTEXT_FILE);\n            if context_path.exists() {\n                debug!(\"Found context.toml at {:?}\", context_path);\n                return Some(context_path);\n            }\n\n            // Also check for context.toml directly (without .aeterna directory)\n            let direct_path = current.join(CONTEXT_FILE);\n            if direct_path.exists() {\n                debug!(\"Found context.toml at {:?}\", direct_path);\n                return Some(direct_path);\n            }\n\n            depth += 1;\n            if depth >= self.max_search_depth {\n                break;\n            }\n\n            match current.parent() {\n                Some(parent) if parent != current => {\n                    current = parent.to_path_buf();\n                }\n                _ => break,\n            }\n        }\n\n        trace!(\n            \"No context.toml found after searching {} levels\",\n            self.max_search_depth\n        );\n        None\n    }\n\n    /// Find git repository root.\n    fn find_git_root(&self) -> Option<PathBuf> {\n        Repository::discover(&self.start_dir)\n            .ok()\n            .and_then(|repo| repo.workdir().map(PathBuf::from))\n    }\n\n    /// Extract user email from git config.\n    fn resolve_git_user_email(&self, git_root: &Path) -> Option<String> {\n        let repo = Repository::open(git_root).ok()?;\n        let config = repo.config().ok()?;\n\n        // Try repository-level config first, then global\n        config\n            .get_string(\"user.email\")\n            .ok()\n            .filter(|e| !e.is_empty())\n    }\n\n    /// Extract project_id from git remote URL.\n    ///\n    /// Parses URLs like:\n    /// - `git@github.com:org/repo.git` -> `org/repo`\n    /// - `https://github.com/org/repo.git` -> `org/repo`\n    /// - `https://github.com/org/repo` -> `org/repo`\n    fn resolve_git_project_id(&self, git_root: &Path) -> Option<String> {\n        let repo = Repository::open(git_root).ok()?;\n        let remote = repo.find_remote(\"origin\").ok()?;\n        let url = remote.url()?;\n\n        parse_git_remote_url(url)\n    }\n\n    /// Load and parse context.toml file.\n    fn load_context_toml(&self, path: &Path) -> Result<ContextConfig, ContextError> {\n        let content = std::fs::read_to_string(path)?;\n        let config: ContextConfig = toml::from_str(&content)?;\n        Ok(config)\n    }\n\n    /// Apply values from context.toml to resolved context.\n    fn apply_context_config(\n        &self,\n        ctx: &mut ResolvedContext,\n        config: &ContextConfig,\n        toml_path: &Path,\n    ) {\n        let source = ContextSource::ContextToml(toml_path.to_path_buf());\n\n        if let Some(ref tenant_id) = config.tenant_id {\n            ctx.tenant_id = ResolvedValue::new(tenant_id.clone(), source.clone());\n        }\n\n        if let Some(ref user_id) = config.user_id {\n            ctx.user_id = ResolvedValue::new(user_id.clone(), source.clone());\n        }\n\n        if let Some(ref org_id) = config.org_id {\n            ctx.org_id = Some(ResolvedValue::new(org_id.clone(), source.clone()));\n        }\n\n        if let Some(ref team_id) = config.team_id {\n            ctx.team_id = Some(ResolvedValue::new(team_id.clone(), source.clone()));\n        }\n\n        if let Some(ref project_id) = config.project_id {\n            ctx.project_id = Some(ResolvedValue::new(project_id.clone(), source.clone()));\n        }\n\n        if let Some(ref agent_id) = config.agent_id {\n            ctx.agent_id = Some(ResolvedValue::new(agent_id.clone(), source.clone()));\n        }\n\n        // Apply hints\n        let hints = config.to_hints();\n        if hints != OperationHints::default() {\n            ctx.hints = ResolvedValue::new(hints, source);\n        }\n    }\n\n    /// Apply environment variables to resolved context.\n    fn apply_env_vars(&self, ctx: &mut ResolvedContext) {\n        // AETERNA_TENANT_ID\n        if let Ok(value) = env::var(format!(\"{ENV_PREFIX}TENANT_ID\")) {\n            ctx.tenant_id = ResolvedValue::new(\n                value,\n                ContextSource::EnvVar(format!(\"{ENV_PREFIX}TENANT_ID\")),\n            );\n        }\n\n        // AETERNA_USER_ID\n        if let Ok(value) = env::var(format!(\"{ENV_PREFIX}USER_ID\")) {\n            ctx.user_id =\n                ResolvedValue::new(value, ContextSource::EnvVar(format!(\"{ENV_PREFIX}USER_ID\")));\n        }\n\n        // AETERNA_ORG_ID\n        if let Ok(value) = env::var(format!(\"{ENV_PREFIX}ORG_ID\")) {\n            ctx.org_id = Some(ResolvedValue::new(\n                value,\n                ContextSource::EnvVar(format!(\"{ENV_PREFIX}ORG_ID\")),\n            ));\n        }\n\n        // AETERNA_TEAM_ID\n        if let Ok(value) = env::var(format!(\"{ENV_PREFIX}TEAM_ID\")) {\n            ctx.team_id = Some(ResolvedValue::new(\n                value,\n                ContextSource::EnvVar(format!(\"{ENV_PREFIX}TEAM_ID\")),\n            ));\n        }\n\n        // AETERNA_PROJECT_ID\n        if let Ok(value) = env::var(format!(\"{ENV_PREFIX}PROJECT_ID\")) {\n            ctx.project_id = Some(ResolvedValue::new(\n                value,\n                ContextSource::EnvVar(format!(\"{ENV_PREFIX}PROJECT_ID\")),\n            ));\n        }\n\n        // AETERNA_AGENT_ID\n        if let Ok(value) = env::var(format!(\"{ENV_PREFIX}AGENT_ID\")) {\n            ctx.agent_id = Some(ResolvedValue::new(\n                value,\n                ContextSource::EnvVar(format!(\"{ENV_PREFIX}AGENT_ID\")),\n            ));\n        }\n\n        // AETERNA_HINTS (merged with existing hints from env)\n        let env_hints = OperationHints::from_env();\n        if env_hints != OperationHints::default() {\n            // Merge with existing hints\n            let merged = ctx.hints.value.clone().merge(&env_hints);\n            ctx.hints = ResolvedValue::new(\n                merged,\n                ContextSource::EnvVar(format!(\"{ENV_PREFIX}HINTS_*\")),\n            );\n        }\n    }\n\n    /// Apply explicit overrides to resolved context.\n    fn apply_explicit_overrides(&self, ctx: &mut ResolvedContext) {\n        if let Some(value) = self.explicit_overrides.get(\"tenant_id\") {\n            ctx.tenant_id = ResolvedValue::explicit(value.clone());\n        }\n\n        if let Some(value) = self.explicit_overrides.get(\"user_id\") {\n            ctx.user_id = ResolvedValue::explicit(value.clone());\n        }\n\n        if let Some(value) = self.explicit_overrides.get(\"org_id\") {\n            ctx.org_id = Some(ResolvedValue::explicit(value.clone()));\n        }\n\n        if let Some(value) = self.explicit_overrides.get(\"team_id\") {\n            ctx.team_id = Some(ResolvedValue::explicit(value.clone()));\n        }\n\n        if let Some(value) = self.explicit_overrides.get(\"project_id\") {\n            ctx.project_id = Some(ResolvedValue::explicit(value.clone()));\n        }\n\n        if let Some(value) = self.explicit_overrides.get(\"agent_id\") {\n            ctx.agent_id = Some(ResolvedValue::explicit(value.clone()));\n        }\n\n        if let Some(value) = self.explicit_overrides.get(\"session_id\") {\n            ctx.session_id = Some(ResolvedValue::explicit(value.clone()));\n        }\n\n        // Parse hints from string (e.g., \"no-llm,fast,no-reasoning\")\n        if let Some(value) = self.explicit_overrides.get(\"hints\") {\n            let hints = OperationHints::parse_hint_string(value);\n            ctx.hints = ResolvedValue::explicit(hints);\n        }\n\n        // Handle preset override\n        if let Some(value) = self.explicit_overrides.get(\"preset\") {\n            if let Ok(preset) = value.parse() {\n                let hints = OperationHints::from_preset(preset);\n                ctx.hints = ResolvedValue::explicit(hints);\n            }\n        }\n    }\n}\n\n/// Resolves and enriches context using Cedar Agent.\n///\n/// This resolver wraps the standard `ContextResolver` and adds Cedar Agent\n/// integration for:\n/// - Resolving user by email (from git config)\n/// - Resolving project by git remote URL\n/// - Discovering accessible layers (company/org/team/project)\n///\n/// # Example\n///\n/// ```rust,ignore\n/// use context::{ContextResolver, CedarContextResolver};\n///\n/// // First resolve local context\n/// let local_ctx = ContextResolver::new().resolve()?;\n///\n/// // Then enrich with Cedar Agent data\n/// let cedar = CedarContextResolver::new();\n/// let enriched = cedar.enrich(local_ctx).await?;\n/// ```\npub struct CedarContextResolver {\n    client: crate::cedar::CedarClient,\n}\n\nimpl CedarContextResolver {\n    #[must_use]\n    pub fn new() -> Self {\n        Self {\n            client: crate::cedar::CedarClient::from_env(),\n        }\n    }\n\n    #[must_use]\n    pub fn with_config(config: crate::cedar::CedarConfig) -> Self {\n        Self {\n            client: crate::cedar::CedarClient::new(config),\n        }\n    }\n\n    pub async fn health_check(&self) -> bool {\n        self.client.health_check().await.unwrap_or(false)\n    }\n\n    /// Enrich resolved context with Cedar Agent data.\n    ///\n    /// Attempts to resolve user and project from Cedar Agent based on:\n    /// - user_id (if it looks like an email, resolve to Cedar User entity)\n    /// - project_id (if resolved from git remote, resolve to Cedar Project entity)\n    ///\n    /// If Cedar Agent is unavailable, returns the original context unchanged.\n    pub async fn enrich(&self, mut ctx: ResolvedContext) -> Result<ResolvedContext, ContextError> {\n        if !self.client.health_check().await.unwrap_or(false) {\n            warn!(\"Cedar Agent unavailable, using local context only\");\n            return Ok(ctx);\n        }\n\n        if let Some(ref project) = ctx.project_id {\n            if project.source == ContextSource::GitRemote {\n                if let Ok(cedar_project) = self\n                    .client\n                    .resolve_project_by_git_remote(&project.value)\n                    .await\n                {\n                    debug!(\n                        \"Resolved project from Cedar Agent: {}\",\n                        cedar_project.uid.id\n                    );\n                    ctx.project_id = Some(ResolvedValue::new(\n                        cedar_project.uid.id.clone(),\n                        ContextSource::CedarAgent,\n                    ));\n\n                    if let Some(team_parent) = cedar_project\n                        .parents\n                        .iter()\n                        .find(|p| p.entity_type == \"Aeterna::Team\")\n                    {\n                        ctx.team_id = Some(ResolvedValue::new(\n                            team_parent.id.clone(),\n                            ContextSource::CedarAgent,\n                        ));\n                    }\n                }\n            }\n        }\n\n        if ctx.user_id.source == ContextSource::GitConfig && ctx.user_id.value.contains('@') {\n            if let Ok(cedar_user) = self.client.resolve_user_by_email(&ctx.user_id.value).await {\n                debug!(\"Resolved user from Cedar Agent: {}\", cedar_user.uid.id);\n                ctx.user_id =\n                    ResolvedValue::new(cedar_user.uid.id.clone(), ContextSource::CedarAgent);\n\n                if ctx.tenant_id.source == ContextSource::SystemDefault {\n                    if let Some(company_slug) = cedar_user.get_attr_str(\"company_slug\") {\n                        ctx.tenant_id =\n                            ResolvedValue::new(company_slug.to_string(), ContextSource::CedarAgent);\n                    }\n                }\n            }\n        }\n\n        Ok(ctx)\n    }\n\n    /// Get accessible layers for the current user.\n    pub async fn get_accessible_layers(\n        &self,\n        user_id: &str,\n    ) -> Result<crate::cedar::AccessibleLayers, crate::cedar::CedarError> {\n        self.client.get_accessible_layers(user_id).await\n    }\n\n    /// Check if a user is authorized to perform an action.\n    pub async fn check_authorization(\n        &self,\n        principal: &crate::cedar::EntityUid,\n        action: &str,\n        resource: &crate::cedar::EntityUid,\n    ) -> Result<bool, crate::cedar::CedarError> {\n        self.client\n            .check_authorization(principal, action, resource, None)\n            .await\n    }\n\n    pub fn client(&self) -> &crate::cedar::CedarClient {\n        &self.client\n    }\n}\n\nimpl Default for CedarContextResolver {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n/// Parse git remote URL to extract org/repo.\n///\n/// Supports:\n/// - SSH: `git@github.com:org/repo.git`\n/// - HTTPS: `https://github.com/org/repo.git`\n/// - HTTPS without .git: `https://github.com/org/repo`\nfn parse_git_remote_url(url: &str) -> Option<String> {\n    // SSH format: git@github.com:org/repo.git\n    if url.starts_with(\"git@\") {\n        let parts: Vec<&str> = url.split(':').collect();\n        if parts.len() == 2 {\n            let path = parts[1].trim_end_matches(\".git\");\n            return Some(path.to_string());\n        }\n    }\n\n    // HTTPS format: https://github.com/org/repo.git\n    if url.starts_with(\"https://\") || url.starts_with(\"http://\") {\n        let path = url\n            .trim_start_matches(\"https://\")\n            .trim_start_matches(\"http://\");\n\n        // Skip the hostname\n        let parts: Vec<&str> = path.splitn(2, '/').collect();\n        if parts.len() == 2 {\n            let repo_path = parts[1].trim_end_matches(\".git\");\n            return Some(repo_path.to_string());\n        }\n    }\n\n    None\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::fs;\n    use tempfile::TempDir;\n\n    #[test]\n    fn test_parse_git_remote_ssh() {\n        assert_eq!(\n            parse_git_remote_url(\"git@github.com:acme-corp/payments-service.git\"),\n            Some(\"acme-corp/payments-service\".to_string())\n        );\n    }\n\n    #[test]\n    fn test_parse_git_remote_https_with_git() {\n        assert_eq!(\n            parse_git_remote_url(\"https://github.com/acme-corp/payments-service.git\"),\n            Some(\"acme-corp/payments-service\".to_string())\n        );\n    }\n\n    #[test]\n    fn test_parse_git_remote_https_without_git() {\n        assert_eq!(\n            parse_git_remote_url(\"https://github.com/acme-corp/payments-service\"),\n            Some(\"acme-corp/payments-service\".to_string())\n        );\n    }\n\n    #[test]\n    fn test_parse_git_remote_gitlab() {\n        assert_eq!(\n            parse_git_remote_url(\"git@gitlab.com:my-org/my-project.git\"),\n            Some(\"my-org/my-project\".to_string())\n        );\n    }\n\n    #[test]\n    fn test_resolver_default() {\n        let resolver = ContextResolver::new();\n        let ctx = resolver.skip_git().skip_env().resolve().unwrap();\n\n        assert_eq!(ctx.tenant_id.value, \"default\");\n        assert_eq!(ctx.user_id.value, \"default\");\n        assert!(ctx.org_id.is_none());\n    }\n\n    #[test]\n    fn test_resolver_explicit_overrides() {\n        let resolver = ContextResolver::new()\n            .skip_git()\n            .skip_env()\n            .with_override(\"tenant_id\", \"acme-corp\")\n            .with_override(\"user_id\", \"alice\")\n            .with_override(\"org_id\", \"platform\");\n\n        let ctx = resolver.resolve().unwrap();\n\n        assert_eq!(ctx.tenant_id.value, \"acme-corp\");\n        assert_eq!(ctx.tenant_id.source, ContextSource::Explicit);\n        assert_eq!(ctx.user_id.value, \"alice\");\n        assert_eq!(ctx.org_id.unwrap().value, \"platform\");\n    }\n\n    #[test]\n    fn test_resolver_hints_override() {\n        let resolver = ContextResolver::new()\n            .skip_git()\n            .skip_env()\n            .with_override(\"hints\", \"fast,no-llm,no-reasoning\");\n\n        let ctx = resolver.resolve().unwrap();\n\n        assert!(!ctx.hints.value.llm);\n        assert!(!ctx.hints.value.reasoning);\n    }\n\n    #[test]\n    fn test_resolver_preset_override() {\n        let resolver = ContextResolver::new()\n            .skip_git()\n            .skip_env()\n            .with_override(\"preset\", \"minimal\");\n\n        let ctx = resolver.resolve().unwrap();\n\n        assert!(!ctx.hints.value.llm);\n        assert!(!ctx.hints.value.reasoning);\n        assert!(!ctx.hints.value.multi_hop);\n    }\n\n    #[test]\n    fn test_resolver_with_context_toml() {\n        let temp_dir = TempDir::new().unwrap();\n        let aeterna_dir = temp_dir.path().join(\".aeterna\");\n        fs::create_dir(&aeterna_dir).unwrap();\n\n        let toml_content = r#\"\ntenant-id = \"acme-corp\"\nuser-id = \"alice\"\norg-id = \"platform\"\nproject-id = \"payments\"\n\n[hints]\npreset = \"fast\"\nverbose = true\n\"#;\n\n        fs::write(aeterna_dir.join(\"context.toml\"), toml_content).unwrap();\n\n        let resolver = ContextResolver::from_dir(temp_dir.path())\n            .skip_git()\n            .skip_env();\n\n        let ctx = resolver.resolve().unwrap();\n\n        assert_eq!(ctx.tenant_id.value, \"acme-corp\");\n        assert_eq!(ctx.user_id.value, \"alice\");\n        assert_eq!(ctx.org_id.unwrap().value, \"platform\");\n        assert_eq!(ctx.project_id.unwrap().value, \"payments\");\n        assert!(ctx.hints.value.verbose);\n        assert!(!ctx.hints.value.reasoning); // Fast preset disables reasoning\n    }\n\n    #[test]\n    fn test_resolver_context_toml_without_aeterna_dir() {\n        let temp_dir = TempDir::new().unwrap();\n\n        let toml_content = r#\"\ntenant-id = \"direct-tenant\"\nuser-id = \"direct-user\"\n\"#;\n\n        fs::write(temp_dir.path().join(\"context.toml\"), toml_content).unwrap();\n\n        let resolver = ContextResolver::from_dir(temp_dir.path())\n            .skip_git()\n            .skip_env();\n\n        let ctx = resolver.resolve().unwrap();\n\n        assert_eq!(ctx.tenant_id.value, \"direct-tenant\");\n        assert_eq!(ctx.user_id.value, \"direct-user\");\n    }\n\n    #[test]\n    fn test_resolver_walks_up_directory() {\n        let temp_dir = TempDir::new().unwrap();\n        let deep_dir = temp_dir.path().join(\"a/b/c/d\");\n        fs::create_dir_all(&deep_dir).unwrap();\n\n        // Create context.toml at root\n        let aeterna_dir = temp_dir.path().join(\".aeterna\");\n        fs::create_dir(&aeterna_dir).unwrap();\n        fs::write(\n            aeterna_dir.join(\"context.toml\"),\n            \"tenant-id = \\\"root-tenant\\\"\",\n        )\n        .unwrap();\n\n        // Resolve from deep directory\n        let resolver = ContextResolver::from_dir(&deep_dir).skip_git().skip_env();\n\n        let ctx = resolver.resolve().unwrap();\n\n        assert_eq!(ctx.tenant_id.value, \"root-tenant\");\n    }\n\n    #[test]\n    fn test_resolver_precedence() {\n        let temp_dir = TempDir::new().unwrap();\n        let aeterna_dir = temp_dir.path().join(\".aeterna\");\n        fs::create_dir(&aeterna_dir).unwrap();\n\n        // Context.toml sets tenant_id = \"from-file\"\n        fs::write(\n            aeterna_dir.join(\"context.toml\"),\n            \"tenant-id = \\\"from-file\\\"\",\n        )\n        .unwrap();\n\n        // Explicit override should win\n        let resolver = ContextResolver::from_dir(temp_dir.path())\n            .skip_git()\n            .skip_env()\n            .with_override(\"tenant_id\", \"from-override\");\n\n        let ctx = resolver.resolve().unwrap();\n\n        assert_eq!(ctx.tenant_id.value, \"from-override\");\n        assert_eq!(ctx.tenant_id.source, ContextSource::Explicit);\n    }\n\n    #[test]\n    fn test_resolver_explain() {\n        let resolver = ContextResolver::new()\n            .skip_git()\n            .skip_env()\n            .with_override(\"tenant_id\", \"test-tenant\")\n            .with_override(\"org_id\", \"test-org\");\n\n        let ctx = resolver.resolve().unwrap();\n        let explanations = ctx.explain();\n\n        assert!(\n            explanations\n                .iter()\n                .any(|(name, value, _)| name == \"tenant_id\" && value == \"test-tenant\")\n        );\n        assert!(\n            explanations\n                .iter()\n                .any(|(name, value, _)| name == \"org_id\" && value == \"test-org\")\n        );\n    }\n\n    #[test]\n    fn test_resolver_to_tenant_context() {\n        let resolver = ContextResolver::new()\n            .skip_git()\n            .skip_env()\n            .with_override(\"tenant_id\", \"acme\")\n            .with_override(\"user_id\", \"bob\");\n\n        let ctx = resolver.resolve().unwrap();\n        let tenant_ctx = ctx.to_tenant_context();\n\n        assert_eq!(tenant_ctx.tenant_id.as_str(), \"acme\");\n        assert_eq!(tenant_ctx.user_id.as_str(), \"bob\");\n    }\n\n    #[test]\n    fn test_resolver_with_agent_id() {\n        let resolver = ContextResolver::new()\n            .skip_git()\n            .skip_env()\n            .with_override(\"tenant_id\", \"acme\")\n            .with_override(\"user_id\", \"bob\")\n            .with_override(\"agent_id\", \"code-assistant-1\");\n\n        let ctx = resolver.resolve().unwrap();\n        let tenant_ctx = ctx.to_tenant_context();\n\n        assert!(tenant_ctx.agent_id.is_some());\n        assert_eq!(tenant_ctx.agent_id.unwrap(), \"code-assistant-1\");\n    }\n\n    #[test]\n    fn test_resolver_max_search_depth() {\n        let temp_dir = TempDir::new().unwrap();\n        let deep_dir = temp_dir.path().join(\"a/b/c/d/e\");\n        fs::create_dir_all(&deep_dir).unwrap();\n\n        let aeterna_dir = temp_dir.path().join(\".aeterna\");\n        fs::create_dir(&aeterna_dir).unwrap();\n        fs::write(\n            aeterna_dir.join(\"context.toml\"),\n            \"tenant-id = \\\"root-tenant\\\"\",\n        )\n        .unwrap();\n\n        let resolver = ContextResolver::from_dir(&deep_dir)\n            .skip_git()\n            .skip_env()\n            .with_max_search_depth(10);\n\n        let ctx = resolver.resolve().unwrap();\n        assert_eq!(ctx.tenant_id.value, \"root-tenant\");\n\n        let resolver = ContextResolver::from_dir(&deep_dir)\n            .skip_git()\n            .skip_env()\n            .with_max_search_depth(3);\n\n        let ctx = resolver.resolve().unwrap();\n        assert_eq!(ctx.tenant_id.value, \"default\");\n    }\n\n    #[test]\n    fn test_context_root_tracking() {\n        let temp_dir = TempDir::new().unwrap();\n        let aeterna_dir = temp_dir.path().join(\".aeterna\");\n        fs::create_dir(&aeterna_dir).unwrap();\n        fs::write(aeterna_dir.join(\"context.toml\"), \"tenant-id = \\\"test\\\"\").unwrap();\n\n        let resolver = ContextResolver::from_dir(temp_dir.path())\n            .skip_git()\n            .skip_env();\n\n        let ctx = resolver.resolve().unwrap();\n\n        assert!(ctx.context_root.is_some());\n        assert_eq!(ctx.context_root.unwrap(), aeterna_dir);\n    }\n}\n","traces":[{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":48}},{"line":101,"address":[],"length":0,"stats":{"Line":96}},{"line":102,"address":[],"length":0,"stats":{"Line":48}},{"line":111,"address":[],"length":0,"stats":{"Line":7}},{"line":113,"address":[],"length":0,"stats":{"Line":14}},{"line":120,"address":[],"length":0,"stats":{"Line":13}},{"line":121,"address":[],"length":0,"stats":{"Line":13}},{"line":122,"address":[],"length":0,"stats":{"Line":65}},{"line":123,"address":[],"length":0,"stats":{"Line":13}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":14}},{"line":136,"address":[],"length":0,"stats":{"Line":14}},{"line":137,"address":[],"length":0,"stats":{"Line":14}},{"line":142,"address":[],"length":0,"stats":{"Line":14}},{"line":143,"address":[],"length":0,"stats":{"Line":14}},{"line":144,"address":[],"length":0,"stats":{"Line":14}},{"line":149,"address":[],"length":0,"stats":{"Line":2}},{"line":150,"address":[],"length":0,"stats":{"Line":2}},{"line":151,"address":[],"length":0,"stats":{"Line":2}},{"line":159,"address":[],"length":0,"stats":{"Line":48}},{"line":160,"address":[],"length":0,"stats":{"Line":96}},{"line":163,"address":[],"length":0,"stats":{"Line":144}},{"line":164,"address":[],"length":0,"stats":{"Line":96}},{"line":165,"address":[],"length":0,"stats":{"Line":14}},{"line":167,"address":[],"length":0,"stats":{"Line":68}},{"line":170,"address":[],"length":0,"stats":{"Line":96}},{"line":171,"address":[],"length":0,"stats":{"Line":48}},{"line":172,"address":[],"length":0,"stats":{"Line":60}},{"line":173,"address":[],"length":0,"stats":{"Line":144}},{"line":176,"address":[],"length":0,"stats":{"Line":48}},{"line":182,"address":[],"length":0,"stats":{"Line":82}},{"line":183,"address":[],"length":0,"stats":{"Line":102}},{"line":184,"address":[],"length":0,"stats":{"Line":34}},{"line":185,"address":[],"length":0,"stats":{"Line":136}},{"line":190,"address":[],"length":0,"stats":{"Line":82}},{"line":191,"address":[],"length":0,"stats":{"Line":102}},{"line":192,"address":[],"length":0,"stats":{"Line":34}},{"line":193,"address":[],"length":0,"stats":{"Line":102}},{"line":198,"address":[],"length":0,"stats":{"Line":54}},{"line":199,"address":[],"length":0,"stats":{"Line":12}},{"line":200,"address":[],"length":0,"stats":{"Line":12}},{"line":201,"address":[],"length":0,"stats":{"Line":24}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":204,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":82}},{"line":212,"address":[],"length":0,"stats":{"Line":68}},{"line":216,"address":[],"length":0,"stats":{"Line":144}},{"line":218,"address":[],"length":0,"stats":{"Line":48}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":225,"address":[],"length":0,"stats":{"Line":48}},{"line":229,"address":[],"length":0,"stats":{"Line":48}},{"line":230,"address":[],"length":0,"stats":{"Line":144}},{"line":231,"address":[],"length":0,"stats":{"Line":96}},{"line":234,"address":[],"length":0,"stats":{"Line":610}},{"line":235,"address":[],"length":0,"stats":{"Line":305}},{"line":236,"address":[],"length":0,"stats":{"Line":5}},{"line":237,"address":[],"length":0,"stats":{"Line":5}},{"line":241,"address":[],"length":0,"stats":{"Line":600}},{"line":242,"address":[],"length":0,"stats":{"Line":300}},{"line":243,"address":[],"length":0,"stats":{"Line":1}},{"line":244,"address":[],"length":0,"stats":{"Line":1}},{"line":247,"address":[],"length":0,"stats":{"Line":299}},{"line":248,"address":[],"length":0,"stats":{"Line":299}},{"line":249,"address":[],"length":0,"stats":{"Line":1}},{"line":252,"address":[],"length":0,"stats":{"Line":596}},{"line":253,"address":[],"length":0,"stats":{"Line":1028}},{"line":254,"address":[],"length":0,"stats":{"Line":514}},{"line":256,"address":[],"length":0,"stats":{"Line":41}},{"line":260,"address":[],"length":0,"stats":{"Line":42}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":264,"address":[],"length":0,"stats":{"Line":42}},{"line":268,"address":[],"length":0,"stats":{"Line":34}},{"line":269,"address":[],"length":0,"stats":{"Line":68}},{"line":271,"address":[],"length":0,"stats":{"Line":136}},{"line":275,"address":[],"length":0,"stats":{"Line":34}},{"line":276,"address":[],"length":0,"stats":{"Line":136}},{"line":277,"address":[],"length":0,"stats":{"Line":136}},{"line":280,"address":[],"length":0,"stats":{"Line":34}},{"line":283,"address":[],"length":0,"stats":{"Line":102}},{"line":292,"address":[],"length":0,"stats":{"Line":34}},{"line":293,"address":[],"length":0,"stats":{"Line":136}},{"line":294,"address":[],"length":0,"stats":{"Line":170}},{"line":295,"address":[],"length":0,"stats":{"Line":102}},{"line":297,"address":[],"length":0,"stats":{"Line":68}},{"line":301,"address":[],"length":0,"stats":{"Line":6}},{"line":302,"address":[],"length":0,"stats":{"Line":18}},{"line":303,"address":[],"length":0,"stats":{"Line":24}},{"line":304,"address":[],"length":0,"stats":{"Line":6}},{"line":308,"address":[],"length":0,"stats":{"Line":6}},{"line":314,"address":[],"length":0,"stats":{"Line":12}},{"line":316,"address":[],"length":0,"stats":{"Line":18}},{"line":317,"address":[],"length":0,"stats":{"Line":30}},{"line":320,"address":[],"length":0,"stats":{"Line":10}},{"line":321,"address":[],"length":0,"stats":{"Line":10}},{"line":324,"address":[],"length":0,"stats":{"Line":8}},{"line":325,"address":[],"length":0,"stats":{"Line":5}},{"line":328,"address":[],"length":0,"stats":{"Line":6}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":8}},{"line":333,"address":[],"length":0,"stats":{"Line":5}},{"line":336,"address":[],"length":0,"stats":{"Line":6}},{"line":337,"address":[],"length":0,"stats":{"Line":0}},{"line":341,"address":[],"length":0,"stats":{"Line":18}},{"line":342,"address":[],"length":0,"stats":{"Line":7}},{"line":343,"address":[],"length":0,"stats":{"Line":3}},{"line":348,"address":[],"length":0,"stats":{"Line":34}},{"line":350,"address":[],"length":0,"stats":{"Line":68}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":353,"address":[],"length":0,"stats":{"Line":0}},{"line":358,"address":[],"length":0,"stats":{"Line":68}},{"line":359,"address":[],"length":0,"stats":{"Line":0}},{"line":360,"address":[],"length":0,"stats":{"Line":0}},{"line":364,"address":[],"length":0,"stats":{"Line":68}},{"line":365,"address":[],"length":0,"stats":{"Line":0}},{"line":366,"address":[],"length":0,"stats":{"Line":0}},{"line":367,"address":[],"length":0,"stats":{"Line":0}},{"line":372,"address":[],"length":0,"stats":{"Line":68}},{"line":373,"address":[],"length":0,"stats":{"Line":0}},{"line":374,"address":[],"length":0,"stats":{"Line":0}},{"line":375,"address":[],"length":0,"stats":{"Line":0}},{"line":380,"address":[],"length":0,"stats":{"Line":68}},{"line":381,"address":[],"length":0,"stats":{"Line":0}},{"line":382,"address":[],"length":0,"stats":{"Line":0}},{"line":383,"address":[],"length":0,"stats":{"Line":0}},{"line":388,"address":[],"length":0,"stats":{"Line":68}},{"line":389,"address":[],"length":0,"stats":{"Line":0}},{"line":390,"address":[],"length":0,"stats":{"Line":0}},{"line":391,"address":[],"length":0,"stats":{"Line":0}},{"line":396,"address":[],"length":0,"stats":{"Line":68}},{"line":397,"address":[],"length":0,"stats":{"Line":34}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":400,"address":[],"length":0,"stats":{"Line":0}},{"line":401,"address":[],"length":0,"stats":{"Line":0}},{"line":402,"address":[],"length":0,"stats":{"Line":0}},{"line":408,"address":[],"length":0,"stats":{"Line":48}},{"line":409,"address":[],"length":0,"stats":{"Line":106}},{"line":410,"address":[],"length":0,"stats":{"Line":15}},{"line":413,"address":[],"length":0,"stats":{"Line":102}},{"line":414,"address":[],"length":0,"stats":{"Line":9}},{"line":417,"address":[],"length":0,"stats":{"Line":100}},{"line":418,"address":[],"length":0,"stats":{"Line":6}},{"line":421,"address":[],"length":0,"stats":{"Line":96}},{"line":422,"address":[],"length":0,"stats":{"Line":0}},{"line":425,"address":[],"length":0,"stats":{"Line":96}},{"line":426,"address":[],"length":0,"stats":{"Line":0}},{"line":429,"address":[],"length":0,"stats":{"Line":98}},{"line":430,"address":[],"length":0,"stats":{"Line":3}},{"line":433,"address":[],"length":0,"stats":{"Line":96}},{"line":434,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":98}},{"line":439,"address":[],"length":0,"stats":{"Line":4}},{"line":440,"address":[],"length":0,"stats":{"Line":2}},{"line":444,"address":[],"length":0,"stats":{"Line":97}},{"line":445,"address":[],"length":0,"stats":{"Line":3}},{"line":446,"address":[],"length":0,"stats":{"Line":4}},{"line":447,"address":[],"length":0,"stats":{"Line":2}},{"line":479,"address":[],"length":0,"stats":{"Line":0}},{"line":481,"address":[],"length":0,"stats":{"Line":0}},{"line":486,"address":[],"length":0,"stats":{"Line":0}},{"line":488,"address":[],"length":0,"stats":{"Line":0}},{"line":492,"address":[],"length":0,"stats":{"Line":0}},{"line":493,"address":[],"length":0,"stats":{"Line":0}},{"line":503,"address":[],"length":0,"stats":{"Line":0}},{"line":504,"address":[],"length":0,"stats":{"Line":0}},{"line":505,"address":[],"length":0,"stats":{"Line":0}},{"line":506,"address":[],"length":0,"stats":{"Line":0}},{"line":509,"address":[],"length":0,"stats":{"Line":0}},{"line":510,"address":[],"length":0,"stats":{"Line":0}},{"line":511,"address":[],"length":0,"stats":{"Line":0}},{"line":512,"address":[],"length":0,"stats":{"Line":0}},{"line":513,"address":[],"length":0,"stats":{"Line":0}},{"line":514,"address":[],"length":0,"stats":{"Line":0}},{"line":516,"address":[],"length":0,"stats":{"Line":0}},{"line":517,"address":[],"length":0,"stats":{"Line":0}},{"line":520,"address":[],"length":0,"stats":{"Line":0}},{"line":521,"address":[],"length":0,"stats":{"Line":0}},{"line":522,"address":[],"length":0,"stats":{"Line":0}},{"line":525,"address":[],"length":0,"stats":{"Line":0}},{"line":526,"address":[],"length":0,"stats":{"Line":0}},{"line":528,"address":[],"length":0,"stats":{"Line":0}},{"line":530,"address":[],"length":0,"stats":{"Line":0}},{"line":531,"address":[],"length":0,"stats":{"Line":0}},{"line":532,"address":[],"length":0,"stats":{"Line":0}},{"line":539,"address":[],"length":0,"stats":{"Line":0}},{"line":540,"address":[],"length":0,"stats":{"Line":0}},{"line":541,"address":[],"length":0,"stats":{"Line":0}},{"line":542,"address":[],"length":0,"stats":{"Line":0}},{"line":543,"address":[],"length":0,"stats":{"Line":0}},{"line":545,"address":[],"length":0,"stats":{"Line":0}},{"line":546,"address":[],"length":0,"stats":{"Line":0}},{"line":547,"address":[],"length":0,"stats":{"Line":0}},{"line":548,"address":[],"length":0,"stats":{"Line":0}},{"line":554,"address":[],"length":0,"stats":{"Line":0}},{"line":558,"address":[],"length":0,"stats":{"Line":0}},{"line":562,"address":[],"length":0,"stats":{"Line":0}},{"line":566,"address":[],"length":0,"stats":{"Line":0}},{"line":572,"address":[],"length":0,"stats":{"Line":0}},{"line":573,"address":[],"length":0,"stats":{"Line":0}},{"line":574,"address":[],"length":0,"stats":{"Line":0}},{"line":577,"address":[],"length":0,"stats":{"Line":0}},{"line":578,"address":[],"length":0,"stats":{"Line":0}},{"line":583,"address":[],"length":0,"stats":{"Line":0}},{"line":584,"address":[],"length":0,"stats":{"Line":0}},{"line":594,"address":[],"length":0,"stats":{"Line":38}},{"line":596,"address":[],"length":0,"stats":{"Line":76}},{"line":597,"address":[],"length":0,"stats":{"Line":10}},{"line":598,"address":[],"length":0,"stats":{"Line":2}},{"line":599,"address":[],"length":0,"stats":{"Line":6}},{"line":600,"address":[],"length":0,"stats":{"Line":2}},{"line":605,"address":[],"length":0,"stats":{"Line":72}},{"line":606,"address":[],"length":0,"stats":{"Line":72}},{"line":611,"address":[],"length":0,"stats":{"Line":180}},{"line":612,"address":[],"length":0,"stats":{"Line":36}},{"line":613,"address":[],"length":0,"stats":{"Line":108}},{"line":614,"address":[],"length":0,"stats":{"Line":36}},{"line":618,"address":[],"length":0,"stats":{"Line":0}}],"covered":138,"coverable":222},{"path":["/","Users","christian.klat","dev","git","aeterna","context","src","types.rs"],"content":"use mk_core::hints::{HintsConfig, OperationHints};\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\nuse std::path::PathBuf;\n\n#[derive(Debug, Clone, PartialEq)]\npub enum ContextSource {\n    Explicit,\n    EnvVar(String),\n    ContextToml(PathBuf),\n    GitConfig,\n    GitRemote,\n    CedarAgent,\n    OrgDefault,\n    SystemDefault,\n}\n\nimpl std::fmt::Display for ContextSource {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            ContextSource::Explicit => write!(f, \"explicit\"),\n            ContextSource::EnvVar(name) => write!(f, \"env:{name}\"),\n            ContextSource::ContextToml(path) => write!(f, \"context.toml:{}\", path.display()),\n            ContextSource::GitConfig => write!(f, \"git-config\"),\n            ContextSource::GitRemote => write!(f, \"git-remote\"),\n            ContextSource::CedarAgent => write!(f, \"cedar-agent\"),\n            ContextSource::OrgDefault => write!(f, \"org-default\"),\n            ContextSource::SystemDefault => write!(f, \"system-default\"),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct ResolvedValue<T> {\n    pub value: T,\n    pub source: ContextSource,\n}\n\nimpl<T> ResolvedValue<T> {\n    pub fn new(value: T, source: ContextSource) -> Self {\n        Self { value, source }\n    }\n\n    pub fn explicit(value: T) -> Self {\n        Self::new(value, ContextSource::Explicit)\n    }\n\n    pub fn default(value: T) -> Self {\n        Self::new(value, ContextSource::SystemDefault)\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct ResolvedContext {\n    pub tenant_id: ResolvedValue<String>,\n    pub user_id: ResolvedValue<String>,\n    pub org_id: Option<ResolvedValue<String>>,\n    pub team_id: Option<ResolvedValue<String>>,\n    pub project_id: Option<ResolvedValue<String>>,\n    pub agent_id: Option<ResolvedValue<String>>,\n    pub session_id: Option<ResolvedValue<String>>,\n    pub hints: ResolvedValue<OperationHints>,\n    pub context_root: Option<PathBuf>,\n    pub git_root: Option<PathBuf>,\n}\n\nimpl Default for ResolvedContext {\n    fn default() -> Self {\n        Self {\n            tenant_id: ResolvedValue::default(\"default\".to_string()),\n            user_id: ResolvedValue::default(\"default\".to_string()),\n            org_id: None,\n            team_id: None,\n            project_id: None,\n            agent_id: None,\n            session_id: None,\n            hints: ResolvedValue::default(OperationHints::default()),\n            context_root: None,\n            git_root: None,\n        }\n    }\n}\n\nimpl ResolvedContext {\n    pub fn to_tenant_context(&self) -> mk_core::TenantContext {\n        let tenant_id = mk_core::TenantId::new(self.tenant_id.value.clone())\n            .unwrap_or_else(mk_core::TenantId::default);\n        let user_id = mk_core::UserId::new(self.user_id.value.clone())\n            .unwrap_or_else(mk_core::UserId::default);\n\n        match &self.agent_id {\n            Some(agent) => {\n                mk_core::TenantContext::with_agent(tenant_id, user_id, agent.value.clone())\n            }\n            None => mk_core::TenantContext::new(tenant_id, user_id),\n        }\n    }\n\n    /// Returns the resolved operation hints.\n    pub fn to_hints(&self) -> OperationHints {\n        self.hints.value.clone()\n    }\n\n    pub fn explain(&self) -> Vec<(String, String, String)> {\n        let mut explanations = vec![\n            (\n                \"tenant_id\".to_string(),\n                self.tenant_id.value.clone(),\n                self.tenant_id.source.to_string(),\n            ),\n            (\n                \"user_id\".to_string(),\n                self.user_id.value.clone(),\n                self.user_id.source.to_string(),\n            ),\n        ];\n\n        if let Some(org) = &self.org_id {\n            explanations.push((\n                \"org_id\".to_string(),\n                org.value.clone(),\n                org.source.to_string(),\n            ));\n        }\n\n        if let Some(team) = &self.team_id {\n            explanations.push((\n                \"team_id\".to_string(),\n                team.value.clone(),\n                team.source.to_string(),\n            ));\n        }\n\n        if let Some(project) = &self.project_id {\n            explanations.push((\n                \"project_id\".to_string(),\n                project.value.clone(),\n                project.source.to_string(),\n            ));\n        }\n\n        if let Some(agent) = &self.agent_id {\n            explanations.push((\n                \"agent_id\".to_string(),\n                agent.value.clone(),\n                agent.source.to_string(),\n            ));\n        }\n\n        explanations.push((\n            \"hints\".to_string(),\n            format!(\"{:?}\", self.hints.value.preset),\n            self.hints.source.to_string(),\n        ));\n\n        explanations\n    }\n}\n\n#[derive(Debug, Clone, Default, Serialize, Deserialize)]\n#[serde(rename_all = \"kebab-case\")]\npub struct ContextConfig {\n    #[serde(default)]\n    pub tenant_id: Option<String>,\n\n    #[serde(default)]\n    pub user_id: Option<String>,\n\n    #[serde(default)]\n    pub org_id: Option<String>,\n\n    #[serde(default)]\n    pub team_id: Option<String>,\n\n    #[serde(default)]\n    pub project_id: Option<String>,\n\n    #[serde(default)]\n    pub agent_id: Option<String>,\n\n    #[serde(default)]\n    pub hints: Option<HintsConfig>,\n\n    #[serde(default)]\n    pub server: Option<ServerConfig>,\n\n    #[serde(default)]\n    pub storage: Option<StorageConfig>,\n\n    #[serde(default)]\n    pub extra: HashMap<String, toml::Value>,\n}\n\n#[derive(Debug, Clone, Default, Serialize, Deserialize)]\n#[serde(rename_all = \"kebab-case\")]\npub struct ServerConfig {\n    pub url: Option<String>,\n\n    pub api_key: Option<String>,\n\n    pub timeout_seconds: Option<u64>,\n}\n\n#[derive(Debug, Clone, Default, Serialize, Deserialize)]\n#[serde(rename_all = \"kebab-case\")]\npub struct StorageConfig {\n    pub data_dir: Option<PathBuf>,\n\n    pub cache_dir: Option<PathBuf>,\n\n    pub logs_dir: Option<PathBuf>,\n}\n\nimpl ContextConfig {\n    pub fn from_toml(content: &str) -> Result<Self, toml::de::Error> {\n        toml::from_str(content)\n    }\n\n    pub fn to_toml(&self) -> Result<String, toml::ser::Error> {\n        toml::to_string_pretty(self)\n    }\n\n    pub fn to_hints(&self) -> OperationHints {\n        match &self.hints {\n            Some(hints_config) => hints_config.to_operation_hints(),\n            None => OperationHints::default(),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::hints::HintPreset;\n\n    #[test]\n    fn test_context_source_display() {\n        assert_eq!(ContextSource::Explicit.to_string(), \"explicit\");\n        assert_eq!(\n            ContextSource::EnvVar(\"AETERNA_TENANT\".to_string()).to_string(),\n            \"env:AETERNA_TENANT\"\n        );\n        assert_eq!(ContextSource::GitRemote.to_string(), \"git-remote\");\n    }\n\n    #[test]\n    fn test_resolved_value_explicit() {\n        let val = ResolvedValue::explicit(\"test\".to_string());\n        assert_eq!(val.value, \"test\");\n        assert_eq!(val.source, ContextSource::Explicit);\n    }\n\n    #[test]\n    fn test_resolved_context_default() {\n        let ctx = ResolvedContext::default();\n        assert_eq!(ctx.tenant_id.value, \"default\");\n        assert_eq!(ctx.user_id.value, \"default\");\n        assert!(ctx.org_id.is_none());\n    }\n\n    #[test]\n    fn test_resolved_context_to_tenant_context() {\n        let mut ctx = ResolvedContext::default();\n        ctx.tenant_id = ResolvedValue::explicit(\"acme-corp\".to_string());\n        ctx.user_id = ResolvedValue::explicit(\"alice\".to_string());\n\n        let tenant_ctx = ctx.to_tenant_context();\n        assert_eq!(tenant_ctx.tenant_id.as_str(), \"acme-corp\");\n        assert_eq!(tenant_ctx.user_id.as_str(), \"alice\");\n    }\n\n    #[test]\n    fn test_context_config_from_toml() {\n        let toml_content = r#\"\ntenant-id = \"acme-corp\"\nuser-id = \"alice\"\norg-id = \"platform\"\nproject-id = \"payments\"\n\n[hints]\npreset = \"fast\"\nverbose = true\n\n[server]\nurl = \"https://aeterna.example.com\"\ntimeout-seconds = 30\n\"#;\n\n        let config = ContextConfig::from_toml(toml_content).unwrap();\n        assert_eq!(config.tenant_id, Some(\"acme-corp\".to_string()));\n        assert_eq!(config.user_id, Some(\"alice\".to_string()));\n        assert_eq!(config.org_id, Some(\"platform\".to_string()));\n        assert_eq!(config.project_id, Some(\"payments\".to_string()));\n        assert!(config.hints.is_some());\n        assert!(config.server.is_some());\n    }\n\n    #[test]\n    fn test_context_config_to_hints() {\n        let config = ContextConfig {\n            hints: Some(HintsConfig {\n                preset: Some(HintPreset::Fast),\n                ..Default::default()\n            }),\n            ..Default::default()\n        };\n\n        let hints = config.to_hints();\n        assert!(!hints.reasoning);\n        assert!(!hints.multi_hop);\n    }\n\n    #[test]\n    fn test_resolved_context_explain() {\n        let ctx = ResolvedContext::default();\n        let explanations = ctx.explain();\n        assert!(explanations.iter().any(|(name, _, _)| name == \"tenant_id\"));\n        assert!(explanations.iter().any(|(name, _, _)| name == \"user_id\"));\n        assert!(explanations.iter().any(|(name, _, _)| name == \"hints\"));\n    }\n}\n","traces":[{"line":19,"address":[],"length":0,"stats":{"Line":25}},{"line":20,"address":[],"length":0,"stats":{"Line":25}},{"line":21,"address":[],"length":0,"stats":{"Line":9}},{"line":22,"address":[],"length":0,"stats":{"Line":4}},{"line":23,"address":[],"length":0,"stats":{"Line":0}},{"line":24,"address":[],"length":0,"stats":{"Line":12}},{"line":25,"address":[],"length":0,"stats":{"Line":15}},{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":28,"address":[],"length":0,"stats":{"Line":36}},{"line":40,"address":[],"length":0,"stats":{"Line":248}},{"line":44,"address":[],"length":0,"stats":{"Line":16}},{"line":45,"address":[],"length":0,"stats":{"Line":48}},{"line":48,"address":[],"length":0,"stats":{"Line":153}},{"line":49,"address":[],"length":0,"stats":{"Line":459}},{"line":68,"address":[],"length":0,"stats":{"Line":51}},{"line":70,"address":[],"length":0,"stats":{"Line":204}},{"line":71,"address":[],"length":0,"stats":{"Line":204}},{"line":77,"address":[],"length":0,"stats":{"Line":153}},{"line":85,"address":[],"length":0,"stats":{"Line":3}},{"line":86,"address":[],"length":0,"stats":{"Line":12}},{"line":87,"address":[],"length":0,"stats":{"Line":3}},{"line":88,"address":[],"length":0,"stats":{"Line":12}},{"line":89,"address":[],"length":0,"stats":{"Line":3}},{"line":91,"address":[],"length":0,"stats":{"Line":3}},{"line":92,"address":[],"length":0,"stats":{"Line":1}},{"line":93,"address":[],"length":0,"stats":{"Line":5}},{"line":95,"address":[],"length":0,"stats":{"Line":6}},{"line":100,"address":[],"length":0,"stats":{"Line":20}},{"line":101,"address":[],"length":0,"stats":{"Line":40}},{"line":104,"address":[],"length":0,"stats":{"Line":5}},{"line":105,"address":[],"length":0,"stats":{"Line":10}},{"line":107,"address":[],"length":0,"stats":{"Line":15}},{"line":108,"address":[],"length":0,"stats":{"Line":15}},{"line":109,"address":[],"length":0,"stats":{"Line":5}},{"line":112,"address":[],"length":0,"stats":{"Line":15}},{"line":113,"address":[],"length":0,"stats":{"Line":15}},{"line":114,"address":[],"length":0,"stats":{"Line":5}},{"line":118,"address":[],"length":0,"stats":{"Line":7}},{"line":119,"address":[],"length":0,"stats":{"Line":3}},{"line":120,"address":[],"length":0,"stats":{"Line":3}},{"line":121,"address":[],"length":0,"stats":{"Line":3}},{"line":122,"address":[],"length":0,"stats":{"Line":1}},{"line":126,"address":[],"length":0,"stats":{"Line":5}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":11}},{"line":135,"address":[],"length":0,"stats":{"Line":9}},{"line":136,"address":[],"length":0,"stats":{"Line":9}},{"line":137,"address":[],"length":0,"stats":{"Line":9}},{"line":138,"address":[],"length":0,"stats":{"Line":3}},{"line":142,"address":[],"length":0,"stats":{"Line":5}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":15}},{"line":151,"address":[],"length":0,"stats":{"Line":15}},{"line":152,"address":[],"length":0,"stats":{"Line":15}},{"line":153,"address":[],"length":0,"stats":{"Line":5}},{"line":156,"address":[],"length":0,"stats":{"Line":5}},{"line":215,"address":[],"length":0,"stats":{"Line":1}},{"line":216,"address":[],"length":0,"stats":{"Line":2}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":0}},{"line":223,"address":[],"length":0,"stats":{"Line":7}},{"line":224,"address":[],"length":0,"stats":{"Line":7}},{"line":225,"address":[],"length":0,"stats":{"Line":6}},{"line":226,"address":[],"length":0,"stats":{"Line":5}}],"covered":58,"coverable":71},{"path":["/","Users","christian.klat","dev","git","aeterna","errors","src","lib.rs"],"content":"//! # Memory-Knowledge Errors\n//!\n//! Comprehensive error handling for Memory-Knowledge system.\n//!\n//! Follows Microsoft Pragmatic Rust Guidelines:\n//! - Uses `thiserror` for structured error definitions\n//! - Provides `Display` and `Error` trait implementations\n//! - Includes error context for debugging\n\nuse thiserror::Error;\n\n/// Memory-specific errors\n#[derive(Debug, Error)]\npub enum MemoryError {\n    // FIX: Use named field {layer} instead of positional {0}\n    #[error(\"Invalid memory layer: {layer}\")]\n    InvalidLayer { layer: String },\n\n    // FIX: Use named field {identifier} instead of positional {0}\n    #[error(\"Missing required identifier: {identifier}\")]\n    MissingIdentifier { identifier: String },\n\n    // FIX: Use named field {id} instead of positional {0}\n    #[error(\"Memory not found: {id}\")]\n    MemoryNotFound { id: String },\n\n    // FIX: Use named fields {length} and {max} instead of positional {0} and {1}\n    #[error(\"Content too long: {length} characters max {max}\")]\n    ContentTooLong { length: usize, max: usize },\n\n    // FIX: Use named fields {length} and {max} instead of positional {0} and {1}\n    #[error(\"Query too long: {length} characters max {max}\")]\n    QueryTooLong { length: usize, max: usize },\n\n    // FIX: Use named field {reason} instead of positional {0}\n    #[error(\"Embedding generation failed: {reason}\")]\n    EmbeddingFailed { reason: String },\n\n    // FIX: Use named fields {source_name} and {reason} to match the struct\n    #[error(\"Provider error: {source_name} - {reason}\")]\n    ProviderError { source_name: String, reason: String },\n\n    // FIX: Use named field {retry_after} instead of positional {0}\n    #[error(\"Rate limited: retry after {retry_after}s\")]\n    RateLimited { retry_after: u64 },\n\n    // FIX: Use named field {reason} instead of positional {0}\n    #[error(\"Unauthorized access: {reason}\")]\n    Unauthorized { reason: String },\n\n    // FIX: Use named field {message} instead of positional {0}\n    #[error(\"Configuration error: {message}\")]\n    ConfigurationError { message: String },\n}\n\n/// Knowledge repository errors\n#[derive(Debug, Error)]\npub enum KnowledgeError {\n    // FIX: Use named field {id} instead of positional {0}\n    #[error(\"Knowledge item not found: {id}\")]\n    ItemNotFound { id: String },\n\n    // FIX: Use named field {type_} instead of positional {0}\n    #[error(\"Invalid knowledge type: {type_}\")]\n    InvalidType { type_: String },\n\n    // FIX: Use named field {layer} instead of positional {0}\n    #[error(\"Invalid knowledge layer: {layer}\")]\n    InvalidLayer { layer: String },\n\n    // FIX: Use named fields {from} and {to} instead of positional {0} and {1}\n    #[error(\"Invalid status transition: {from} to {to}\")]\n    InvalidStatusTransition { from: String, to: String },\n\n    // FIX: Use named fields {operation} and {reason} instead of positional {0} and {1}\n    #[error(\"Git operation: {operation} failed: {reason}\")]\n    GitError { operation: String, reason: String },\n\n    // FIX: Use named field {reason} instead of positional {0}\n    #[error(\"Manifest corrupted: {reason}\")]\n    ManifestCorrupted { reason: String },\n\n    // FIX: Use named field {constraint_id} instead of positional {0}\n    #[error(\"Constraint violation: {constraint_id}\")]\n    ConstraintViolation { constraint_id: String },\n}\n\n/// Sync bridge errors\n#[derive(Debug, Error)]\npub enum SyncError {\n    // FIX: Use named field {reason} instead of positional {0}\n    #[error(\"Knowledge unavailable: {reason}\")]\n    KnowledgeUnavailable { reason: String },\n\n    // FIX: Use named field {reason} instead of positional {0}\n    #[error(\"Memory unavailable: {reason}\")]\n    MemoryUnavailable { reason: String },\n\n    // FIX: Use named field {reason} instead of positional {0}\n    #[error(\"State corrupted: {reason}\")]\n    StateCorrupted { reason: String },\n\n    // FIX: Use named field {checkpoint_id} instead of positional {0}\n    #[error(\"Checkpoint failed: {checkpoint_id}\")]\n    CheckpointFailed { checkpoint_id: String },\n\n    // FIX: Use named fields {checkpoint_id} and {reason} instead of positional {0} and {1}\n    #[error(\"Rollback of {checkpoint_id} failed: {reason}\")]\n    RollbackFailed {\n        checkpoint_id: String,\n        reason: String,\n    },\n\n    // FIX: Use named field {conflict_id} instead of positional {0}\n    #[error(\"Conflict unresolvable: {conflict_id}\")]\n    ConflictUnresolvable { conflict_id: String },\n\n    // FIX: Use named field {failed_items} instead of positional {0}\n    #[error(\"Partial failure: {failed_items:?} items failed\")]\n    PartialFailure { failed_items: Vec<String> },\n}\n\n/// Tool interface errors\n#[derive(Debug, Error)]\npub enum ToolError {\n    // FIX: Use named fields {field} and {reason} instead of positional {0}\n    #[error(\"Invalid input: {field} reason: {reason}\")]\n    InvalidInput { field: String, reason: String },\n\n    // FIX: Use named fields {resource} and {id} instead of positional {0} and {1}\n    #[error(\"Resource not found: {resource}:{id}\")]\n    NotFound { resource: String, id: String },\n\n    // FIX: Use named fields {source_name} and {reason} to match the struct\n    #[error(\"Provider error: {source_name} - {reason}\")]\n    ProviderError { source_name: String, reason: String },\n\n    // FIX: Use named field {retry_after} instead of positional {0}\n    #[error(\"Rate limited: retry after {retry_after}s\")]\n    RateLimited { retry_after: u64 },\n\n    // FIX: Use named field {reason} instead of positional {0}\n    #[error(\"Unauthorized access: {reason}\")]\n    Unauthorized { reason: String },\n\n    // FIX: Use named field {timeout_ms} instead of positional {0}\n    #[error(\"Timeout: operation took longer than {timeout_ms}ms\")]\n    Timeout { timeout_ms: u64 },\n\n    // FIX: Use named fields {conflict_id} and {details} instead of positional {0} and {1}\n    #[error(\"Conflict: {conflict_id}: {details}\")]\n    Conflict {\n        conflict_id: String,\n        details: String,\n    },\n}\n\n/// Storage layer errors\n#[derive(Debug, Error)]\npub enum StorageError {\n    // FIX: Use named fields {backend} and {reason} instead of positional {0} and {1}\n    #[error(\"Connection to {backend} failed: {reason}\")]\n    ConnectionError { backend: String, reason: String },\n\n    // FIX: Use named fields {backend} and {reason} instead of positional {0} and {1}\n    #[error(\"Query on {backend} failed: {reason}\")]\n    QueryError { backend: String, reason: String },\n\n    // FIX: Use named fields {error_type} and {reason} instead of positional {0} and {1}\n    #[error(\"Serialization error: {error_type} - {reason}\")]\n    SerializationError { error_type: String, reason: String },\n\n    // FIX: Use named fields {backend} and {id} instead of positional {0} and {1}\n    #[error(\"Not found on {backend}:{id}\")]\n    NotFound { backend: String, id: String },\n\n    // FIX: Use named fields {backend} and {reason} instead of positional {0} and {1}\n    #[error(\"Transaction on {backend} failed: {reason}\")]\n    TransactionError { backend: String, reason: String },\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","expanded_qdrant.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","api.rs"],"content":"use crate::governance::GovernanceEngine;\nuse crate::governance_client::{GovernanceClient, RemoteGovernanceClient};\nuse config::config::DeploymentConfig;\nuse mk_core::traits::StorageBackend;\nuse mk_core::types::{\n    DriftConfig, DriftResult, DriftSuppression, GovernanceEvent, KnowledgeLayer, TenantContext,\n};\nuse std::sync::Arc;\nuse storage::postgres::PostgresBackend;\nuse utoipa::OpenApi;\n\n#[derive(OpenApi)]\n#[openapi(\n    paths(\n        get_drift_status,\n        get_org_report,\n        approve_proposal,\n        reject_proposal,\n        get_job_status,\n        replay_events,\n        create_suppression,\n        list_suppressions,\n        delete_suppression,\n        get_drift_config,\n        save_drift_config\n    ),\n    components(\n        schemas(\n            mk_core::types::DriftResult,\n            mk_core::types::PolicyViolation,\n            mk_core::types::GovernanceEvent,\n            mk_core::types::DriftSuppression,\n            mk_core::types::DriftConfig\n        )\n    ),\n    tags(\n        (name = \"governance\", description = \"Governance Dashboard API\")\n    )\n)]\npub struct GovernanceApiDoc;\n\npub struct GovernanceDashboardApi {\n    engine: Arc<GovernanceEngine>,\n    storage: Arc<PostgresBackend>,\n    governance_client: Option<Arc<dyn GovernanceClient>>,\n    deployment_config: DeploymentConfig,\n}\n\n#[utoipa::path(\n    get,\n    path = \"/api/v1/governance/drift/{project_id}\",\n    responses(\n        (status = 200, description = \"Drift status fetched successfully\", body = Option<DriftResult>),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"project_id\" = String, Path, description = \"Project ID\")\n    ),\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn get_drift_status(\n    api: Arc<GovernanceDashboardApi>,\n    ctx: &TenantContext,\n    project_id: &str,\n) -> anyhow::Result<Option<DriftResult>> {\n    if api.deployment_config.mode == \"remote\" {\n        if let Some(client) = &api.governance_client {\n            return client\n                .get_drift_status(ctx, project_id)\n                .await\n                .map_err(|e| anyhow::anyhow!(\"Remote drift status failed: {}\", e));\n        }\n    }\n\n    let result =\n        StorageBackend::get_latest_drift_result(api.storage.as_ref(), ctx.clone(), project_id)\n            .await\n            .map_err(|e| anyhow::anyhow!(\"Failed to fetch drift result: {:?}\", e))?;\n\n    Ok(result)\n}\n\n#[utoipa::path(\n    get,\n    path = \"/api/v1/governance/reports/{org_id}\",\n    responses(\n        (status = 200, description = \"Organization report fetched successfully\", body = serde_json::Value),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"org_id\" = String, Path, description = \"Organization ID\")\n    ),\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn get_org_report(\n    api: Arc<GovernanceDashboardApi>,\n    ctx: &TenantContext,\n    org_id: &str,\n) -> anyhow::Result<serde_json::Value> {\n    let descendants = StorageBackend::get_descendants(api.storage.as_ref(), ctx.clone(), org_id)\n        .await\n        .map_err(|e| anyhow::anyhow!(\"Failed to fetch descendants: {:?}\", e))?;\n\n    let mut project_drifts = Vec::new();\n    for unit in descendants {\n        if unit.unit_type == mk_core::types::UnitType::Project {\n            if let Some(drift) = get_drift_status(api.clone(), ctx, &unit.id).await? {\n                project_drifts.push(drift);\n            }\n        }\n    }\n\n    let avg_drift = if project_drifts.is_empty() {\n        0.0\n    } else {\n        project_drifts.iter().map(|d| d.drift_score).sum::<f32>() / project_drifts.len() as f32\n    };\n\n    Ok(serde_json::json!({\n        \"orgId\": org_id,\n        \"averageDrift\": avg_drift,\n        \"projectCount\": project_drifts.len(),\n        \"projects\": project_drifts,\n        \"timestamp\": chrono::Utc::now().timestamp()\n    }))\n}\n\n#[utoipa::path(\n    post,\n    path = \"/api/v1/governance/proposals/{proposal_id}/approve\",\n    responses(\n        (status = 200, description = \"Proposal approved successfully\"),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 404, description = \"Proposal not found\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"proposal_id\" = String, Path, description = \"Proposal ID\")\n    ),\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn approve_proposal(\n    api: Arc<GovernanceDashboardApi>,\n    ctx: &TenantContext,\n    proposal_id: &str,\n) -> anyhow::Result<()> {\n    let repo = api\n        .engine\n        .repository()\n        .ok_or_else(|| anyhow::anyhow!(\"Repository not configured\"))?;\n\n    let entry = repo\n        .get(\n            ctx.clone(),\n            mk_core::types::KnowledgeLayer::Project,\n            proposal_id,\n        )\n        .await\n        .map_err(|e| anyhow::anyhow!(\"Failed to fetch proposal: {:?}\", e))?\n        .ok_or_else(|| anyhow::anyhow!(\"Proposal not found\"))?;\n\n    let mut accepted_entry = entry.clone();\n    accepted_entry.status = mk_core::types::KnowledgeStatus::Accepted;\n\n    repo.store(ctx.clone(), accepted_entry, \"Proposal approved\")\n        .await\n        .map_err(|e| anyhow::anyhow!(\"Failed to approve proposal: {:?}\", e))?;\n\n    Ok(())\n}\n\n#[utoipa::path(\n    post,\n    path = \"/api/v1/governance/proposals/{proposal_id}/reject\",\n    responses(\n        (status = 200, description = \"Proposal rejected successfully\"),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 404, description = \"Proposal not found\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"proposal_id\" = String, Path, description = \"Proposal ID\"),\n        (\"reason\" = String, Query, description = \"Rejection reason\")\n    ),\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn reject_proposal(\n    api: Arc<GovernanceDashboardApi>,\n    ctx: &TenantContext,\n    proposal_id: &str,\n    reason: &str,\n) -> anyhow::Result<()> {\n    let repo = api\n        .engine\n        .repository()\n        .ok_or_else(|| anyhow::anyhow!(\"Repository not configured\"))?;\n\n    let entry = repo\n        .get(\n            ctx.clone(),\n            mk_core::types::KnowledgeLayer::Project,\n            proposal_id,\n        )\n        .await\n        .map_err(|e| anyhow::anyhow!(\"Failed to fetch proposal: {:?}\", e))?\n        .ok_or_else(|| anyhow::anyhow!(\"Proposal not found\"))?;\n\n    let mut rejected_entry = entry.clone();\n    rejected_entry.status = mk_core::types::KnowledgeStatus::Draft;\n    rejected_entry\n        .metadata\n        .insert(\"rejection_reason\".to_string(), serde_json::json!(reason));\n\n    repo.store(\n        ctx.clone(),\n        rejected_entry,\n        &format!(\"Proposal rejected: {}\", reason),\n    )\n    .await\n    .map_err(|e| anyhow::anyhow!(\"Failed to reject proposal: {:?}\", e))?;\n\n    Ok(())\n}\n\n#[utoipa::path(\n    get,\n    path = \"/api/v1/governance/jobs\",\n    responses(\n        (status = 200, description = \"Job status fetched successfully\", body = serde_json::Value),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"job_name\" = Option<String>, Query, description = \"Filter by job name\")\n    ),\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn get_job_status(\n    api: Arc<GovernanceDashboardApi>,\n    ctx: &TenantContext,\n    job_name: Option<&str>,\n) -> anyhow::Result<serde_json::Value> {\n    let rows = sqlx::query(\n        \"SELECT id, job_name, status, message, started_at, finished_at, duration_ms \n         FROM job_status \n         WHERE tenant_id = $1 OR tenant_id = 'all' \n         ORDER BY started_at DESC LIMIT 50\",\n    )\n    .bind(ctx.tenant_id.as_str())\n    .fetch_all(api.storage.pool())\n    .await\n    .map_err(|e| anyhow::anyhow!(\"Failed to fetch job status: {:?}\", e))?;\n\n    let mut jobs = Vec::new();\n    for row in rows {\n        use sqlx::Row;\n        let name: String = row.get(\"job_name\");\n        if let Some(filter) = job_name {\n            if name != filter {\n                continue;\n            }\n        }\n\n        jobs.push(serde_json::json!({\n            \"id\": row.get::<uuid::Uuid, _>(\"id\"),\n            \"jobName\": name,\n            \"status\": row.get::<String, _>(\"status\"),\n            \"message\": row.get::<Option<String>, _>(\"message\"),\n            \"startedAt\": row.get::<i64, _>(\"started_at\"),\n            \"finishedAt\": row.get::<Option<i64>, _>(\"finished_at\"),\n            \"durationMs\": row.get::<Option<i64>, _>(\"duration_ms\"),\n        }));\n    }\n\n    Ok(serde_json::json!(jobs))\n}\n\n#[utoipa::path(\n    get,\n    path = \"/api/v1/governance/events/replay\",\n    responses(\n        (status = 200, description = \"Events replayed successfully\", body = Vec<GovernanceEvent>),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"since_timestamp\" = i64, Query, description = \"Replay events after this timestamp\"),\n        (\"limit\" = usize, Query, description = \"Maximum number of events to return\")\n    ),\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn replay_events(\n    api: Arc<GovernanceDashboardApi>,\n    ctx: &TenantContext,\n    since_timestamp: i64,\n    limit: usize,\n) -> anyhow::Result<Vec<mk_core::types::GovernanceEvent>> {\n    if api.deployment_config.mode == \"remote\" {\n        if let Some(client) = &api.governance_client {\n            return client\n                .replay_events(ctx, since_timestamp, limit)\n                .await\n                .map_err(|e| anyhow::anyhow!(\"Remote replay events failed: {}\", e));\n        }\n    }\n\n    let events = StorageBackend::get_governance_events(\n        api.storage.as_ref(),\n        ctx.clone(),\n        since_timestamp,\n        limit,\n    )\n    .await\n    .map_err(|e| anyhow::anyhow!(\"Failed to replay governance events: {:?}\", e))?;\n\n    Ok(events)\n}\n\n#[utoipa::path(\n    post,\n    path = \"/api/v1/governance/suppressions\",\n    responses(\n        (status = 201, description = \"Suppression created successfully\", body = DriftSuppression),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"project_id\" = String, Query, description = \"Project ID\"),\n        (\"policy_id\" = String, Query, description = \"Policy ID to suppress\"),\n        (\"reason\" = String, Query, description = \"Reason for suppression\"),\n        (\"rule_pattern\" = Option<String>, Query, description = \"Optional regex pattern to match violations\"),\n        (\"expires_at\" = Option<i64>, Query, description = \"Optional expiration timestamp\")\n    ),\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn create_suppression(\n    api: Arc<GovernanceDashboardApi>,\n    ctx: &TenantContext,\n    project_id: &str,\n    policy_id: &str,\n    reason: &str,\n    rule_pattern: Option<&str>,\n    expires_at: Option<i64>,\n) -> anyhow::Result<DriftSuppression> {\n    let mut suppression = DriftSuppression::new(\n        project_id.to_string(),\n        ctx.tenant_id.clone(),\n        policy_id.to_string(),\n        reason.to_string(),\n        ctx.user_id.clone(),\n    );\n\n    if let Some(pattern) = rule_pattern {\n        suppression = suppression.with_pattern(pattern.to_string());\n    }\n\n    if let Some(expires) = expires_at {\n        suppression = suppression.with_expiry(expires);\n    }\n\n    StorageBackend::create_suppression(api.storage.as_ref(), suppression.clone())\n        .await\n        .map_err(|e| anyhow::anyhow!(\"Failed to create suppression: {:?}\", e))?;\n\n    Ok(suppression)\n}\n\n#[utoipa::path(\n    get,\n    path = \"/api/v1/governance/suppressions/{project_id}\",\n    responses(\n        (status = 200, description = \"Suppressions fetched successfully\", body = Vec<DriftSuppression>),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"project_id\" = String, Path, description = \"Project ID\")\n    ),\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn list_suppressions(\n    api: Arc<GovernanceDashboardApi>,\n    ctx: &TenantContext,\n    project_id: &str,\n) -> anyhow::Result<Vec<DriftSuppression>> {\n    let suppressions =\n        StorageBackend::list_suppressions(api.storage.as_ref(), ctx.clone(), project_id)\n            .await\n            .map_err(|e| anyhow::anyhow!(\"Failed to list suppressions: {:?}\", e))?;\n\n    let active_suppressions: Vec<DriftSuppression> = suppressions\n        .into_iter()\n        .filter(|s| !s.is_expired())\n        .collect();\n\n    Ok(active_suppressions)\n}\n\n#[utoipa::path(\n    delete,\n    path = \"/api/v1/governance/suppressions/{suppression_id}\",\n    responses(\n        (status = 200, description = \"Suppression deleted successfully\"),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 404, description = \"Suppression not found\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"suppression_id\" = String, Path, description = \"Suppression ID\")\n    ),\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn delete_suppression(\n    api: Arc<GovernanceDashboardApi>,\n    ctx: &TenantContext,\n    suppression_id: &str,\n) -> anyhow::Result<()> {\n    StorageBackend::delete_suppression(api.storage.as_ref(), ctx.clone(), suppression_id)\n        .await\n        .map_err(|e| anyhow::anyhow!(\"Failed to delete suppression: {:?}\", e))?;\n\n    Ok(())\n}\n\n#[utoipa::path(\n    get,\n    path = \"/api/v1/governance/drift-config/{project_id}\",\n    responses(\n        (status = 200, description = \"Drift config fetched successfully\", body = Option<DriftConfig>),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"project_id\" = String, Path, description = \"Project ID\")\n    ),\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn get_drift_config(\n    api: Arc<GovernanceDashboardApi>,\n    ctx: &TenantContext,\n    project_id: &str,\n) -> anyhow::Result<DriftConfig> {\n    let config = StorageBackend::get_drift_config(api.storage.as_ref(), ctx.clone(), project_id)\n        .await\n        .map_err(|e| anyhow::anyhow!(\"Failed to get drift config: {:?}\", e))?;\n\n    Ok(config\n        .unwrap_or_else(|| DriftConfig::for_project(project_id.to_string(), ctx.tenant_id.clone())))\n}\n\n#[utoipa::path(\n    put,\n    path = \"/api/v1/governance/drift-config/{project_id}\",\n    responses(\n        (status = 200, description = \"Drift config saved successfully\"),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"project_id\" = String, Path, description = \"Project ID\")\n    ),\n    request_body = DriftConfig,\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn save_drift_config(\n    api: Arc<GovernanceDashboardApi>,\n    ctx: &TenantContext,\n    project_id: &str,\n    threshold: f32,\n    low_confidence_threshold: Option<f32>,\n    auto_suppress_info: Option<bool>,\n) -> anyhow::Result<()> {\n    let mut config = DriftConfig::for_project(project_id.to_string(), ctx.tenant_id.clone());\n    config.threshold = threshold;\n    if let Some(lct) = low_confidence_threshold {\n        config.low_confidence_threshold = lct;\n    }\n    if let Some(asi) = auto_suppress_info {\n        config.auto_suppress_info = asi;\n    }\n\n    StorageBackend::save_drift_config(api.storage.as_ref(), config)\n        .await\n        .map_err(|e| anyhow::anyhow!(\"Failed to save drift config: {:?}\", e))?;\n\n    Ok(())\n}\n\nimpl GovernanceDashboardApi {\n    pub fn new(\n        engine: Arc<GovernanceEngine>,\n        storage: Arc<PostgresBackend>,\n        deployment_config: DeploymentConfig,\n    ) -> Self {\n        let governance_client = if deployment_config.mode == \"remote\" {\n            deployment_config.remote_url.as_ref().map(|url: &String| {\n                Arc::new(RemoteGovernanceClient::new(url.clone())) as Arc<dyn GovernanceClient>\n            })\n        } else {\n            None\n        };\n\n        Self {\n            engine,\n            storage,\n            governance_client,\n            deployment_config,\n        }\n    }\n\n    pub async fn list_proposals(\n        &self,\n        ctx: &TenantContext,\n        layer: Option<KnowledgeLayer>,\n    ) -> anyhow::Result<Vec<mk_core::types::KnowledgeEntry>> {\n        if self.deployment_config.mode == \"remote\" {\n            if let Some(client) = &self.governance_client {\n                return client\n                    .list_proposals(ctx, layer)\n                    .await\n                    .map_err(|e| anyhow::anyhow!(\"Remote list proposals failed: {}\", e));\n            }\n        }\n\n        let repo = self\n            .engine\n            .repository()\n            .ok_or_else(|| anyhow::anyhow!(\"Repository not configured\"))?;\n\n        let layers = if let Some(l) = layer {\n            vec![l]\n        } else {\n            vec![\n                KnowledgeLayer::Project,\n                KnowledgeLayer::Team,\n                KnowledgeLayer::Org,\n                KnowledgeLayer::Company,\n            ]\n        };\n\n        let mut proposals = Vec::new();\n        for l in layers {\n            let entries: Vec<mk_core::types::KnowledgeEntry> = repo\n                .list(ctx.clone(), l, \"\")\n                .await\n                .map_err(|e| anyhow::anyhow!(\"Failed to list entries in layer {:?}: {:?}\", l, e))?;\n\n            for entry in entries {\n                if entry.status == mk_core::types::KnowledgeStatus::Proposed {\n                    proposals.push(entry);\n                }\n            }\n        }\n\n        Ok(proposals)\n    }\n}\n","traces":[{"line":64,"address":[],"length":0,"stats":{"Line":4}},{"line":69,"address":[],"length":0,"stats":{"Line":4}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":4}},{"line":79,"address":[],"length":0,"stats":{"Line":20}},{"line":80,"address":[],"length":0,"stats":{"Line":4}},{"line":81,"address":[],"length":0,"stats":{"Line":4}},{"line":83,"address":[],"length":0,"stats":{"Line":4}},{"line":101,"address":[],"length":0,"stats":{"Line":1}},{"line":106,"address":[],"length":0,"stats":{"Line":6}},{"line":107,"address":[],"length":0,"stats":{"Line":1}},{"line":108,"address":[],"length":0,"stats":{"Line":1}},{"line":110,"address":[],"length":0,"stats":{"Line":2}},{"line":111,"address":[],"length":0,"stats":{"Line":7}},{"line":112,"address":[],"length":0,"stats":{"Line":3}},{"line":113,"address":[],"length":0,"stats":{"Line":7}},{"line":114,"address":[],"length":0,"stats":{"Line":2}},{"line":119,"address":[],"length":0,"stats":{"Line":3}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":4}},{"line":125,"address":[],"length":0,"stats":{"Line":2}},{"line":126,"address":[],"length":0,"stats":{"Line":2}},{"line":127,"address":[],"length":0,"stats":{"Line":2}},{"line":128,"address":[],"length":0,"stats":{"Line":4}},{"line":129,"address":[],"length":0,"stats":{"Line":2}},{"line":130,"address":[],"length":0,"stats":{"Line":2}},{"line":150,"address":[],"length":0,"stats":{"Line":1}},{"line":155,"address":[],"length":0,"stats":{"Line":2}},{"line":156,"address":[],"length":0,"stats":{"Line":1}},{"line":158,"address":[],"length":0,"stats":{"Line":1}},{"line":160,"address":[],"length":0,"stats":{"Line":3}},{"line":162,"address":[],"length":0,"stats":{"Line":3}},{"line":163,"address":[],"length":0,"stats":{"Line":1}},{"line":164,"address":[],"length":0,"stats":{"Line":1}},{"line":166,"address":[],"length":0,"stats":{"Line":1}},{"line":167,"address":[],"length":0,"stats":{"Line":1}},{"line":168,"address":[],"length":0,"stats":{"Line":1}},{"line":170,"address":[],"length":0,"stats":{"Line":3}},{"line":171,"address":[],"length":0,"stats":{"Line":1}},{"line":173,"address":[],"length":0,"stats":{"Line":5}},{"line":174,"address":[],"length":0,"stats":{"Line":1}},{"line":175,"address":[],"length":0,"stats":{"Line":1}},{"line":177,"address":[],"length":0,"stats":{"Line":1}},{"line":197,"address":[],"length":0,"stats":{"Line":1}},{"line":203,"address":[],"length":0,"stats":{"Line":2}},{"line":204,"address":[],"length":0,"stats":{"Line":1}},{"line":206,"address":[],"length":0,"stats":{"Line":1}},{"line":208,"address":[],"length":0,"stats":{"Line":3}},{"line":210,"address":[],"length":0,"stats":{"Line":3}},{"line":211,"address":[],"length":0,"stats":{"Line":1}},{"line":212,"address":[],"length":0,"stats":{"Line":1}},{"line":214,"address":[],"length":0,"stats":{"Line":1}},{"line":215,"address":[],"length":0,"stats":{"Line":1}},{"line":216,"address":[],"length":0,"stats":{"Line":1}},{"line":218,"address":[],"length":0,"stats":{"Line":3}},{"line":219,"address":[],"length":0,"stats":{"Line":1}},{"line":220,"address":[],"length":0,"stats":{"Line":1}},{"line":221,"address":[],"length":0,"stats":{"Line":1}},{"line":222,"address":[],"length":0,"stats":{"Line":4}},{"line":224,"address":[],"length":0,"stats":{"Line":3}},{"line":225,"address":[],"length":0,"stats":{"Line":3}},{"line":226,"address":[],"length":0,"stats":{"Line":2}},{"line":227,"address":[],"length":0,"stats":{"Line":1}},{"line":229,"address":[],"length":0,"stats":{"Line":1}},{"line":230,"address":[],"length":0,"stats":{"Line":1}},{"line":232,"address":[],"length":0,"stats":{"Line":1}},{"line":250,"address":[],"length":0,"stats":{"Line":3}},{"line":261,"address":[],"length":0,"stats":{"Line":12}},{"line":262,"address":[],"length":0,"stats":{"Line":6}},{"line":263,"address":[],"length":0,"stats":{"Line":3}},{"line":264,"address":[],"length":0,"stats":{"Line":3}},{"line":266,"address":[],"length":0,"stats":{"Line":6}},{"line":267,"address":[],"length":0,"stats":{"Line":17}},{"line":269,"address":[],"length":0,"stats":{"Line":28}},{"line":270,"address":[],"length":0,"stats":{"Line":11}},{"line":271,"address":[],"length":0,"stats":{"Line":4}},{"line":272,"address":[],"length":0,"stats":{"Line":2}},{"line":276,"address":[],"length":0,"stats":{"Line":15}},{"line":277,"address":[],"length":0,"stats":{"Line":15}},{"line":278,"address":[],"length":0,"stats":{"Line":5}},{"line":279,"address":[],"length":0,"stats":{"Line":15}},{"line":280,"address":[],"length":0,"stats":{"Line":15}},{"line":281,"address":[],"length":0,"stats":{"Line":15}},{"line":282,"address":[],"length":0,"stats":{"Line":15}},{"line":283,"address":[],"length":0,"stats":{"Line":15}},{"line":287,"address":[],"length":0,"stats":{"Line":3}},{"line":306,"address":[],"length":0,"stats":{"Line":2}},{"line":312,"address":[],"length":0,"stats":{"Line":2}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":4}},{"line":323,"address":[],"length":0,"stats":{"Line":6}},{"line":324,"address":[],"length":0,"stats":{"Line":4}},{"line":325,"address":[],"length":0,"stats":{"Line":2}},{"line":327,"address":[],"length":0,"stats":{"Line":2}},{"line":328,"address":[],"length":0,"stats":{"Line":2}},{"line":330,"address":[],"length":0,"stats":{"Line":2}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":363,"address":[],"length":0,"stats":{"Line":0}},{"line":364,"address":[],"length":0,"stats":{"Line":0}},{"line":365,"address":[],"length":0,"stats":{"Line":0}},{"line":366,"address":[],"length":0,"stats":{"Line":0}},{"line":369,"address":[],"length":0,"stats":{"Line":0}},{"line":370,"address":[],"length":0,"stats":{"Line":0}},{"line":373,"address":[],"length":0,"stats":{"Line":0}},{"line":374,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":378,"address":[],"length":0,"stats":{"Line":0}},{"line":379,"address":[],"length":0,"stats":{"Line":0}},{"line":381,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":404,"address":[],"length":0,"stats":{"Line":0}},{"line":405,"address":[],"length":0,"stats":{"Line":0}},{"line":406,"address":[],"length":0,"stats":{"Line":0}},{"line":407,"address":[],"length":0,"stats":{"Line":0}},{"line":409,"address":[],"length":0,"stats":{"Line":0}},{"line":411,"address":[],"length":0,"stats":{"Line":0}},{"line":414,"address":[],"length":0,"stats":{"Line":0}},{"line":433,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":0}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":442,"address":[],"length":0,"stats":{"Line":0}},{"line":460,"address":[],"length":0,"stats":{"Line":0}},{"line":465,"address":[],"length":0,"stats":{"Line":0}},{"line":466,"address":[],"length":0,"stats":{"Line":0}},{"line":467,"address":[],"length":0,"stats":{"Line":0}},{"line":469,"address":[],"length":0,"stats":{"Line":0}},{"line":470,"address":[],"length":0,"stats":{"Line":0}},{"line":489,"address":[],"length":0,"stats":{"Line":0}},{"line":497,"address":[],"length":0,"stats":{"Line":0}},{"line":498,"address":[],"length":0,"stats":{"Line":0}},{"line":499,"address":[],"length":0,"stats":{"Line":0}},{"line":500,"address":[],"length":0,"stats":{"Line":0}},{"line":502,"address":[],"length":0,"stats":{"Line":0}},{"line":503,"address":[],"length":0,"stats":{"Line":0}},{"line":506,"address":[],"length":0,"stats":{"Line":0}},{"line":507,"address":[],"length":0,"stats":{"Line":0}},{"line":508,"address":[],"length":0,"stats":{"Line":0}},{"line":510,"address":[],"length":0,"stats":{"Line":0}},{"line":514,"address":[],"length":0,"stats":{"Line":6}},{"line":519,"address":[],"length":0,"stats":{"Line":12}},{"line":520,"address":[],"length":0,"stats":{"Line":0}},{"line":521,"address":[],"length":0,"stats":{"Line":0}},{"line":524,"address":[],"length":0,"stats":{"Line":6}},{"line":535,"address":[],"length":0,"stats":{"Line":1}},{"line":540,"address":[],"length":0,"stats":{"Line":1}},{"line":541,"address":[],"length":0,"stats":{"Line":0}},{"line":542,"address":[],"length":0,"stats":{"Line":0}},{"line":543,"address":[],"length":0,"stats":{"Line":0}},{"line":544,"address":[],"length":0,"stats":{"Line":0}},{"line":545,"address":[],"length":0,"stats":{"Line":0}},{"line":549,"address":[],"length":0,"stats":{"Line":2}},{"line":550,"address":[],"length":0,"stats":{"Line":1}},{"line":552,"address":[],"length":0,"stats":{"Line":1}},{"line":554,"address":[],"length":0,"stats":{"Line":2}},{"line":555,"address":[],"length":0,"stats":{"Line":0}},{"line":557,"address":[],"length":0,"stats":{"Line":1}},{"line":558,"address":[],"length":0,"stats":{"Line":1}},{"line":559,"address":[],"length":0,"stats":{"Line":1}},{"line":560,"address":[],"length":0,"stats":{"Line":1}},{"line":561,"address":[],"length":0,"stats":{"Line":1}},{"line":565,"address":[],"length":0,"stats":{"Line":2}},{"line":566,"address":[],"length":0,"stats":{"Line":9}},{"line":567,"address":[],"length":0,"stats":{"Line":16}},{"line":568,"address":[],"length":0,"stats":{"Line":16}},{"line":569,"address":[],"length":0,"stats":{"Line":4}},{"line":570,"address":[],"length":0,"stats":{"Line":4}},{"line":572,"address":[],"length":0,"stats":{"Line":6}},{"line":573,"address":[],"length":0,"stats":{"Line":2}},{"line":574,"address":[],"length":0,"stats":{"Line":2}},{"line":579,"address":[],"length":0,"stats":{"Line":1}}],"covered":117,"coverable":180},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","backend.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","bridge.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","config.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","context_architect","assembler.rs"],"content":"use std::collections::HashMap;\nuse std::hash::Hasher;\nuse std::sync::Arc;\nuse std::sync::atomic::{AtomicU64, Ordering};\nuse std::time::{Duration, Instant};\n\nuse config::cca::StalenessPolicy;\nuse dashmap::DashMap;\nuse mk_core::types::{ContextVector, LayerSummary, MemoryLayer, SummaryDepth, compute_xxhash64};\nuse serde::{Deserialize, Serialize};\nuse tracing::{info_span, warn};\n\nuse crate::context_architect::compressor::ViewMode;\n\n#[derive(Debug, Clone, Eq, Hash, PartialEq)]\nstruct CacheKey {\n    query_hash: u64,\n    token_budget: u32,\n    view_mode: ViewMode,\n}\n\nimpl CacheKey {\n    fn new(\n        query_embedding: Option<&ContextVector>,\n        token_budget: u32,\n        view_mode: ViewMode,\n    ) -> Self {\n        let query_hash = match query_embedding {\n            Some(vec) => {\n                let mut hasher = std::collections::hash_map::DefaultHasher::new();\n                for &val in vec {\n                    let bytes = val.to_le_bytes();\n                    for byte in bytes {\n                        hasher.write_u8(byte);\n                    }\n                }\n                hasher.finish()\n            }\n            None => 0,\n        };\n\n        Self {\n            query_hash,\n            token_budget,\n            view_mode,\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\nstruct CacheEntry {\n    context: AssembledContext,\n    created_at: Instant,\n}\n\n#[derive(Debug, Clone)]\npub struct AssemblyMetrics {\n    total_assemblies: Arc<AtomicU64>,\n    cache_hits: Arc<AtomicU64>,\n    cache_misses: Arc<AtomicU64>,\n    timeouts: Arc<AtomicU64>,\n    latency_sum_ms: Arc<AtomicU64>,\n    partial_returns: Arc<AtomicU64>,\n}\n\nimpl AssemblyMetrics {\n    pub fn new() -> Self {\n        Self {\n            total_assemblies: Arc::new(AtomicU64::new(0)),\n            cache_hits: Arc::new(AtomicU64::new(0)),\n            cache_misses: Arc::new(AtomicU64::new(0)),\n            timeouts: Arc::new(AtomicU64::new(0)),\n            latency_sum_ms: Arc::new(AtomicU64::new(0)),\n            partial_returns: Arc::new(AtomicU64::new(0)),\n        }\n    }\n\n    pub fn record_assembly(\n        &self,\n        latency_ms: u64,\n        hit_cache: bool,\n        timed_out: bool,\n        partial: bool,\n    ) {\n        self.total_assemblies.fetch_add(1, Ordering::Relaxed);\n        self.latency_sum_ms.fetch_add(latency_ms, Ordering::Relaxed);\n\n        if hit_cache {\n            self.cache_hits.fetch_add(1, Ordering::Relaxed);\n        } else {\n            self.cache_misses.fetch_add(1, Ordering::Relaxed);\n        }\n\n        if timed_out {\n            self.timeouts.fetch_add(1, Ordering::Relaxed);\n        }\n\n        if partial {\n            self.partial_returns.fetch_add(1, Ordering::Relaxed);\n        }\n    }\n\n    pub fn total_assemblies(&self) -> u64 {\n        self.total_assemblies.load(Ordering::Relaxed)\n    }\n\n    pub fn cache_hit_rate(&self) -> f64 {\n        let total = self.total_assemblies();\n        if total == 0 {\n            0.0\n        } else {\n            let hits = self.cache_hits.load(Ordering::Relaxed);\n            hits as f64 / total as f64\n        }\n    }\n\n    pub fn timeout_rate(&self) -> f64 {\n        let total = self.total_assemblies();\n        if total == 0 {\n            0.0\n        } else {\n            let timeouts = self.timeouts.load(Ordering::Relaxed);\n            timeouts as f64 / total as f64\n        }\n    }\n\n    pub fn avg_latency_ms(&self) -> f64 {\n        let total = self.total_assemblies.load(Ordering::Relaxed);\n        if total == 0 {\n            0.0\n        } else {\n            let sum = self.latency_sum_ms.load(Ordering::Relaxed);\n            sum as f64 / total as f64\n        }\n    }\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum StalenessStatus {\n    Fresh,\n    Stale,\n    Unknown,\n}\n\n#[derive(Debug, Clone)]\npub struct AssemblerConfig {\n    pub view_mode: ViewMode,\n    pub default_token_budget: u32,\n    pub layer_priorities: Vec<MemoryLayer>,\n    pub min_relevance_score: f32,\n    pub enable_caching: bool,\n    pub cache_ttl_secs: u64,\n    pub staleness_policy: StalenessPolicy,\n    pub assembly_timeout_ms: u64,\n    pub enable_parallel_queries: bool,\n    pub enable_early_termination: bool,\n}\n\nimpl Default for AssemblerConfig {\n    fn default() -> Self {\n        Self {\n            view_mode: ViewMode::Ax,\n            default_token_budget: 4000,\n            layer_priorities: vec![\n                MemoryLayer::Session,\n                MemoryLayer::Project,\n                MemoryLayer::Team,\n                MemoryLayer::Org,\n                MemoryLayer::Company,\n            ],\n            min_relevance_score: 0.3,\n            enable_caching: true,\n            cache_ttl_secs: 300,\n            staleness_policy: StalenessPolicy::default(),\n            assembly_timeout_ms: 100,\n            enable_parallel_queries: true,\n            enable_early_termination: true,\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct ContextEntry {\n    pub entry_id: String,\n    pub layer: MemoryLayer,\n    pub content: String,\n    pub token_count: u32,\n    pub depth: SummaryDepth,\n    pub relevance_score: f32,\n    pub context_vector: Option<ContextVector>,\n    pub staleness_status: StalenessStatus,\n}\n\n#[derive(Debug, Clone)]\npub struct ContextMetadata {\n    pub view_type: String,\n    pub includes_trajectory_logs: bool,\n    pub includes_metrics: bool,\n    pub includes_traces: bool,\n}\n\nimpl ContextMetadata {\n    pub fn minimal() -> Self {\n        Self {\n            view_type: \"agent_experience\".to_string(),\n            includes_trajectory_logs: false,\n            includes_metrics: false,\n            includes_traces: false,\n        }\n    }\n\n    pub fn with_trajectory_logs(mut self) -> Self {\n        self.includes_trajectory_logs = true;\n        self\n    }\n\n    pub fn with_metrics(mut self) -> Self {\n        self.includes_metrics = true;\n        self\n    }\n\n    pub fn with_traces(mut self) -> Self {\n        self.includes_traces = true;\n        self\n    }\n\n    pub fn full_debug() -> Self {\n        Self {\n            view_type: \"developer_experience\".to_string(),\n            includes_trajectory_logs: true,\n            includes_metrics: true,\n            includes_traces: true,\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct ContextView {\n    pub content: String,\n    pub metadata: ContextMetadata,\n}\n\n#[derive(Debug, Clone)]\npub struct AssembledContext {\n    pub view: ContextView,\n    pub entries: Vec<ContextEntry>,\n    pub total_tokens: u32,\n    pub token_budget: u32,\n    pub layers_included: Vec<MemoryLayer>,\n    pub query_embedding: Option<ContextVector>,\n    pub stale_entries: Vec<String>,\n    pub has_stale_content: bool,\n    pub timed_out: bool,\n    pub partial: bool,\n}\n\nimpl AssembledContext {\n    pub fn is_within_budget(&self) -> bool {\n        self.total_tokens <= self.token_budget\n    }\n\n    pub fn content(&self) -> String {\n        self.view.content.clone()\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct SummarySource {\n    pub entry_id: String,\n    pub layer: MemoryLayer,\n    pub summaries: HashMap<SummaryDepth, LayerSummary>,\n    pub context_vector: Option<ContextVector>,\n    pub full_content: Option<String>,\n    pub full_content_tokens: Option<u32>,\n    pub current_source_content: Option<String>,\n}\n\npub struct ContextAssembler {\n    config: AssemblerConfig,\n    cache: Arc<DashMap<CacheKey, CacheEntry>>,\n    metrics: Arc<AssemblyMetrics>,\n}\n\nimpl ContextAssembler {\n    pub fn new(config: AssemblerConfig) -> Self {\n        Self {\n            config,\n            cache: Arc::new(DashMap::new()),\n            metrics: Arc::new(AssemblyMetrics::new()),\n        }\n    }\n\n    pub fn with_cache(mut self, cache: Arc<DashMap<CacheKey, CacheEntry>>) -> Self {\n        self.cache = cache;\n        self\n    }\n\n    pub fn with_metrics(mut self, metrics: Arc<AssemblyMetrics>) -> Self {\n        self.metrics = metrics;\n        self\n    }\n\n    pub fn metrics(&self) -> &Arc<AssemblyMetrics> {\n        &self.metrics\n    }\n\n    pub fn clear_cache(&self) {\n        self.cache.clear();\n    }\n\n    pub fn assemble_context(\n        &self,\n        query_embedding: Option<&ContextVector>,\n        sources: &[SummarySource],\n        token_budget: Option<u32>,\n    ) -> AssembledContext {\n        let start = Instant::now();\n        let budget = token_budget.unwrap_or(self.config.default_token_budget);\n\n        if self.config.enable_caching {\n            let cache_key = CacheKey::new(query_embedding, budget, self.config.view_mode);\n\n            if let Some(entry) = self.cache.get(&cache_key) {\n                if entry.created_at.elapsed() < Duration::from_secs(self.config.cache_ttl_secs) {\n                    let mut cached = entry.context.clone();\n                    cached.timed_out = false;\n                    cached.partial = false;\n                    self.metrics.record_assembly(\n                        start.elapsed().as_millis() as u64,\n                        true,\n                        false,\n                        false,\n                    );\n                    return cached;\n                }\n            }\n\n            self.cache.retain(|_, entry| {\n                entry.created_at.elapsed() < Duration::from_secs(self.config.cache_ttl_secs)\n            });\n        }\n\n        let mut result = self.assemble_context_internal(query_embedding, sources, Some(budget));\n\n        let latency_ms = start.elapsed().as_millis() as u64;\n        result.timed_out = latency_ms >= self.config.assembly_timeout_ms;\n        result.partial = self.config.enable_early_termination && result.total_tokens < budget;\n\n        if self.config.enable_caching {\n            let cache_key = CacheKey::new(query_embedding, budget, self.config.view_mode);\n            self.cache.insert(\n                cache_key,\n                CacheEntry {\n                    context: result.clone(),\n                    created_at: Instant::now(),\n                },\n            );\n        }\n\n        self.metrics\n            .record_assembly(latency_ms, false, result.timed_out, result.partial);\n\n        result\n    }\n\n    fn assemble_context_internal(\n        &self,\n        query_embedding: Option<&ContextVector>,\n        sources: &[SummarySource],\n        token_budget: Option<u32>,\n    ) -> AssembledContext {\n        let budget = token_budget.unwrap_or(self.config.default_token_budget);\n\n        let scored_sources: Vec<_> = sources\n            .iter()\n            .map(|s| {\n                let score = self.compute_relevance_score(query_embedding, s);\n                (s, score)\n            })\n            .filter(|(_, score)| *score >= self.config.min_relevance_score)\n            .collect();\n\n        let token_allocations = self.distribute_token_budget(&scored_sources, budget);\n        let mut entries = self.select_entries(&scored_sources, &token_allocations);\n\n        if self.config.enable_early_termination {\n            let mut total_tokens = 0;\n            entries.retain(|e| {\n                total_tokens += e.token_count;\n                total_tokens <= budget\n            });\n        }\n\n        let total_tokens = entries.iter().map(|e| e.token_count).sum();\n        let layers_included: Vec<_> = entries\n            .iter()\n            .map(|e| e.layer)\n            .collect::<std::collections::HashSet<_>>()\n            .into_iter()\n            .collect();\n\n        let stale_entries: Vec<String> = entries\n            .iter()\n            .filter(|e| e.staleness_status == StalenessStatus::Stale)\n            .map(|e| e.entry_id.clone())\n            .collect();\n        let has_stale_content = !stale_entries.is_empty();\n\n        let view = self.create_view(&entries, budget);\n\n        AssembledContext {\n            view,\n            entries,\n            total_tokens,\n            token_budget: budget,\n            layers_included,\n            query_embedding: query_embedding.cloned(),\n            stale_entries,\n            has_stale_content,\n            timed_out: false,\n            partial: false,\n        }\n    }\n\n    fn create_view(&self, entries: &[ContextEntry], budget: u32) -> ContextView {\n        let preferred_depths = match self.config.view_mode {\n            ViewMode::Ax => vec![SummaryDepth::Sentence],\n            ViewMode::Ux => vec![SummaryDepth::Paragraph, SummaryDepth::Sentence],\n            ViewMode::Dx => vec![\n                SummaryDepth::Detailed,\n                SummaryDepth::Paragraph,\n                SummaryDepth::Sentence,\n            ],\n        };\n\n        let metadata = match self.config.view_mode {\n            ViewMode::Ax => ContextMetadata::minimal(),\n            ViewMode::Ux => ContextMetadata {\n                view_type: \"user_experience\".to_string(),\n                includes_trajectory_logs: false,\n                includes_metrics: false,\n                includes_traces: false,\n            },\n            ViewMode::Dx => ContextMetadata {\n                view_type: \"developer_experience\".to_string(),\n                includes_trajectory_logs: true,\n                includes_metrics: true,\n                includes_traces: true,\n            },\n        };\n\n        let (content, _total_tokens) = self.build_view_content(entries, &preferred_depths, budget);\n\n        ContextView { content, metadata }\n    }\n\n    fn build_view_content(\n        &self,\n        entries: &[ContextEntry],\n        _preferred_depths: &[SummaryDepth],\n        budget: u32,\n    ) -> (String, u32) {\n        let mut output = Vec::new();\n        let mut used_tokens = 0;\n\n        for entry in entries {\n            let entry_tokens = entry.token_count;\n\n            if used_tokens + entry_tokens > budget {\n                break;\n            }\n\n            output.push(entry.content.clone());\n            used_tokens += entry_tokens;\n        }\n\n        (output.join(\"\\n\\n\"), used_tokens)\n    }\n\n    fn compute_relevance_score(\n        &self,\n        query_embedding: Option<&ContextVector>,\n        source: &SummarySource,\n    ) -> f32 {\n        match (query_embedding, &source.context_vector) {\n            (Some(query), Some(source_vec)) => cosine_similarity(query, source_vec),\n            _ => self.layer_base_score(source.layer),\n        }\n    }\n\n    fn layer_base_score(&self, layer: MemoryLayer) -> f32 {\n        let position = self\n            .config\n            .layer_priorities\n            .iter()\n            .position(|&l| l == layer);\n\n        match position {\n            Some(idx) => 1.0 - (idx as f32 * 0.1),\n            None => 0.5,\n        }\n    }\n\n    fn distribute_token_budget(\n        &self,\n        scored_sources: &[(&SummarySource, f32)],\n        budget: u32,\n    ) -> HashMap<String, u32> {\n        let mut allocations = HashMap::new();\n\n        if scored_sources.is_empty() {\n            return allocations;\n        }\n\n        let total_score: f32 = scored_sources.iter().map(|(_, s)| s).sum();\n\n        if total_score <= 0.0 {\n            let per_source = budget / scored_sources.len() as u32;\n            for (source, _) in scored_sources {\n                allocations.insert(source.entry_id.clone(), per_source);\n            }\n            return allocations;\n        }\n\n        for (source, score) in scored_sources {\n            let proportion = score / total_score;\n            let tokens = (budget as f32 * proportion).floor() as u32;\n            allocations.insert(source.entry_id.clone(), tokens.max(50));\n        }\n\n        allocations\n    }\n\n    fn select_entries(\n        &self,\n        scored_sources: &[(&SummarySource, f32)],\n        allocations: &HashMap<String, u32>,\n    ) -> Vec<ContextEntry> {\n        let mut entries = Vec::new();\n\n        for (source, relevance) in scored_sources {\n            let allocation = allocations.get(&source.entry_id).copied().unwrap_or(0);\n\n            if let Some(entry) = self.select_best_summary(source, allocation, *relevance) {\n                entries.push(entry);\n            }\n        }\n\n        entries.sort_by(|a, b| {\n            let layer_cmp = self.layer_order(a.layer).cmp(&self.layer_order(b.layer));\n            if layer_cmp != std::cmp::Ordering::Equal {\n                return layer_cmp;\n            }\n            b.relevance_score\n                .partial_cmp(&a.relevance_score)\n                .unwrap_or(std::cmp::Ordering::Equal)\n        });\n\n        entries\n    }\n\n    fn layer_order(&self, layer: MemoryLayer) -> usize {\n        self.config\n            .layer_priorities\n            .iter()\n            .position(|&l| l == layer)\n            .unwrap_or(usize::MAX)\n    }\n\n    fn select_best_summary(\n        &self,\n        source: &SummarySource,\n        allocation: u32,\n        relevance: f32,\n    ) -> Option<ContextEntry> {\n        let depth_order = [\n            SummaryDepth::Detailed,\n            SummaryDepth::Paragraph,\n            SummaryDepth::Sentence,\n        ];\n\n        for depth in depth_order {\n            if let Some(summary) = source.summaries.get(&depth) {\n                if summary.token_count <= allocation {\n                    let staleness = self.check_staleness(source, summary);\n                    return Some(ContextEntry {\n                        entry_id: source.entry_id.clone(),\n                        layer: source.layer,\n                        content: summary.content.clone(),\n                        token_count: summary.token_count,\n                        depth,\n                        relevance_score: relevance,\n                        context_vector: source.context_vector.clone(),\n                        staleness_status: staleness,\n                    });\n                }\n            }\n        }\n\n        for depth in depth_order {\n            if let Some(summary) = source.summaries.get(&depth) {\n                let staleness = self.check_staleness(source, summary);\n                return Some(ContextEntry {\n                    entry_id: source.entry_id.clone(),\n                    layer: source.layer,\n                    content: summary.content.clone(),\n                    token_count: summary.token_count,\n                    depth,\n                    relevance_score: relevance,\n                    context_vector: source.context_vector.clone(),\n                    staleness_status: staleness,\n                });\n            }\n        }\n\n        source.full_content.as_ref().map(|content| ContextEntry {\n            entry_id: source.entry_id.clone(),\n            layer: source.layer,\n            content: content.clone(),\n            token_count: source.full_content_tokens.unwrap_or(0),\n            depth: SummaryDepth::Detailed,\n            relevance_score: relevance,\n            context_vector: source.context_vector.clone(),\n            staleness_status: StalenessStatus::Fresh,\n        })\n    }\n\n    fn check_staleness(&self, source: &SummarySource, summary: &LayerSummary) -> StalenessStatus {\n        let Some(current_content) = &source.current_source_content else {\n            return StalenessStatus::Unknown;\n        };\n\n        let current_hash = compute_xxhash64(current_content.as_bytes());\n\n        if summary.source_hash == current_hash {\n            StalenessStatus::Fresh\n        } else if let Some(content_hash) = &summary.content_hash {\n            if *content_hash == current_hash {\n                StalenessStatus::Fresh\n            } else {\n                StalenessStatus::Stale\n            }\n        } else {\n            StalenessStatus::Stale\n        }\n    }\n}\n\npub fn cosine_similarity(a: &[f32], b: &[f32]) -> f32 {\n    if a.len() != b.len() || a.is_empty() {\n        return 0.0;\n    }\n\n    let dot_product: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();\n    let magnitude_a: f32 = a.iter().map(|x| x * x).sum::<f32>().sqrt();\n    let magnitude_b: f32 = b.iter().map(|x| x * x).sum::<f32>().sqrt();\n\n    if magnitude_a == 0.0 || magnitude_b == 0.0 {\n        return 0.0;\n    }\n\n    dot_product / (magnitude_a * magnitude_b)\n}\n\n#[cfg(test)]\nfn sample_source(id: &str, layer: MemoryLayer) -> SummarySource {\n    let mut summaries = HashMap::new();\n    summaries.insert(\n        SummaryDepth::Sentence,\n        LayerSummary {\n            depth: SummaryDepth::Sentence,\n            content: format!(\"Sentence summary for {id}\"),\n            token_count: 20,\n            generated_at: 0,\n            source_hash: \"hash\".to_string(),\n            content_hash: None,\n            personalized: false,\n            personalization_context: None,\n        },\n    );\n    summaries.insert(\n        SummaryDepth::Paragraph,\n        LayerSummary {\n            depth: SummaryDepth::Paragraph,\n            content: format!(\"Paragraph summary for {id} with more detail\"),\n            token_count: 100,\n            generated_at: 0,\n            source_hash: \"hash\".to_string(),\n            content_hash: None,\n            personalized: false,\n            personalization_context: None,\n        },\n    );\n\n    SummarySource {\n        entry_id: id.to_string(),\n        layer,\n        summaries,\n        context_vector: None,\n        full_content: None,\n        full_content_tokens: None,\n        current_source_content: None,\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_assemble_empty_sources() {\n        let assembler = ContextAssembler::new(AssemblerConfig::default());\n        let result = assembler.assemble_context(None, &[], None);\n\n        assert!(result.entries.is_empty());\n        assert_eq!(result.total_tokens, 0);\n    }\n\n    #[test]\n    fn test_assemble_single_source() {\n        let assembler = ContextAssembler::new(AssemblerConfig::default());\n        let sources = vec![sample_source(\"entry1\", MemoryLayer::Session)];\n\n        let result = assembler.assemble_context(None, &sources, None);\n\n        assert_eq!(result.entries.len(), 1);\n        assert!(result.total_tokens > 0);\n    }\n\n    #[test]\n    fn test_assemble_multiple_sources() {\n        let assembler = ContextAssembler::new(AssemblerConfig::default());\n        let sources = vec![\n            sample_source(\"entry1\", MemoryLayer::Session),\n            sample_source(\"entry2\", MemoryLayer::Project),\n            sample_source(\"entry3\", MemoryLayer::Team),\n        ];\n\n        let result = assembler.assemble_context(None, &sources, None);\n\n        assert_eq!(result.entries.len(), 3);\n        assert!(result.layers_included.contains(&MemoryLayer::Session));\n        assert!(result.layers_included.contains(&MemoryLayer::Project));\n        assert!(result.layers_included.contains(&MemoryLayer::Team));\n    }\n\n    #[test]\n    fn test_layer_priority_ordering() {\n        let assembler = ContextAssembler::new(AssemblerConfig::default());\n        let sources = vec![\n            sample_source(\"team1\", MemoryLayer::Team),\n            sample_source(\"session1\", MemoryLayer::Session),\n            sample_source(\"project1\", MemoryLayer::Project),\n        ];\n\n        let result = assembler.assemble_context(None, &sources, None);\n\n        assert_eq!(result.entries[0].layer, MemoryLayer::Session);\n        assert_eq!(result.entries[1].layer, MemoryLayer::Project);\n        assert_eq!(result.entries[2].layer, MemoryLayer::Team);\n    }\n\n    #[test]\n    fn test_custom_token_budget() {\n        let assembler = ContextAssembler::new(AssemblerConfig::default());\n        let sources = vec![sample_source(\"entry1\", MemoryLayer::Session)];\n\n        let result = assembler.assemble_context(None, &sources, Some(100));\n\n        assert_eq!(result.token_budget, 100);\n    }\n\n    #[test]\n    fn test_cosine_similarity_identical_vectors() {\n        let vec_a = vec![1.0, 2.0, 3.0];\n        let vec_b = vec![1.0, 2.0, 3.0];\n\n        let similarity = cosine_similarity(&vec_a, &vec_b);\n\n        assert!((similarity - 1.0).abs() < 0.0001);\n    }\n\n    #[test]\n    fn test_cosine_similarity_orthogonal_vectors() {\n        let vec_a = vec![1.0, 0.0];\n        let vec_b = vec![0.0, 1.0];\n\n        let similarity = cosine_similarity(&vec_a, &vec_b);\n\n        assert!(similarity.abs() < 0.0001);\n    }\n\n    #[test]\n    fn test_cosine_similarity_opposite_vectors() {\n        let vec_a = vec![1.0, 2.0, 3.0];\n        let vec_b = vec![-1.0, -2.0, -3.0];\n\n        let similarity = cosine_similarity(&vec_a, &vec_b);\n\n        assert!((similarity + 1.0).abs() < 0.0001);\n    }\n\n    #[test]\n    fn test_cosine_similarity_empty_vectors() {\n        let vec_a: Vec<f32> = vec![];\n        let vec_b: Vec<f32> = vec![];\n\n        let similarity = cosine_similarity(&vec_a, &vec_b);\n\n        assert_eq!(similarity, 0.0);\n    }\n\n    #[test]\n    fn test_cosine_similarity_mismatched_length() {\n        let vec_a = vec![1.0, 2.0, 3.0];\n        let vec_b = vec![1.0, 2.0];\n\n        let similarity = cosine_similarity(&vec_a, &vec_b);\n\n        assert_eq!(similarity, 0.0);\n    }\n\n    #[test]\n    fn test_relevance_scoring_with_embeddings() {\n        let assembler = ContextAssembler::new(AssemblerConfig::default());\n\n        let query = vec![1.0, 0.0, 0.0];\n        let mut source = sample_source(\"entry1\", MemoryLayer::Session);\n        source.context_vector = Some(vec![1.0, 0.0, 0.0]);\n\n        let sources = vec![source];\n        let result = assembler.assemble_context(Some(&query), &sources, None);\n\n        assert_eq!(result.entries.len(), 1);\n        assert!((result.entries[0].relevance_score - 1.0).abs() < 0.0001);\n    }\n\n    #[test]\n    fn test_min_relevance_filtering() {\n        let config = AssemblerConfig {\n            min_relevance_score: 0.9,\n            ..Default::default()\n        };\n        let assembler = ContextAssembler::new(config);\n\n        let query = vec![1.0, 0.0, 0.0];\n        let mut source = sample_source(\"entry1\", MemoryLayer::Session);\n        source.context_vector = Some(vec![0.0, 1.0, 0.0]);\n\n        let sources = vec![source];\n        let result = assembler.assemble_context(Some(&query), &sources, None);\n\n        assert!(result.entries.is_empty());\n    }\n\n    #[test]\n    fn test_select_appropriate_depth() {\n        let assembler = ContextAssembler::new(AssemblerConfig::default());\n\n        let mut source = sample_source(\"entry1\", MemoryLayer::Session);\n        source.summaries.insert(\n            SummaryDepth::Detailed,\n            LayerSummary {\n                depth: SummaryDepth::Detailed,\n                content: \"Very detailed summary\".to_string(),\n                token_count: 300,\n                generated_at: 0,\n                source_hash: \"hash\".to_string(),\n                content_hash: None,\n                personalized: false,\n                personalization_context: None,\n            },\n        );\n\n        let sources = vec![source];\n        let result = assembler.assemble_context(None, &sources, Some(500));\n\n        assert_eq!(result.entries[0].depth, SummaryDepth::Detailed);\n    }\n\n    #[test]\n    fn test_fallback_to_smaller_summary() {\n        let assembler = ContextAssembler::new(AssemblerConfig::default());\n\n        let mut source = sample_source(\"entry1\", MemoryLayer::Session);\n        source.summaries.insert(\n            SummaryDepth::Detailed,\n            LayerSummary {\n                depth: SummaryDepth::Detailed,\n                content: \"Very detailed summary\".to_string(),\n                token_count: 500,\n                generated_at: 0,\n                source_hash: \"hash\".to_string(),\n                content_hash: None,\n                personalized: false,\n                personalization_context: None,\n            },\n        );\n\n        let sources = vec![source];\n        let result = assembler.assemble_context(None, &sources, Some(150));\n\n        assert!(result.entries[0].depth != SummaryDepth::Detailed);\n    }\n\n    #[test]\n    fn test_assembled_context_content() {\n        let assembler = ContextAssembler::new(AssemblerConfig::default());\n        let sources = vec![\n            sample_source(\"entry1\", MemoryLayer::Session),\n            sample_source(\"entry2\", MemoryLayer::Project),\n        ];\n\n        let result = assembler.assemble_context(None, &sources, None);\n        let content = result.content();\n\n        assert!(content.contains(\"entry1\"));\n        assert!(content.contains(\"entry2\"));\n    }\n\n    #[test]\n    fn test_is_within_budget() {\n        let assembler = ContextAssembler::new(AssemblerConfig::default());\n        let sources = vec![sample_source(\"entry1\", MemoryLayer::Session)];\n\n        let result = assembler.assemble_context(None, &sources, Some(1000));\n\n        assert!(result.is_within_budget());\n    }\n\n    #[test]\n    fn test_fallback_to_full_content() {\n        let assembler = ContextAssembler::new(AssemblerConfig::default());\n\n        let source = SummarySource {\n            entry_id: \"entry1\".to_string(),\n            layer: MemoryLayer::Session,\n            summaries: HashMap::new(),\n            context_vector: None,\n            full_content: Some(\"This is the full content\".to_string()),\n            full_content_tokens: Some(100),\n            current_source_content: None,\n        };\n\n        let sources = vec![source];\n        let result = assembler.assemble_context(None, &sources, None);\n\n        assert_eq!(result.entries.len(), 1);\n        assert!(result.entries[0].content.contains(\"full content\"));\n    }\n\n    #[test]\n    fn test_staleness_fresh_when_source_hash_matches() {\n        let assembler = ContextAssembler::new(AssemblerConfig::default());\n        let content = \"Test source content for hashing\";\n        let source_hash = compute_xxhash64(content.as_bytes());\n\n        let mut summaries = HashMap::new();\n        summaries.insert(\n            SummaryDepth::Sentence,\n            LayerSummary {\n                depth: SummaryDepth::Sentence,\n                content: \"Summary of test content\".to_string(),\n                token_count: 10,\n                generated_at: 0,\n                source_hash: source_hash.clone(),\n                content_hash: None,\n                personalized: false,\n                personalization_context: None,\n            },\n        );\n\n        let source = SummarySource {\n            entry_id: \"entry1\".to_string(),\n            layer: MemoryLayer::Session,\n            summaries,\n            context_vector: None,\n            full_content: None,\n            full_content_tokens: None,\n            current_source_content: Some(content.to_string()),\n        };\n\n        let result = assembler.assemble_context(None, &[source], None);\n\n        assert_eq!(result.entries.len(), 1);\n        assert_eq!(result.entries[0].staleness_status, StalenessStatus::Fresh);\n        assert!(!result.has_stale_content);\n        assert!(result.stale_entries.is_empty());\n    }\n\n    #[test]\n    fn test_staleness_stale_when_source_hash_mismatch() {\n        let assembler = ContextAssembler::new(AssemblerConfig::default());\n        let original_content = \"Original source content\";\n        let modified_content = \"Modified source content - changed!\";\n        let original_hash = compute_xxhash64(original_content.as_bytes());\n\n        let mut summaries = HashMap::new();\n        summaries.insert(\n            SummaryDepth::Sentence,\n            LayerSummary {\n                depth: SummaryDepth::Sentence,\n                content: \"Summary of original content\".to_string(),\n                token_count: 10,\n                generated_at: 0,\n                source_hash: original_hash,\n                content_hash: None,\n                personalized: false,\n                personalization_context: None,\n            },\n        );\n\n        let source = SummarySource {\n            entry_id: \"entry1\".to_string(),\n            layer: MemoryLayer::Session,\n            summaries,\n            context_vector: None,\n            full_content: None,\n            full_content_tokens: None,\n            current_source_content: Some(modified_content.to_string()),\n        };\n\n        let result = assembler.assemble_context(None, &[source], None);\n\n        assert_eq!(result.entries.len(), 1);\n        assert_eq!(result.entries[0].staleness_status, StalenessStatus::Stale);\n        assert!(result.has_stale_content);\n        assert_eq!(result.stale_entries.len(), 1);\n        assert!(result.stale_entries.contains(&\"entry1\".to_string()));\n    }\n\n    #[test]\n    fn test_staleness_unknown_when_no_current_content() {\n        let assembler = ContextAssembler::new(AssemblerConfig::default());\n        let source = sample_source(\"entry1\", MemoryLayer::Session);\n\n        let result = assembler.assemble_context(None, &[source], None);\n\n        assert_eq!(result.entries.len(), 1);\n        assert_eq!(result.entries[0].staleness_status, StalenessStatus::Unknown);\n        assert!(!result.has_stale_content);\n    }\n\n    #[test]\n    fn test_staleness_mixed_entries() {\n        let assembler = ContextAssembler::new(AssemblerConfig::default());\n\n        let fresh_content = \"Fresh content here\";\n        let fresh_hash = compute_xxhash64(fresh_content.as_bytes());\n        let mut fresh_summaries = HashMap::new();\n        fresh_summaries.insert(\n            SummaryDepth::Sentence,\n            LayerSummary {\n                depth: SummaryDepth::Sentence,\n                content: \"Fresh summary\".to_string(),\n                token_count: 10,\n                generated_at: 0,\n                source_hash: fresh_hash,\n                content_hash: None,\n                personalized: false,\n                personalization_context: None,\n            },\n        );\n\n        let fresh_source = SummarySource {\n            entry_id: \"fresh_entry\".to_string(),\n            layer: MemoryLayer::Session,\n            summaries: fresh_summaries,\n            context_vector: None,\n            full_content: None,\n            full_content_tokens: None,\n            current_source_content: Some(fresh_content.to_string()),\n        };\n\n        let stale_original = \"Stale original\";\n        let stale_modified = \"Stale modified content\";\n        let stale_hash = compute_xxhash64(stale_original.as_bytes());\n        let mut stale_summaries = HashMap::new();\n        stale_summaries.insert(\n            SummaryDepth::Sentence,\n            LayerSummary {\n                depth: SummaryDepth::Sentence,\n                content: \"Stale summary\".to_string(),\n                token_count: 10,\n                generated_at: 0,\n                source_hash: stale_hash,\n                content_hash: None,\n                personalized: false,\n                personalization_context: None,\n            },\n        );\n\n        let stale_source = SummarySource {\n            entry_id: \"stale_entry\".to_string(),\n            layer: MemoryLayer::Project,\n            summaries: stale_summaries,\n            context_vector: None,\n            full_content: None,\n            full_content_tokens: None,\n            current_source_content: Some(stale_modified.to_string()),\n        };\n\n        let result = assembler.assemble_context(None, &[fresh_source, stale_source], None);\n\n        assert_eq!(result.entries.len(), 2);\n        assert!(result.has_stale_content);\n        assert_eq!(result.stale_entries.len(), 1);\n        assert!(result.stale_entries.contains(&\"stale_entry\".to_string()));\n\n        let fresh_entry = result\n            .entries\n            .iter()\n            .find(|e| e.entry_id == \"fresh_entry\")\n            .unwrap();\n        let stale_entry = result\n            .entries\n            .iter()\n            .find(|e| e.entry_id == \"stale_entry\")\n            .unwrap();\n\n        assert_eq!(fresh_entry.staleness_status, StalenessStatus::Fresh);\n        assert_eq!(stale_entry.staleness_status, StalenessStatus::Stale);\n    }\n\n    #[test]\n    fn test_staleness_empty_content_hashes_correctly() {\n        let assembler = ContextAssembler::new(AssemblerConfig::default());\n        let empty_content = \"\";\n        let empty_hash = compute_xxhash64(empty_content.as_bytes());\n\n        let mut summaries = HashMap::new();\n        summaries.insert(\n            SummaryDepth::Sentence,\n            LayerSummary {\n                depth: SummaryDepth::Sentence,\n                content: \"Summary of empty\".to_string(),\n                token_count: 5,\n                generated_at: 0,\n                source_hash: empty_hash,\n                content_hash: None,\n                personalized: false,\n                personalization_context: None,\n            },\n        );\n\n        let source = SummarySource {\n            entry_id: \"empty_entry\".to_string(),\n            layer: MemoryLayer::Session,\n            summaries,\n            context_vector: None,\n            full_content: None,\n            full_content_tokens: None,\n            current_source_content: Some(empty_content.to_string()),\n        };\n\n        let result = assembler.assemble_context(None, &[source], None);\n\n        assert_eq!(result.entries[0].staleness_status, StalenessStatus::Fresh);\n    }\n\n    #[test]\n    fn test_staleness_large_content_hashes_correctly() {\n        let assembler = ContextAssembler::new(AssemblerConfig::default());\n        let large_content = \"x\".repeat(100_000);\n        let large_hash = compute_xxhash64(large_content.as_bytes());\n\n        let mut summaries = HashMap::new();\n        summaries.insert(\n            SummaryDepth::Sentence,\n            LayerSummary {\n                depth: SummaryDepth::Sentence,\n                content: \"Summary of large content\".to_string(),\n                token_count: 10,\n                generated_at: 0,\n                source_hash: large_hash,\n                content_hash: None,\n                personalized: false,\n                personalization_context: None,\n            },\n        );\n\n        let source = SummarySource {\n            entry_id: \"large_entry\".to_string(),\n            layer: MemoryLayer::Session,\n            summaries,\n            context_vector: None,\n            full_content: None,\n            full_content_tokens: None,\n            current_source_content: Some(large_content),\n        };\n\n        let result = assembler.assemble_context(None, &[source], None);\n\n        assert_eq!(result.entries[0].staleness_status, StalenessStatus::Fresh);\n    }\n\n    #[test]\n    fn test_staleness_unicode_content_hashes_correctly() {\n        let assembler = ContextAssembler::new(AssemblerConfig::default());\n        let unicode_content = \"  mojis and  special chars\";\n        let unicode_hash = compute_xxhash64(unicode_content.as_bytes());\n\n        let mut summaries = HashMap::new();\n        summaries.insert(\n            SummaryDepth::Sentence,\n            LayerSummary {\n                depth: SummaryDepth::Sentence,\n                content: \"Summary of unicode\".to_string(),\n                token_count: 8,\n                generated_at: 0,\n                source_hash: unicode_hash,\n                content_hash: None,\n                personalized: false,\n                personalization_context: None,\n            },\n        );\n\n        let source = SummarySource {\n            entry_id: \"unicode_entry\".to_string(),\n            layer: MemoryLayer::Session,\n            summaries,\n            context_vector: None,\n            full_content: None,\n            full_content_tokens: None,\n            current_source_content: Some(unicode_content.to_string()),\n        };\n\n        let result = assembler.assemble_context(None, &[source], None);\n\n        assert_eq!(result.entries[0].staleness_status, StalenessStatus::Fresh);\n    }\n\n    #[test]\n    fn test_staleness_whitespace_changes_detected() {\n        let assembler = ContextAssembler::new(AssemblerConfig::default());\n        let original = \"Content with spaces\";\n        let modified = \"Content  with  spaces\";\n        let original_hash = compute_xxhash64(original.as_bytes());\n\n        let mut summaries = HashMap::new();\n        summaries.insert(\n            SummaryDepth::Sentence,\n            LayerSummary {\n                depth: SummaryDepth::Sentence,\n                content: \"Summary\".to_string(),\n                token_count: 5,\n                generated_at: 0,\n                source_hash: original_hash,\n                content_hash: None,\n                personalized: false,\n                personalization_context: None,\n            },\n        );\n\n        let source = SummarySource {\n            entry_id: \"ws_entry\".to_string(),\n            layer: MemoryLayer::Session,\n            summaries,\n            context_vector: None,\n            full_content: None,\n            full_content_tokens: None,\n            current_source_content: Some(modified.to_string()),\n        };\n\n        let result = assembler.assemble_context(None, &[source], None);\n\n        assert_eq!(result.entries[0].staleness_status, StalenessStatus::Stale);\n    }\n\n    #[test]\n    fn test_cache_hit_returns_cached_result() {\n        let config = AssemblerConfig {\n            enable_caching: true,\n            cache_ttl_secs: 3600,\n            ..Default::default()\n        };\n        let assembler = ContextAssembler::new(config);\n\n        let sources = vec![sample_source(\"entry1\", MemoryLayer::Session)];\n        let query = vec![1.0, 0.0, 0.0];\n\n        let result1 = assembler.assemble_context(Some(&query), &sources, None);\n        assert_eq!(result1.entries.len(), 1);\n\n        let result2 = assembler.assemble_context(Some(&query), &sources, None);\n        assert_eq!(result2.entries.len(), 1);\n        assert_eq!(result2.total_tokens, result1.total_tokens);\n\n        assert_eq!(assembler.metrics().cache_hits.load(Ordering::Relaxed), 1);\n        assert_eq!(assembler.metrics().cache_misses.load(Ordering::Relaxed), 1);\n    }\n\n    #[test]\n    fn test_cache_miss_after_ttl_expiry() {\n        use std::thread;\n        use std::time::Duration;\n\n        let config = AssemblerConfig {\n            enable_caching: true,\n            cache_ttl_secs: 1,\n            ..Default::default()\n        };\n        let assembler = ContextAssembler::new(config);\n\n        let sources = vec![sample_source(\"entry1\", MemoryLayer::Session)];\n        let query = vec![1.0, 0.0, 0.0];\n\n        let result1 = assembler.assemble_context(Some(&query), &sources, None);\n        assert_eq!(assembler.metrics().cache_hits.load(Ordering::Relaxed), 0);\n        assert_eq!(assembler.metrics().cache_misses.load(Ordering::Relaxed), 1);\n\n        thread::sleep(Duration::from_millis(1100));\n\n        let result2 = assembler.assemble_context(Some(&query), &sources, None);\n        assert_eq!(result2.entries.len(), 1);\n\n        assert_eq!(assembler.metrics().cache_hits.load(Ordering::Relaxed), 0);\n        assert_eq!(assembler.metrics().cache_misses.load(Ordering::Relaxed), 2);\n    }\n\n    #[test]\n    fn test_assembly_timeout_detection() {\n        let config = AssemblerConfig {\n            assembly_timeout_ms: 0,\n            ..Default::default()\n        };\n        let assembler = ContextAssembler::new(config);\n\n        let sources = vec![sample_source(\"entry1\", MemoryLayer::Session)];\n        let result = assembler.assemble_context(None, &sources, None);\n\n        assert_eq!(result.entries.len(), 1);\n        assert!(result.timed_out);\n    }\n\n    #[test]\n    fn test_partial_context_return() {\n        let config = AssemblerConfig {\n            enable_early_termination: true,\n            ..Default::default()\n        };\n        let assembler = ContextAssembler::new(config);\n\n        let mut sources = vec![];\n        for i in 0..10 {\n            sources.push(sample_source(&format!(\"entry{}\", i), MemoryLayer::Session));\n        }\n\n        let result = assembler.assemble_context(None, &sources, Some(500));\n\n        assert!(result.partial);\n        assert!(result.total_tokens < 500);\n    }\n\n    #[test]\n    fn test_early_termination_disabled() {\n        let config = AssemblerConfig {\n            enable_early_termination: false,\n            ..Default::default()\n        };\n        let assembler = ContextAssembler::new(config);\n\n        let mut sources = vec![];\n        for i in 0..10 {\n            sources.push(sample_source(&format!(\"entry{}\", i), MemoryLayer::Session));\n        }\n\n        let result = assembler.assemble_context(None, &sources, Some(500));\n\n        assert!(!result.partial);\n    }\n\n    #[test]\n    fn test_metrics_avg_latency() {\n        let assembler = ContextAssembler::new(AssemblerConfig::default());\n\n        let sources = vec![sample_source(\"entry1\", MemoryLayer::Session)];\n\n        for _ in 0..10 {\n            assembler.assemble_context(None, &sources, None);\n        }\n\n        let avg = assembler.metrics().avg_latency_ms();\n        assert!(avg >= 0.0);\n        assert_eq!(\n            assembler.metrics().total_assemblies.load(Ordering::Relaxed),\n            10\n        );\n\n        let avg = assembler.metrics().avg_latency_ms();\n        assert!(avg >= 0.0);\n        assert_eq!(\n            assembler.metrics().total_assemblies.load(Ordering::Relaxed),\n            10\n        );\n    }\n\n    #[test]\n    fn test_metrics_cache_hit_rate() {\n        let config = AssemblerConfig {\n            enable_caching: true,\n            cache_ttl_secs: 3600,\n            ..Default::default()\n        };\n        let assembler = ContextAssembler::new(config);\n\n        let sources = vec![sample_source(\"entry1\", MemoryLayer::Session)];\n        let query = vec![1.0, 0.0, 0.0];\n\n        for _ in 0..5 {\n            assembler.assemble_context(Some(&query), &sources, None);\n        }\n\n        let hit_rate = assembler.metrics().cache_hit_rate();\n        assert!(hit_rate > 0.0 && hit_rate < 1.0);\n    }\n\n    #[test]\n    fn test_clear_cache() {\n        let config = AssemblerConfig {\n            enable_caching: true,\n            cache_ttl_secs: 3600,\n            ..Default::default()\n        };\n        let assembler = ContextAssembler::new(config);\n\n        let sources = vec![sample_source(\"entry1\", MemoryLayer::Session)];\n        let query = vec![1.0, 0.0, 0.0];\n\n        assembler.assemble_context(Some(&query), &sources, None);\n        assert_eq!(assembler.metrics().cache_hits.load(Ordering::Relaxed), 0);\n        assert_eq!(assembler.metrics().cache_misses.load(Ordering::Relaxed), 1);\n\n        assembler.clear_cache();\n\n        assembler.assemble_context(Some(&query), &sources, None);\n        assert_eq!(assembler.metrics().cache_hits.load(Ordering::Relaxed), 0);\n        assert_eq!(assembler.metrics().cache_misses.load(Ordering::Relaxed), 2);\n    }\n\n    #[test]\n    fn test_different_token_budgets_cache_separately() {\n        let config = AssemblerConfig {\n            enable_caching: true,\n            cache_ttl_secs: 3600,\n            ..Default::default()\n        };\n        let assembler = ContextAssembler::new(config);\n\n        let sources = vec![sample_source(\"entry1\", MemoryLayer::Session)];\n        let query = vec![1.0, 0.0, 0.0];\n\n        assembler.assemble_context(Some(&query), &sources, Some(100));\n        assembler.assemble_context(Some(&query), &sources, Some(200));\n\n        assert_eq!(assembler.metrics().cache_hits.load(Ordering::Relaxed), 0);\n        assert_eq!(assembler.metrics().cache_misses.load(Ordering::Relaxed), 2);\n    }\n}\n","traces":[{"line":23,"address":[],"length":0,"stats":{"Line":80}},{"line":28,"address":[],"length":0,"stats":{"Line":160}},{"line":29,"address":[],"length":0,"stats":{"Line":25}},{"line":30,"address":[],"length":0,"stats":{"Line":50}},{"line":31,"address":[],"length":0,"stats":{"Line":175}},{"line":32,"address":[],"length":0,"stats":{"Line":225}},{"line":33,"address":[],"length":0,"stats":{"Line":975}},{"line":34,"address":[],"length":0,"stats":{"Line":600}},{"line":37,"address":[],"length":0,"stats":{"Line":50}},{"line":39,"address":[],"length":0,"stats":{"Line":55}},{"line":67,"address":[],"length":0,"stats":{"Line":52}},{"line":69,"address":[],"length":0,"stats":{"Line":156}},{"line":70,"address":[],"length":0,"stats":{"Line":156}},{"line":71,"address":[],"length":0,"stats":{"Line":156}},{"line":72,"address":[],"length":0,"stats":{"Line":156}},{"line":73,"address":[],"length":0,"stats":{"Line":156}},{"line":74,"address":[],"length":0,"stats":{"Line":52}},{"line":78,"address":[],"length":0,"stats":{"Line":47}},{"line":85,"address":[],"length":0,"stats":{"Line":94}},{"line":86,"address":[],"length":0,"stats":{"Line":141}},{"line":88,"address":[],"length":0,"stats":{"Line":61}},{"line":89,"address":[],"length":0,"stats":{"Line":28}},{"line":91,"address":[],"length":0,"stats":{"Line":66}},{"line":94,"address":[],"length":0,"stats":{"Line":48}},{"line":95,"address":[],"length":0,"stats":{"Line":2}},{"line":98,"address":[],"length":0,"stats":{"Line":77}},{"line":99,"address":[],"length":0,"stats":{"Line":60}},{"line":103,"address":[],"length":0,"stats":{"Line":1}},{"line":104,"address":[],"length":0,"stats":{"Line":2}},{"line":107,"address":[],"length":0,"stats":{"Line":1}},{"line":108,"address":[],"length":0,"stats":{"Line":3}},{"line":109,"address":[],"length":0,"stats":{"Line":1}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":3}},{"line":113,"address":[],"length":0,"stats":{"Line":1}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":2}},{"line":128,"address":[],"length":0,"stats":{"Line":6}},{"line":129,"address":[],"length":0,"stats":{"Line":2}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":6}},{"line":133,"address":[],"length":0,"stats":{"Line":2}},{"line":160,"address":[],"length":0,"stats":{"Line":52}},{"line":164,"address":[],"length":0,"stats":{"Line":104}},{"line":174,"address":[],"length":0,"stats":{"Line":52}},{"line":203,"address":[],"length":0,"stats":{"Line":33}},{"line":205,"address":[],"length":0,"stats":{"Line":33}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":223,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":2}},{"line":259,"address":[],"length":0,"stats":{"Line":2}},{"line":262,"address":[],"length":0,"stats":{"Line":2}},{"line":263,"address":[],"length":0,"stats":{"Line":4}},{"line":285,"address":[],"length":0,"stats":{"Line":52}},{"line":288,"address":[],"length":0,"stats":{"Line":156}},{"line":289,"address":[],"length":0,"stats":{"Line":52}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":298,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":17}},{"line":304,"address":[],"length":0,"stats":{"Line":17}},{"line":307,"address":[],"length":0,"stats":{"Line":1}},{"line":308,"address":[],"length":0,"stats":{"Line":1}},{"line":311,"address":[],"length":0,"stats":{"Line":47}},{"line":317,"address":[],"length":0,"stats":{"Line":94}},{"line":318,"address":[],"length":0,"stats":{"Line":188}},{"line":320,"address":[],"length":0,"stats":{"Line":47}},{"line":321,"address":[],"length":0,"stats":{"Line":235}},{"line":323,"address":[],"length":0,"stats":{"Line":109}},{"line":324,"address":[],"length":0,"stats":{"Line":30}},{"line":325,"address":[],"length":0,"stats":{"Line":42}},{"line":326,"address":[],"length":0,"stats":{"Line":14}},{"line":327,"address":[],"length":0,"stats":{"Line":14}},{"line":328,"address":[],"length":0,"stats":{"Line":42}},{"line":329,"address":[],"length":0,"stats":{"Line":14}},{"line":334,"address":[],"length":0,"stats":{"Line":14}},{"line":338,"address":[],"length":0,"stats":{"Line":68}},{"line":339,"address":[],"length":0,"stats":{"Line":4}},{"line":343,"address":[],"length":0,"stats":{"Line":198}},{"line":345,"address":[],"length":0,"stats":{"Line":66}},{"line":346,"address":[],"length":0,"stats":{"Line":33}},{"line":347,"address":[],"length":0,"stats":{"Line":65}},{"line":349,"address":[],"length":0,"stats":{"Line":66}},{"line":350,"address":[],"length":0,"stats":{"Line":198}},{"line":351,"address":[],"length":0,"stats":{"Line":99}},{"line":352,"address":[],"length":0,"stats":{"Line":66}},{"line":353,"address":[],"length":0,"stats":{"Line":33}},{"line":354,"address":[],"length":0,"stats":{"Line":66}},{"line":355,"address":[],"length":0,"stats":{"Line":33}},{"line":360,"address":[],"length":0,"stats":{"Line":66}},{"line":361,"address":[],"length":0,"stats":{"Line":99}},{"line":363,"address":[],"length":0,"stats":{"Line":33}},{"line":366,"address":[],"length":0,"stats":{"Line":33}},{"line":372,"address":[],"length":0,"stats":{"Line":132}},{"line":374,"address":[],"length":0,"stats":{"Line":99}},{"line":376,"address":[],"length":0,"stats":{"Line":88}},{"line":377,"address":[],"length":0,"stats":{"Line":275}},{"line":378,"address":[],"length":0,"stats":{"Line":55}},{"line":380,"address":[],"length":0,"stats":{"Line":143}},{"line":383,"address":[],"length":0,"stats":{"Line":165}},{"line":384,"address":[],"length":0,"stats":{"Line":165}},{"line":386,"address":[],"length":0,"stats":{"Line":33}},{"line":387,"address":[],"length":0,"stats":{"Line":64}},{"line":388,"address":[],"length":0,"stats":{"Line":108}},{"line":389,"address":[],"length":0,"stats":{"Line":44}},{"line":390,"address":[],"length":0,"stats":{"Line":44}},{"line":394,"address":[],"length":0,"stats":{"Line":132}},{"line":395,"address":[],"length":0,"stats":{"Line":99}},{"line":397,"address":[],"length":0,"stats":{"Line":33}},{"line":402,"address":[],"length":0,"stats":{"Line":99}},{"line":404,"address":[],"length":0,"stats":{"Line":141}},{"line":405,"address":[],"length":0,"stats":{"Line":39}},{"line":407,"address":[],"length":0,"stats":{"Line":66}},{"line":409,"address":[],"length":0,"stats":{"Line":165}},{"line":417,"address":[],"length":0,"stats":{"Line":99}},{"line":425,"address":[],"length":0,"stats":{"Line":33}},{"line":426,"address":[],"length":0,"stats":{"Line":66}},{"line":427,"address":[],"length":0,"stats":{"Line":66}},{"line":428,"address":[],"length":0,"stats":{"Line":0}},{"line":429,"address":[],"length":0,"stats":{"Line":0}},{"line":430,"address":[],"length":0,"stats":{"Line":0}},{"line":431,"address":[],"length":0,"stats":{"Line":0}},{"line":432,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":66}},{"line":437,"address":[],"length":0,"stats":{"Line":33}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":445,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":198}},{"line":457,"address":[],"length":0,"stats":{"Line":33}},{"line":463,"address":[],"length":0,"stats":{"Line":66}},{"line":464,"address":[],"length":0,"stats":{"Line":66}},{"line":466,"address":[],"length":0,"stats":{"Line":141}},{"line":467,"address":[],"length":0,"stats":{"Line":108}},{"line":469,"address":[],"length":0,"stats":{"Line":54}},{"line":470,"address":[],"length":0,"stats":{"Line":0}},{"line":473,"address":[],"length":0,"stats":{"Line":216}},{"line":474,"address":[],"length":0,"stats":{"Line":54}},{"line":477,"address":[],"length":0,"stats":{"Line":66}},{"line":480,"address":[],"length":0,"stats":{"Line":55}},{"line":485,"address":[],"length":0,"stats":{"Line":110}},{"line":486,"address":[],"length":0,"stats":{"Line":10}},{"line":487,"address":[],"length":0,"stats":{"Line":159}},{"line":491,"address":[],"length":0,"stats":{"Line":53}},{"line":492,"address":[],"length":0,"stats":{"Line":106}},{"line":493,"address":[],"length":0,"stats":{"Line":53}},{"line":494,"address":[],"length":0,"stats":{"Line":53}},{"line":496,"address":[],"length":0,"stats":{"Line":175}},{"line":498,"address":[],"length":0,"stats":{"Line":53}},{"line":499,"address":[],"length":0,"stats":{"Line":106}},{"line":500,"address":[],"length":0,"stats":{"Line":0}},{"line":504,"address":[],"length":0,"stats":{"Line":33}},{"line":509,"address":[],"length":0,"stats":{"Line":66}},{"line":511,"address":[],"length":0,"stats":{"Line":66}},{"line":512,"address":[],"length":0,"stats":{"Line":3}},{"line":515,"address":[],"length":0,"stats":{"Line":180}},{"line":517,"address":[],"length":0,"stats":{"Line":30}},{"line":518,"address":[],"length":0,"stats":{"Line":0}},{"line":519,"address":[],"length":0,"stats":{"Line":0}},{"line":520,"address":[],"length":0,"stats":{"Line":0}},{"line":522,"address":[],"length":0,"stats":{"Line":0}},{"line":525,"address":[],"length":0,"stats":{"Line":246}},{"line":526,"address":[],"length":0,"stats":{"Line":162}},{"line":527,"address":[],"length":0,"stats":{"Line":162}},{"line":528,"address":[],"length":0,"stats":{"Line":270}},{"line":531,"address":[],"length":0,"stats":{"Line":30}},{"line":534,"address":[],"length":0,"stats":{"Line":33}},{"line":539,"address":[],"length":0,"stats":{"Line":66}},{"line":541,"address":[],"length":0,"stats":{"Line":195}},{"line":542,"address":[],"length":0,"stats":{"Line":324}},{"line":544,"address":[],"length":0,"stats":{"Line":324}},{"line":545,"address":[],"length":0,"stats":{"Line":108}},{"line":549,"address":[],"length":0,"stats":{"Line":91}},{"line":550,"address":[],"length":0,"stats":{"Line":150}},{"line":551,"address":[],"length":0,"stats":{"Line":25}},{"line":552,"address":[],"length":0,"stats":{"Line":7}},{"line":554,"address":[],"length":0,"stats":{"Line":18}},{"line":555,"address":[],"length":0,"stats":{"Line":36}},{"line":556,"address":[],"length":0,"stats":{"Line":36}},{"line":559,"address":[],"length":0,"stats":{"Line":33}},{"line":562,"address":[],"length":0,"stats":{"Line":50}},{"line":563,"address":[],"length":0,"stats":{"Line":50}},{"line":564,"address":[],"length":0,"stats":{"Line":50}},{"line":566,"address":[],"length":0,"stats":{"Line":174}},{"line":567,"address":[],"length":0,"stats":{"Line":50}},{"line":570,"address":[],"length":0,"stats":{"Line":54}},{"line":576,"address":[],"length":0,"stats":{"Line":108}},{"line":577,"address":[],"length":0,"stats":{"Line":108}},{"line":578,"address":[],"length":0,"stats":{"Line":54}},{"line":579,"address":[],"length":0,"stats":{"Line":54}},{"line":582,"address":[],"length":0,"stats":{"Line":273}},{"line":583,"address":[],"length":0,"stats":{"Line":346}},{"line":584,"address":[],"length":0,"stats":{"Line":74}},{"line":585,"address":[],"length":0,"stats":{"Line":265}},{"line":586,"address":[],"length":0,"stats":{"Line":53}},{"line":587,"address":[],"length":0,"stats":{"Line":159}},{"line":588,"address":[],"length":0,"stats":{"Line":106}},{"line":589,"address":[],"length":0,"stats":{"Line":159}},{"line":590,"address":[],"length":0,"stats":{"Line":106}},{"line":591,"address":[],"length":0,"stats":{"Line":106}},{"line":592,"address":[],"length":0,"stats":{"Line":106}},{"line":593,"address":[],"length":0,"stats":{"Line":106}},{"line":594,"address":[],"length":0,"stats":{"Line":53}},{"line":600,"address":[],"length":0,"stats":{"Line":7}},{"line":601,"address":[],"length":0,"stats":{"Line":6}},{"line":602,"address":[],"length":0,"stats":{"Line":0}},{"line":603,"address":[],"length":0,"stats":{"Line":0}},{"line":604,"address":[],"length":0,"stats":{"Line":0}},{"line":605,"address":[],"length":0,"stats":{"Line":0}},{"line":606,"address":[],"length":0,"stats":{"Line":0}},{"line":607,"address":[],"length":0,"stats":{"Line":0}},{"line":608,"address":[],"length":0,"stats":{"Line":0}},{"line":609,"address":[],"length":0,"stats":{"Line":0}},{"line":610,"address":[],"length":0,"stats":{"Line":0}},{"line":611,"address":[],"length":0,"stats":{"Line":0}},{"line":616,"address":[],"length":0,"stats":{"Line":3}},{"line":617,"address":[],"length":0,"stats":{"Line":2}},{"line":618,"address":[],"length":0,"stats":{"Line":1}},{"line":619,"address":[],"length":0,"stats":{"Line":2}},{"line":620,"address":[],"length":0,"stats":{"Line":2}},{"line":621,"address":[],"length":0,"stats":{"Line":1}},{"line":622,"address":[],"length":0,"stats":{"Line":1}},{"line":623,"address":[],"length":0,"stats":{"Line":2}},{"line":624,"address":[],"length":0,"stats":{"Line":1}},{"line":628,"address":[],"length":0,"stats":{"Line":53}},{"line":629,"address":[],"length":0,"stats":{"Line":61}},{"line":630,"address":[],"length":0,"stats":{"Line":45}},{"line":633,"address":[],"length":0,"stats":{"Line":24}},{"line":635,"address":[],"length":0,"stats":{"Line":8}},{"line":636,"address":[],"length":0,"stats":{"Line":5}},{"line":637,"address":[],"length":0,"stats":{"Line":3}},{"line":638,"address":[],"length":0,"stats":{"Line":0}},{"line":639,"address":[],"length":0,"stats":{"Line":0}},{"line":641,"address":[],"length":0,"stats":{"Line":0}},{"line":644,"address":[],"length":0,"stats":{"Line":3}},{"line":649,"address":[],"length":0,"stats":{"Line":7}},{"line":650,"address":[],"length":0,"stats":{"Line":33}},{"line":651,"address":[],"length":0,"stats":{"Line":2}},{"line":654,"address":[],"length":0,"stats":{"Line":73}},{"line":655,"address":[],"length":0,"stats":{"Line":63}},{"line":656,"address":[],"length":0,"stats":{"Line":63}},{"line":658,"address":[],"length":0,"stats":{"Line":10}},{"line":659,"address":[],"length":0,"stats":{"Line":0}},{"line":662,"address":[],"length":0,"stats":{"Line":10}},{"line":666,"address":[],"length":0,"stats":{"Line":43}},{"line":667,"address":[],"length":0,"stats":{"Line":86}},{"line":668,"address":[],"length":0,"stats":{"Line":86}},{"line":669,"address":[],"length":0,"stats":{"Line":43}},{"line":670,"address":[],"length":0,"stats":{"Line":43}},{"line":671,"address":[],"length":0,"stats":{"Line":86}},{"line":672,"address":[],"length":0,"stats":{"Line":129}},{"line":673,"address":[],"length":0,"stats":{"Line":43}},{"line":674,"address":[],"length":0,"stats":{"Line":43}},{"line":675,"address":[],"length":0,"stats":{"Line":129}},{"line":676,"address":[],"length":0,"stats":{"Line":43}},{"line":677,"address":[],"length":0,"stats":{"Line":43}},{"line":678,"address":[],"length":0,"stats":{"Line":43}},{"line":681,"address":[],"length":0,"stats":{"Line":86}},{"line":682,"address":[],"length":0,"stats":{"Line":43}},{"line":683,"address":[],"length":0,"stats":{"Line":43}},{"line":684,"address":[],"length":0,"stats":{"Line":86}},{"line":685,"address":[],"length":0,"stats":{"Line":129}},{"line":686,"address":[],"length":0,"stats":{"Line":43}},{"line":687,"address":[],"length":0,"stats":{"Line":43}},{"line":688,"address":[],"length":0,"stats":{"Line":129}},{"line":689,"address":[],"length":0,"stats":{"Line":43}},{"line":690,"address":[],"length":0,"stats":{"Line":43}},{"line":691,"address":[],"length":0,"stats":{"Line":43}},{"line":696,"address":[],"length":0,"stats":{"Line":129}}],"covered":233,"coverable":285},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","context_architect","budget.rs"],"content":"use std::collections::HashMap;\nuse std::sync::RwLock;\nuse std::sync::atomic::{AtomicU64, Ordering};\nuse std::time::{SystemTime, UNIX_EPOCH};\n\nuse mk_core::types::MemoryLayer;\nuse tracing::{info_span, warn};\n\n#[derive(Debug, Clone)]\npub struct SummarizationBudget {\n    pub daily_token_limit: u64,\n    pub hourly_token_limit: u64,\n    pub per_layer_limits: HashMap<MemoryLayer, u64>,\n    pub warning_threshold_percent: u8,\n    pub critical_threshold_percent: u8,\n}\n\nimpl Default for SummarizationBudget {\n    fn default() -> Self {\n        let mut per_layer_limits = HashMap::new();\n        per_layer_limits.insert(MemoryLayer::Agent, 10_000);\n        per_layer_limits.insert(MemoryLayer::User, 20_000);\n        per_layer_limits.insert(MemoryLayer::Session, 50_000);\n        per_layer_limits.insert(MemoryLayer::Project, 100_000);\n        per_layer_limits.insert(MemoryLayer::Team, 200_000);\n        per_layer_limits.insert(MemoryLayer::Org, 500_000);\n        per_layer_limits.insert(MemoryLayer::Company, 1_000_000);\n\n        Self {\n            daily_token_limit: 1_000_000,\n            hourly_token_limit: 100_000,\n            per_layer_limits,\n            warning_threshold_percent: 80,\n            critical_threshold_percent: 90,\n        }\n    }\n}\n\nimpl SummarizationBudget {\n    pub fn with_daily_limit(mut self, limit: u64) -> Self {\n        self.daily_token_limit = limit;\n        self\n    }\n\n    pub fn with_hourly_limit(mut self, limit: u64) -> Self {\n        self.hourly_token_limit = limit;\n        self\n    }\n\n    pub fn with_layer_limit(mut self, layer: MemoryLayer, limit: u64) -> Self {\n        self.per_layer_limits.insert(layer, limit);\n        self\n    }\n\n    pub fn with_warning_threshold(mut self, percent: u8) -> Self {\n        self.warning_threshold_percent = percent.min(100);\n        self\n    }\n\n    pub fn with_critical_threshold(mut self, percent: u8) -> Self {\n        self.critical_threshold_percent = percent.min(100);\n        self\n    }\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum BudgetStatus {\n    Available,\n    Warning,\n    Critical,\n    Exhausted,\n}\n\n#[derive(Debug, Clone)]\npub struct BudgetCheck {\n    pub status: BudgetStatus,\n    pub daily_used: u64,\n    pub daily_remaining: u64,\n    pub hourly_used: u64,\n    pub hourly_remaining: u64,\n    pub layer_used: Option<u64>,\n    pub layer_remaining: Option<u64>,\n    pub percent_used: f32,\n}\n\nimpl BudgetCheck {\n    pub fn can_proceed(&self) -> bool {\n        self.status != BudgetStatus::Exhausted\n    }\n\n    pub fn tokens_available(&self) -> u64 {\n        self.daily_remaining\n            .min(self.hourly_remaining)\n            .min(self.layer_remaining.unwrap_or(u64::MAX))\n    }\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum BudgetExhaustedAction {\n    Reject,\n    Queue,\n    AllowWithWarning,\n}\n\n#[derive(Debug, Clone)]\npub struct BudgetTrackerConfig {\n    pub budget: SummarizationBudget,\n    pub exhausted_action: BudgetExhaustedAction,\n    pub enable_alerts: bool,\n    pub queue_max_size: usize,\n}\n\nimpl Default for BudgetTrackerConfig {\n    fn default() -> Self {\n        Self {\n            budget: SummarizationBudget::default(),\n            exhausted_action: BudgetExhaustedAction::Reject,\n            enable_alerts: true,\n            queue_max_size: 100,\n        }\n    }\n}\n\nconst DAILY_WINDOW_SECS: u64 = 86400;\nconst HOURLY_WINDOW_SECS: u64 = 3600;\nconst ALERT_COOLDOWN_SECS: u64 = 300;\nconst EXHAUSTED_ALERT_COOLDOWN_SECS: u64 = 60;\n\nstruct UsageWindow {\n    tokens_used: AtomicU64,\n    window_start: AtomicU64,\n}\n\nimpl UsageWindow {\n    fn new() -> Self {\n        Self {\n            tokens_used: AtomicU64::new(0),\n            window_start: AtomicU64::new(current_timestamp()),\n        }\n    }\n\n    fn record(&self, tokens: u64, window_duration_secs: u64) {\n        let now = current_timestamp();\n        let window_start = self.window_start.load(Ordering::Relaxed);\n\n        if now - window_start >= window_duration_secs {\n            self.tokens_used.store(tokens, Ordering::Relaxed);\n            self.window_start.store(now, Ordering::Relaxed);\n        } else {\n            self.tokens_used.fetch_add(tokens, Ordering::Relaxed);\n        }\n    }\n\n    fn used(&self, window_duration_secs: u64) -> u64 {\n        let now = current_timestamp();\n        let window_start = self.window_start.load(Ordering::Relaxed);\n\n        if now - window_start >= window_duration_secs {\n            0\n        } else {\n            self.tokens_used.load(Ordering::Relaxed)\n        }\n    }\n\n    fn reset_if_expired(&self, window_duration_secs: u64) -> bool {\n        let now = current_timestamp();\n        let window_start = self.window_start.load(Ordering::Relaxed);\n\n        if now - window_start >= window_duration_secs {\n            self.tokens_used.store(0, Ordering::Relaxed);\n            self.window_start.store(now, Ordering::Relaxed);\n            true\n        } else {\n            false\n        }\n    }\n}\n\nstruct LayerUsage {\n    usage: RwLock<HashMap<MemoryLayer, UsageWindow>>,\n}\n\nimpl LayerUsage {\n    fn new() -> Self {\n        Self {\n            usage: RwLock::new(HashMap::new()),\n        }\n    }\n\n    fn record(&self, layer: MemoryLayer, tokens: u64) {\n        {\n            let usage = self.usage.read().unwrap();\n            if let Some(window) = usage.get(&layer) {\n                window.record(tokens, DAILY_WINDOW_SECS);\n                return;\n            }\n        }\n\n        let mut usage = self.usage.write().unwrap();\n        let window = usage.entry(layer).or_insert_with(UsageWindow::new);\n        window.record(tokens, DAILY_WINDOW_SECS);\n    }\n\n    fn used(&self, layer: MemoryLayer) -> u64 {\n        let usage = self.usage.read().unwrap();\n        usage\n            .get(&layer)\n            .map(|w| w.used(DAILY_WINDOW_SECS))\n            .unwrap_or(0)\n    }\n}\n\npub struct BudgetTracker {\n    config: BudgetTrackerConfig,\n    daily_usage: UsageWindow,\n    hourly_usage: UsageWindow,\n    layer_usage: LayerUsage,\n    alert_triggered_warning: AtomicU64,\n    alert_triggered_critical: AtomicU64,\n    alert_triggered_exhausted: AtomicU64,\n    queued_requests: RwLock<Vec<QueuedRequest>>,\n}\n\n#[derive(Debug, Clone)]\npub struct QueuedRequest {\n    pub layer: MemoryLayer,\n    pub estimated_tokens: u64,\n    pub queued_at: u64,\n    pub request_id: String,\n}\n\n#[derive(Debug, Clone, thiserror::Error)]\npub enum BudgetError {\n    #[error(\"Budget exhausted: {reason}\")]\n    Exhausted { reason: String },\n\n    #[error(\"Queue full: max size {max_size} reached\")]\n    QueueFull { max_size: usize },\n\n    #[error(\"Request too large: {requested} tokens exceeds available {available}\")]\n    RequestTooLarge { requested: u64, available: u64 },\n}\n\nimpl BudgetTracker {\n    pub fn new(config: BudgetTrackerConfig) -> Self {\n        Self {\n            config,\n            daily_usage: UsageWindow::new(),\n            hourly_usage: UsageWindow::new(),\n            layer_usage: LayerUsage::new(),\n            alert_triggered_warning: AtomicU64::new(0),\n            alert_triggered_critical: AtomicU64::new(0),\n            alert_triggered_exhausted: AtomicU64::new(0),\n            queued_requests: RwLock::new(Vec::new()),\n        }\n    }\n\n    pub fn check(&self, layer: Option<MemoryLayer>) -> BudgetCheck {\n        self.daily_usage.reset_if_expired(DAILY_WINDOW_SECS);\n        self.hourly_usage.reset_if_expired(HOURLY_WINDOW_SECS);\n\n        let daily_used = self.daily_usage.used(DAILY_WINDOW_SECS);\n        let hourly_used = self.hourly_usage.used(HOURLY_WINDOW_SECS);\n        let daily_limit = self.config.budget.daily_token_limit;\n        let hourly_limit = self.config.budget.hourly_token_limit;\n\n        let daily_remaining = daily_limit.saturating_sub(daily_used);\n        let hourly_remaining = hourly_limit.saturating_sub(hourly_used);\n\n        let (layer_used, layer_remaining) = if let Some(l) = layer {\n            let used = self.layer_usage.used(l);\n            let limit = self\n                .config\n                .budget\n                .per_layer_limits\n                .get(&l)\n                .copied()\n                .unwrap_or(u64::MAX);\n            (Some(used), Some(limit.saturating_sub(used)))\n        } else {\n            (None, None)\n        };\n\n        let percent_used = (daily_used as f32 / daily_limit as f32) * 100.0;\n\n        let status = if daily_remaining == 0 || hourly_remaining == 0 || layer_remaining == Some(0)\n        {\n            BudgetStatus::Exhausted\n        } else if percent_used >= self.config.budget.critical_threshold_percent as f32 {\n            BudgetStatus::Critical\n        } else if percent_used >= self.config.budget.warning_threshold_percent as f32 {\n            BudgetStatus::Warning\n        } else {\n            BudgetStatus::Available\n        };\n\n        BudgetCheck {\n            status,\n            daily_used,\n            daily_remaining,\n            hourly_used,\n            hourly_remaining,\n            layer_used,\n            layer_remaining,\n            percent_used,\n        }\n    }\n\n    pub fn try_consume(&self, tokens: u64, layer: MemoryLayer) -> Result<BudgetCheck, BudgetError> {\n        let span = info_span!(\n            \"budget.try_consume\",\n            tokens = tokens,\n            layer = ?layer\n        );\n        let _enter = span.enter();\n\n        let check = self.check(Some(layer));\n\n        if check.tokens_available() < tokens {\n            match self.config.exhausted_action {\n                BudgetExhaustedAction::Reject => {\n                    self.trigger_exhausted_alert();\n                    return Err(BudgetError::RequestTooLarge {\n                        requested: tokens,\n                        available: check.tokens_available(),\n                    });\n                }\n                BudgetExhaustedAction::Queue => {\n                    return self.queue_request(layer, tokens);\n                }\n                BudgetExhaustedAction::AllowWithWarning => {\n                    warn!(\n                        tokens = tokens,\n                        available = check.tokens_available(),\n                        \"Allowing request despite budget constraints\"\n                    );\n                }\n            }\n        }\n\n        self.record_usage(tokens, layer);\n\n        let new_check = self.check(Some(layer));\n        self.check_and_trigger_alerts(&new_check);\n\n        Ok(new_check)\n    }\n\n    pub fn record_usage(&self, tokens: u64, layer: MemoryLayer) {\n        self.daily_usage.record(tokens, DAILY_WINDOW_SECS);\n        self.hourly_usage.record(tokens, HOURLY_WINDOW_SECS);\n        self.layer_usage.record(layer, tokens);\n    }\n\n    fn queue_request(&self, layer: MemoryLayer, tokens: u64) -> Result<BudgetCheck, BudgetError> {\n        let mut queue = self.queued_requests.write().unwrap();\n\n        if queue.len() >= self.config.queue_max_size {\n            return Err(BudgetError::QueueFull {\n                max_size: self.config.queue_max_size,\n            });\n        }\n\n        let request = QueuedRequest {\n            layer,\n            estimated_tokens: tokens,\n            queued_at: current_timestamp(),\n            request_id: format!(\"{}-{}\", layer.display_name(), queue.len()),\n        };\n\n        queue.push(request);\n        drop(queue);\n\n        self.trigger_exhausted_alert();\n\n        Err(BudgetError::Exhausted {\n            reason: \"Request queued due to budget exhaustion\".to_string(),\n        })\n    }\n\n    pub fn drain_queue(&self, max_tokens: u64) -> Vec<QueuedRequest> {\n        let mut queue = self.queued_requests.write().unwrap();\n        let mut drained = Vec::new();\n        let mut remaining_tokens = max_tokens;\n\n        queue.retain(|req| {\n            if req.estimated_tokens <= remaining_tokens {\n                remaining_tokens -= req.estimated_tokens;\n                drained.push(req.clone());\n                false\n            } else {\n                true\n            }\n        });\n\n        drained\n    }\n\n    pub fn queued_count(&self) -> usize {\n        self.queued_requests.read().unwrap().len()\n    }\n\n    fn check_and_trigger_alerts(&self, check: &BudgetCheck) {\n        if !self.config.enable_alerts {\n            return;\n        }\n\n        let now = current_timestamp();\n\n        match check.status {\n            BudgetStatus::Warning => {\n                let last = self.alert_triggered_warning.load(Ordering::Relaxed);\n                if now - last >= ALERT_COOLDOWN_SECS {\n                    self.alert_triggered_warning.store(now, Ordering::Relaxed);\n                    warn!(\n                        percent_used = check.percent_used,\n                        daily_remaining = check.daily_remaining,\n                        \"Summarization budget at warning threshold ({}%)\",\n                        self.config.budget.warning_threshold_percent\n                    );\n                }\n            }\n            BudgetStatus::Critical => {\n                let last = self.alert_triggered_critical.load(Ordering::Relaxed);\n                if now - last >= ALERT_COOLDOWN_SECS {\n                    self.alert_triggered_critical.store(now, Ordering::Relaxed);\n                    warn!(\n                        percent_used = check.percent_used,\n                        daily_remaining = check.daily_remaining,\n                        \"Summarization budget at CRITICAL threshold ({}%)\",\n                        self.config.budget.critical_threshold_percent\n                    );\n                }\n            }\n            BudgetStatus::Exhausted => {\n                self.trigger_exhausted_alert();\n            }\n            BudgetStatus::Available => {}\n        }\n    }\n\n    fn trigger_exhausted_alert(&self) {\n        if !self.config.enable_alerts {\n            return;\n        }\n\n        let now = current_timestamp();\n        let last = self.alert_triggered_exhausted.load(Ordering::Relaxed);\n\n        if now - last >= EXHAUSTED_ALERT_COOLDOWN_SECS {\n            self.alert_triggered_exhausted.store(now, Ordering::Relaxed);\n            warn!(\"Summarization budget EXHAUSTED - requests being rejected or queued\");\n        }\n    }\n\n    pub fn get_metrics(&self) -> BudgetMetrics {\n        let check = self.check(None);\n        let queue_size = self.queued_count();\n\n        BudgetMetrics {\n            daily_tokens_used: check.daily_used,\n            daily_tokens_remaining: check.daily_remaining,\n            hourly_tokens_used: check.hourly_used,\n            hourly_tokens_remaining: check.hourly_remaining,\n            percent_used: check.percent_used,\n            status: check.status,\n            queued_requests: queue_size,\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct BudgetMetrics {\n    pub daily_tokens_used: u64,\n    pub daily_tokens_remaining: u64,\n    pub hourly_tokens_used: u64,\n    pub hourly_tokens_remaining: u64,\n    pub percent_used: f32,\n    pub status: BudgetStatus,\n    pub queued_requests: usize,\n}\n\n#[derive(Debug, Clone)]\npub struct TieredModelConfig {\n    pub expensive_model: String,\n    pub cheap_model: String,\n    pub expensive_layers: Vec<MemoryLayer>,\n    pub cheap_layers: Vec<MemoryLayer>,\n}\n\nimpl Default for TieredModelConfig {\n    fn default() -> Self {\n        Self {\n            expensive_model: \"gpt-4\".to_string(),\n            cheap_model: \"gpt-3.5-turbo\".to_string(),\n            expensive_layers: vec![MemoryLayer::User, MemoryLayer::Session, MemoryLayer::Agent],\n            cheap_layers: vec![\n                MemoryLayer::Company,\n                MemoryLayer::Org,\n                MemoryLayer::Team,\n                MemoryLayer::Project,\n            ],\n        }\n    }\n}\n\nimpl TieredModelConfig {\n    pub fn model_for_layer(&self, layer: MemoryLayer) -> &str {\n        if self.expensive_layers.contains(&layer) {\n            &self.expensive_model\n        } else {\n            &self.cheap_model\n        }\n    }\n\n    pub fn with_expensive_model(mut self, model: String) -> Self {\n        self.expensive_model = model;\n        self\n    }\n\n    pub fn with_cheap_model(mut self, model: String) -> Self {\n        self.cheap_model = model;\n        self\n    }\n}\n\nfn current_timestamp() -> u64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs())\n        .unwrap_or(0)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_summarization_budget_defaults() {\n        let budget = SummarizationBudget::default();\n\n        assert_eq!(budget.daily_token_limit, 1_000_000);\n        assert_eq!(budget.hourly_token_limit, 100_000);\n        assert_eq!(budget.warning_threshold_percent, 80);\n        assert_eq!(budget.critical_threshold_percent, 90);\n        assert!(budget.per_layer_limits.contains_key(&MemoryLayer::Session));\n    }\n\n    #[test]\n    fn test_summarization_budget_builder() {\n        let budget = SummarizationBudget::default()\n            .with_daily_limit(500_000)\n            .with_hourly_limit(50_000)\n            .with_layer_limit(MemoryLayer::Project, 75_000)\n            .with_warning_threshold(70)\n            .with_critical_threshold(85);\n\n        assert_eq!(budget.daily_token_limit, 500_000);\n        assert_eq!(budget.hourly_token_limit, 50_000);\n        assert_eq!(\n            budget.per_layer_limits.get(&MemoryLayer::Project),\n            Some(&75_000)\n        );\n        assert_eq!(budget.warning_threshold_percent, 70);\n        assert_eq!(budget.critical_threshold_percent, 85);\n    }\n\n    #[test]\n    fn test_budget_tracker_initial_state() {\n        let tracker = BudgetTracker::new(BudgetTrackerConfig::default());\n        let check = tracker.check(None);\n\n        assert_eq!(check.status, BudgetStatus::Available);\n        assert_eq!(check.daily_used, 0);\n        assert_eq!(check.hourly_used, 0);\n        assert!(check.can_proceed());\n    }\n\n    #[test]\n    fn test_budget_tracker_record_usage() {\n        let tracker = BudgetTracker::new(BudgetTrackerConfig::default());\n\n        tracker.record_usage(1000, MemoryLayer::Session);\n        let check = tracker.check(Some(MemoryLayer::Session));\n\n        assert_eq!(check.daily_used, 1000);\n        assert_eq!(check.hourly_used, 1000);\n        assert_eq!(check.layer_used, Some(1000));\n    }\n\n    #[test]\n    fn test_budget_tracker_try_consume_success() {\n        let tracker = BudgetTracker::new(BudgetTrackerConfig::default());\n\n        let result = tracker.try_consume(500, MemoryLayer::Session);\n        assert!(result.is_ok());\n\n        let check = result.unwrap();\n        assert_eq!(check.daily_used, 500);\n    }\n\n    #[test]\n    fn test_budget_tracker_exhaustion_reject() {\n        let config = BudgetTrackerConfig {\n            budget: SummarizationBudget::default()\n                .with_daily_limit(1000)\n                .with_hourly_limit(1000),\n            exhausted_action: BudgetExhaustedAction::Reject,\n            enable_alerts: false,\n            ..Default::default()\n        };\n        let tracker = BudgetTracker::new(config);\n\n        tracker.record_usage(900, MemoryLayer::Session);\n\n        let result = tracker.try_consume(200, MemoryLayer::Session);\n        assert!(result.is_err());\n\n        match result {\n            Err(BudgetError::RequestTooLarge {\n                requested,\n                available,\n            }) => {\n                assert_eq!(requested, 200);\n                assert_eq!(available, 100);\n            }\n            _ => panic!(\"Expected RequestTooLarge error\"),\n        }\n    }\n\n    #[test]\n    fn test_budget_tracker_exhaustion_queue() {\n        let config = BudgetTrackerConfig {\n            budget: SummarizationBudget::default()\n                .with_daily_limit(1000)\n                .with_hourly_limit(1000),\n            exhausted_action: BudgetExhaustedAction::Queue,\n            enable_alerts: false,\n            queue_max_size: 10,\n        };\n        let tracker = BudgetTracker::new(config);\n\n        tracker.record_usage(900, MemoryLayer::Session);\n\n        let result = tracker.try_consume(200, MemoryLayer::Session);\n        assert!(result.is_err());\n        assert_eq!(tracker.queued_count(), 1);\n    }\n\n    #[test]\n    fn test_budget_tracker_queue_full() {\n        let config = BudgetTrackerConfig {\n            budget: SummarizationBudget::default()\n                .with_daily_limit(100)\n                .with_hourly_limit(100),\n            exhausted_action: BudgetExhaustedAction::Queue,\n            enable_alerts: false,\n            queue_max_size: 2,\n        };\n        let tracker = BudgetTracker::new(config);\n\n        tracker.record_usage(100, MemoryLayer::Session);\n\n        let _ = tracker.try_consume(50, MemoryLayer::Session);\n        let _ = tracker.try_consume(50, MemoryLayer::Session);\n        let result = tracker.try_consume(50, MemoryLayer::Session);\n\n        assert!(matches!(\n            result,\n            Err(BudgetError::QueueFull { max_size: 2 })\n        ));\n    }\n\n    #[test]\n    fn test_budget_tracker_drain_queue() {\n        let config = BudgetTrackerConfig {\n            budget: SummarizationBudget::default()\n                .with_daily_limit(100)\n                .with_hourly_limit(100),\n            exhausted_action: BudgetExhaustedAction::Queue,\n            enable_alerts: false,\n            queue_max_size: 10,\n        };\n        let tracker = BudgetTracker::new(config);\n\n        tracker.record_usage(100, MemoryLayer::Session);\n\n        let _ = tracker.try_consume(30, MemoryLayer::Session);\n        let _ = tracker.try_consume(40, MemoryLayer::Session);\n        let _ = tracker.try_consume(50, MemoryLayer::Session);\n\n        assert_eq!(tracker.queued_count(), 3);\n\n        let drained = tracker.drain_queue(70);\n        assert_eq!(drained.len(), 2);\n        assert_eq!(tracker.queued_count(), 1);\n    }\n\n    #[test]\n    fn test_budget_status_warning() {\n        let config = BudgetTrackerConfig {\n            budget: SummarizationBudget::default()\n                .with_daily_limit(1000)\n                .with_warning_threshold(50),\n            enable_alerts: false,\n            ..Default::default()\n        };\n        let tracker = BudgetTracker::new(config);\n\n        tracker.record_usage(600, MemoryLayer::Session);\n        let check = tracker.check(None);\n\n        assert_eq!(check.status, BudgetStatus::Warning);\n    }\n\n    #[test]\n    fn test_budget_status_critical() {\n        let config = BudgetTrackerConfig {\n            budget: SummarizationBudget::default()\n                .with_daily_limit(1000)\n                .with_warning_threshold(50)\n                .with_critical_threshold(80),\n            enable_alerts: false,\n            ..Default::default()\n        };\n        let tracker = BudgetTracker::new(config);\n\n        tracker.record_usage(850, MemoryLayer::Session);\n        let check = tracker.check(None);\n\n        assert_eq!(check.status, BudgetStatus::Critical);\n    }\n\n    #[test]\n    fn test_budget_check_tokens_available() {\n        let config = BudgetTrackerConfig {\n            budget: SummarizationBudget::default()\n                .with_daily_limit(1000)\n                .with_hourly_limit(500)\n                .with_layer_limit(MemoryLayer::Session, 200),\n            ..Default::default()\n        };\n        let tracker = BudgetTracker::new(config);\n\n        tracker.record_usage(100, MemoryLayer::Session);\n        let check = tracker.check(Some(MemoryLayer::Session));\n\n        assert_eq!(check.tokens_available(), 100);\n    }\n\n    #[test]\n    fn test_budget_metrics() {\n        let tracker = BudgetTracker::new(BudgetTrackerConfig::default());\n        tracker.record_usage(50_000, MemoryLayer::Session);\n\n        let metrics = tracker.get_metrics();\n\n        assert_eq!(metrics.daily_tokens_used, 50_000);\n        assert_eq!(metrics.hourly_tokens_used, 50_000);\n        assert!(metrics.percent_used > 0.0);\n        assert_eq!(metrics.status, BudgetStatus::Available);\n    }\n\n    #[test]\n    fn test_tiered_model_config_defaults() {\n        let config = TieredModelConfig::default();\n\n        assert_eq!(config.expensive_model, \"gpt-4\");\n        assert_eq!(config.cheap_model, \"gpt-3.5-turbo\");\n        assert!(config.expensive_layers.contains(&MemoryLayer::User));\n        assert!(config.cheap_layers.contains(&MemoryLayer::Company));\n    }\n\n    #[test]\n    fn test_tiered_model_selection() {\n        let config = TieredModelConfig::default();\n\n        assert_eq!(config.model_for_layer(MemoryLayer::User), \"gpt-4\");\n        assert_eq!(config.model_for_layer(MemoryLayer::Session), \"gpt-4\");\n        assert_eq!(\n            config.model_for_layer(MemoryLayer::Company),\n            \"gpt-3.5-turbo\"\n        );\n        assert_eq!(\n            config.model_for_layer(MemoryLayer::Project),\n            \"gpt-3.5-turbo\"\n        );\n    }\n\n    #[test]\n    fn test_tiered_model_config_builder() {\n        let config = TieredModelConfig::default()\n            .with_expensive_model(\"claude-3-opus\".to_string())\n            .with_cheap_model(\"claude-3-haiku\".to_string());\n\n        assert_eq!(config.expensive_model, \"claude-3-opus\");\n        assert_eq!(config.cheap_model, \"claude-3-haiku\");\n    }\n\n    #[test]\n    fn test_multiple_layer_usage() {\n        let tracker = BudgetTracker::new(BudgetTrackerConfig::default());\n\n        tracker.record_usage(100, MemoryLayer::Session);\n        tracker.record_usage(200, MemoryLayer::Project);\n        tracker.record_usage(300, MemoryLayer::Team);\n\n        let check = tracker.check(None);\n        assert_eq!(check.daily_used, 600);\n\n        let session_check = tracker.check(Some(MemoryLayer::Session));\n        assert_eq!(session_check.layer_used, Some(100));\n\n        let project_check = tracker.check(Some(MemoryLayer::Project));\n        assert_eq!(project_check.layer_used, Some(200));\n    }\n}\n","traces":[{"line":19,"address":[],"length":0,"stats":{"Line":58}},{"line":20,"address":[],"length":0,"stats":{"Line":116}},{"line":21,"address":[],"length":0,"stats":{"Line":174}},{"line":22,"address":[],"length":0,"stats":{"Line":174}},{"line":23,"address":[],"length":0,"stats":{"Line":174}},{"line":24,"address":[],"length":0,"stats":{"Line":174}},{"line":25,"address":[],"length":0,"stats":{"Line":174}},{"line":26,"address":[],"length":0,"stats":{"Line":174}},{"line":27,"address":[],"length":0,"stats":{"Line":174}},{"line":40,"address":[],"length":0,"stats":{"Line":33}},{"line":41,"address":[],"length":0,"stats":{"Line":33}},{"line":42,"address":[],"length":0,"stats":{"Line":33}},{"line":45,"address":[],"length":0,"stats":{"Line":29}},{"line":46,"address":[],"length":0,"stats":{"Line":29}},{"line":47,"address":[],"length":0,"stats":{"Line":29}},{"line":50,"address":[],"length":0,"stats":{"Line":5}},{"line":51,"address":[],"length":0,"stats":{"Line":20}},{"line":52,"address":[],"length":0,"stats":{"Line":5}},{"line":55,"address":[],"length":0,"stats":{"Line":5}},{"line":56,"address":[],"length":0,"stats":{"Line":5}},{"line":57,"address":[],"length":0,"stats":{"Line":5}},{"line":60,"address":[],"length":0,"stats":{"Line":4}},{"line":61,"address":[],"length":0,"stats":{"Line":4}},{"line":62,"address":[],"length":0,"stats":{"Line":4}},{"line":87,"address":[],"length":0,"stats":{"Line":41}},{"line":88,"address":[],"length":0,"stats":{"Line":41}},{"line":91,"address":[],"length":0,"stats":{"Line":54}},{"line":92,"address":[],"length":0,"stats":{"Line":54}},{"line":93,"address":[],"length":0,"stats":{"Line":108}},{"line":94,"address":[],"length":0,"stats":{"Line":162}},{"line":114,"address":[],"length":0,"stats":{"Line":23}},{"line":116,"address":[],"length":0,"stats":{"Line":23}},{"line":135,"address":[],"length":0,"stats":{"Line":129}},{"line":137,"address":[],"length":0,"stats":{"Line":258}},{"line":138,"address":[],"length":0,"stats":{"Line":129}},{"line":142,"address":[],"length":0,"stats":{"Line":171}},{"line":143,"address":[],"length":0,"stats":{"Line":342}},{"line":144,"address":[],"length":0,"stats":{"Line":684}},{"line":146,"address":[],"length":0,"stats":{"Line":171}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":513}},{"line":154,"address":[],"length":0,"stats":{"Line":346}},{"line":155,"address":[],"length":0,"stats":{"Line":692}},{"line":156,"address":[],"length":0,"stats":{"Line":1384}},{"line":158,"address":[],"length":0,"stats":{"Line":346}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":1038}},{"line":165,"address":[],"length":0,"stats":{"Line":268}},{"line":166,"address":[],"length":0,"stats":{"Line":536}},{"line":167,"address":[],"length":0,"stats":{"Line":1072}},{"line":169,"address":[],"length":0,"stats":{"Line":268}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":268}},{"line":184,"address":[],"length":0,"stats":{"Line":40}},{"line":186,"address":[],"length":0,"stats":{"Line":40}},{"line":190,"address":[],"length":0,"stats":{"Line":57}},{"line":192,"address":[],"length":0,"stats":{"Line":228}},{"line":193,"address":[],"length":0,"stats":{"Line":122}},{"line":194,"address":[],"length":0,"stats":{"Line":24}},{"line":195,"address":[],"length":0,"stats":{"Line":8}},{"line":199,"address":[],"length":0,"stats":{"Line":196}},{"line":200,"address":[],"length":0,"stats":{"Line":196}},{"line":201,"address":[],"length":0,"stats":{"Line":147}},{"line":204,"address":[],"length":0,"stats":{"Line":115}},{"line":205,"address":[],"length":0,"stats":{"Line":460}},{"line":206,"address":[],"length":0,"stats":{"Line":230}},{"line":207,"address":[],"length":0,"stats":{"Line":115}},{"line":208,"address":[],"length":0,"stats":{"Line":271}},{"line":245,"address":[],"length":0,"stats":{"Line":40}},{"line":248,"address":[],"length":0,"stats":{"Line":80}},{"line":249,"address":[],"length":0,"stats":{"Line":80}},{"line":250,"address":[],"length":0,"stats":{"Line":80}},{"line":251,"address":[],"length":0,"stats":{"Line":80}},{"line":252,"address":[],"length":0,"stats":{"Line":80}},{"line":253,"address":[],"length":0,"stats":{"Line":80}},{"line":254,"address":[],"length":0,"stats":{"Line":40}},{"line":258,"address":[],"length":0,"stats":{"Line":134}},{"line":259,"address":[],"length":0,"stats":{"Line":268}},{"line":260,"address":[],"length":0,"stats":{"Line":268}},{"line":262,"address":[],"length":0,"stats":{"Line":402}},{"line":263,"address":[],"length":0,"stats":{"Line":402}},{"line":264,"address":[],"length":0,"stats":{"Line":268}},{"line":265,"address":[],"length":0,"stats":{"Line":268}},{"line":267,"address":[],"length":0,"stats":{"Line":536}},{"line":268,"address":[],"length":0,"stats":{"Line":536}},{"line":270,"address":[],"length":0,"stats":{"Line":517}},{"line":271,"address":[],"length":0,"stats":{"Line":460}},{"line":272,"address":[],"length":0,"stats":{"Line":230}},{"line":273,"address":[],"length":0,"stats":{"Line":115}},{"line":274,"address":[],"length":0,"stats":{"Line":115}},{"line":275,"address":[],"length":0,"stats":{"Line":115}},{"line":276,"address":[],"length":0,"stats":{"Line":230}},{"line":278,"address":[],"length":0,"stats":{"Line":115}},{"line":279,"address":[],"length":0,"stats":{"Line":345}},{"line":281,"address":[],"length":0,"stats":{"Line":19}},{"line":284,"address":[],"length":0,"stats":{"Line":268}},{"line":286,"address":[],"length":0,"stats":{"Line":499}},{"line":288,"address":[],"length":0,"stats":{"Line":20}},{"line":289,"address":[],"length":0,"stats":{"Line":114}},{"line":290,"address":[],"length":0,"stats":{"Line":4}},{"line":291,"address":[],"length":0,"stats":{"Line":110}},{"line":292,"address":[],"length":0,"stats":{"Line":7}},{"line":294,"address":[],"length":0,"stats":{"Line":103}},{"line":309,"address":[],"length":0,"stats":{"Line":44}},{"line":310,"address":[],"length":0,"stats":{"Line":88}},{"line":315,"address":[],"length":0,"stats":{"Line":132}},{"line":317,"address":[],"length":0,"stats":{"Line":176}},{"line":319,"address":[],"length":0,"stats":{"Line":88}},{"line":320,"address":[],"length":0,"stats":{"Line":20}},{"line":322,"address":[],"length":0,"stats":{"Line":12}},{"line":323,"address":[],"length":0,"stats":{"Line":6}},{"line":324,"address":[],"length":0,"stats":{"Line":12}},{"line":325,"address":[],"length":0,"stats":{"Line":6}},{"line":329,"address":[],"length":0,"stats":{"Line":52}},{"line":332,"address":[],"length":0,"stats":{"Line":1}},{"line":334,"address":[],"length":0,"stats":{"Line":0}},{"line":335,"address":[],"length":0,"stats":{"Line":0}},{"line":341,"address":[],"length":0,"stats":{"Line":100}},{"line":343,"address":[],"length":0,"stats":{"Line":100}},{"line":344,"address":[],"length":0,"stats":{"Line":75}},{"line":346,"address":[],"length":0,"stats":{"Line":25}},{"line":349,"address":[],"length":0,"stats":{"Line":57}},{"line":350,"address":[],"length":0,"stats":{"Line":171}},{"line":351,"address":[],"length":0,"stats":{"Line":171}},{"line":352,"address":[],"length":0,"stats":{"Line":228}},{"line":355,"address":[],"length":0,"stats":{"Line":13}},{"line":356,"address":[],"length":0,"stats":{"Line":52}},{"line":358,"address":[],"length":0,"stats":{"Line":13}},{"line":359,"address":[],"length":0,"stats":{"Line":2}},{"line":360,"address":[],"length":0,"stats":{"Line":2}},{"line":367,"address":[],"length":0,"stats":{"Line":22}},{"line":368,"address":[],"length":0,"stats":{"Line":55}},{"line":371,"address":[],"length":0,"stats":{"Line":22}},{"line":372,"address":[],"length":0,"stats":{"Line":22}},{"line":374,"address":[],"length":0,"stats":{"Line":22}},{"line":376,"address":[],"length":0,"stats":{"Line":11}},{"line":377,"address":[],"length":0,"stats":{"Line":11}},{"line":381,"address":[],"length":0,"stats":{"Line":2}},{"line":382,"address":[],"length":0,"stats":{"Line":8}},{"line":383,"address":[],"length":0,"stats":{"Line":4}},{"line":384,"address":[],"length":0,"stats":{"Line":4}},{"line":386,"address":[],"length":0,"stats":{"Line":10}},{"line":387,"address":[],"length":0,"stats":{"Line":6}},{"line":388,"address":[],"length":0,"stats":{"Line":4}},{"line":389,"address":[],"length":0,"stats":{"Line":16}},{"line":390,"address":[],"length":0,"stats":{"Line":4}},{"line":392,"address":[],"length":0,"stats":{"Line":2}},{"line":396,"address":[],"length":0,"stats":{"Line":2}},{"line":399,"address":[],"length":0,"stats":{"Line":8}},{"line":400,"address":[],"length":0,"stats":{"Line":16}},{"line":403,"address":[],"length":0,"stats":{"Line":25}},{"line":404,"address":[],"length":0,"stats":{"Line":25}},{"line":405,"address":[],"length":0,"stats":{"Line":24}},{"line":408,"address":[],"length":0,"stats":{"Line":2}},{"line":410,"address":[],"length":0,"stats":{"Line":1}},{"line":412,"address":[],"length":0,"stats":{"Line":0}},{"line":413,"address":[],"length":0,"stats":{"Line":0}},{"line":414,"address":[],"length":0,"stats":{"Line":0}},{"line":415,"address":[],"length":0,"stats":{"Line":0}},{"line":418,"address":[],"length":0,"stats":{"Line":0}},{"line":424,"address":[],"length":0,"stats":{"Line":0}},{"line":425,"address":[],"length":0,"stats":{"Line":0}},{"line":426,"address":[],"length":0,"stats":{"Line":0}},{"line":427,"address":[],"length":0,"stats":{"Line":0}},{"line":430,"address":[],"length":0,"stats":{"Line":0}},{"line":435,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":1}},{"line":442,"address":[],"length":0,"stats":{"Line":17}},{"line":443,"address":[],"length":0,"stats":{"Line":17}},{"line":444,"address":[],"length":0,"stats":{"Line":17}},{"line":447,"address":[],"length":0,"stats":{"Line":0}},{"line":448,"address":[],"length":0,"stats":{"Line":0}},{"line":450,"address":[],"length":0,"stats":{"Line":0}},{"line":451,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":456,"address":[],"length":0,"stats":{"Line":3}},{"line":457,"address":[],"length":0,"stats":{"Line":12}},{"line":458,"address":[],"length":0,"stats":{"Line":9}},{"line":461,"address":[],"length":0,"stats":{"Line":6}},{"line":462,"address":[],"length":0,"stats":{"Line":6}},{"line":463,"address":[],"length":0,"stats":{"Line":6}},{"line":464,"address":[],"length":0,"stats":{"Line":6}},{"line":465,"address":[],"length":0,"stats":{"Line":6}},{"line":466,"address":[],"length":0,"stats":{"Line":3}},{"line":492,"address":[],"length":0,"stats":{"Line":19}},{"line":494,"address":[],"length":0,"stats":{"Line":57}},{"line":495,"address":[],"length":0,"stats":{"Line":57}},{"line":496,"address":[],"length":0,"stats":{"Line":95}},{"line":497,"address":[],"length":0,"stats":{"Line":38}},{"line":508,"address":[],"length":0,"stats":{"Line":57}},{"line":509,"address":[],"length":0,"stats":{"Line":114}},{"line":510,"address":[],"length":0,"stats":{"Line":31}},{"line":512,"address":[],"length":0,"stats":{"Line":26}},{"line":516,"address":[],"length":0,"stats":{"Line":3}},{"line":517,"address":[],"length":0,"stats":{"Line":6}},{"line":518,"address":[],"length":0,"stats":{"Line":3}},{"line":521,"address":[],"length":0,"stats":{"Line":3}},{"line":522,"address":[],"length":0,"stats":{"Line":6}},{"line":523,"address":[],"length":0,"stats":{"Line":3}},{"line":527,"address":[],"length":0,"stats":{"Line":926}},{"line":528,"address":[],"length":0,"stats":{"Line":926}},{"line":529,"address":[],"length":0,"stats":{"Line":926}},{"line":530,"address":[],"length":0,"stats":{"Line":2778}}],"covered":182,"coverable":207},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","context_architect","compressor.rs"],"content":"use std::collections::HashMap;\n\nuse mk_core::types::{LayerSummary, MemoryLayer, SummaryDepth};\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]\npub enum ViewMode {\n    Ax,\n    Ux,\n    Dx,\n}\n\nimpl ViewMode {\n    pub fn token_budget_multiplier(&self) -> f32 {\n        match self {\n            ViewMode::Ax => 0.3,\n            ViewMode::Ux => 0.6,\n            ViewMode::Dx => 1.0,\n        }\n    }\n\n    pub fn preferred_depths(&self) -> Vec<SummaryDepth> {\n        match self {\n            ViewMode::Ax => vec![SummaryDepth::Sentence],\n            ViewMode::Ux => vec![SummaryDepth::Paragraph, SummaryDepth::Sentence],\n            ViewMode::Dx => vec![\n                SummaryDepth::Detailed,\n                SummaryDepth::Paragraph,\n                SummaryDepth::Sentence,\n            ],\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct CompressorConfig {\n    pub base_token_budget: u32,\n    pub layer_order: Vec<MemoryLayer>,\n    pub enable_inheritance: bool,\n    pub inheritance_compression_ratio: f32,\n    pub min_tokens_per_layer: u32,\n}\n\nimpl Default for CompressorConfig {\n    fn default() -> Self {\n        Self {\n            base_token_budget: 4000,\n            layer_order: vec![\n                MemoryLayer::Company,\n                MemoryLayer::Org,\n                MemoryLayer::Team,\n                MemoryLayer::Project,\n                MemoryLayer::Session,\n            ],\n            enable_inheritance: true,\n            inheritance_compression_ratio: 0.5,\n            min_tokens_per_layer: 50,\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct LayerContent {\n    pub layer: MemoryLayer,\n    pub entries: Vec<LayerEntry>,\n}\n\n#[derive(Debug, Clone)]\npub struct LayerEntry {\n    pub entry_id: String,\n    pub summaries: HashMap<SummaryDepth, LayerSummary>,\n    pub full_content: Option<String>,\n    pub full_content_tokens: Option<u32>,\n}\n\n#[derive(Debug, Clone)]\npub struct CompressedLayer {\n    pub layer: MemoryLayer,\n    pub entries: Vec<CompressedEntry>,\n    pub inherited_context: Option<String>,\n    pub inherited_tokens: u32,\n    pub total_tokens: u32,\n}\n\n#[derive(Debug, Clone)]\npub struct CompressedEntry {\n    pub entry_id: String,\n    pub content: String,\n    pub depth: SummaryDepth,\n    pub token_count: u32,\n    pub is_fallback: bool,\n}\n\n#[derive(Debug, Clone)]\npub struct CompressionResult {\n    pub layers: Vec<CompressedLayer>,\n    pub total_tokens: u32,\n    pub token_budget: u32,\n    pub view_mode: ViewMode,\n}\n\nimpl CompressionResult {\n    pub fn combined_content(&self) -> String {\n        self.layers\n            .iter()\n            .flat_map(|layer| {\n                let mut parts = Vec::new();\n                if let Some(inherited) = &layer.inherited_context {\n                    parts.push(inherited.clone());\n                }\n                parts.extend(layer.entries.iter().map(|e| e.content.clone()));\n                parts\n            })\n            .collect::<Vec<_>>()\n            .join(\"\\n\\n\")\n    }\n\n    pub fn is_within_budget(&self) -> bool {\n        self.total_tokens <= self.token_budget\n    }\n}\n\npub struct HierarchicalCompressor {\n    config: CompressorConfig,\n}\n\nimpl HierarchicalCompressor {\n    pub fn new(config: CompressorConfig) -> Self {\n        Self { config }\n    }\n\n    pub fn compress(\n        &self,\n        layers: &[LayerContent],\n        view_mode: ViewMode,\n        token_budget: Option<u32>,\n    ) -> CompressionResult {\n        let base_budget = token_budget.unwrap_or(self.config.base_token_budget);\n        let adjusted_budget = (base_budget as f32 * view_mode.token_budget_multiplier()) as u32;\n\n        let layer_budgets = self.distribute_budget_to_layers(layers, adjusted_budget);\n        let preferred_depths = view_mode.preferred_depths();\n\n        let mut compressed_layers = Vec::new();\n        let mut inherited_context: Option<String> = None;\n        let mut inherited_tokens: u32 = 0;\n\n        for layer_content in self.order_layers(layers) {\n            let layer_budget = layer_budgets\n                .get(&layer_content.layer)\n                .copied()\n                .unwrap_or(self.config.min_tokens_per_layer);\n\n            let available_budget = if self.config.enable_inheritance && inherited_tokens > 0 {\n                layer_budget.saturating_sub(inherited_tokens)\n            } else {\n                layer_budget\n            };\n\n            let compressed = self.compress_layer(\n                layer_content,\n                available_budget,\n                &preferred_depths,\n                inherited_context.clone(),\n                inherited_tokens,\n            );\n\n            if self.config.enable_inheritance && !compressed.entries.is_empty() {\n                inherited_context =\n                    Some(self.create_inherited_context(&compressed, &preferred_depths));\n                inherited_tokens = self.estimate_tokens(inherited_context.as_deref().unwrap_or(\"\"));\n                inherited_tokens =\n                    (inherited_tokens as f32 * self.config.inheritance_compression_ratio) as u32;\n            }\n\n            compressed_layers.push(compressed);\n        }\n\n        let total_tokens = compressed_layers.iter().map(|l| l.total_tokens).sum();\n\n        CompressionResult {\n            layers: compressed_layers,\n            total_tokens,\n            token_budget: adjusted_budget,\n            view_mode,\n        }\n    }\n\n    fn distribute_budget_to_layers(\n        &self,\n        layers: &[LayerContent],\n        total_budget: u32,\n    ) -> HashMap<MemoryLayer, u32> {\n        let mut budgets = HashMap::new();\n\n        if layers.is_empty() {\n            return budgets;\n        }\n\n        let layer_count = layers.len() as u32;\n        let min_total = self.config.min_tokens_per_layer * layer_count;\n\n        if total_budget <= min_total {\n            for layer in layers {\n                budgets.insert(layer.layer, self.config.min_tokens_per_layer);\n            }\n            return budgets;\n        }\n\n        let weights: Vec<(MemoryLayer, f32)> = layers\n            .iter()\n            .map(|l| {\n                let position = self\n                    .config\n                    .layer_order\n                    .iter()\n                    .position(|&x| x == l.layer)\n                    .unwrap_or(self.config.layer_order.len());\n                let weight = 1.0 + (position as f32 * 0.2);\n                (l.layer, weight)\n            })\n            .collect();\n\n        let total_weight: f32 = weights.iter().map(|(_, w)| w).sum();\n\n        for (layer, weight) in weights {\n            let proportion = weight / total_weight;\n            let tokens =\n                ((total_budget as f32 * proportion) as u32).max(self.config.min_tokens_per_layer);\n            budgets.insert(layer, tokens);\n        }\n\n        budgets\n    }\n\n    fn order_layers<'a>(&self, layers: &'a [LayerContent]) -> Vec<&'a LayerContent> {\n        let mut ordered: Vec<_> = layers.iter().collect();\n        ordered.sort_by_key(|l| {\n            self.config\n                .layer_order\n                .iter()\n                .position(|&x| x == l.layer)\n                .unwrap_or(usize::MAX)\n        });\n        ordered\n    }\n\n    fn compress_layer(\n        &self,\n        layer: &LayerContent,\n        budget: u32,\n        preferred_depths: &[SummaryDepth],\n        inherited_context: Option<String>,\n        inherited_tokens: u32,\n    ) -> CompressedLayer {\n        let mut entries = Vec::new();\n        let mut remaining_budget = budget;\n\n        let entry_budget = if !layer.entries.is_empty() {\n            budget / layer.entries.len() as u32\n        } else {\n            budget\n        };\n\n        for entry in &layer.entries {\n            if remaining_budget < self.config.min_tokens_per_layer {\n                break;\n            }\n\n            let allocation = entry_budget.min(remaining_budget);\n            if let Some(compressed) = self.select_best_content(entry, allocation, preferred_depths)\n            {\n                remaining_budget = remaining_budget.saturating_sub(compressed.token_count);\n                entries.push(compressed);\n            }\n        }\n\n        let entry_tokens: u32 = entries.iter().map(|e| e.token_count).sum();\n        let total_tokens = entry_tokens + inherited_tokens;\n\n        CompressedLayer {\n            layer: layer.layer,\n            entries,\n            inherited_context,\n            inherited_tokens,\n            total_tokens,\n        }\n    }\n\n    fn select_best_content(\n        &self,\n        entry: &LayerEntry,\n        budget: u32,\n        preferred_depths: &[SummaryDepth],\n    ) -> Option<CompressedEntry> {\n        for &depth in preferred_depths {\n            if let Some(summary) = entry.summaries.get(&depth) {\n                if summary.token_count <= budget {\n                    return Some(CompressedEntry {\n                        entry_id: entry.entry_id.clone(),\n                        content: summary.content.clone(),\n                        depth,\n                        token_count: summary.token_count,\n                        is_fallback: false,\n                    });\n                }\n            }\n        }\n\n        let all_depths = [\n            SummaryDepth::Sentence,\n            SummaryDepth::Paragraph,\n            SummaryDepth::Detailed,\n        ];\n        for depth in all_depths {\n            if let Some(summary) = entry.summaries.get(&depth) {\n                if summary.token_count <= budget {\n                    return Some(CompressedEntry {\n                        entry_id: entry.entry_id.clone(),\n                        content: summary.content.clone(),\n                        depth,\n                        token_count: summary.token_count,\n                        is_fallback: false,\n                    });\n                }\n            }\n        }\n\n        for depth in all_depths {\n            if let Some(summary) = entry.summaries.get(&depth) {\n                return Some(CompressedEntry {\n                    entry_id: entry.entry_id.clone(),\n                    content: summary.content.clone(),\n                    depth,\n                    token_count: summary.token_count,\n                    is_fallback: false,\n                });\n            }\n        }\n\n        entry.full_content.as_ref().map(|content| CompressedEntry {\n            entry_id: entry.entry_id.clone(),\n            content: content.clone(),\n            depth: SummaryDepth::Detailed,\n            token_count: entry\n                .full_content_tokens\n                .unwrap_or_else(|| self.estimate_tokens(content)),\n            is_fallback: true,\n        })\n    }\n\n    fn create_inherited_context(\n        &self,\n        layer: &CompressedLayer,\n        preferred_depths: &[SummaryDepth],\n    ) -> String {\n        let shortest_depth = preferred_depths\n            .last()\n            .copied()\n            .unwrap_or(SummaryDepth::Sentence);\n\n        layer\n            .entries\n            .iter()\n            .filter(|e| e.depth == shortest_depth || e.depth == SummaryDepth::Sentence)\n            .map(|e| e.content.as_str())\n            .collect::<Vec<_>>()\n            .join(\" | \")\n    }\n\n    fn estimate_tokens(&self, content: &str) -> u32 {\n        let char_count = content.chars().count();\n        (char_count / 4).max(1) as u32\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    fn sample_summary(depth: SummaryDepth, content: &str, tokens: u32) -> LayerSummary {\n        LayerSummary {\n            depth,\n            content: content.to_string(),\n            token_count: tokens,\n            generated_at: 0,\n            source_hash: \"test\".to_string(),\n            content_hash: None,\n            personalized: false,\n            personalization_context: None,\n        }\n    }\n\n    fn sample_entry(id: &str) -> LayerEntry {\n        let mut summaries = HashMap::new();\n        summaries.insert(\n            SummaryDepth::Sentence,\n            sample_summary(SummaryDepth::Sentence, &format!(\"Sentence: {id}\"), 20),\n        );\n        summaries.insert(\n            SummaryDepth::Paragraph,\n            sample_summary(\n                SummaryDepth::Paragraph,\n                &format!(\"Paragraph about {id}\"),\n                80,\n            ),\n        );\n        summaries.insert(\n            SummaryDepth::Detailed,\n            sample_summary(\n                SummaryDepth::Detailed,\n                &format!(\"Detailed content for {id}\"),\n                200,\n            ),\n        );\n\n        LayerEntry {\n            entry_id: id.to_string(),\n            summaries,\n            full_content: None,\n            full_content_tokens: None,\n        }\n    }\n\n    fn sample_layer(layer: MemoryLayer, entry_ids: &[&str]) -> LayerContent {\n        LayerContent {\n            layer,\n            entries: entry_ids.iter().map(|id| sample_entry(id)).collect(),\n        }\n    }\n\n    #[test]\n    fn test_compress_empty_layers() {\n        let compressor = HierarchicalCompressor::new(CompressorConfig::default());\n        let result = compressor.compress(&[], ViewMode::Dx, None);\n\n        assert!(result.layers.is_empty());\n        assert_eq!(result.total_tokens, 0);\n    }\n\n    #[test]\n    fn test_compress_single_layer() {\n        let compressor = HierarchicalCompressor::new(CompressorConfig::default());\n        let layers = vec![sample_layer(MemoryLayer::Session, &[\"entry1\"])];\n\n        let result = compressor.compress(&layers, ViewMode::Dx, None);\n\n        assert_eq!(result.layers.len(), 1);\n        assert!(!result.layers[0].entries.is_empty());\n    }\n\n    #[test]\n    fn test_compress_multiple_layers() {\n        let compressor = HierarchicalCompressor::new(CompressorConfig::default());\n        let layers = vec![\n            sample_layer(MemoryLayer::Company, &[\"company1\"]),\n            sample_layer(MemoryLayer::Team, &[\"team1\"]),\n            sample_layer(MemoryLayer::Session, &[\"session1\"]),\n        ];\n\n        let result = compressor.compress(&layers, ViewMode::Dx, None);\n\n        assert_eq!(result.layers.len(), 3);\n    }\n\n    #[test]\n    fn test_layer_ordering() {\n        let compressor = HierarchicalCompressor::new(CompressorConfig::default());\n        let layers = vec![\n            sample_layer(MemoryLayer::Session, &[\"session1\"]),\n            sample_layer(MemoryLayer::Company, &[\"company1\"]),\n            sample_layer(MemoryLayer::Team, &[\"team1\"]),\n        ];\n\n        let result = compressor.compress(&layers, ViewMode::Dx, None);\n\n        assert_eq!(result.layers[0].layer, MemoryLayer::Company);\n        assert_eq!(result.layers[1].layer, MemoryLayer::Team);\n        assert_eq!(result.layers[2].layer, MemoryLayer::Session);\n    }\n\n    #[test]\n    fn test_view_mode_ax_prefers_sentence() {\n        let compressor = HierarchicalCompressor::new(CompressorConfig::default());\n        let layers = vec![sample_layer(MemoryLayer::Session, &[\"entry1\"])];\n\n        let result = compressor.compress(&layers, ViewMode::Ax, Some(1000));\n\n        assert_eq!(result.layers[0].entries[0].depth, SummaryDepth::Sentence);\n    }\n\n    #[test]\n    fn test_view_mode_dx_prefers_detailed() {\n        let compressor = HierarchicalCompressor::new(CompressorConfig::default());\n        let layers = vec![sample_layer(MemoryLayer::Session, &[\"entry1\"])];\n\n        let result = compressor.compress(&layers, ViewMode::Dx, Some(1000));\n\n        assert_eq!(result.layers[0].entries[0].depth, SummaryDepth::Detailed);\n    }\n\n    #[test]\n    fn test_view_mode_budget_multiplier() {\n        assert!((ViewMode::Ax.token_budget_multiplier() - 0.3).abs() < 0.001);\n        assert!((ViewMode::Ux.token_budget_multiplier() - 0.6).abs() < 0.001);\n        assert!((ViewMode::Dx.token_budget_multiplier() - 1.0).abs() < 0.001);\n    }\n\n    #[test]\n    fn test_inheritance_creates_context() {\n        let config = CompressorConfig {\n            enable_inheritance: true,\n            ..Default::default()\n        };\n        let compressor = HierarchicalCompressor::new(config);\n        let layers = vec![\n            sample_layer(MemoryLayer::Company, &[\"company1\"]),\n            sample_layer(MemoryLayer::Team, &[\"team1\"]),\n        ];\n\n        let result = compressor.compress(&layers, ViewMode::Dx, None);\n\n        assert!(result.layers[1].inherited_context.is_some());\n    }\n\n    #[test]\n    fn test_inheritance_disabled() {\n        let config = CompressorConfig {\n            enable_inheritance: false,\n            ..Default::default()\n        };\n        let compressor = HierarchicalCompressor::new(config);\n        let layers = vec![\n            sample_layer(MemoryLayer::Company, &[\"company1\"]),\n            sample_layer(MemoryLayer::Team, &[\"team1\"]),\n        ];\n\n        let result = compressor.compress(&layers, ViewMode::Dx, None);\n\n        assert!(result.layers[1].inherited_context.is_none());\n    }\n\n    #[test]\n    fn test_fallback_to_full_content() {\n        let compressor = HierarchicalCompressor::new(CompressorConfig::default());\n\n        let entry = LayerEntry {\n            entry_id: \"fallback\".to_string(),\n            summaries: HashMap::new(),\n            full_content: Some(\"Full content here\".to_string()),\n            full_content_tokens: Some(50),\n        };\n\n        let layers = vec![LayerContent {\n            layer: MemoryLayer::Session,\n            entries: vec![entry],\n        }];\n\n        let result = compressor.compress(&layers, ViewMode::Dx, None);\n\n        assert!(result.layers[0].entries[0].is_fallback);\n        assert!(result.layers[0].entries[0].content.contains(\"Full content\"));\n    }\n\n    #[test]\n    fn test_empty_layer_entries() {\n        let compressor = HierarchicalCompressor::new(CompressorConfig::default());\n        let layers = vec![LayerContent {\n            layer: MemoryLayer::Session,\n            entries: vec![],\n        }];\n\n        let result = compressor.compress(&layers, ViewMode::Dx, None);\n\n        assert_eq!(result.layers.len(), 1);\n        assert!(result.layers[0].entries.is_empty());\n    }\n\n    #[test]\n    fn test_combined_content() {\n        let compressor = HierarchicalCompressor::new(CompressorConfig::default());\n        let layers = vec![\n            sample_layer(MemoryLayer::Company, &[\"company1\"]),\n            sample_layer(MemoryLayer::Session, &[\"session1\"]),\n        ];\n\n        let result = compressor.compress(&layers, ViewMode::Dx, None);\n        let content = result.combined_content();\n\n        assert!(content.contains(\"company1\"));\n        assert!(content.contains(\"session1\"));\n    }\n\n    #[test]\n    fn test_is_within_budget() {\n        let compressor = HierarchicalCompressor::new(CompressorConfig::default());\n        let layers = vec![sample_layer(MemoryLayer::Session, &[\"entry1\"])];\n\n        let result = compressor.compress(&layers, ViewMode::Dx, Some(10000));\n\n        assert!(result.is_within_budget());\n    }\n\n    #[test]\n    fn test_progressive_compression_tight_budget() {\n        let compressor = HierarchicalCompressor::new(CompressorConfig::default());\n        let layers = vec![sample_layer(MemoryLayer::Session, &[\"e1\", \"e2\", \"e3\"])];\n\n        let result = compressor.compress(&layers, ViewMode::Ax, Some(100));\n\n        for entry in &result.layers[0].entries {\n            assert_eq!(entry.depth, SummaryDepth::Sentence);\n        }\n    }\n\n    #[test]\n    fn test_missing_summaries_skips_entry() {\n        let compressor = HierarchicalCompressor::new(CompressorConfig::default());\n\n        let entry = LayerEntry {\n            entry_id: \"empty\".to_string(),\n            summaries: HashMap::new(),\n            full_content: None,\n            full_content_tokens: None,\n        };\n\n        let layers = vec![LayerContent {\n            layer: MemoryLayer::Session,\n            entries: vec![entry],\n        }];\n\n        let result = compressor.compress(&layers, ViewMode::Dx, None);\n\n        assert!(result.layers[0].entries.is_empty());\n    }\n}\n","traces":[{"line":13,"address":[],"length":0,"stats":{"Line":17}},{"line":14,"address":[],"length":0,"stats":{"Line":17}},{"line":15,"address":[],"length":0,"stats":{"Line":3}},{"line":16,"address":[],"length":0,"stats":{"Line":1}},{"line":17,"address":[],"length":0,"stats":{"Line":13}},{"line":21,"address":[],"length":0,"stats":{"Line":14}},{"line":22,"address":[],"length":0,"stats":{"Line":14}},{"line":23,"address":[],"length":0,"stats":{"Line":4}},{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":12}},{"line":26,"address":[],"length":0,"stats":{"Line":12}},{"line":27,"address":[],"length":0,"stats":{"Line":12}},{"line":28,"address":[],"length":0,"stats":{"Line":12}},{"line":44,"address":[],"length":0,"stats":{"Line":14}},{"line":47,"address":[],"length":0,"stats":{"Line":28}},{"line":102,"address":[],"length":0,"stats":{"Line":1}},{"line":103,"address":[],"length":0,"stats":{"Line":1}},{"line":105,"address":[],"length":0,"stats":{"Line":3}},{"line":106,"address":[],"length":0,"stats":{"Line":4}},{"line":107,"address":[],"length":0,"stats":{"Line":4}},{"line":108,"address":[],"length":0,"stats":{"Line":3}},{"line":110,"address":[],"length":0,"stats":{"Line":12}},{"line":111,"address":[],"length":0,"stats":{"Line":2}},{"line":117,"address":[],"length":0,"stats":{"Line":1}},{"line":118,"address":[],"length":0,"stats":{"Line":1}},{"line":127,"address":[],"length":0,"stats":{"Line":14}},{"line":131,"address":[],"length":0,"stats":{"Line":14}},{"line":137,"address":[],"length":0,"stats":{"Line":56}},{"line":138,"address":[],"length":0,"stats":{"Line":42}},{"line":140,"address":[],"length":0,"stats":{"Line":70}},{"line":141,"address":[],"length":0,"stats":{"Line":42}},{"line":143,"address":[],"length":0,"stats":{"Line":28}},{"line":144,"address":[],"length":0,"stats":{"Line":42}},{"line":145,"address":[],"length":0,"stats":{"Line":42}},{"line":147,"address":[],"length":0,"stats":{"Line":62}},{"line":148,"address":[],"length":0,"stats":{"Line":40}},{"line":149,"address":[],"length":0,"stats":{"Line":40}},{"line":151,"address":[],"length":0,"stats":{"Line":40}},{"line":153,"address":[],"length":0,"stats":{"Line":58}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":20}},{"line":159,"address":[],"length":0,"stats":{"Line":60}},{"line":160,"address":[],"length":0,"stats":{"Line":20}},{"line":161,"address":[],"length":0,"stats":{"Line":20}},{"line":162,"address":[],"length":0,"stats":{"Line":20}},{"line":163,"address":[],"length":0,"stats":{"Line":40}},{"line":164,"address":[],"length":0,"stats":{"Line":20}},{"line":167,"address":[],"length":0,"stats":{"Line":54}},{"line":168,"address":[],"length":0,"stats":{"Line":32}},{"line":169,"address":[],"length":0,"stats":{"Line":64}},{"line":170,"address":[],"length":0,"stats":{"Line":96}},{"line":171,"address":[],"length":0,"stats":{"Line":16}},{"line":172,"address":[],"length":0,"stats":{"Line":16}},{"line":175,"address":[],"length":0,"stats":{"Line":60}},{"line":178,"address":[],"length":0,"stats":{"Line":56}},{"line":188,"address":[],"length":0,"stats":{"Line":14}},{"line":193,"address":[],"length":0,"stats":{"Line":28}},{"line":195,"address":[],"length":0,"stats":{"Line":28}},{"line":196,"address":[],"length":0,"stats":{"Line":1}},{"line":199,"address":[],"length":0,"stats":{"Line":26}},{"line":200,"address":[],"length":0,"stats":{"Line":26}},{"line":202,"address":[],"length":0,"stats":{"Line":13}},{"line":203,"address":[],"length":0,"stats":{"Line":4}},{"line":204,"address":[],"length":0,"stats":{"Line":3}},{"line":206,"address":[],"length":0,"stats":{"Line":1}},{"line":209,"address":[],"length":0,"stats":{"Line":36}},{"line":211,"address":[],"length":0,"stats":{"Line":31}},{"line":212,"address":[],"length":0,"stats":{"Line":38}},{"line":213,"address":[],"length":0,"stats":{"Line":19}},{"line":214,"address":[],"length":0,"stats":{"Line":19}},{"line":215,"address":[],"length":0,"stats":{"Line":19}},{"line":216,"address":[],"length":0,"stats":{"Line":153}},{"line":217,"address":[],"length":0,"stats":{"Line":57}},{"line":218,"address":[],"length":0,"stats":{"Line":38}},{"line":219,"address":[],"length":0,"stats":{"Line":19}},{"line":223,"address":[],"length":0,"stats":{"Line":60}},{"line":225,"address":[],"length":0,"stats":{"Line":88}},{"line":226,"address":[],"length":0,"stats":{"Line":57}},{"line":227,"address":[],"length":0,"stats":{"Line":38}},{"line":228,"address":[],"length":0,"stats":{"Line":76}},{"line":229,"address":[],"length":0,"stats":{"Line":57}},{"line":232,"address":[],"length":0,"stats":{"Line":12}},{"line":235,"address":[],"length":0,"stats":{"Line":14}},{"line":236,"address":[],"length":0,"stats":{"Line":70}},{"line":237,"address":[],"length":0,"stats":{"Line":44}},{"line":238,"address":[],"length":0,"stats":{"Line":16}},{"line":239,"address":[],"length":0,"stats":{"Line":16}},{"line":240,"address":[],"length":0,"stats":{"Line":16}},{"line":241,"address":[],"length":0,"stats":{"Line":104}},{"line":242,"address":[],"length":0,"stats":{"Line":16}},{"line":244,"address":[],"length":0,"stats":{"Line":14}},{"line":247,"address":[],"length":0,"stats":{"Line":20}},{"line":255,"address":[],"length":0,"stats":{"Line":40}},{"line":256,"address":[],"length":0,"stats":{"Line":40}},{"line":258,"address":[],"length":0,"stats":{"Line":40}},{"line":259,"address":[],"length":0,"stats":{"Line":38}},{"line":261,"address":[],"length":0,"stats":{"Line":1}},{"line":264,"address":[],"length":0,"stats":{"Line":59}},{"line":265,"address":[],"length":0,"stats":{"Line":20}},{"line":266,"address":[],"length":0,"stats":{"Line":1}},{"line":269,"address":[],"length":0,"stats":{"Line":76}},{"line":270,"address":[],"length":0,"stats":{"Line":94}},{"line":272,"address":[],"length":0,"stats":{"Line":54}},{"line":273,"address":[],"length":0,"stats":{"Line":36}},{"line":277,"address":[],"length":0,"stats":{"Line":100}},{"line":278,"address":[],"length":0,"stats":{"Line":40}},{"line":281,"address":[],"length":0,"stats":{"Line":40}},{"line":289,"address":[],"length":0,"stats":{"Line":19}},{"line":295,"address":[],"length":0,"stats":{"Line":49}},{"line":296,"address":[],"length":0,"stats":{"Line":63}},{"line":297,"address":[],"length":0,"stats":{"Line":17}},{"line":298,"address":[],"length":0,"stats":{"Line":16}},{"line":299,"address":[],"length":0,"stats":{"Line":48}},{"line":300,"address":[],"length":0,"stats":{"Line":48}},{"line":301,"address":[],"length":0,"stats":{"Line":16}},{"line":302,"address":[],"length":0,"stats":{"Line":16}},{"line":303,"address":[],"length":0,"stats":{"Line":16}},{"line":309,"address":[],"length":0,"stats":{"Line":6}},{"line":310,"address":[],"length":0,"stats":{"Line":6}},{"line":311,"address":[],"length":0,"stats":{"Line":3}},{"line":312,"address":[],"length":0,"stats":{"Line":3}},{"line":314,"address":[],"length":0,"stats":{"Line":21}},{"line":315,"address":[],"length":0,"stats":{"Line":21}},{"line":316,"address":[],"length":0,"stats":{"Line":3}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":0}},{"line":321,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":16}},{"line":329,"address":[],"length":0,"stats":{"Line":15}},{"line":330,"address":[],"length":0,"stats":{"Line":1}},{"line":331,"address":[],"length":0,"stats":{"Line":3}},{"line":332,"address":[],"length":0,"stats":{"Line":3}},{"line":333,"address":[],"length":0,"stats":{"Line":1}},{"line":334,"address":[],"length":0,"stats":{"Line":1}},{"line":335,"address":[],"length":0,"stats":{"Line":1}},{"line":340,"address":[],"length":0,"stats":{"Line":6}},{"line":341,"address":[],"length":0,"stats":{"Line":2}},{"line":342,"address":[],"length":0,"stats":{"Line":2}},{"line":343,"address":[],"length":0,"stats":{"Line":1}},{"line":344,"address":[],"length":0,"stats":{"Line":1}},{"line":345,"address":[],"length":0,"stats":{"Line":1}},{"line":346,"address":[],"length":0,"stats":{"Line":1}},{"line":351,"address":[],"length":0,"stats":{"Line":16}},{"line":356,"address":[],"length":0,"stats":{"Line":32}},{"line":359,"address":[],"length":0,"stats":{"Line":32}},{"line":361,"address":[],"length":0,"stats":{"Line":16}},{"line":362,"address":[],"length":0,"stats":{"Line":16}},{"line":364,"address":[],"length":0,"stats":{"Line":46}},{"line":365,"address":[],"length":0,"stats":{"Line":20}},{"line":370,"address":[],"length":0,"stats":{"Line":16}},{"line":371,"address":[],"length":0,"stats":{"Line":64}},{"line":372,"address":[],"length":0,"stats":{"Line":16}}],"covered":147,"coverable":155},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","context_architect","failure_handling.rs"],"content":"use std::collections::VecDeque;\nuse std::sync::Arc;\nuse std::sync::atomic::{AtomicU64, AtomicUsize, Ordering};\nuse std::time::{Duration, Instant};\n\n// Removed unused 'backoff' crate import to avoid conflicts with tokio_retry\nuse mk_core::types::{LayerSummary, SummaryDepth};\nuse tracing::{error, warn};\n\n// Assuming these exist in your project structure\nuse super::generator::{GenerationError, SummaryResult};\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum CircuitState {\n    Closed,\n    Open,\n    HalfOpen,\n}\n\n#[derive(Debug, Clone)]\npub struct CircuitBreakerConfig {\n    pub failure_threshold: usize,\n    pub success_threshold: usize,\n    pub timeout_secs: u64,\n    pub half_open_max_calls: usize,\n}\n\nimpl Default for CircuitBreakerConfig {\n    fn default() -> Self {\n        Self {\n            failure_threshold: 5,\n            success_threshold: 2,\n            timeout_secs: 60,\n            half_open_max_calls: 3,\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct RetryConfig {\n    pub max_retries: u32,\n    pub initial_delay_ms: u64,\n    pub max_delay_ms: u64,\n    pub multiplier: f64,\n    pub jitter_factor: f64,\n}\n\nimpl Default for RetryConfig {\n    fn default() -> Self {\n        Self {\n            max_retries: 3,\n            initial_delay_ms: 1000,\n            max_delay_ms: 30000,\n            multiplier: 2.0,\n            jitter_factor: 0.1,\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct FailureMetrics {\n    failures_total: Arc<AtomicU64>,\n    retries_total: Arc<AtomicU64>,\n    circuit_trips: Arc<AtomicU64>,\n    consecutive_failures: Arc<AtomicUsize>,\n    cached_fallbacks: Arc<AtomicU64>,\n    raw_content_fallbacks: Arc<AtomicU64>,\n    fallback_model_uses: Arc<AtomicU64>,\n}\n\nimpl FailureMetrics {\n    pub fn new() -> Self {\n        Self {\n            failures_total: Arc::new(AtomicU64::new(0)),\n            retries_total: Arc::new(AtomicU64::new(0)),\n            circuit_trips: Arc::new(AtomicU64::new(0)),\n            consecutive_failures: Arc::new(AtomicUsize::new(0)),\n            cached_fallbacks: Arc::new(AtomicU64::new(0)),\n            raw_content_fallbacks: Arc::new(AtomicU64::new(0)),\n            fallback_model_uses: Arc::new(AtomicU64::new(0)),\n        }\n    }\n\n    pub fn record_failure(&self) {\n        self.failures_total.fetch_add(1, Ordering::Relaxed);\n        self.consecutive_failures.fetch_add(1, Ordering::Relaxed);\n    }\n\n    pub fn record_retry(&self) {\n        self.retries_total.fetch_add(1, Ordering::Relaxed);\n    }\n\n    pub fn record_circuit_trip(&self) {\n        self.circuit_trips.fetch_add(1, Ordering::Relaxed);\n    }\n\n    pub fn record_success(&self) {\n        self.consecutive_failures.store(0, Ordering::Relaxed);\n    }\n\n    pub fn record_cached_fallback(&self) {\n        self.cached_fallbacks.fetch_add(1, Ordering::Relaxed);\n    }\n\n    pub fn record_raw_content_fallback(&self) {\n        self.raw_content_fallbacks.fetch_add(1, Ordering::Relaxed);\n    }\n\n    pub fn record_fallback_model_use(&self) {\n        self.fallback_model_uses.fetch_add(1, Ordering::Relaxed);\n    }\n\n    pub fn failures_total(&self) -> u64 {\n        self.failures_total.load(Ordering::Relaxed)\n    }\n\n    pub fn retries_total(&self) -> u64 {\n        self.retries_total.load(Ordering::Relaxed)\n    }\n\n    pub fn circuit_trips(&self) -> u64 {\n        self.circuit_trips.load(Ordering::Relaxed)\n    }\n\n    pub fn consecutive_failures(&self) -> usize {\n        self.consecutive_failures.load(Ordering::Relaxed)\n    }\n\n    pub fn cached_fallbacks(&self) -> u64 {\n        self.cached_fallbacks.load(Ordering::Relaxed)\n    }\n\n    pub fn raw_content_fallbacks(&self) -> u64 {\n        self.raw_content_fallbacks.load(Ordering::Relaxed)\n    }\n\n    pub fn fallback_model_uses(&self) -> u64 {\n        self.fallback_model_uses.load(Ordering::Relaxed)\n    }\n}\n\nimpl Default for FailureMetrics {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\npub struct CircuitBreaker {\n    state: Arc<std::sync::Mutex<CircuitState>>,\n    config: CircuitBreakerConfig,\n    failure_count: Arc<AtomicUsize>,\n    success_count: Arc<AtomicUsize>,\n    opened_at: Arc<std::sync::Mutex<Option<Instant>>>,\n    metrics: Arc<FailureMetrics>,\n    half_open_calls: Arc<AtomicUsize>,\n}\n\nimpl CircuitBreaker {\n    pub fn new(config: CircuitBreakerConfig, metrics: Arc<FailureMetrics>) -> Self {\n        Self {\n            state: Arc::new(std::sync::Mutex::new(CircuitState::Closed)),\n            config,\n            failure_count: Arc::new(AtomicUsize::new(0)),\n            success_count: Arc::new(AtomicUsize::new(0)),\n            opened_at: Arc::new(std::sync::Mutex::new(None)),\n            metrics,\n            half_open_calls: Arc::new(AtomicUsize::new(0)),\n        }\n    }\n\n    pub fn should_allow_request(&self) -> bool {\n        let mut state = self.state.lock().unwrap();\n\n        match *state {\n            CircuitState::Open => {\n                if let Some(opened_at) = *self.opened_at.lock().unwrap() {\n                    if opened_at.elapsed() >= Duration::from_secs(self.config.timeout_secs) {\n                        *state = CircuitState::HalfOpen;\n                        self.half_open_calls.store(0, Ordering::Relaxed);\n                        true\n                    } else {\n                        false\n                    }\n                } else {\n                    false\n                }\n            }\n            CircuitState::HalfOpen => {\n                let calls = self.half_open_calls.fetch_add(1, Ordering::Relaxed);\n                calls < self.config.half_open_max_calls\n            }\n            CircuitState::Closed => true,\n        }\n    }\n\n    pub fn record_success(&self) {\n        self.metrics.record_success();\n        let mut state = self.state.lock().unwrap();\n\n        match *state {\n            CircuitState::HalfOpen => {\n                let successes = self.success_count.fetch_add(1, Ordering::Relaxed) + 1;\n                if successes >= self.config.success_threshold {\n                    *state = CircuitState::Closed;\n                    self.failure_count.store(0, Ordering::Relaxed);\n                    self.success_count.store(0, Ordering::Relaxed);\n                }\n            }\n            CircuitState::Closed => {\n                self.success_count.fetch_add(1, Ordering::Relaxed);\n            }\n            CircuitState::Open => {}\n        }\n    }\n\n    pub fn record_failure(&self) {\n        self.metrics.record_failure();\n        let mut state = self.state.lock().unwrap();\n\n        match *state {\n            CircuitState::Closed | CircuitState::HalfOpen => {\n                let failures = self.failure_count.fetch_add(1, Ordering::Relaxed) + 1;\n                if failures >= self.config.failure_threshold {\n                    *state = CircuitState::Open;\n                    *self.opened_at.lock().unwrap() = Some(Instant::now());\n                    self.metrics.record_circuit_trip();\n                    self.failure_count.store(0, Ordering::Relaxed);\n                    self.success_count.store(0, Ordering::Relaxed);\n                    warn!(\"Circuit breaker opened after {} failures\", failures);\n                }\n            }\n            CircuitState::Open => {}\n        }\n    }\n\n    pub fn state(&self) -> CircuitState {\n        *self.state.lock().unwrap()\n    }\n}\n\npub struct CachedSummaryStore {\n    cache: Arc<dashmap::DashMap<String, CachedEntry>>,\n}\n\n#[derive(Debug, Clone)]\nstruct CachedEntry {\n    summary: LayerSummary,\n    timestamp: Instant,\n}\n\nimpl CachedSummaryStore {\n    pub fn new() -> Self {\n        Self {\n            cache: Arc::new(dashmap::DashMap::new()),\n        }\n    }\n\n    pub fn get(&self, key: &str, max_age_secs: u64) -> Option<LayerSummary> {\n        self.cache.get(key).and_then(|entry| {\n            if entry.timestamp.elapsed() < Duration::from_secs(max_age_secs) {\n                Some(entry.summary.clone())\n            } else {\n                None\n            }\n        })\n    }\n\n    pub fn put(&self, key: String, summary: LayerSummary) {\n        self.cache.insert(\n            key,\n            CachedEntry {\n                summary,\n                timestamp: Instant::now(),\n            },\n        );\n    }\n\n    pub fn remove(&self, key: &str) {\n        self.cache.remove(key);\n    }\n\n    pub fn clear(&self) {\n        self.cache.clear();\n    }\n\n    pub fn len(&self) -> usize {\n        self.cache.len()\n    }\n}\n\nimpl Default for CachedSummaryStore {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\npub async fn retry_with_backoff<F, Fut, T, E>(\n    retry_config: &RetryConfig,\n    metrics: &Arc<FailureMetrics>,\n    operation: F,\n) -> Result<T, E>\nwhere\n    F: Fn() -> Fut,\n    Fut: std::future::Future<Output = Result<T, E>>,\n{\n    use tokio_retry::strategy::{ExponentialBackoff, jitter};\n\n    // Initialize the backoff strategy iterator\n    let mut backoff_strategy =\n        ExponentialBackoff::from_millis(retry_config.initial_delay_ms).map(|duration| {\n            let capped = duration.min(Duration::from_millis(retry_config.max_delay_ms));\n            // Apply jitter to the capped duration\n            jitter(capped)\n        });\n\n    let mut attempt = 0;\n\n    loop {\n        attempt += 1;\n        let result = operation().await;\n\n        match result {\n            Ok(val) => return Ok(val),\n            Err(e) => {\n                if attempt > retry_config.max_retries {\n                    metrics.record_failure();\n                    return Err(e);\n                }\n\n                metrics.record_retry();\n\n                // Retrieve the next delay from the strategy\n                if let Some(delay) = backoff_strategy.next() {\n                    tokio::time::sleep(delay).await;\n                } else {\n                    // Fallback if strategy runs out (unlikely with infinite ExponentialBackoff)\n                    metrics.record_failure();\n                    return Err(e);\n                }\n            }\n        }\n    }\n}\n\npub fn alert_on_consecutive_failures(metrics: &FailureMetrics, threshold: usize) -> bool {\n    metrics.consecutive_failures() >= threshold\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_circuit_breaker_initial_closed() {\n        let config = CircuitBreakerConfig::default();\n        let metrics = Arc::new(FailureMetrics::new());\n        let breaker = CircuitBreaker::new(config, metrics);\n\n        assert_eq!(breaker.state(), CircuitState::Closed);\n        assert!(breaker.should_allow_request());\n    }\n\n    #[test]\n    fn test_circuit_breaker_trips_on_threshold() {\n        let config = CircuitBreakerConfig {\n            failure_threshold: 3,\n            ..Default::default()\n        };\n        let metrics = Arc::new(FailureMetrics::new());\n        let breaker = CircuitBreaker::new(config, metrics);\n\n        assert!(breaker.should_allow_request());\n        breaker.record_failure();\n        assert!(breaker.should_allow_request());\n        breaker.record_failure();\n        assert!(breaker.should_allow_request());\n        breaker.record_failure();\n\n        assert_eq!(breaker.state(), CircuitState::Open);\n        assert!(!breaker.should_allow_request());\n    }\n\n    #[test]\n    fn test_circuit_breaker_recovers() {\n        let config = CircuitBreakerConfig {\n            failure_threshold: 2,\n            timeout_secs: 1,\n            ..Default::default()\n        };\n        let metrics = Arc::new(FailureMetrics::new());\n        let breaker = CircuitBreaker::new(config, metrics);\n\n        breaker.record_failure();\n        breaker.record_failure();\n\n        assert_eq!(breaker.state(), CircuitState::Open);\n\n        std::thread::sleep(Duration::from_millis(1100));\n\n        let _ = breaker.should_allow_request(); // Triggers state transition check\n        let recovered_state = breaker.state();\n        assert_eq!(recovered_state, CircuitState::HalfOpen);\n\n        let can_request = breaker.should_allow_request();\n        assert!(\n            can_request,\n            \"Should allow request after timeout recovery to HalfOpen state\"\n        );\n    }\n\n    #[test]\n    fn test_cached_summary_store() {\n        let store = CachedSummaryStore::new();\n\n        let summary = LayerSummary {\n            depth: SummaryDepth::Sentence,\n            content: \"Test summary\".to_string(),\n            token_count: 10,\n            generated_at: 1000,\n            source_hash: \"hash\".to_string(),\n            content_hash: None,\n            personalized: false,\n            personalization_context: None,\n        };\n\n        store.put(\"key1\".to_string(), summary.clone());\n\n        let retrieved = store.get(\"key1\", 3600);\n        assert!(retrieved.is_some());\n        assert_eq!(retrieved.unwrap().content, \"Test summary\");\n\n        let expired = store.get(\"key1\", 0);\n        assert!(expired.is_none());\n    }\n\n    #[test]\n    fn test_failure_metrics() {\n        let metrics = FailureMetrics::new();\n\n        assert_eq!(metrics.failures_total(), 0);\n        assert_eq!(metrics.consecutive_failures(), 0);\n\n        metrics.record_failure();\n        metrics.record_failure();\n        metrics.record_retry();\n\n        assert_eq!(metrics.failures_total(), 2);\n        assert_eq!(metrics.consecutive_failures(), 2);\n        assert_eq!(metrics.retries_total(), 1);\n\n        metrics.record_success();\n        assert_eq!(metrics.consecutive_failures(), 0);\n    }\n\n    #[test]\n    fn test_alert_on_consecutive_failures() {\n        let metrics = FailureMetrics::new();\n\n        assert!(!alert_on_consecutive_failures(&metrics, 3));\n\n        metrics.record_failure();\n        metrics.record_failure();\n\n        assert!(!alert_on_consecutive_failures(&metrics, 3));\n\n        metrics.record_failure();\n\n        assert!(alert_on_consecutive_failures(&metrics, 3));\n    }\n}\n","traces":[{"line":29,"address":[],"length":0,"stats":{"Line":3}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":5}},{"line":74,"address":[],"length":0,"stats":{"Line":15}},{"line":75,"address":[],"length":0,"stats":{"Line":15}},{"line":76,"address":[],"length":0,"stats":{"Line":15}},{"line":77,"address":[],"length":0,"stats":{"Line":15}},{"line":78,"address":[],"length":0,"stats":{"Line":15}},{"line":79,"address":[],"length":0,"stats":{"Line":15}},{"line":80,"address":[],"length":0,"stats":{"Line":5}},{"line":84,"address":[],"length":0,"stats":{"Line":10}},{"line":85,"address":[],"length":0,"stats":{"Line":20}},{"line":86,"address":[],"length":0,"stats":{"Line":20}},{"line":89,"address":[],"length":0,"stats":{"Line":1}},{"line":90,"address":[],"length":0,"stats":{"Line":2}},{"line":93,"address":[],"length":0,"stats":{"Line":2}},{"line":94,"address":[],"length":0,"stats":{"Line":4}},{"line":97,"address":[],"length":0,"stats":{"Line":1}},{"line":98,"address":[],"length":0,"stats":{"Line":2}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":2}},{"line":114,"address":[],"length":0,"stats":{"Line":4}},{"line":117,"address":[],"length":0,"stats":{"Line":1}},{"line":118,"address":[],"length":0,"stats":{"Line":2}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":6}},{"line":126,"address":[],"length":0,"stats":{"Line":12}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":3}},{"line":161,"address":[],"length":0,"stats":{"Line":12}},{"line":163,"address":[],"length":0,"stats":{"Line":9}},{"line":164,"address":[],"length":0,"stats":{"Line":9}},{"line":165,"address":[],"length":0,"stats":{"Line":12}},{"line":167,"address":[],"length":0,"stats":{"Line":3}},{"line":171,"address":[],"length":0,"stats":{"Line":7}},{"line":172,"address":[],"length":0,"stats":{"Line":21}},{"line":174,"address":[],"length":0,"stats":{"Line":7}},{"line":176,"address":[],"length":0,"stats":{"Line":4}},{"line":177,"address":[],"length":0,"stats":{"Line":4}},{"line":178,"address":[],"length":0,"stats":{"Line":1}},{"line":179,"address":[],"length":0,"stats":{"Line":2}},{"line":180,"address":[],"length":0,"stats":{"Line":1}},{"line":182,"address":[],"length":0,"stats":{"Line":1}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":3}},{"line":190,"address":[],"length":0,"stats":{"Line":1}},{"line":192,"address":[],"length":0,"stats":{"Line":4}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":204,"address":[],"length":0,"stats":{"Line":0}},{"line":205,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":5}},{"line":217,"address":[],"length":0,"stats":{"Line":5}},{"line":218,"address":[],"length":0,"stats":{"Line":15}},{"line":220,"address":[],"length":0,"stats":{"Line":5}},{"line":222,"address":[],"length":0,"stats":{"Line":15}},{"line":223,"address":[],"length":0,"stats":{"Line":5}},{"line":224,"address":[],"length":0,"stats":{"Line":2}},{"line":225,"address":[],"length":0,"stats":{"Line":2}},{"line":226,"address":[],"length":0,"stats":{"Line":2}},{"line":227,"address":[],"length":0,"stats":{"Line":4}},{"line":228,"address":[],"length":0,"stats":{"Line":4}},{"line":229,"address":[],"length":0,"stats":{"Line":2}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":4}},{"line":237,"address":[],"length":0,"stats":{"Line":4}},{"line":252,"address":[],"length":0,"stats":{"Line":1}},{"line":254,"address":[],"length":0,"stats":{"Line":1}},{"line":258,"address":[],"length":0,"stats":{"Line":2}},{"line":259,"address":[],"length":0,"stats":{"Line":8}},{"line":260,"address":[],"length":0,"stats":{"Line":4}},{"line":261,"address":[],"length":0,"stats":{"Line":1}},{"line":263,"address":[],"length":0,"stats":{"Line":1}},{"line":268,"address":[],"length":0,"stats":{"Line":1}},{"line":269,"address":[],"length":0,"stats":{"Line":3}},{"line":270,"address":[],"length":0,"stats":{"Line":2}},{"line":271,"address":[],"length":0,"stats":{"Line":1}},{"line":272,"address":[],"length":0,"stats":{"Line":1}},{"line":273,"address":[],"length":0,"stats":{"Line":1}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":0}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":0}},{"line":323,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":325,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":333,"address":[],"length":0,"stats":{"Line":0}},{"line":334,"address":[],"length":0,"stats":{"Line":0}},{"line":337,"address":[],"length":0,"stats":{"Line":0}},{"line":338,"address":[],"length":0,"stats":{"Line":0}},{"line":345,"address":[],"length":0,"stats":{"Line":3}},{"line":346,"address":[],"length":0,"stats":{"Line":6}}],"covered":71,"coverable":130},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","context_architect","generator.rs"],"content":"use std::sync::Arc;\nuse std::time::{SystemTime, UNIX_EPOCH};\n\nuse mk_core::types::{LayerSummary, MemoryLayer, SummaryDepth};\nuse sha2::{Digest, Sha256};\nuse tracing::{Instrument, info_span, warn};\n\nuse super::budget::{BudgetCheck, BudgetError, BudgetTracker, TieredModelConfig};\nuse super::prompts::PromptTemplates;\nuse super::{LlmClient, LlmError};\n\n#[derive(Debug, Clone)]\npub struct SummaryGeneratorConfig {\n    pub max_retries: u32,\n    pub retry_delay_ms: u64,\n    pub sentence_max_tokens: u32,\n    pub paragraph_max_tokens: u32,\n    pub detailed_max_tokens: u32,\n}\n\nimpl Default for SummaryGeneratorConfig {\n    fn default() -> Self {\n        Self {\n            max_retries: 3,\n            retry_delay_ms: 1000,\n            sentence_max_tokens: 50,\n            paragraph_max_tokens: 200,\n            detailed_max_tokens: 500,\n        }\n    }\n}\n\npub struct SummaryGenerator<C: LlmClient> {\n    client: Arc<C>,\n    config: SummaryGeneratorConfig,\n    prompts: PromptTemplates,\n}\n\n#[derive(Debug, Clone)]\npub struct SummaryRequest {\n    pub content: String,\n    pub depth: SummaryDepth,\n    pub context: Option<String>,\n    pub personalization_context: Option<String>,\n}\n\n#[derive(Debug, Clone)]\npub struct SummaryResult {\n    pub summary: LayerSummary,\n    pub tokens_used: u32,\n}\n\n#[derive(Debug, Clone)]\npub struct BatchSummaryRequest {\n    pub requests: Vec<SummaryRequest>,\n}\n\n#[derive(Debug, Clone)]\npub struct BatchSummaryResult {\n    pub results: Vec<Result<SummaryResult, GenerationError>>,\n    pub total_tokens_used: u32,\n}\n\n#[derive(Debug, Clone, thiserror::Error)]\npub enum GenerationError {\n    #[error(\"LLM error: {0}\")]\n    Llm(#[from] LlmError),\n\n    #[error(\"Empty content provided\")]\n    EmptyContent,\n\n    #[error(\"Content too short for summarization: {length} chars, minimum {minimum}\")]\n    ContentTooShort { length: usize, minimum: usize },\n\n    #[error(\"Token limit exceeded: {actual} > {limit}\")]\n    TokenLimitExceeded { actual: u32, limit: u32 },\n\n    #[error(\"Budget exhausted: {0}\")]\n    BudgetExhausted(#[from] BudgetError),\n}\n\nimpl<C: LlmClient> SummaryGenerator<C> {\n    pub fn new(client: Arc<C>, config: SummaryGeneratorConfig) -> Self {\n        Self {\n            client,\n            config,\n            prompts: PromptTemplates::default(),\n        }\n    }\n\n    pub fn with_prompts(mut self, prompts: PromptTemplates) -> Self {\n        self.prompts = prompts;\n        self\n    }\n\n    pub async fn generate_summary(\n        &self,\n        content: &str,\n        depth: SummaryDepth,\n        context: Option<&str>,\n    ) -> Result<LayerSummary, GenerationError> {\n        self.generate_summary_with_personalization(content, depth, context, None)\n            .await\n    }\n\n    pub async fn generate_summary_with_personalization(\n        &self,\n        content: &str,\n        depth: SummaryDepth,\n        context: Option<&str>,\n        personalization_context: Option<&str>,\n    ) -> Result<LayerSummary, GenerationError> {\n        let span = info_span!(\n            \"context_architect.generate_summary\",\n            depth = ?depth,\n            content_length = content.len(),\n            has_context = context.is_some(),\n            has_personalization = personalization_context.is_some()\n        );\n\n        async move {\n            if content.is_empty() {\n                return Err(GenerationError::EmptyContent);\n            }\n\n            let min_length = match depth {\n                SummaryDepth::Sentence => 20,\n                SummaryDepth::Paragraph => 50,\n                SummaryDepth::Detailed => 100,\n            };\n\n            if content.len() < min_length {\n                return Err(GenerationError::ContentTooShort {\n                    length: content.len(),\n                    minimum: min_length,\n                });\n            }\n\n            let (system_prompt, user_prompt) = self.prompts.build_prompt(\n                content,\n                depth,\n                context,\n                personalization_context,\n                self.token_limit_for_depth(depth),\n            );\n\n            let response = self\n                .client\n                .complete_with_system(&system_prompt, &user_prompt)\n                .await?;\n\n            let token_count = estimate_tokens(&response);\n            let source_hash = compute_content_hash(content);\n            let generated_at = SystemTime::now()\n                .duration_since(UNIX_EPOCH)\n                .map(|d| d.as_secs() as i64)\n                .unwrap_or(0);\n\n            let summary_content = response.trim().to_string();\n            let content_hash = Some(compute_content_hash(&summary_content));\n\n            Ok(LayerSummary {\n                depth,\n                content: summary_content,\n                token_count,\n                generated_at,\n                source_hash,\n                content_hash,\n                personalized: personalization_context.is_some(),\n                personalization_context: personalization_context.map(String::from),\n            })\n        }\n        .instrument(span)\n        .await\n    }\n\n    pub async fn generate_batch(&self, requests: Vec<SummaryRequest>) -> BatchSummaryResult {\n        let span = info_span!(\n            \"context_architect.generate_batch\",\n            batch_size = requests.len()\n        );\n\n        let _enter = span.enter();\n\n        let mut results = Vec::with_capacity(requests.len());\n        let mut total_tokens = 0u32;\n\n        for request in requests {\n            let result = self\n                .generate_summary_with_personalization(\n                    &request.content,\n                    request.depth,\n                    request.context.as_deref(),\n                    request.personalization_context.as_deref(),\n                )\n                .await;\n\n            match &result {\n                Ok(summary) => {\n                    total_tokens = total_tokens.saturating_add(summary.token_count);\n                    results.push(Ok(SummaryResult {\n                        summary: summary.clone(),\n                        tokens_used: summary.token_count,\n                    }));\n                }\n                Err(e) => {\n                    results.push(Err(e.clone()));\n                }\n            }\n        }\n\n        BatchSummaryResult {\n            results,\n            total_tokens_used: total_tokens,\n        }\n    }\n\n    pub fn token_limit_for_depth(&self, depth: SummaryDepth) -> u32 {\n        match depth {\n            SummaryDepth::Sentence => self.config.sentence_max_tokens,\n            SummaryDepth::Paragraph => self.config.paragraph_max_tokens,\n            SummaryDepth::Detailed => self.config.detailed_max_tokens,\n        }\n    }\n}\n\npub fn estimate_tokens(text: &str) -> u32 {\n    let word_count = text.split_whitespace().count();\n    let char_count = text.chars().count();\n\n    // GPT-style estimation: ~4 chars per token, with adjustment for whitespace\n    // Using max of word-based and char-based estimates for safety\n    let char_based = (char_count as f64 / 4.0).ceil() as u32;\n    let word_based = (word_count as f64 * 1.3).ceil() as u32;\n\n    char_based.max(word_based)\n}\n\nfn compute_content_hash(content: &str) -> String {\n    let mut hasher = Sha256::new();\n    hasher.update(content.as_bytes());\n    let result = hasher.finalize();\n    hex::encode(&result[..8])\n}\n\npub struct BudgetAwareSummaryGenerator<C: LlmClient> {\n    generator: SummaryGenerator<C>,\n    budget_tracker: Arc<BudgetTracker>,\n    model_config: TieredModelConfig,\n}\n\n#[derive(Debug, Clone)]\npub struct BudgetAwareSummaryRequest {\n    pub content: String,\n    pub depth: SummaryDepth,\n    pub layer: MemoryLayer,\n    pub context: Option<String>,\n    pub personalization_context: Option<String>,\n}\n\n#[derive(Debug, Clone)]\npub struct BudgetAwareSummaryResult {\n    pub summary: LayerSummary,\n    pub tokens_used: u32,\n    pub budget_check: BudgetCheck,\n    pub model_used: String,\n}\n\nimpl<C: LlmClient> BudgetAwareSummaryGenerator<C> {\n    pub fn new(\n        generator: SummaryGenerator<C>,\n        budget_tracker: Arc<BudgetTracker>,\n        model_config: TieredModelConfig,\n    ) -> Self {\n        Self {\n            generator,\n            budget_tracker,\n            model_config,\n        }\n    }\n\n    pub fn check_budget(&self, layer: MemoryLayer) -> BudgetCheck {\n        self.budget_tracker.check(Some(layer))\n    }\n\n    pub fn model_for_layer(&self, layer: MemoryLayer) -> &str {\n        self.model_config.model_for_layer(layer)\n    }\n\n    pub async fn generate_with_budget(\n        &self,\n        request: BudgetAwareSummaryRequest,\n    ) -> Result<BudgetAwareSummaryResult, GenerationError> {\n        let span = info_span!(\n            \"context_architect.generate_with_budget\",\n            layer = ?request.layer,\n            depth = ?request.depth,\n            content_length = request.content.len()\n        );\n\n        async move {\n            let estimated_tokens = self.estimate_request_tokens(&request);\n            let model = self.model_config.model_for_layer(request.layer).to_string();\n\n            let budget_check = self\n                .budget_tracker\n                .try_consume(estimated_tokens as u64, request.layer)?;\n\n            if !budget_check.can_proceed() {\n                warn!(\n                    layer = ?request.layer,\n                    estimated_tokens = estimated_tokens,\n                    \"Budget exhausted for summarization request\"\n                );\n                return Err(GenerationError::BudgetExhausted(BudgetError::Exhausted {\n                    reason: format!(\n                        \"Budget exhausted for layer {:?}: {}% used\",\n                        request.layer, budget_check.percent_used\n                    ),\n                }));\n            }\n\n            let summary = self\n                .generator\n                .generate_summary_with_personalization(\n                    &request.content,\n                    request.depth,\n                    request.context.as_deref(),\n                    request.personalization_context.as_deref(),\n                )\n                .await?;\n\n            let actual_tokens = summary.token_count;\n            let token_diff = actual_tokens as i64 - estimated_tokens as i64;\n            if token_diff > 0 {\n                self.budget_tracker\n                    .record_usage(token_diff as u64, request.layer);\n            }\n\n            let final_check = self.budget_tracker.check(Some(request.layer));\n\n            Ok(BudgetAwareSummaryResult {\n                summary,\n                tokens_used: actual_tokens,\n                budget_check: final_check,\n                model_used: model,\n            })\n        }\n        .instrument(span)\n        .await\n    }\n\n    pub async fn generate_batch_with_budget(\n        &self,\n        requests: Vec<BudgetAwareSummaryRequest>,\n    ) -> Vec<Result<BudgetAwareSummaryResult, GenerationError>> {\n        let span = info_span!(\n            \"context_architect.generate_batch_with_budget\",\n            batch_size = requests.len()\n        );\n        let _enter = span.enter();\n\n        let mut results = Vec::with_capacity(requests.len());\n\n        for request in requests {\n            let budget_check = self.budget_tracker.check(Some(request.layer));\n            if !budget_check.can_proceed() {\n                results.push(Err(GenerationError::BudgetExhausted(\n                    BudgetError::Exhausted {\n                        reason: format!(\n                            \"Budget exhausted before processing: {}% used\",\n                            budget_check.percent_used\n                        ),\n                    },\n                )));\n                continue;\n            }\n\n            results.push(self.generate_with_budget(request).await);\n        }\n\n        results\n    }\n\n    fn estimate_request_tokens(&self, request: &BudgetAwareSummaryRequest) -> u32 {\n        let output_limit = self.generator.token_limit_for_depth(request.depth);\n        let input_estimate = estimate_tokens(&request.content);\n        let context_estimate = request\n            .context\n            .as_ref()\n            .map(|c| estimate_tokens(c))\n            .unwrap_or(0);\n\n        input_estimate + context_estimate + output_limit\n    }\n\n    pub fn budget_tracker(&self) -> &BudgetTracker {\n        &self.budget_tracker\n    }\n}\n\npub struct BatchedSummarizer<C: LlmClient> {\n    generator: Arc<BudgetAwareSummaryGenerator<C>>,\n    max_concurrent: usize,\n}\n\n#[derive(Debug, Clone)]\npub struct LayerBatchResult {\n    pub layer: MemoryLayer,\n    pub results: Vec<Result<BudgetAwareSummaryResult, GenerationError>>,\n    pub total_tokens: u64,\n    pub model_used: String,\n}\n\n#[derive(Debug, Clone)]\npub struct BatchedSummaryResult {\n    pub layer_results: Vec<LayerBatchResult>,\n    pub total_tokens: u64,\n    pub successful_count: usize,\n    pub failed_count: usize,\n}\n\nimpl<C: LlmClient> BatchedSummarizer<C> {\n    pub fn new(generator: Arc<BudgetAwareSummaryGenerator<C>>) -> Self {\n        Self {\n            generator,\n            max_concurrent: 4,\n        }\n    }\n\n    pub fn with_max_concurrent(mut self, max: usize) -> Self {\n        self.max_concurrent = max.max(1);\n        self\n    }\n\n    pub async fn process_batch(\n        &self,\n        requests: Vec<BudgetAwareSummaryRequest>,\n    ) -> BatchedSummaryResult {\n        let span = info_span!(\n            \"context_architect.batched_summarizer.process_batch\",\n            request_count = requests.len(),\n            max_concurrent = self.max_concurrent\n        );\n        let _enter = span.enter();\n\n        let grouped = self.group_by_layer(requests);\n        let layer_order = self.prioritize_layers(&grouped);\n\n        let mut layer_results = Vec::new();\n        let mut total_tokens = 0u64;\n        let mut successful_count = 0usize;\n        let mut failed_count = 0usize;\n\n        for layer in layer_order {\n            if let Some(layer_requests) = grouped.get(&layer) {\n                let budget_check = self.generator.check_budget(layer);\n                if !budget_check.can_proceed() {\n                    let failed_results: Vec<_> = layer_requests\n                        .iter()\n                        .map(|_| {\n                            Err(GenerationError::BudgetExhausted(BudgetError::Exhausted {\n                                reason: format!(\"Budget exhausted for layer {:?}\", layer),\n                            }))\n                        })\n                        .collect();\n\n                    failed_count += failed_results.len();\n                    layer_results.push(LayerBatchResult {\n                        layer,\n                        results: failed_results,\n                        total_tokens: 0,\n                        model_used: self.generator.model_for_layer(layer).to_string(),\n                    });\n                    continue;\n                }\n\n                let results = self.process_layer_batch(layer_requests).await;\n                let layer_tokens: u64 = results\n                    .iter()\n                    .filter_map(|r| r.as_ref().ok())\n                    .map(|r| r.tokens_used as u64)\n                    .sum();\n\n                successful_count += results.iter().filter(|r| r.is_ok()).count();\n                failed_count += results.iter().filter(|r| r.is_err()).count();\n                total_tokens += layer_tokens;\n\n                layer_results.push(LayerBatchResult {\n                    layer,\n                    results,\n                    total_tokens: layer_tokens,\n                    model_used: self.generator.model_for_layer(layer).to_string(),\n                });\n            }\n        }\n\n        BatchedSummaryResult {\n            layer_results,\n            total_tokens,\n            successful_count,\n            failed_count,\n        }\n    }\n\n    fn group_by_layer(\n        &self,\n        requests: Vec<BudgetAwareSummaryRequest>,\n    ) -> std::collections::HashMap<MemoryLayer, Vec<BudgetAwareSummaryRequest>> {\n        let mut grouped: std::collections::HashMap<MemoryLayer, Vec<BudgetAwareSummaryRequest>> =\n            std::collections::HashMap::new();\n\n        for request in requests {\n            grouped.entry(request.layer).or_default().push(request);\n        }\n\n        grouped\n    }\n\n    fn prioritize_layers(\n        &self,\n        grouped: &std::collections::HashMap<MemoryLayer, Vec<BudgetAwareSummaryRequest>>,\n    ) -> Vec<MemoryLayer> {\n        let layer_priority: std::collections::HashMap<MemoryLayer, u8> = [\n            (MemoryLayer::Company, 0),\n            (MemoryLayer::Org, 1),\n            (MemoryLayer::Team, 2),\n            (MemoryLayer::Project, 3),\n            (MemoryLayer::Session, 4),\n            (MemoryLayer::User, 5),\n            (MemoryLayer::Agent, 6),\n        ]\n        .into_iter()\n        .collect();\n\n        let mut layers: Vec<_> = grouped.keys().copied().collect();\n        layers.sort_by_key(|l| layer_priority.get(l).copied().unwrap_or(99));\n        layers\n    }\n\n    async fn process_layer_batch(\n        &self,\n        requests: &[BudgetAwareSummaryRequest],\n    ) -> Vec<Result<BudgetAwareSummaryResult, GenerationError>> {\n        let mut results = Vec::with_capacity(requests.len());\n\n        for request in requests {\n            results.push(self.generator.generate_with_budget(request.clone()).await);\n        }\n\n        results\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::sync::Mutex;\n\n    struct MockLlmClient {\n        responses: Mutex<Vec<String>>,\n    }\n\n    impl MockLlmClient {\n        fn new(responses: Vec<String>) -> Self {\n            Self {\n                responses: Mutex::new(responses),\n            }\n        }\n    }\n\n    #[async_trait::async_trait]\n    impl LlmClient for MockLlmClient {\n        async fn complete(&self, _prompt: &str) -> Result<String, LlmError> {\n            let mut responses = self.responses.lock().unwrap();\n            responses\n                .pop()\n                .ok_or_else(|| LlmError::InvalidResponse(\"No mock response\".into()))\n        }\n\n        async fn complete_with_system(\n            &self,\n            _system: &str,\n            _user: &str,\n        ) -> Result<String, LlmError> {\n            let mut responses = self.responses.lock().unwrap();\n            responses\n                .pop()\n                .ok_or_else(|| LlmError::InvalidResponse(\"No mock response\".into()))\n        }\n    }\n\n    #[tokio::test]\n    async fn test_generate_sentence_summary() {\n        let mock = Arc::new(MockLlmClient::new(vec![\n            \"This is a concise one-sentence summary.\".to_string(),\n        ]));\n        let generator = SummaryGenerator::new(mock, SummaryGeneratorConfig::default());\n\n        let content = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod \\\n                       tempor incididunt ut labore et dolore magna aliqua.\";\n\n        let result = generator\n            .generate_summary(content, SummaryDepth::Sentence, None)\n            .await\n            .unwrap();\n\n        assert_eq!(result.depth, SummaryDepth::Sentence);\n        assert!(!result.content.is_empty());\n        assert!(!result.source_hash.is_empty());\n        assert!(!result.personalized);\n    }\n\n    #[tokio::test]\n    async fn test_generate_paragraph_summary() {\n        let mock = Arc::new(MockLlmClient::new(vec![\n            \"This is a paragraph summary. It contains multiple sentences that provide more detail \\\n             about the content.\"\n                .to_string(),\n        ]));\n        let generator = SummaryGenerator::new(mock, SummaryGeneratorConfig::default());\n\n        let content = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod \\\n                       tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim \\\n                       veniam, quis nostrud exercitation ullamco laboris.\";\n\n        let result = generator\n            .generate_summary(content, SummaryDepth::Paragraph, None)\n            .await\n            .unwrap();\n\n        assert_eq!(result.depth, SummaryDepth::Paragraph);\n        assert!(result.token_count > 0);\n    }\n\n    #[tokio::test]\n    async fn test_generate_detailed_summary() {\n        let mock = Arc::new(MockLlmClient::new(vec![\n            \"This is a detailed summary with comprehensive information. It covers all the key \\\n             points from the original content. Multiple aspects are addressed including context \\\n             and implications.\"\n                .to_string(),\n        ]));\n        let generator = SummaryGenerator::new(mock, SummaryGeneratorConfig::default());\n\n        let content = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod \\\n                       tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim \\\n                       veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea \\\n                       commodo consequat. Duis aute irure dolor in reprehenderit in voluptate \\\n                       velit esse cillum dolore.\";\n\n        let result = generator\n            .generate_summary(content, SummaryDepth::Detailed, None)\n            .await\n            .unwrap();\n\n        assert_eq!(result.depth, SummaryDepth::Detailed);\n    }\n\n    #[tokio::test]\n    async fn test_generate_with_context() {\n        let mock = Arc::new(MockLlmClient::new(vec![\n            \"Summary considering the provided context.\".to_string(),\n        ]));\n        let generator = SummaryGenerator::new(mock, SummaryGeneratorConfig::default());\n\n        let content = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit.\";\n        let context = \"This is a technical document about software architecture.\";\n\n        let result = generator\n            .generate_summary(content, SummaryDepth::Sentence, Some(context))\n            .await\n            .unwrap();\n\n        assert_eq!(result.depth, SummaryDepth::Sentence);\n    }\n\n    #[tokio::test]\n    async fn test_generate_with_personalization() {\n        let mock = Arc::new(MockLlmClient::new(vec![\n            \"Personalized summary for developer context.\".to_string(),\n        ]));\n        let generator = SummaryGenerator::new(mock, SummaryGeneratorConfig::default());\n\n        let content = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit.\";\n        let personalization = \"developer\";\n\n        let result = generator\n            .generate_summary_with_personalization(\n                content,\n                SummaryDepth::Sentence,\n                None,\n                Some(personalization),\n            )\n            .await\n            .unwrap();\n\n        assert!(result.personalized);\n        assert_eq!(\n            result.personalization_context,\n            Some(\"developer\".to_string())\n        );\n    }\n\n    #[tokio::test]\n    async fn test_empty_content_error() {\n        let mock = Arc::new(MockLlmClient::new(vec![]));\n        let generator = SummaryGenerator::new(mock, SummaryGeneratorConfig::default());\n\n        let result = generator\n            .generate_summary(\"\", SummaryDepth::Sentence, None)\n            .await;\n\n        assert!(matches!(result, Err(GenerationError::EmptyContent)));\n    }\n\n    #[tokio::test]\n    async fn test_content_too_short_error() {\n        let mock = Arc::new(MockLlmClient::new(vec![]));\n        let generator = SummaryGenerator::new(mock, SummaryGeneratorConfig::default());\n\n        let result = generator\n            .generate_summary(\"Short\", SummaryDepth::Sentence, None)\n            .await;\n\n        assert!(matches!(\n            result,\n            Err(GenerationError::ContentTooShort { .. })\n        ));\n    }\n\n    #[tokio::test]\n    async fn test_batch_summarization() {\n        let mock = Arc::new(MockLlmClient::new(vec![\n            \"Summary 3\".to_string(),\n            \"Summary 2\".to_string(),\n            \"Summary 1\".to_string(),\n        ]));\n        let generator = SummaryGenerator::new(mock, SummaryGeneratorConfig::default());\n\n        let content = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod \\\n                       tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim \\\n                       veniam, quis nostrud exercitation ullamco laboris.\";\n        let requests = vec![\n            SummaryRequest {\n                content: content.to_string(),\n                depth: SummaryDepth::Sentence,\n                context: None,\n                personalization_context: None,\n            },\n            SummaryRequest {\n                content: content.to_string(),\n                depth: SummaryDepth::Paragraph,\n                context: None,\n                personalization_context: None,\n            },\n            SummaryRequest {\n                content: content.to_string(),\n                depth: SummaryDepth::Detailed,\n                context: None,\n                personalization_context: None,\n            },\n        ];\n\n        let result = generator.generate_batch(requests).await;\n\n        assert_eq!(result.results.len(), 3);\n        assert!(result.results.iter().all(|r| r.is_ok()));\n        assert!(result.total_tokens_used > 0);\n    }\n\n    #[tokio::test]\n    async fn test_batch_with_partial_failure() {\n        let mock = Arc::new(MockLlmClient::new(vec![\n            \"Summary for second request\".to_string(),\n        ]));\n        let generator = SummaryGenerator::new(mock, SummaryGeneratorConfig::default());\n\n        let valid_content = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do \\\n                             eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim \\\n                             ad minim veniam, quis nostrud exercitation ullamco laboris.\";\n        let requests = vec![\n            SummaryRequest {\n                content: \"Short\".to_string(),\n                depth: SummaryDepth::Sentence,\n                context: None,\n                personalization_context: None,\n            },\n            SummaryRequest {\n                content: valid_content.to_string(),\n                depth: SummaryDepth::Paragraph,\n                context: None,\n                personalization_context: None,\n            },\n        ];\n\n        let result = generator.generate_batch(requests).await;\n\n        assert_eq!(result.results.len(), 2);\n        assert!(result.results[0].is_err());\n        assert!(result.results[1].is_ok());\n    }\n\n    #[test]\n    fn test_estimate_tokens() {\n        assert!(estimate_tokens(\"Hello world\") >= 2);\n        assert!(estimate_tokens(\"A\") >= 1);\n        assert_eq!(estimate_tokens(\"\"), 0);\n\n        let long_text = \"The quick brown fox jumps over the lazy dog\";\n        let tokens = estimate_tokens(long_text);\n        assert!(tokens >= 9);\n        assert!(tokens <= 15);\n    }\n\n    #[test]\n    fn test_token_limits_by_depth() {\n        let mock = Arc::new(MockLlmClient::new(vec![]));\n        let config = SummaryGeneratorConfig {\n            sentence_max_tokens: 50,\n            paragraph_max_tokens: 200,\n            detailed_max_tokens: 500,\n            ..Default::default()\n        };\n        let generator = SummaryGenerator::new(mock, config);\n\n        assert_eq!(generator.token_limit_for_depth(SummaryDepth::Sentence), 50);\n        assert_eq!(\n            generator.token_limit_for_depth(SummaryDepth::Paragraph),\n            200\n        );\n        assert_eq!(generator.token_limit_for_depth(SummaryDepth::Detailed), 500);\n    }\n\n    #[test]\n    fn test_source_hash_consistency() {\n        let content = \"Test content for hashing\";\n        let hash1 = compute_content_hash(content);\n        let hash2 = compute_content_hash(content);\n\n        assert_eq!(hash1, hash2);\n        assert_eq!(hash1.len(), 16);\n    }\n\n    #[test]\n    fn test_source_hash_uniqueness() {\n        let hash1 = compute_content_hash(\"Content A\");\n        let hash2 = compute_content_hash(\"Content B\");\n\n        assert_ne!(hash1, hash2);\n    }\n\n    mod budget_aware_tests {\n        use super::*;\n        use crate::context_architect::budget::{\n            BudgetExhaustedAction, BudgetStatus, BudgetTrackerConfig, SummarizationBudget,\n        };\n\n        fn create_budget_tracker(daily_limit: u64, hourly_limit: u64) -> Arc<BudgetTracker> {\n            let config = BudgetTrackerConfig {\n                budget: SummarizationBudget::default()\n                    .with_daily_limit(daily_limit)\n                    .with_hourly_limit(hourly_limit),\n                exhausted_action: BudgetExhaustedAction::Reject,\n                enable_alerts: false,\n                queue_max_size: 10,\n            };\n            Arc::new(BudgetTracker::new(config))\n        }\n\n        fn create_budget_aware_generator(\n            responses: Vec<String>,\n            budget_tracker: Arc<BudgetTracker>,\n        ) -> BudgetAwareSummaryGenerator<MockLlmClient> {\n            let mock = Arc::new(MockLlmClient::new(responses));\n            let generator = SummaryGenerator::new(mock, SummaryGeneratorConfig::default());\n            BudgetAwareSummaryGenerator::new(\n                generator,\n                budget_tracker,\n                TieredModelConfig::default(),\n            )\n        }\n\n        #[tokio::test]\n        async fn test_generate_with_budget_success() {\n            let tracker = create_budget_tracker(1_000_000, 100_000);\n            let generator =\n                create_budget_aware_generator(vec![\"Budget-aware summary.\".to_string()], tracker);\n\n            let request = BudgetAwareSummaryRequest {\n                content: \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod \\\n                          tempor incididunt ut labore.\"\n                    .to_string(),\n                depth: SummaryDepth::Sentence,\n                layer: MemoryLayer::Session,\n                context: None,\n                personalization_context: None,\n            };\n\n            let result = generator.generate_with_budget(request).await;\n            assert!(result.is_ok());\n\n            let result = result.unwrap();\n            assert!(result.tokens_used > 0);\n            assert_eq!(result.budget_check.status, BudgetStatus::Available);\n            assert_eq!(result.model_used, \"gpt-4\");\n        }\n\n        #[tokio::test]\n        async fn test_generate_with_budget_exhausted() {\n            let tracker = create_budget_tracker(100, 100);\n            tracker.record_usage(100, MemoryLayer::Session);\n\n            let generator = create_budget_aware_generator(vec![], tracker);\n\n            let request = BudgetAwareSummaryRequest {\n                content: \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod \\\n                          tempor incididunt ut labore.\"\n                    .to_string(),\n                depth: SummaryDepth::Sentence,\n                layer: MemoryLayer::Session,\n                context: None,\n                personalization_context: None,\n            };\n\n            let result = generator.generate_with_budget(request).await;\n            assert!(result.is_err());\n            assert!(matches!(result, Err(GenerationError::BudgetExhausted(_))));\n        }\n\n        #[tokio::test]\n        async fn test_tiered_model_selection() {\n            let tracker = create_budget_tracker(1_000_000, 100_000);\n            let generator = create_budget_aware_generator(\n                vec![\n                    \"Company layer summary.\".to_string(),\n                    \"User layer summary.\".to_string(),\n                ],\n                tracker,\n            );\n\n            assert_eq!(generator.model_for_layer(MemoryLayer::User), \"gpt-4\");\n            assert_eq!(generator.model_for_layer(MemoryLayer::Session), \"gpt-4\");\n            assert_eq!(generator.model_for_layer(MemoryLayer::Agent), \"gpt-4\");\n\n            assert_eq!(\n                generator.model_for_layer(MemoryLayer::Company),\n                \"gpt-3.5-turbo\"\n            );\n            assert_eq!(generator.model_for_layer(MemoryLayer::Org), \"gpt-3.5-turbo\");\n            assert_eq!(\n                generator.model_for_layer(MemoryLayer::Project),\n                \"gpt-3.5-turbo\"\n            );\n        }\n\n        #[tokio::test]\n        async fn test_budget_check() {\n            let tracker = create_budget_tracker(1000, 500);\n            let generator = create_budget_aware_generator(vec![], tracker.clone());\n\n            tracker.record_usage(300, MemoryLayer::Session);\n\n            let check = generator.check_budget(MemoryLayer::Session);\n            assert_eq!(check.daily_used, 300);\n            assert_eq!(check.hourly_used, 300);\n            assert_eq!(check.layer_used, Some(300));\n        }\n\n        #[tokio::test]\n        async fn test_batch_with_budget_partial_exhaustion() {\n            let tracker = create_budget_tracker(500, 500);\n\n            let generator = create_budget_aware_generator(\n                vec![\"Summary 2.\".to_string(), \"Summary 1.\".to_string()],\n                tracker.clone(),\n            );\n\n            let content = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do \\\n                           eiusmod tempor incididunt ut labore et dolore magna aliqua.\"\n                .to_string();\n\n            let requests = vec![\n                BudgetAwareSummaryRequest {\n                    content: content.clone(),\n                    depth: SummaryDepth::Sentence,\n                    layer: MemoryLayer::Session,\n                    context: None,\n                    personalization_context: None,\n                },\n                BudgetAwareSummaryRequest {\n                    content: content.clone(),\n                    depth: SummaryDepth::Sentence,\n                    layer: MemoryLayer::Project,\n                    context: None,\n                    personalization_context: None,\n                },\n            ];\n\n            let results = generator.generate_batch_with_budget(requests).await;\n            assert_eq!(results.len(), 2);\n\n            let successful_count = results.iter().filter(|r| r.is_ok()).count();\n            assert!(successful_count >= 1);\n        }\n\n        #[tokio::test]\n        async fn test_budget_tracking_accumulation() {\n            let tracker = create_budget_tracker(10_000, 10_000);\n            let generator = create_budget_aware_generator(\n                vec![\n                    \"Third summary.\".to_string(),\n                    \"Second summary.\".to_string(),\n                    \"First summary.\".to_string(),\n                ],\n                tracker.clone(),\n            );\n\n            let content = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do \\\n                           eiusmod tempor incididunt ut labore.\"\n                .to_string();\n\n            for _ in 0..3 {\n                let request = BudgetAwareSummaryRequest {\n                    content: content.clone(),\n                    depth: SummaryDepth::Sentence,\n                    layer: MemoryLayer::Session,\n                    context: None,\n                    personalization_context: None,\n                };\n                let _ = generator.generate_with_budget(request).await;\n            }\n\n            let metrics = tracker.get_metrics();\n            assert!(metrics.daily_tokens_used > 0);\n            assert!(metrics.percent_used > 0.0);\n        }\n\n        #[tokio::test]\n        async fn test_batched_summarizer_groups_by_layer() {\n            let tracker = create_budget_tracker(100_000, 100_000);\n            let budget_aware_generator = Arc::new(create_budget_aware_generator(\n                vec![\n                    \"Company summary.\".to_string(),\n                    \"Org summary.\".to_string(),\n                    \"Session summary 2.\".to_string(),\n                    \"Session summary 1.\".to_string(),\n                ],\n                tracker,\n            ));\n            let batched = BatchedSummarizer::new(budget_aware_generator);\n\n            let content = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do \\\n                           eiusmod tempor incididunt ut labore.\"\n                .to_string();\n\n            let requests = vec![\n                BudgetAwareSummaryRequest {\n                    content: content.clone(),\n                    depth: SummaryDepth::Sentence,\n                    layer: MemoryLayer::Session,\n                    context: None,\n                    personalization_context: None,\n                },\n                BudgetAwareSummaryRequest {\n                    content: content.clone(),\n                    depth: SummaryDepth::Sentence,\n                    layer: MemoryLayer::Company,\n                    context: None,\n                    personalization_context: None,\n                },\n                BudgetAwareSummaryRequest {\n                    content: content.clone(),\n                    depth: SummaryDepth::Sentence,\n                    layer: MemoryLayer::Session,\n                    context: None,\n                    personalization_context: None,\n                },\n                BudgetAwareSummaryRequest {\n                    content: content.clone(),\n                    depth: SummaryDepth::Sentence,\n                    layer: MemoryLayer::Org,\n                    context: None,\n                    personalization_context: None,\n                },\n            ];\n\n            let result = batched.process_batch(requests).await;\n\n            assert_eq!(result.layer_results.len(), 3);\n            assert_eq!(result.successful_count, 4);\n            assert_eq!(result.failed_count, 0);\n\n            let layers: Vec<_> = result.layer_results.iter().map(|r| r.layer).collect();\n            assert_eq!(layers[0], MemoryLayer::Company);\n            assert_eq!(layers[1], MemoryLayer::Org);\n            assert_eq!(layers[2], MemoryLayer::Session);\n        }\n\n        #[tokio::test]\n        async fn test_batched_summarizer_respects_budget() {\n            let tracker = create_budget_tracker(200, 200);\n            tracker.record_usage(100, MemoryLayer::Session);\n\n            let budget_aware_generator = Arc::new(create_budget_aware_generator(\n                vec![\"Company summary.\".to_string()],\n                tracker,\n            ));\n            let batched = BatchedSummarizer::new(budget_aware_generator);\n\n            let content = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do \\\n                           eiusmod tempor incididunt ut labore.\"\n                .to_string();\n\n            let requests = vec![\n                BudgetAwareSummaryRequest {\n                    content: content.clone(),\n                    depth: SummaryDepth::Sentence,\n                    layer: MemoryLayer::Session,\n                    context: None,\n                    personalization_context: None,\n                },\n                BudgetAwareSummaryRequest {\n                    content: content.clone(),\n                    depth: SummaryDepth::Sentence,\n                    layer: MemoryLayer::Company,\n                    context: None,\n                    personalization_context: None,\n                },\n            ];\n\n            let result = batched.process_batch(requests).await;\n\n            assert!(result.failed_count >= 1);\n        }\n\n        #[tokio::test]\n        async fn test_batched_summarizer_layer_priority() {\n            let tracker = create_budget_tracker(100_000, 100_000);\n            let budget_aware_generator = Arc::new(create_budget_aware_generator(\n                vec![\n                    \"Agent summary.\".to_string(),\n                    \"User summary.\".to_string(),\n                    \"Company summary.\".to_string(),\n                ],\n                tracker,\n            ));\n            let batched = BatchedSummarizer::new(budget_aware_generator);\n\n            let content = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do \\\n                           eiusmod tempor incididunt ut labore.\"\n                .to_string();\n\n            let requests = vec![\n                BudgetAwareSummaryRequest {\n                    content: content.clone(),\n                    depth: SummaryDepth::Sentence,\n                    layer: MemoryLayer::Agent,\n                    context: None,\n                    personalization_context: None,\n                },\n                BudgetAwareSummaryRequest {\n                    content: content.clone(),\n                    depth: SummaryDepth::Sentence,\n                    layer: MemoryLayer::Company,\n                    context: None,\n                    personalization_context: None,\n                },\n                BudgetAwareSummaryRequest {\n                    content: content.clone(),\n                    depth: SummaryDepth::Sentence,\n                    layer: MemoryLayer::User,\n                    context: None,\n                    personalization_context: None,\n                },\n            ];\n\n            let result = batched.process_batch(requests).await;\n\n            let layers: Vec<_> = result.layer_results.iter().map(|r| r.layer).collect();\n            assert_eq!(layers[0], MemoryLayer::Company);\n            assert_eq!(layers[1], MemoryLayer::User);\n            assert_eq!(layers[2], MemoryLayer::Agent);\n        }\n    }\n}\n","traces":[{"line":22,"address":[],"length":0,"stats":{"Line":24}},{"line":83,"address":[],"length":0,"stats":{"Line":24}},{"line":87,"address":[],"length":0,"stats":{"Line":24}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":6}},{"line":102,"address":[],"length":0,"stats":{"Line":36}},{"line":103,"address":[],"length":0,"stats":{"Line":6}},{"line":106,"address":[],"length":0,"stats":{"Line":34}},{"line":113,"address":[],"length":0,"stats":{"Line":68}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":68}},{"line":117,"address":[],"length":0,"stats":{"Line":68}},{"line":118,"address":[],"length":0,"stats":{"Line":68}},{"line":121,"address":[],"length":0,"stats":{"Line":34}},{"line":122,"address":[],"length":0,"stats":{"Line":68}},{"line":123,"address":[],"length":0,"stats":{"Line":1}},{"line":126,"address":[],"length":0,"stats":{"Line":66}},{"line":127,"address":[],"length":0,"stats":{"Line":28}},{"line":128,"address":[],"length":0,"stats":{"Line":3}},{"line":129,"address":[],"length":0,"stats":{"Line":2}},{"line":132,"address":[],"length":0,"stats":{"Line":66}},{"line":133,"address":[],"length":0,"stats":{"Line":2}},{"line":134,"address":[],"length":0,"stats":{"Line":4}},{"line":135,"address":[],"length":0,"stats":{"Line":2}},{"line":139,"address":[],"length":0,"stats":{"Line":155}},{"line":140,"address":[],"length":0,"stats":{"Line":62}},{"line":141,"address":[],"length":0,"stats":{"Line":62}},{"line":142,"address":[],"length":0,"stats":{"Line":62}},{"line":143,"address":[],"length":0,"stats":{"Line":62}},{"line":144,"address":[],"length":0,"stats":{"Line":62}},{"line":147,"address":[],"length":0,"stats":{"Line":93}},{"line":148,"address":[],"length":0,"stats":{"Line":62}},{"line":149,"address":[],"length":0,"stats":{"Line":62}},{"line":150,"address":[],"length":0,"stats":{"Line":31}},{"line":152,"address":[],"length":0,"stats":{"Line":93}},{"line":153,"address":[],"length":0,"stats":{"Line":93}},{"line":154,"address":[],"length":0,"stats":{"Line":62}},{"line":155,"address":[],"length":0,"stats":{"Line":31}},{"line":156,"address":[],"length":0,"stats":{"Line":93}},{"line":159,"address":[],"length":0,"stats":{"Line":93}},{"line":160,"address":[],"length":0,"stats":{"Line":62}},{"line":162,"address":[],"length":0,"stats":{"Line":31}},{"line":163,"address":[],"length":0,"stats":{"Line":62}},{"line":164,"address":[],"length":0,"stats":{"Line":62}},{"line":165,"address":[],"length":0,"stats":{"Line":62}},{"line":166,"address":[],"length":0,"stats":{"Line":62}},{"line":167,"address":[],"length":0,"stats":{"Line":62}},{"line":168,"address":[],"length":0,"stats":{"Line":62}},{"line":169,"address":[],"length":0,"stats":{"Line":93}},{"line":170,"address":[],"length":0,"stats":{"Line":31}},{"line":173,"address":[],"length":0,"stats":{"Line":68}},{"line":174,"address":[],"length":0,"stats":{"Line":34}},{"line":177,"address":[],"length":0,"stats":{"Line":4}},{"line":178,"address":[],"length":0,"stats":{"Line":4}},{"line":180,"address":[],"length":0,"stats":{"Line":4}},{"line":183,"address":[],"length":0,"stats":{"Line":6}},{"line":185,"address":[],"length":0,"stats":{"Line":8}},{"line":186,"address":[],"length":0,"stats":{"Line":4}},{"line":188,"address":[],"length":0,"stats":{"Line":12}},{"line":189,"address":[],"length":0,"stats":{"Line":15}},{"line":191,"address":[],"length":0,"stats":{"Line":10}},{"line":192,"address":[],"length":0,"stats":{"Line":10}},{"line":193,"address":[],"length":0,"stats":{"Line":15}},{"line":194,"address":[],"length":0,"stats":{"Line":10}},{"line":196,"address":[],"length":0,"stats":{"Line":5}},{"line":198,"address":[],"length":0,"stats":{"Line":5}},{"line":199,"address":[],"length":0,"stats":{"Line":8}},{"line":200,"address":[],"length":0,"stats":{"Line":12}},{"line":201,"address":[],"length":0,"stats":{"Line":12}},{"line":202,"address":[],"length":0,"stats":{"Line":8}},{"line":203,"address":[],"length":0,"stats":{"Line":4}},{"line":206,"address":[],"length":0,"stats":{"Line":2}},{"line":207,"address":[],"length":0,"stats":{"Line":3}},{"line":218,"address":[],"length":0,"stats":{"Line":59}},{"line":219,"address":[],"length":0,"stats":{"Line":59}},{"line":220,"address":[],"length":0,"stats":{"Line":52}},{"line":221,"address":[],"length":0,"stats":{"Line":4}},{"line":222,"address":[],"length":0,"stats":{"Line":3}},{"line":227,"address":[],"length":0,"stats":{"Line":60}},{"line":228,"address":[],"length":0,"stats":{"Line":240}},{"line":229,"address":[],"length":0,"stats":{"Line":240}},{"line":233,"address":[],"length":0,"stats":{"Line":120}},{"line":234,"address":[],"length":0,"stats":{"Line":120}},{"line":236,"address":[],"length":0,"stats":{"Line":180}},{"line":239,"address":[],"length":0,"stats":{"Line":66}},{"line":240,"address":[],"length":0,"stats":{"Line":132}},{"line":241,"address":[],"length":0,"stats":{"Line":264}},{"line":242,"address":[],"length":0,"stats":{"Line":198}},{"line":243,"address":[],"length":0,"stats":{"Line":132}},{"line":270,"address":[],"length":0,"stats":{"Line":14}},{"line":282,"address":[],"length":0,"stats":{"Line":14}},{"line":283,"address":[],"length":0,"stats":{"Line":28}},{"line":286,"address":[],"length":0,"stats":{"Line":19}},{"line":287,"address":[],"length":0,"stats":{"Line":38}},{"line":290,"address":[],"length":0,"stats":{"Line":25}},{"line":294,"address":[],"length":0,"stats":{"Line":50}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":298,"address":[],"length":0,"stats":{"Line":50}},{"line":301,"address":[],"length":0,"stats":{"Line":25}},{"line":302,"address":[],"length":0,"stats":{"Line":100}},{"line":303,"address":[],"length":0,"stats":{"Line":100}},{"line":305,"address":[],"length":0,"stats":{"Line":72}},{"line":306,"address":[],"length":0,"stats":{"Line":50}},{"line":307,"address":[],"length":0,"stats":{"Line":53}},{"line":309,"address":[],"length":0,"stats":{"Line":22}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":323,"address":[],"length":0,"stats":{"Line":66}},{"line":324,"address":[],"length":0,"stats":{"Line":44}},{"line":326,"address":[],"length":0,"stats":{"Line":44}},{"line":327,"address":[],"length":0,"stats":{"Line":44}},{"line":328,"address":[],"length":0,"stats":{"Line":66}},{"line":329,"address":[],"length":0,"stats":{"Line":44}},{"line":331,"address":[],"length":0,"stats":{"Line":22}},{"line":333,"address":[],"length":0,"stats":{"Line":44}},{"line":334,"address":[],"length":0,"stats":{"Line":44}},{"line":335,"address":[],"length":0,"stats":{"Line":22}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":337,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":66}},{"line":342,"address":[],"length":0,"stats":{"Line":22}},{"line":343,"address":[],"length":0,"stats":{"Line":44}},{"line":344,"address":[],"length":0,"stats":{"Line":44}},{"line":345,"address":[],"length":0,"stats":{"Line":22}},{"line":346,"address":[],"length":0,"stats":{"Line":22}},{"line":349,"address":[],"length":0,"stats":{"Line":50}},{"line":350,"address":[],"length":0,"stats":{"Line":25}},{"line":353,"address":[],"length":0,"stats":{"Line":1}},{"line":357,"address":[],"length":0,"stats":{"Line":2}},{"line":359,"address":[],"length":0,"stats":{"Line":2}},{"line":361,"address":[],"length":0,"stats":{"Line":3}},{"line":363,"address":[],"length":0,"stats":{"Line":4}},{"line":365,"address":[],"length":0,"stats":{"Line":5}},{"line":366,"address":[],"length":0,"stats":{"Line":6}},{"line":367,"address":[],"length":0,"stats":{"Line":2}},{"line":368,"address":[],"length":0,"stats":{"Line":0}},{"line":369,"address":[],"length":0,"stats":{"Line":0}},{"line":370,"address":[],"length":0,"stats":{"Line":0}},{"line":371,"address":[],"length":0,"stats":{"Line":0}},{"line":372,"address":[],"length":0,"stats":{"Line":0}},{"line":376,"address":[],"length":0,"stats":{"Line":0}},{"line":379,"address":[],"length":0,"stats":{"Line":10}},{"line":382,"address":[],"length":0,"stats":{"Line":1}},{"line":385,"address":[],"length":0,"stats":{"Line":25}},{"line":386,"address":[],"length":0,"stats":{"Line":100}},{"line":387,"address":[],"length":0,"stats":{"Line":75}},{"line":388,"address":[],"length":0,"stats":{"Line":50}},{"line":389,"address":[],"length":0,"stats":{"Line":25}},{"line":391,"address":[],"length":0,"stats":{"Line":25}},{"line":394,"address":[],"length":0,"stats":{"Line":25}},{"line":397,"address":[],"length":0,"stats":{"Line":0}},{"line":398,"address":[],"length":0,"stats":{"Line":0}},{"line":424,"address":[],"length":0,"stats":{"Line":5}},{"line":431,"address":[],"length":0,"stats":{"Line":0}},{"line":432,"address":[],"length":0,"stats":{"Line":0}},{"line":433,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":5}},{"line":440,"address":[],"length":0,"stats":{"Line":10}},{"line":442,"address":[],"length":0,"stats":{"Line":10}},{"line":443,"address":[],"length":0,"stats":{"Line":0}},{"line":445,"address":[],"length":0,"stats":{"Line":15}},{"line":447,"address":[],"length":0,"stats":{"Line":20}},{"line":448,"address":[],"length":0,"stats":{"Line":20}},{"line":450,"address":[],"length":0,"stats":{"Line":10}},{"line":451,"address":[],"length":0,"stats":{"Line":10}},{"line":452,"address":[],"length":0,"stats":{"Line":10}},{"line":453,"address":[],"length":0,"stats":{"Line":10}},{"line":455,"address":[],"length":0,"stats":{"Line":31}},{"line":456,"address":[],"length":0,"stats":{"Line":39}},{"line":457,"address":[],"length":0,"stats":{"Line":39}},{"line":458,"address":[],"length":0,"stats":{"Line":13}},{"line":459,"address":[],"length":0,"stats":{"Line":0}},{"line":461,"address":[],"length":0,"stats":{"Line":0}},{"line":462,"address":[],"length":0,"stats":{"Line":0}},{"line":463,"address":[],"length":0,"stats":{"Line":0}},{"line":468,"address":[],"length":0,"stats":{"Line":0}},{"line":469,"address":[],"length":0,"stats":{"Line":0}},{"line":470,"address":[],"length":0,"stats":{"Line":0}},{"line":471,"address":[],"length":0,"stats":{"Line":0}},{"line":472,"address":[],"length":0,"stats":{"Line":0}},{"line":473,"address":[],"length":0,"stats":{"Line":0}},{"line":475,"address":[],"length":0,"stats":{"Line":0}},{"line":478,"address":[],"length":0,"stats":{"Line":52}},{"line":479,"address":[],"length":0,"stats":{"Line":39}},{"line":481,"address":[],"length":0,"stats":{"Line":55}},{"line":482,"address":[],"length":0,"stats":{"Line":26}},{"line":485,"address":[],"length":0,"stats":{"Line":67}},{"line":486,"address":[],"length":0,"stats":{"Line":67}},{"line":487,"address":[],"length":0,"stats":{"Line":13}},{"line":489,"address":[],"length":0,"stats":{"Line":39}},{"line":490,"address":[],"length":0,"stats":{"Line":26}},{"line":491,"address":[],"length":0,"stats":{"Line":26}},{"line":492,"address":[],"length":0,"stats":{"Line":26}},{"line":493,"address":[],"length":0,"stats":{"Line":26}},{"line":506,"address":[],"length":0,"stats":{"Line":5}},{"line":510,"address":[],"length":0,"stats":{"Line":10}},{"line":511,"address":[],"length":0,"stats":{"Line":5}},{"line":513,"address":[],"length":0,"stats":{"Line":47}},{"line":514,"address":[],"length":0,"stats":{"Line":56}},{"line":517,"address":[],"length":0,"stats":{"Line":5}},{"line":520,"address":[],"length":0,"stats":{"Line":5}},{"line":524,"address":[],"length":0,"stats":{"Line":15}},{"line":525,"address":[],"length":0,"stats":{"Line":10}},{"line":526,"address":[],"length":0,"stats":{"Line":10}},{"line":527,"address":[],"length":0,"stats":{"Line":10}},{"line":528,"address":[],"length":0,"stats":{"Line":10}},{"line":529,"address":[],"length":0,"stats":{"Line":10}},{"line":530,"address":[],"length":0,"stats":{"Line":5}},{"line":531,"address":[],"length":0,"stats":{"Line":5}},{"line":536,"address":[],"length":0,"stats":{"Line":30}},{"line":537,"address":[],"length":0,"stats":{"Line":100}},{"line":538,"address":[],"length":0,"stats":{"Line":5}},{"line":541,"address":[],"length":0,"stats":{"Line":13}},{"line":545,"address":[],"length":0,"stats":{"Line":52}},{"line":547,"address":[],"length":0,"stats":{"Line":41}},{"line":548,"address":[],"length":0,"stats":{"Line":70}},{"line":551,"address":[],"length":0,"stats":{"Line":13}}],"covered":187,"coverable":226},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","context_architect","mod.rs"],"content":"//! # Context Architect\n//!\n//! Hierarchical context compression for efficient memory storage.\n//! Implements the CCA (Confucius Code Agent) Context Architect pattern.\n\nmod assembler;\nmod budget;\nmod compressor;\nmod failure_handling;\nmod generator;\nmod prompts;\nmod triggers;\n\npub use assembler::{\n    AssembledContext, AssemblerConfig, ContextAssembler, ContextEntry, ContextMetadata,\n    ContextView, SummarySource, cosine_similarity,\n};\npub use budget::{\n    BudgetCheck, BudgetError, BudgetExhaustedAction, BudgetMetrics, BudgetStatus, BudgetTracker,\n    BudgetTrackerConfig, QueuedRequest, SummarizationBudget, TieredModelConfig,\n};\npub use compressor::{\n    CompressedEntry, CompressedLayer, CompressionResult, CompressorConfig, HierarchicalCompressor,\n    LayerContent, LayerEntry, ViewMode,\n};\npub use failure_handling::{\n    CachedSummaryStore, CircuitBreaker, CircuitBreakerConfig, CircuitState, FailureMetrics,\n    RetryConfig, alert_on_consecutive_failures, retry_with_backoff,\n};\npub use generator::{\n    BatchSummaryRequest, BatchSummaryResult, BatchedSummarizer,\n    BatchedSummaryResult as BatchedResult, BudgetAwareSummaryGenerator, BudgetAwareSummaryRequest,\n    BudgetAwareSummaryResult, GenerationError, LayerBatchResult, SummaryGenerator,\n    SummaryGeneratorConfig, SummaryRequest, SummaryResult, estimate_tokens,\n};\npub use prompts::{PromptTemplate, PromptTemplates};\npub use triggers::{\n    EntryState, SummaryState, SummaryTriggerMonitor, TriggerMonitorConfig, TriggerReason,\n    TriggerResult,\n};\n\nuse async_trait::async_trait;\n\n#[async_trait]\npub trait LlmClient: Send + Sync {\n    async fn complete(&self, prompt: &str) -> Result<String, LlmError>;\n\n    async fn complete_with_system(&self, system: &str, user: &str) -> Result<String, LlmError>;\n}\n\n#[derive(Debug, Clone, thiserror::Error)]\npub enum LlmError {\n    #[error(\"API request failed: {0}\")]\n    RequestFailed(String),\n\n    #[error(\"Rate limited: retry after {retry_after_secs} seconds\")]\n    RateLimited { retry_after_secs: u64 },\n\n    #[error(\"Invalid response: {0}\")]\n    InvalidResponse(String),\n\n    #[error(\"Provider not configured: {0}\")]\n    NotConfigured(String),\n\n    #[error(\"Timeout after {0} seconds\")]\n    Timeout(u64),\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","context_architect","prompts.rs"],"content":"use mk_core::types::SummaryDepth;\n\n#[derive(Debug, Clone)]\npub struct PromptTemplate {\n    pub system: String,\n    pub user: String,\n}\n\n#[derive(Debug, Clone)]\npub struct PromptTemplates {\n    pub sentence: PromptTemplate,\n    pub paragraph: PromptTemplate,\n    pub detailed: PromptTemplate,\n}\n\nimpl Default for PromptTemplates {\n    fn default() -> Self {\n        Self {\n            sentence: PromptTemplate {\n                system: SENTENCE_SYSTEM.to_string(),\n                user: SENTENCE_USER.to_string(),\n            },\n            paragraph: PromptTemplate {\n                system: PARAGRAPH_SYSTEM.to_string(),\n                user: PARAGRAPH_USER.to_string(),\n            },\n            detailed: PromptTemplate {\n                system: DETAILED_SYSTEM.to_string(),\n                user: DETAILED_USER.to_string(),\n            },\n        }\n    }\n}\n\nimpl PromptTemplates {\n    pub fn get_template(&self, depth: SummaryDepth) -> &PromptTemplate {\n        match depth {\n            SummaryDepth::Sentence => &self.sentence,\n            SummaryDepth::Paragraph => &self.paragraph,\n            SummaryDepth::Detailed => &self.detailed,\n        }\n    }\n\n    pub fn build_prompt(\n        &self,\n        content: &str,\n        depth: SummaryDepth,\n        context: Option<&str>,\n        personalization: Option<&str>,\n        max_tokens: u32,\n    ) -> (String, String) {\n        let template = self.get_template(depth);\n\n        let system = self.build_system_prompt(&template.system, personalization);\n        let user = self.build_user_prompt(&template.user, content, context, max_tokens);\n\n        (system, user)\n    }\n\n    fn build_system_prompt(&self, base: &str, personalization: Option<&str>) -> String {\n        match personalization {\n            Some(ctx) => format!(\"{base}\\n\\nPersonalization context: {ctx}\"),\n            None => base.to_string(),\n        }\n    }\n\n    fn build_user_prompt(\n        &self,\n        base: &str,\n        content: &str,\n        context: Option<&str>,\n        max_tokens: u32,\n    ) -> String {\n        let context_section = context\n            .map(|c| format!(\"Context: {c}\\n\\n\"))\n            .unwrap_or_default();\n\n        base.replace(\"{content}\", content)\n            .replace(\"{context}\", &context_section)\n            .replace(\"{max_tokens}\", &max_tokens.to_string())\n    }\n}\n\nconst SENTENCE_SYSTEM: &str = \"\\\nYou are a precise summarization assistant. Your task is to distill content into exactly ONE clear, \\\n                               informative sentence. Focus on the most critical information. \\\n                               Never use phrases like 'This document describes...' or 'The \\\n                               content covers...'. State the key point directly.\";\n\nconst SENTENCE_USER: &str = \"\\\n{context}Summarize the following content in exactly ONE sentence (maximum {max_tokens} tokens):\n\n{content}\";\n\nconst PARAGRAPH_SYSTEM: &str = \"\\\nYou are a summarization assistant specializing in concise paragraph summaries. Your task is to \\\n                                capture all key points in a single well-structured paragraph. \\\n                                Maintain logical flow and ensure completeness. Avoid introductory \\\n                                phrases and filler content.\";\n\nconst PARAGRAPH_USER: &str = \"\\\n{context}Summarize the following content in ONE paragraph (maximum {max_tokens} tokens). Include \\\n                              all significant points while maintaining clarity:\n\n{content}\";\n\nconst DETAILED_SYSTEM: &str = \"\\\nYou are a comprehensive summarization assistant. Your task is to create detailed summaries that \\\n                               preserve important nuances, context, and relationships within the \\\n                               content. Use clear structure with bullet points if appropriate. \\\n                               Maintain the original meaning while being concise.\";\n\nconst DETAILED_USER: &str = \"\\\n{context}Create a detailed summary of the following content (maximum {max_tokens} tokens). \\\n                             Preserve key details, relationships, and nuances:\n\n{content}\";\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_default_templates_exist() {\n        let templates = PromptTemplates::default();\n\n        assert!(!templates.sentence.system.is_empty());\n        assert!(!templates.sentence.user.is_empty());\n        assert!(!templates.paragraph.system.is_empty());\n        assert!(!templates.paragraph.user.is_empty());\n        assert!(!templates.detailed.system.is_empty());\n        assert!(!templates.detailed.user.is_empty());\n    }\n\n    #[test]\n    fn test_get_template_by_depth() {\n        let templates = PromptTemplates::default();\n\n        let sentence = templates.get_template(SummaryDepth::Sentence);\n        let paragraph = templates.get_template(SummaryDepth::Paragraph);\n        let detailed = templates.get_template(SummaryDepth::Detailed);\n\n        assert!(sentence.system.contains(\"ONE\"));\n        assert!(paragraph.system.contains(\"paragraph\"));\n        assert!(detailed.system.contains(\"detailed\"));\n    }\n\n    #[test]\n    fn test_build_prompt_basic() {\n        let templates = PromptTemplates::default();\n        let content = \"Test content here\";\n\n        let (system, user) =\n            templates.build_prompt(content, SummaryDepth::Sentence, None, None, 50);\n\n        assert!(!system.is_empty());\n        assert!(user.contains(\"Test content here\"));\n        assert!(user.contains(\"50\"));\n    }\n\n    #[test]\n    fn test_build_prompt_with_context() {\n        let templates = PromptTemplates::default();\n        let content = \"Test content\";\n        let context = \"Technical documentation\";\n\n        let (_, user) =\n            templates.build_prompt(content, SummaryDepth::Paragraph, Some(context), None, 200);\n\n        assert!(user.contains(\"Context: Technical documentation\"));\n        assert!(user.contains(\"Test content\"));\n    }\n\n    #[test]\n    fn test_build_prompt_with_personalization() {\n        let templates = PromptTemplates::default();\n        let content = \"Test content\";\n        let personalization = \"developer audience\";\n\n        let (system, _) = templates.build_prompt(\n            content,\n            SummaryDepth::Detailed,\n            None,\n            Some(personalization),\n            500,\n        );\n\n        assert!(system.contains(\"Personalization context: developer audience\"));\n    }\n\n    #[test]\n    fn test_build_prompt_with_all_options() {\n        let templates = PromptTemplates::default();\n        let content = \"Complex technical content\";\n        let context = \"API documentation\";\n        let personalization = \"senior engineers\";\n\n        let (system, user) = templates.build_prompt(\n            content,\n            SummaryDepth::Detailed,\n            Some(context),\n            Some(personalization),\n            500,\n        );\n\n        assert!(system.contains(\"senior engineers\"));\n        assert!(user.contains(\"API documentation\"));\n        assert!(user.contains(\"Complex technical content\"));\n        assert!(user.contains(\"500\"));\n    }\n\n    #[test]\n    fn test_sentence_template_constraints() {\n        let templates = PromptTemplates::default();\n        let template = templates.get_template(SummaryDepth::Sentence);\n\n        assert!(template.system.contains(\"ONE\"));\n        assert!(template.system.contains(\"sentence\"));\n        assert!(template.user.contains(\"{content}\"));\n        assert!(template.user.contains(\"{max_tokens}\"));\n    }\n\n    #[test]\n    fn test_paragraph_template_constraints() {\n        let templates = PromptTemplates::default();\n        let template = templates.get_template(SummaryDepth::Paragraph);\n\n        assert!(template.system.contains(\"paragraph\"));\n        assert!(template.user.contains(\"{content}\"));\n    }\n\n    #[test]\n    fn test_detailed_template_constraints() {\n        let templates = PromptTemplates::default();\n        let template = templates.get_template(SummaryDepth::Detailed);\n\n        assert!(template.system.contains(\"detailed\"));\n        assert!(template.system.contains(\"comprehensive\"));\n    }\n\n    #[test]\n    fn test_custom_templates() {\n        let custom = PromptTemplates {\n            sentence: PromptTemplate {\n                system: \"Custom system\".to_string(),\n                user: \"Custom user: {content}\".to_string(),\n            },\n            paragraph: PromptTemplate {\n                system: \"Para system\".to_string(),\n                user: \"Para user: {content}\".to_string(),\n            },\n            detailed: PromptTemplate {\n                system: \"Detail system\".to_string(),\n                user: \"Detail user: {content}\".to_string(),\n            },\n        };\n\n        let (system, user) = custom.build_prompt(\"Test\", SummaryDepth::Sentence, None, None, 50);\n\n        assert_eq!(system, \"Custom system\");\n        assert!(user.contains(\"Custom user\"));\n    }\n}\n","traces":[{"line":17,"address":[],"length":0,"stats":{"Line":33}},{"line":19,"address":[],"length":0,"stats":{"Line":66}},{"line":23,"address":[],"length":0,"stats":{"Line":66}},{"line":27,"address":[],"length":0,"stats":{"Line":33}},{"line":36,"address":[],"length":0,"stats":{"Line":42}},{"line":37,"address":[],"length":0,"stats":{"Line":42}},{"line":38,"address":[],"length":0,"stats":{"Line":30}},{"line":39,"address":[],"length":0,"stats":{"Line":6}},{"line":40,"address":[],"length":0,"stats":{"Line":6}},{"line":44,"address":[],"length":0,"stats":{"Line":36}},{"line":52,"address":[],"length":0,"stats":{"Line":144}},{"line":54,"address":[],"length":0,"stats":{"Line":180}},{"line":55,"address":[],"length":0,"stats":{"Line":252}},{"line":57,"address":[],"length":0,"stats":{"Line":36}},{"line":60,"address":[],"length":0,"stats":{"Line":36}},{"line":61,"address":[],"length":0,"stats":{"Line":36}},{"line":62,"address":[],"length":0,"stats":{"Line":9}},{"line":63,"address":[],"length":0,"stats":{"Line":66}},{"line":67,"address":[],"length":0,"stats":{"Line":36}},{"line":74,"address":[],"length":0,"stats":{"Line":72}},{"line":75,"address":[],"length":0,"stats":{"Line":42}},{"line":78,"address":[],"length":0,"stats":{"Line":144}},{"line":79,"address":[],"length":0,"stats":{"Line":72}},{"line":80,"address":[],"length":0,"stats":{"Line":72}}],"covered":24,"coverable":24},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","context_architect","triggers.rs"],"content":"use std::collections::HashMap;\nuse std::time::{SystemTime, UNIX_EPOCH};\n\nuse mk_core::types::{MemoryLayer, SummaryConfig, SummaryDepth};\nuse tokio::sync::RwLock;\n\n#[derive(Debug, Clone)]\npub struct TriggerMonitorConfig {\n    pub default_check_interval_secs: u64,\n    pub enable_time_based_triggers: bool,\n    pub enable_change_count_triggers: bool,\n    pub enable_hash_based_triggers: bool,\n}\n\nimpl Default for TriggerMonitorConfig {\n    fn default() -> Self {\n        Self {\n            default_check_interval_secs: 300,\n            enable_time_based_triggers: true,\n            enable_change_count_triggers: true,\n            enable_hash_based_triggers: true,\n        }\n    }\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub enum TriggerReason {\n    TimeThresholdExceeded {\n        age_seconds: u64,\n        threshold_seconds: u64,\n    },\n    ChangeCountExceeded {\n        change_count: u32,\n        threshold: u32,\n    },\n    SourceHashChanged {\n        previous_hash: String,\n        new_hash: String,\n    },\n    NoExistingSummary,\n    ManualRefresh,\n    ParentSummaryInvalidated {\n        parent_layer: MemoryLayer,\n    },\n}\n\n#[derive(Debug, Clone)]\npub struct TriggerResult {\n    pub entry_id: String,\n    pub layer: MemoryLayer,\n    pub depth: SummaryDepth,\n    pub reason: TriggerReason,\n    pub triggered_at: i64,\n}\n\n#[derive(Debug, Clone)]\npub struct EntryState {\n    pub entry_id: String,\n    pub layer: MemoryLayer,\n    pub source_hash: String,\n    pub change_count: u32,\n    pub summaries: HashMap<SummaryDepth, SummaryState>,\n    pub last_modified_at: i64,\n}\n\n#[derive(Debug, Clone)]\npub struct SummaryState {\n    pub content_hash: String,\n    pub generated_at: i64,\n    pub is_stale: bool,\n}\n\npub struct SummaryTriggerMonitor {\n    config: TriggerMonitorConfig,\n    layer_configs: RwLock<HashMap<MemoryLayer, SummaryConfig>>,\n    entry_states: RwLock<HashMap<String, EntryState>>,\n}\n\nimpl SummaryTriggerMonitor {\n    pub fn new(config: TriggerMonitorConfig) -> Self {\n        Self {\n            config,\n            layer_configs: RwLock::new(HashMap::new()),\n            entry_states: RwLock::new(HashMap::new()),\n        }\n    }\n\n    pub async fn register_layer_config(&self, config: SummaryConfig) {\n        let mut configs = self.layer_configs.write().await;\n        configs.insert(config.layer, config);\n    }\n\n    pub async fn get_layer_config(&self, layer: MemoryLayer) -> Option<SummaryConfig> {\n        let configs = self.layer_configs.read().await;\n        configs.get(&layer).cloned()\n    }\n\n    pub async fn record_change(&self, entry_id: &str, layer: MemoryLayer, new_source_hash: &str) {\n        let mut states = self.entry_states.write().await;\n        let now = current_timestamp();\n\n        let entry = states\n            .entry(entry_id.to_string())\n            .or_insert_with(|| EntryState {\n                entry_id: entry_id.to_string(),\n                layer,\n                source_hash: new_source_hash.to_string(),\n                change_count: 0,\n                summaries: HashMap::new(),\n                last_modified_at: now,\n            });\n\n        entry.change_count += 1;\n        entry.source_hash = new_source_hash.to_string();\n        entry.last_modified_at = now;\n    }\n\n    pub async fn record_summary_generated(\n        &self,\n        entry_id: &str,\n        layer: MemoryLayer,\n        depth: SummaryDepth,\n        content_hash: &str,\n        source_hash: &str,\n    ) {\n        let mut states = self.entry_states.write().await;\n        let now = current_timestamp();\n\n        let entry = states\n            .entry(entry_id.to_string())\n            .or_insert_with(|| EntryState {\n                entry_id: entry_id.to_string(),\n                layer,\n                source_hash: source_hash.to_string(),\n                change_count: 0,\n                summaries: HashMap::new(),\n                last_modified_at: now,\n            });\n\n        entry.summaries.insert(\n            depth,\n            SummaryState {\n                content_hash: content_hash.to_string(),\n                generated_at: now,\n                is_stale: false,\n            },\n        );\n\n        entry.change_count = 0;\n        entry.source_hash = source_hash.to_string();\n    }\n\n    pub async fn mark_stale(&self, entry_id: &str, depth: SummaryDepth) {\n        let mut states = self.entry_states.write().await;\n        if let Some(entry) = states.get_mut(entry_id) {\n            if let Some(summary) = entry.summaries.get_mut(&depth) {\n                summary.is_stale = true;\n            }\n        }\n    }\n\n    pub async fn should_update_summary(\n        &self,\n        entry_id: &str,\n        layer: MemoryLayer,\n        depth: SummaryDepth,\n        current_source_hash: &str,\n    ) -> Option<TriggerResult> {\n        let configs = self.layer_configs.read().await;\n        let config = configs.get(&layer)?;\n\n        if !config.depths.contains(&depth) {\n            return None;\n        }\n\n        let states = self.entry_states.read().await;\n        let now = current_timestamp();\n\n        match states.get(entry_id) {\n            None => Some(TriggerResult {\n                entry_id: entry_id.to_string(),\n                layer,\n                depth,\n                reason: TriggerReason::NoExistingSummary,\n                triggered_at: now,\n            }),\n            Some(entry) => {\n                self.check_entry_triggers(entry, depth, current_source_hash, config, now)\n            }\n        }\n    }\n\n    pub async fn check_all_entries(&self) -> Vec<TriggerResult> {\n        let configs = self.layer_configs.read().await;\n        let states = self.entry_states.read().await;\n        let now = current_timestamp();\n        let mut results = Vec::new();\n\n        for (_, entry) in states.iter() {\n            if let Some(config) = configs.get(&entry.layer) {\n                for depth in &config.depths {\n                    if let Some(trigger) =\n                        self.check_entry_triggers(entry, *depth, &entry.source_hash, config, now)\n                    {\n                        results.push(trigger);\n                    }\n                }\n            }\n        }\n\n        results\n    }\n\n    pub async fn get_entries_needing_update(&self, layer: MemoryLayer) -> Vec<TriggerResult> {\n        let configs = self.layer_configs.read().await;\n        let config = match configs.get(&layer) {\n            Some(c) => c,\n            None => return Vec::new(),\n        };\n\n        let states = self.entry_states.read().await;\n        let now = current_timestamp();\n        let mut results = Vec::new();\n\n        for (_, entry) in states.iter() {\n            if entry.layer != layer {\n                continue;\n            }\n\n            for depth in &config.depths {\n                if let Some(trigger) =\n                    self.check_entry_triggers(entry, *depth, &entry.source_hash, config, now)\n                {\n                    results.push(trigger);\n                }\n            }\n        }\n\n        results\n    }\n\n    fn check_entry_triggers(\n        &self,\n        entry: &EntryState,\n        depth: SummaryDepth,\n        current_source_hash: &str,\n        config: &SummaryConfig,\n        now: i64,\n    ) -> Option<TriggerResult> {\n        match entry.summaries.get(&depth) {\n            None => Some(TriggerResult {\n                entry_id: entry.entry_id.clone(),\n                layer: entry.layer,\n                depth,\n                reason: TriggerReason::NoExistingSummary,\n                triggered_at: now,\n            }),\n            Some(summary) => {\n                if summary.is_stale {\n                    return Some(TriggerResult {\n                        entry_id: entry.entry_id.clone(),\n                        layer: entry.layer,\n                        depth,\n                        reason: TriggerReason::ManualRefresh,\n                        triggered_at: now,\n                    });\n                }\n\n                if self.config.enable_hash_based_triggers\n                    && entry.source_hash != current_source_hash\n                {\n                    return Some(TriggerResult {\n                        entry_id: entry.entry_id.clone(),\n                        layer: entry.layer,\n                        depth,\n                        reason: TriggerReason::SourceHashChanged {\n                            previous_hash: entry.source_hash.clone(),\n                            new_hash: current_source_hash.to_string(),\n                        },\n                        triggered_at: now,\n                    });\n                }\n\n                if self.config.enable_time_based_triggers {\n                    if let Some(interval) = config.update_interval_secs {\n                        let age = (now - summary.generated_at) as u64;\n                        if age >= interval {\n                            return Some(TriggerResult {\n                                entry_id: entry.entry_id.clone(),\n                                layer: entry.layer,\n                                depth,\n                                reason: TriggerReason::TimeThresholdExceeded {\n                                    age_seconds: age,\n                                    threshold_seconds: interval,\n                                },\n                                triggered_at: now,\n                            });\n                        }\n                    }\n                }\n\n                if self.config.enable_change_count_triggers {\n                    if let Some(threshold) = config.update_on_changes {\n                        if entry.change_count >= threshold {\n                            return Some(TriggerResult {\n                                entry_id: entry.entry_id.clone(),\n                                layer: entry.layer,\n                                depth,\n                                reason: TriggerReason::ChangeCountExceeded {\n                                    change_count: entry.change_count,\n                                    threshold,\n                                },\n                                triggered_at: now,\n                            });\n                        }\n                    }\n                }\n\n                None\n            }\n        }\n    }\n\n    pub async fn clear_entry(&self, entry_id: &str) {\n        let mut states = self.entry_states.write().await;\n        states.remove(entry_id);\n    }\n\n    pub async fn entry_count(&self) -> usize {\n        let states = self.entry_states.read().await;\n        states.len()\n    }\n}\n\nfn current_timestamp() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or(0)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    fn test_config() -> SummaryConfig {\n        SummaryConfig {\n            layer: MemoryLayer::Session,\n            update_interval_secs: Some(60),\n            update_on_changes: Some(5),\n            skip_if_unchanged: true,\n            personalized: false,\n            depths: vec![SummaryDepth::Sentence, SummaryDepth::Paragraph],\n        }\n    }\n\n    #[tokio::test]\n    async fn test_new_entry_triggers_no_summary() {\n        let monitor = SummaryTriggerMonitor::new(TriggerMonitorConfig::default());\n        monitor.register_layer_config(test_config()).await;\n\n        let result = monitor\n            .should_update_summary(\n                \"entry1\",\n                MemoryLayer::Session,\n                SummaryDepth::Sentence,\n                \"hash1\",\n            )\n            .await;\n\n        assert!(result.is_some());\n        let trigger = result.unwrap();\n        assert_eq!(trigger.entry_id, \"entry1\");\n        assert!(matches!(trigger.reason, TriggerReason::NoExistingSummary));\n    }\n\n    #[tokio::test]\n    async fn test_no_trigger_for_unconfigured_layer() {\n        let monitor = SummaryTriggerMonitor::new(TriggerMonitorConfig::default());\n\n        let result = monitor\n            .should_update_summary(\n                \"entry1\",\n                MemoryLayer::Session,\n                SummaryDepth::Sentence,\n                \"hash1\",\n            )\n            .await;\n\n        assert!(result.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_no_trigger_for_unconfigured_depth() {\n        let mut config = test_config();\n        config.depths = vec![SummaryDepth::Detailed];\n\n        let monitor = SummaryTriggerMonitor::new(TriggerMonitorConfig::default());\n        monitor.register_layer_config(config).await;\n\n        let result = monitor\n            .should_update_summary(\n                \"entry1\",\n                MemoryLayer::Session,\n                SummaryDepth::Sentence,\n                \"hash1\",\n            )\n            .await;\n\n        assert!(result.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_hash_change_triggers_update() {\n        let monitor = SummaryTriggerMonitor::new(TriggerMonitorConfig::default());\n        monitor.register_layer_config(test_config()).await;\n\n        monitor\n            .record_summary_generated(\n                \"entry1\",\n                MemoryLayer::Session,\n                SummaryDepth::Sentence,\n                \"summary_hash\",\n                \"old_source_hash\",\n            )\n            .await;\n\n        let result = monitor\n            .should_update_summary(\n                \"entry1\",\n                MemoryLayer::Session,\n                SummaryDepth::Sentence,\n                \"new_source_hash\",\n            )\n            .await;\n\n        assert!(result.is_some());\n        let trigger = result.unwrap();\n        assert!(matches!(\n            trigger.reason,\n            TriggerReason::SourceHashChanged { .. }\n        ));\n    }\n\n    #[tokio::test]\n    async fn test_change_count_triggers_update() {\n        let monitor = SummaryTriggerMonitor::new(TriggerMonitorConfig::default());\n        monitor.register_layer_config(test_config()).await;\n\n        monitor\n            .record_summary_generated(\n                \"entry1\",\n                MemoryLayer::Session,\n                SummaryDepth::Sentence,\n                \"summary_hash\",\n                \"source_hash\",\n            )\n            .await;\n\n        for _ in 0..5 {\n            monitor\n                .record_change(\"entry1\", MemoryLayer::Session, \"source_hash\")\n                .await;\n        }\n\n        let result = monitor\n            .should_update_summary(\n                \"entry1\",\n                MemoryLayer::Session,\n                SummaryDepth::Sentence,\n                \"source_hash\",\n            )\n            .await;\n\n        assert!(result.is_some());\n        let trigger = result.unwrap();\n        assert!(matches!(\n            trigger.reason,\n            TriggerReason::ChangeCountExceeded {\n                change_count: 5,\n                threshold: 5\n            }\n        ));\n    }\n\n    #[tokio::test]\n    async fn test_stale_summary_triggers_update() {\n        let monitor = SummaryTriggerMonitor::new(TriggerMonitorConfig::default());\n        monitor.register_layer_config(test_config()).await;\n\n        monitor\n            .record_summary_generated(\n                \"entry1\",\n                MemoryLayer::Session,\n                SummaryDepth::Sentence,\n                \"summary_hash\",\n                \"source_hash\",\n            )\n            .await;\n\n        monitor.mark_stale(\"entry1\", SummaryDepth::Sentence).await;\n\n        let result = monitor\n            .should_update_summary(\n                \"entry1\",\n                MemoryLayer::Session,\n                SummaryDepth::Sentence,\n                \"source_hash\",\n            )\n            .await;\n\n        assert!(result.is_some());\n        let trigger = result.unwrap();\n        assert!(matches!(trigger.reason, TriggerReason::ManualRefresh));\n    }\n\n    #[tokio::test]\n    async fn test_no_trigger_when_up_to_date() {\n        let mut config = test_config();\n        config.update_interval_secs = None;\n        config.update_on_changes = None;\n\n        let monitor = SummaryTriggerMonitor::new(TriggerMonitorConfig::default());\n        monitor.register_layer_config(config).await;\n\n        monitor\n            .record_summary_generated(\n                \"entry1\",\n                MemoryLayer::Session,\n                SummaryDepth::Sentence,\n                \"summary_hash\",\n                \"source_hash\",\n            )\n            .await;\n\n        let result = monitor\n            .should_update_summary(\n                \"entry1\",\n                MemoryLayer::Session,\n                SummaryDepth::Sentence,\n                \"source_hash\",\n            )\n            .await;\n\n        assert!(result.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_check_all_entries() {\n        let monitor = SummaryTriggerMonitor::new(TriggerMonitorConfig::default());\n        monitor.register_layer_config(test_config()).await;\n\n        monitor\n            .record_summary_generated(\n                \"entry1\",\n                MemoryLayer::Session,\n                SummaryDepth::Sentence,\n                \"hash1\",\n                \"src1\",\n            )\n            .await;\n        monitor\n            .record_summary_generated(\n                \"entry2\",\n                MemoryLayer::Session,\n                SummaryDepth::Paragraph,\n                \"hash2\",\n                \"src2\",\n            )\n            .await;\n\n        monitor.mark_stale(\"entry1\", SummaryDepth::Sentence).await;\n        monitor.mark_stale(\"entry2\", SummaryDepth::Paragraph).await;\n\n        let results = monitor.check_all_entries().await;\n\n        assert!(results.len() >= 2);\n    }\n\n    #[tokio::test]\n    async fn test_get_entries_needing_update() {\n        let mut session_config = test_config();\n        session_config.depths = vec![SummaryDepth::Sentence];\n\n        let mut project_config = test_config();\n        project_config.layer = MemoryLayer::Project;\n        project_config.depths = vec![SummaryDepth::Sentence];\n\n        let monitor = SummaryTriggerMonitor::new(TriggerMonitorConfig::default());\n        monitor.register_layer_config(session_config).await;\n        monitor.register_layer_config(project_config).await;\n\n        monitor\n            .record_summary_generated(\n                \"entry1\",\n                MemoryLayer::Session,\n                SummaryDepth::Sentence,\n                \"hash1\",\n                \"src1\",\n            )\n            .await;\n        monitor\n            .record_summary_generated(\n                \"entry2\",\n                MemoryLayer::Project,\n                SummaryDepth::Sentence,\n                \"hash2\",\n                \"src2\",\n            )\n            .await;\n\n        monitor.mark_stale(\"entry1\", SummaryDepth::Sentence).await;\n        monitor.mark_stale(\"entry2\", SummaryDepth::Sentence).await;\n\n        let session_results = monitor\n            .get_entries_needing_update(MemoryLayer::Session)\n            .await;\n        let project_results = monitor\n            .get_entries_needing_update(MemoryLayer::Project)\n            .await;\n\n        assert_eq!(session_results.len(), 1);\n        assert_eq!(session_results[0].entry_id, \"entry1\");\n\n        assert_eq!(project_results.len(), 1);\n        assert_eq!(project_results[0].entry_id, \"entry2\");\n    }\n\n    #[tokio::test]\n    async fn test_clear_entry() {\n        let monitor = SummaryTriggerMonitor::new(TriggerMonitorConfig::default());\n        monitor.register_layer_config(test_config()).await;\n\n        monitor\n            .record_summary_generated(\n                \"entry1\",\n                MemoryLayer::Session,\n                SummaryDepth::Sentence,\n                \"hash\",\n                \"src\",\n            )\n            .await;\n\n        assert_eq!(monitor.entry_count().await, 1);\n\n        monitor.clear_entry(\"entry1\").await;\n\n        assert_eq!(monitor.entry_count().await, 0);\n    }\n\n    #[tokio::test]\n    async fn test_disabled_triggers() {\n        let config = TriggerMonitorConfig {\n            enable_time_based_triggers: false,\n            enable_change_count_triggers: false,\n            enable_hash_based_triggers: false,\n            ..Default::default()\n        };\n\n        let monitor = SummaryTriggerMonitor::new(config);\n        monitor.register_layer_config(test_config()).await;\n\n        monitor\n            .record_summary_generated(\n                \"entry1\",\n                MemoryLayer::Session,\n                SummaryDepth::Sentence,\n                \"summary_hash\",\n                \"old_hash\",\n            )\n            .await;\n\n        for _ in 0..10 {\n            monitor\n                .record_change(\"entry1\", MemoryLayer::Session, \"new_hash\")\n                .await;\n        }\n\n        let result = monitor\n            .should_update_summary(\n                \"entry1\",\n                MemoryLayer::Session,\n                SummaryDepth::Sentence,\n                \"new_hash\",\n            )\n            .await;\n\n        assert!(result.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_record_change_increments_count() {\n        let monitor = SummaryTriggerMonitor::new(TriggerMonitorConfig::default());\n\n        monitor\n            .record_change(\"entry1\", MemoryLayer::Session, \"hash1\")\n            .await;\n        monitor\n            .record_change(\"entry1\", MemoryLayer::Session, \"hash1\")\n            .await;\n        monitor\n            .record_change(\"entry1\", MemoryLayer::Session, \"hash1\")\n            .await;\n\n        let states = monitor.entry_states.read().await;\n        let entry = states.get(\"entry1\").unwrap();\n        assert_eq!(entry.change_count, 3);\n    }\n\n    #[tokio::test]\n    async fn test_summary_generated_resets_change_count() {\n        let monitor = SummaryTriggerMonitor::new(TriggerMonitorConfig::default());\n\n        monitor\n            .record_change(\"entry1\", MemoryLayer::Session, \"hash1\")\n            .await;\n        monitor\n            .record_change(\"entry1\", MemoryLayer::Session, \"hash1\")\n            .await;\n\n        {\n            let states = monitor.entry_states.read().await;\n            let entry = states.get(\"entry1\").unwrap();\n            assert_eq!(entry.change_count, 2);\n        }\n\n        monitor\n            .record_summary_generated(\n                \"entry1\",\n                MemoryLayer::Session,\n                SummaryDepth::Sentence,\n                \"summary_hash\",\n                \"hash1\",\n            )\n            .await;\n\n        let states = monitor.entry_states.read().await;\n        let entry = states.get(\"entry1\").unwrap();\n        assert_eq!(entry.change_count, 0);\n    }\n}\n","traces":[{"line":16,"address":[],"length":0,"stats":{"Line":13}},{"line":80,"address":[],"length":0,"stats":{"Line":13}},{"line":83,"address":[],"length":0,"stats":{"Line":39}},{"line":84,"address":[],"length":0,"stats":{"Line":13}},{"line":88,"address":[],"length":0,"stats":{"Line":22}},{"line":89,"address":[],"length":0,"stats":{"Line":33}},{"line":90,"address":[],"length":0,"stats":{"Line":33}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":40}},{"line":99,"address":[],"length":0,"stats":{"Line":60}},{"line":100,"address":[],"length":0,"stats":{"Line":40}},{"line":102,"address":[],"length":0,"stats":{"Line":60}},{"line":103,"address":[],"length":0,"stats":{"Line":40}},{"line":104,"address":[],"length":0,"stats":{"Line":20}},{"line":105,"address":[],"length":0,"stats":{"Line":4}},{"line":106,"address":[],"length":0,"stats":{"Line":2}},{"line":107,"address":[],"length":0,"stats":{"Line":4}},{"line":109,"address":[],"length":0,"stats":{"Line":2}},{"line":110,"address":[],"length":0,"stats":{"Line":2}},{"line":113,"address":[],"length":0,"stats":{"Line":20}},{"line":114,"address":[],"length":0,"stats":{"Line":60}},{"line":115,"address":[],"length":0,"stats":{"Line":20}},{"line":118,"address":[],"length":0,"stats":{"Line":11}},{"line":126,"address":[],"length":0,"stats":{"Line":33}},{"line":127,"address":[],"length":0,"stats":{"Line":22}},{"line":129,"address":[],"length":0,"stats":{"Line":33}},{"line":130,"address":[],"length":0,"stats":{"Line":22}},{"line":131,"address":[],"length":0,"stats":{"Line":11}},{"line":132,"address":[],"length":0,"stats":{"Line":20}},{"line":133,"address":[],"length":0,"stats":{"Line":10}},{"line":134,"address":[],"length":0,"stats":{"Line":20}},{"line":136,"address":[],"length":0,"stats":{"Line":10}},{"line":137,"address":[],"length":0,"stats":{"Line":10}},{"line":140,"address":[],"length":0,"stats":{"Line":22}},{"line":141,"address":[],"length":0,"stats":{"Line":11}},{"line":142,"address":[],"length":0,"stats":{"Line":11}},{"line":143,"address":[],"length":0,"stats":{"Line":22}},{"line":144,"address":[],"length":0,"stats":{"Line":11}},{"line":145,"address":[],"length":0,"stats":{"Line":11}},{"line":149,"address":[],"length":0,"stats":{"Line":11}},{"line":150,"address":[],"length":0,"stats":{"Line":33}},{"line":153,"address":[],"length":0,"stats":{"Line":10}},{"line":154,"address":[],"length":0,"stats":{"Line":15}},{"line":155,"address":[],"length":0,"stats":{"Line":15}},{"line":156,"address":[],"length":0,"stats":{"Line":20}},{"line":157,"address":[],"length":0,"stats":{"Line":5}},{"line":162,"address":[],"length":0,"stats":{"Line":8}},{"line":169,"address":[],"length":0,"stats":{"Line":24}},{"line":170,"address":[],"length":0,"stats":{"Line":24}},{"line":172,"address":[],"length":0,"stats":{"Line":14}},{"line":173,"address":[],"length":0,"stats":{"Line":1}},{"line":176,"address":[],"length":0,"stats":{"Line":18}},{"line":177,"address":[],"length":0,"stats":{"Line":12}},{"line":179,"address":[],"length":0,"stats":{"Line":12}},{"line":180,"address":[],"length":0,"stats":{"Line":1}},{"line":181,"address":[],"length":0,"stats":{"Line":3}},{"line":182,"address":[],"length":0,"stats":{"Line":2}},{"line":183,"address":[],"length":0,"stats":{"Line":2}},{"line":184,"address":[],"length":0,"stats":{"Line":1}},{"line":185,"address":[],"length":0,"stats":{"Line":1}},{"line":187,"address":[],"length":0,"stats":{"Line":5}},{"line":188,"address":[],"length":0,"stats":{"Line":35}},{"line":193,"address":[],"length":0,"stats":{"Line":2}},{"line":194,"address":[],"length":0,"stats":{"Line":3}},{"line":195,"address":[],"length":0,"stats":{"Line":3}},{"line":196,"address":[],"length":0,"stats":{"Line":2}},{"line":197,"address":[],"length":0,"stats":{"Line":2}},{"line":199,"address":[],"length":0,"stats":{"Line":4}},{"line":200,"address":[],"length":0,"stats":{"Line":6}},{"line":201,"address":[],"length":0,"stats":{"Line":10}},{"line":202,"address":[],"length":0,"stats":{"Line":4}},{"line":203,"address":[],"length":0,"stats":{"Line":24}},{"line":205,"address":[],"length":0,"stats":{"Line":8}},{"line":211,"address":[],"length":0,"stats":{"Line":1}},{"line":214,"address":[],"length":0,"stats":{"Line":4}},{"line":215,"address":[],"length":0,"stats":{"Line":6}},{"line":216,"address":[],"length":0,"stats":{"Line":6}},{"line":217,"address":[],"length":0,"stats":{"Line":4}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":221,"address":[],"length":0,"stats":{"Line":6}},{"line":222,"address":[],"length":0,"stats":{"Line":4}},{"line":223,"address":[],"length":0,"stats":{"Line":4}},{"line":225,"address":[],"length":0,"stats":{"Line":8}},{"line":226,"address":[],"length":0,"stats":{"Line":4}},{"line":227,"address":[],"length":0,"stats":{"Line":2}},{"line":230,"address":[],"length":0,"stats":{"Line":6}},{"line":231,"address":[],"length":0,"stats":{"Line":2}},{"line":232,"address":[],"length":0,"stats":{"Line":12}},{"line":234,"address":[],"length":0,"stats":{"Line":4}},{"line":239,"address":[],"length":0,"stats":{"Line":2}},{"line":242,"address":[],"length":0,"stats":{"Line":11}},{"line":250,"address":[],"length":0,"stats":{"Line":22}},{"line":251,"address":[],"length":0,"stats":{"Line":2}},{"line":252,"address":[],"length":0,"stats":{"Line":6}},{"line":253,"address":[],"length":0,"stats":{"Line":4}},{"line":254,"address":[],"length":0,"stats":{"Line":4}},{"line":255,"address":[],"length":0,"stats":{"Line":2}},{"line":256,"address":[],"length":0,"stats":{"Line":2}},{"line":258,"address":[],"length":0,"stats":{"Line":9}},{"line":259,"address":[],"length":0,"stats":{"Line":9}},{"line":260,"address":[],"length":0,"stats":{"Line":5}},{"line":261,"address":[],"length":0,"stats":{"Line":15}},{"line":262,"address":[],"length":0,"stats":{"Line":10}},{"line":263,"address":[],"length":0,"stats":{"Line":10}},{"line":264,"address":[],"length":0,"stats":{"Line":5}},{"line":265,"address":[],"length":0,"stats":{"Line":5}},{"line":269,"address":[],"length":0,"stats":{"Line":4}},{"line":270,"address":[],"length":0,"stats":{"Line":3}},{"line":272,"address":[],"length":0,"stats":{"Line":1}},{"line":273,"address":[],"length":0,"stats":{"Line":3}},{"line":274,"address":[],"length":0,"stats":{"Line":2}},{"line":275,"address":[],"length":0,"stats":{"Line":2}},{"line":276,"address":[],"length":0,"stats":{"Line":1}},{"line":277,"address":[],"length":0,"stats":{"Line":3}},{"line":278,"address":[],"length":0,"stats":{"Line":1}},{"line":280,"address":[],"length":0,"stats":{"Line":1}},{"line":284,"address":[],"length":0,"stats":{"Line":3}},{"line":285,"address":[],"length":0,"stats":{"Line":3}},{"line":286,"address":[],"length":0,"stats":{"Line":2}},{"line":287,"address":[],"length":0,"stats":{"Line":1}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":3}},{"line":303,"address":[],"length":0,"stats":{"Line":3}},{"line":304,"address":[],"length":0,"stats":{"Line":1}},{"line":305,"address":[],"length":0,"stats":{"Line":1}},{"line":306,"address":[],"length":0,"stats":{"Line":3}},{"line":307,"address":[],"length":0,"stats":{"Line":2}},{"line":308,"address":[],"length":0,"stats":{"Line":2}},{"line":309,"address":[],"length":0,"stats":{"Line":1}},{"line":310,"address":[],"length":0,"stats":{"Line":1}},{"line":311,"address":[],"length":0,"stats":{"Line":1}},{"line":313,"address":[],"length":0,"stats":{"Line":1}},{"line":319,"address":[],"length":0,"stats":{"Line":2}},{"line":324,"address":[],"length":0,"stats":{"Line":2}},{"line":325,"address":[],"length":0,"stats":{"Line":3}},{"line":326,"address":[],"length":0,"stats":{"Line":2}},{"line":329,"address":[],"length":0,"stats":{"Line":4}},{"line":330,"address":[],"length":0,"stats":{"Line":6}},{"line":331,"address":[],"length":0,"stats":{"Line":2}},{"line":335,"address":[],"length":0,"stats":{"Line":40}},{"line":336,"address":[],"length":0,"stats":{"Line":40}},{"line":337,"address":[],"length":0,"stats":{"Line":40}},{"line":338,"address":[],"length":0,"stats":{"Line":120}}],"covered":140,"coverable":152},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","durable_events.rs"],"content":"use mk_core::traits::{EventPublisher, StorageBackend};\nuse mk_core::types::{EventStatus, GovernanceEvent, PersistentEvent, TenantContext};\nuse std::sync::Arc;\nuse tracing::{error, info, warn};\n\npub struct DurableEventPublisher<S, P>\nwhere\n    S: StorageBackend + Send + Sync,\n    P: EventPublisher + Send + Sync,\n{\n    storage: Arc<S>,\n    redis_publisher: Arc<P>,\n    tenant_ctx: TenantContext,\n}\n\nimpl<S, P> DurableEventPublisher<S, P>\nwhere\n    S: StorageBackend + Send + Sync,\n    S::Error: std::error::Error + Send + Sync + 'static,\n    P: EventPublisher + Send + Sync,\n    P::Error: std::error::Error + Send + Sync + 'static,\n{\n    pub fn new(storage: Arc<S>, redis_publisher: Arc<P>, tenant_ctx: TenantContext) -> Self {\n        Self {\n            storage,\n            redis_publisher,\n            tenant_ctx,\n        }\n    }\n\n    pub async fn publish_durable(\n        &self,\n        event: GovernanceEvent,\n    ) -> Result<String, DurablePublishError> {\n        let persistent_event = PersistentEvent::new(event.clone());\n        let event_id = persistent_event.event_id.clone();\n        let idempotency_key = persistent_event.idempotency_key.clone();\n\n        self.storage\n            .persist_event(persistent_event)\n            .await\n            .map_err(|e| DurablePublishError::PersistenceError(e.to_string()))?;\n\n        match self.redis_publisher.publish(event).await {\n            Ok(()) => {\n                self.storage\n                    .update_event_status(&event_id, EventStatus::Published, None)\n                    .await\n                    .map_err(|e| DurablePublishError::StatusUpdateError(e.to_string()))?;\n\n                info!(event_id = %event_id, \"Event published successfully\");\n                Ok(idempotency_key)\n            }\n            Err(e) => {\n                warn!(event_id = %event_id, error = %e, \"Failed to publish to Redis, event persisted for retry\");\n                self.storage\n                    .update_event_status(&event_id, EventStatus::Pending, Some(e.to_string()))\n                    .await\n                    .ok();\n\n                Err(DurablePublishError::PublishError(e.to_string()))\n            }\n        }\n    }\n\n    pub async fn retry_pending_events(\n        &self,\n        limit: usize,\n    ) -> Result<RetryResult, DurablePublishError> {\n        let pending = self\n            .storage\n            .get_pending_events(self.tenant_ctx.clone(), limit)\n            .await\n            .map_err(|e| DurablePublishError::StorageError(e.to_string()))?;\n\n        let mut result = RetryResult::default();\n        result.total = pending.len();\n\n        for event in pending {\n            if !event.is_retriable() {\n                continue;\n            }\n\n            match self.redis_publisher.publish(event.payload.clone()).await {\n                Ok(()) => {\n                    self.storage\n                        .update_event_status(&event.event_id, EventStatus::Published, None)\n                        .await\n                        .ok();\n                    result.succeeded += 1;\n                }\n                Err(e) => {\n                    let mut updated_event = event.clone();\n                    let can_retry = updated_event.mark_failed(e.to_string());\n\n                    if can_retry {\n                        self.storage\n                            .update_event_status(\n                                &event.event_id,\n                                EventStatus::Pending,\n                                Some(e.to_string()),\n                            )\n                            .await\n                            .ok();\n                        result.retried += 1;\n                    } else {\n                        self.storage\n                            .update_event_status(\n                                &event.event_id,\n                                EventStatus::DeadLettered,\n                                Some(e.to_string()),\n                            )\n                            .await\n                            .ok();\n                        result.dead_lettered += 1;\n                        error!(\n                            event_id = %event.event_id,\n                            \"Event moved to dead letter queue after max retries\"\n                        );\n                    }\n                }\n            }\n        }\n\n        Ok(result)\n    }\n\n    pub async fn process_dead_letter_queue(\n        &self,\n        limit: usize,\n        handler: impl Fn(&PersistentEvent) -> bool,\n    ) -> Result<DlqResult, DurablePublishError> {\n        let dead_letters = self\n            .storage\n            .get_dead_letter_events(self.tenant_ctx.clone(), limit)\n            .await\n            .map_err(|e| DurablePublishError::StorageError(e.to_string()))?;\n\n        let mut result = DlqResult::default();\n        result.total = dead_letters.len();\n\n        for event in dead_letters {\n            if handler(&event) {\n                match self.redis_publisher.publish(event.payload.clone()).await {\n                    Ok(()) => {\n                        self.storage\n                            .update_event_status(&event.event_id, EventStatus::Published, None)\n                            .await\n                            .ok();\n                        result.reprocessed += 1;\n                    }\n                    Err(e) => {\n                        warn!(\n                            event_id = %event.event_id,\n                            error = %e,\n                            \"DLQ reprocessing failed\"\n                        );\n                        result.failed += 1;\n                    }\n                }\n            } else {\n                result.skipped += 1;\n            }\n        }\n\n        Ok(result)\n    }\n}\n\n#[derive(Debug, Default)]\npub struct RetryResult {\n    pub total: usize,\n    pub succeeded: usize,\n    pub retried: usize,\n    pub dead_lettered: usize,\n}\n\n#[derive(Debug, Default)]\npub struct DlqResult {\n    pub total: usize,\n    pub reprocessed: usize,\n    pub failed: usize,\n    pub skipped: usize,\n}\n\n#[derive(Debug, thiserror::Error)]\npub enum DurablePublishError {\n    #[error(\"Failed to persist event: {0}\")]\n    PersistenceError(String),\n\n    #[error(\"Failed to publish event: {0}\")]\n    PublishError(String),\n\n    #[error(\"Failed to update event status: {0}\")]\n    StatusUpdateError(String),\n\n    #[error(\"Storage operation failed: {0}\")]\n    StorageError(String),\n}\n\npub struct IdempotentConsumer<S>\nwhere\n    S: StorageBackend + Send + Sync,\n{\n    storage: Arc<S>,\n    consumer_group: String,\n}\n\nimpl<S> IdempotentConsumer<S>\nwhere\n    S: StorageBackend + Send + Sync,\n    S::Error: std::error::Error + Send + Sync + 'static,\n{\n    pub fn new(storage: Arc<S>, consumer_group: String) -> Self {\n        Self {\n            storage,\n            consumer_group,\n        }\n    }\n\n    pub async fn process_if_new<F, T, E>(\n        &self,\n        idempotency_key: &str,\n        tenant_id: &mk_core::types::TenantId,\n        handler: F,\n    ) -> Result<Option<T>, IdempotentConsumerError>\n    where\n        F: std::future::Future<Output = Result<T, E>>,\n        E: std::error::Error,\n    {\n        let already_processed = self\n            .storage\n            .check_idempotency(&self.consumer_group, idempotency_key)\n            .await\n            .map_err(|e| IdempotentConsumerError::StorageError(e.to_string()))?;\n\n        if already_processed {\n            return Ok(None);\n        }\n\n        let result = handler\n            .await\n            .map_err(|e| IdempotentConsumerError::ProcessingError(e.to_string()))?;\n\n        let state = mk_core::types::ConsumerState::new(\n            self.consumer_group.clone(),\n            idempotency_key.to_string(),\n            tenant_id.clone(),\n        );\n\n        self.storage\n            .record_consumer_state(state)\n            .await\n            .map_err(|e| IdempotentConsumerError::StorageError(e.to_string()))?;\n\n        Ok(Some(result))\n    }\n}\n\n#[derive(Debug, thiserror::Error)]\npub enum IdempotentConsumerError {\n    #[error(\"Storage operation failed: {0}\")]\n    StorageError(String),\n\n    #[error(\"Event processing failed: {0}\")]\n    ProcessingError(String),\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use async_trait::async_trait;\n    use mk_core::types::{\n        ConsumerState, DriftConfig, DriftResult, DriftSuppression, EventDeliveryMetrics,\n        GovernanceEvent, OrganizationalUnit, PersistentEvent, Policy, Role, TenantId, UnitType,\n        UserId,\n    };\n    use std::sync::Arc;\n    use std::sync::atomic::{AtomicUsize, Ordering};\n    use tokio::sync::RwLock;\n\n    #[derive(Clone)]\n    struct MockStorage {\n        persist_calls: Arc<AtomicUsize>,\n        update_calls: Arc<AtomicUsize>,\n        pending_events: Arc<RwLock<Vec<PersistentEvent>>>,\n        dead_letter_events: Arc<RwLock<Vec<PersistentEvent>>>,\n        idempotency_keys: Arc<RwLock<Vec<String>>>,\n        should_fail: Arc<RwLock<bool>>,\n    }\n\n    impl MockStorage {\n        fn new() -> Self {\n            Self {\n                persist_calls: Arc::new(AtomicUsize::new(0)),\n                update_calls: Arc::new(AtomicUsize::new(0)),\n                pending_events: Arc::new(RwLock::new(Vec::new())),\n                dead_letter_events: Arc::new(RwLock::new(Vec::new())),\n                idempotency_keys: Arc::new(RwLock::new(Vec::new())),\n                should_fail: Arc::new(RwLock::new(false)),\n            }\n        }\n\n        fn with_pending(events: Vec<PersistentEvent>) -> Self {\n            let storage = Self::new();\n            let pending = Arc::new(RwLock::new(events));\n            Self {\n                pending_events: pending,\n                ..storage\n            }\n        }\n\n        fn with_dead_letters(events: Vec<PersistentEvent>) -> Self {\n            let storage = Self::new();\n            let dlq = Arc::new(RwLock::new(events));\n            Self {\n                dead_letter_events: dlq,\n                ..storage\n            }\n        }\n    }\n\n    #[derive(Debug)]\n    struct MockStorageError(String);\n\n    impl std::fmt::Display for MockStorageError {\n        fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n            write!(f, \"{}\", self.0)\n        }\n    }\n\n    impl std::error::Error for MockStorageError {}\n\n    #[async_trait]\n    impl StorageBackend for MockStorage {\n        type Error = MockStorageError;\n\n        async fn store(\n            &self,\n            _ctx: TenantContext,\n            _key: &str,\n            _value: &[u8],\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn retrieve(\n            &self,\n            _ctx: TenantContext,\n            _key: &str,\n        ) -> Result<Option<Vec<u8>>, Self::Error> {\n            Ok(None)\n        }\n\n        async fn delete(&self, _ctx: TenantContext, _key: &str) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn exists(&self, _ctx: TenantContext, _key: &str) -> Result<bool, Self::Error> {\n            Ok(false)\n        }\n\n        async fn get_ancestors(\n            &self,\n            _ctx: TenantContext,\n            _unit_id: &str,\n        ) -> Result<Vec<OrganizationalUnit>, Self::Error> {\n            Ok(Vec::new())\n        }\n\n        async fn get_descendants(\n            &self,\n            _ctx: TenantContext,\n            _unit_id: &str,\n        ) -> Result<Vec<OrganizationalUnit>, Self::Error> {\n            Ok(Vec::new())\n        }\n\n        async fn get_unit_policies(\n            &self,\n            _ctx: TenantContext,\n            _unit_id: &str,\n        ) -> Result<Vec<Policy>, Self::Error> {\n            Ok(Vec::new())\n        }\n\n        async fn create_unit(&self, _unit: &OrganizationalUnit) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn add_unit_policy(\n            &self,\n            _ctx: &TenantContext,\n            _unit_id: &str,\n            _policy: &Policy,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn assign_role(\n            &self,\n            _user_id: &UserId,\n            _tenant_id: &TenantId,\n            _unit_id: &str,\n            _role: Role,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn remove_role(\n            &self,\n            _user_id: &UserId,\n            _tenant_id: &TenantId,\n            _unit_id: &str,\n            _role: Role,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn store_drift_result(&self, _result: DriftResult) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn get_latest_drift_result(\n            &self,\n            _ctx: TenantContext,\n            _project_id: &str,\n        ) -> Result<Option<DriftResult>, Self::Error> {\n            Ok(None)\n        }\n\n        async fn list_all_units(&self) -> Result<Vec<OrganizationalUnit>, Self::Error> {\n            Ok(Vec::new())\n        }\n\n        async fn record_job_status(\n            &self,\n            _job_name: &str,\n            _tenant_id: &str,\n            _status: &str,\n            _message: Option<&str>,\n            _started_at: i64,\n            _finished_at: Option<i64>,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn get_governance_events(\n            &self,\n            _ctx: TenantContext,\n            _since_timestamp: i64,\n            _limit: usize,\n        ) -> Result<Vec<GovernanceEvent>, Self::Error> {\n            Ok(Vec::new())\n        }\n\n        async fn persist_event(&self, _event: PersistentEvent) -> Result<(), Self::Error> {\n            self.persist_calls.fetch_add(1, Ordering::SeqCst);\n            if *self.should_fail.read().await {\n                return Err(MockStorageError(\"Persist failed\".to_string()));\n            }\n            Ok(())\n        }\n\n        async fn get_pending_events(\n            &self,\n            _ctx: TenantContext,\n            _limit: usize,\n        ) -> Result<Vec<PersistentEvent>, Self::Error> {\n            Ok(self.pending_events.read().await.clone())\n        }\n\n        async fn update_event_status(\n            &self,\n            _event_id: &str,\n            _status: EventStatus,\n            _error: Option<String>,\n        ) -> Result<(), Self::Error> {\n            self.update_calls.fetch_add(1, Ordering::SeqCst);\n            Ok(())\n        }\n\n        async fn get_dead_letter_events(\n            &self,\n            _ctx: TenantContext,\n            _limit: usize,\n        ) -> Result<Vec<PersistentEvent>, Self::Error> {\n            Ok(self.dead_letter_events.read().await.clone())\n        }\n\n        async fn check_idempotency(\n            &self,\n            _consumer_group: &str,\n            idempotency_key: &str,\n        ) -> Result<bool, Self::Error> {\n            let keys = self.idempotency_keys.read().await;\n            Ok(keys.contains(&idempotency_key.to_string()))\n        }\n\n        async fn record_consumer_state(&self, state: ConsumerState) -> Result<(), Self::Error> {\n            self.idempotency_keys\n                .write()\n                .await\n                .push(state.idempotency_key);\n            Ok(())\n        }\n\n        async fn get_event_metrics(\n            &self,\n            _ctx: TenantContext,\n            _period_start: i64,\n            _period_end: i64,\n        ) -> Result<Vec<EventDeliveryMetrics>, Self::Error> {\n            Ok(Vec::new())\n        }\n\n        async fn record_event_metrics(\n            &self,\n            _metrics: EventDeliveryMetrics,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn create_suppression(\n            &self,\n            _suppression: DriftSuppression,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn list_suppressions(\n            &self,\n            _ctx: TenantContext,\n            _project_id: &str,\n        ) -> Result<Vec<DriftSuppression>, Self::Error> {\n            Ok(Vec::new())\n        }\n\n        async fn delete_suppression(\n            &self,\n            _ctx: TenantContext,\n            _suppression_id: &str,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn get_drift_config(\n            &self,\n            _ctx: TenantContext,\n            _project_id: &str,\n        ) -> Result<Option<DriftConfig>, Self::Error> {\n            Ok(None)\n        }\n\n        async fn save_drift_config(&self, _config: DriftConfig) -> Result<(), Self::Error> {\n            Ok(())\n        }\n    }\n\n    struct MockPublisher {\n        publish_calls: Arc<AtomicUsize>,\n        should_fail: Arc<RwLock<bool>>,\n    }\n\n    impl MockPublisher {\n        fn new() -> Self {\n            Self {\n                publish_calls: Arc::new(AtomicUsize::new(0)),\n                should_fail: Arc::new(RwLock::new(false)),\n            }\n        }\n\n        fn failing() -> Self {\n            Self {\n                publish_calls: Arc::new(AtomicUsize::new(0)),\n                should_fail: Arc::new(RwLock::new(true)),\n            }\n        }\n    }\n\n    #[derive(Debug)]\n    struct MockPublisherError(String);\n\n    impl std::fmt::Display for MockPublisherError {\n        fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n            write!(f, \"{}\", self.0)\n        }\n    }\n\n    impl std::error::Error for MockPublisherError {}\n\n    #[async_trait]\n    impl EventPublisher for MockPublisher {\n        type Error = MockPublisherError;\n\n        async fn publish(&self, _event: GovernanceEvent) -> Result<(), Self::Error> {\n            self.publish_calls.fetch_add(1, Ordering::SeqCst);\n            if *self.should_fail.read().await {\n                return Err(MockPublisherError(\"Publish failed\".to_string()));\n            }\n            Ok(())\n        }\n\n        async fn subscribe(\n            &self,\n            _channels: &[&str],\n        ) -> Result<tokio::sync::mpsc::Receiver<GovernanceEvent>, Self::Error> {\n            let (_tx, rx) = tokio::sync::mpsc::channel(1);\n            Ok(rx)\n        }\n    }\n\n    fn create_test_event() -> GovernanceEvent {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        GovernanceEvent::UnitCreated {\n            unit_id: \"unit-1\".to_string(),\n            unit_type: UnitType::Company,\n            tenant_id,\n            parent_id: None,\n            timestamp: chrono::Utc::now().timestamp(),\n        }\n    }\n\n    fn create_test_context() -> TenantContext {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let user_id = UserId::new(\"user-1\".to_string()).unwrap();\n        TenantContext::new(tenant_id, user_id)\n    }\n\n    #[test]\n    fn test_retry_result_default() {\n        let result = RetryResult::default();\n        assert_eq!(result.total, 0);\n        assert_eq!(result.succeeded, 0);\n        assert_eq!(result.retried, 0);\n        assert_eq!(result.dead_lettered, 0);\n    }\n\n    #[test]\n    fn test_dlq_result_default() {\n        let result = DlqResult::default();\n        assert_eq!(result.total, 0);\n        assert_eq!(result.reprocessed, 0);\n        assert_eq!(result.failed, 0);\n        assert_eq!(result.skipped, 0);\n    }\n\n    #[test]\n    fn test_durable_publish_error_display() {\n        let error = DurablePublishError::PersistenceError(\"DB down\".to_string());\n        assert!(error.to_string().contains(\"persist\"));\n\n        let error = DurablePublishError::PublishError(\"Redis timeout\".to_string());\n        assert!(error.to_string().contains(\"publish\"));\n\n        let error = DurablePublishError::StatusUpdateError(\"Update failed\".to_string());\n        assert!(error.to_string().contains(\"status\"));\n\n        let error = DurablePublishError::StorageError(\"IO error\".to_string());\n        assert!(error.to_string().contains(\"Storage\"));\n    }\n\n    #[test]\n    fn test_idempotent_consumer_error_display() {\n        let error = IdempotentConsumerError::StorageError(\"Connection lost\".to_string());\n        assert!(error.to_string().contains(\"Storage\"));\n\n        let error = IdempotentConsumerError::ProcessingError(\"Handler failed\".to_string());\n        assert!(error.to_string().contains(\"processing\"));\n    }\n\n    #[tokio::test]\n    async fn test_durable_publisher_new() {\n        let storage = Arc::new(MockStorage::new());\n        let publisher = Arc::new(MockPublisher::new());\n        let ctx = create_test_context();\n\n        let durable = DurableEventPublisher::new(storage, publisher, ctx);\n        assert!(std::ptr::eq(&*durable.storage, &*durable.storage));\n    }\n\n    #[tokio::test]\n    async fn test_publish_durable_success() {\n        let storage = Arc::new(MockStorage::new());\n        let publisher = Arc::new(MockPublisher::new());\n        let ctx = create_test_context();\n        let event = create_test_event();\n\n        let durable = DurableEventPublisher::new(storage.clone(), publisher.clone(), ctx);\n        let result = durable.publish_durable(event).await;\n\n        assert!(result.is_ok());\n        assert_eq!(storage.persist_calls.load(Ordering::SeqCst), 1);\n        assert_eq!(publisher.publish_calls.load(Ordering::SeqCst), 1);\n        assert_eq!(storage.update_calls.load(Ordering::SeqCst), 1);\n    }\n\n    #[tokio::test]\n    async fn test_publish_durable_publish_failure() {\n        let storage = Arc::new(MockStorage::new());\n        let publisher = Arc::new(MockPublisher::failing());\n        let ctx = create_test_context();\n        let event = create_test_event();\n\n        let durable = DurableEventPublisher::new(storage.clone(), publisher.clone(), ctx);\n        let result = durable.publish_durable(event).await;\n\n        assert!(result.is_err());\n        assert!(matches!(\n            result.unwrap_err(),\n            DurablePublishError::PublishError(_)\n        ));\n        assert_eq!(storage.persist_calls.load(Ordering::SeqCst), 1);\n        assert_eq!(publisher.publish_calls.load(Ordering::SeqCst), 1);\n    }\n\n    #[tokio::test]\n    async fn test_retry_pending_events_empty() {\n        let storage = Arc::new(MockStorage::new());\n        let publisher = Arc::new(MockPublisher::new());\n        let ctx = create_test_context();\n\n        let durable = DurableEventPublisher::new(storage, publisher, ctx);\n        let result = durable.retry_pending_events(10).await;\n\n        assert!(result.is_ok());\n        let retry_result = result.unwrap();\n        assert_eq!(retry_result.total, 0);\n        assert_eq!(retry_result.succeeded, 0);\n    }\n\n    #[tokio::test]\n    async fn test_retry_pending_events_success() {\n        let event = create_test_event();\n        let pending = vec![PersistentEvent::new(event)];\n        let storage = Arc::new(MockStorage::with_pending(pending));\n        let publisher = Arc::new(MockPublisher::new());\n        let ctx = create_test_context();\n\n        let durable = DurableEventPublisher::new(storage.clone(), publisher.clone(), ctx);\n        let result = durable.retry_pending_events(10).await;\n\n        assert!(result.is_ok());\n        let retry_result = result.unwrap();\n        assert_eq!(retry_result.total, 1);\n        assert_eq!(retry_result.succeeded, 1);\n        assert_eq!(publisher.publish_calls.load(Ordering::SeqCst), 1);\n    }\n\n    #[tokio::test]\n    async fn test_retry_pending_events_failure() {\n        let event = create_test_event();\n        let pending = vec![PersistentEvent::new(event)];\n        let storage = Arc::new(MockStorage::with_pending(pending));\n        let publisher = Arc::new(MockPublisher::failing());\n        let ctx = create_test_context();\n\n        let durable = DurableEventPublisher::new(storage.clone(), publisher, ctx);\n        let result = durable.retry_pending_events(10).await;\n\n        assert!(result.is_ok());\n        let retry_result = result.unwrap();\n        assert_eq!(retry_result.total, 1);\n        assert_eq!(retry_result.retried, 1);\n    }\n\n    #[tokio::test]\n    async fn test_process_dead_letter_queue_empty() {\n        let storage = Arc::new(MockStorage::new());\n        let publisher = Arc::new(MockPublisher::new());\n        let ctx = create_test_context();\n\n        let durable = DurableEventPublisher::new(storage, publisher, ctx);\n        let result = durable.process_dead_letter_queue(10, |_| true).await;\n\n        assert!(result.is_ok());\n        let dlq_result = result.unwrap();\n        assert_eq!(dlq_result.total, 0);\n    }\n\n    #[tokio::test]\n    async fn test_process_dead_letter_queue_reprocess() {\n        let event = create_test_event();\n        let dead_letters = vec![PersistentEvent::new(event)];\n        let storage = Arc::new(MockStorage::with_dead_letters(dead_letters));\n        let publisher = Arc::new(MockPublisher::new());\n        let ctx = create_test_context();\n\n        let durable = DurableEventPublisher::new(storage, publisher.clone(), ctx);\n        let result = durable.process_dead_letter_queue(10, |_| true).await;\n\n        assert!(result.is_ok());\n        let dlq_result = result.unwrap();\n        assert_eq!(dlq_result.total, 1);\n        assert_eq!(dlq_result.reprocessed, 1);\n        assert_eq!(publisher.publish_calls.load(Ordering::SeqCst), 1);\n    }\n\n    #[tokio::test]\n    async fn test_process_dead_letter_queue_skipped() {\n        let event = create_test_event();\n        let dead_letters = vec![PersistentEvent::new(event)];\n        let storage = Arc::new(MockStorage::with_dead_letters(dead_letters));\n        let publisher = Arc::new(MockPublisher::new());\n        let ctx = create_test_context();\n\n        let durable = DurableEventPublisher::new(storage, publisher.clone(), ctx);\n        let result = durable.process_dead_letter_queue(10, |_| false).await;\n\n        assert!(result.is_ok());\n        let dlq_result = result.unwrap();\n        assert_eq!(dlq_result.total, 1);\n        assert_eq!(dlq_result.skipped, 1);\n        assert_eq!(publisher.publish_calls.load(Ordering::SeqCst), 0);\n    }\n\n    #[tokio::test]\n    async fn test_idempotent_consumer_new() {\n        let storage = Arc::new(MockStorage::new());\n        let consumer = IdempotentConsumer::new(storage, \"test_group\".to_string());\n\n        assert_eq!(consumer.consumer_group, \"test_group\");\n    }\n\n    #[tokio::test]\n    async fn test_idempotent_consumer_process_new_event() {\n        let storage = Arc::new(MockStorage::new());\n        let consumer = IdempotentConsumer::new(storage, \"test_group\".to_string());\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n\n        let result = consumer\n            .process_if_new(\"key-1\", &tenant_id, async { Ok::<_, std::io::Error>(42) })\n            .await;\n\n        assert!(result.is_ok());\n        assert_eq!(result.unwrap(), Some(42));\n    }\n\n    #[tokio::test]\n    async fn test_idempotent_consumer_skip_duplicate() {\n        let storage = Arc::new(MockStorage::new());\n        storage\n            .idempotency_keys\n            .write()\n            .await\n            .push(\"key-1\".to_string());\n\n        let consumer = IdempotentConsumer::new(storage, \"test_group\".to_string());\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n\n        let result = consumer\n            .process_if_new(\"key-1\", &tenant_id, async { Ok::<_, std::io::Error>(42) })\n            .await;\n\n        assert!(result.is_ok());\n        assert_eq!(result.unwrap(), None);\n    }\n}\n","traces":[{"line":23,"address":[],"length":0,"stats":{"Line":9}},{"line":31,"address":[],"length":0,"stats":{"Line":2}},{"line":35,"address":[],"length":0,"stats":{"Line":8}},{"line":36,"address":[],"length":0,"stats":{"Line":6}},{"line":37,"address":[],"length":0,"stats":{"Line":6}},{"line":39,"address":[],"length":0,"stats":{"Line":4}},{"line":40,"address":[],"length":0,"stats":{"Line":2}},{"line":41,"address":[],"length":0,"stats":{"Line":2}},{"line":42,"address":[],"length":0,"stats":{"Line":2}},{"line":44,"address":[],"length":0,"stats":{"Line":6}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":2}},{"line":47,"address":[],"length":0,"stats":{"Line":3}},{"line":48,"address":[],"length":0,"stats":{"Line":1}},{"line":49,"address":[],"length":0,"stats":{"Line":1}},{"line":51,"address":[],"length":0,"stats":{"Line":1}},{"line":52,"address":[],"length":0,"stats":{"Line":1}},{"line":54,"address":[],"length":0,"stats":{"Line":1}},{"line":55,"address":[],"length":0,"stats":{"Line":1}},{"line":56,"address":[],"length":0,"stats":{"Line":2}},{"line":57,"address":[],"length":0,"stats":{"Line":4}},{"line":58,"address":[],"length":0,"stats":{"Line":1}},{"line":61,"address":[],"length":0,"stats":{"Line":1}},{"line":66,"address":[],"length":0,"stats":{"Line":3}},{"line":70,"address":[],"length":0,"stats":{"Line":9}},{"line":71,"address":[],"length":0,"stats":{"Line":6}},{"line":72,"address":[],"length":0,"stats":{"Line":9}},{"line":73,"address":[],"length":0,"stats":{"Line":3}},{"line":74,"address":[],"length":0,"stats":{"Line":3}},{"line":76,"address":[],"length":0,"stats":{"Line":6}},{"line":77,"address":[],"length":0,"stats":{"Line":3}},{"line":79,"address":[],"length":0,"stats":{"Line":7}},{"line":80,"address":[],"length":0,"stats":{"Line":2}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":8}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":2}},{"line":87,"address":[],"length":0,"stats":{"Line":3}},{"line":88,"address":[],"length":0,"stats":{"Line":1}},{"line":90,"address":[],"length":0,"stats":{"Line":1}},{"line":92,"address":[],"length":0,"stats":{"Line":1}},{"line":93,"address":[],"length":0,"stats":{"Line":3}},{"line":94,"address":[],"length":0,"stats":{"Line":5}},{"line":96,"address":[],"length":0,"stats":{"Line":1}},{"line":97,"address":[],"length":0,"stats":{"Line":2}},{"line":99,"address":[],"length":0,"stats":{"Line":2}},{"line":100,"address":[],"length":0,"stats":{"Line":2}},{"line":101,"address":[],"length":0,"stats":{"Line":1}},{"line":103,"address":[],"length":0,"stats":{"Line":1}},{"line":105,"address":[],"length":0,"stats":{"Line":1}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":3}},{"line":128,"address":[],"length":0,"stats":{"Line":3}},{"line":133,"address":[],"length":0,"stats":{"Line":9}},{"line":134,"address":[],"length":0,"stats":{"Line":6}},{"line":135,"address":[],"length":0,"stats":{"Line":9}},{"line":136,"address":[],"length":0,"stats":{"Line":3}},{"line":137,"address":[],"length":0,"stats":{"Line":3}},{"line":139,"address":[],"length":0,"stats":{"Line":6}},{"line":140,"address":[],"length":0,"stats":{"Line":3}},{"line":142,"address":[],"length":0,"stats":{"Line":7}},{"line":143,"address":[],"length":0,"stats":{"Line":2}},{"line":144,"address":[],"length":0,"stats":{"Line":4}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":2}},{"line":147,"address":[],"length":0,"stats":{"Line":3}},{"line":148,"address":[],"length":0,"stats":{"Line":1}},{"line":150,"address":[],"length":0,"stats":{"Line":1}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":1}},{"line":166,"address":[],"length":0,"stats":{"Line":3}},{"line":214,"address":[],"length":0,"stats":{"Line":3}},{"line":221,"address":[],"length":0,"stats":{"Line":2}},{"line":231,"address":[],"length":0,"stats":{"Line":6}},{"line":232,"address":[],"length":0,"stats":{"Line":4}},{"line":233,"address":[],"length":0,"stats":{"Line":4}},{"line":234,"address":[],"length":0,"stats":{"Line":2}},{"line":235,"address":[],"length":0,"stats":{"Line":2}},{"line":237,"address":[],"length":0,"stats":{"Line":2}},{"line":238,"address":[],"length":0,"stats":{"Line":1}},{"line":241,"address":[],"length":0,"stats":{"Line":2}},{"line":242,"address":[],"length":0,"stats":{"Line":1}},{"line":243,"address":[],"length":0,"stats":{"Line":1}},{"line":246,"address":[],"length":0,"stats":{"Line":2}},{"line":247,"address":[],"length":0,"stats":{"Line":2}},{"line":248,"address":[],"length":0,"stats":{"Line":2}},{"line":251,"address":[],"length":0,"stats":{"Line":2}},{"line":252,"address":[],"length":0,"stats":{"Line":1}},{"line":253,"address":[],"length":0,"stats":{"Line":1}},{"line":254,"address":[],"length":0,"stats":{"Line":1}},{"line":256,"address":[],"length":0,"stats":{"Line":1}}],"covered":85,"coverable":104},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","ecosystem.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","episodic.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","federation.rs"],"content":"use crate::repository::RepositoryError;\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct UpstreamConfig {\n    pub id: String,\n    pub url: String,\n    pub branch: String,\n    pub auth_token: Option<String>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct FederationConfig {\n    pub upstreams: Vec<UpstreamConfig>,\n    pub sync_interval_secs: u64,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct KnowledgeManifest {\n    pub version: String,\n    pub items: HashMap<String, String>,\n}\n\n#[async_trait::async_trait]\npub trait FederationProvider: Send + Sync {\n    fn config(&self) -> &FederationConfig;\n    async fn fetch_upstream_manifest(\n        &self,\n        upstream_id: &str,\n    ) -> Result<KnowledgeManifest, RepositoryError>;\n    async fn sync_upstream(\n        &self,\n        upstream_id: &str,\n        target_path: &std::path::Path,\n    ) -> Result<(), RepositoryError>;\n}\n\npub struct FederationManager {\n    config: FederationConfig,\n}\n\n#[async_trait::async_trait]\nimpl FederationProvider for FederationManager {\n    fn config(&self) -> &FederationConfig {\n        &self.config\n    }\n\n    async fn fetch_upstream_manifest(\n        &self,\n        upstream_id: &str,\n    ) -> Result<KnowledgeManifest, RepositoryError> {\n        let _upstream = self\n            .config\n            .upstreams\n            .iter()\n            .find(|u| u.id == upstream_id)\n            .ok_or_else(|| {\n                RepositoryError::InvalidPath(format!(\"Upstream not found: {}\", upstream_id))\n            })?;\n\n        Ok(KnowledgeManifest {\n            version: \"1.0\".to_string(),\n            items: HashMap::new(),\n        })\n    }\n\n    async fn sync_upstream(\n        &self,\n        upstream_id: &str,\n        target_path: &std::path::Path,\n    ) -> Result<(), RepositoryError> {\n        let upstream = self\n            .config\n            .upstreams\n            .iter()\n            .find(|u| u.id == upstream_id)\n            .ok_or_else(|| {\n                RepositoryError::InvalidPath(format!(\"Upstream not found: {}\", upstream_id))\n            })?;\n\n        if target_path.exists() {\n            let repo = git2::Repository::open(target_path)?;\n            let mut remote = repo.find_remote(\"origin\")?;\n            remote.fetch(&[&upstream.branch], None, None)?;\n\n            let head = repo.head()?.peel_to_commit()?;\n            let remote_ref =\n                repo.find_reference(&format!(\"refs/remotes/origin/{}\", upstream.branch))?;\n            let remote_commit = remote_ref.peel_to_commit()?;\n\n            if repo.merge_base(head.id(), remote_commit.id())? != remote_commit.id() {\n                return Err(RepositoryError::InvalidPath(\n                    \"Local changes conflict with upstream\".to_string(),\n                ));\n            }\n        } else {\n            git2::Repository::clone(&upstream.url, target_path)?;\n        }\n\n        Ok(())\n    }\n}\n\nimpl FederationManager {\n    pub fn new(config: FederationConfig) -> Self {\n        Self { config }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_federation_config_serialization() {\n        let config = FederationConfig {\n            upstreams: vec![UpstreamConfig {\n                id: \"test\".to_string(),\n                url: \"https://github.com/test/repo\".to_string(),\n                branch: \"main\".to_string(),\n                auth_token: Some(\"secret\".to_string()),\n            }],\n            sync_interval_secs: 3600,\n        };\n\n        let json = serde_json::to_string(&config).unwrap();\n        let decoded: FederationConfig = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(decoded.upstreams.len(), 1);\n        assert_eq!(decoded.upstreams[0].id, \"test\");\n        assert_eq!(decoded.sync_interval_secs, 3600);\n    }\n\n    #[tokio::test]\n    async fn test_fetch_upstream_manifest_not_found() {\n        let manager = FederationManager::new(FederationConfig {\n            upstreams: vec![],\n            sync_interval_secs: 60,\n        });\n\n        let result = manager.fetch_upstream_manifest(\"nonexistent\").await;\n        assert!(result.is_err());\n        match result {\n            Err(RepositoryError::InvalidPath(msg)) => assert!(msg.contains(\"Upstream not found\")),\n            _ => panic!(\"Expected InvalidPath error\"),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_sync_upstream_not_found() {\n        let manager = FederationManager::new(FederationConfig {\n            upstreams: vec![],\n            sync_interval_secs: 60,\n        });\n\n        let result = manager\n            .sync_upstream(\"nonexistent\", std::path::Path::new(\"/tmp\"))\n            .await;\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_knowledge_manifest_serialization() {\n        let mut items = HashMap::new();\n        items.insert(\"key1\".to_string(), \"hash1\".to_string());\n\n        let manifest = KnowledgeManifest {\n            version: \"1.0\".to_string(),\n            items,\n        };\n\n        let json = serde_json::to_string(&manifest).unwrap();\n        let decoded: KnowledgeManifest = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(decoded.version, \"1.0\");\n        assert_eq!(decoded.items.get(\"key1\").unwrap(), \"hash1\");\n    }\n}\n","traces":[{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":1}},{"line":59,"address":[],"length":0,"stats":{"Line":1}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":1}},{"line":79,"address":[],"length":0,"stats":{"Line":1}},{"line":106,"address":[],"length":0,"stats":{"Line":2}}],"covered":5,"coverable":9},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","governance.rs"],"content":"use crate::telemetry::KnowledgeTelemetry;\nuse mk_core::traits::{EmbeddingService, EventPublisher, LlmService};\nuse mk_core::types::{\n    ConstraintSeverity, GovernanceEvent, KnowledgeLayer, Policy, PolicyViolation, TenantContext,\n    ValidationResult,\n};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse storage::events::EventError;\n\npub struct GovernanceEngine {\n    policies: HashMap<KnowledgeLayer, Vec<Policy>>,\n    telemetry: KnowledgeTelemetry,\n    storage:\n        Option<Arc<dyn mk_core::traits::StorageBackend<Error = storage::postgres::PostgresError>>>,\n    event_publisher: Option<Arc<dyn EventPublisher<Error = EventError>>>,\n    embedding_service: Option<Arc<dyn EmbeddingService<Error = anyhow::Error>>>,\n    llm_service: Option<Arc<dyn LlmService<Error = Box<dyn std::error::Error + Send + Sync>>>>,\n    knowledge_repository: Option<\n        Arc<dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>>,\n    >,\n}\n\nimpl GovernanceEngine {\n    pub fn new() -> Self {\n        Self {\n            policies: HashMap::new(),\n            telemetry: KnowledgeTelemetry,\n            storage: None,\n            event_publisher: None,\n            embedding_service: None,\n            llm_service: None,\n            knowledge_repository: None,\n        }\n    }\n\n    pub fn with_storage(\n        mut self,\n        storage: Arc<dyn mk_core::traits::StorageBackend<Error = storage::postgres::PostgresError>>,\n    ) -> Self {\n        self.storage = Some(storage);\n        self\n    }\n\n    pub fn with_event_publisher(\n        mut self,\n        publisher: Arc<dyn EventPublisher<Error = EventError>>,\n    ) -> Self {\n        self.event_publisher = Some(publisher);\n        self\n    }\n\n    pub fn with_embedding_service(\n        mut self,\n        embedding_service: Arc<dyn EmbeddingService<Error = anyhow::Error>>,\n    ) -> Self {\n        self.embedding_service = Some(embedding_service);\n        self\n    }\n\n    pub fn with_llm_service(\n        mut self,\n        llm_service: Arc<dyn LlmService<Error = Box<dyn std::error::Error + Send + Sync>>>,\n    ) -> Self {\n        self.llm_service = Some(llm_service);\n        self\n    }\n\n    pub fn with_repository(\n        mut self,\n        repository: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        >,\n    ) -> Self {\n        self.knowledge_repository = Some(repository);\n        self\n    }\n\n    pub fn storage(\n        &self,\n    ) -> Option<Arc<dyn mk_core::traits::StorageBackend<Error = storage::postgres::PostgresError>>>\n    {\n        self.storage.clone()\n    }\n\n    pub fn llm_service(\n        &self,\n    ) -> Option<Arc<dyn LlmService<Error = Box<dyn std::error::Error + Send + Sync>>>> {\n        self.llm_service.clone()\n    }\n\n    pub fn repository(\n        &self,\n    ) -> Option<\n        Arc<dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>>,\n    > {\n        self.knowledge_repository.clone()\n    }\n    pub async fn publish_event(&self, event: GovernanceEvent) -> Result<(), EventError> {\n        if let Some(publisher) = &self.event_publisher {\n            publisher.publish(event).await\n        } else {\n            Ok(())\n        }\n    }\n}\n\nimpl Default for GovernanceEngine {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\nimpl GovernanceEngine {\n    pub fn add_policy(&mut self, policy: Policy) {\n        self.policies.entry(policy.layer).or_default().push(policy);\n    }\n\n    pub fn event_publisher(&self) -> Option<Arc<dyn EventPublisher<Error = EventError>>> {\n        self.event_publisher.clone()\n    }\n\n    pub fn validate(\n        &self,\n        target_layer: KnowledgeLayer,\n        context: &HashMap<String, serde_json::Value>,\n    ) -> ValidationResult {\n        let mut resolved_map: HashMap<String, Policy> = HashMap::new();\n        let mut mandatory_policies: HashMap<String, KnowledgeLayer> = HashMap::new();\n\n        let layers = [\n            KnowledgeLayer::Company,\n            KnowledgeLayer::Org,\n            KnowledgeLayer::Team,\n            KnowledgeLayer::Project,\n        ];\n\n        for layer in &layers {\n            if let Some(layer_policies) = self.policies.get(layer) {\n                for policy in layer_policies {\n                    let mut p = policy.clone();\n                    p.layer = *layer;\n                    self.merge_policy(&mut resolved_map, &mut mandatory_policies, p);\n                }\n            }\n            if layer == &target_layer {\n                break;\n            }\n        }\n\n        let mut violations = Vec::new();\n        let mut resolved_vec: Vec<Policy> = resolved_map.into_values().collect();\n        resolved_vec.sort_by_key(|p| p.layer);\n\n        for policy in resolved_vec {\n            for rule in &policy.rules {\n                if let Some(violation) = self.evaluate_rule(&policy, rule, context) {\n                    self.telemetry.record_violation(\n                        &format!(\"{:?}\", policy.layer),\n                        &format!(\"{:?}\", rule.severity),\n                    );\n                    violations.push(violation);\n                }\n            }\n        }\n\n        ValidationResult {\n            is_valid: violations.is_empty(),\n            violations,\n        }\n    }\n\n    pub async fn validate_with_context(\n        &self,\n        target_layer: KnowledgeLayer,\n        context: &HashMap<String, serde_json::Value>,\n        tenant_ctx: Option<&TenantContext>,\n    ) -> ValidationResult {\n        let mut violations = Vec::new();\n\n        let active_policies = self\n            .resolve_active_policies(target_layer, context, tenant_ctx)\n            .await;\n\n        for policy in active_policies {\n            for rule in &policy.rules {\n                if let Some(violation) = self.evaluate_rule(&policy, rule, context) {\n                    self.telemetry.record_violation(\n                        &format!(\"{:?}\", policy.layer),\n                        &format!(\"{:?}\", rule.severity),\n                    );\n                    violations.push(violation);\n                }\n            }\n        }\n\n        if !violations.is_empty() {\n            self.emit_drift_event(context, tenant_ctx, &violations)\n                .await;\n        }\n\n        ValidationResult {\n            is_valid: violations.is_empty(),\n            violations,\n        }\n    }\n\n    async fn resolve_active_policies(\n        &self,\n        target_layer: KnowledgeLayer,\n        context: &HashMap<String, serde_json::Value>,\n        tenant_ctx: Option<&TenantContext>,\n    ) -> Vec<Policy> {\n        let mut resolved_map: HashMap<String, Policy> = HashMap::new();\n        let mut mandatory_policies: HashMap<String, KnowledgeLayer> = HashMap::new();\n\n        let layers = [\n            KnowledgeLayer::Company,\n            KnowledgeLayer::Org,\n            KnowledgeLayer::Team,\n            KnowledgeLayer::Project,\n        ];\n\n        for layer in &layers {\n            if let Some(layer_policies) = self.policies.get(layer) {\n                for policy in layer_policies {\n                    self.merge_policy(&mut resolved_map, &mut mandatory_policies, policy.clone());\n                }\n            }\n            if layer == &target_layer {\n                break;\n            }\n        }\n\n        if let Some(storage) = &self.storage {\n            let unit_id = context\n                .get(\"unitId\")\n                .or_else(|| context.get(\"projectId\"))\n                .and_then(|v| v.as_str());\n\n            if let Some(uid) = unit_id {\n                let ctx = tenant_ctx.cloned().unwrap_or_default();\n\n                let mut units = Vec::new();\n                if let Ok(mut ancestors) = storage.get_ancestors(ctx.clone(), uid).await {\n                    units.append(&mut ancestors);\n                }\n\n                units.reverse();\n\n                for unit in units {\n                    if let Ok(unit_policies) =\n                        storage.get_unit_policies(ctx.clone(), &unit.id).await\n                    {\n                        for policy in unit_policies {\n                            self.merge_policy(&mut resolved_map, &mut mandatory_policies, policy);\n                        }\n                    }\n                }\n\n                if let Ok(unit_policies) = storage.get_unit_policies(ctx, uid).await {\n                    for policy in unit_policies {\n                        self.merge_policy(&mut resolved_map, &mut mandatory_policies, policy);\n                    }\n                }\n            }\n        }\n\n        resolved_map.into_values().collect()\n    }\n\n    fn merge_policy(\n        &self,\n        resolved: &mut HashMap<String, Policy>,\n        mandatory_policies: &mut HashMap<String, KnowledgeLayer>,\n        incoming: Policy,\n    ) {\n        use mk_core::types::{PolicyMode, RuleMergeStrategy};\n\n        let policy_id = incoming.id.clone();\n\n        if let Some(mandatory_layer) = mandatory_policies.get(&policy_id) {\n            if incoming.layer != *mandatory_layer\n                && incoming.merge_strategy != RuleMergeStrategy::Override\n            {\n                return;\n            }\n        }\n\n        if incoming.mode == PolicyMode::Mandatory {\n            mandatory_policies.insert(policy_id.clone(), incoming.layer);\n        }\n\n        if let Some(existing) = resolved.get_mut(&policy_id) {\n            match incoming.merge_strategy {\n                RuleMergeStrategy::Override => {\n                    *existing = incoming;\n                }\n                RuleMergeStrategy::Merge => {\n                    for rule in incoming.rules {\n                        if !existing.rules.iter().any(|r| r.id == rule.id) {\n                            existing.rules.push(rule);\n                        }\n                    }\n                    for (k, v) in incoming.metadata {\n                        existing.metadata.insert(k, v);\n                    }\n                    existing.layer = incoming.layer;\n                }\n                RuleMergeStrategy::Intersect => {\n                    existing\n                        .rules\n                        .retain(|r| incoming.rules.iter().any(|ir| ir.id == r.id));\n                    existing.layer = incoming.layer;\n                }\n            }\n        } else {\n            resolved.insert(policy_id, incoming);\n        }\n    }\n\n    pub async fn check_drift(\n        &self,\n        tenant_ctx: &TenantContext,\n        _project_id: &str,\n        context: &HashMap<String, serde_json::Value>,\n    ) -> Result<f32, anyhow::Error> {\n        let mut violations = Vec::new();\n        let mut confidence: f32 = 1.0;\n\n        let content = context.get(\"content\").and_then(|v| v.as_str());\n        if let Some(c) = content {\n            if self.embedding_service.is_some() {\n                let mut semantic_violations = self.check_contradictions(tenant_ctx, c, 0.8).await?;\n                if !semantic_violations.is_empty() {\n                    confidence = confidence.min(0.85);\n                }\n                violations.append(&mut semantic_violations);\n            }\n        }\n\n        let active_policies = self\n            .resolve_active_policies(KnowledgeLayer::Project, context, Some(tenant_ctx))\n            .await;\n\n        for policy in &active_policies {\n            for rule in &policy.rules {\n                if let Some(violation) = self.evaluate_rule(policy, rule, context) {\n                    violations.push(violation);\n                }\n            }\n        }\n\n        let mandatory_policies_count = active_policies\n            .iter()\n            .filter(|p| p.mode == mk_core::types::PolicyMode::Mandatory)\n            .count();\n\n        if mandatory_policies_count == 0 {\n            violations.push(PolicyViolation {\n                rule_id: \"missing_mandatory_policies\".to_string(),\n                policy_id: \"governance_requirement\".to_string(),\n                severity: ConstraintSeverity::Warn,\n                message: \"No mandatory policies detected for this project layer\".to_string(),\n                context: context.clone(),\n            });\n        }\n\n        for policy in &active_policies {\n            if let Some(expected_hash) =\n                policy.metadata.get(\"version_hash\").and_then(|v| v.as_str())\n            {\n                let actual_hash = context.get(\"version_hash\").and_then(|v| v.as_str());\n                if let Some(actual) = actual_hash {\n                    if actual != expected_hash {\n                        violations.push(PolicyViolation {\n                            rule_id: \"stale_policy_reference\".to_string(),\n                            policy_id: policy.id.clone(),\n                            severity: ConstraintSeverity::Warn,\n                            message: format!(\n                                \"Project uses stale policy version (expected: {}, actual: {})\",\n                                expected_hash, actual\n                            ),\n                            context: context.clone(),\n                        });\n                    }\n                }\n            }\n        }\n\n        if let Some(c) = content {\n            if let Some(llm_violations) = self\n                .analyze_drift_with_llm(c, &active_policies, context)\n                .await\n            {\n                confidence = confidence.min(0.75);\n                for v in llm_violations {\n                    if !violations\n                        .iter()\n                        .any(|existing| existing.rule_id == v.rule_id)\n                    {\n                        violations.push(v);\n                    }\n                }\n            }\n        }\n\n        let (active_violations, suppressed_violations) = if let Some(storage) = &self.storage {\n            let suppressions = storage\n                .list_suppressions(tenant_ctx.clone(), _project_id)\n                .await\n                .unwrap_or_default();\n\n            let active_suppressions: Vec<_> = suppressions\n                .into_iter()\n                .filter(|s| !s.is_expired())\n                .collect();\n\n            self.apply_suppressions(violations, &active_suppressions)\n        } else {\n            (violations, Vec::new())\n        };\n\n        let drift_config = if let Some(storage) = &self.storage {\n            storage\n                .get_drift_config(tenant_ctx.clone(), _project_id)\n                .await\n                .ok()\n                .flatten()\n        } else {\n            None\n        };\n\n        let config = drift_config.unwrap_or_default();\n\n        if config.auto_suppress_info {\n            let filtered: Vec<_> = active_violations\n                .iter()\n                .filter(|v| v.severity != ConstraintSeverity::Info)\n                .cloned()\n                .collect();\n            let auto_suppressed: Vec<_> = active_violations\n                .iter()\n                .filter(|v| v.severity == ConstraintSeverity::Info)\n                .cloned()\n                .collect();\n            let mut all_suppressed = suppressed_violations;\n            all_suppressed.extend(auto_suppressed);\n\n            let drift_score = self.calculate_drift_score(&filtered);\n\n            if drift_score > 0.0 {\n                self.emit_drift_event(context, Some(tenant_ctx), &filtered)\n                    .await;\n            }\n\n            if let Some(storage) = &self.storage {\n                let drift_result = mk_core::types::DriftResult::new(\n                    _project_id.to_string(),\n                    tenant_ctx.tenant_id.clone(),\n                    filtered,\n                )\n                .with_confidence(confidence)\n                .with_suppressions(all_suppressed);\n                let _ = storage.store_drift_result(drift_result).await;\n            }\n\n            return Ok(drift_score);\n        }\n\n        let drift_score = self.calculate_drift_score(&active_violations);\n\n        if drift_score > 0.0 {\n            self.emit_drift_event(context, Some(tenant_ctx), &active_violations)\n                .await;\n        }\n\n        if let Some(storage) = &self.storage {\n            let drift_result = mk_core::types::DriftResult::new(\n                _project_id.to_string(),\n                tenant_ctx.tenant_id.clone(),\n                active_violations,\n            )\n            .with_confidence(confidence)\n            .with_suppressions(suppressed_violations);\n            let _ = storage.store_drift_result(drift_result).await;\n        }\n\n        Ok(drift_score)\n    }\n\n    fn apply_suppressions(\n        &self,\n        violations: Vec<PolicyViolation>,\n        suppressions: &[mk_core::types::DriftSuppression],\n    ) -> (Vec<PolicyViolation>, Vec<PolicyViolation>) {\n        let mut active = Vec::new();\n        let mut suppressed = Vec::new();\n\n        for violation in violations {\n            let is_suppressed = suppressions.iter().any(|s| s.matches(&violation));\n            if is_suppressed {\n                suppressed.push(violation);\n            } else {\n                active.push(violation);\n            }\n        }\n\n        (active, suppressed)\n    }\n\n    async fn analyze_drift_with_llm(\n        &self,\n        content: &str,\n        policies: &[Policy],\n        context: &HashMap<String, serde_json::Value>,\n    ) -> Option<Vec<PolicyViolation>> {\n        let llm = self.llm_service.as_ref()?;\n\n        if policies.is_empty() {\n            return None;\n        }\n\n        match llm.analyze_drift(content, policies).await {\n            Ok(result) => {\n                if result.is_valid {\n                    return None;\n                }\n\n                let violations = result\n                    .violations\n                    .into_iter()\n                    .map(|v| PolicyViolation {\n                        rule_id: format!(\"llm_{}\", v.rule_id),\n                        policy_id: v.policy_id,\n                        severity: v.severity,\n                        message: format!(\"[LLM Analysis] {}\", v.message),\n                        context: context.clone(),\n                    })\n                    .collect();\n\n                Some(violations)\n            }\n            Err(e) => {\n                tracing::warn!(\"LLM drift analysis failed: {}\", e);\n                None\n            }\n        }\n    }\n\n    fn calculate_drift_score(&self, violations: &[PolicyViolation]) -> f32 {\n        if violations.is_empty() {\n            return 0.0;\n        }\n\n        let score = violations\n            .iter()\n            .map(|v| match v.severity {\n                ConstraintSeverity::Block => 1.0,\n                ConstraintSeverity::Warn => 0.5,\n                ConstraintSeverity::Info => 0.1,\n            })\n            .sum::<f32>();\n\n        score.min(1.0)\n    }\n\n    async fn emit_drift_event(\n        &self,\n        context: &HashMap<String, serde_json::Value>,\n        tenant_ctx: Option<&TenantContext>,\n        violations: &[PolicyViolation],\n    ) {\n        if let Some(publisher) = &self.event_publisher {\n            let project_id = context\n                .get(\"projectId\")\n                .and_then(|v| v.as_str())\n                .or_else(|| context.get(\"unitId\").and_then(|v| v.as_str()));\n\n            if let Some(pid) = project_id {\n                let drift_score = violations\n                    .iter()\n                    .map(|v| match v.severity {\n                        mk_core::types::ConstraintSeverity::Block => 1.0,\n                        mk_core::types::ConstraintSeverity::Warn => 0.5,\n                        mk_core::types::ConstraintSeverity::Info => 0.1,\n                    })\n                    .sum::<f32>();\n\n                let _ = publisher\n                    .publish(GovernanceEvent::DriftDetected {\n                        project_id: pid.to_string(),\n                        tenant_id: tenant_ctx.map(|c| c.tenant_id.clone()).unwrap_or_default(),\n                        drift_score: drift_score.min(1.0),\n                        timestamp: chrono::Utc::now().timestamp(),\n                    })\n                    .await;\n            }\n        }\n    }\n\n    fn evaluate_rule(\n        &self,\n        policy: &Policy,\n        rule: &mk_core::types::PolicyRule,\n        context: &HashMap<String, serde_json::Value>,\n    ) -> Option<PolicyViolation> {\n        use mk_core::types::{ConstraintOperator, RuleType};\n\n        let target_key = match rule.target {\n            mk_core::types::ConstraintTarget::File => \"path\",\n            mk_core::types::ConstraintTarget::Code => \"content\",\n            mk_core::types::ConstraintTarget::Dependency => \"dependencies\",\n            mk_core::types::ConstraintTarget::Import => \"imports\",\n            mk_core::types::ConstraintTarget::Config => \"config\",\n        };\n\n        let value = context.get(target_key);\n\n        let is_condition_met = match rule.operator {\n            ConstraintOperator::MustExist => value.is_some(),\n            ConstraintOperator::MustNotExist => value.is_none(),\n            ConstraintOperator::MustUse => {\n                if let Some(v) = value {\n                    if let Some(arr) = v.as_array() {\n                        arr.contains(&rule.value)\n                    } else {\n                        v == &rule.value\n                    }\n                } else {\n                    false\n                }\n            }\n            ConstraintOperator::MustNotUse => {\n                if let Some(v) = value {\n                    if let Some(arr) = v.as_array() {\n                        !arr.contains(&rule.value)\n                    } else {\n                        v != &rule.value\n                    }\n                } else {\n                    true\n                }\n            }\n            ConstraintOperator::MustMatch => {\n                if let Some(v) = value {\n                    if let Some(s) = v.as_str() {\n                        if let Some(re_str) = rule.value.as_str() {\n                            if let Ok(re) = regex::Regex::new(re_str) {\n                                re.is_match(s)\n                            } else {\n                                false\n                            }\n                        } else {\n                            false\n                        }\n                    } else {\n                        false\n                    }\n                } else {\n                    false\n                }\n            }\n            ConstraintOperator::MustNotMatch => {\n                if let Some(v) = value {\n                    if let Some(s) = v.as_str() {\n                        if let Some(re_str) = rule.value.as_str() {\n                            if let Ok(re) = regex::Regex::new(re_str) {\n                                !re.is_match(s)\n                            } else {\n                                true\n                            }\n                        } else {\n                            true\n                        }\n                    } else {\n                        true\n                    }\n                } else {\n                    true\n                }\n            }\n        };\n\n        let is_violated = match rule.rule_type {\n            RuleType::Allow => !is_condition_met,\n            RuleType::Deny => is_condition_met,\n        };\n\n        if is_violated {\n            Some(PolicyViolation {\n                rule_id: rule.id.clone(),\n                policy_id: policy.id.clone(),\n                severity: rule.severity,\n                message: rule.message.clone(),\n                context: context.clone(),\n            })\n        } else {\n            None\n        }\n    }\n\n    pub async fn check_contradictions(\n        &self,\n        tenant_ctx: &TenantContext,\n        content: &str,\n        threshold: f32,\n    ) -> Result<Vec<PolicyViolation>, anyhow::Error> {\n        let embedding_service = self\n            .embedding_service\n            .as_ref()\n            .ok_or_else(|| anyhow::anyhow!(\"Embedding service not configured\"))?;\n\n        let content_embedding = embedding_service.embed(content).await?;\n\n        let mut violations = Vec::new();\n\n        let mut context = HashMap::new();\n        context.insert(\"content\".to_string(), serde_json::json!(content));\n\n        let active_policies = self\n            .resolve_active_policies(KnowledgeLayer::Project, &context, Some(tenant_ctx))\n            .await;\n\n        for policy in active_policies {\n            for rule in &policy.rules {\n                if let Some(rule_embedding_val) =\n                    policy.metadata.get(&format!(\"rule_{}_embedding\", rule.id))\n                {\n                    if let Ok(rule_embedding) =\n                        serde_json::from_value::<Vec<f32>>(rule_embedding_val.clone())\n                    {\n                        let similarity =\n                            self.cosine_similarity(&content_embedding, &rule_embedding);\n                        if similarity > threshold {\n                            violations.push(PolicyViolation {\n                                rule_id: rule.id.clone(),\n                                policy_id: policy.id.clone(),\n                                severity: rule.severity,\n                                message: format!(\n                                    \"Semantic contradiction detected (similarity: {:.2}): {}\",\n                                    similarity, rule.message\n                                ),\n                                context: context.clone(),\n                            });\n                        }\n                    }\n                }\n            }\n        }\n\n        Ok(violations)\n    }\n\n    fn cosine_similarity(&self, v1: &[f32], v2: &[f32]) -> f32 {\n        if v1.len() != v2.len() || v1.is_empty() {\n            return 0.0;\n        }\n        let dot_product: f32 = v1.iter().zip(v2.iter()).map(|(a, b)| a * b).sum();\n        let norm1: f32 = v1.iter().map(|a| a * a).sum::<f32>().sqrt();\n        let norm2: f32 = v2.iter().map(|a| a * a).sum::<f32>().sqrt();\n\n        if norm1 == 0.0 || norm2 == 0.0 {\n            0.0\n        } else {\n            dot_product / (norm1 * norm2)\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::{ConstraintOperator, ConstraintSeverity, ConstraintTarget, PolicyRule};\n\n    #[test]\n    fn test_governance_engine_evaluation() {\n        let mut engine = GovernanceEngine::new();\n\n        let company_policy = Policy {\n            id: \"p1\".to_string(),\n            name: \"Security Standards\".to_string(),\n            description: None,\n            layer: KnowledgeLayer::Company,\n            rules: vec![\n                PolicyRule {\n                    id: \"r1\".to_string(),\n                    target: ConstraintTarget::Dependency,\n                    operator: ConstraintOperator::MustNotUse,\n                    value: serde_json::json!(\"unsafe-lib\"),\n                    severity: ConstraintSeverity::Block,\n                    message: \"unsafe-lib is banned\".to_string(),\n                    rule_type: mk_core::types::RuleType::Allow,\n                },\n                PolicyRule {\n                    id: \"r2\".to_string(),\n                    target: ConstraintTarget::Code,\n                    operator: ConstraintOperator::MustMatch,\n                    value: serde_json::json!(\"^# ADR\"),\n                    severity: ConstraintSeverity::Warn,\n                    message: \"ADRs must start with # ADR\".to_string(),\n                    rule_type: mk_core::types::RuleType::Allow,\n                },\n            ],\n            metadata: HashMap::new(),\n            mode: mk_core::types::PolicyMode::Optional,\n            merge_strategy: mk_core::types::RuleMergeStrategy::Merge,\n        };\n\n        engine.add_policy(company_policy);\n\n        let mut context = HashMap::new();\n        context.insert(\n            \"dependencies\".to_string(),\n            serde_json::json!([\"safe-lib\", \"unsafe-lib\"]),\n        );\n        context.insert(\"content\".to_string(), serde_json::json!(\"# ADR 001\\n...\"));\n\n        let result = engine.validate(KnowledgeLayer::Project, &context);\n        assert!(!result.is_valid);\n        assert_eq!(result.violations.len(), 1);\n        assert_eq!(result.violations[0].rule_id, \"r1\");\n\n        let mut context = HashMap::new();\n        context.insert(\"dependencies\".to_string(), serde_json::json!([\"safe-lib\"]));\n        context.insert(\"content\".to_string(), serde_json::json!(\"ADR 001\\n...\"));\n\n        let result = engine.validate(KnowledgeLayer::Project, &context);\n        assert!(!result.is_valid);\n        assert_eq!(result.violations.len(), 1);\n        assert_eq!(result.violations[0].rule_id, \"r2\");\n\n        let mut context = HashMap::new();\n        context.insert(\"dependencies\".to_string(), serde_json::json!([\"safe-lib\"]));\n        context.insert(\"content\".to_string(), serde_json::json!(\"# ADR 001\\n...\"));\n\n        let result = engine.validate(KnowledgeLayer::Project, &context);\n        assert!(result.is_valid);\n    }\n\n    fn create_test_policy(rule: PolicyRule) -> Policy {\n        Policy {\n            id: \"test-policy\".to_string(),\n            name: \"Test Policy\".to_string(),\n            description: None,\n            layer: KnowledgeLayer::Project,\n            rules: vec![rule],\n            metadata: HashMap::new(),\n            mode: mk_core::types::PolicyMode::Optional,\n            merge_strategy: mk_core::types::RuleMergeStrategy::Merge,\n        }\n    }\n\n    fn create_rule(\n        operator: ConstraintOperator,\n        target: ConstraintTarget,\n        value: serde_json::Value,\n    ) -> PolicyRule {\n        PolicyRule {\n            id: \"test-rule\".to_string(),\n            target,\n            operator,\n            value,\n            severity: ConstraintSeverity::Block,\n            message: \"Test rule violation\".to_string(),\n            rule_type: mk_core::types::RuleType::Allow,\n        }\n    }\n\n    #[test]\n    fn test_evaluate_rule_must_exist_passes_when_value_present() {\n        let engine = GovernanceEngine::new();\n        let rule = create_rule(\n            ConstraintOperator::MustExist,\n            ConstraintTarget::File,\n            serde_json::json!(null),\n        );\n        let policy = create_test_policy(rule.clone());\n\n        let mut context = HashMap::new();\n        context.insert(\"path\".to_string(), serde_json::json!(\"src/main.rs\"));\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_none());\n    }\n\n    #[test]\n    fn test_evaluate_rule_must_exist_fails_when_value_absent() {\n        let engine = GovernanceEngine::new();\n        let rule = create_rule(\n            ConstraintOperator::MustExist,\n            ConstraintTarget::File,\n            serde_json::json!(null),\n        );\n        let policy = create_test_policy(rule.clone());\n\n        let context = HashMap::new();\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_some());\n    }\n\n    #[test]\n    fn test_evaluate_rule_must_not_exist_passes_when_value_absent() {\n        let engine = GovernanceEngine::new();\n        let rule = create_rule(\n            ConstraintOperator::MustNotExist,\n            ConstraintTarget::File,\n            serde_json::json!(null),\n        );\n        let policy = create_test_policy(rule.clone());\n\n        let context = HashMap::new();\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_none());\n    }\n\n    #[test]\n    fn test_evaluate_rule_must_not_exist_fails_when_value_present() {\n        let engine = GovernanceEngine::new();\n        let rule = create_rule(\n            ConstraintOperator::MustNotExist,\n            ConstraintTarget::File,\n            serde_json::json!(null),\n        );\n        let policy = create_test_policy(rule.clone());\n\n        let mut context = HashMap::new();\n        context.insert(\"path\".to_string(), serde_json::json!(\"forbidden.txt\"));\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_some());\n    }\n\n    #[test]\n    fn test_evaluate_rule_must_use_with_array_passes_when_value_in_array() {\n        let engine = GovernanceEngine::new();\n        let rule = create_rule(\n            ConstraintOperator::MustUse,\n            ConstraintTarget::Dependency,\n            serde_json::json!(\"required-lib\"),\n        );\n        let policy = create_test_policy(rule.clone());\n\n        let mut context = HashMap::new();\n        context.insert(\n            \"dependencies\".to_string(),\n            serde_json::json!([\"required-lib\", \"other-lib\"]),\n        );\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_none());\n    }\n\n    #[test]\n    fn test_evaluate_rule_must_use_with_array_fails_when_value_not_in_array() {\n        let engine = GovernanceEngine::new();\n        let rule = create_rule(\n            ConstraintOperator::MustUse,\n            ConstraintTarget::Dependency,\n            serde_json::json!(\"required-lib\"),\n        );\n        let policy = create_test_policy(rule.clone());\n\n        let mut context = HashMap::new();\n        context.insert(\"dependencies\".to_string(), serde_json::json!([\"other-lib\"]));\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_some());\n    }\n\n    #[test]\n    fn test_evaluate_rule_must_use_with_scalar_passes_when_values_match() {\n        let engine = GovernanceEngine::new();\n        let rule = create_rule(\n            ConstraintOperator::MustUse,\n            ConstraintTarget::Config,\n            serde_json::json!(\"production\"),\n        );\n        let policy = create_test_policy(rule.clone());\n\n        let mut context = HashMap::new();\n        context.insert(\"config\".to_string(), serde_json::json!(\"production\"));\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_none());\n    }\n\n    #[test]\n    fn test_evaluate_rule_must_use_fails_when_value_absent() {\n        let engine = GovernanceEngine::new();\n        let rule = create_rule(\n            ConstraintOperator::MustUse,\n            ConstraintTarget::Dependency,\n            serde_json::json!(\"required-lib\"),\n        );\n        let policy = create_test_policy(rule.clone());\n\n        let context = HashMap::new();\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_some());\n    }\n\n    #[test]\n    fn test_evaluate_rule_must_not_use_with_array_passes_when_value_not_in_array() {\n        let engine = GovernanceEngine::new();\n        let rule = create_rule(\n            ConstraintOperator::MustNotUse,\n            ConstraintTarget::Dependency,\n            serde_json::json!(\"banned-lib\"),\n        );\n        let policy = create_test_policy(rule.clone());\n\n        let mut context = HashMap::new();\n        context.insert(\n            \"dependencies\".to_string(),\n            serde_json::json!([\"safe-lib\", \"another-lib\"]),\n        );\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_none());\n    }\n\n    #[test]\n    fn test_evaluate_rule_must_not_use_with_array_fails_when_value_in_array() {\n        let engine = GovernanceEngine::new();\n        let rule = create_rule(\n            ConstraintOperator::MustNotUse,\n            ConstraintTarget::Dependency,\n            serde_json::json!(\"banned-lib\"),\n        );\n        let policy = create_test_policy(rule.clone());\n\n        let mut context = HashMap::new();\n        context.insert(\n            \"dependencies\".to_string(),\n            serde_json::json!([\"safe-lib\", \"banned-lib\"]),\n        );\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_some());\n    }\n\n    #[test]\n    fn test_evaluate_rule_must_not_use_passes_when_value_absent() {\n        let engine = GovernanceEngine::new();\n        let rule = create_rule(\n            ConstraintOperator::MustNotUse,\n            ConstraintTarget::Dependency,\n            serde_json::json!(\"banned-lib\"),\n        );\n        let policy = create_test_policy(rule.clone());\n\n        let context = HashMap::new();\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_none());\n    }\n\n    #[test]\n    fn test_evaluate_rule_must_match_passes_when_regex_matches() {\n        let engine = GovernanceEngine::new();\n        let rule = create_rule(\n            ConstraintOperator::MustMatch,\n            ConstraintTarget::Code,\n            serde_json::json!(\"^# ADR\"),\n        );\n        let policy = create_test_policy(rule.clone());\n\n        let mut context = HashMap::new();\n        context.insert(\n            \"content\".to_string(),\n            serde_json::json!(\"# ADR 001\\nDecision...\"),\n        );\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_none());\n    }\n\n    #[test]\n    fn test_evaluate_rule_must_match_fails_when_regex_does_not_match() {\n        let engine = GovernanceEngine::new();\n        let rule = create_rule(\n            ConstraintOperator::MustMatch,\n            ConstraintTarget::Code,\n            serde_json::json!(\"^# ADR\"),\n        );\n        let policy = create_test_policy(rule.clone());\n\n        let mut context = HashMap::new();\n        context.insert(\n            \"content\".to_string(),\n            serde_json::json!(\"Some other content\"),\n        );\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_some());\n    }\n\n    #[test]\n    fn test_evaluate_rule_must_match_fails_when_value_absent() {\n        let engine = GovernanceEngine::new();\n        let rule = create_rule(\n            ConstraintOperator::MustMatch,\n            ConstraintTarget::Code,\n            serde_json::json!(\"^# ADR\"),\n        );\n        let policy = create_test_policy(rule.clone());\n\n        let context = HashMap::new();\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_some());\n    }\n\n    #[test]\n    fn test_evaluate_rule_must_match_fails_when_value_not_string() {\n        let engine = GovernanceEngine::new();\n        let rule = create_rule(\n            ConstraintOperator::MustMatch,\n            ConstraintTarget::Code,\n            serde_json::json!(\"^# ADR\"),\n        );\n        let policy = create_test_policy(rule.clone());\n\n        let mut context = HashMap::new();\n        context.insert(\"content\".to_string(), serde_json::json!(12345));\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_some());\n    }\n\n    #[test]\n    fn test_evaluate_rule_must_match_fails_when_regex_invalid() {\n        let engine = GovernanceEngine::new();\n        let rule = create_rule(\n            ConstraintOperator::MustMatch,\n            ConstraintTarget::Code,\n            serde_json::json!(\"[invalid(regex\"),\n        );\n        let policy = create_test_policy(rule.clone());\n\n        let mut context = HashMap::new();\n        context.insert(\"content\".to_string(), serde_json::json!(\"any content\"));\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_some());\n    }\n\n    #[test]\n    fn test_evaluate_rule_must_not_match_passes_when_regex_does_not_match() {\n        let engine = GovernanceEngine::new();\n        let rule = create_rule(\n            ConstraintOperator::MustNotMatch,\n            ConstraintTarget::Code,\n            serde_json::json!(\"TODO|FIXME\"),\n        );\n        let policy = create_test_policy(rule.clone());\n\n        let mut context = HashMap::new();\n        context.insert(\"content\".to_string(), serde_json::json!(\"Clean code here\"));\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_none());\n    }\n\n    #[test]\n    fn test_evaluate_rule_must_not_match_fails_when_regex_matches() {\n        let engine = GovernanceEngine::new();\n        let rule = create_rule(\n            ConstraintOperator::MustNotMatch,\n            ConstraintTarget::Code,\n            serde_json::json!(\"TODO|FIXME\"),\n        );\n        let policy = create_test_policy(rule.clone());\n\n        let mut context = HashMap::new();\n        context.insert(\n            \"content\".to_string(),\n            serde_json::json!(\"// TODO: fix this later\"),\n        );\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_some());\n    }\n\n    #[test]\n    fn test_evaluate_rule_must_not_match_passes_when_value_absent() {\n        let engine = GovernanceEngine::new();\n        let rule = create_rule(\n            ConstraintOperator::MustNotMatch,\n            ConstraintTarget::Code,\n            serde_json::json!(\"TODO\"),\n        );\n        let policy = create_test_policy(rule.clone());\n\n        let context = HashMap::new();\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_none());\n    }\n\n    #[test]\n    fn test_evaluate_rule_must_not_match_passes_when_value_not_string() {\n        let engine = GovernanceEngine::new();\n        let rule = create_rule(\n            ConstraintOperator::MustNotMatch,\n            ConstraintTarget::Code,\n            serde_json::json!(\"pattern\"),\n        );\n        let policy = create_test_policy(rule.clone());\n\n        let mut context = HashMap::new();\n        context.insert(\n            \"content\".to_string(),\n            serde_json::json!([\"not\", \"a\", \"string\"]),\n        );\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_none());\n    }\n\n    #[test]\n    fn test_evaluate_rule_must_not_match_passes_when_regex_invalid() {\n        let engine = GovernanceEngine::new();\n        let rule = create_rule(\n            ConstraintOperator::MustNotMatch,\n            ConstraintTarget::Code,\n            serde_json::json!(\"[invalid(regex\"),\n        );\n        let policy = create_test_policy(rule.clone());\n\n        let mut context = HashMap::new();\n        context.insert(\"content\".to_string(), serde_json::json!(\"any content\"));\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_none());\n    }\n\n    #[test]\n    fn test_evaluate_rule_must_not_match_passes_when_pattern_not_string() {\n        let engine = GovernanceEngine::new();\n        let rule = create_rule(\n            ConstraintOperator::MustNotMatch,\n            ConstraintTarget::Code,\n            serde_json::json!(12345),\n        );\n        let policy = create_test_policy(rule.clone());\n\n        let mut context = HashMap::new();\n        context.insert(\"content\".to_string(), serde_json::json!(\"any content\"));\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_none());\n    }\n\n    #[test]\n    fn test_evaluate_rule_deny_rule_type_inverts_logic() {\n        let engine = GovernanceEngine::new();\n        let mut rule = create_rule(\n            ConstraintOperator::MustExist,\n            ConstraintTarget::File,\n            serde_json::json!(null),\n        );\n        rule.rule_type = mk_core::types::RuleType::Deny;\n        let policy = create_test_policy(rule.clone());\n\n        let mut context = HashMap::new();\n        context.insert(\"path\".to_string(), serde_json::json!(\"src/main.rs\"));\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_some());\n    }\n\n    #[test]\n    fn test_evaluate_rule_all_constraint_targets() {\n        let engine = GovernanceEngine::new();\n\n        let targets_and_keys = [\n            (ConstraintTarget::File, \"path\"),\n            (ConstraintTarget::Code, \"content\"),\n            (ConstraintTarget::Dependency, \"dependencies\"),\n            (ConstraintTarget::Import, \"imports\"),\n            (ConstraintTarget::Config, \"config\"),\n        ];\n\n        for (target, key) in targets_and_keys {\n            let rule = create_rule(\n                ConstraintOperator::MustExist,\n                target,\n                serde_json::json!(null),\n            );\n            let policy = create_test_policy(rule.clone());\n\n            let mut context = HashMap::new();\n            context.insert(key.to_string(), serde_json::json!(\"value\"));\n\n            let result = engine.evaluate_rule(&policy, &rule, &context);\n            assert!(\n                result.is_none(),\n                \"Target {:?} with key {} should pass\",\n                target,\n                key\n            );\n        }\n    }\n\n    #[test]\n    fn test_evaluate_rule_violation_contains_correct_metadata() {\n        let engine = GovernanceEngine::new();\n        let mut rule = create_rule(\n            ConstraintOperator::MustExist,\n            ConstraintTarget::File,\n            serde_json::json!(null),\n        );\n        rule.id = \"specific-rule-id\".to_string();\n        rule.message = \"Custom error message\".to_string();\n        rule.severity = ConstraintSeverity::Warn;\n\n        let mut policy = create_test_policy(rule.clone());\n        policy.id = \"specific-policy-id\".to_string();\n\n        let mut context = HashMap::new();\n        context.insert(\"other_key\".to_string(), serde_json::json!(\"value\"));\n\n        let result = engine.evaluate_rule(&policy, &rule, &context);\n        assert!(result.is_some());\n\n        let violation = result.unwrap();\n        assert_eq!(violation.rule_id, \"specific-rule-id\");\n        assert_eq!(violation.policy_id, \"specific-policy-id\");\n        assert_eq!(violation.message, \"Custom error message\");\n        assert_eq!(violation.severity, ConstraintSeverity::Warn);\n        assert!(violation.context.contains_key(\"other_key\"));\n    }\n\n    #[test]\n    fn test_cosine_similarity_identical_vectors() {\n        let engine = GovernanceEngine::new();\n        let v1 = vec![1.0, 2.0, 3.0];\n        let v2 = vec![1.0, 2.0, 3.0];\n        let similarity = engine.cosine_similarity(&v1, &v2);\n        assert!((similarity - 1.0).abs() < 0.0001);\n    }\n\n    #[test]\n    fn test_cosine_similarity_orthogonal_vectors() {\n        let engine = GovernanceEngine::new();\n        let v1 = vec![1.0, 0.0];\n        let v2 = vec![0.0, 1.0];\n        let similarity = engine.cosine_similarity(&v1, &v2);\n        assert!(similarity.abs() < 0.0001);\n    }\n\n    #[test]\n    fn test_cosine_similarity_different_lengths() {\n        let engine = GovernanceEngine::new();\n        let v1 = vec![1.0, 2.0, 3.0];\n        let v2 = vec![1.0, 2.0];\n        let similarity = engine.cosine_similarity(&v1, &v2);\n        assert_eq!(similarity, 0.0);\n    }\n\n    #[test]\n    fn test_cosine_similarity_empty_vectors() {\n        let engine = GovernanceEngine::new();\n        let v1: Vec<f32> = vec![];\n        let v2: Vec<f32> = vec![];\n        let similarity = engine.cosine_similarity(&v1, &v2);\n        assert_eq!(similarity, 0.0);\n    }\n\n    #[test]\n    fn test_cosine_similarity_zero_vector() {\n        let engine = GovernanceEngine::new();\n        let v1 = vec![0.0, 0.0, 0.0];\n        let v2 = vec![1.0, 2.0, 3.0];\n        let similarity = engine.cosine_similarity(&v1, &v2);\n        assert_eq!(similarity, 0.0);\n    }\n\n    #[test]\n    fn test_governance_engine_default() {\n        let engine = GovernanceEngine::default();\n        assert!(engine.storage().is_none());\n        assert!(engine.llm_service().is_none());\n        assert!(engine.repository().is_none());\n        assert!(engine.event_publisher().is_none());\n    }\n\n    #[test]\n    fn test_calculate_drift_score_empty_violations() {\n        let engine = GovernanceEngine::new();\n        let violations: Vec<PolicyViolation> = vec![];\n        let score = engine.calculate_drift_score(&violations);\n        assert_eq!(score, 0.0);\n    }\n\n    #[test]\n    fn test_calculate_drift_score_single_block() {\n        let engine = GovernanceEngine::new();\n        let violations = vec![PolicyViolation {\n            rule_id: \"test\".to_string(),\n            policy_id: \"test\".to_string(),\n            severity: ConstraintSeverity::Block,\n            message: \"Test\".to_string(),\n            context: HashMap::new(),\n        }];\n        let score = engine.calculate_drift_score(&violations);\n        assert_eq!(score, 1.0);\n    }\n\n    #[test]\n    fn test_calculate_drift_score_single_warn() {\n        let engine = GovernanceEngine::new();\n        let violations = vec![PolicyViolation {\n            rule_id: \"test\".to_string(),\n            policy_id: \"test\".to_string(),\n            severity: ConstraintSeverity::Warn,\n            message: \"Test\".to_string(),\n            context: HashMap::new(),\n        }];\n        let score = engine.calculate_drift_score(&violations);\n        assert!((score - 0.5).abs() < 0.001);\n    }\n\n    #[test]\n    fn test_calculate_drift_score_single_info() {\n        let engine = GovernanceEngine::new();\n        let violations = vec![PolicyViolation {\n            rule_id: \"test\".to_string(),\n            policy_id: \"test\".to_string(),\n            severity: ConstraintSeverity::Info,\n            message: \"Test\".to_string(),\n            context: HashMap::new(),\n        }];\n        let score = engine.calculate_drift_score(&violations);\n        assert!((score - 0.1).abs() < 0.001);\n    }\n\n    #[test]\n    fn test_calculate_drift_score_capped_at_one() {\n        let engine = GovernanceEngine::new();\n        let violations = vec![\n            PolicyViolation {\n                rule_id: \"test1\".to_string(),\n                policy_id: \"test\".to_string(),\n                severity: ConstraintSeverity::Block,\n                message: \"Test\".to_string(),\n                context: HashMap::new(),\n            },\n            PolicyViolation {\n                rule_id: \"test2\".to_string(),\n                policy_id: \"test\".to_string(),\n                severity: ConstraintSeverity::Block,\n                message: \"Test\".to_string(),\n                context: HashMap::new(),\n            },\n        ];\n        let score = engine.calculate_drift_score(&violations);\n        assert_eq!(score, 1.0);\n    }\n\n    #[test]\n    fn test_calculate_drift_score_mixed_severities() {\n        let engine = GovernanceEngine::new();\n        let violations = vec![\n            PolicyViolation {\n                rule_id: \"warn\".to_string(),\n                policy_id: \"test\".to_string(),\n                severity: ConstraintSeverity::Warn,\n                message: \"Test\".to_string(),\n                context: HashMap::new(),\n            },\n            PolicyViolation {\n                rule_id: \"info\".to_string(),\n                policy_id: \"test\".to_string(),\n                severity: ConstraintSeverity::Info,\n                message: \"Test\".to_string(),\n                context: HashMap::new(),\n            },\n        ];\n        let score = engine.calculate_drift_score(&violations);\n        assert!((score - 0.6).abs() < 0.001);\n    }\n\n    #[test]\n    fn test_apply_suppressions_no_suppressions() {\n        let engine = GovernanceEngine::new();\n        let violations = vec![PolicyViolation {\n            rule_id: \"rule1\".to_string(),\n            policy_id: \"policy1\".to_string(),\n            severity: ConstraintSeverity::Block,\n            message: \"Test\".to_string(),\n            context: HashMap::new(),\n        }];\n        let suppressions: Vec<mk_core::types::DriftSuppression> = vec![];\n\n        let (active, suppressed) = engine.apply_suppressions(violations, &suppressions);\n        assert_eq!(active.len(), 1);\n        assert_eq!(suppressed.len(), 0);\n    }\n\n    #[test]\n    fn test_apply_suppressions_with_matching_suppression() {\n        use mk_core::types::{TenantId, UserId};\n        let engine = GovernanceEngine::new();\n        let violations = vec![\n            PolicyViolation {\n                rule_id: \"rule1\".to_string(),\n                policy_id: \"policy1\".to_string(),\n                severity: ConstraintSeverity::Block,\n                message: \"Test message for policy1\".to_string(),\n                context: HashMap::new(),\n            },\n            PolicyViolation {\n                rule_id: \"rule2\".to_string(),\n                policy_id: \"policy2\".to_string(),\n                severity: ConstraintSeverity::Warn,\n                message: \"Test message for policy2\".to_string(),\n                context: HashMap::new(),\n            },\n        ];\n        let suppressions = vec![\n            mk_core::types::DriftSuppression::new(\n                \"project1\".to_string(),\n                TenantId::new(\"tenant1\".to_string()).unwrap(),\n                \"policy1\".to_string(),\n                \"Test suppression\".to_string(),\n                UserId::new(\"tester\".to_string()).unwrap(),\n            )\n            .with_expiry(chrono::Utc::now().timestamp() + 3600),\n        ];\n\n        let (active, suppressed) = engine.apply_suppressions(violations, &suppressions);\n        assert_eq!(active.len(), 1);\n        assert_eq!(active[0].rule_id, \"rule2\");\n        assert_eq!(suppressed.len(), 1);\n        assert_eq!(suppressed[0].rule_id, \"rule1\");\n    }\n\n    #[test]\n    fn test_apply_suppressions_all_suppressed() {\n        use mk_core::types::{TenantId, UserId};\n        let engine = GovernanceEngine::new();\n        let violations = vec![PolicyViolation {\n            rule_id: \"rule1\".to_string(),\n            policy_id: \"policy1\".to_string(),\n            severity: ConstraintSeverity::Block,\n            message: \"Test message\".to_string(),\n            context: HashMap::new(),\n        }];\n        let suppressions = vec![mk_core::types::DriftSuppression::new(\n            \"project1\".to_string(),\n            TenantId::new(\"tenant1\".to_string()).unwrap(),\n            \"policy1\".to_string(),\n            \"Test suppression\".to_string(),\n            UserId::new(\"tester\".to_string()).unwrap(),\n        )];\n\n        let (active, suppressed) = engine.apply_suppressions(violations, &suppressions);\n        assert_eq!(active.len(), 0);\n        assert_eq!(suppressed.len(), 1);\n    }\n\n    #[test]\n    fn test_apply_suppressions_with_rule_pattern() {\n        use mk_core::types::{TenantId, UserId};\n        let engine = GovernanceEngine::new();\n        let violations = vec![PolicyViolation {\n            rule_id: \"rule1\".to_string(),\n            policy_id: \"policy1\".to_string(),\n            severity: ConstraintSeverity::Block,\n            message: \"Violation for rule1 detected\".to_string(),\n            context: HashMap::new(),\n        }];\n        let suppressions = vec![\n            mk_core::types::DriftSuppression::new(\n                \"project1\".to_string(),\n                TenantId::new(\"tenant1\".to_string()).unwrap(),\n                \"policy1\".to_string(),\n                \"Test suppression\".to_string(),\n                UserId::new(\"tester\".to_string()).unwrap(),\n            )\n            .with_pattern(\"rule1\".to_string()),\n        ];\n\n        let (active, suppressed) = engine.apply_suppressions(violations, &suppressions);\n        assert_eq!(active.len(), 0);\n        assert_eq!(suppressed.len(), 1);\n    }\n\n    #[test]\n    fn test_apply_suppressions_pattern_not_matching() {\n        use mk_core::types::{TenantId, UserId};\n        let engine = GovernanceEngine::new();\n        let violations = vec![PolicyViolation {\n            rule_id: \"rule1\".to_string(),\n            policy_id: \"policy1\".to_string(),\n            severity: ConstraintSeverity::Block,\n            message: \"Some other message\".to_string(),\n            context: HashMap::new(),\n        }];\n        let suppressions = vec![\n            mk_core::types::DriftSuppression::new(\n                \"project1\".to_string(),\n                TenantId::new(\"tenant1\".to_string()).unwrap(),\n                \"policy1\".to_string(),\n                \"Test suppression\".to_string(),\n                UserId::new(\"tester\".to_string()).unwrap(),\n            )\n            .with_pattern(\"specific_pattern\".to_string()),\n        ];\n\n        let (active, suppressed) = engine.apply_suppressions(violations, &suppressions);\n        assert_eq!(active.len(), 1);\n        assert_eq!(suppressed.len(), 0);\n    }\n\n    #[test]\n    fn test_merge_policy_override_strategy() {\n        let mut engine = GovernanceEngine::new();\n\n        let company_policy = Policy {\n            id: \"merge-test\".to_string(),\n            name: \"Company Policy\".to_string(),\n            description: None,\n            layer: KnowledgeLayer::Company,\n            mode: mk_core::types::PolicyMode::Optional,\n            merge_strategy: mk_core::types::RuleMergeStrategy::Merge,\n            rules: vec![PolicyRule {\n                id: \"r1\".to_string(),\n                target: ConstraintTarget::Code,\n                operator: ConstraintOperator::MustExist,\n                value: serde_json::json!(null),\n                severity: ConstraintSeverity::Block,\n                message: \"Company rule\".to_string(),\n                rule_type: mk_core::types::RuleType::Allow,\n            }],\n            metadata: HashMap::new(),\n        };\n\n        let org_policy = Policy {\n            id: \"merge-test\".to_string(),\n            name: \"Org Policy\".to_string(),\n            description: None,\n            layer: KnowledgeLayer::Org,\n            mode: mk_core::types::PolicyMode::Optional,\n            merge_strategy: mk_core::types::RuleMergeStrategy::Override,\n            rules: vec![PolicyRule {\n                id: \"r2\".to_string(),\n                target: ConstraintTarget::Code,\n                operator: ConstraintOperator::MustExist,\n                value: serde_json::json!(null),\n                severity: ConstraintSeverity::Warn,\n                message: \"Org rule\".to_string(),\n                rule_type: mk_core::types::RuleType::Allow,\n            }],\n            metadata: HashMap::new(),\n        };\n\n        engine.add_policy(company_policy);\n        engine.add_policy(org_policy);\n\n        let context = HashMap::new();\n        let result = engine.validate(KnowledgeLayer::Org, &context);\n\n        assert!(!result.is_valid);\n        assert_eq!(result.violations.len(), 1);\n        assert_eq!(result.violations[0].message, \"Org rule\");\n    }\n\n    #[test]\n    fn test_merge_policy_intersect_strategy() {\n        let mut engine = GovernanceEngine::new();\n\n        let company_policy = Policy {\n            id: \"intersect-test\".to_string(),\n            name: \"Company Policy\".to_string(),\n            description: None,\n            layer: KnowledgeLayer::Company,\n            mode: mk_core::types::PolicyMode::Optional,\n            merge_strategy: mk_core::types::RuleMergeStrategy::Merge,\n            rules: vec![\n                PolicyRule {\n                    id: \"r1\".to_string(),\n                    target: ConstraintTarget::Code,\n                    operator: ConstraintOperator::MustExist,\n                    value: serde_json::json!(null),\n                    severity: ConstraintSeverity::Block,\n                    message: \"Rule 1\".to_string(),\n                    rule_type: mk_core::types::RuleType::Allow,\n                },\n                PolicyRule {\n                    id: \"r2\".to_string(),\n                    target: ConstraintTarget::File,\n                    operator: ConstraintOperator::MustExist,\n                    value: serde_json::json!(null),\n                    severity: ConstraintSeverity::Block,\n                    message: \"Rule 2\".to_string(),\n                    rule_type: mk_core::types::RuleType::Allow,\n                },\n            ],\n            metadata: HashMap::new(),\n        };\n\n        let org_policy = Policy {\n            id: \"intersect-test\".to_string(),\n            name: \"Org Policy\".to_string(),\n            description: None,\n            layer: KnowledgeLayer::Org,\n            mode: mk_core::types::PolicyMode::Optional,\n            merge_strategy: mk_core::types::RuleMergeStrategy::Intersect,\n            rules: vec![PolicyRule {\n                id: \"r1\".to_string(),\n                target: ConstraintTarget::Code,\n                operator: ConstraintOperator::MustExist,\n                value: serde_json::json!(null),\n                severity: ConstraintSeverity::Warn,\n                message: \"Rule 1 only\".to_string(),\n                rule_type: mk_core::types::RuleType::Allow,\n            }],\n            metadata: HashMap::new(),\n        };\n\n        engine.add_policy(company_policy);\n        engine.add_policy(org_policy);\n\n        let context = HashMap::new();\n        let result = engine.validate(KnowledgeLayer::Org, &context);\n\n        assert!(!result.is_valid);\n        assert_eq!(result.violations.len(), 1);\n    }\n\n    #[test]\n    fn test_merge_policy_metadata_merged() {\n        let mut engine = GovernanceEngine::new();\n\n        let mut metadata1 = HashMap::new();\n        metadata1.insert(\"key1\".to_string(), serde_json::json!(\"value1\"));\n\n        let company_policy = Policy {\n            id: \"metadata-test\".to_string(),\n            name: \"Company Policy\".to_string(),\n            description: None,\n            layer: KnowledgeLayer::Company,\n            mode: mk_core::types::PolicyMode::Optional,\n            merge_strategy: mk_core::types::RuleMergeStrategy::Merge,\n            rules: vec![],\n            metadata: metadata1,\n        };\n\n        let mut metadata2 = HashMap::new();\n        metadata2.insert(\"key2\".to_string(), serde_json::json!(\"value2\"));\n\n        let org_policy = Policy {\n            id: \"metadata-test\".to_string(),\n            name: \"Org Policy\".to_string(),\n            description: None,\n            layer: KnowledgeLayer::Org,\n            mode: mk_core::types::PolicyMode::Optional,\n            merge_strategy: mk_core::types::RuleMergeStrategy::Merge,\n            rules: vec![],\n            metadata: metadata2,\n        };\n\n        engine.add_policy(company_policy);\n        engine.add_policy(org_policy);\n\n        let context = HashMap::new();\n        let result = engine.validate(KnowledgeLayer::Org, &context);\n\n        assert!(result.is_valid);\n    }\n\n    #[test]\n    fn test_mandatory_policy_cannot_be_overridden_at_lower_layer() {\n        let mut engine = GovernanceEngine::new();\n\n        let company_policy = Policy {\n            id: \"mandatory-test\".to_string(),\n            name: \"Mandatory Company Policy\".to_string(),\n            description: None,\n            layer: KnowledgeLayer::Company,\n            mode: mk_core::types::PolicyMode::Mandatory,\n            merge_strategy: mk_core::types::RuleMergeStrategy::Merge,\n            rules: vec![PolicyRule {\n                id: \"mandatory-rule\".to_string(),\n                target: ConstraintTarget::Code,\n                operator: ConstraintOperator::MustNotMatch,\n                value: serde_json::json!(\"FORBIDDEN\"),\n                severity: ConstraintSeverity::Block,\n                message: \"Forbidden content\".to_string(),\n                rule_type: mk_core::types::RuleType::Allow,\n            }],\n            metadata: HashMap::new(),\n        };\n\n        let org_policy = Policy {\n            id: \"mandatory-test\".to_string(),\n            name: \"Org Override Attempt\".to_string(),\n            description: None,\n            layer: KnowledgeLayer::Org,\n            mode: mk_core::types::PolicyMode::Optional,\n            merge_strategy: mk_core::types::RuleMergeStrategy::Merge,\n            rules: vec![],\n            metadata: HashMap::new(),\n        };\n\n        engine.add_policy(company_policy);\n        engine.add_policy(org_policy);\n\n        let mut context = HashMap::new();\n        context.insert(\"content\".to_string(), serde_json::json!(\"FORBIDDEN text\"));\n\n        let result = engine.validate(KnowledgeLayer::Org, &context);\n        assert!(\n            !result.is_valid,\n            \"Mandatory policy should still apply despite org override attempt\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_publish_event_without_publisher() {\n        let engine = GovernanceEngine::new();\n        let event = mk_core::types::GovernanceEvent::DriftDetected {\n            project_id: \"test\".to_string(),\n            tenant_id: mk_core::types::TenantId::new(\"test\".to_string()).unwrap(),\n            drift_score: 0.5,\n            timestamp: chrono::Utc::now().timestamp(),\n        };\n\n        let result = engine.publish_event(event).await;\n        assert!(result.is_ok());\n    }\n}\n","traces":[{"line":25,"address":[],"length":0,"stats":{"Line":213}},{"line":27,"address":[],"length":0,"stats":{"Line":426}},{"line":37,"address":[],"length":0,"stats":{"Line":28}},{"line":41,"address":[],"length":0,"stats":{"Line":56}},{"line":42,"address":[],"length":0,"stats":{"Line":28}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":6}},{"line":65,"address":[],"length":0,"stats":{"Line":12}},{"line":66,"address":[],"length":0,"stats":{"Line":6}},{"line":69,"address":[],"length":0,"stats":{"Line":1}},{"line":75,"address":[],"length":0,"stats":{"Line":2}},{"line":76,"address":[],"length":0,"stats":{"Line":1}},{"line":79,"address":[],"length":0,"stats":{"Line":20}},{"line":83,"address":[],"length":0,"stats":{"Line":40}},{"line":86,"address":[],"length":0,"stats":{"Line":4}},{"line":89,"address":[],"length":0,"stats":{"Line":8}},{"line":92,"address":[],"length":0,"stats":{"Line":7}},{"line":97,"address":[],"length":0,"stats":{"Line":14}},{"line":99,"address":[],"length":0,"stats":{"Line":2}},{"line":100,"address":[],"length":0,"stats":{"Line":1}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":1}},{"line":109,"address":[],"length":0,"stats":{"Line":1}},{"line":110,"address":[],"length":0,"stats":{"Line":1}},{"line":115,"address":[],"length":0,"stats":{"Line":59}},{"line":116,"address":[],"length":0,"stats":{"Line":295}},{"line":119,"address":[],"length":0,"stats":{"Line":1}},{"line":120,"address":[],"length":0,"stats":{"Line":2}},{"line":123,"address":[],"length":0,"stats":{"Line":67}},{"line":128,"address":[],"length":0,"stats":{"Line":201}},{"line":129,"address":[],"length":0,"stats":{"Line":201}},{"line":131,"address":[],"length":0,"stats":{"Line":134}},{"line":132,"address":[],"length":0,"stats":{"Line":134}},{"line":133,"address":[],"length":0,"stats":{"Line":134}},{"line":134,"address":[],"length":0,"stats":{"Line":67}},{"line":135,"address":[],"length":0,"stats":{"Line":67}},{"line":138,"address":[],"length":0,"stats":{"Line":474}},{"line":139,"address":[],"length":0,"stats":{"Line":525}},{"line":140,"address":[],"length":0,"stats":{"Line":210}},{"line":141,"address":[],"length":0,"stats":{"Line":212}},{"line":142,"address":[],"length":0,"stats":{"Line":106}},{"line":143,"address":[],"length":0,"stats":{"Line":212}},{"line":146,"address":[],"length":0,"stats":{"Line":237}},{"line":147,"address":[],"length":0,"stats":{"Line":67}},{"line":151,"address":[],"length":0,"stats":{"Line":134}},{"line":152,"address":[],"length":0,"stats":{"Line":335}},{"line":153,"address":[],"length":0,"stats":{"Line":134}},{"line":155,"address":[],"length":0,"stats":{"Line":147}},{"line":156,"address":[],"length":0,"stats":{"Line":142}},{"line":157,"address":[],"length":0,"stats":{"Line":258}},{"line":158,"address":[],"length":0,"stats":{"Line":81}},{"line":159,"address":[],"length":0,"stats":{"Line":54}},{"line":160,"address":[],"length":0,"stats":{"Line":54}},{"line":162,"address":[],"length":0,"stats":{"Line":54}},{"line":168,"address":[],"length":0,"stats":{"Line":134}},{"line":173,"address":[],"length":0,"stats":{"Line":3}},{"line":179,"address":[],"length":0,"stats":{"Line":6}},{"line":181,"address":[],"length":0,"stats":{"Line":9}},{"line":182,"address":[],"length":0,"stats":{"Line":12}},{"line":183,"address":[],"length":0,"stats":{"Line":3}},{"line":185,"address":[],"length":0,"stats":{"Line":3}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":3}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":6}},{"line":208,"address":[],"length":0,"stats":{"Line":47}},{"line":214,"address":[],"length":0,"stats":{"Line":141}},{"line":215,"address":[],"length":0,"stats":{"Line":141}},{"line":217,"address":[],"length":0,"stats":{"Line":94}},{"line":218,"address":[],"length":0,"stats":{"Line":94}},{"line":219,"address":[],"length":0,"stats":{"Line":94}},{"line":220,"address":[],"length":0,"stats":{"Line":47}},{"line":221,"address":[],"length":0,"stats":{"Line":47}},{"line":224,"address":[],"length":0,"stats":{"Line":376}},{"line":225,"address":[],"length":0,"stats":{"Line":405}},{"line":226,"address":[],"length":0,"stats":{"Line":119}},{"line":227,"address":[],"length":0,"stats":{"Line":150}},{"line":230,"address":[],"length":0,"stats":{"Line":188}},{"line":231,"address":[],"length":0,"stats":{"Line":47}},{"line":235,"address":[],"length":0,"stats":{"Line":62}},{"line":236,"address":[],"length":0,"stats":{"Line":30}},{"line":238,"address":[],"length":0,"stats":{"Line":30}},{"line":239,"address":[],"length":0,"stats":{"Line":39}},{"line":241,"address":[],"length":0,"stats":{"Line":27}},{"line":242,"address":[],"length":0,"stats":{"Line":48}},{"line":244,"address":[],"length":0,"stats":{"Line":24}},{"line":245,"address":[],"length":0,"stats":{"Line":84}},{"line":246,"address":[],"length":0,"stats":{"Line":24}},{"line":249,"address":[],"length":0,"stats":{"Line":12}},{"line":251,"address":[],"length":0,"stats":{"Line":38}},{"line":252,"address":[],"length":0,"stats":{"Line":13}},{"line":253,"address":[],"length":0,"stats":{"Line":65}},{"line":255,"address":[],"length":0,"stats":{"Line":46}},{"line":256,"address":[],"length":0,"stats":{"Line":44}},{"line":261,"address":[],"length":0,"stats":{"Line":60}},{"line":262,"address":[],"length":0,"stats":{"Line":33}},{"line":263,"address":[],"length":0,"stats":{"Line":28}},{"line":269,"address":[],"length":0,"stats":{"Line":141}},{"line":272,"address":[],"length":0,"stats":{"Line":101}},{"line":280,"address":[],"length":0,"stats":{"Line":303}},{"line":282,"address":[],"length":0,"stats":{"Line":207}},{"line":283,"address":[],"length":0,"stats":{"Line":5}},{"line":284,"address":[],"length":0,"stats":{"Line":5}},{"line":286,"address":[],"length":0,"stats":{"Line":3}},{"line":290,"address":[],"length":0,"stats":{"Line":161}},{"line":291,"address":[],"length":0,"stats":{"Line":252}},{"line":294,"address":[],"length":0,"stats":{"Line":207}},{"line":295,"address":[],"length":0,"stats":{"Line":11}},{"line":296,"address":[],"length":0,"stats":{"Line":6}},{"line":297,"address":[],"length":0,"stats":{"Line":6}},{"line":300,"address":[],"length":0,"stats":{"Line":10}},{"line":301,"address":[],"length":0,"stats":{"Line":15}},{"line":302,"address":[],"length":0,"stats":{"Line":6}},{"line":305,"address":[],"length":0,"stats":{"Line":8}},{"line":306,"address":[],"length":0,"stats":{"Line":3}},{"line":308,"address":[],"length":0,"stats":{"Line":4}},{"line":311,"address":[],"length":0,"stats":{"Line":1}},{"line":312,"address":[],"length":0,"stats":{"Line":1}},{"line":313,"address":[],"length":0,"stats":{"Line":9}},{"line":314,"address":[],"length":0,"stats":{"Line":1}},{"line":318,"address":[],"length":0,"stats":{"Line":261}},{"line":322,"address":[],"length":0,"stats":{"Line":44}},{"line":328,"address":[],"length":0,"stats":{"Line":88}},{"line":329,"address":[],"length":0,"stats":{"Line":132}},{"line":331,"address":[],"length":0,"stats":{"Line":240}},{"line":332,"address":[],"length":0,"stats":{"Line":54}},{"line":333,"address":[],"length":0,"stats":{"Line":20}},{"line":334,"address":[],"length":0,"stats":{"Line":0}},{"line":335,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":338,"address":[],"length":0,"stats":{"Line":0}},{"line":342,"address":[],"length":0,"stats":{"Line":132}},{"line":343,"address":[],"length":0,"stats":{"Line":176}},{"line":344,"address":[],"length":0,"stats":{"Line":44}},{"line":346,"address":[],"length":0,"stats":{"Line":138}},{"line":347,"address":[],"length":0,"stats":{"Line":145}},{"line":348,"address":[],"length":0,"stats":{"Line":258}},{"line":349,"address":[],"length":0,"stats":{"Line":62}},{"line":354,"address":[],"length":0,"stats":{"Line":88}},{"line":356,"address":[],"length":0,"stats":{"Line":138}},{"line":359,"address":[],"length":0,"stats":{"Line":50}},{"line":360,"address":[],"length":0,"stats":{"Line":18}},{"line":361,"address":[],"length":0,"stats":{"Line":18}},{"line":362,"address":[],"length":0,"stats":{"Line":18}},{"line":363,"address":[],"length":0,"stats":{"Line":12}},{"line":364,"address":[],"length":0,"stats":{"Line":18}},{"line":365,"address":[],"length":0,"stats":{"Line":6}},{"line":369,"address":[],"length":0,"stats":{"Line":138}},{"line":370,"address":[],"length":0,"stats":{"Line":2}},{"line":371,"address":[],"length":0,"stats":{"Line":192}},{"line":373,"address":[],"length":0,"stats":{"Line":14}},{"line":374,"address":[],"length":0,"stats":{"Line":4}},{"line":375,"address":[],"length":0,"stats":{"Line":3}},{"line":376,"address":[],"length":0,"stats":{"Line":3}},{"line":377,"address":[],"length":0,"stats":{"Line":3}},{"line":378,"address":[],"length":0,"stats":{"Line":3}},{"line":379,"address":[],"length":0,"stats":{"Line":2}},{"line":380,"address":[],"length":0,"stats":{"Line":2}},{"line":381,"address":[],"length":0,"stats":{"Line":2}},{"line":382,"address":[],"length":0,"stats":{"Line":1}},{"line":384,"address":[],"length":0,"stats":{"Line":1}},{"line":391,"address":[],"length":0,"stats":{"Line":54}},{"line":392,"address":[],"length":0,"stats":{"Line":13}},{"line":393,"address":[],"length":0,"stats":{"Line":40}},{"line":394,"address":[],"length":0,"stats":{"Line":10}},{"line":396,"address":[],"length":0,"stats":{"Line":3}},{"line":397,"address":[],"length":0,"stats":{"Line":9}},{"line":398,"address":[],"length":0,"stats":{"Line":3}},{"line":399,"address":[],"length":0,"stats":{"Line":3}},{"line":400,"address":[],"length":0,"stats":{"Line":7}},{"line":402,"address":[],"length":0,"stats":{"Line":6}},{"line":408,"address":[],"length":0,"stats":{"Line":147}},{"line":409,"address":[],"length":0,"stats":{"Line":45}},{"line":410,"address":[],"length":0,"stats":{"Line":45}},{"line":411,"address":[],"length":0,"stats":{"Line":15}},{"line":414,"address":[],"length":0,"stats":{"Line":45}},{"line":416,"address":[],"length":0,"stats":{"Line":15}},{"line":419,"address":[],"length":0,"stats":{"Line":60}},{"line":421,"address":[],"length":0,"stats":{"Line":29}},{"line":424,"address":[],"length":0,"stats":{"Line":103}},{"line":425,"address":[],"length":0,"stats":{"Line":30}},{"line":426,"address":[],"length":0,"stats":{"Line":45}},{"line":427,"address":[],"length":0,"stats":{"Line":15}},{"line":431,"address":[],"length":0,"stats":{"Line":29}},{"line":434,"address":[],"length":0,"stats":{"Line":132}},{"line":436,"address":[],"length":0,"stats":{"Line":44}},{"line":437,"address":[],"length":0,"stats":{"Line":6}},{"line":439,"address":[],"length":0,"stats":{"Line":8}},{"line":442,"address":[],"length":0,"stats":{"Line":6}},{"line":444,"address":[],"length":0,"stats":{"Line":8}},{"line":447,"address":[],"length":0,"stats":{"Line":4}},{"line":448,"address":[],"length":0,"stats":{"Line":6}},{"line":450,"address":[],"length":0,"stats":{"Line":8}},{"line":452,"address":[],"length":0,"stats":{"Line":2}},{"line":453,"address":[],"length":0,"stats":{"Line":5}},{"line":454,"address":[],"length":0,"stats":{"Line":1}},{"line":457,"address":[],"length":0,"stats":{"Line":4}},{"line":459,"address":[],"length":0,"stats":{"Line":4}},{"line":460,"address":[],"length":0,"stats":{"Line":4}},{"line":461,"address":[],"length":0,"stats":{"Line":2}},{"line":463,"address":[],"length":0,"stats":{"Line":4}},{"line":464,"address":[],"length":0,"stats":{"Line":4}},{"line":465,"address":[],"length":0,"stats":{"Line":6}},{"line":468,"address":[],"length":0,"stats":{"Line":2}},{"line":471,"address":[],"length":0,"stats":{"Line":168}},{"line":473,"address":[],"length":0,"stats":{"Line":42}},{"line":474,"address":[],"length":0,"stats":{"Line":150}},{"line":475,"address":[],"length":0,"stats":{"Line":30}},{"line":478,"address":[],"length":0,"stats":{"Line":55}},{"line":480,"address":[],"length":0,"stats":{"Line":26}},{"line":481,"address":[],"length":0,"stats":{"Line":26}},{"line":482,"address":[],"length":0,"stats":{"Line":13}},{"line":484,"address":[],"length":0,"stats":{"Line":26}},{"line":485,"address":[],"length":0,"stats":{"Line":26}},{"line":486,"address":[],"length":0,"stats":{"Line":39}},{"line":489,"address":[],"length":0,"stats":{"Line":42}},{"line":492,"address":[],"length":0,"stats":{"Line":20}},{"line":497,"address":[],"length":0,"stats":{"Line":40}},{"line":498,"address":[],"length":0,"stats":{"Line":40}},{"line":500,"address":[],"length":0,"stats":{"Line":54}},{"line":501,"address":[],"length":0,"stats":{"Line":66}},{"line":502,"address":[],"length":0,"stats":{"Line":20}},{"line":503,"address":[],"length":0,"stats":{"Line":6}},{"line":505,"address":[],"length":0,"stats":{"Line":28}},{"line":509,"address":[],"length":0,"stats":{"Line":20}},{"line":512,"address":[],"length":0,"stats":{"Line":10}},{"line":518,"address":[],"length":0,"stats":{"Line":30}},{"line":520,"address":[],"length":0,"stats":{"Line":10}},{"line":521,"address":[],"length":0,"stats":{"Line":2}},{"line":524,"address":[],"length":0,"stats":{"Line":12}},{"line":525,"address":[],"length":0,"stats":{"Line":3}},{"line":526,"address":[],"length":0,"stats":{"Line":3}},{"line":527,"address":[],"length":0,"stats":{"Line":0}},{"line":530,"address":[],"length":0,"stats":{"Line":6}},{"line":531,"address":[],"length":0,"stats":{"Line":3}},{"line":533,"address":[],"length":0,"stats":{"Line":3}},{"line":534,"address":[],"length":0,"stats":{"Line":6}},{"line":535,"address":[],"length":0,"stats":{"Line":3}},{"line":536,"address":[],"length":0,"stats":{"Line":3}},{"line":537,"address":[],"length":0,"stats":{"Line":6}},{"line":538,"address":[],"length":0,"stats":{"Line":6}},{"line":542,"address":[],"length":0,"stats":{"Line":3}},{"line":544,"address":[],"length":0,"stats":{"Line":0}},{"line":545,"address":[],"length":0,"stats":{"Line":0}},{"line":546,"address":[],"length":0,"stats":{"Line":0}},{"line":551,"address":[],"length":0,"stats":{"Line":50}},{"line":552,"address":[],"length":0,"stats":{"Line":100}},{"line":553,"address":[],"length":0,"stats":{"Line":14}},{"line":556,"address":[],"length":0,"stats":{"Line":72}},{"line":558,"address":[],"length":0,"stats":{"Line":82}},{"line":559,"address":[],"length":0,"stats":{"Line":16}},{"line":560,"address":[],"length":0,"stats":{"Line":21}},{"line":561,"address":[],"length":0,"stats":{"Line":9}},{"line":565,"address":[],"length":0,"stats":{"Line":72}},{"line":568,"address":[],"length":0,"stats":{"Line":31}},{"line":574,"address":[],"length":0,"stats":{"Line":31}},{"line":575,"address":[],"length":0,"stats":{"Line":0}},{"line":577,"address":[],"length":0,"stats":{"Line":0}},{"line":578,"address":[],"length":0,"stats":{"Line":0}},{"line":580,"address":[],"length":0,"stats":{"Line":0}},{"line":581,"address":[],"length":0,"stats":{"Line":0}},{"line":583,"address":[],"length":0,"stats":{"Line":0}},{"line":584,"address":[],"length":0,"stats":{"Line":0}},{"line":585,"address":[],"length":0,"stats":{"Line":0}},{"line":586,"address":[],"length":0,"stats":{"Line":0}},{"line":590,"address":[],"length":0,"stats":{"Line":0}},{"line":591,"address":[],"length":0,"stats":{"Line":0}},{"line":592,"address":[],"length":0,"stats":{"Line":0}},{"line":593,"address":[],"length":0,"stats":{"Line":0}},{"line":594,"address":[],"length":0,"stats":{"Line":0}},{"line":595,"address":[],"length":0,"stats":{"Line":0}},{"line":597,"address":[],"length":0,"stats":{"Line":0}},{"line":602,"address":[],"length":0,"stats":{"Line":129}},{"line":610,"address":[],"length":0,"stats":{"Line":258}},{"line":611,"address":[],"length":0,"stats":{"Line":13}},{"line":612,"address":[],"length":0,"stats":{"Line":55}},{"line":613,"address":[],"length":0,"stats":{"Line":54}},{"line":614,"address":[],"length":0,"stats":{"Line":1}},{"line":615,"address":[],"length":0,"stats":{"Line":6}},{"line":618,"address":[],"length":0,"stats":{"Line":516}},{"line":620,"address":[],"length":0,"stats":{"Line":258}},{"line":621,"address":[],"length":0,"stats":{"Line":32}},{"line":622,"address":[],"length":0,"stats":{"Line":8}},{"line":624,"address":[],"length":0,"stats":{"Line":89}},{"line":625,"address":[],"length":0,"stats":{"Line":87}},{"line":626,"address":[],"length":0,"stats":{"Line":86}},{"line":628,"address":[],"length":0,"stats":{"Line":1}},{"line":631,"address":[],"length":0,"stats":{"Line":1}},{"line":635,"address":[],"length":0,"stats":{"Line":15}},{"line":636,"address":[],"length":0,"stats":{"Line":14}},{"line":637,"address":[],"length":0,"stats":{"Line":14}},{"line":639,"address":[],"length":0,"stats":{"Line":0}},{"line":642,"address":[],"length":0,"stats":{"Line":1}},{"line":646,"address":[],"length":0,"stats":{"Line":43}},{"line":647,"address":[],"length":0,"stats":{"Line":41}},{"line":648,"address":[],"length":0,"stats":{"Line":40}},{"line":649,"address":[],"length":0,"stats":{"Line":39}},{"line":650,"address":[],"length":0,"stats":{"Line":57}},{"line":652,"address":[],"length":0,"stats":{"Line":1}},{"line":655,"address":[],"length":0,"stats":{"Line":0}},{"line":658,"address":[],"length":0,"stats":{"Line":1}},{"line":661,"address":[],"length":0,"stats":{"Line":1}},{"line":665,"address":[],"length":0,"stats":{"Line":67}},{"line":666,"address":[],"length":0,"stats":{"Line":65}},{"line":667,"address":[],"length":0,"stats":{"Line":63}},{"line":668,"address":[],"length":0,"stats":{"Line":61}},{"line":669,"address":[],"length":0,"stats":{"Line":60}},{"line":671,"address":[],"length":0,"stats":{"Line":1}},{"line":674,"address":[],"length":0,"stats":{"Line":1}},{"line":677,"address":[],"length":0,"stats":{"Line":1}},{"line":680,"address":[],"length":0,"stats":{"Line":1}},{"line":685,"address":[],"length":0,"stats":{"Line":258}},{"line":686,"address":[],"length":0,"stats":{"Line":125}},{"line":687,"address":[],"length":0,"stats":{"Line":4}},{"line":690,"address":[],"length":0,"stats":{"Line":129}},{"line":691,"address":[],"length":0,"stats":{"Line":70}},{"line":692,"address":[],"length":0,"stats":{"Line":210}},{"line":693,"address":[],"length":0,"stats":{"Line":210}},{"line":694,"address":[],"length":0,"stats":{"Line":140}},{"line":695,"address":[],"length":0,"stats":{"Line":210}},{"line":696,"address":[],"length":0,"stats":{"Line":70}},{"line":699,"address":[],"length":0,"stats":{"Line":59}},{"line":703,"address":[],"length":0,"stats":{"Line":0}},{"line":709,"address":[],"length":0,"stats":{"Line":0}},{"line":710,"address":[],"length":0,"stats":{"Line":0}},{"line":712,"address":[],"length":0,"stats":{"Line":0}},{"line":714,"address":[],"length":0,"stats":{"Line":0}},{"line":716,"address":[],"length":0,"stats":{"Line":0}},{"line":718,"address":[],"length":0,"stats":{"Line":0}},{"line":719,"address":[],"length":0,"stats":{"Line":0}},{"line":721,"address":[],"length":0,"stats":{"Line":0}},{"line":722,"address":[],"length":0,"stats":{"Line":0}},{"line":723,"address":[],"length":0,"stats":{"Line":0}},{"line":725,"address":[],"length":0,"stats":{"Line":0}},{"line":726,"address":[],"length":0,"stats":{"Line":0}},{"line":727,"address":[],"length":0,"stats":{"Line":0}},{"line":728,"address":[],"length":0,"stats":{"Line":0}},{"line":730,"address":[],"length":0,"stats":{"Line":0}},{"line":731,"address":[],"length":0,"stats":{"Line":0}},{"line":733,"address":[],"length":0,"stats":{"Line":0}},{"line":734,"address":[],"length":0,"stats":{"Line":0}},{"line":735,"address":[],"length":0,"stats":{"Line":0}},{"line":736,"address":[],"length":0,"stats":{"Line":0}},{"line":737,"address":[],"length":0,"stats":{"Line":0}},{"line":738,"address":[],"length":0,"stats":{"Line":0}},{"line":739,"address":[],"length":0,"stats":{"Line":0}},{"line":740,"address":[],"length":0,"stats":{"Line":0}},{"line":741,"address":[],"length":0,"stats":{"Line":0}},{"line":742,"address":[],"length":0,"stats":{"Line":0}},{"line":744,"address":[],"length":0,"stats":{"Line":0}},{"line":752,"address":[],"length":0,"stats":{"Line":0}},{"line":755,"address":[],"length":0,"stats":{"Line":5}},{"line":756,"address":[],"length":0,"stats":{"Line":23}},{"line":757,"address":[],"length":0,"stats":{"Line":2}},{"line":759,"address":[],"length":0,"stats":{"Line":43}},{"line":760,"address":[],"length":0,"stats":{"Line":37}},{"line":761,"address":[],"length":0,"stats":{"Line":37}},{"line":763,"address":[],"length":0,"stats":{"Line":5}},{"line":764,"address":[],"length":0,"stats":{"Line":1}},{"line":766,"address":[],"length":0,"stats":{"Line":4}}],"covered":301,"coverable":371},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","governance_client.rs"],"content":"use async_trait::async_trait;\nuse mk_core::types::{\n    DriftResult, GovernanceEvent, KnowledgeEntry, KnowledgeLayer, TenantContext, ValidationResult,\n};\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse std::time::{Duration, Instant};\nuse tokio::sync::RwLock;\n\n#[derive(Debug, thiserror::Error)]\npub enum GovernanceClientError {\n    #[error(\"Network error: {0}\")]\n    Network(#[from] reqwest::Error),\n    #[error(\"API error: {0}\")]\n    Api(String),\n    #[error(\"Serialization error: {0}\")]\n    Serialization(#[from] serde_json::Error),\n    #[error(\"Internal error: {0}\")]\n    Internal(String),\n    #[error(\"Remote unavailable, using cached data\")]\n    RemoteUnavailable,\n    #[error(\"Sync conflict: {0}\")]\n    SyncConflict(String),\n}\n\npub type Result<T> = std::result::Result<T, GovernanceClientError>;\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct SyncState {\n    pub last_sync_timestamp: i64,\n    pub local_version: u64,\n    pub remote_version: u64,\n    pub pending_changes: Vec<PendingChange>,\n}\n\nimpl Default for SyncState {\n    fn default() -> Self {\n        Self {\n            last_sync_timestamp: 0,\n            local_version: 0,\n            remote_version: 0,\n            pending_changes: Vec::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PendingChange {\n    pub id: String,\n    pub change_type: ChangeType,\n    pub data: serde_json::Value,\n    pub created_at: i64,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\npub enum ChangeType {\n    PolicyUpdate,\n    DriftResult,\n    ProposalAction,\n}\n\n#[derive(Debug, Clone)]\nstruct CacheEntry<T> {\n    data: T,\n    inserted_at: Instant,\n    ttl: Duration,\n}\n\nimpl<T: Clone> CacheEntry<T> {\n    fn new(data: T, ttl: Duration) -> Self {\n        Self {\n            data,\n            inserted_at: Instant::now(),\n            ttl,\n        }\n    }\n\n    fn is_expired(&self) -> bool {\n        self.inserted_at.elapsed() > self.ttl\n    }\n}\n\n#[async_trait]\npub trait GovernanceClient: Send + Sync {\n    async fn validate(\n        &self,\n        ctx: &TenantContext,\n        layer: KnowledgeLayer,\n        context: &std::collections::HashMap<String, serde_json::Value>,\n    ) -> Result<ValidationResult>;\n\n    async fn get_drift_status(\n        &self,\n        ctx: &TenantContext,\n        project_id: &str,\n    ) -> Result<Option<DriftResult>>;\n\n    async fn list_proposals(\n        &self,\n        ctx: &TenantContext,\n        layer: Option<KnowledgeLayer>,\n    ) -> Result<Vec<KnowledgeEntry>>;\n\n    async fn replay_events(\n        &self,\n        ctx: &TenantContext,\n        since_timestamp: i64,\n        limit: usize,\n    ) -> Result<Vec<GovernanceEvent>>;\n}\n\npub struct RemoteGovernanceClient {\n    client: reqwest::Client,\n    base_url: String,\n}\n\nimpl RemoteGovernanceClient {\n    pub fn new(base_url: String) -> Self {\n        Self {\n            client: reqwest::Client::new(),\n            base_url,\n        }\n    }\n}\n\npub struct HybridGovernanceClient {\n    remote_client: RemoteGovernanceClient,\n    local_engine: Arc<crate::governance::GovernanceEngine>,\n    cache: Arc<RwLock<HybridCache>>,\n    sync_state: Arc<RwLock<SyncState>>,\n    cache_ttl: Duration,\n    sync_interval: Duration,\n}\n\nstruct HybridCache {\n    drift_results: HashMap<String, CacheEntry<DriftResult>>,\n    proposals: Option<CacheEntry<Vec<KnowledgeEntry>>>,\n}\n\nimpl Default for HybridCache {\n    fn default() -> Self {\n        Self {\n            drift_results: HashMap::new(),\n            proposals: None,\n        }\n    }\n}\n\nimpl HybridGovernanceClient {\n    pub fn new(remote_url: String, local_engine: Arc<crate::governance::GovernanceEngine>) -> Self {\n        Self {\n            remote_client: RemoteGovernanceClient::new(remote_url),\n            local_engine,\n            cache: Arc::new(RwLock::new(HybridCache::default())),\n            sync_state: Arc::new(RwLock::new(SyncState::default())),\n            cache_ttl: Duration::from_secs(300),\n            sync_interval: Duration::from_secs(60),\n        }\n    }\n\n    pub fn with_cache_ttl(mut self, ttl: Duration) -> Self {\n        self.cache_ttl = ttl;\n        self\n    }\n\n    pub fn with_sync_interval(mut self, interval: Duration) -> Self {\n        self.sync_interval = interval;\n        self\n    }\n\n    fn cache_key(ctx: &TenantContext, suffix: &str) -> String {\n        format!(\n            \"{}:{}:{}\",\n            ctx.tenant_id.as_str(),\n            ctx.user_id.as_str(),\n            suffix\n        )\n    }\n\n    pub async fn sync_pending_changes(&self, ctx: &TenantContext) -> Result<usize> {\n        let mut state = self.sync_state.write().await;\n        let pending = std::mem::take(&mut state.pending_changes);\n        let mut synced = 0;\n\n        for change in pending {\n            match self.push_change_to_remote(ctx, &change).await {\n                Ok(_) => {\n                    synced += 1;\n                    state.local_version += 1;\n                }\n                Err(e) => {\n                    tracing::error!(\"Failed to sync change {}: {:?}\", change.id, e);\n                    state.pending_changes.push(change);\n                }\n            }\n        }\n\n        if synced > 0 {\n            state.last_sync_timestamp = chrono::Utc::now().timestamp();\n        }\n\n        Ok(synced)\n    }\n\n    async fn push_change_to_remote(\n        &self,\n        ctx: &TenantContext,\n        change: &PendingChange,\n    ) -> Result<()> {\n        let url = match change.change_type {\n            ChangeType::PolicyUpdate => {\n                format!(\n                    \"{}/api/v1/governance/policies/sync\",\n                    self.remote_client.base_url\n                )\n            }\n            ChangeType::DriftResult => {\n                format!(\n                    \"{}/api/v1/governance/drift/sync\",\n                    self.remote_client.base_url\n                )\n            }\n            ChangeType::ProposalAction => {\n                format!(\n                    \"{}/api/v1/governance/proposals/sync\",\n                    self.remote_client.base_url\n                )\n            }\n        };\n\n        let response = self\n            .remote_client\n            .client\n            .post(&url)\n            .header(\"X-Tenant-Id\", ctx.tenant_id.as_str())\n            .header(\"X-User-Id\", ctx.user_id.as_str())\n            .json(&change.data)\n            .send()\n            .await?;\n\n        if response.status().is_success() {\n            Ok(())\n        } else {\n            Err(GovernanceClientError::Api(response.text().await?))\n        }\n    }\n\n    pub async fn queue_local_change(&self, change: PendingChange) {\n        let mut state = self.sync_state.write().await;\n        state.pending_changes.push(change);\n    }\n\n    pub async fn get_sync_state(&self) -> SyncState {\n        self.sync_state.read().await.clone()\n    }\n}\n\n#[async_trait]\nimpl GovernanceClient for HybridGovernanceClient {\n    async fn validate(\n        &self,\n        ctx: &TenantContext,\n        layer: KnowledgeLayer,\n        context: &std::collections::HashMap<String, serde_json::Value>,\n    ) -> Result<ValidationResult> {\n        let local_result = self\n            .local_engine\n            .validate_with_context(layer, context, Some(ctx))\n            .await;\n\n        self.queue_local_change(PendingChange {\n            id: uuid::Uuid::new_v4().to_string(),\n            change_type: ChangeType::PolicyUpdate,\n            data: serde_json::json!({\n                \"layer\": layer,\n                \"context\": context,\n                \"result\": local_result\n            }),\n            created_at: chrono::Utc::now().timestamp(),\n        })\n        .await;\n\n        Ok(local_result)\n    }\n\n    async fn get_drift_status(\n        &self,\n        ctx: &TenantContext,\n        project_id: &str,\n    ) -> Result<Option<DriftResult>> {\n        let cache_key = Self::cache_key(ctx, &format!(\"drift:{}\", project_id));\n\n        {\n            let cache = self.cache.read().await;\n            if let Some(entry) = cache.drift_results.get(&cache_key) {\n                if !entry.is_expired() {\n                    return Ok(Some(entry.data.clone()));\n                }\n            }\n        }\n\n        match self.remote_client.get_drift_status(ctx, project_id).await {\n            Ok(result) => {\n                if let Some(ref drift) = result {\n                    let mut cache = self.cache.write().await;\n                    cache\n                        .drift_results\n                        .insert(cache_key, CacheEntry::new(drift.clone(), self.cache_ttl));\n                }\n                Ok(result)\n            }\n            Err(_) => {\n                if let Some(storage) = self.local_engine.storage() {\n                    match storage\n                        .get_latest_drift_result(ctx.clone(), project_id)\n                        .await\n                    {\n                        Ok(result) => Ok(result),\n                        Err(e) => Err(GovernanceClientError::Internal(format!(\"{:?}\", e))),\n                    }\n                } else {\n                    Ok(None)\n                }\n            }\n        }\n    }\n\n    async fn list_proposals(\n        &self,\n        ctx: &TenantContext,\n        layer: Option<KnowledgeLayer>,\n    ) -> Result<Vec<KnowledgeEntry>> {\n        {\n            let cache = self.cache.read().await;\n            if let Some(ref entry) = cache.proposals {\n                if !entry.is_expired() {\n                    let filtered: Vec<_> = entry\n                        .data\n                        .iter()\n                        .filter(|e| layer.is_none() || Some(e.layer) == layer)\n                        .cloned()\n                        .collect();\n                    return Ok(filtered);\n                }\n            }\n        }\n\n        match self.remote_client.list_proposals(ctx, layer).await {\n            Ok(proposals) => {\n                let mut cache = self.cache.write().await;\n                cache.proposals = Some(CacheEntry::new(proposals.clone(), self.cache_ttl));\n                Ok(proposals)\n            }\n            Err(_) => {\n                if let Some(repo) = self.local_engine.repository() {\n                    let target_layer = layer.unwrap_or(KnowledgeLayer::Project);\n                    match repo.list(ctx.clone(), target_layer, \"proposals/\").await {\n                        Ok(entries) => Ok(entries),\n                        Err(e) => Err(GovernanceClientError::Internal(format!(\"{:?}\", e))),\n                    }\n                } else {\n                    Ok(vec![])\n                }\n            }\n        }\n    }\n\n    async fn replay_events(\n        &self,\n        ctx: &TenantContext,\n        since_timestamp: i64,\n        limit: usize,\n    ) -> Result<Vec<GovernanceEvent>> {\n        self.remote_client\n            .replay_events(ctx, since_timestamp, limit)\n            .await\n    }\n}\n\npub enum GovernanceClientKind {\n    Local(LocalGovernanceClient),\n    Hybrid(HybridGovernanceClient),\n    Remote(RemoteGovernanceClient),\n}\n\nimpl std::fmt::Debug for GovernanceClientKind {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            GovernanceClientKind::Local(_) => f.debug_tuple(\"Local\").finish(),\n            GovernanceClientKind::Hybrid(_) => f.debug_tuple(\"Hybrid\").finish(),\n            GovernanceClientKind::Remote(_) => f.debug_tuple(\"Remote\").finish(),\n        }\n    }\n}\n\nimpl GovernanceClientKind {\n    pub fn as_client(&self) -> &dyn GovernanceClient {\n        match self {\n            GovernanceClientKind::Local(c) => c,\n            GovernanceClientKind::Hybrid(c) => c,\n            GovernanceClientKind::Remote(c) => c,\n        }\n    }\n}\n\npub fn create_governance_client(\n    config: &config::DeploymentConfig,\n    engine: Option<Arc<crate::governance::GovernanceEngine>>,\n) -> Result<GovernanceClientKind> {\n    match config.mode.as_str() {\n        \"local\" => {\n            let engine = engine.ok_or_else(|| {\n                GovernanceClientError::Internal(\n                    \"Local mode requires a GovernanceEngine instance\".to_string(),\n                )\n            })?;\n            Ok(GovernanceClientKind::Local(LocalGovernanceClient::new(\n                engine,\n            )))\n        }\n        \"hybrid\" => {\n            let engine = engine.ok_or_else(|| {\n                GovernanceClientError::Internal(\n                    \"Hybrid mode requires a GovernanceEngine instance\".to_string(),\n                )\n            })?;\n            let remote_url = config.remote_url.clone().ok_or_else(|| {\n                GovernanceClientError::Internal(\n                    \"Hybrid mode requires a remote_url configuration\".to_string(),\n                )\n            })?;\n            Ok(GovernanceClientKind::Hybrid(HybridGovernanceClient::new(\n                remote_url, engine,\n            )))\n        }\n        \"remote\" => {\n            let remote_url = config.remote_url.clone().ok_or_else(|| {\n                GovernanceClientError::Internal(\n                    \"Remote mode requires a remote_url configuration\".to_string(),\n                )\n            })?;\n            Ok(GovernanceClientKind::Remote(RemoteGovernanceClient::new(\n                remote_url,\n            )))\n        }\n        other => Err(GovernanceClientError::Internal(format!(\n            \"Invalid deployment mode: {}\",\n            other\n        ))),\n    }\n}\n\n/// Local governance client that wraps the `GovernanceEngine` directly.\n///\n/// Used in \"local\" deployment mode where all governance operations are\n/// performed locally without any remote communication.\npub struct LocalGovernanceClient {\n    engine: Arc<crate::governance::GovernanceEngine>,\n}\n\nimpl LocalGovernanceClient {\n    pub fn new(engine: Arc<crate::governance::GovernanceEngine>) -> Self {\n        Self { engine }\n    }\n}\n\n#[async_trait]\nimpl GovernanceClient for LocalGovernanceClient {\n    async fn validate(\n        &self,\n        _ctx: &TenantContext,\n        layer: KnowledgeLayer,\n        context: &std::collections::HashMap<String, serde_json::Value>,\n    ) -> Result<ValidationResult> {\n        Ok(self\n            .engine\n            .validate_with_context(layer, context, None)\n            .await)\n    }\n\n    async fn get_drift_status(\n        &self,\n        ctx: &TenantContext,\n        project_id: &str,\n    ) -> Result<Option<DriftResult>> {\n        if let Some(storage) = self.engine.storage() {\n            match storage\n                .get_latest_drift_result(ctx.clone(), project_id)\n                .await\n            {\n                Ok(result) => Ok(result),\n                Err(e) => Err(GovernanceClientError::Internal(format!(\"{:?}\", e))),\n            }\n        } else {\n            Ok(None)\n        }\n    }\n\n    async fn list_proposals(\n        &self,\n        ctx: &TenantContext,\n        layer: Option<KnowledgeLayer>,\n    ) -> Result<Vec<KnowledgeEntry>> {\n        if let Some(repo) = self.engine.repository() {\n            let target_layer = layer.unwrap_or(KnowledgeLayer::Project);\n            match repo.list(ctx.clone(), target_layer, \"proposals/\").await {\n                Ok(entries) => Ok(entries),\n                Err(e) => Err(GovernanceClientError::Internal(format!(\"{:?}\", e))),\n            }\n        } else {\n            Ok(vec![])\n        }\n    }\n\n    async fn replay_events(\n        &self,\n        ctx: &TenantContext,\n        since_timestamp: i64,\n        limit: usize,\n    ) -> Result<Vec<GovernanceEvent>> {\n        if let Some(storage) = self.engine.storage() {\n            match storage\n                .get_governance_events(ctx.clone(), since_timestamp, limit)\n                .await\n            {\n                Ok(events) => Ok(events),\n                Err(e) => Err(GovernanceClientError::Internal(format!(\"{:?}\", e))),\n            }\n        } else {\n            Ok(vec![])\n        }\n    }\n}\n\n#[async_trait]\nimpl GovernanceClient for RemoteGovernanceClient {\n    async fn validate(\n        &self,\n        ctx: &TenantContext,\n        layer: KnowledgeLayer,\n        context: &std::collections::HashMap<String, serde_json::Value>,\n    ) -> Result<ValidationResult> {\n        let url = format!(\"{}/api/v1/governance/validate\", self.base_url);\n        let response = self\n            .client\n            .post(&url)\n            .header(\"X-Tenant-Id\", ctx.tenant_id.as_str())\n            .header(\"X-User-Id\", ctx.user_id.as_str())\n            .json(&serde_json::json!({\n                \"layer\": layer,\n                \"context\": context\n            }))\n            .send()\n            .await?;\n\n        if response.status().is_success() {\n            Ok(response.json().await?)\n        } else {\n            Err(GovernanceClientError::Api(response.text().await?))\n        }\n    }\n\n    async fn get_drift_status(\n        &self,\n        ctx: &TenantContext,\n        project_id: &str,\n    ) -> Result<Option<DriftResult>> {\n        let url = format!(\"{}/api/v1/governance/drift/{}\", self.base_url, project_id);\n        let response = self\n            .client\n            .get(&url)\n            .header(\"X-Tenant-Id\", ctx.tenant_id.as_str())\n            .header(\"X-User-Id\", ctx.user_id.as_str())\n            .send()\n            .await?;\n\n        if response.status().is_success() {\n            Ok(response.json().await?)\n        } else {\n            Err(GovernanceClientError::Api(response.text().await?))\n        }\n    }\n\n    async fn list_proposals(\n        &self,\n        ctx: &TenantContext,\n        layer: Option<KnowledgeLayer>,\n    ) -> Result<Vec<KnowledgeEntry>> {\n        let mut url = format!(\"{}/api/v1/governance/proposals\", self.base_url);\n        if let Some(l) = layer {\n            url.push_str(&format!(\"?layer={:?}\", l));\n        }\n\n        let response = self\n            .client\n            .get(&url)\n            .header(\"X-Tenant-Id\", ctx.tenant_id.as_str())\n            .header(\"X-User-Id\", ctx.user_id.as_str())\n            .send()\n            .await?;\n\n        if response.status().is_success() {\n            Ok(response.json().await?)\n        } else {\n            Err(GovernanceClientError::Api(response.text().await?))\n        }\n    }\n\n    async fn replay_events(\n        &self,\n        ctx: &TenantContext,\n        since_timestamp: i64,\n        limit: usize,\n    ) -> Result<Vec<GovernanceEvent>> {\n        let url = format!(\n            \"{}/api/v1/governance/events/replay?since_timestamp={}&limit={}\",\n            self.base_url, since_timestamp, limit\n        );\n\n        let response = self\n            .client\n            .get(&url)\n            .header(\"X-Tenant-Id\", ctx.tenant_id.as_str())\n            .header(\"X-User-Id\", ctx.user_id.as_str())\n            .send()\n            .await?;\n\n        if response.status().is_success() {\n            Ok(response.json().await?)\n        } else {\n            Err(GovernanceClientError::Api(response.text().await?))\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::{TenantId, UserId};\n\n    fn test_tenant_context() -> TenantContext {\n        TenantContext::new(TenantId::default(), UserId::default())\n    }\n\n    #[test]\n    fn test_sync_state_default() {\n        let state = SyncState::default();\n        assert_eq!(state.last_sync_timestamp, 0);\n        assert_eq!(state.local_version, 0);\n        assert_eq!(state.remote_version, 0);\n        assert!(state.pending_changes.is_empty());\n    }\n\n    #[test]\n    fn test_pending_change_serialization() {\n        let change = PendingChange {\n            id: \"change-1\".to_string(),\n            change_type: ChangeType::PolicyUpdate,\n            data: serde_json::json!({\"key\": \"value\"}),\n            created_at: 1234567890,\n        };\n\n        let json = serde_json::to_string(&change).unwrap();\n        let deserialized: PendingChange = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(deserialized.id, \"change-1\");\n        assert_eq!(deserialized.change_type, ChangeType::PolicyUpdate);\n        assert_eq!(deserialized.created_at, 1234567890);\n    }\n\n    #[test]\n    fn test_change_type_variants() {\n        assert_eq!(ChangeType::PolicyUpdate, ChangeType::PolicyUpdate);\n        assert_eq!(ChangeType::DriftResult, ChangeType::DriftResult);\n        assert_eq!(ChangeType::ProposalAction, ChangeType::ProposalAction);\n        assert_ne!(ChangeType::PolicyUpdate, ChangeType::DriftResult);\n    }\n\n    #[test]\n    fn test_cache_entry_expiration() {\n        let entry = CacheEntry::new(\"test data\".to_string(), Duration::from_millis(10));\n        assert!(!entry.is_expired());\n\n        std::thread::sleep(Duration::from_millis(15));\n        assert!(entry.is_expired());\n    }\n\n    #[test]\n    fn test_cache_entry_not_expired() {\n        let entry = CacheEntry::new(42i32, Duration::from_secs(60));\n        assert!(!entry.is_expired());\n    }\n\n    #[test]\n    fn test_hybrid_cache_default() {\n        let cache = HybridCache::default();\n        assert!(cache.drift_results.is_empty());\n        assert!(cache.proposals.is_none());\n    }\n\n    #[test]\n    fn test_cache_key_generation() {\n        let ctx = test_tenant_context();\n        let key = HybridGovernanceClient::cache_key(&ctx, \"drift:proj-1\");\n        assert_eq!(key, \"default:default:drift:proj-1\");\n    }\n\n    #[test]\n    fn test_remote_client_construction() {\n        let client = RemoteGovernanceClient::new(\"http://localhost:8080\".to_string());\n        assert_eq!(client.base_url, \"http://localhost:8080\");\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_client_construction() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client =\n            HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine.clone());\n\n        assert_eq!(client.cache_ttl, Duration::from_secs(300));\n        assert_eq!(client.sync_interval, Duration::from_secs(60));\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_client_with_custom_ttl() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine)\n            .with_cache_ttl(Duration::from_secs(120));\n\n        assert_eq!(client.cache_ttl, Duration::from_secs(120));\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_client_with_custom_sync_interval() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine)\n            .with_sync_interval(Duration::from_secs(30));\n\n        assert_eq!(client.sync_interval, Duration::from_secs(30));\n    }\n\n    #[tokio::test]\n    async fn test_queue_local_change() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine);\n\n        let change = PendingChange {\n            id: \"test-change\".to_string(),\n            change_type: ChangeType::PolicyUpdate,\n            data: serde_json::json!({\"test\": true}),\n            created_at: chrono::Utc::now().timestamp(),\n        };\n\n        client.queue_local_change(change).await;\n\n        let state = client.get_sync_state().await;\n        assert_eq!(state.pending_changes.len(), 1);\n        assert_eq!(state.pending_changes[0].id, \"test-change\");\n    }\n\n    #[tokio::test]\n    async fn test_get_sync_state_initial() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine);\n\n        let state = client.get_sync_state().await;\n        assert_eq!(state.last_sync_timestamp, 0);\n        assert_eq!(state.local_version, 0);\n        assert_eq!(state.remote_version, 0);\n        assert!(state.pending_changes.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_validate_queues_change() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine);\n\n        let ctx = test_tenant_context();\n        let context = HashMap::new();\n\n        let result = client\n            .validate(&ctx, KnowledgeLayer::Project, &context)\n            .await;\n        assert!(result.is_ok());\n\n        let state = client.get_sync_state().await;\n        assert_eq!(state.pending_changes.len(), 1);\n        assert_eq!(\n            state.pending_changes[0].change_type,\n            ChangeType::PolicyUpdate\n        );\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_get_drift_status_no_storage() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://invalid-host:9999\".to_string(), engine);\n\n        let ctx = test_tenant_context();\n        let result = client.get_drift_status(&ctx, \"proj-1\").await;\n\n        assert!(result.is_ok());\n        assert!(result.unwrap().is_none());\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_list_proposals_no_repo() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://invalid-host:9999\".to_string(), engine);\n\n        let ctx = test_tenant_context();\n        let result = client.list_proposals(&ctx, None).await;\n\n        assert!(result.is_ok());\n        assert!(result.unwrap().is_empty());\n    }\n\n    #[test]\n    fn test_governance_client_error_display() {\n        let err = GovernanceClientError::Api(\"Not found\".to_string());\n        assert_eq!(err.to_string(), \"API error: Not found\");\n\n        let err = GovernanceClientError::Internal(\"Something went wrong\".to_string());\n        assert_eq!(err.to_string(), \"Internal error: Something went wrong\");\n\n        let err = GovernanceClientError::RemoteUnavailable;\n        assert_eq!(err.to_string(), \"Remote unavailable, using cached data\");\n\n        let err = GovernanceClientError::SyncConflict(\"Version mismatch\".to_string());\n        assert_eq!(err.to_string(), \"Sync conflict: Version mismatch\");\n    }\n\n    #[test]\n    fn test_sync_state_serialization() {\n        let state = SyncState {\n            last_sync_timestamp: 1234567890,\n            local_version: 5,\n            remote_version: 3,\n            pending_changes: vec![PendingChange {\n                id: \"change-1\".to_string(),\n                change_type: ChangeType::DriftResult,\n                data: serde_json::json!({}),\n                created_at: 1234567890,\n            }],\n        };\n\n        let json = serde_json::to_string(&state).unwrap();\n        let deserialized: SyncState = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(deserialized.last_sync_timestamp, 1234567890);\n        assert_eq!(deserialized.local_version, 5);\n        assert_eq!(deserialized.remote_version, 3);\n        assert_eq!(deserialized.pending_changes.len(), 1);\n    }\n\n    #[tokio::test]\n    async fn test_multiple_queued_changes() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine);\n\n        for i in 0..5 {\n            client\n                .queue_local_change(PendingChange {\n                    id: format!(\"change-{}\", i),\n                    change_type: ChangeType::PolicyUpdate,\n                    data: serde_json::json!({\"index\": i}),\n                    created_at: chrono::Utc::now().timestamp(),\n                })\n                .await;\n        }\n\n        let state = client.get_sync_state().await;\n        assert_eq!(state.pending_changes.len(), 5);\n    }\n\n    #[tokio::test]\n    async fn test_sync_pending_changes_empty() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine);\n\n        let ctx = test_tenant_context();\n        let synced = client.sync_pending_changes(&ctx).await.unwrap();\n\n        assert_eq!(synced, 0);\n    }\n\n    #[tokio::test]\n    async fn test_cache_key_with_custom_context() {\n        let tenant_id = TenantId::new(\"acme-corp\".to_string()).unwrap();\n        let user_id = UserId::new(\"john-doe\".to_string()).unwrap();\n        let ctx = TenantContext::new(tenant_id, user_id);\n\n        let key = HybridGovernanceClient::cache_key(&ctx, \"proposals\");\n        assert_eq!(key, \"acme-corp:john-doe:proposals\");\n    }\n\n    #[test]\n    fn test_change_type_serialization() {\n        let policy = ChangeType::PolicyUpdate;\n        let drift = ChangeType::DriftResult;\n        let proposal = ChangeType::ProposalAction;\n\n        let policy_json = serde_json::to_string(&policy).unwrap();\n        let drift_json = serde_json::to_string(&drift).unwrap();\n        let proposal_json = serde_json::to_string(&proposal).unwrap();\n\n        assert_eq!(policy_json, \"\\\"PolicyUpdate\\\"\");\n        assert_eq!(drift_json, \"\\\"DriftResult\\\"\");\n        assert_eq!(proposal_json, \"\\\"ProposalAction\\\"\");\n\n        let deserialized: ChangeType = serde_json::from_str(&policy_json).unwrap();\n        assert_eq!(deserialized, ChangeType::PolicyUpdate);\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_client_builder_chain() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine)\n            .with_cache_ttl(Duration::from_secs(600))\n            .with_sync_interval(Duration::from_secs(120));\n\n        assert_eq!(client.cache_ttl, Duration::from_secs(600));\n        assert_eq!(client.sync_interval, Duration::from_secs(120));\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_validate_returns_valid_result() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine);\n\n        let ctx = test_tenant_context();\n        let context = HashMap::new();\n\n        let result = client\n            .validate(&ctx, KnowledgeLayer::Project, &context)\n            .await\n            .unwrap();\n\n        assert!(result.is_valid);\n        assert!(result.violations.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_list_proposals_with_layer_filter() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://invalid-host:9999\".to_string(), engine);\n\n        let ctx = test_tenant_context();\n        let result = client\n            .list_proposals(&ctx, Some(KnowledgeLayer::Company))\n            .await;\n\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_local_client_construction() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let _client = LocalGovernanceClient::new(engine);\n    }\n\n    #[tokio::test]\n    async fn test_local_client_validate() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = LocalGovernanceClient::new(engine);\n\n        let ctx = test_tenant_context();\n        let context = HashMap::new();\n\n        let result = client\n            .validate(&ctx, KnowledgeLayer::Project, &context)\n            .await;\n        assert!(result.is_ok());\n        assert!(result.unwrap().is_valid);\n    }\n\n    #[tokio::test]\n    async fn test_local_client_get_drift_status_no_storage() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = LocalGovernanceClient::new(engine);\n\n        let ctx = test_tenant_context();\n        let result = client.get_drift_status(&ctx, \"proj-1\").await;\n\n        assert!(result.is_ok());\n        assert!(result.unwrap().is_none());\n    }\n\n    #[tokio::test]\n    async fn test_local_client_list_proposals_no_repo() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = LocalGovernanceClient::new(engine);\n\n        let ctx = test_tenant_context();\n        let result = client.list_proposals(&ctx, None).await;\n\n        assert!(result.is_ok());\n        assert!(result.unwrap().is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_local_client_replay_events_no_storage() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = LocalGovernanceClient::new(engine);\n\n        let ctx = test_tenant_context();\n        let result = client.replay_events(&ctx, 0, 100).await;\n\n        assert!(result.is_ok());\n        assert!(result.unwrap().is_empty());\n    }\n\n    #[test]\n    fn test_create_governance_client_local_mode() {\n        let config = config::DeploymentConfig {\n            mode: \"local\".to_string(),\n            remote_url: None,\n            sync_enabled: true,\n        };\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n\n        let result = create_governance_client(&config, Some(engine));\n        assert!(result.is_ok());\n        assert!(matches!(result.unwrap(), GovernanceClientKind::Local(_)));\n    }\n\n    #[test]\n    fn test_create_governance_client_local_mode_requires_engine() {\n        let config = config::DeploymentConfig {\n            mode: \"local\".to_string(),\n            remote_url: None,\n            sync_enabled: true,\n        };\n\n        let result = create_governance_client(&config, None);\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Local mode requires\")\n        );\n    }\n\n    #[test]\n    fn test_create_governance_client_hybrid_mode() {\n        let config = config::DeploymentConfig {\n            mode: \"hybrid\".to_string(),\n            remote_url: Some(\"http://localhost:8080\".to_string()),\n            sync_enabled: true,\n        };\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n\n        let result = create_governance_client(&config, Some(engine));\n        assert!(result.is_ok());\n        assert!(matches!(result.unwrap(), GovernanceClientKind::Hybrid(_)));\n    }\n\n    #[test]\n    fn test_create_governance_client_hybrid_mode_requires_engine() {\n        let config = config::DeploymentConfig {\n            mode: \"hybrid\".to_string(),\n            remote_url: Some(\"http://localhost:8080\".to_string()),\n            sync_enabled: true,\n        };\n\n        let result = create_governance_client(&config, None);\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Hybrid mode requires a GovernanceEngine\")\n        );\n    }\n\n    #[test]\n    fn test_create_governance_client_hybrid_mode_requires_url() {\n        let config = config::DeploymentConfig {\n            mode: \"hybrid\".to_string(),\n            remote_url: None,\n            sync_enabled: true,\n        };\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n\n        let result = create_governance_client(&config, Some(engine));\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Hybrid mode requires a remote_url\")\n        );\n    }\n\n    #[test]\n    fn test_create_governance_client_remote_mode() {\n        let config = config::DeploymentConfig {\n            mode: \"remote\".to_string(),\n            remote_url: Some(\"http://localhost:8080\".to_string()),\n            sync_enabled: false,\n        };\n\n        let result = create_governance_client(&config, None);\n        assert!(result.is_ok());\n        assert!(matches!(result.unwrap(), GovernanceClientKind::Remote(_)));\n    }\n\n    #[test]\n    fn test_create_governance_client_remote_mode_requires_url() {\n        let config = config::DeploymentConfig {\n            mode: \"remote\".to_string(),\n            remote_url: None,\n            sync_enabled: false,\n        };\n\n        let result = create_governance_client(&config, None);\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Remote mode requires a remote_url\")\n        );\n    }\n\n    #[test]\n    fn test_create_governance_client_invalid_mode() {\n        let config = config::DeploymentConfig {\n            mode: \"invalid\".to_string(),\n            remote_url: None,\n            sync_enabled: true,\n        };\n\n        let result = create_governance_client(&config, None);\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Invalid deployment mode\")\n        );\n    }\n\n    #[test]\n    fn test_governance_client_kind_as_client_local() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client_kind = GovernanceClientKind::Local(LocalGovernanceClient::new(engine));\n        let _client: &dyn GovernanceClient = client_kind.as_client();\n    }\n\n    #[test]\n    fn test_governance_client_kind_as_client_hybrid() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client_kind = GovernanceClientKind::Hybrid(HybridGovernanceClient::new(\n            \"http://localhost:8080\".to_string(),\n            engine,\n        ));\n        let _client: &dyn GovernanceClient = client_kind.as_client();\n    }\n\n    #[test]\n    fn test_governance_client_kind_as_client_remote() {\n        let client_kind = GovernanceClientKind::Remote(RemoteGovernanceClient::new(\n            \"http://localhost:8080\".to_string(),\n        ));\n        let _client: &dyn GovernanceClient = client_kind.as_client();\n    }\n}\n","traces":[{"line":38,"address":[],"length":0,"stats":{"Line":16}},{"line":43,"address":[],"length":0,"stats":{"Line":16}},{"line":71,"address":[],"length":0,"stats":{"Line":2}},{"line":74,"address":[],"length":0,"stats":{"Line":2}},{"line":79,"address":[],"length":0,"stats":{"Line":3}},{"line":80,"address":[],"length":0,"stats":{"Line":3}},{"line":119,"address":[],"length":0,"stats":{"Line":18}},{"line":121,"address":[],"length":0,"stats":{"Line":18}},{"line":142,"address":[],"length":0,"stats":{"Line":16}},{"line":144,"address":[],"length":0,"stats":{"Line":16}},{"line":151,"address":[],"length":0,"stats":{"Line":15}},{"line":153,"address":[],"length":0,"stats":{"Line":45}},{"line":155,"address":[],"length":0,"stats":{"Line":60}},{"line":156,"address":[],"length":0,"stats":{"Line":60}},{"line":157,"address":[],"length":0,"stats":{"Line":15}},{"line":158,"address":[],"length":0,"stats":{"Line":15}},{"line":162,"address":[],"length":0,"stats":{"Line":2}},{"line":163,"address":[],"length":0,"stats":{"Line":2}},{"line":164,"address":[],"length":0,"stats":{"Line":2}},{"line":167,"address":[],"length":0,"stats":{"Line":2}},{"line":168,"address":[],"length":0,"stats":{"Line":2}},{"line":169,"address":[],"length":0,"stats":{"Line":2}},{"line":172,"address":[],"length":0,"stats":{"Line":3}},{"line":173,"address":[],"length":0,"stats":{"Line":3}},{"line":175,"address":[],"length":0,"stats":{"Line":6}},{"line":176,"address":[],"length":0,"stats":{"Line":6}},{"line":181,"address":[],"length":0,"stats":{"Line":2}},{"line":182,"address":[],"length":0,"stats":{"Line":2}},{"line":183,"address":[],"length":0,"stats":{"Line":3}},{"line":184,"address":[],"length":0,"stats":{"Line":2}},{"line":186,"address":[],"length":0,"stats":{"Line":1}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":1}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":1}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":225,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":235,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":240,"address":[],"length":0,"stats":{"Line":0}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":16}},{"line":250,"address":[],"length":0,"stats":{"Line":16}},{"line":251,"address":[],"length":0,"stats":{"Line":24}},{"line":254,"address":[],"length":0,"stats":{"Line":8}},{"line":255,"address":[],"length":0,"stats":{"Line":12}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":388,"address":[],"length":0,"stats":{"Line":0}},{"line":389,"address":[],"length":0,"stats":{"Line":0}},{"line":390,"address":[],"length":0,"stats":{"Line":0}},{"line":391,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":0}},{"line":398,"address":[],"length":0,"stats":{"Line":3}},{"line":399,"address":[],"length":0,"stats":{"Line":3}},{"line":400,"address":[],"length":0,"stats":{"Line":2}},{"line":401,"address":[],"length":0,"stats":{"Line":2}},{"line":402,"address":[],"length":0,"stats":{"Line":2}},{"line":407,"address":[],"length":0,"stats":{"Line":8}},{"line":411,"address":[],"length":0,"stats":{"Line":8}},{"line":412,"address":[],"length":0,"stats":{"Line":8}},{"line":413,"address":[],"length":0,"stats":{"Line":6}},{"line":414,"address":[],"length":0,"stats":{"Line":1}},{"line":415,"address":[],"length":0,"stats":{"Line":1}},{"line":418,"address":[],"length":0,"stats":{"Line":1}},{"line":419,"address":[],"length":0,"stats":{"Line":1}},{"line":422,"address":[],"length":0,"stats":{"Line":6}},{"line":423,"address":[],"length":0,"stats":{"Line":9}},{"line":424,"address":[],"length":0,"stats":{"Line":1}},{"line":425,"address":[],"length":0,"stats":{"Line":1}},{"line":428,"address":[],"length":0,"stats":{"Line":8}},{"line":429,"address":[],"length":0,"stats":{"Line":1}},{"line":430,"address":[],"length":0,"stats":{"Line":1}},{"line":433,"address":[],"length":0,"stats":{"Line":2}},{"line":434,"address":[],"length":0,"stats":{"Line":1}},{"line":437,"address":[],"length":0,"stats":{"Line":3}},{"line":438,"address":[],"length":0,"stats":{"Line":8}},{"line":439,"address":[],"length":0,"stats":{"Line":1}},{"line":440,"address":[],"length":0,"stats":{"Line":1}},{"line":443,"address":[],"length":0,"stats":{"Line":1}},{"line":444,"address":[],"length":0,"stats":{"Line":1}},{"line":447,"address":[],"length":0,"stats":{"Line":2}},{"line":448,"address":[],"length":0,"stats":{"Line":1}},{"line":449,"address":[],"length":0,"stats":{"Line":1}},{"line":463,"address":[],"length":0,"stats":{"Line":7}}],"covered":70,"coverable":100},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","hindsight","capture.rs"],"content":"use mk_core::traits::EmbeddingService;\nuse mk_core::types::ErrorSignature;\nuse std::collections::{HashMap, HashSet};\nuse std::sync::Arc;\nuse tracing::info_span;\n\n#[derive(Debug, Clone)]\npub struct ErrorCaptureConfig {\n    pub max_stack_patterns: usize,\n    pub max_context_patterns: usize,\n    pub normalize_line_numbers: bool,\n    pub normalize_hex: bool,\n    pub normalize_uuid: bool,\n    pub normalize_timestamps: bool,\n}\n\nimpl Default for ErrorCaptureConfig {\n    fn default() -> Self {\n        Self {\n            max_stack_patterns: 8,\n            max_context_patterns: 8,\n            normalize_line_numbers: true,\n            normalize_hex: true,\n            normalize_uuid: true,\n            normalize_timestamps: true,\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct ErrorContext {\n    pub tool_name: Option<String>,\n    pub operation: Option<String>,\n    pub file_path: Option<String>,\n    pub metadata: HashMap<String, String>,\n}\n\nimpl Default for ErrorContext {\n    fn default() -> Self {\n        Self {\n            tool_name: None,\n            operation: None,\n            file_path: None,\n            metadata: HashMap::new(),\n        }\n    }\n}\n\nimpl ErrorContext {\n    pub fn with_tool(mut self, tool: impl Into<String>) -> Self {\n        self.tool_name = Some(tool.into());\n        self\n    }\n\n    pub fn with_operation(mut self, op: impl Into<String>) -> Self {\n        self.operation = Some(op.into());\n        self\n    }\n\n    pub fn with_file(mut self, path: impl Into<String>) -> Self {\n        self.file_path = Some(path.into());\n        self\n    }\n\n    pub fn with_meta(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {\n        self.metadata.insert(key.into(), value.into());\n        self\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct CapturedError {\n    pub signature: ErrorSignature,\n    pub raw_message: String,\n    pub raw_stack: Vec<String>,\n    pub context: ErrorContext,\n}\n\npub trait ErrorNormalizer: Send + Sync {\n    fn normalize_message(&self, message: &str) -> String;\n    fn normalize_stack_line(&self, line: &str) -> String;\n}\n\n#[derive(Debug, Clone)]\npub struct DefaultErrorNormalizer {\n    cfg: ErrorCaptureConfig,\n}\n\nimpl DefaultErrorNormalizer {\n    pub fn new(cfg: ErrorCaptureConfig) -> Self {\n        Self { cfg }\n    }\n}\n\nimpl ErrorNormalizer for DefaultErrorNormalizer {\n    fn normalize_message(&self, message: &str) -> String {\n        normalize_text(message, &self.cfg)\n    }\n\n    fn normalize_stack_line(&self, line: &str) -> String {\n        normalize_text(line, &self.cfg)\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct ErrorCapture<N> {\n    normalizer: N,\n    cfg: ErrorCaptureConfig,\n}\n\nimpl ErrorCapture<DefaultErrorNormalizer> {\n    pub fn new(cfg: ErrorCaptureConfig) -> Self {\n        let normalizer = DefaultErrorNormalizer::new(cfg.clone());\n        Self { normalizer, cfg }\n    }\n}\n\nimpl<N: ErrorNormalizer> ErrorCapture<N> {\n    pub fn with_normalizer(cfg: ErrorCaptureConfig, normalizer: N) -> Self {\n        Self { cfg, normalizer }\n    }\n\n    pub fn capture(\n        &self,\n        error_type: impl Into<String>,\n        message: &str,\n        stack: &[String],\n        context: ErrorContext,\n    ) -> CapturedError {\n        let error_type_str = error_type.into();\n        let _span = info_span!(\n            \"capture_error\",\n            error_type = %error_type_str,\n            message_len = message.len(),\n            stack_len = stack.len(),\n            has_tool = context.tool_name.is_some(),\n            has_file = context.file_path.is_some(),\n            metadata_count = context.metadata.len()\n        )\n        .entered();\n\n        let error_type = error_type_str;\n\n        let normalized_message = self.normalizer.normalize_message(message);\n        let mut stack_patterns: Vec<String> = stack\n            .iter()\n            .map(|l| self.normalizer.normalize_stack_line(l))\n            .filter(|l| !l.trim().is_empty())\n            .collect();\n\n        if stack_patterns.len() > self.cfg.max_stack_patterns {\n            stack_patterns.truncate(self.cfg.max_stack_patterns);\n        }\n\n        let mut context_patterns = Vec::new();\n        if let Some(ref tool) = context.tool_name {\n            context_patterns.push(format!(\"tool:{tool}\"));\n        }\n        if let Some(ref op) = context.operation {\n            context_patterns.push(format!(\"op:{op}\"));\n        }\n        if let Some(ref file) = context.file_path {\n            context_patterns.push(format!(\"file:{file}\"));\n        }\n\n        for (k, v) in &context.metadata {\n            if context_patterns.len() >= self.cfg.max_context_patterns {\n                break;\n            }\n            context_patterns.push(format!(\"meta:{k}={v}\"));\n        }\n\n        CapturedError {\n            signature: ErrorSignature {\n                error_type,\n                message_pattern: normalized_message,\n                stack_patterns,\n                context_patterns,\n                embedding: None,\n            },\n            raw_message: message.to_string(),\n            raw_stack: stack.to_vec(),\n            context,\n        }\n    }\n\n    pub async fn capture_with_embedding<E: std::error::Error + Send + Sync + 'static>(\n        &self,\n        error_type: impl Into<String>,\n        message: &str,\n        stack: &[String],\n        context: ErrorContext,\n        embedder: Option<&Arc<dyn EmbeddingService<Error = E>>>,\n    ) -> CapturedError {\n        let error_type_str = error_type.into();\n        let span = info_span!(\n            \"capture_error_with_embedding\",\n            error_type = %error_type_str,\n            has_embedder = embedder.is_some()\n        );\n\n        let _guard = span.enter();\n\n        let mut captured = self.capture(error_type_str, message, stack, context);\n        if let Some(service) = embedder {\n            let text = format!(\n                \"{}\\n{}\\n{}\",\n                captured.signature.message_pattern,\n                captured.signature.stack_patterns.join(\"\\n\"),\n                captured.signature.context_patterns.join(\"\\n\")\n            );\n            captured.signature.embedding = service.embed(&text).await.ok();\n        }\n        captured\n    }\n\n    pub fn should_deduplicate(\n        &self,\n        candidate: &ErrorSignature,\n        existing: &[ErrorSignature],\n        threshold: f32,\n    ) -> bool {\n        existing.iter().any(|sig| {\n            if sig.error_type != candidate.error_type {\n                return false;\n            }\n\n            let msg_sim = jaccard_similarity(\n                &tokenize(&candidate.message_pattern),\n                &tokenize(&sig.message_pattern),\n            );\n            let ctx_sim = jaccard_similarity(&candidate.context_patterns, &sig.context_patterns);\n            let stack_sim = jaccard_similarity(&candidate.stack_patterns, &sig.stack_patterns);\n\n            let mut score = msg_sim * 0.6 + ctx_sim * 0.2 + stack_sim * 0.2;\n\n            if let (Some(a), Some(b)) = (candidate.embedding.as_ref(), sig.embedding.as_ref()) {\n                let sim = cosine_similarity(a, b);\n                score = score.max(sim);\n            }\n\n            score >= threshold\n        })\n    }\n}\n\nfn normalize_text(input: &str, cfg: &ErrorCaptureConfig) -> String {\n    let mut out = input.to_string();\n\n    if cfg.normalize_uuid {\n        out = replace_uuid_like(&out);\n    }\n    if cfg.normalize_hex {\n        out = replace_hex_like(&out);\n    }\n    if cfg.normalize_line_numbers {\n        out = replace_line_numbers(&out);\n    }\n    if cfg.normalize_timestamps {\n        out = replace_timestamps(&out);\n    }\n\n    out\n}\n\nfn replace_uuid_like(input: &str) -> String {\n    let re =\n        regex::Regex::new(r\"(?i)\\b[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\\b\");\n    match re {\n        Ok(re) => re.replace_all(input, \"<uuid>\").to_string(),\n        Err(_) => input.to_string(),\n    }\n}\n\nfn replace_hex_like(input: &str) -> String {\n    let re = regex::Regex::new(r\"(?i)\\b0x[0-9a-f]+\\b\");\n    match re {\n        Ok(re) => re.replace_all(input, \"<hex>\").to_string(),\n        Err(_) => input.to_string(),\n    }\n}\n\nfn replace_line_numbers(input: &str) -> String {\n    let re = regex::Regex::new(r\"\\bline\\s+\\d+\\b\");\n    match re {\n        Ok(re) => re.replace_all(input, \"line <n>\").to_string(),\n        Err(_) => input.to_string(),\n    }\n}\n\nfn replace_timestamps(input: &str) -> String {\n    let re = regex::Regex::new(r\"\\b\\d{4}-\\d{2}-\\d{2}[T\\s]\\d{2}:\\d{2}:\\d{2}(?:\\.\\d+)?Z?\\b\");\n    match re {\n        Ok(re) => re.replace_all(input, \"<ts>\").to_string(),\n        Err(_) => input.to_string(),\n    }\n}\n\nfn tokenize(text: &str) -> Vec<String> {\n    text.split(|c: char| !c.is_alphanumeric())\n        .filter(|s| !s.is_empty())\n        .map(|s| s.to_lowercase())\n        .collect()\n}\n\nfn jaccard_similarity(a: &[String], b: &[String]) -> f32 {\n    if a.is_empty() || b.is_empty() {\n        return 0.0;\n    }\n\n    let a_set: HashSet<_> = a.iter().collect();\n    let b_set: HashSet<_> = b.iter().collect();\n\n    let intersection = a_set.intersection(&b_set).count() as f32;\n    let union = a_set.union(&b_set).count() as f32;\n\n    if union == 0.0 {\n        0.0\n    } else {\n        intersection / union\n    }\n}\n\nfn cosine_similarity(a: &[f32], b: &[f32]) -> f32 {\n    if a.len() != b.len() || a.is_empty() {\n        return 0.0;\n    }\n\n    let dot: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();\n    let norm_a: f32 = a.iter().map(|x| x * x).sum::<f32>().sqrt();\n    let norm_b: f32 = b.iter().map(|x| x * x).sum::<f32>().sqrt();\n\n    if norm_a == 0.0 || norm_b == 0.0 {\n        return 0.0;\n    }\n\n    dot / (norm_a * norm_b)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_capture_basic() {\n        let cap = ErrorCapture::new(ErrorCaptureConfig::default());\n        let stack = vec![\"at foo (src/lib.rs:10)\".to_string()];\n        let ctx = ErrorContext::default().with_tool(\"cargo_test\");\n\n        let captured = cap.capture(\"TypeError\", \"Something failed\", &stack, ctx);\n\n        assert_eq!(captured.signature.error_type, \"TypeError\");\n        assert_eq!(captured.signature.message_pattern, \"Something failed\");\n        assert_eq!(captured.signature.stack_patterns.len(), 1);\n        assert!(\n            captured\n                .signature\n                .context_patterns\n                .iter()\n                .any(|p| p.contains(\"tool:\"))\n        );\n    }\n\n    #[test]\n    fn test_normalize_uuid_and_hex() {\n        let cfg = ErrorCaptureConfig::default();\n        let cap = ErrorCapture::new(cfg);\n        let msg = \"Failed request id 550e8400-e29b-41d4-a716-446655440000 ptr 0xDEADBEEF\";\n\n        let captured = cap.capture(\"Err\", msg, &[], ErrorContext::default());\n\n        assert!(captured.signature.message_pattern.contains(\"<uuid>\"));\n        assert!(captured.signature.message_pattern.contains(\"<hex>\"));\n    }\n\n    #[test]\n    fn test_normalize_line_numbers() {\n        let cfg = ErrorCaptureConfig::default();\n        let cap = ErrorCapture::new(cfg);\n        let msg = \"Parse error at line 123\";\n\n        let captured = cap.capture(\"ParseError\", msg, &[], ErrorContext::default());\n\n        assert_eq!(\n            captured.signature.message_pattern,\n            \"Parse error at line <n>\"\n        );\n    }\n\n    #[test]\n    fn test_normalize_timestamps() {\n        let cfg = ErrorCaptureConfig::default();\n        let cap = ErrorCapture::new(cfg);\n        let msg = \"Event at 2025-01-10T12:13:14Z failed\";\n\n        let captured = cap.capture(\"EventError\", msg, &[], ErrorContext::default());\n\n        assert!(captured.signature.message_pattern.contains(\"<ts>\"));\n    }\n\n    #[test]\n    fn test_stack_truncation() {\n        let cfg = ErrorCaptureConfig {\n            max_stack_patterns: 2,\n            ..Default::default()\n        };\n        let cap = ErrorCapture::new(cfg);\n        let stack = vec![\"a\".to_string(), \"b\".to_string(), \"c\".to_string()];\n\n        let captured = cap.capture(\"Err\", \"msg\", &stack, ErrorContext::default());\n\n        assert_eq!(captured.signature.stack_patterns.len(), 2);\n    }\n\n    #[test]\n    fn test_context_pattern_limit() {\n        let cfg = ErrorCaptureConfig {\n            max_context_patterns: 2,\n            ..Default::default()\n        };\n        let cap = ErrorCapture::new(cfg);\n        let ctx = ErrorContext::default()\n            .with_tool(\"t\")\n            .with_operation(\"o\")\n            .with_meta(\"k1\", \"v1\");\n\n        let captured = cap.capture(\"Err\", \"msg\", &[], ctx);\n\n        assert_eq!(captured.signature.context_patterns.len(), 2);\n    }\n\n    #[test]\n    fn test_deduplication_match() {\n        let cap = ErrorCapture::new(ErrorCaptureConfig::default());\n        let existing = vec![ErrorSignature {\n            error_type: \"TypeError\".to_string(),\n            message_pattern: \"cannot read property\".to_string(),\n            stack_patterns: vec![\"at foo\".to_string()],\n            context_patterns: vec![\"tool:cargo_test\".to_string()],\n            embedding: None,\n        }];\n\n        let candidate = ErrorSignature {\n            error_type: \"TypeError\".to_string(),\n            message_pattern: \"cannot read property\".to_string(),\n            stack_patterns: vec![\"at foo\".to_string()],\n            context_patterns: vec![\"tool:cargo_test\".to_string()],\n            embedding: None,\n        };\n\n        assert!(cap.should_deduplicate(&candidate, &existing, 0.6));\n    }\n\n    #[test]\n    fn test_deduplication_no_match() {\n        let cap = ErrorCapture::new(ErrorCaptureConfig::default());\n        let existing = vec![ErrorSignature {\n            error_type: \"TypeError\".to_string(),\n            message_pattern: \"cannot read property\".to_string(),\n            stack_patterns: vec![],\n            context_patterns: vec![],\n            embedding: None,\n        }];\n\n        let candidate = ErrorSignature {\n            error_type: \"TypeError\".to_string(),\n            message_pattern: \"different error\".to_string(),\n            stack_patterns: vec![],\n            context_patterns: vec![],\n            embedding: None,\n        };\n\n        assert!(!cap.should_deduplicate(&candidate, &existing, 0.8));\n    }\n}\n","traces":[{"line":18,"address":[],"length":0,"stats":{"Line":8}},{"line":39,"address":[],"length":0,"stats":{"Line":6}},{"line":44,"address":[],"length":0,"stats":{"Line":6}},{"line":50,"address":[],"length":0,"stats":{"Line":2}},{"line":51,"address":[],"length":0,"stats":{"Line":4}},{"line":52,"address":[],"length":0,"stats":{"Line":2}},{"line":55,"address":[],"length":0,"stats":{"Line":1}},{"line":56,"address":[],"length":0,"stats":{"Line":2}},{"line":57,"address":[],"length":0,"stats":{"Line":1}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":1}},{"line":66,"address":[],"length":0,"stats":{"Line":6}},{"line":67,"address":[],"length":0,"stats":{"Line":1}},{"line":90,"address":[],"length":0,"stats":{"Line":8}},{"line":96,"address":[],"length":0,"stats":{"Line":6}},{"line":97,"address":[],"length":0,"stats":{"Line":18}},{"line":100,"address":[],"length":0,"stats":{"Line":4}},{"line":101,"address":[],"length":0,"stats":{"Line":12}},{"line":112,"address":[],"length":0,"stats":{"Line":8}},{"line":113,"address":[],"length":0,"stats":{"Line":32}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":6}},{"line":130,"address":[],"length":0,"stats":{"Line":18}},{"line":131,"address":[],"length":0,"stats":{"Line":12}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":12}},{"line":135,"address":[],"length":0,"stats":{"Line":12}},{"line":136,"address":[],"length":0,"stats":{"Line":12}},{"line":137,"address":[],"length":0,"stats":{"Line":12}},{"line":138,"address":[],"length":0,"stats":{"Line":12}},{"line":142,"address":[],"length":0,"stats":{"Line":12}},{"line":144,"address":[],"length":0,"stats":{"Line":24}},{"line":145,"address":[],"length":0,"stats":{"Line":18}},{"line":147,"address":[],"length":0,"stats":{"Line":18}},{"line":148,"address":[],"length":0,"stats":{"Line":14}},{"line":151,"address":[],"length":0,"stats":{"Line":13}},{"line":152,"address":[],"length":0,"stats":{"Line":2}},{"line":155,"address":[],"length":0,"stats":{"Line":12}},{"line":156,"address":[],"length":0,"stats":{"Line":10}},{"line":157,"address":[],"length":0,"stats":{"Line":6}},{"line":159,"address":[],"length":0,"stats":{"Line":8}},{"line":160,"address":[],"length":0,"stats":{"Line":3}},{"line":162,"address":[],"length":0,"stats":{"Line":6}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":8}},{"line":167,"address":[],"length":0,"stats":{"Line":2}},{"line":168,"address":[],"length":0,"stats":{"Line":1}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":12}},{"line":181,"address":[],"length":0,"stats":{"Line":18}},{"line":182,"address":[],"length":0,"stats":{"Line":12}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":204,"address":[],"length":0,"stats":{"Line":0}},{"line":205,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":2}},{"line":223,"address":[],"length":0,"stats":{"Line":6}},{"line":224,"address":[],"length":0,"stats":{"Line":2}},{"line":225,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":4}},{"line":229,"address":[],"length":0,"stats":{"Line":2}},{"line":230,"address":[],"length":0,"stats":{"Line":2}},{"line":232,"address":[],"length":0,"stats":{"Line":8}},{"line":233,"address":[],"length":0,"stats":{"Line":8}},{"line":235,"address":[],"length":0,"stats":{"Line":4}},{"line":237,"address":[],"length":0,"stats":{"Line":8}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":242,"address":[],"length":0,"stats":{"Line":2}},{"line":247,"address":[],"length":0,"stats":{"Line":10}},{"line":248,"address":[],"length":0,"stats":{"Line":30}},{"line":250,"address":[],"length":0,"stats":{"Line":20}},{"line":251,"address":[],"length":0,"stats":{"Line":20}},{"line":253,"address":[],"length":0,"stats":{"Line":20}},{"line":254,"address":[],"length":0,"stats":{"Line":20}},{"line":256,"address":[],"length":0,"stats":{"Line":20}},{"line":257,"address":[],"length":0,"stats":{"Line":20}},{"line":259,"address":[],"length":0,"stats":{"Line":20}},{"line":260,"address":[],"length":0,"stats":{"Line":20}},{"line":263,"address":[],"length":0,"stats":{"Line":10}},{"line":266,"address":[],"length":0,"stats":{"Line":10}},{"line":267,"address":[],"length":0,"stats":{"Line":10}},{"line":268,"address":[],"length":0,"stats":{"Line":20}},{"line":269,"address":[],"length":0,"stats":{"Line":10}},{"line":270,"address":[],"length":0,"stats":{"Line":40}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":10}},{"line":276,"address":[],"length":0,"stats":{"Line":30}},{"line":277,"address":[],"length":0,"stats":{"Line":10}},{"line":278,"address":[],"length":0,"stats":{"Line":40}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":10}},{"line":284,"address":[],"length":0,"stats":{"Line":30}},{"line":285,"address":[],"length":0,"stats":{"Line":10}},{"line":286,"address":[],"length":0,"stats":{"Line":40}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":10}},{"line":292,"address":[],"length":0,"stats":{"Line":30}},{"line":293,"address":[],"length":0,"stats":{"Line":10}},{"line":294,"address":[],"length":0,"stats":{"Line":40}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":4}},{"line":300,"address":[],"length":0,"stats":{"Line":158}},{"line":301,"address":[],"length":0,"stats":{"Line":26}},{"line":302,"address":[],"length":0,"stats":{"Line":26}},{"line":306,"address":[],"length":0,"stats":{"Line":6}},{"line":307,"address":[],"length":0,"stats":{"Line":20}},{"line":308,"address":[],"length":0,"stats":{"Line":2}},{"line":311,"address":[],"length":0,"stats":{"Line":20}},{"line":312,"address":[],"length":0,"stats":{"Line":20}},{"line":314,"address":[],"length":0,"stats":{"Line":16}},{"line":315,"address":[],"length":0,"stats":{"Line":16}},{"line":317,"address":[],"length":0,"stats":{"Line":4}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":4}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":325,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":333,"address":[],"length":0,"stats":{"Line":0}},{"line":334,"address":[],"length":0,"stats":{"Line":0}},{"line":337,"address":[],"length":0,"stats":{"Line":0}}],"covered":98,"coverable":136},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","hindsight","dedup.rs"],"content":"use std::collections::HashMap;\nuse std::sync::{Arc, RwLock};\nuse std::time::{SystemTime, UNIX_EPOCH};\n\nuse async_trait::async_trait;\nuse mk_core::types::{ErrorSignature, HindsightNote, Resolution};\nuse serde::{Deserialize, Serialize};\nuse thiserror::Error;\nuse tracing::{info, info_span, instrument};\n\n#[derive(Debug, Clone)]\npub struct DeduplicationConfig {\n    pub similarity_threshold: f32,\n    pub embedding_weight: f32,\n    pub message_weight: f32,\n    pub context_weight: f32,\n    pub stack_weight: f32,\n    pub background_scan_interval_secs: u64,\n    pub max_signatures_per_scan: usize,\n}\n\nimpl Default for DeduplicationConfig {\n    fn default() -> Self {\n        Self {\n            similarity_threshold: 0.95,\n            embedding_weight: 0.5,\n            message_weight: 0.3,\n            context_weight: 0.1,\n            stack_weight: 0.1,\n            background_scan_interval_secs: 3600,\n            max_signatures_per_scan: 1000,\n        }\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct IndexedSignature {\n    pub id: String,\n    pub error_type: String,\n    pub normalized_message: String,\n    pub context_hash: u64,\n    pub embedding: Option<Vec<f32>>,\n    pub created_at: i64,\n    pub merge_count: u32,\n}\n\nimpl IndexedSignature {\n    pub fn from_signature(id: impl Into<String>, sig: &ErrorSignature) -> Self {\n        let context_hash = compute_context_hash(&sig.context_patterns);\n        Self {\n            id: id.into(),\n            error_type: sig.error_type.clone(),\n            normalized_message: sig.message_pattern.clone(),\n            context_hash,\n            embedding: sig.embedding.clone(),\n            created_at: current_timestamp(),\n            merge_count: 0,\n        }\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct DeduplicationMetrics {\n    pub duplicates_detected: u64,\n    pub duplicates_merged: u64,\n    pub unique_signatures: u64,\n    pub last_scan_at: Option<i64>,\n    pub last_scan_duration_ms: Option<u64>,\n    pub scans_completed: u64,\n}\n\nimpl Default for DeduplicationMetrics {\n    fn default() -> Self {\n        Self {\n            duplicates_detected: 0,\n            duplicates_merged: 0,\n            unique_signatures: 0,\n            last_scan_at: None,\n            last_scan_duration_ms: None,\n            scans_completed: 0,\n        }\n    }\n}\n\n#[derive(Debug, Error)]\npub enum DeduplicationError {\n    #[error(\"Index error: {0}\")]\n    Index(String),\n    #[error(\"Storage error: {0}\")]\n    Storage(String),\n    #[error(\"Merge error: {0}\")]\n    Merge(String),\n}\n\n#[async_trait]\npub trait SignatureStorage: Send + Sync {\n    async fn get_signature(&self, id: &str)\n    -> Result<Option<IndexedSignature>, DeduplicationError>;\n    async fn save_signature(&self, sig: &IndexedSignature) -> Result<(), DeduplicationError>;\n    async fn list_signatures_by_type(\n        &self,\n        error_type: &str,\n    ) -> Result<Vec<IndexedSignature>, DeduplicationError>;\n    async fn delete_signature(&self, id: &str) -> Result<(), DeduplicationError>;\n    async fn get_all_signatures(&self) -> Result<Vec<IndexedSignature>, DeduplicationError>;\n    async fn merge_signatures(\n        &self,\n        keep_id: &str,\n        remove_id: &str,\n    ) -> Result<(), DeduplicationError>;\n}\n\npub struct InMemorySignatureStorage {\n    signatures: RwLock<HashMap<String, IndexedSignature>>,\n}\n\nimpl InMemorySignatureStorage {\n    pub fn new() -> Self {\n        Self {\n            signatures: RwLock::new(HashMap::new()),\n        }\n    }\n}\n\nimpl Default for InMemorySignatureStorage {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n#[async_trait]\nimpl SignatureStorage for InMemorySignatureStorage {\n    async fn get_signature(\n        &self,\n        id: &str,\n    ) -> Result<Option<IndexedSignature>, DeduplicationError> {\n        let sigs = self\n            .signatures\n            .read()\n            .map_err(|e| DeduplicationError::Storage(format!(\"Lock poisoned: {e}\")))?;\n        Ok(sigs.get(id).cloned())\n    }\n\n    async fn save_signature(&self, sig: &IndexedSignature) -> Result<(), DeduplicationError> {\n        let mut sigs = self\n            .signatures\n            .write()\n            .map_err(|e| DeduplicationError::Storage(format!(\"Lock poisoned: {e}\")))?;\n        sigs.insert(sig.id.clone(), sig.clone());\n        Ok(())\n    }\n\n    async fn list_signatures_by_type(\n        &self,\n        error_type: &str,\n    ) -> Result<Vec<IndexedSignature>, DeduplicationError> {\n        let sigs = self\n            .signatures\n            .read()\n            .map_err(|e| DeduplicationError::Storage(format!(\"Lock poisoned: {e}\")))?;\n        Ok(sigs\n            .values()\n            .filter(|s| s.error_type == error_type)\n            .cloned()\n            .collect())\n    }\n\n    async fn delete_signature(&self, id: &str) -> Result<(), DeduplicationError> {\n        let mut sigs = self\n            .signatures\n            .write()\n            .map_err(|e| DeduplicationError::Storage(format!(\"Lock poisoned: {e}\")))?;\n        sigs.remove(id);\n        Ok(())\n    }\n\n    async fn get_all_signatures(&self) -> Result<Vec<IndexedSignature>, DeduplicationError> {\n        let sigs = self\n            .signatures\n            .read()\n            .map_err(|e| DeduplicationError::Storage(format!(\"Lock poisoned: {e}\")))?;\n        Ok(sigs.values().cloned().collect())\n    }\n\n    async fn merge_signatures(\n        &self,\n        keep_id: &str,\n        remove_id: &str,\n    ) -> Result<(), DeduplicationError> {\n        let mut sigs = self\n            .signatures\n            .write()\n            .map_err(|e| DeduplicationError::Storage(format!(\"Lock poisoned: {e}\")))?;\n\n        if let Some(removed) = sigs.remove(remove_id) {\n            if let Some(kept) = sigs.get_mut(keep_id) {\n                kept.merge_count += removed.merge_count + 1;\n            }\n        }\n        Ok(())\n    }\n}\n\npub struct ErrorSignatureIndex<S: SignatureStorage> {\n    storage: Arc<S>,\n    cfg: DeduplicationConfig,\n    metrics: Arc<RwLock<DeduplicationMetrics>>,\n}\n\nimpl<S: SignatureStorage> ErrorSignatureIndex<S> {\n    pub fn new(storage: Arc<S>, cfg: DeduplicationConfig) -> Self {\n        Self {\n            storage,\n            cfg,\n            metrics: Arc::new(RwLock::new(DeduplicationMetrics::default())),\n        }\n    }\n\n    pub fn metrics(&self) -> DeduplicationMetrics {\n        self.metrics.read().map(|m| m.clone()).unwrap_or_default()\n    }\n\n    #[instrument(skip(self, signature), fields(error_type = %signature.error_type))]\n    pub async fn find_duplicate(\n        &self,\n        signature: &ErrorSignature,\n    ) -> Result<Option<IndexedSignature>, DeduplicationError> {\n        let candidates = self\n            .storage\n            .list_signatures_by_type(&signature.error_type)\n            .await?;\n\n        if candidates.is_empty() {\n            return Ok(None);\n        }\n\n        let candidate = IndexedSignature::from_signature(\"temp\", signature);\n\n        for existing in &candidates {\n            let score = self.compute_similarity(&candidate, existing);\n            if score >= self.cfg.similarity_threshold {\n                if let Ok(mut m) = self.metrics.write() {\n                    m.duplicates_detected += 1;\n                }\n                return Ok(Some(existing.clone()));\n            }\n        }\n\n        Ok(None)\n    }\n\n    #[instrument(skip(self, id, signature))]\n    pub async fn insert_or_deduplicate(\n        &self,\n        id: impl Into<String>,\n        signature: &ErrorSignature,\n    ) -> Result<DeduplicationResult, DeduplicationError> {\n        let id = id.into();\n\n        if let Some(existing) = self.find_duplicate(signature).await? {\n            info!(\n                existing_id = %existing.id,\n                new_id = %id,\n                \"Duplicate signature detected, merging\"\n            );\n            return Ok(DeduplicationResult::Duplicate {\n                existing_id: existing.id,\n                new_id: id,\n            });\n        }\n\n        let indexed = IndexedSignature::from_signature(&id, signature);\n        self.storage.save_signature(&indexed).await?;\n\n        if let Ok(mut m) = self.metrics.write() {\n            m.unique_signatures += 1;\n        }\n\n        Ok(DeduplicationResult::Unique { id })\n    }\n\n    fn compute_similarity(&self, a: &IndexedSignature, b: &IndexedSignature) -> f32 {\n        let mut total_weight = 0.0;\n        let mut weighted_score = 0.0;\n\n        if let (Some(emb_a), Some(emb_b)) = (&a.embedding, &b.embedding) {\n            let emb_sim = cosine_similarity(emb_a, emb_b);\n            weighted_score += emb_sim * self.cfg.embedding_weight;\n            total_weight += self.cfg.embedding_weight;\n        }\n\n        let msg_sim = jaccard_similarity(\n            &tokenize(&a.normalized_message),\n            &tokenize(&b.normalized_message),\n        );\n        weighted_score += msg_sim * self.cfg.message_weight;\n        total_weight += self.cfg.message_weight;\n\n        let ctx_sim = if a.context_hash == b.context_hash {\n            1.0\n        } else {\n            0.0\n        };\n        weighted_score += ctx_sim * self.cfg.context_weight;\n        total_weight += self.cfg.context_weight;\n\n        if total_weight > 0.0 {\n            weighted_score / total_weight\n        } else {\n            0.0\n        }\n    }\n\n    #[instrument(skip(self))]\n    pub async fn run_background_scan(&self) -> Result<ScanResult, DeduplicationError> {\n        let start = std::time::Instant::now();\n        let _span = info_span!(\"dedup_background_scan\").entered();\n\n        let all_sigs = self.storage.get_all_signatures().await?;\n        let mut duplicates_found = 0;\n        let mut merges_performed = 0;\n\n        let mut by_type: HashMap<String, Vec<IndexedSignature>> = HashMap::new();\n        for sig in all_sigs.into_iter().take(self.cfg.max_signatures_per_scan) {\n            by_type.entry(sig.error_type.clone()).or_default().push(sig);\n        }\n\n        for (_error_type, sigs) in by_type {\n            if sigs.len() < 2 {\n                continue;\n            }\n\n            let mut to_merge: Vec<(String, String)> = Vec::new();\n\n            for i in 0..sigs.len() {\n                for j in (i + 1)..sigs.len() {\n                    let score = self.compute_similarity(&sigs[i], &sigs[j]);\n                    if score >= self.cfg.similarity_threshold {\n                        duplicates_found += 1;\n                        let keep = if sigs[i].created_at <= sigs[j].created_at {\n                            &sigs[i]\n                        } else {\n                            &sigs[j]\n                        };\n                        let remove = if sigs[i].created_at <= sigs[j].created_at {\n                            &sigs[j]\n                        } else {\n                            &sigs[i]\n                        };\n                        to_merge.push((keep.id.clone(), remove.id.clone()));\n                    }\n                }\n            }\n\n            for (keep_id, remove_id) in to_merge {\n                if self\n                    .storage\n                    .merge_signatures(&keep_id, &remove_id)\n                    .await\n                    .is_ok()\n                {\n                    merges_performed += 1;\n                }\n            }\n        }\n\n        let duration_ms = start.elapsed().as_millis() as u64;\n\n        if let Ok(mut m) = self.metrics.write() {\n            m.duplicates_merged += merges_performed;\n            m.last_scan_at = Some(current_timestamp());\n            m.last_scan_duration_ms = Some(duration_ms);\n            m.scans_completed += 1;\n        }\n\n        info!(\n            duplicates_found = duplicates_found,\n            merges_performed = merges_performed,\n            duration_ms = duration_ms,\n            \"Background deduplication scan completed\"\n        );\n\n        Ok(ScanResult {\n            duplicates_found,\n            merges_performed,\n            duration_ms,\n        })\n    }\n}\n\n#[derive(Debug, Clone)]\npub enum DeduplicationResult {\n    Unique { id: String },\n    Duplicate { existing_id: String, new_id: String },\n}\n\nimpl DeduplicationResult {\n    pub fn is_duplicate(&self) -> bool {\n        matches!(self, DeduplicationResult::Duplicate { .. })\n    }\n\n    pub fn effective_id(&self) -> &str {\n        match self {\n            DeduplicationResult::Unique { id } => id,\n            DeduplicationResult::Duplicate { existing_id, .. } => existing_id,\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct ScanResult {\n    pub duplicates_found: u64,\n    pub merges_performed: u64,\n    pub duration_ms: u64,\n}\n\npub struct ResolutionMerger;\n\nimpl ResolutionMerger {\n    pub fn merge_resolutions(primary: &mut Resolution, secondary: &Resolution) {\n        let combined_applications =\n            primary.application_count as f64 + secondary.application_count as f64;\n\n        if combined_applications > 0.0 {\n            let primary_weight = primary.application_count as f64 * primary.success_rate as f64;\n            let secondary_weight =\n                secondary.application_count as f64 * secondary.success_rate as f64;\n            primary.success_rate =\n                ((primary_weight + secondary_weight) / combined_applications) as f32;\n        }\n\n        primary.application_count += secondary.application_count;\n\n        if secondary.last_success_at > primary.last_success_at {\n            primary.last_success_at = secondary.last_success_at;\n        }\n\n        for change in &secondary.changes {\n            if !primary\n                .changes\n                .iter()\n                .any(|c| c.file_path == change.file_path)\n            {\n                primary.changes.push(change.clone());\n            }\n        }\n    }\n\n    pub fn merge_hindsight_notes(primary: &mut HindsightNote, secondary: &HindsightNote) {\n        for resolution in &secondary.resolutions {\n            if !primary.resolutions.iter().any(|r| r.id == resolution.id) {\n                primary.resolutions.push(resolution.clone());\n            }\n        }\n\n        for tag in &secondary.tags {\n            if !primary.tags.contains(tag) {\n                primary.tags.push(tag.clone());\n            }\n        }\n\n        if secondary.updated_at > primary.updated_at {\n            primary.updated_at = secondary.updated_at;\n        }\n    }\n}\n\nfn current_timestamp() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or(0)\n}\n\nfn compute_context_hash(patterns: &[String]) -> u64 {\n    use std::collections::hash_map::DefaultHasher;\n    use std::hash::{Hash, Hasher};\n\n    let mut sorted: Vec<_> = patterns.iter().collect();\n    sorted.sort();\n\n    let mut hasher = DefaultHasher::new();\n    for p in sorted {\n        p.hash(&mut hasher);\n    }\n    hasher.finish()\n}\n\nfn tokenize(text: &str) -> Vec<String> {\n    text.split(|c: char| !c.is_alphanumeric())\n        .filter(|s| !s.is_empty())\n        .map(|s| s.to_lowercase())\n        .collect()\n}\n\nfn jaccard_similarity(a: &[String], b: &[String]) -> f32 {\n    if a.is_empty() || b.is_empty() {\n        return 0.0;\n    }\n\n    use std::collections::HashSet;\n    let a_set: HashSet<_> = a.iter().collect();\n    let b_set: HashSet<_> = b.iter().collect();\n\n    let intersection = a_set.intersection(&b_set).count() as f32;\n    let union = a_set.union(&b_set).count() as f32;\n\n    if union == 0.0 {\n        0.0\n    } else {\n        intersection / union\n    }\n}\n\nfn cosine_similarity(a: &[f32], b: &[f32]) -> f32 {\n    if a.len() != b.len() || a.is_empty() {\n        return 0.0;\n    }\n\n    let dot: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();\n    let norm_a: f32 = a.iter().map(|x| x * x).sum::<f32>().sqrt();\n    let norm_b: f32 = b.iter().map(|x| x * x).sum::<f32>().sqrt();\n\n    if norm_a == 0.0 || norm_b == 0.0 {\n        0.0\n    } else {\n        dot / (norm_a * norm_b)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    fn sample_signature(error_type: &str, message: &str) -> ErrorSignature {\n        ErrorSignature {\n            error_type: error_type.to_string(),\n            message_pattern: message.to_string(),\n            stack_patterns: vec![],\n            context_patterns: vec![],\n            embedding: None,\n        }\n    }\n\n    fn sample_signature_with_embedding(\n        error_type: &str,\n        message: &str,\n        embedding: Vec<f32>,\n    ) -> ErrorSignature {\n        ErrorSignature {\n            error_type: error_type.to_string(),\n            message_pattern: message.to_string(),\n            stack_patterns: vec![],\n            context_patterns: vec![],\n            embedding: Some(embedding),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_insert_unique_signature() {\n        let storage = Arc::new(InMemorySignatureStorage::new());\n        let index = ErrorSignatureIndex::new(storage, DeduplicationConfig::default());\n\n        let sig = sample_signature(\"TypeError\", \"Cannot read property\");\n        let result = index.insert_or_deduplicate(\"sig1\", &sig).await.unwrap();\n\n        assert!(!result.is_duplicate());\n        assert_eq!(result.effective_id(), \"sig1\");\n\n        let metrics = index.metrics();\n        assert_eq!(metrics.unique_signatures, 1);\n    }\n\n    #[tokio::test]\n    async fn test_detect_duplicate_signature() {\n        let storage = Arc::new(InMemorySignatureStorage::new());\n        let index = ErrorSignatureIndex::new(storage, DeduplicationConfig::default());\n\n        let sig1 = sample_signature(\"TypeError\", \"Cannot read property\");\n        index.insert_or_deduplicate(\"sig1\", &sig1).await.unwrap();\n\n        let sig2 = sample_signature(\"TypeError\", \"Cannot read property\");\n        let result = index.insert_or_deduplicate(\"sig2\", &sig2).await.unwrap();\n\n        assert!(result.is_duplicate());\n        assert_eq!(result.effective_id(), \"sig1\");\n\n        let metrics = index.metrics();\n        assert_eq!(metrics.duplicates_detected, 1);\n    }\n\n    #[tokio::test]\n    async fn test_different_error_types_not_duplicate() {\n        let storage = Arc::new(InMemorySignatureStorage::new());\n        let index = ErrorSignatureIndex::new(storage, DeduplicationConfig::default());\n\n        let sig1 = sample_signature(\"TypeError\", \"Cannot read property\");\n        index.insert_or_deduplicate(\"sig1\", &sig1).await.unwrap();\n\n        let sig2 = sample_signature(\"ReferenceError\", \"Cannot read property\");\n        let result = index.insert_or_deduplicate(\"sig2\", &sig2).await.unwrap();\n\n        assert!(!result.is_duplicate());\n    }\n\n    #[tokio::test]\n    async fn test_embedding_similarity_detection() {\n        let storage = Arc::new(InMemorySignatureStorage::new());\n        let cfg = DeduplicationConfig {\n            embedding_weight: 1.0,\n            message_weight: 0.0,\n            context_weight: 0.0,\n            stack_weight: 0.0,\n            similarity_threshold: 0.95,\n            ..Default::default()\n        };\n        let index = ErrorSignatureIndex::new(storage, cfg);\n\n        let emb1 = vec![1.0, 0.0, 0.0];\n        let sig1 = sample_signature_with_embedding(\"TypeError\", \"msg1\", emb1.clone());\n        index.insert_or_deduplicate(\"sig1\", &sig1).await.unwrap();\n\n        let sig2 = sample_signature_with_embedding(\"TypeError\", \"different message\", emb1);\n        let result = index.insert_or_deduplicate(\"sig2\", &sig2).await.unwrap();\n\n        assert!(result.is_duplicate());\n    }\n\n    #[tokio::test]\n    async fn test_background_scan_finds_duplicates() {\n        let storage = Arc::new(InMemorySignatureStorage::new());\n        let cfg = DeduplicationConfig {\n            similarity_threshold: 0.9,\n            ..Default::default()\n        };\n        let index = ErrorSignatureIndex::new(storage.clone(), cfg);\n\n        let sig1 = IndexedSignature {\n            id: \"s1\".to_string(),\n            error_type: \"TypeError\".to_string(),\n            normalized_message: \"cannot read property foo\".to_string(),\n            context_hash: 0,\n            embedding: None,\n            created_at: 100,\n            merge_count: 0,\n        };\n        let sig2 = IndexedSignature {\n            id: \"s2\".to_string(),\n            error_type: \"TypeError\".to_string(),\n            normalized_message: \"cannot read property foo\".to_string(),\n            context_hash: 0,\n            embedding: None,\n            created_at: 200,\n            merge_count: 0,\n        };\n\n        storage.save_signature(&sig1).await.unwrap();\n        storage.save_signature(&sig2).await.unwrap();\n\n        let scan_result = index.run_background_scan().await.unwrap();\n\n        assert!(scan_result.duplicates_found > 0);\n    }\n\n    #[test]\n    fn test_resolution_merger() {\n        let mut primary = Resolution {\n            id: \"r1\".to_string(),\n            error_signature_id: \"e1\".to_string(),\n            description: \"Primary fix\".to_string(),\n            changes: vec![],\n            success_rate: 0.8,\n            application_count: 10,\n            last_success_at: 100,\n        };\n\n        let secondary = Resolution {\n            id: \"r2\".to_string(),\n            error_signature_id: \"e1\".to_string(),\n            description: \"Secondary fix\".to_string(),\n            changes: vec![],\n            success_rate: 0.9,\n            application_count: 5,\n            last_success_at: 200,\n        };\n\n        ResolutionMerger::merge_resolutions(&mut primary, &secondary);\n\n        assert_eq!(primary.application_count, 15);\n        assert_eq!(primary.last_success_at, 200);\n        let expected_rate = (0.8 * 10.0 + 0.9 * 5.0) / 15.0;\n        assert!((primary.success_rate - expected_rate as f32).abs() < 0.01);\n    }\n\n    #[test]\n    fn test_hindsight_note_merger() {\n        let mut primary = HindsightNote {\n            id: \"n1\".to_string(),\n            error_signature: sample_signature(\"Err\", \"msg\"),\n            resolutions: vec![],\n            content: \"Primary note\".to_string(),\n            tags: vec![\"tag1\".to_string()],\n            created_at: 100,\n            updated_at: 100,\n        };\n\n        let secondary = HindsightNote {\n            id: \"n2\".to_string(),\n            error_signature: sample_signature(\"Err\", \"msg\"),\n            resolutions: vec![],\n            content: \"Secondary note\".to_string(),\n            tags: vec![\"tag1\".to_string(), \"tag2\".to_string()],\n            created_at: 50,\n            updated_at: 200,\n        };\n\n        ResolutionMerger::merge_hindsight_notes(&mut primary, &secondary);\n\n        assert_eq!(primary.tags.len(), 2);\n        assert!(primary.tags.contains(&\"tag2\".to_string()));\n        assert_eq!(primary.updated_at, 200);\n    }\n\n    #[test]\n    fn test_context_hash_consistency() {\n        let patterns1 = vec![\"tool:test\".to_string(), \"file:main.rs\".to_string()];\n        let patterns2 = vec![\"file:main.rs\".to_string(), \"tool:test\".to_string()];\n\n        let hash1 = compute_context_hash(&patterns1);\n        let hash2 = compute_context_hash(&patterns2);\n\n        assert_eq!(hash1, hash2);\n    }\n\n    #[test]\n    fn test_jaccard_similarity() {\n        let a = vec![\"foo\".to_string(), \"bar\".to_string()];\n        let b = vec![\"foo\".to_string(), \"bar\".to_string()];\n        assert!((jaccard_similarity(&a, &b) - 1.0).abs() < 0.001);\n\n        let c = vec![\"foo\".to_string(), \"baz\".to_string()];\n        let sim = jaccard_similarity(&a, &c);\n        assert!(sim > 0.0 && sim < 1.0);\n    }\n\n    #[test]\n    fn test_cosine_similarity() {\n        let a = vec![1.0, 0.0, 0.0];\n        let b = vec![1.0, 0.0, 0.0];\n        assert!((cosine_similarity(&a, &b) - 1.0).abs() < 0.001);\n\n        let c = vec![0.0, 1.0, 0.0];\n        assert!(cosine_similarity(&a, &c).abs() < 0.001);\n    }\n\n    #[test]\n    fn test_deduplication_result() {\n        let unique = DeduplicationResult::Unique {\n            id: \"sig1\".to_string(),\n        };\n        assert!(!unique.is_duplicate());\n        assert_eq!(unique.effective_id(), \"sig1\");\n\n        let duplicate = DeduplicationResult::Duplicate {\n            existing_id: \"sig1\".to_string(),\n            new_id: \"sig2\".to_string(),\n        };\n        assert!(duplicate.is_duplicate());\n        assert_eq!(duplicate.effective_id(), \"sig1\");\n    }\n}\n","traces":[{"line":23,"address":[],"length":0,"stats":{"Line":5}},{"line":48,"address":[],"length":0,"stats":{"Line":7}},{"line":49,"address":[],"length":0,"stats":{"Line":21}},{"line":51,"address":[],"length":0,"stats":{"Line":21}},{"line":52,"address":[],"length":0,"stats":{"Line":21}},{"line":53,"address":[],"length":0,"stats":{"Line":21}},{"line":55,"address":[],"length":0,"stats":{"Line":14}},{"line":56,"address":[],"length":0,"stats":{"Line":7}},{"line":73,"address":[],"length":0,"stats":{"Line":5}},{"line":118,"address":[],"length":0,"stats":{"Line":5}},{"line":120,"address":[],"length":0,"stats":{"Line":5}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":7}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":6}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":1}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":5}},{"line":215,"address":[],"length":0,"stats":{"Line":10}},{"line":219,"address":[],"length":0,"stats":{"Line":2}},{"line":220,"address":[],"length":0,"stats":{"Line":10}},{"line":224,"address":[],"length":0,"stats":{"Line":7}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":231,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":240,"address":[],"length":0,"stats":{"Line":0}},{"line":241,"address":[],"length":0,"stats":{"Line":0}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":7}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":264,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":0}},{"line":272,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":276,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":3}},{"line":283,"address":[],"length":0,"stats":{"Line":6}},{"line":284,"address":[],"length":0,"stats":{"Line":6}},{"line":286,"address":[],"length":0,"stats":{"Line":9}},{"line":287,"address":[],"length":0,"stats":{"Line":5}},{"line":288,"address":[],"length":0,"stats":{"Line":1}},{"line":289,"address":[],"length":0,"stats":{"Line":1}},{"line":293,"address":[],"length":0,"stats":{"Line":3}},{"line":294,"address":[],"length":0,"stats":{"Line":3}},{"line":296,"address":[],"length":0,"stats":{"Line":3}},{"line":297,"address":[],"length":0,"stats":{"Line":3}},{"line":299,"address":[],"length":0,"stats":{"Line":6}},{"line":300,"address":[],"length":0,"stats":{"Line":3}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":3}},{"line":305,"address":[],"length":0,"stats":{"Line":3}},{"line":307,"address":[],"length":0,"stats":{"Line":3}},{"line":308,"address":[],"length":0,"stats":{"Line":3}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":2}},{"line":316,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":0}},{"line":321,"address":[],"length":0,"stats":{"Line":0}},{"line":323,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":325,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":333,"address":[],"length":0,"stats":{"Line":0}},{"line":335,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":337,"address":[],"length":0,"stats":{"Line":0}},{"line":338,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":343,"address":[],"length":0,"stats":{"Line":0}},{"line":345,"address":[],"length":0,"stats":{"Line":0}},{"line":346,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":350,"address":[],"length":0,"stats":{"Line":0}},{"line":355,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":358,"address":[],"length":0,"stats":{"Line":0}},{"line":359,"address":[],"length":0,"stats":{"Line":0}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":367,"address":[],"length":0,"stats":{"Line":0}},{"line":369,"address":[],"length":0,"stats":{"Line":0}},{"line":370,"address":[],"length":0,"stats":{"Line":0}},{"line":371,"address":[],"length":0,"stats":{"Line":0}},{"line":372,"address":[],"length":0,"stats":{"Line":0}},{"line":373,"address":[],"length":0,"stats":{"Line":0}},{"line":376,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":378,"address":[],"length":0,"stats":{"Line":0}},{"line":379,"address":[],"length":0,"stats":{"Line":0}},{"line":380,"address":[],"length":0,"stats":{"Line":0}},{"line":383,"address":[],"length":0,"stats":{"Line":0}},{"line":384,"address":[],"length":0,"stats":{"Line":0}},{"line":385,"address":[],"length":0,"stats":{"Line":0}},{"line":386,"address":[],"length":0,"stats":{"Line":0}},{"line":398,"address":[],"length":0,"stats":{"Line":6}},{"line":399,"address":[],"length":0,"stats":{"Line":9}},{"line":402,"address":[],"length":0,"stats":{"Line":4}},{"line":403,"address":[],"length":0,"stats":{"Line":4}},{"line":404,"address":[],"length":0,"stats":{"Line":4}},{"line":405,"address":[],"length":0,"stats":{"Line":4}},{"line":420,"address":[],"length":0,"stats":{"Line":1}},{"line":421,"address":[],"length":0,"stats":{"Line":1}},{"line":422,"address":[],"length":0,"stats":{"Line":1}},{"line":424,"address":[],"length":0,"stats":{"Line":2}},{"line":425,"address":[],"length":0,"stats":{"Line":3}},{"line":426,"address":[],"length":0,"stats":{"Line":2}},{"line":427,"address":[],"length":0,"stats":{"Line":2}},{"line":428,"address":[],"length":0,"stats":{"Line":1}},{"line":429,"address":[],"length":0,"stats":{"Line":1}},{"line":432,"address":[],"length":0,"stats":{"Line":1}},{"line":434,"address":[],"length":0,"stats":{"Line":2}},{"line":435,"address":[],"length":0,"stats":{"Line":1}},{"line":438,"address":[],"length":0,"stats":{"Line":1}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":441,"address":[],"length":0,"stats":{"Line":0}},{"line":442,"address":[],"length":0,"stats":{"Line":0}},{"line":444,"address":[],"length":0,"stats":{"Line":0}},{"line":449,"address":[],"length":0,"stats":{"Line":1}},{"line":450,"address":[],"length":0,"stats":{"Line":1}},{"line":451,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":456,"address":[],"length":0,"stats":{"Line":5}},{"line":457,"address":[],"length":0,"stats":{"Line":5}},{"line":458,"address":[],"length":0,"stats":{"Line":3}},{"line":462,"address":[],"length":0,"stats":{"Line":2}},{"line":463,"address":[],"length":0,"stats":{"Line":1}},{"line":468,"address":[],"length":0,"stats":{"Line":8}},{"line":469,"address":[],"length":0,"stats":{"Line":8}},{"line":470,"address":[],"length":0,"stats":{"Line":8}},{"line":471,"address":[],"length":0,"stats":{"Line":24}},{"line":475,"address":[],"length":0,"stats":{"Line":9}},{"line":479,"address":[],"length":0,"stats":{"Line":45}},{"line":480,"address":[],"length":0,"stats":{"Line":9}},{"line":482,"address":[],"length":0,"stats":{"Line":18}},{"line":483,"address":[],"length":0,"stats":{"Line":21}},{"line":484,"address":[],"length":0,"stats":{"Line":8}},{"line":486,"address":[],"length":0,"stats":{"Line":18}},{"line":489,"address":[],"length":0,"stats":{"Line":6}},{"line":490,"address":[],"length":0,"stats":{"Line":230}},{"line":491,"address":[],"length":0,"stats":{"Line":40}},{"line":492,"address":[],"length":0,"stats":{"Line":40}},{"line":496,"address":[],"length":0,"stats":{"Line":5}},{"line":497,"address":[],"length":0,"stats":{"Line":20}},{"line":498,"address":[],"length":0,"stats":{"Line":0}},{"line":502,"address":[],"length":0,"stats":{"Line":25}},{"line":503,"address":[],"length":0,"stats":{"Line":25}},{"line":505,"address":[],"length":0,"stats":{"Line":20}},{"line":506,"address":[],"length":0,"stats":{"Line":20}},{"line":508,"address":[],"length":0,"stats":{"Line":5}},{"line":509,"address":[],"length":0,"stats":{"Line":0}},{"line":511,"address":[],"length":0,"stats":{"Line":5}},{"line":515,"address":[],"length":0,"stats":{"Line":3}},{"line":516,"address":[],"length":0,"stats":{"Line":15}},{"line":517,"address":[],"length":0,"stats":{"Line":0}},{"line":520,"address":[],"length":0,"stats":{"Line":45}},{"line":521,"address":[],"length":0,"stats":{"Line":39}},{"line":522,"address":[],"length":0,"stats":{"Line":39}},{"line":524,"address":[],"length":0,"stats":{"Line":6}},{"line":525,"address":[],"length":0,"stats":{"Line":0}},{"line":527,"address":[],"length":0,"stats":{"Line":6}}],"covered":94,"coverable":189},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","hindsight","mod.rs"],"content":"mod capture;\nmod dedup;\nmod note_gen;\nmod promotion;\nmod query;\nmod resolution;\nmod retrieval;\n\npub use capture::{CapturedError, ErrorCapture, ErrorCaptureConfig, ErrorContext, ErrorNormalizer};\npub use dedup::{\n    DeduplicationConfig, DeduplicationError, DeduplicationMetrics, DeduplicationResult,\n    ErrorSignatureIndex, InMemorySignatureStorage, IndexedSignature, ResolutionMerger, ScanResult,\n    SignatureStorage,\n};\npub use note_gen::{\n    HindsightNoteGenerationMode, HindsightNoteGenerator, HindsightNoteGeneratorConfig,\n    HindsightNoteRequest, HindsightNoteResult, HindsightPromptTemplate, HindsightPromptTemplates,\n    NoteGenerationError,\n};\npub use promotion::{\n    HindsightPromoter, HindsightPromotionConfig, HindsightPromotionError, HindsightPromotionRequest,\n};\npub use query::{HindsightMatch, HindsightQuery, HindsightQueryConfig};\npub use resolution::{\n    ApplicationContext, ApplicationRecord, FailureContext, InMemoryResolutionStorage,\n    ResolutionMetrics, ResolutionOutcome, ResolutionStorage, ResolutionStorageError,\n    ResolutionTracker, ResolutionTrackerConfig,\n};\npub use retrieval::{\n    HindsightRetrievalConfig, HindsightRetrievalFilter, HindsightRetriever, ScoredHindsightNote,\n};\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","hindsight","note_gen.rs"],"content":"use std::sync::Arc;\nuse std::time::{Duration, SystemTime, UNIX_EPOCH};\n\nuse mk_core::types::{ErrorSignature, HindsightNote, Resolution};\nuse storage::postgres::{PostgresBackend, PostgresError};\nuse tracing::{Instrument, info_span};\n\nuse crate::context_architect::{LlmClient, LlmError, ViewMode};\n\n#[derive(Debug, Clone)]\npub enum HindsightNoteGenerationMode {\n    Single,\n    DraftAndRefine,\n}\n\n#[derive(Debug, Clone)]\npub struct HindsightNoteGeneratorConfig {\n    pub max_retries: u32,\n    pub retry_delay_ms: u64,\n    pub max_tokens: u32,\n    pub mode: HindsightNoteGenerationMode,\n}\n\nimpl Default for HindsightNoteGeneratorConfig {\n    fn default() -> Self {\n        Self {\n            max_retries: 2,\n            retry_delay_ms: 500,\n            max_tokens: 600,\n            mode: HindsightNoteGenerationMode::Single,\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct HindsightNoteRequest {\n    pub error_signature: ErrorSignature,\n    pub resolutions: Vec<Resolution>,\n    pub context: Option<String>,\n    pub tags: Vec<String>,\n    pub view_mode: ViewMode,\n}\n\nimpl HindsightNoteRequest {\n    pub fn new(\n        error_signature: ErrorSignature,\n        resolutions: Vec<Resolution>,\n        context: Option<String>,\n        tags: Vec<String>,\n        view_mode: ViewMode,\n    ) -> Self {\n        Self {\n            error_signature,\n            resolutions,\n            context,\n            tags,\n            view_mode,\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct HindsightNoteResult {\n    pub note: HindsightNote,\n    pub tokens_used: u32,\n}\n\n#[derive(Debug, thiserror::Error)]\npub enum NoteGenerationError {\n    #[error(\"LLM error: {0}\")]\n    Llm(#[from] LlmError),\n\n    #[error(\"Storage error: {0}\")]\n    Storage(#[from] PostgresError),\n\n    #[error(\"Storage not configured\")]\n    StorageNotConfigured,\n\n    #[error(\"Empty error message pattern\")]\n    EmptyMessagePattern,\n\n    #[error(\"Empty LLM response\")]\n    EmptyResponse,\n}\n\n#[derive(Debug, Clone)]\npub struct HindsightPromptTemplate {\n    pub system: String,\n    pub user: String,\n}\n\n#[derive(Debug, Clone)]\npub struct HindsightPromptTemplates {\n    pub default: HindsightPromptTemplate,\n    pub draft: HindsightPromptTemplate,\n    pub refine: HindsightPromptTemplate,\n}\n\nimpl Default for HindsightPromptTemplates {\n    fn default() -> Self {\n        Self {\n            default: HindsightPromptTemplate {\n                system: DEFAULT_SYSTEM.to_string(),\n                user: DEFAULT_USER.to_string(),\n            },\n            draft: HindsightPromptTemplate {\n                system: DRAFT_SYSTEM.to_string(),\n                user: DRAFT_USER.to_string(),\n            },\n            refine: HindsightPromptTemplate {\n                system: REFINE_SYSTEM.to_string(),\n                user: REFINE_USER.to_string(),\n            },\n        }\n    }\n}\n\nimpl HindsightPromptTemplates {\n    pub fn build_prompt(\n        &self,\n        signature: &ErrorSignature,\n        resolutions: &[Resolution],\n        context: Option<&str>,\n        max_tokens: u32,\n        view_mode: ViewMode,\n    ) -> (String, String) {\n        self.build_template(\n            &self.default,\n            signature,\n            resolutions,\n            context,\n            max_tokens,\n            None,\n            view_mode,\n        )\n    }\n\n    pub fn build_draft_prompt(\n        &self,\n        signature: &ErrorSignature,\n        resolutions: &[Resolution],\n        context: Option<&str>,\n        max_tokens: u32,\n        view_mode: ViewMode,\n    ) -> (String, String) {\n        self.build_template(\n            &self.draft,\n            signature,\n            resolutions,\n            context,\n            max_tokens,\n            None,\n            view_mode,\n        )\n    }\n\n    pub fn build_refine_prompt(\n        &self,\n        signature: &ErrorSignature,\n        resolutions: &[Resolution],\n        context: Option<&str>,\n        draft: &str,\n        max_tokens: u32,\n        view_mode: ViewMode,\n    ) -> (String, String) {\n        self.build_template(\n            &self.refine,\n            signature,\n            resolutions,\n            context,\n            max_tokens,\n            Some(draft),\n            view_mode,\n        )\n    }\n\n    fn build_template(\n        &self,\n        template: &HindsightPromptTemplate,\n        signature: &ErrorSignature,\n        resolutions: &[Resolution],\n        context: Option<&str>,\n        max_tokens: u32,\n        draft: Option<&str>,\n        view_mode: ViewMode,\n    ) -> (String, String) {\n        let context_text = context.unwrap_or(\"None\");\n        let stack_patterns = format_list(&signature.stack_patterns);\n        let context_patterns = format_list(&signature.context_patterns);\n        let resolution_list = format_resolutions(resolutions);\n        let draft_text = draft.unwrap_or(\"None\");\n        let view_mode_text = view_mode_label(view_mode);\n\n        let user = template\n            .user\n            .replace(\"{error_type}\", &signature.error_type)\n            .replace(\"{message_pattern}\", &signature.message_pattern)\n            .replace(\"{stack_patterns}\", &stack_patterns)\n            .replace(\"{context_patterns}\", &context_patterns)\n            .replace(\"{resolutions}\", &resolution_list)\n            .replace(\"{context}\", context_text)\n            .replace(\"{draft}\", draft_text)\n            .replace(\"{view_mode}\", view_mode_text)\n            .replace(\"{max_tokens}\", &max_tokens.to_string());\n\n        (template.system.clone(), user)\n    }\n}\n\npub struct HindsightNoteGenerator<C: LlmClient> {\n    client: Arc<C>,\n    config: HindsightNoteGeneratorConfig,\n    prompts: HindsightPromptTemplates,\n    storage: Option<Arc<PostgresBackend>>,\n}\n\nimpl<C: LlmClient> HindsightNoteGenerator<C> {\n    pub fn new(client: Arc<C>, config: HindsightNoteGeneratorConfig) -> Self {\n        Self {\n            client,\n            config,\n            prompts: HindsightPromptTemplates::default(),\n            storage: None,\n        }\n    }\n\n    pub fn with_prompts(mut self, prompts: HindsightPromptTemplates) -> Self {\n        self.prompts = prompts;\n        self\n    }\n\n    pub fn with_storage(mut self, storage: Arc<PostgresBackend>) -> Self {\n        self.storage = Some(storage);\n        self\n    }\n\n    pub async fn generate_note(\n        &self,\n        request: &HindsightNoteRequest,\n    ) -> Result<HindsightNoteResult, NoteGenerationError> {\n        let span = info_span!(\n            \"generate_hindsight_note\",\n            error_type = %request.error_signature.error_type,\n            mode = ?self.config.mode,\n            has_context = request.context.is_some(),\n            resolutions_count = request.resolutions.len(),\n            tags_count = request.tags.len()\n        );\n\n        async move {\n            if request.error_signature.message_pattern.trim().is_empty() {\n                return Err(NoteGenerationError::EmptyMessagePattern);\n            }\n\n            let content = match self.config.mode {\n                HindsightNoteGenerationMode::Single => {\n                    let (system, user) = self.prompts.build_prompt(\n                        &request.error_signature,\n                        &request.resolutions,\n                        request.context.as_deref(),\n                        self.config.max_tokens,\n                        request.view_mode,\n                    );\n                    self.call_llm_with_retry(&system, &user).await?\n                }\n                HindsightNoteGenerationMode::DraftAndRefine => {\n                    let (system, user) = self.prompts.build_draft_prompt(\n                        &request.error_signature,\n                        &request.resolutions,\n                        request.context.as_deref(),\n                        self.config.max_tokens,\n                        request.view_mode,\n                    );\n                    let draft = self.call_llm_with_retry(&system, &user).await?;\n                    let draft = draft.trim();\n                    if draft.is_empty() {\n                        return Err(NoteGenerationError::EmptyResponse);\n                    }\n                    let (system, user) = self.prompts.build_refine_prompt(\n                        &request.error_signature,\n                        &request.resolutions,\n                        request.context.as_deref(),\n                        draft,\n                        self.config.max_tokens,\n                        request.view_mode,\n                    );\n                    self.call_llm_with_retry(&system, &user).await?\n                }\n            };\n\n            let response = content.trim().to_string();\n            if response.is_empty() {\n                return Err(NoteGenerationError::EmptyResponse);\n            }\n\n            let now = SystemTime::now()\n                .duration_since(UNIX_EPOCH)\n                .map(|d| d.as_secs() as i64)\n                .unwrap_or(0);\n\n            let mut tags = request.tags.clone();\n            tags.extend(derive_tags(&request.error_signature, &request.context));\n            tags.sort();\n            tags.dedup();\n\n            let note = HindsightNote {\n                id: uuid::Uuid::new_v4().to_string(),\n                error_signature: request.error_signature.clone(),\n                resolutions: request.resolutions.clone(),\n                content: response.clone(),\n                tags,\n                created_at: now,\n                updated_at: now,\n            };\n\n            Ok(HindsightNoteResult {\n                note,\n                tokens_used: estimate_tokens(&response),\n            })\n        }\n        .instrument(span)\n        .await\n    }\n\n    pub async fn generate_and_store(\n        &self,\n        tenant_id: &str,\n        request: &HindsightNoteRequest,\n    ) -> Result<HindsightNoteResult, NoteGenerationError> {\n        let span = info_span!(\n            \"generate_and_store_hindsight_note\",\n            tenant_id,\n            error_type = %request.error_signature.error_type,\n            has_storage = self.storage.is_some()\n        );\n\n        async move {\n            let storage = self\n                .storage\n                .as_ref()\n                .ok_or(NoteGenerationError::StorageNotConfigured)?;\n\n            let result = self.generate_note(request).await?;\n            storage\n                .create_hindsight_note(tenant_id, &result.note)\n                .await?;\n            Ok(result)\n        }\n        .instrument(span)\n        .await\n    }\n\n    async fn call_llm_with_retry(\n        &self,\n        system: &str,\n        user: &str,\n    ) -> Result<String, NoteGenerationError> {\n        let mut attempt = 0;\n        loop {\n            match self.client.complete_with_system(system, user).await {\n                Ok(result) => return Ok(result),\n                Err(err) => {\n                    if attempt >= self.config.max_retries {\n                        return Err(NoteGenerationError::Llm(err));\n                    }\n                    attempt += 1;\n                    tokio::time::sleep(Duration::from_millis(self.config.retry_delay_ms)).await;\n                }\n            }\n        }\n    }\n}\n\nfn format_list(items: &[String]) -> String {\n    if items.is_empty() {\n        \"None\".to_string()\n    } else {\n        let mut out = String::new();\n        for item in items {\n            out.push_str(\"- \");\n            out.push_str(item);\n            out.push('\\n');\n        }\n        out.trim_end().to_string()\n    }\n}\n\nfn format_resolutions(resolutions: &[Resolution]) -> String {\n    if resolutions.is_empty() {\n        return \"None\".to_string();\n    }\n\n    let mut out = String::new();\n    for resolution in resolutions {\n        let line = format!(\n            \"- {} (success_rate: {:.2}, applications: {})\",\n            resolution.description, resolution.success_rate, resolution.application_count\n        );\n        out.push_str(&line);\n        out.push('\\n');\n    }\n    out.trim_end().to_string()\n}\n\npub fn estimate_tokens(text: &str) -> u32 {\n    let word_count = text.split_whitespace().count();\n    let char_count = text.chars().count();\n\n    let char_based = (char_count as f64 / 4.0).ceil() as u32;\n    let word_based = (word_count as f64 * 1.3).ceil() as u32;\n\n    char_based.max(word_based)\n}\n\nfn derive_tags(signature: &ErrorSignature, context: &Option<String>) -> Vec<String> {\n    let mut tags = vec![signature.error_type.to_lowercase()];\n\n    for pattern in &signature.context_patterns {\n        if let Some((key, value)) = pattern.split_once(':') {\n            if key == \"tool\" || key == \"op\" || key == \"file\" {\n                tags.push(value.to_lowercase());\n            }\n        }\n    }\n\n    if let Some(ctx) = context {\n        if ctx.to_lowercase().contains(\"test\") {\n            tags.push(\"tests\".to_string());\n        }\n    }\n\n    tags\n}\n\nconst DEFAULT_SYSTEM: &str = \"You are a hindsight learning assistant. Produce a concise markdown \\\n                              note that captures the error pattern, root cause, resolution, and \\\n                              prevention guidance. Be factual and avoid speculation.\";\n\nconst DEFAULT_USER: &str = \"Error type: {error_type}\\nMessage pattern: {message_pattern}\\n\\nStack \\\n     patterns:\\n{stack_patterns}\\n\\nContext patterns:\\n{context_patterns}\\n\\nKnown \\\n     resolutions:\\n{resolutions}\\n\\nAdditional context:\\n{context}\\n\\nView mode: \\\n     {view_mode}\\n\\nWrite a markdown note with these sections:\\n- Summary\\n- Root Cause\\n- \\\n     Resolution\\n- Prevention\\n\\nKeep it under {max_tokens} tokens.\";\n\nconst DRAFT_SYSTEM: &str = \"You are a hindsight learning assistant. Draft a concise markdown note \\\n                            that captures the error pattern, root cause, resolution, and \\\n                            prevention guidance. Be factual and avoid speculation.\";\n\nconst DRAFT_USER: &str = \"Error type: {error_type}\\nMessage pattern: {message_pattern}\\n\\nStack \\\n     patterns:\\n{stack_patterns}\\n\\nContext patterns:\\n{context_patterns}\\n\\nKnown \\\n     resolutions:\\n{resolutions}\\n\\nAdditional context:\\n{context}\\n\\nView mode: \\\n     {view_mode}\\n\\nDraft a markdown note with these sections:\\n- Summary\\n- Root Cause\\n- \\\n     Resolution\\n- Prevention\\n\\nKeep it under {max_tokens} tokens.\";\n\nconst REFINE_SYSTEM: &str = \"You are a hindsight learning assistant. Refine the draft into a \\\n                             clear, well-structured markdown note without adding speculative \\\n                             details.\";\n\nconst REFINE_USER: &str = \"Error type: {error_type}\\nMessage pattern: {message_pattern}\\n\\nStack \\\n                           patterns:\\n{stack_patterns}\\n\\nContext \\\n                           patterns:\\n{context_patterns}\\n\\nKnown \\\n                           resolutions:\\n{resolutions}\\n\\nAdditional context:\\n{context}\\n\\nView \\\n                           mode: {view_mode}\\n\\nDraft:\\n{draft}\\n\\nRefine the draft into a \\\n                           markdown note with these sections:\\n- Summary\\n- Root Cause\\n- \\\n                           Resolution\\n- Prevention\\n\\nKeep it under {max_tokens} tokens.\";\n\nfn view_mode_label(view_mode: ViewMode) -> &'static str {\n    match view_mode {\n        ViewMode::Ax => \"AX\",\n        ViewMode::Ux => \"UX\",\n        ViewMode::Dx => \"DX\",\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::sync::Mutex;\n\n    struct MockLlmClient {\n        responses: Mutex<Vec<String>>,\n    }\n\n    impl MockLlmClient {\n        fn new(responses: Vec<String>) -> Self {\n            Self {\n                responses: Mutex::new(responses),\n            }\n        }\n    }\n\n    #[async_trait::async_trait]\n    impl LlmClient for MockLlmClient {\n        async fn complete(&self, _prompt: &str) -> Result<String, LlmError> {\n            let mut responses = self.responses.lock().unwrap();\n            responses\n                .pop()\n                .ok_or_else(|| LlmError::InvalidResponse(\"No mock response\".into()))\n        }\n\n        async fn complete_with_system(\n            &self,\n            _system: &str,\n            _user: &str,\n        ) -> Result<String, LlmError> {\n            let mut responses = self.responses.lock().unwrap();\n            responses\n                .pop()\n                .ok_or_else(|| LlmError::InvalidResponse(\"No mock response\".into()))\n        }\n    }\n\n    struct RecordingLlmClient {\n        responses: Mutex<Vec<String>>,\n        calls: Mutex<Vec<(String, String)>>,\n    }\n\n    impl RecordingLlmClient {\n        fn new(responses: Vec<String>) -> Self {\n            Self {\n                responses: Mutex::new(responses),\n                calls: Mutex::new(Vec::new()),\n            }\n        }\n\n        fn calls(&self) -> Vec<(String, String)> {\n            self.calls.lock().unwrap().clone()\n        }\n    }\n\n    #[async_trait::async_trait]\n    impl LlmClient for RecordingLlmClient {\n        async fn complete(&self, _prompt: &str) -> Result<String, LlmError> {\n            Err(LlmError::InvalidResponse(\"Unsupported\".into()))\n        }\n\n        async fn complete_with_system(&self, system: &str, user: &str) -> Result<String, LlmError> {\n            self.calls\n                .lock()\n                .unwrap()\n                .push((system.to_string(), user.to_string()));\n            let mut responses = self.responses.lock().unwrap();\n            responses\n                .pop()\n                .ok_or_else(|| LlmError::InvalidResponse(\"No mock response\".into()))\n        }\n    }\n\n    fn sample_signature() -> ErrorSignature {\n        ErrorSignature {\n            error_type: \"TypeError\".to_string(),\n            message_pattern: \"cannot read property\".to_string(),\n            stack_patterns: vec![\"at foo (src/lib.rs:10)\".to_string()],\n            context_patterns: vec![\"tool:cargo_test\".to_string()],\n            embedding: None,\n        }\n    }\n\n    fn sample_resolution() -> Resolution {\n        Resolution {\n            id: \"r1\".to_string(),\n            error_signature_id: \"e1\".to_string(),\n            description: \"Add null guard\".to_string(),\n            changes: vec![],\n            success_rate: 0.9,\n            application_count: 3,\n            last_success_at: 0,\n        }\n    }\n\n    #[tokio::test]\n    async fn test_generate_note_success() {\n        let mock = Arc::new(MockLlmClient::new(vec![\n            \"## Summary\\nSomething broke.\".to_string(),\n        ]));\n        let generator = HindsightNoteGenerator::new(mock, HindsightNoteGeneratorConfig::default());\n\n        let request = HindsightNoteRequest::new(\n            sample_signature(),\n            vec![sample_resolution()],\n            Some(\"running tests\".to_string()),\n            vec![\"rust\".to_string()],\n            ViewMode::Dx,\n        );\n\n        let result = generator.generate_note(&request).await.unwrap();\n\n        assert!(!result.note.id.is_empty());\n        assert!(result.note.content.contains(\"Summary\"));\n        assert!(result.note.tags.contains(&\"rust\".to_string()));\n        assert!(result.note.tags.contains(&\"typeerror\".to_string()));\n        assert!(result.note.tags.contains(&\"tests\".to_string()));\n        assert!(result.tokens_used > 0);\n    }\n\n    #[tokio::test]\n    async fn test_generate_note_refine() {\n        let mock = Arc::new(RecordingLlmClient::new(vec![\n            \"## Summary\\nFinal note.\".to_string(),\n            \"## Summary\\nDraft note.\".to_string(),\n        ]));\n        let config = HindsightNoteGeneratorConfig {\n            mode: HindsightNoteGenerationMode::DraftAndRefine,\n            ..Default::default()\n        };\n        let generator = HindsightNoteGenerator::new(mock.clone(), config);\n\n        let request = HindsightNoteRequest::new(\n            sample_signature(),\n            vec![sample_resolution()],\n            Some(\"running tests\".to_string()),\n            vec![\"rust\".to_string()],\n            ViewMode::Dx,\n        );\n\n        let result = generator.generate_note(&request).await.unwrap();\n\n        assert!(result.note.content.contains(\"Final\"));\n        let calls = mock.calls();\n        assert_eq!(calls.len(), 2);\n        assert!(calls[1].1.contains(\"Draft:\\n## Summary\\nDraft note.\"));\n    }\n\n    #[tokio::test]\n    async fn test_empty_message_pattern_error() {\n        let mock = Arc::new(MockLlmClient::new(vec![\"x\".to_string()]));\n        let generator = HindsightNoteGenerator::new(mock, HindsightNoteGeneratorConfig::default());\n\n        let request = HindsightNoteRequest::new(\n            ErrorSignature {\n                error_type: \"TypeError\".to_string(),\n                message_pattern: \"\".to_string(),\n                stack_patterns: vec![],\n                context_patterns: vec![],\n                embedding: None,\n            },\n            vec![],\n            None,\n            vec![],\n            ViewMode::Dx,\n        );\n\n        let result = generator.generate_note(&request).await;\n        assert!(matches!(\n            result,\n            Err(NoteGenerationError::EmptyMessagePattern)\n        ));\n    }\n\n    #[tokio::test]\n    async fn test_empty_response_error() {\n        let mock = Arc::new(MockLlmClient::new(vec![\"   \".to_string()]));\n        let generator = HindsightNoteGenerator::new(mock, HindsightNoteGeneratorConfig::default());\n\n        let request =\n            HindsightNoteRequest::new(sample_signature(), vec![], None, vec![], ViewMode::Dx);\n\n        let result = generator.generate_note(&request).await;\n        assert!(matches!(result, Err(NoteGenerationError::EmptyResponse)));\n    }\n\n    #[test]\n    fn test_build_prompt_includes_context() {\n        let templates = HindsightPromptTemplates::default();\n        let signature = sample_signature();\n        let (system, user) = templates.build_prompt(\n            &signature,\n            &[sample_resolution()],\n            Some(\"extra context\"),\n            400,\n            ViewMode::Dx,\n        );\n\n        assert!(system.contains(\"hindsight\"));\n        assert!(user.contains(\"extra context\"));\n        assert!(user.contains(\"400\"));\n        assert!(user.contains(\"View mode: DX\"));\n        assert_eq!(view_mode_label(ViewMode::Ux), \"UX\");\n    }\n\n    #[test]\n    fn test_format_list_empty() {\n        assert_eq!(format_list(&[]), \"None\");\n    }\n\n    #[test]\n    fn test_format_resolutions_empty() {\n        assert_eq!(format_resolutions(&[]), \"None\");\n    }\n\n    #[test]\n    fn test_derive_tags_from_context() {\n        let signature = sample_signature();\n        let tags = derive_tags(&signature, &Some(\"run tests\".to_string()));\n        assert!(tags.contains(&\"typeerror\".to_string()));\n        assert!(tags.contains(&\"cargo_test\".to_string()));\n        assert!(tags.contains(&\"tests\".to_string()));\n    }\n}\n","traces":[{"line":25,"address":[],"length":0,"stats":{"Line":5}},{"line":45,"address":[],"length":0,"stats":{"Line":5}},{"line":100,"address":[],"length":0,"stats":{"Line":6}},{"line":102,"address":[],"length":0,"stats":{"Line":12}},{"line":106,"address":[],"length":0,"stats":{"Line":12}},{"line":110,"address":[],"length":0,"stats":{"Line":6}},{"line":119,"address":[],"length":0,"stats":{"Line":4}},{"line":127,"address":[],"length":0,"stats":{"Line":8}},{"line":128,"address":[],"length":0,"stats":{"Line":4}},{"line":129,"address":[],"length":0,"stats":{"Line":4}},{"line":130,"address":[],"length":0,"stats":{"Line":4}},{"line":131,"address":[],"length":0,"stats":{"Line":4}},{"line":132,"address":[],"length":0,"stats":{"Line":4}},{"line":133,"address":[],"length":0,"stats":{"Line":4}},{"line":134,"address":[],"length":0,"stats":{"Line":4}},{"line":138,"address":[],"length":0,"stats":{"Line":1}},{"line":146,"address":[],"length":0,"stats":{"Line":2}},{"line":147,"address":[],"length":0,"stats":{"Line":1}},{"line":148,"address":[],"length":0,"stats":{"Line":1}},{"line":149,"address":[],"length":0,"stats":{"Line":1}},{"line":150,"address":[],"length":0,"stats":{"Line":1}},{"line":151,"address":[],"length":0,"stats":{"Line":1}},{"line":152,"address":[],"length":0,"stats":{"Line":1}},{"line":153,"address":[],"length":0,"stats":{"Line":1}},{"line":157,"address":[],"length":0,"stats":{"Line":1}},{"line":166,"address":[],"length":0,"stats":{"Line":2}},{"line":167,"address":[],"length":0,"stats":{"Line":1}},{"line":168,"address":[],"length":0,"stats":{"Line":1}},{"line":169,"address":[],"length":0,"stats":{"Line":1}},{"line":170,"address":[],"length":0,"stats":{"Line":1}},{"line":171,"address":[],"length":0,"stats":{"Line":1}},{"line":172,"address":[],"length":0,"stats":{"Line":1}},{"line":173,"address":[],"length":0,"stats":{"Line":1}},{"line":177,"address":[],"length":0,"stats":{"Line":6}},{"line":187,"address":[],"length":0,"stats":{"Line":24}},{"line":188,"address":[],"length":0,"stats":{"Line":18}},{"line":189,"address":[],"length":0,"stats":{"Line":18}},{"line":190,"address":[],"length":0,"stats":{"Line":18}},{"line":191,"address":[],"length":0,"stats":{"Line":24}},{"line":192,"address":[],"length":0,"stats":{"Line":18}},{"line":194,"address":[],"length":0,"stats":{"Line":66}},{"line":195,"address":[],"length":0,"stats":{"Line":60}},{"line":196,"address":[],"length":0,"stats":{"Line":54}},{"line":197,"address":[],"length":0,"stats":{"Line":48}},{"line":198,"address":[],"length":0,"stats":{"Line":42}},{"line":199,"address":[],"length":0,"stats":{"Line":36}},{"line":200,"address":[],"length":0,"stats":{"Line":30}},{"line":201,"address":[],"length":0,"stats":{"Line":24}},{"line":202,"address":[],"length":0,"stats":{"Line":18}},{"line":203,"address":[],"length":0,"stats":{"Line":12}},{"line":204,"address":[],"length":0,"stats":{"Line":12}},{"line":206,"address":[],"length":0,"stats":{"Line":12}},{"line":218,"address":[],"length":0,"stats":{"Line":5}},{"line":222,"address":[],"length":0,"stats":{"Line":5}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":1}},{"line":233,"address":[],"length":0,"stats":{"Line":2}},{"line":234,"address":[],"length":0,"stats":{"Line":1}},{"line":237,"address":[],"length":0,"stats":{"Line":5}},{"line":241,"address":[],"length":0,"stats":{"Line":10}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":10}},{"line":246,"address":[],"length":0,"stats":{"Line":10}},{"line":247,"address":[],"length":0,"stats":{"Line":10}},{"line":250,"address":[],"length":0,"stats":{"Line":5}},{"line":251,"address":[],"length":0,"stats":{"Line":10}},{"line":252,"address":[],"length":0,"stats":{"Line":1}},{"line":255,"address":[],"length":0,"stats":{"Line":8}},{"line":256,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":15}},{"line":258,"address":[],"length":0,"stats":{"Line":6}},{"line":259,"address":[],"length":0,"stats":{"Line":6}},{"line":260,"address":[],"length":0,"stats":{"Line":9}},{"line":261,"address":[],"length":0,"stats":{"Line":3}},{"line":262,"address":[],"length":0,"stats":{"Line":3}},{"line":264,"address":[],"length":0,"stats":{"Line":12}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":5}},{"line":268,"address":[],"length":0,"stats":{"Line":2}},{"line":269,"address":[],"length":0,"stats":{"Line":2}},{"line":270,"address":[],"length":0,"stats":{"Line":3}},{"line":271,"address":[],"length":0,"stats":{"Line":1}},{"line":272,"address":[],"length":0,"stats":{"Line":1}},{"line":274,"address":[],"length":0,"stats":{"Line":5}},{"line":275,"address":[],"length":0,"stats":{"Line":2}},{"line":276,"address":[],"length":0,"stats":{"Line":2}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":5}},{"line":280,"address":[],"length":0,"stats":{"Line":2}},{"line":281,"address":[],"length":0,"stats":{"Line":2}},{"line":282,"address":[],"length":0,"stats":{"Line":3}},{"line":283,"address":[],"length":0,"stats":{"Line":2}},{"line":284,"address":[],"length":0,"stats":{"Line":1}},{"line":285,"address":[],"length":0,"stats":{"Line":1}},{"line":287,"address":[],"length":0,"stats":{"Line":4}},{"line":291,"address":[],"length":0,"stats":{"Line":12}},{"line":292,"address":[],"length":0,"stats":{"Line":8}},{"line":293,"address":[],"length":0,"stats":{"Line":1}},{"line":296,"address":[],"length":0,"stats":{"Line":6}},{"line":297,"address":[],"length":0,"stats":{"Line":3}},{"line":298,"address":[],"length":0,"stats":{"Line":9}},{"line":301,"address":[],"length":0,"stats":{"Line":9}},{"line":302,"address":[],"length":0,"stats":{"Line":15}},{"line":303,"address":[],"length":0,"stats":{"Line":3}},{"line":304,"address":[],"length":0,"stats":{"Line":6}},{"line":307,"address":[],"length":0,"stats":{"Line":9}},{"line":308,"address":[],"length":0,"stats":{"Line":9}},{"line":309,"address":[],"length":0,"stats":{"Line":9}},{"line":310,"address":[],"length":0,"stats":{"Line":9}},{"line":316,"address":[],"length":0,"stats":{"Line":3}},{"line":317,"address":[],"length":0,"stats":{"Line":6}},{"line":318,"address":[],"length":0,"stats":{"Line":3}},{"line":321,"address":[],"length":0,"stats":{"Line":10}},{"line":322,"address":[],"length":0,"stats":{"Line":5}},{"line":325,"address":[],"length":0,"stats":{"Line":1}},{"line":330,"address":[],"length":0,"stats":{"Line":2}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":333,"address":[],"length":0,"stats":{"Line":0}},{"line":334,"address":[],"length":0,"stats":{"Line":2}},{"line":337,"address":[],"length":0,"stats":{"Line":1}},{"line":338,"address":[],"length":0,"stats":{"Line":2}},{"line":339,"address":[],"length":0,"stats":{"Line":1}},{"line":341,"address":[],"length":0,"stats":{"Line":2}},{"line":343,"address":[],"length":0,"stats":{"Line":4}},{"line":344,"address":[],"length":0,"stats":{"Line":2}},{"line":345,"address":[],"length":0,"stats":{"Line":2}},{"line":346,"address":[],"length":0,"stats":{"Line":1}},{"line":347,"address":[],"length":0,"stats":{"Line":1}},{"line":349,"address":[],"length":0,"stats":{"Line":2}},{"line":350,"address":[],"length":0,"stats":{"Line":1}},{"line":353,"address":[],"length":0,"stats":{"Line":5}},{"line":358,"address":[],"length":0,"stats":{"Line":10}},{"line":359,"address":[],"length":0,"stats":{"Line":0}},{"line":360,"address":[],"length":0,"stats":{"Line":20}},{"line":361,"address":[],"length":0,"stats":{"Line":10}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":363,"address":[],"length":0,"stats":{"Line":0}},{"line":364,"address":[],"length":0,"stats":{"Line":0}},{"line":366,"address":[],"length":0,"stats":{"Line":0}},{"line":367,"address":[],"length":0,"stats":{"Line":0}},{"line":374,"address":[],"length":0,"stats":{"Line":13}},{"line":375,"address":[],"length":0,"stats":{"Line":26}},{"line":376,"address":[],"length":0,"stats":{"Line":2}},{"line":378,"address":[],"length":0,"stats":{"Line":24}},{"line":379,"address":[],"length":0,"stats":{"Line":51}},{"line":380,"address":[],"length":0,"stats":{"Line":52}},{"line":381,"address":[],"length":0,"stats":{"Line":52}},{"line":382,"address":[],"length":0,"stats":{"Line":13}},{"line":384,"address":[],"length":0,"stats":{"Line":24}},{"line":388,"address":[],"length":0,"stats":{"Line":7}},{"line":389,"address":[],"length":0,"stats":{"Line":14}},{"line":390,"address":[],"length":0,"stats":{"Line":4}},{"line":393,"address":[],"length":0,"stats":{"Line":10}},{"line":394,"address":[],"length":0,"stats":{"Line":20}},{"line":395,"address":[],"length":0,"stats":{"Line":15}},{"line":397,"address":[],"length":0,"stats":{"Line":5}},{"line":399,"address":[],"length":0,"stats":{"Line":20}},{"line":400,"address":[],"length":0,"stats":{"Line":5}},{"line":402,"address":[],"length":0,"stats":{"Line":10}},{"line":405,"address":[],"length":0,"stats":{"Line":3}},{"line":406,"address":[],"length":0,"stats":{"Line":12}},{"line":407,"address":[],"length":0,"stats":{"Line":12}},{"line":409,"address":[],"length":0,"stats":{"Line":6}},{"line":410,"address":[],"length":0,"stats":{"Line":6}},{"line":412,"address":[],"length":0,"stats":{"Line":9}},{"line":415,"address":[],"length":0,"stats":{"Line":4}},{"line":416,"address":[],"length":0,"stats":{"Line":12}},{"line":418,"address":[],"length":0,"stats":{"Line":12}},{"line":419,"address":[],"length":0,"stats":{"Line":10}},{"line":420,"address":[],"length":0,"stats":{"Line":6}},{"line":421,"address":[],"length":0,"stats":{"Line":9}},{"line":426,"address":[],"length":0,"stats":{"Line":8}},{"line":427,"address":[],"length":0,"stats":{"Line":8}},{"line":428,"address":[],"length":0,"stats":{"Line":12}},{"line":432,"address":[],"length":0,"stats":{"Line":4}},{"line":467,"address":[],"length":0,"stats":{"Line":7}},{"line":468,"address":[],"length":0,"stats":{"Line":7}},{"line":469,"address":[],"length":0,"stats":{"Line":0}},{"line":470,"address":[],"length":0,"stats":{"Line":1}},{"line":471,"address":[],"length":0,"stats":{"Line":6}}],"covered":166,"coverable":183},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","hindsight","promotion.rs"],"content":"use std::collections::HashMap;\nuse std::sync::Arc;\n\nuse mk_core::traits::KnowledgeRepository;\nuse mk_core::types::{\n    KnowledgeEntry, KnowledgeLayer, KnowledgeStatus, KnowledgeType, TenantContext,\n};\nuse tracing::info_span;\n\nuse crate::governance::GovernanceEngine;\nuse crate::repository::RepositoryError;\n\n#[derive(Debug, Clone)]\npub struct HindsightPromotionConfig {\n    pub min_successes: u32,\n    pub require_governance_check: bool,\n    pub proposal_prefix: String,\n}\n\nimpl Default for HindsightPromotionConfig {\n    fn default() -> Self {\n        Self {\n            min_successes: 3,\n            require_governance_check: true,\n            proposal_prefix: \"proposals/hindsight/\".to_string(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct HindsightPromotionRequest {\n    pub note_id: String,\n    pub target_layer: KnowledgeLayer,\n    pub success_count: u32,\n    pub note_content: String,\n    pub tags: Vec<String>,\n}\n\n#[derive(Debug, thiserror::Error)]\npub enum HindsightPromotionError {\n    #[error(\"Success threshold not met\")]\n    ThresholdNotMet,\n\n    #[error(\"Governance rejected promotion\")]\n    GovernanceRejected,\n\n    #[error(\"Repository error: {0}\")]\n    Repository(#[from] RepositoryError),\n}\n\npub struct HindsightPromoter {\n    repository: Arc<dyn KnowledgeRepository<Error = RepositoryError>>,\n    governance: Option<Arc<GovernanceEngine>>,\n    config: HindsightPromotionConfig,\n}\n\nimpl HindsightPromoter {\n    pub fn new(\n        repository: Arc<dyn KnowledgeRepository<Error = RepositoryError>>,\n        config: HindsightPromotionConfig,\n    ) -> Self {\n        Self {\n            repository,\n            governance: None,\n            config,\n        }\n    }\n\n    pub fn with_governance(mut self, governance: Arc<GovernanceEngine>) -> Self {\n        self.governance = Some(governance);\n        self\n    }\n\n    pub async fn promote(\n        &self,\n        ctx: TenantContext,\n        request: HindsightPromotionRequest,\n    ) -> Result<String, HindsightPromotionError> {\n        let _span = info_span!(\n            \"promote_hindsight_note\",\n            note_id = %request.note_id,\n            target_layer = ?request.target_layer,\n            success_count = request.success_count,\n            min_successes = self.config.min_successes,\n            has_governance = self.governance.is_some(),\n            require_governance_check = self.config.require_governance_check\n        )\n        .entered();\n\n        if request.success_count < self.config.min_successes {\n            return Err(HindsightPromotionError::ThresholdNotMet);\n        }\n\n        if self.config.require_governance_check {\n            if let Some(engine) = &self.governance {\n                let mut metadata = HashMap::new();\n                metadata.insert(\"note_id\".to_string(), serde_json::json!(request.note_id));\n                metadata.insert(\n                    \"success_count\".to_string(),\n                    serde_json::json!(request.success_count),\n                );\n                metadata.insert(\"tags\".to_string(), serde_json::json!(request.tags));\n                let result = engine.validate(request.target_layer, &metadata);\n                if !result.is_valid {\n                    return Err(HindsightPromotionError::GovernanceRejected);\n                }\n            }\n        }\n\n        let path = format!(\"{}{}.md\", self.config.proposal_prefix, request.note_id);\n        let entry = KnowledgeEntry {\n            path,\n            content: request.note_content,\n            layer: request.target_layer,\n            kind: KnowledgeType::Hindsight,\n            status: KnowledgeStatus::Proposed,\n            summaries: HashMap::new(),\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: chrono::Utc::now().timestamp(),\n        };\n\n        let message = format!(\"Propose hindsight promotion {}\", request.note_id);\n        let commit = self.repository.store(ctx, entry, &message).await?;\n        Ok(commit)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use async_trait::async_trait;\n    use std::sync::Mutex;\n\n    struct MockRepository {\n        stored: Mutex<Vec<KnowledgeEntry>>,\n    }\n\n    impl MockRepository {\n        fn new() -> Self {\n            Self {\n                stored: Mutex::new(Vec::new()),\n            }\n        }\n    }\n\n    #[async_trait]\n    impl KnowledgeRepository for MockRepository {\n        type Error = RepositoryError;\n\n        async fn get(\n            &self,\n            _ctx: TenantContext,\n            _layer: KnowledgeLayer,\n            _path: &str,\n        ) -> Result<Option<KnowledgeEntry>, Self::Error> {\n            Ok(None)\n        }\n\n        async fn store(\n            &self,\n            _ctx: TenantContext,\n            entry: KnowledgeEntry,\n            _message: &str,\n        ) -> Result<String, Self::Error> {\n            self.stored.lock().unwrap().push(entry);\n            Ok(\"commit\".to_string())\n        }\n\n        async fn list(\n            &self,\n            _ctx: TenantContext,\n            _layer: KnowledgeLayer,\n            _prefix: &str,\n        ) -> Result<Vec<KnowledgeEntry>, Self::Error> {\n            Ok(Vec::new())\n        }\n\n        async fn delete(\n            &self,\n            _ctx: TenantContext,\n            _layer: KnowledgeLayer,\n            _path: &str,\n            _message: &str,\n        ) -> Result<String, Self::Error> {\n            Ok(String::new())\n        }\n\n        async fn get_head_commit(\n            &self,\n            _ctx: TenantContext,\n        ) -> Result<Option<String>, Self::Error> {\n            Ok(None)\n        }\n\n        async fn get_affected_items(\n            &self,\n            _ctx: TenantContext,\n            _since_commit: &str,\n        ) -> Result<Vec<(KnowledgeLayer, String)>, Self::Error> {\n            Ok(Vec::new())\n        }\n\n        async fn search(\n            &self,\n            _ctx: TenantContext,\n            _query: &str,\n            _layers: Vec<KnowledgeLayer>,\n            _limit: usize,\n        ) -> Result<Vec<KnowledgeEntry>, Self::Error> {\n            Ok(Vec::new())\n        }\n\n        fn root_path(&self) -> Option<std::path::PathBuf> {\n            None\n        }\n    }\n\n    fn ctx() -> TenantContext {\n        TenantContext::new(\n            mk_core::types::TenantId::new(\"t\".to_string()).unwrap(),\n            mk_core::types::UserId::new(\"u\".to_string()).unwrap(),\n        )\n    }\n\n    #[tokio::test]\n    async fn test_promote_threshold_not_met() {\n        let repo = Arc::new(MockRepository::new());\n        let promoter = HindsightPromoter::new(repo, HindsightPromotionConfig::default());\n        let request = HindsightPromotionRequest {\n            note_id: \"n1\".to_string(),\n            target_layer: KnowledgeLayer::Project,\n            success_count: 1,\n            note_content: \"content\".to_string(),\n            tags: vec![],\n        };\n\n        let result = promoter.promote(ctx(), request).await;\n        assert!(matches!(\n            result,\n            Err(HindsightPromotionError::ThresholdNotMet)\n        ));\n    }\n\n    #[tokio::test]\n    async fn test_promote_creates_proposal() {\n        let repo = Arc::new(MockRepository::new());\n        let promoter = HindsightPromoter::new(repo.clone(), HindsightPromotionConfig::default());\n        let request = HindsightPromotionRequest {\n            note_id: \"n1\".to_string(),\n            target_layer: KnowledgeLayer::Project,\n            success_count: 5,\n            note_content: \"content\".to_string(),\n            tags: vec![\"tag\".to_string()],\n        };\n\n        let commit = promoter.promote(ctx(), request).await.unwrap();\n        assert_eq!(commit, \"commit\");\n\n        let stored = repo.stored.lock().unwrap();\n        assert_eq!(stored.len(), 1);\n        assert_eq!(stored[0].kind, KnowledgeType::Hindsight);\n        assert_eq!(stored[0].status, KnowledgeStatus::Proposed);\n        assert!(stored[0].path.starts_with(\"proposals/hindsight/\"));\n    }\n}\n","traces":[{"line":21,"address":[],"length":0,"stats":{"Line":2}},{"line":25,"address":[],"length":0,"stats":{"Line":2}},{"line":58,"address":[],"length":0,"stats":{"Line":2}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":2}},{"line":79,"address":[],"length":0,"stats":{"Line":4}},{"line":85,"address":[],"length":0,"stats":{"Line":4}},{"line":90,"address":[],"length":0,"stats":{"Line":2}},{"line":91,"address":[],"length":0,"stats":{"Line":1}},{"line":94,"address":[],"length":0,"stats":{"Line":1}},{"line":95,"address":[],"length":0,"stats":{"Line":1}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":3}},{"line":113,"address":[],"length":0,"stats":{"Line":2}},{"line":114,"address":[],"length":0,"stats":{"Line":2}},{"line":117,"address":[],"length":0,"stats":{"Line":2}},{"line":118,"address":[],"length":0,"stats":{"Line":2}},{"line":121,"address":[],"length":0,"stats":{"Line":1}},{"line":124,"address":[],"length":0,"stats":{"Line":3}},{"line":125,"address":[],"length":0,"stats":{"Line":5}},{"line":126,"address":[],"length":0,"stats":{"Line":1}}],"covered":19,"coverable":31},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","hindsight","query.rs"],"content":"use mk_core::types::{ErrorSignature, HindsightNote, Resolution};\n\n#[derive(Debug, Clone)]\npub struct HindsightQueryConfig {\n    pub semantic_threshold: f32,\n    pub max_results: usize,\n}\n\nimpl Default for HindsightQueryConfig {\n    fn default() -> Self {\n        Self {\n            semantic_threshold: 0.8,\n            max_results: 5,\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct HindsightQuery {\n    cfg: HindsightQueryConfig,\n}\n\nimpl HindsightQuery {\n    pub fn new(cfg: HindsightQueryConfig) -> Self {\n        Self { cfg }\n    }\n\n    pub fn query_hindsight(\n        &self,\n        error: &ErrorSignature,\n        notes: &[HindsightNote],\n    ) -> Vec<HindsightMatch> {\n        let mut matches: Vec<HindsightMatch> = notes\n            .iter()\n            .filter_map(|note| self.match_note(error, note))\n            .collect();\n\n        matches.sort_by(|a, b| {\n            b.score\n                .partial_cmp(&a.score)\n                .unwrap_or(std::cmp::Ordering::Equal)\n        });\n\n        matches.truncate(self.cfg.max_results);\n        matches\n    }\n\n    fn match_note(&self, err: &ErrorSignature, note: &HindsightNote) -> Option<HindsightMatch> {\n        let mut score = 0.0;\n\n        if err.error_type == note.error_signature.error_type {\n            score += 0.6;\n        }\n\n        let msg_sim = jaccard_similarity(\n            &tokenize(&err.message_pattern),\n            &tokenize(&note.error_signature.message_pattern),\n        );\n        score += msg_sim * 0.3;\n\n        let ctx_sim = jaccard_similarity(\n            &note.error_signature.context_patterns,\n            &err.context_patterns,\n        );\n        score += ctx_sim * 0.1;\n\n        if score < 0.01 {\n            return None;\n        }\n\n        Some(HindsightMatch {\n            note_id: note.id.clone(),\n            score,\n            note: note.clone(),\n            best_resolution: select_best_resolution(&note.resolutions),\n        })\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct HindsightMatch {\n    pub note_id: String,\n    pub score: f32,\n    pub note: HindsightNote,\n    pub best_resolution: Option<Resolution>,\n}\n\nfn select_best_resolution(resolutions: &[Resolution]) -> Option<Resolution> {\n    resolutions.iter().cloned().max_by(|a, b| {\n        let a_key = (a.success_rate, a.application_count as f32);\n        let b_key = (b.success_rate, b.application_count as f32);\n        a_key\n            .partial_cmp(&b_key)\n            .unwrap_or(std::cmp::Ordering::Equal)\n    })\n}\n\nfn tokenize(input: &str) -> Vec<String> {\n    input\n        .split(|c: char| !c.is_alphanumeric())\n        .filter(|s| !s.is_empty())\n        .map(|s| s.to_lowercase())\n        .collect()\n}\n\nfn jaccard_similarity(a: &[String], b: &[String]) -> f32 {\n    if a.is_empty() || b.is_empty() {\n        return 0.0;\n    }\n\n    let a_set: std::collections::HashSet<_> = a.iter().collect();\n    let b_set: std::collections::HashSet<_> = b.iter().collect();\n\n    let intersection = a_set.intersection(&b_set).count() as f32;\n    let union = a_set.union(&b_set).count() as f32;\n\n    if union == 0.0 {\n        0.0\n    } else {\n        intersection / union\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    fn sig(error_type: &str, msg: &str) -> ErrorSignature {\n        ErrorSignature {\n            error_type: error_type.to_string(),\n            message_pattern: msg.to_string(),\n            stack_patterns: vec![],\n            context_patterns: vec![\"tool:cargo_test\".to_string()],\n            embedding: None,\n        }\n    }\n\n    fn note(id: &str, sig: ErrorSignature, resolutions: Vec<Resolution>) -> HindsightNote {\n        let now = chrono::Utc::now().timestamp();\n        HindsightNote {\n            id: id.to_string(),\n            error_signature: sig,\n            resolutions,\n            content: \"content\".to_string(),\n            tags: vec![\"tag\".to_string()],\n            created_at: now,\n            updated_at: now,\n        }\n    }\n\n    fn resolution(id: &str, sig_id: &str, success: f32, count: u32) -> Resolution {\n        Resolution {\n            id: id.to_string(),\n            error_signature_id: sig_id.to_string(),\n            description: \"desc\".to_string(),\n            changes: vec![],\n            success_rate: success,\n            application_count: count,\n            last_success_at: 0,\n        }\n    }\n\n    #[test]\n    fn test_query_prefers_same_error_type() {\n        let query = HindsightQuery::new(HindsightQueryConfig::default());\n        let err = sig(\"TypeError\", \"cannot read property\");\n\n        let n1 = note(\"1\", sig(\"TypeError\", \"cannot read property\"), vec![]);\n        let n2 = note(\"2\", sig(\"OtherError\", \"cannot read property\"), vec![]);\n\n        let matches = query.query_hindsight(&err, &[n1, n2]);\n\n        assert_eq!(matches.len(), 2);\n        assert_eq!(matches[0].note_id, \"1\");\n    }\n\n    #[test]\n    fn test_match_filters_unrelated() {\n        let query = HindsightQuery::new(HindsightQueryConfig::default());\n        let err = sig(\"TypeError\", \"foo bar baz\");\n        let unrelated = note(\"1\", sig(\"Other\", \"completely different\"), vec![]);\n\n        let matches = query.query_hindsight(&err, &[unrelated]);\n\n        assert_eq!(matches.len(), 1);\n        assert!(matches[0].score > 0.0);\n    }\n\n    #[test]\n    fn test_select_best_resolution() {\n        let r1 = resolution(\"r1\", \"e\", 0.9, 1);\n        let r2 = resolution(\"r2\", \"e\", 0.8, 100);\n\n        let best = select_best_resolution(&[r1.clone(), r2.clone()]).unwrap();\n        assert_eq!(best.id, \"r1\");\n    }\n\n    #[test]\n    fn test_tokenize_and_jaccard() {\n        let a = tokenize(\"Foo bar\");\n        let b = tokenize(\"foo baz\");\n\n        let sim = jaccard_similarity(&a, &b);\n\n        assert!(sim > 0.0);\n        assert!(sim < 1.0);\n    }\n\n    #[test]\n    fn test_query_max_results() {\n        let cfg = HindsightQueryConfig {\n            max_results: 2,\n            ..Default::default()\n        };\n        let query = HindsightQuery::new(cfg);\n        let err = sig(\"E\", \"m\");\n\n        let notes = vec![\n            note(\"1\", sig(\"E\", \"m\"), vec![]),\n            note(\"2\", sig(\"E\", \"m\"), vec![]),\n            note(\"3\", sig(\"E\", \"m\"), vec![]),\n        ];\n\n        let matches = query.query_hindsight(&err, &notes);\n\n        assert_eq!(matches.len(), 2);\n    }\n\n    #[test]\n    fn test_best_resolution_in_match() {\n        let query = HindsightQuery::new(HindsightQueryConfig::default());\n        let err = sig(\"E\", \"m\");\n        let r1 = resolution(\"r1\", \"e\", 0.9, 1);\n        let r2 = resolution(\"r2\", \"e\", 0.95, 10);\n        let n = note(\"1\", sig(\"E\", \"m\"), vec![r1.clone(), r2.clone()]);\n\n        let matches = query.query_hindsight(&err, &[n]);\n\n        assert_eq!(matches.len(), 1);\n        assert!(matches[0].best_resolution.is_some());\n        assert_eq!(matches[0].best_resolution.clone().unwrap().id, \"r2\");\n    }\n}\n","traces":[{"line":10,"address":[],"length":0,"stats":{"Line":27}},{"line":24,"address":[],"length":0,"stats":{"Line":27}},{"line":28,"address":[],"length":0,"stats":{"Line":5}},{"line":33,"address":[],"length":0,"stats":{"Line":15}},{"line":35,"address":[],"length":0,"stats":{"Line":33}},{"line":38,"address":[],"length":0,"stats":{"Line":13}},{"line":39,"address":[],"length":0,"stats":{"Line":3}},{"line":40,"address":[],"length":0,"stats":{"Line":6}},{"line":41,"address":[],"length":0,"stats":{"Line":6}},{"line":44,"address":[],"length":0,"stats":{"Line":15}},{"line":45,"address":[],"length":0,"stats":{"Line":5}},{"line":48,"address":[],"length":0,"stats":{"Line":7}},{"line":49,"address":[],"length":0,"stats":{"Line":14}},{"line":51,"address":[],"length":0,"stats":{"Line":12}},{"line":52,"address":[],"length":0,"stats":{"Line":5}},{"line":56,"address":[],"length":0,"stats":{"Line":7}},{"line":57,"address":[],"length":0,"stats":{"Line":7}},{"line":59,"address":[],"length":0,"stats":{"Line":7}},{"line":62,"address":[],"length":0,"stats":{"Line":7}},{"line":63,"address":[],"length":0,"stats":{"Line":7}},{"line":65,"address":[],"length":0,"stats":{"Line":7}},{"line":67,"address":[],"length":0,"stats":{"Line":7}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":7}},{"line":72,"address":[],"length":0,"stats":{"Line":21}},{"line":73,"address":[],"length":0,"stats":{"Line":14}},{"line":74,"address":[],"length":0,"stats":{"Line":21}},{"line":75,"address":[],"length":0,"stats":{"Line":7}},{"line":88,"address":[],"length":0,"stats":{"Line":8}},{"line":89,"address":[],"length":0,"stats":{"Line":34}},{"line":90,"address":[],"length":0,"stats":{"Line":4}},{"line":91,"address":[],"length":0,"stats":{"Line":4}},{"line":92,"address":[],"length":0,"stats":{"Line":2}},{"line":93,"address":[],"length":0,"stats":{"Line":4}},{"line":94,"address":[],"length":0,"stats":{"Line":4}},{"line":98,"address":[],"length":0,"stats":{"Line":16}},{"line":99,"address":[],"length":0,"stats":{"Line":16}},{"line":100,"address":[],"length":0,"stats":{"Line":282}},{"line":101,"address":[],"length":0,"stats":{"Line":74}},{"line":102,"address":[],"length":0,"stats":{"Line":74}},{"line":106,"address":[],"length":0,"stats":{"Line":15}},{"line":107,"address":[],"length":0,"stats":{"Line":60}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":75}},{"line":112,"address":[],"length":0,"stats":{"Line":75}},{"line":114,"address":[],"length":0,"stats":{"Line":60}},{"line":115,"address":[],"length":0,"stats":{"Line":60}},{"line":117,"address":[],"length":0,"stats":{"Line":15}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":15}}],"covered":47,"coverable":50},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","hindsight","resolution.rs"],"content":"use std::collections::HashMap;\nuse std::time::{SystemTime, UNIX_EPOCH};\n\nuse async_trait::async_trait;\nuse mk_core::types::{CodeChange, Resolution};\nuse serde::{Deserialize, Serialize};\nuse thiserror::Error;\nuse tracing::{info, instrument, warn};\n\n#[derive(Debug, Clone)]\npub struct ResolutionTrackerConfig {\n    pub default_success_rate: f32,\n    pub min_success_rate: f32,\n    pub max_success_rate: f32,\n    pub promotion_threshold_applications: u32,\n    pub promotion_threshold_success_rate: f32,\n}\n\nimpl Default for ResolutionTrackerConfig {\n    fn default() -> Self {\n        Self {\n            default_success_rate: 1.0,\n            min_success_rate: 0.0,\n            max_success_rate: 1.0,\n            promotion_threshold_applications: 5,\n            promotion_threshold_success_rate: 0.8,\n        }\n    }\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]\npub enum ResolutionOutcome {\n    Success,\n    Failure,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ResolutionMetrics {\n    pub resolution_id: String,\n    pub error_signature_id: String,\n    pub success_count: u32,\n    pub failure_count: u32,\n    pub last_success_at: Option<i64>,\n    pub last_failure_at: Option<i64>,\n    pub failure_contexts: Vec<FailureContext>,\n    pub created_at: i64,\n}\n\nimpl ResolutionMetrics {\n    pub fn new(resolution_id: impl Into<String>, error_signature_id: impl Into<String>) -> Self {\n        let now = current_timestamp();\n        Self {\n            resolution_id: resolution_id.into(),\n            error_signature_id: error_signature_id.into(),\n            success_count: 0,\n            failure_count: 0,\n            last_success_at: None,\n            last_failure_at: None,\n            failure_contexts: Vec::new(),\n            created_at: now,\n        }\n    }\n\n    pub fn application_count(&self) -> u32 {\n        self.success_count + self.failure_count\n    }\n\n    pub fn success_rate(&self) -> f32 {\n        let total = self.application_count();\n        if total == 0 {\n            return 1.0;\n        }\n        self.success_count as f32 / total as f32\n    }\n\n    pub fn record_success(&mut self) {\n        self.success_count = self.success_count.saturating_add(1);\n        self.last_success_at = Some(current_timestamp());\n    }\n\n    pub fn record_failure(&mut self, context: Option<FailureContext>) {\n        self.failure_count = self.failure_count.saturating_add(1);\n        self.last_failure_at = Some(current_timestamp());\n        if let Some(ctx) = context {\n            if self.failure_contexts.len() < 10 {\n                self.failure_contexts.push(ctx);\n            }\n        }\n    }\n\n    pub fn should_promote(&self, config: &ResolutionTrackerConfig) -> bool {\n        self.application_count() >= config.promotion_threshold_applications\n            && self.success_rate() >= config.promotion_threshold_success_rate\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct FailureContext {\n    pub timestamp: i64,\n    pub error_message: Option<String>,\n    pub stack_trace: Option<String>,\n    pub session_id: Option<String>,\n}\n\nimpl FailureContext {\n    pub fn new() -> Self {\n        Self {\n            timestamp: current_timestamp(),\n            error_message: None,\n            stack_trace: None,\n            session_id: None,\n        }\n    }\n\n    pub fn with_error(mut self, msg: impl Into<String>) -> Self {\n        self.error_message = Some(msg.into());\n        self\n    }\n\n    pub fn with_stack_trace(mut self, trace: impl Into<String>) -> Self {\n        self.stack_trace = Some(trace.into());\n        self\n    }\n\n    pub fn with_session(mut self, session_id: impl Into<String>) -> Self {\n        self.session_id = Some(session_id.into());\n        self\n    }\n}\n\nimpl Default for FailureContext {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ApplicationRecord {\n    pub resolution_id: String,\n    pub outcome: ResolutionOutcome,\n    pub timestamp: i64,\n    pub context: Option<ApplicationContext>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ApplicationContext {\n    pub session_id: Option<String>,\n    pub error_id: Option<String>,\n    pub notes: Option<String>,\n}\n\n#[derive(Debug, Error)]\npub enum ResolutionStorageError {\n    #[error(\"Resolution not found: {0}\")]\n    NotFound(String),\n    #[error(\"Storage error: {0}\")]\n    Storage(String),\n    #[error(\"Serialization error: {0}\")]\n    Serialization(String),\n}\n\n#[async_trait]\npub trait ResolutionStorage: Send + Sync {\n    async fn get_metrics(\n        &self,\n        resolution_id: &str,\n    ) -> Result<Option<ResolutionMetrics>, ResolutionStorageError>;\n\n    async fn save_metrics(&self, metrics: &ResolutionMetrics)\n    -> Result<(), ResolutionStorageError>;\n\n    async fn get_metrics_by_error(\n        &self,\n        error_signature_id: &str,\n    ) -> Result<Vec<ResolutionMetrics>, ResolutionStorageError>;\n\n    async fn record_application(\n        &self,\n        record: &ApplicationRecord,\n    ) -> Result<(), ResolutionStorageError>;\n\n    async fn get_applications(\n        &self,\n        resolution_id: &str,\n        limit: usize,\n    ) -> Result<Vec<ApplicationRecord>, ResolutionStorageError>;\n}\n\npub struct InMemoryResolutionStorage {\n    metrics: std::sync::RwLock<HashMap<String, ResolutionMetrics>>,\n    applications: std::sync::RwLock<Vec<ApplicationRecord>>,\n}\n\nimpl InMemoryResolutionStorage {\n    pub fn new() -> Self {\n        Self {\n            metrics: std::sync::RwLock::new(HashMap::new()),\n            applications: std::sync::RwLock::new(Vec::new()),\n        }\n    }\n}\n\nimpl Default for InMemoryResolutionStorage {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n#[async_trait]\nimpl ResolutionStorage for InMemoryResolutionStorage {\n    async fn get_metrics(\n        &self,\n        resolution_id: &str,\n    ) -> Result<Option<ResolutionMetrics>, ResolutionStorageError> {\n        let metrics = self\n            .metrics\n            .read()\n            .map_err(|e| ResolutionStorageError::Storage(format!(\"Lock poisoned: {e}\")))?;\n        Ok(metrics.get(resolution_id).cloned())\n    }\n\n    async fn save_metrics(\n        &self,\n        metrics: &ResolutionMetrics,\n    ) -> Result<(), ResolutionStorageError> {\n        let mut store = self\n            .metrics\n            .write()\n            .map_err(|e| ResolutionStorageError::Storage(format!(\"Lock poisoned: {e}\")))?;\n        store.insert(metrics.resolution_id.clone(), metrics.clone());\n        Ok(())\n    }\n\n    async fn get_metrics_by_error(\n        &self,\n        error_signature_id: &str,\n    ) -> Result<Vec<ResolutionMetrics>, ResolutionStorageError> {\n        let metrics = self\n            .metrics\n            .read()\n            .map_err(|e| ResolutionStorageError::Storage(format!(\"Lock poisoned: {e}\")))?;\n        Ok(metrics\n            .values()\n            .filter(|m| m.error_signature_id == error_signature_id)\n            .cloned()\n            .collect())\n    }\n\n    async fn record_application(\n        &self,\n        record: &ApplicationRecord,\n    ) -> Result<(), ResolutionStorageError> {\n        let mut apps = self\n            .applications\n            .write()\n            .map_err(|e| ResolutionStorageError::Storage(format!(\"Lock poisoned: {e}\")))?;\n        apps.push(record.clone());\n        Ok(())\n    }\n\n    async fn get_applications(\n        &self,\n        resolution_id: &str,\n        limit: usize,\n    ) -> Result<Vec<ApplicationRecord>, ResolutionStorageError> {\n        let apps = self\n            .applications\n            .read()\n            .map_err(|e| ResolutionStorageError::Storage(format!(\"Lock poisoned: {e}\")))?;\n        Ok(apps\n            .iter()\n            .filter(|a| a.resolution_id == resolution_id)\n            .take(limit)\n            .cloned()\n            .collect())\n    }\n}\n\npub struct ResolutionTracker<S: ResolutionStorage> {\n    cfg: ResolutionTrackerConfig,\n    storage: S,\n    local_stats: std::sync::RwLock<HashMap<String, (u32, u32)>>,\n}\n\nimpl<S: ResolutionStorage> ResolutionTracker<S> {\n    pub fn new(cfg: ResolutionTrackerConfig, storage: S) -> Self {\n        Self {\n            cfg,\n            storage,\n            local_stats: std::sync::RwLock::new(HashMap::new()),\n        }\n    }\n\n    pub fn config(&self) -> &ResolutionTrackerConfig {\n        &self.cfg\n    }\n\n    #[instrument(skip(self), fields(resolution_id = %resolution_id))]\n    pub async fn record_application(\n        &self,\n        resolution_id: &str,\n        outcome: ResolutionOutcome,\n        context: Option<ApplicationContext>,\n    ) -> Result<ResolutionMetrics, ResolutionStorageError> {\n        let mut metrics = self\n            .storage\n            .get_metrics(resolution_id)\n            .await?\n            .ok_or_else(|| ResolutionStorageError::NotFound(resolution_id.to_string()))?;\n\n        match outcome {\n            ResolutionOutcome::Success => {\n                metrics.record_success();\n                info!(\n                    resolution_id = %resolution_id,\n                    success_rate = metrics.success_rate(),\n                    application_count = metrics.application_count(),\n                    \"Resolution application succeeded\"\n                );\n            }\n            ResolutionOutcome::Failure => {\n                let failure_ctx = context.as_ref().map(|c| {\n                    FailureContext::new()\n                        .with_session(c.session_id.clone().unwrap_or_default())\n                        .with_error(c.notes.clone().unwrap_or_default())\n                });\n                metrics.record_failure(failure_ctx);\n                warn!(\n                    resolution_id = %resolution_id,\n                    success_rate = metrics.success_rate(),\n                    application_count = metrics.application_count(),\n                    \"Resolution application failed\"\n                );\n            }\n        }\n\n        self.storage.save_metrics(&metrics).await?;\n\n        let record = ApplicationRecord {\n            resolution_id: resolution_id.to_string(),\n            outcome,\n            timestamp: current_timestamp(),\n            context,\n        };\n        self.storage.record_application(&record).await?;\n\n        if let Ok(mut stats) = self.local_stats.write() {\n            let entry = stats.entry(resolution_id.to_string()).or_insert((0, 0));\n            match outcome {\n                ResolutionOutcome::Success => entry.0 += 1,\n                ResolutionOutcome::Failure => entry.1 += 1,\n            }\n        }\n\n        Ok(metrics)\n    }\n\n    pub fn record_outcome(&self, resolution_id: &str, outcome: ResolutionOutcome) {\n        if let Ok(mut stats) = self.local_stats.write() {\n            let entry = stats.entry(resolution_id.to_string()).or_insert((0, 0));\n            match outcome {\n                ResolutionOutcome::Success => entry.0 += 1,\n                ResolutionOutcome::Failure => entry.1 += 1,\n            }\n        }\n    }\n\n    pub fn compute_success_rate(&self, resolution_id: &str) -> f32 {\n        let stats = match self.local_stats.read() {\n            Ok(s) => s,\n            Err(_) => return self.cfg.default_success_rate,\n        };\n\n        let Some((successes, failures)) = stats.get(resolution_id) else {\n            return self.cfg.default_success_rate;\n        };\n\n        let total = *successes as f32 + *failures as f32;\n        if total == 0.0 {\n            return self.cfg.default_success_rate;\n        }\n\n        let rate = *successes as f32 / total;\n        rate.clamp(self.cfg.min_success_rate, self.cfg.max_success_rate)\n    }\n\n    pub fn apply_stats(&self, mut resolution: Resolution) -> Resolution {\n        resolution.success_rate = self.compute_success_rate(&resolution.id);\n        resolution.application_count = self\n            .local_stats\n            .read()\n            .ok()\n            .and_then(|s| s.get(&resolution.id).map(|(s, f)| s + f))\n            .unwrap_or(resolution.application_count);\n        resolution\n    }\n\n    #[instrument(skip(self, changes, resolution_id, error_signature_id, description))]\n    pub async fn link_resolution(\n        &self,\n        resolution_id: impl Into<String>,\n        error_signature_id: impl Into<String>,\n        description: impl Into<String>,\n        changes: Vec<CodeChange>,\n    ) -> Result<Resolution, ResolutionStorageError> {\n        let resolution_id = resolution_id.into();\n        let error_signature_id = error_signature_id.into();\n        let now = current_timestamp();\n\n        let mut metrics = ResolutionMetrics::new(&resolution_id, &error_signature_id);\n        metrics.record_success();\n\n        self.storage.save_metrics(&metrics).await?;\n\n        let record = ApplicationRecord {\n            resolution_id: resolution_id.clone(),\n            outcome: ResolutionOutcome::Success,\n            timestamp: now,\n            context: None,\n        };\n        self.storage.record_application(&record).await?;\n\n        if let Ok(mut stats) = self.local_stats.write() {\n            stats.insert(resolution_id.clone(), (1, 0));\n        }\n\n        info!(\n            resolution_id = %resolution_id,\n            error_signature_id = %error_signature_id,\n            \"Linked resolution to error\"\n        );\n\n        Ok(Resolution {\n            id: resolution_id,\n            error_signature_id: error_signature_id.into(),\n            description: description.into(),\n            changes,\n            success_rate: 1.0,\n            application_count: 1,\n            last_success_at: now,\n        })\n    }\n\n    pub fn create_resolution(\n        &self,\n        id: impl Into<String>,\n        error_signature_id: impl Into<String>,\n        description: impl Into<String>,\n        changes: Vec<CodeChange>,\n        last_success_at: i64,\n    ) -> Resolution {\n        Resolution {\n            id: id.into(),\n            error_signature_id: error_signature_id.into(),\n            description: description.into(),\n            changes,\n            success_rate: self.cfg.default_success_rate,\n            application_count: 0,\n            last_success_at,\n        }\n    }\n\n    pub async fn get_metrics(\n        &self,\n        resolution_id: &str,\n    ) -> Result<Option<ResolutionMetrics>, ResolutionStorageError> {\n        self.storage.get_metrics(resolution_id).await\n    }\n\n    pub async fn get_resolutions_for_error(\n        &self,\n        error_signature_id: &str,\n    ) -> Result<Vec<ResolutionMetrics>, ResolutionStorageError> {\n        self.storage.get_metrics_by_error(error_signature_id).await\n    }\n\n    pub async fn check_promotion_candidates(\n        &self,\n        error_signature_id: &str,\n    ) -> Result<Vec<ResolutionMetrics>, ResolutionStorageError> {\n        let metrics = self\n            .storage\n            .get_metrics_by_error(error_signature_id)\n            .await?;\n        Ok(metrics\n            .into_iter()\n            .filter(|m| m.should_promote(&self.cfg))\n            .collect())\n    }\n\n    pub fn extract_changes_from_diff(&self, diff: &str) -> Vec<CodeChange> {\n        let mut changes = Vec::new();\n        let mut current_path: Option<String> = None;\n        let mut current_diff = String::new();\n\n        for line in diff.lines() {\n            if let Some(path) = parse_diff_header(line) {\n                if let Some(existing_path) = current_path.take() {\n                    if !current_diff.trim().is_empty() {\n                        changes.push(CodeChange {\n                            file_path: existing_path,\n                            diff: current_diff.trim_end().to_string(),\n                            description: None,\n                        });\n                    }\n                }\n                current_path = Some(path);\n                current_diff.clear();\n                continue;\n            }\n\n            if current_path.is_some() {\n                current_diff.push_str(line);\n                current_diff.push('\\n');\n            }\n        }\n\n        if let Some(path) = current_path {\n            if !current_diff.trim().is_empty() {\n                changes.push(CodeChange {\n                    file_path: path,\n                    diff: current_diff.trim_end().to_string(),\n                    description: None,\n                });\n            }\n        }\n\n        changes\n    }\n}\n\nfn current_timestamp() -> i64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .map(|d| d.as_secs() as i64)\n        .unwrap_or(0)\n}\n\nfn parse_diff_header(line: &str) -> Option<String> {\n    if !line.starts_with(\"diff --git \") {\n        return None;\n    }\n\n    let parts: Vec<&str> = line.split_whitespace().collect();\n    if parts.len() < 4 {\n        return None;\n    }\n\n    let path = parts[3];\n    Some(path.trim_start_matches(\"b/\").to_string())\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    fn create_tracker() -> ResolutionTracker<InMemoryResolutionStorage> {\n        ResolutionTracker::new(\n            ResolutionTrackerConfig::default(),\n            InMemoryResolutionStorage::new(),\n        )\n    }\n\n    #[test]\n    fn test_resolution_metrics_new() {\n        let metrics = ResolutionMetrics::new(\"r1\", \"e1\");\n\n        assert_eq!(metrics.resolution_id, \"r1\");\n        assert_eq!(metrics.error_signature_id, \"e1\");\n        assert_eq!(metrics.success_count, 0);\n        assert_eq!(metrics.failure_count, 0);\n        assert_eq!(metrics.application_count(), 0);\n        assert_eq!(metrics.success_rate(), 1.0);\n    }\n\n    #[test]\n    fn test_resolution_metrics_record_success() {\n        let mut metrics = ResolutionMetrics::new(\"r1\", \"e1\");\n\n        metrics.record_success();\n\n        assert_eq!(metrics.success_count, 1);\n        assert!(metrics.last_success_at.is_some());\n        assert_eq!(metrics.success_rate(), 1.0);\n    }\n\n    #[test]\n    fn test_resolution_metrics_record_failure() {\n        let mut metrics = ResolutionMetrics::new(\"r1\", \"e1\");\n\n        metrics.record_failure(Some(FailureContext::new().with_error(\"test error\")));\n\n        assert_eq!(metrics.failure_count, 1);\n        assert!(metrics.last_failure_at.is_some());\n        assert_eq!(metrics.success_rate(), 0.0);\n        assert_eq!(metrics.failure_contexts.len(), 1);\n    }\n\n    #[test]\n    fn test_resolution_metrics_success_rate_calculation() {\n        let mut metrics = ResolutionMetrics::new(\"r1\", \"e1\");\n\n        metrics.record_success();\n        metrics.record_success();\n        metrics.record_failure(None);\n\n        assert!((metrics.success_rate() - (2.0 / 3.0)).abs() < 0.001);\n        assert_eq!(metrics.application_count(), 3);\n    }\n\n    #[test]\n    fn test_resolution_metrics_should_promote() {\n        let config = ResolutionTrackerConfig {\n            promotion_threshold_applications: 5,\n            promotion_threshold_success_rate: 0.8,\n            ..Default::default()\n        };\n        let mut metrics = ResolutionMetrics::new(\"r1\", \"e1\");\n\n        assert!(!metrics.should_promote(&config));\n\n        for _ in 0..5 {\n            metrics.record_success();\n        }\n\n        assert!(metrics.should_promote(&config));\n\n        // Add 2 failures to drop below 0.8: 5/(5+2) = 0.714\n        metrics.record_failure(None);\n        metrics.record_failure(None);\n        assert!(!metrics.should_promote(&config));\n    }\n\n    #[test]\n    fn test_failure_context_builder() {\n        let ctx = FailureContext::new()\n            .with_error(\"test error\")\n            .with_stack_trace(\"at line 1\")\n            .with_session(\"sess-123\");\n\n        assert_eq!(ctx.error_message, Some(\"test error\".to_string()));\n        assert_eq!(ctx.stack_trace, Some(\"at line 1\".to_string()));\n        assert_eq!(ctx.session_id, Some(\"sess-123\".to_string()));\n    }\n\n    #[test]\n    fn test_failure_contexts_limited_to_10() {\n        let mut metrics = ResolutionMetrics::new(\"r1\", \"e1\");\n\n        for i in 0..15 {\n            metrics.record_failure(Some(FailureContext::new().with_error(format!(\"error {i}\"))));\n        }\n\n        assert_eq!(metrics.failure_contexts.len(), 10);\n        assert_eq!(metrics.failure_count, 15);\n    }\n\n    #[tokio::test]\n    async fn test_in_memory_storage_save_and_get() {\n        let storage = InMemoryResolutionStorage::new();\n        let metrics = ResolutionMetrics::new(\"r1\", \"e1\");\n\n        storage.save_metrics(&metrics).await.unwrap();\n        let retrieved = storage.get_metrics(\"r1\").await.unwrap();\n\n        assert!(retrieved.is_some());\n        assert_eq!(retrieved.unwrap().resolution_id, \"r1\");\n    }\n\n    #[tokio::test]\n    async fn test_in_memory_storage_get_by_error() {\n        let storage = InMemoryResolutionStorage::new();\n        storage\n            .save_metrics(&ResolutionMetrics::new(\"r1\", \"e1\"))\n            .await\n            .unwrap();\n        storage\n            .save_metrics(&ResolutionMetrics::new(\"r2\", \"e1\"))\n            .await\n            .unwrap();\n        storage\n            .save_metrics(&ResolutionMetrics::new(\"r3\", \"e2\"))\n            .await\n            .unwrap();\n\n        let results = storage.get_metrics_by_error(\"e1\").await.unwrap();\n\n        assert_eq!(results.len(), 2);\n    }\n\n    #[tokio::test]\n    async fn test_tracker_link_resolution() {\n        let tracker = create_tracker();\n\n        let resolution = tracker\n            .link_resolution(\"r1\", \"e1\", \"Fix the bug\", vec![])\n            .await\n            .unwrap();\n\n        assert_eq!(resolution.id, \"r1\");\n        assert_eq!(resolution.error_signature_id, \"e1\");\n        assert_eq!(resolution.success_rate, 1.0);\n        assert_eq!(resolution.application_count, 1);\n\n        let metrics = tracker.get_metrics(\"r1\").await.unwrap().unwrap();\n        assert_eq!(metrics.success_count, 1);\n    }\n\n    #[tokio::test]\n    async fn test_tracker_record_application_success() {\n        let tracker = create_tracker();\n        tracker\n            .link_resolution(\"r1\", \"e1\", \"desc\", vec![])\n            .await\n            .unwrap();\n\n        let metrics = tracker\n            .record_application(\"r1\", ResolutionOutcome::Success, None)\n            .await\n            .unwrap();\n\n        assert_eq!(metrics.success_count, 2);\n        assert_eq!(metrics.success_rate(), 1.0);\n    }\n\n    #[tokio::test]\n    async fn test_tracker_record_application_failure() {\n        let tracker = create_tracker();\n        tracker\n            .link_resolution(\"r1\", \"e1\", \"desc\", vec![])\n            .await\n            .unwrap();\n\n        let context = ApplicationContext {\n            session_id: Some(\"sess-1\".to_string()),\n            error_id: None,\n            notes: Some(\"Did not work\".to_string()),\n        };\n\n        let metrics = tracker\n            .record_application(\"r1\", ResolutionOutcome::Failure, Some(context))\n            .await\n            .unwrap();\n\n        assert_eq!(metrics.success_count, 1);\n        assert_eq!(metrics.failure_count, 1);\n        assert!((metrics.success_rate() - 0.5).abs() < 0.001);\n    }\n\n    #[tokio::test]\n    async fn test_tracker_check_promotion_candidates() {\n        let tracker = create_tracker();\n        tracker\n            .link_resolution(\"r1\", \"e1\", \"desc\", vec![])\n            .await\n            .unwrap();\n\n        for _ in 0..4 {\n            tracker\n                .record_application(\"r1\", ResolutionOutcome::Success, None)\n                .await\n                .unwrap();\n        }\n\n        let candidates = tracker.check_promotion_candidates(\"e1\").await.unwrap();\n\n        assert_eq!(candidates.len(), 1);\n        assert_eq!(candidates[0].resolution_id, \"r1\");\n    }\n\n    #[test]\n    fn test_default_success_rate() {\n        let tracker = create_tracker();\n        let rate = tracker.compute_success_rate(\"missing\");\n        assert_eq!(rate, 1.0);\n    }\n\n    #[test]\n    fn test_success_rate_updates() {\n        let tracker = create_tracker();\n\n        tracker.record_outcome(\"r1\", ResolutionOutcome::Success);\n        tracker.record_outcome(\"r1\", ResolutionOutcome::Failure);\n        tracker.record_outcome(\"r1\", ResolutionOutcome::Success);\n\n        let rate = tracker.compute_success_rate(\"r1\");\n        assert!((rate - (2.0 / 3.0)).abs() < 0.001);\n    }\n\n    #[test]\n    fn test_apply_stats_updates_fields() {\n        let tracker = create_tracker();\n        tracker.record_outcome(\"r1\", ResolutionOutcome::Success);\n        tracker.record_outcome(\"r1\", ResolutionOutcome::Failure);\n\n        let res = Resolution {\n            id: \"r1\".to_string(),\n            error_signature_id: \"e\".to_string(),\n            description: \"d\".to_string(),\n            changes: vec![],\n            success_rate: 0.0,\n            application_count: 0,\n            last_success_at: 0,\n        };\n\n        let updated = tracker.apply_stats(res);\n        assert_eq!(updated.application_count, 2);\n        assert!(updated.success_rate > 0.0);\n    }\n\n    #[test]\n    fn test_create_resolution() {\n        let tracker = create_tracker();\n        let res = tracker.create_resolution(\"r\", \"e\", \"desc\", vec![], 123);\n\n        assert_eq!(res.id, \"r\");\n        assert_eq!(res.error_signature_id, \"e\");\n        assert_eq!(res.description, \"desc\");\n        assert_eq!(res.last_success_at, 123);\n    }\n\n    #[test]\n    fn test_extract_changes_from_diff() {\n        let tracker = create_tracker();\n        let diff = \"diff --git a/src/a.rs b/src/a.rs\\n+fn foo() {}\\n\\n\\n\";\n        let changes = tracker.extract_changes_from_diff(diff);\n\n        assert_eq!(changes.len(), 1);\n        assert_eq!(changes[0].file_path, \"src/a.rs\");\n        assert!(changes[0].diff.contains(\"+fn foo\"));\n    }\n\n    #[test]\n    fn test_extract_changes_multiple_files() {\n        let tracker = create_tracker();\n        let diff = r#\"diff --git a/src/a.rs b/src/a.rs\n+fn foo() {}\ndiff --git a/src/b.rs b/src/b.rs\n+fn bar() {}\n\"#;\n        let changes = tracker.extract_changes_from_diff(diff);\n\n        assert_eq!(changes.len(), 2);\n        assert_eq!(changes[0].file_path, \"src/a.rs\");\n        assert_eq!(changes[1].file_path, \"src/b.rs\");\n    }\n}\n","traces":[{"line":20,"address":[],"length":0,"stats":{"Line":11}},{"line":50,"address":[],"length":0,"stats":{"Line":14}},{"line":51,"address":[],"length":0,"stats":{"Line":28}},{"line":53,"address":[],"length":0,"stats":{"Line":42}},{"line":54,"address":[],"length":0,"stats":{"Line":42}},{"line":59,"address":[],"length":0,"stats":{"Line":14}},{"line":64,"address":[],"length":0,"stats":{"Line":15}},{"line":65,"address":[],"length":0,"stats":{"Line":15}},{"line":68,"address":[],"length":0,"stats":{"Line":9}},{"line":69,"address":[],"length":0,"stats":{"Line":27}},{"line":70,"address":[],"length":0,"stats":{"Line":9}},{"line":71,"address":[],"length":0,"stats":{"Line":1}},{"line":73,"address":[],"length":0,"stats":{"Line":8}},{"line":76,"address":[],"length":0,"stats":{"Line":17}},{"line":77,"address":[],"length":0,"stats":{"Line":17}},{"line":78,"address":[],"length":0,"stats":{"Line":17}},{"line":81,"address":[],"length":0,"stats":{"Line":20}},{"line":82,"address":[],"length":0,"stats":{"Line":20}},{"line":83,"address":[],"length":0,"stats":{"Line":20}},{"line":84,"address":[],"length":0,"stats":{"Line":37}},{"line":85,"address":[],"length":0,"stats":{"Line":29}},{"line":86,"address":[],"length":0,"stats":{"Line":24}},{"line":91,"address":[],"length":0,"stats":{"Line":4}},{"line":92,"address":[],"length":0,"stats":{"Line":8}},{"line":93,"address":[],"length":0,"stats":{"Line":6}},{"line":106,"address":[],"length":0,"stats":{"Line":18}},{"line":108,"address":[],"length":0,"stats":{"Line":36}},{"line":115,"address":[],"length":0,"stats":{"Line":18}},{"line":116,"address":[],"length":0,"stats":{"Line":36}},{"line":117,"address":[],"length":0,"stats":{"Line":18}},{"line":120,"address":[],"length":0,"stats":{"Line":1}},{"line":121,"address":[],"length":0,"stats":{"Line":2}},{"line":122,"address":[],"length":0,"stats":{"Line":1}},{"line":125,"address":[],"length":0,"stats":{"Line":2}},{"line":126,"address":[],"length":0,"stats":{"Line":4}},{"line":127,"address":[],"length":0,"stats":{"Line":2}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":12}},{"line":197,"address":[],"length":0,"stats":{"Line":36}},{"line":198,"address":[],"length":0,"stats":{"Line":12}},{"line":204,"address":[],"length":0,"stats":{"Line":0}},{"line":205,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":241,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":8}},{"line":256,"address":[],"length":0,"stats":{"Line":0}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":272,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":10}},{"line":290,"address":[],"length":0,"stats":{"Line":10}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":6}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":6}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":321,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":1}},{"line":323,"address":[],"length":0,"stats":{"Line":1}},{"line":324,"address":[],"length":0,"stats":{"Line":4}},{"line":325,"address":[],"length":0,"stats":{"Line":4}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":337,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":342,"address":[],"length":0,"stats":{"Line":0}},{"line":345,"address":[],"length":0,"stats":{"Line":0}},{"line":347,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":6}},{"line":350,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":355,"address":[],"length":0,"stats":{"Line":0}},{"line":358,"address":[],"length":0,"stats":{"Line":5}},{"line":359,"address":[],"length":0,"stats":{"Line":10}},{"line":360,"address":[],"length":0,"stats":{"Line":30}},{"line":361,"address":[],"length":0,"stats":{"Line":5}},{"line":362,"address":[],"length":0,"stats":{"Line":3}},{"line":363,"address":[],"length":0,"stats":{"Line":2}},{"line":368,"address":[],"length":0,"stats":{"Line":3}},{"line":369,"address":[],"length":0,"stats":{"Line":6}},{"line":370,"address":[],"length":0,"stats":{"Line":6}},{"line":371,"address":[],"length":0,"stats":{"Line":0}},{"line":374,"address":[],"length":0,"stats":{"Line":10}},{"line":375,"address":[],"length":0,"stats":{"Line":1}},{"line":378,"address":[],"length":0,"stats":{"Line":4}},{"line":379,"address":[],"length":0,"stats":{"Line":2}},{"line":380,"address":[],"length":0,"stats":{"Line":0}},{"line":383,"address":[],"length":0,"stats":{"Line":4}},{"line":384,"address":[],"length":0,"stats":{"Line":8}},{"line":387,"address":[],"length":0,"stats":{"Line":1}},{"line":388,"address":[],"length":0,"stats":{"Line":2}},{"line":389,"address":[],"length":0,"stats":{"Line":1}},{"line":390,"address":[],"length":0,"stats":{"Line":1}},{"line":391,"address":[],"length":0,"stats":{"Line":1}},{"line":392,"address":[],"length":0,"stats":{"Line":1}},{"line":393,"address":[],"length":0,"stats":{"Line":6}},{"line":394,"address":[],"length":0,"stats":{"Line":2}},{"line":395,"address":[],"length":0,"stats":{"Line":1}},{"line":399,"address":[],"length":0,"stats":{"Line":4}},{"line":406,"address":[],"length":0,"stats":{"Line":0}},{"line":407,"address":[],"length":0,"stats":{"Line":0}},{"line":408,"address":[],"length":0,"stats":{"Line":0}},{"line":410,"address":[],"length":0,"stats":{"Line":0}},{"line":411,"address":[],"length":0,"stats":{"Line":0}},{"line":413,"address":[],"length":0,"stats":{"Line":0}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":421,"address":[],"length":0,"stats":{"Line":0}},{"line":423,"address":[],"length":0,"stats":{"Line":0}},{"line":424,"address":[],"length":0,"stats":{"Line":0}},{"line":427,"address":[],"length":0,"stats":{"Line":0}},{"line":428,"address":[],"length":0,"stats":{"Line":0}},{"line":429,"address":[],"length":0,"stats":{"Line":0}},{"line":430,"address":[],"length":0,"stats":{"Line":0}},{"line":433,"address":[],"length":0,"stats":{"Line":0}},{"line":434,"address":[],"length":0,"stats":{"Line":0}},{"line":435,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":0}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":444,"address":[],"length":0,"stats":{"Line":1}},{"line":453,"address":[],"length":0,"stats":{"Line":3}},{"line":454,"address":[],"length":0,"stats":{"Line":3}},{"line":455,"address":[],"length":0,"stats":{"Line":3}},{"line":457,"address":[],"length":0,"stats":{"Line":1}},{"line":463,"address":[],"length":0,"stats":{"Line":1}},{"line":467,"address":[],"length":0,"stats":{"Line":3}},{"line":470,"address":[],"length":0,"stats":{"Line":0}},{"line":474,"address":[],"length":0,"stats":{"Line":0}},{"line":477,"address":[],"length":0,"stats":{"Line":1}},{"line":481,"address":[],"length":0,"stats":{"Line":3}},{"line":482,"address":[],"length":0,"stats":{"Line":2}},{"line":483,"address":[],"length":0,"stats":{"Line":2}},{"line":484,"address":[],"length":0,"stats":{"Line":1}},{"line":485,"address":[],"length":0,"stats":{"Line":1}},{"line":486,"address":[],"length":0,"stats":{"Line":1}},{"line":487,"address":[],"length":0,"stats":{"Line":4}},{"line":488,"address":[],"length":0,"stats":{"Line":1}},{"line":491,"address":[],"length":0,"stats":{"Line":2}},{"line":492,"address":[],"length":0,"stats":{"Line":4}},{"line":493,"address":[],"length":0,"stats":{"Line":6}},{"line":494,"address":[],"length":0,"stats":{"Line":4}},{"line":496,"address":[],"length":0,"stats":{"Line":12}},{"line":497,"address":[],"length":0,"stats":{"Line":11}},{"line":498,"address":[],"length":0,"stats":{"Line":4}},{"line":499,"address":[],"length":0,"stats":{"Line":2}},{"line":500,"address":[],"length":0,"stats":{"Line":3}},{"line":501,"address":[],"length":0,"stats":{"Line":2}},{"line":502,"address":[],"length":0,"stats":{"Line":2}},{"line":503,"address":[],"length":0,"stats":{"Line":1}},{"line":507,"address":[],"length":0,"stats":{"Line":6}},{"line":508,"address":[],"length":0,"stats":{"Line":6}},{"line":509,"address":[],"length":0,"stats":{"Line":3}},{"line":512,"address":[],"length":0,"stats":{"Line":15}},{"line":513,"address":[],"length":0,"stats":{"Line":20}},{"line":514,"address":[],"length":0,"stats":{"Line":5}},{"line":518,"address":[],"length":0,"stats":{"Line":4}},{"line":519,"address":[],"length":0,"stats":{"Line":4}},{"line":520,"address":[],"length":0,"stats":{"Line":6}},{"line":521,"address":[],"length":0,"stats":{"Line":4}},{"line":522,"address":[],"length":0,"stats":{"Line":4}},{"line":523,"address":[],"length":0,"stats":{"Line":2}},{"line":528,"address":[],"length":0,"stats":{"Line":2}},{"line":532,"address":[],"length":0,"stats":{"Line":79}},{"line":533,"address":[],"length":0,"stats":{"Line":79}},{"line":534,"address":[],"length":0,"stats":{"Line":79}},{"line":535,"address":[],"length":0,"stats":{"Line":237}},{"line":539,"address":[],"length":0,"stats":{"Line":8}},{"line":540,"address":[],"length":0,"stats":{"Line":8}},{"line":541,"address":[],"length":0,"stats":{"Line":5}},{"line":544,"address":[],"length":0,"stats":{"Line":15}},{"line":545,"address":[],"length":0,"stats":{"Line":3}},{"line":546,"address":[],"length":0,"stats":{"Line":0}},{"line":549,"address":[],"length":0,"stats":{"Line":6}},{"line":550,"address":[],"length":0,"stats":{"Line":3}}],"covered":126,"coverable":193},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","hindsight","retrieval.rs"],"content":"use std::collections::HashSet;\nuse std::sync::Arc;\n\nuse mk_core::types::{ErrorSignature, HindsightNote};\nuse storage::postgres::{PostgresBackend, PostgresError};\nuse tracing::{Instrument, info_span};\n\n#[derive(Debug, Clone)]\npub struct HindsightRetrievalConfig {\n    pub max_results: usize,\n    pub max_candidate_notes: usize,\n    pub relevance_threshold: f32,\n    pub semantic_threshold: f32,\n    pub recency_weight: f32,\n    pub success_weight: f32,\n    pub enable_tag_filtering: bool,\n}\n\nimpl Default for HindsightRetrievalConfig {\n    fn default() -> Self {\n        Self {\n            max_results: 5,\n            max_candidate_notes: 50,\n            relevance_threshold: 0.4,\n            semantic_threshold: 0.8,\n            recency_weight: 0.2,\n            success_weight: 0.2,\n            enable_tag_filtering: true,\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct HindsightRetrievalFilter {\n    pub tags: Option<Vec<String>>,\n    pub min_success_rate: Option<f32>,\n    pub created_after: Option<i64>,\n    pub created_before: Option<i64>,\n}\n\nimpl Default for HindsightRetrievalFilter {\n    fn default() -> Self {\n        Self {\n            tags: None,\n            min_success_rate: None,\n            created_after: None,\n            created_before: None,\n        }\n    }\n}\n\nimpl HindsightRetrievalFilter {\n    pub fn with_tags(mut self, tags: Vec<String>) -> Self {\n        self.tags = Some(tags);\n        self\n    }\n\n    pub fn with_min_success_rate(mut self, rate: f32) -> Self {\n        self.min_success_rate = Some(rate);\n        self\n    }\n\n    pub fn created_after(mut self, ts: i64) -> Self {\n        self.created_after = Some(ts);\n        self\n    }\n\n    pub fn created_before(mut self, ts: i64) -> Self {\n        self.created_before = Some(ts);\n        self\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct ScoredHindsightNote {\n    pub note: HindsightNote,\n    pub relevance_score: f32,\n    pub recency_score: f32,\n    pub success_score: f32,\n    pub combined_score: f32,\n}\n\nimpl ScoredHindsightNote {\n    fn new(\n        note: HindsightNote,\n        relevance_score: f32,\n        recency_score: f32,\n        success_score: f32,\n        config: &HindsightRetrievalConfig,\n    ) -> Self {\n        let relevance_weight = 1.0 - config.recency_weight - config.success_weight;\n        let combined_score = relevance_score * relevance_weight\n            + recency_score * config.recency_weight\n            + success_score * config.success_weight;\n\n        Self {\n            note,\n            relevance_score,\n            recency_score,\n            success_score,\n            combined_score,\n        }\n    }\n}\n\npub struct HindsightRetriever {\n    storage: Arc<PostgresBackend>,\n    config: HindsightRetrievalConfig,\n}\n\nimpl HindsightRetriever {\n    pub fn new(storage: Arc<PostgresBackend>, config: HindsightRetrievalConfig) -> Self {\n        Self { storage, config }\n    }\n\n    pub async fn retrieve(\n        &self,\n        tenant_id: &str,\n        error: &ErrorSignature,\n        filter: Option<&HindsightRetrievalFilter>,\n    ) -> Result<Vec<ScoredHindsightNote>, PostgresError> {\n        let span = info_span!(\n            \"retrieve_hindsight_notes\",\n            tenant_id,\n            error_type = %error.error_type,\n            has_filter = filter.is_some(),\n            max_candidates = self.config.max_candidate_notes\n        );\n\n        async move {\n            let notes = self\n                .storage\n                .list_hindsight_notes(tenant_id, self.config.max_candidate_notes as i64, 0)\n                .await?;\n\n            Ok(rank_notes(error, &notes, &self.config, filter))\n        }\n        .instrument(span)\n        .await\n    }\n}\n\nfn rank_notes(\n    error: &ErrorSignature,\n    notes: &[HindsightNote],\n    config: &HindsightRetrievalConfig,\n    filter: Option<&HindsightRetrievalFilter>,\n) -> Vec<ScoredHindsightNote> {\n    let now = chrono::Utc::now().timestamp();\n\n    let mut scored: Vec<ScoredHindsightNote> = notes\n        .iter()\n        .filter(|note| matches_filter(note, config, filter))\n        .filter_map(|note| {\n            let relevance = relevance_score(error, note, config);\n            if relevance < config.relevance_threshold {\n                return None;\n            }\n            let recency = recency_score(note.created_at, now);\n            let success = success_score(note);\n            Some(ScoredHindsightNote::new(\n                note.clone(),\n                relevance,\n                recency,\n                success,\n                config,\n            ))\n        })\n        .collect();\n\n    scored.sort_by(|a, b| {\n        b.combined_score\n            .partial_cmp(&a.combined_score)\n            .unwrap_or(std::cmp::Ordering::Equal)\n    });\n\n    scored.truncate(config.max_results);\n    scored\n}\n\nfn matches_filter(\n    note: &HindsightNote,\n    config: &HindsightRetrievalConfig,\n    filter: Option<&HindsightRetrievalFilter>,\n) -> bool {\n    let Some(filter) = filter else {\n        return true;\n    };\n\n    if let Some(min_success) = filter.min_success_rate {\n        if success_score(note) < min_success {\n            return false;\n        }\n    }\n\n    if let Some(after) = filter.created_after {\n        if note.created_at < after {\n            return false;\n        }\n    }\n\n    if let Some(before) = filter.created_before {\n        if note.created_at > before {\n            return false;\n        }\n    }\n\n    if config.enable_tag_filtering {\n        if let Some(tags) = &filter.tags {\n            if !tags.is_empty() {\n                let matches = tags.iter().any(|tag| note.tags.contains(tag));\n                if !matches {\n                    return false;\n                }\n            }\n        }\n    }\n\n    true\n}\n\nfn relevance_score(\n    error: &ErrorSignature,\n    note: &HindsightNote,\n    config: &HindsightRetrievalConfig,\n) -> f32 {\n    if let (Some(query_vec), Some(note_vec)) = (\n        error.embedding.as_ref(),\n        note.error_signature.embedding.as_ref(),\n    ) {\n        let sim = cosine_similarity(query_vec, note_vec);\n        if sim >= config.semantic_threshold {\n            return sim;\n        }\n    }\n\n    let mut score = 0.0;\n\n    if error.error_type == note.error_signature.error_type {\n        score += 0.6;\n    }\n\n    let msg_sim = jaccard_similarity(\n        &tokenize(&error.message_pattern),\n        &tokenize(&note.error_signature.message_pattern),\n    );\n    score += msg_sim * 0.3;\n\n    let ctx_sim = jaccard_similarity(\n        &error.context_patterns,\n        &note.error_signature.context_patterns,\n    );\n    score += ctx_sim * 0.1;\n\n    score\n}\n\nfn success_score(note: &HindsightNote) -> f32 {\n    note.resolutions\n        .iter()\n        .map(|r| r.success_rate)\n        .fold(0.0_f32, f32::max)\n}\n\nfn recency_score(created_at: i64, now: i64) -> f32 {\n    if now <= created_at {\n        return 1.0;\n    }\n\n    let age_seconds = (now - created_at) as f32;\n    let one_week = 604800.0_f32;\n\n    let score = 1.0 - (age_seconds / one_week).min(1.0);\n    score.max(0.0)\n}\n\nfn cosine_similarity(a: &[f32], b: &[f32]) -> f32 {\n    if a.len() != b.len() || a.is_empty() {\n        return 0.0;\n    }\n\n    let dot: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();\n    let norm_a: f32 = a.iter().map(|x| x * x).sum::<f32>().sqrt();\n    let norm_b: f32 = b.iter().map(|x| x * x).sum::<f32>().sqrt();\n\n    if norm_a == 0.0 || norm_b == 0.0 {\n        return 0.0;\n    }\n\n    dot / (norm_a * norm_b)\n}\n\nfn tokenize(input: &str) -> Vec<String> {\n    input\n        .split(|c: char| !c.is_alphanumeric())\n        .filter(|s| !s.is_empty())\n        .map(|s| s.to_lowercase())\n        .collect()\n}\n\nfn jaccard_similarity(a: &[String], b: &[String]) -> f32 {\n    if a.is_empty() || b.is_empty() {\n        return 0.0;\n    }\n\n    let a_set: HashSet<_> = a.iter().collect();\n    let b_set: HashSet<_> = b.iter().collect();\n\n    let intersection = a_set.intersection(&b_set).count() as f32;\n    let union = a_set.union(&b_set).count() as f32;\n\n    if union == 0.0 {\n        0.0\n    } else {\n        intersection / union\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::Resolution;\n\n    fn signature(error_type: &str, message: &str) -> ErrorSignature {\n        ErrorSignature {\n            error_type: error_type.to_string(),\n            message_pattern: message.to_string(),\n            stack_patterns: vec![],\n            context_patterns: vec![\"tool:cargo_test\".to_string()],\n            embedding: None,\n        }\n    }\n\n    fn note(id: &str, signature: ErrorSignature, created_at: i64, success: f32) -> HindsightNote {\n        HindsightNote {\n            id: id.to_string(),\n            error_signature: signature,\n            resolutions: vec![Resolution {\n                id: format!(\"res-{id}\"),\n                error_signature_id: \"err\".to_string(),\n                description: \"fix\".to_string(),\n                changes: vec![],\n                success_rate: success,\n                application_count: 1,\n                last_success_at: 0,\n            }],\n            content: \"content\".to_string(),\n            tags: vec![\"rust\".to_string()],\n            created_at,\n            updated_at: created_at,\n        }\n    }\n\n    #[test]\n    fn test_rank_notes_prefers_relevance() {\n        let cfg = HindsightRetrievalConfig {\n            max_results: 2,\n            relevance_threshold: 0.0,\n            recency_weight: 0.0,\n            success_weight: 0.0,\n            ..Default::default()\n        };\n        let err = signature(\"TypeError\", \"cannot read property\");\n        let notes = vec![\n            note(\"1\", signature(\"TypeError\", \"cannot read property\"), 0, 0.5),\n            note(\"2\", signature(\"Other\", \"different\"), 0, 0.5),\n        ];\n\n        let ranked = rank_notes(&err, &notes, &cfg, None);\n\n        assert_eq!(ranked.len(), 2);\n        assert_eq!(ranked[0].note.id, \"1\");\n    }\n\n    #[test]\n    fn test_rank_notes_filters_by_tags() {\n        let cfg = HindsightRetrievalConfig {\n            max_results: 2,\n            relevance_threshold: 0.0,\n            ..Default::default()\n        };\n        let err = signature(\"TypeError\", \"cannot read property\");\n        let note1 = note(\"1\", signature(\"TypeError\", \"cannot read property\"), 0, 0.5);\n        let mut note2 = note(\"2\", signature(\"TypeError\", \"cannot read property\"), 0, 0.5);\n        note2.tags = vec![\"python\".to_string()];\n        let filter = HindsightRetrievalFilter::default().with_tags(vec![\"rust\".to_string()]);\n\n        let ranked = rank_notes(&err, &[note1, note2], &cfg, Some(&filter));\n\n        assert_eq!(ranked.len(), 1);\n        assert_eq!(ranked[0].note.id, \"1\");\n    }\n\n    #[test]\n    fn test_rank_notes_filters_by_success_rate() {\n        let cfg = HindsightRetrievalConfig {\n            max_results: 5,\n            relevance_threshold: 0.0,\n            ..Default::default()\n        };\n        let err = signature(\"TypeError\", \"cannot read property\");\n        let notes = vec![\n            note(\"1\", signature(\"TypeError\", \"cannot read property\"), 0, 0.3),\n            note(\"2\", signature(\"TypeError\", \"cannot read property\"), 0, 0.9),\n        ];\n        let filter = HindsightRetrievalFilter::default().with_min_success_rate(0.5);\n\n        let ranked = rank_notes(&err, &notes, &cfg, Some(&filter));\n\n        assert_eq!(ranked.len(), 1);\n        assert_eq!(ranked[0].note.id, \"2\");\n    }\n\n    #[test]\n    fn test_rank_notes_recency_weight() {\n        let cfg = HindsightRetrievalConfig {\n            max_results: 2,\n            relevance_threshold: 0.0,\n            recency_weight: 0.5,\n            success_weight: 0.0,\n            ..Default::default()\n        };\n        let err = signature(\"TypeError\", \"cannot read property\");\n        let now = chrono::Utc::now().timestamp();\n        let notes = vec![\n            note(\n                \"1\",\n                signature(\"TypeError\", \"cannot read property\"),\n                now - 604800,\n                0.5,\n            ),\n            note(\n                \"2\",\n                signature(\"TypeError\", \"cannot read property\"),\n                now,\n                0.5,\n            ),\n        ];\n\n        let ranked = rank_notes(&err, &notes, &cfg, None);\n\n        assert_eq!(ranked[0].note.id, \"2\");\n        assert!(ranked[0].recency_score > ranked[1].recency_score);\n    }\n\n    #[test]\n    fn test_rank_notes_success_weight() {\n        let cfg = HindsightRetrievalConfig {\n            max_results: 2,\n            relevance_threshold: 0.0,\n            recency_weight: 0.0,\n            success_weight: 0.5,\n            ..Default::default()\n        };\n        let err = signature(\"TypeError\", \"cannot read property\");\n        let notes = vec![\n            note(\"1\", signature(\"TypeError\", \"cannot read property\"), 0, 0.2),\n            note(\"2\", signature(\"TypeError\", \"cannot read property\"), 0, 0.9),\n        ];\n\n        let ranked = rank_notes(&err, &notes, &cfg, None);\n\n        assert_eq!(ranked[0].note.id, \"2\");\n        assert!(ranked[0].success_score > ranked[1].success_score);\n    }\n\n    #[test]\n    fn test_cosine_similarity_valid() {\n        let a = vec![1.0, 0.0, 0.0];\n        let b = vec![1.0, 0.0, 0.0];\n        let sim = cosine_similarity(&a, &b);\n        assert!((sim - 1.0).abs() < 0.001);\n    }\n}\n","traces":[{"line":20,"address":[],"length":0,"stats":{"Line":5}},{"line":42,"address":[],"length":0,"stats":{"Line":2}},{"line":53,"address":[],"length":0,"stats":{"Line":1}},{"line":54,"address":[],"length":0,"stats":{"Line":2}},{"line":55,"address":[],"length":0,"stats":{"Line":1}},{"line":58,"address":[],"length":0,"stats":{"Line":1}},{"line":59,"address":[],"length":0,"stats":{"Line":1}},{"line":60,"address":[],"length":0,"stats":{"Line":1}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":8}},{"line":91,"address":[],"length":0,"stats":{"Line":16}},{"line":92,"address":[],"length":0,"stats":{"Line":32}},{"line":93,"address":[],"length":0,"stats":{"Line":16}},{"line":94,"address":[],"length":0,"stats":{"Line":8}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":5}},{"line":149,"address":[],"length":0,"stats":{"Line":15}},{"line":151,"address":[],"length":0,"stats":{"Line":15}},{"line":153,"address":[],"length":0,"stats":{"Line":45}},{"line":154,"address":[],"length":0,"stats":{"Line":13}},{"line":155,"address":[],"length":0,"stats":{"Line":40}},{"line":156,"address":[],"length":0,"stats":{"Line":8}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":32}},{"line":160,"address":[],"length":0,"stats":{"Line":24}},{"line":161,"address":[],"length":0,"stats":{"Line":16}},{"line":162,"address":[],"length":0,"stats":{"Line":24}},{"line":163,"address":[],"length":0,"stats":{"Line":16}},{"line":164,"address":[],"length":0,"stats":{"Line":16}},{"line":165,"address":[],"length":0,"stats":{"Line":8}},{"line":166,"address":[],"length":0,"stats":{"Line":8}},{"line":171,"address":[],"length":0,"stats":{"Line":13}},{"line":172,"address":[],"length":0,"stats":{"Line":3}},{"line":173,"address":[],"length":0,"stats":{"Line":6}},{"line":174,"address":[],"length":0,"stats":{"Line":6}},{"line":177,"address":[],"length":0,"stats":{"Line":15}},{"line":178,"address":[],"length":0,"stats":{"Line":5}},{"line":181,"address":[],"length":0,"stats":{"Line":10}},{"line":186,"address":[],"length":0,"stats":{"Line":14}},{"line":187,"address":[],"length":0,"stats":{"Line":6}},{"line":190,"address":[],"length":0,"stats":{"Line":6}},{"line":191,"address":[],"length":0,"stats":{"Line":4}},{"line":192,"address":[],"length":0,"stats":{"Line":1}},{"line":196,"address":[],"length":0,"stats":{"Line":3}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":3}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":204,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":3}},{"line":209,"address":[],"length":0,"stats":{"Line":5}},{"line":210,"address":[],"length":0,"stats":{"Line":2}},{"line":211,"address":[],"length":0,"stats":{"Line":12}},{"line":212,"address":[],"length":0,"stats":{"Line":2}},{"line":213,"address":[],"length":0,"stats":{"Line":1}},{"line":219,"address":[],"length":0,"stats":{"Line":2}},{"line":222,"address":[],"length":0,"stats":{"Line":8}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":16}},{"line":229,"address":[],"length":0,"stats":{"Line":16}},{"line":231,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":16}},{"line":239,"address":[],"length":0,"stats":{"Line":15}},{"line":240,"address":[],"length":0,"stats":{"Line":7}},{"line":244,"address":[],"length":0,"stats":{"Line":8}},{"line":245,"address":[],"length":0,"stats":{"Line":8}},{"line":247,"address":[],"length":0,"stats":{"Line":8}},{"line":250,"address":[],"length":0,"stats":{"Line":8}},{"line":251,"address":[],"length":0,"stats":{"Line":8}},{"line":253,"address":[],"length":0,"stats":{"Line":8}},{"line":255,"address":[],"length":0,"stats":{"Line":8}},{"line":258,"address":[],"length":0,"stats":{"Line":10}},{"line":259,"address":[],"length":0,"stats":{"Line":10}},{"line":261,"address":[],"length":0,"stats":{"Line":10}},{"line":262,"address":[],"length":0,"stats":{"Line":10}},{"line":265,"address":[],"length":0,"stats":{"Line":8}},{"line":266,"address":[],"length":0,"stats":{"Line":8}},{"line":267,"address":[],"length":0,"stats":{"Line":1}},{"line":270,"address":[],"length":0,"stats":{"Line":14}},{"line":271,"address":[],"length":0,"stats":{"Line":14}},{"line":273,"address":[],"length":0,"stats":{"Line":14}},{"line":274,"address":[],"length":0,"stats":{"Line":14}},{"line":277,"address":[],"length":0,"stats":{"Line":1}},{"line":278,"address":[],"length":0,"stats":{"Line":5}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":15}},{"line":283,"address":[],"length":0,"stats":{"Line":13}},{"line":284,"address":[],"length":0,"stats":{"Line":13}},{"line":286,"address":[],"length":0,"stats":{"Line":2}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":2}},{"line":293,"address":[],"length":0,"stats":{"Line":16}},{"line":294,"address":[],"length":0,"stats":{"Line":16}},{"line":295,"address":[],"length":0,"stats":{"Line":634}},{"line":296,"address":[],"length":0,"stats":{"Line":108}},{"line":297,"address":[],"length":0,"stats":{"Line":108}},{"line":301,"address":[],"length":0,"stats":{"Line":16}},{"line":302,"address":[],"length":0,"stats":{"Line":64}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":306,"address":[],"length":0,"stats":{"Line":80}},{"line":307,"address":[],"length":0,"stats":{"Line":80}},{"line":309,"address":[],"length":0,"stats":{"Line":64}},{"line":310,"address":[],"length":0,"stats":{"Line":64}},{"line":312,"address":[],"length":0,"stats":{"Line":16}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":16}}],"covered":93,"coverable":124},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","hot_reload.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","lib.rs"],"content":"//! # Knowledge Repository\n//!\n//! Git-based knowledge management with governance.\n\npub mod api;\npub mod context_architect;\npub mod durable_events;\npub mod federation;\npub mod governance;\npub mod governance_client;\npub mod hindsight;\npub mod meta_agent;\npub mod note_taking;\npub mod repository;\npub mod scheduler;\npub mod telemetry;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","loader.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","meta_agent","build.rs"],"content":"use std::sync::Arc;\n\nuse crate::context_architect::LlmClient;\nuse tracing::{Instrument, info_span};\n\nuse super::{BuildResult, HindsightLookup, HindsightStore, MetaAgentConfig, NoteLookup, NoteStore};\n\n#[derive(Debug, Clone)]\npub struct BuildPhaseConfig {\n    pub max_tokens: u32,\n}\n\nimpl Default for BuildPhaseConfig {\n    fn default() -> Self {\n        Self { max_tokens: 1200 }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct BuildPromptTemplate {\n    pub system: String,\n    pub user: String,\n}\n\n#[derive(Debug, Clone)]\npub struct BuildPromptTemplates {\n    pub default: BuildPromptTemplate,\n}\n\nimpl Default for BuildPromptTemplates {\n    fn default() -> Self {\n        Self {\n            default: BuildPromptTemplate {\n                system: DEFAULT_SYSTEM.to_string(),\n                user: DEFAULT_USER.to_string(),\n            },\n        }\n    }\n}\n\npub struct BuildPhase<C: LlmClient> {\n    client: Arc<C>,\n    config: BuildPhaseConfig,\n    prompt_templates: BuildPromptTemplates,\n    note_lookup: Option<Arc<dyn NoteLookup>>,\n    hindsight_lookup: Option<Arc<dyn HindsightLookup>>,\n    note_store: Option<Arc<dyn NoteStore>>,\n    hindsight_store: Option<Arc<dyn HindsightStore>>,\n    meta_config: MetaAgentConfig,\n}\n\nimpl<C: LlmClient> BuildPhase<C> {\n    pub fn new(client: Arc<C>, config: BuildPhaseConfig) -> Self {\n        Self {\n            client,\n            config,\n            prompt_templates: BuildPromptTemplates::default(),\n            note_lookup: None,\n            hindsight_lookup: None,\n            note_store: None,\n            hindsight_store: None,\n            meta_config: MetaAgentConfig::default(),\n        }\n    }\n\n    pub fn with_prompts(mut self, templates: BuildPromptTemplates) -> Self {\n        self.prompt_templates = templates;\n        self\n    }\n\n    pub fn with_note_lookup(mut self, lookup: Arc<dyn NoteLookup>) -> Self {\n        self.note_lookup = Some(lookup);\n        self\n    }\n\n    pub fn with_hindsight_lookup(mut self, lookup: Arc<dyn HindsightLookup>) -> Self {\n        self.hindsight_lookup = Some(lookup);\n        self\n    }\n\n    pub fn with_note_store(mut self, store: Arc<dyn NoteStore>) -> Self {\n        self.note_store = Some(store);\n        self\n    }\n\n    pub fn with_hindsight_store(mut self, store: Arc<dyn HindsightStore>) -> Self {\n        self.hindsight_store = Some(store);\n        self\n    }\n\n    pub fn with_meta_config(mut self, config: MetaAgentConfig) -> Self {\n        self.meta_config = config;\n        self\n    }\n\n    pub async fn execute(\n        &self,\n        requirements: &str,\n        context: Option<&str>,\n    ) -> Result<BuildResult, crate::context_architect::LlmError> {\n        let span = info_span!(\n            \"build_phase\",\n            requirements_len = requirements.len(),\n            has_context = context.is_some(),\n            has_note_store = self.note_store.is_some(),\n            has_hindsight_store = self.hindsight_store.is_some(),\n            note_limit = self.meta_config.note_limit,\n            hindsight_limit = self.meta_config.hindsight_limit\n        );\n\n        async move {\n            let notes = match (&self.note_store, &self.note_lookup) {\n                (Some(store), _) => {\n                    store\n                        .retrieve(requirements, self.meta_config.note_limit)\n                        .await\n                }\n                (None, Some(lookup)) => {\n                    lookup\n                        .retrieve(requirements, self.meta_config.note_limit)\n                        .await\n                }\n                _ => Vec::new(),\n            };\n            let hindsight = match (&self.hindsight_store, &self.hindsight_lookup) {\n                (Some(store), _) => {\n                    store\n                        .retrieve(requirements, self.meta_config.hindsight_limit)\n                        .await\n                }\n                (None, Some(lookup)) => {\n                    lookup\n                        .retrieve(requirements, self.meta_config.hindsight_limit)\n                        .await\n                }\n                _ => Vec::new(),\n            };\n\n            let (system, user) = self.build_prompt(requirements, context, &notes, &hindsight);\n            let response = self.client.complete_with_system(&system, &user).await?;\n\n            Ok(BuildResult {\n                output: response.clone(),\n                notes,\n                hindsight,\n                tokens_used: estimate_tokens(&response),\n            })\n        }\n        .instrument(span)\n        .await\n    }\n\n    fn build_prompt(\n        &self,\n        requirements: &str,\n        context: Option<&str>,\n        notes: &[String],\n        hindsight: &[String],\n    ) -> (String, String) {\n        let notes_block = format_list(notes);\n        let hindsight_block = format_list(hindsight);\n        let context_block = context.unwrap_or(\"None\");\n        let view_mode = format!(\"{:?}\", self.meta_config.view_mode);\n\n        let user = self\n            .prompt_templates\n            .default\n            .user\n            .replace(\"{requirements}\", requirements)\n            .replace(\"{context}\", context_block)\n            .replace(\"{notes}\", &notes_block)\n            .replace(\"{hindsight}\", &hindsight_block)\n            .replace(\"{view_mode}\", &view_mode)\n            .replace(\"{max_tokens}\", &self.config.max_tokens.to_string());\n\n        (self.prompt_templates.default.system.clone(), user)\n    }\n}\n\nfn format_list(items: &[String]) -> String {\n    if items.is_empty() {\n        \"None\".to_string()\n    } else {\n        let mut out = String::new();\n        for item in items {\n            out.push_str(\"- \");\n            out.push_str(item);\n            out.push('\\n');\n        }\n        out.trim_end().to_string()\n    }\n}\n\nfn estimate_tokens(text: &str) -> u32 {\n    let word_count = text.split_whitespace().count();\n    let char_count = text.chars().count();\n    let char_based = (char_count as f64 / 4.0).ceil() as u32;\n    let word_based = (word_count as f64 * 1.3).ceil() as u32;\n    char_based.max(word_based)\n}\n\nconst DEFAULT_SYSTEM: &str = \"You are a build assistant that generates code or instructions based \\\n                              on requirements. Use provided notes and hindsight to avoid known \\\n                              pitfalls.\";\n\nconst DEFAULT_USER: &str = \"Requirements:\\n{requirements}\\n\\nContext:\\n{context}\\n\\nNotes:\\\\\n                            n{notes}\\n\\nHindsight:\\n{hindsight}\\n\\nView mode: \\\n                            {view_mode}\\n\\nProvide the implementation plan or code changes. Keep \\\n                            it under {max_tokens} tokens.\";\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::context_architect::LlmError;\n    use async_trait::async_trait;\n    use std::sync::Mutex;\n\n    struct MockLlmClient {\n        responses: Mutex<Vec<String>>,\n    }\n\n    impl MockLlmClient {\n        fn new(responses: Vec<String>) -> Self {\n            Self {\n                responses: Mutex::new(responses),\n            }\n        }\n    }\n\n    #[async_trait]\n    impl LlmClient for MockLlmClient {\n        async fn complete(&self, _prompt: &str) -> Result<String, LlmError> {\n            let mut responses = self.responses.lock().unwrap();\n            responses\n                .pop()\n                .ok_or_else(|| LlmError::InvalidResponse(\"No mock response\".into()))\n        }\n\n        async fn complete_with_system(\n            &self,\n            _system: &str,\n            _user: &str,\n        ) -> Result<String, LlmError> {\n            let mut responses = self.responses.lock().unwrap();\n            responses\n                .pop()\n                .ok_or_else(|| LlmError::InvalidResponse(\"No mock response\".into()))\n        }\n    }\n\n    struct MockLookup;\n\n    #[async_trait]\n    impl NoteLookup for MockLookup {\n        async fn retrieve(&self, _query: &str, _limit: usize) -> Vec<String> {\n            vec![\"note\".to_string()]\n        }\n    }\n\n    #[async_trait]\n    impl HindsightLookup for MockLookup {\n        async fn retrieve(&self, _query: &str, _limit: usize) -> Vec<String> {\n            vec![\"hindsight\".to_string()]\n        }\n    }\n\n    #[tokio::test]\n    async fn test_build_phase_collects_notes() {\n        let client = Arc::new(MockLlmClient::new(vec![\"output\".to_string()]));\n        let build = BuildPhase::new(client, BuildPhaseConfig::default())\n            .with_note_lookup(Arc::new(MockLookup))\n            .with_hindsight_lookup(Arc::new(MockLookup));\n\n        let result = build.execute(\"req\", None).await.unwrap();\n        assert_eq!(result.output, \"output\");\n        assert_eq!(result.notes, vec![\"note\".to_string()]);\n        assert_eq!(result.hindsight, vec![\"hindsight\".to_string()]);\n    }\n\n    struct MockNoteStore;\n\n    #[async_trait]\n    impl NoteStore for MockNoteStore {\n        async fn add_note(&self, _note: crate::note_taking::GeneratedNote) {}\n\n        async fn retrieve(&self, _query: &str, _limit: usize) -> Vec<String> {\n            vec![\"stored_note\".to_string()]\n        }\n    }\n\n    struct MockHindsightStore;\n\n    #[async_trait]\n    impl HindsightStore for MockHindsightStore {\n        async fn retrieve(&self, _query: &str, _limit: usize) -> Vec<String> {\n            vec![\"stored_hindsight\".to_string()]\n        }\n    }\n\n    #[tokio::test]\n    async fn test_build_phase_uses_note_store_over_lookup() {\n        let client = Arc::new(MockLlmClient::new(vec![\"output\".to_string()]));\n        let build = BuildPhase::new(client, BuildPhaseConfig::default())\n            .with_note_lookup(Arc::new(MockLookup))\n            .with_note_store(Arc::new(MockNoteStore))\n            .with_hindsight_lookup(Arc::new(MockLookup));\n\n        let result = build.execute(\"req\", None).await.unwrap();\n        assert_eq!(result.notes, vec![\"stored_note\".to_string()]);\n        assert_eq!(result.hindsight, vec![\"hindsight\".to_string()]);\n    }\n\n    #[tokio::test]\n    async fn test_build_phase_uses_hindsight_store_over_lookup() {\n        let client = Arc::new(MockLlmClient::new(vec![\"output\".to_string()]));\n        let build = BuildPhase::new(client, BuildPhaseConfig::default())\n            .with_note_lookup(Arc::new(MockLookup))\n            .with_hindsight_store(Arc::new(MockHindsightStore));\n\n        let result = build.execute(\"req\", None).await.unwrap();\n        assert_eq!(result.notes, vec![\"note\".to_string()]);\n        assert_eq!(result.hindsight, vec![\"stored_hindsight\".to_string()]);\n    }\n\n    #[tokio::test]\n    async fn test_build_phase_uses_both_stores() {\n        let client = Arc::new(MockLlmClient::new(vec![\"output\".to_string()]));\n        let build = BuildPhase::new(client, BuildPhaseConfig::default())\n            .with_note_store(Arc::new(MockNoteStore))\n            .with_hindsight_store(Arc::new(MockHindsightStore));\n\n        let result = build.execute(\"req\", None).await.unwrap();\n        assert_eq!(result.notes, vec![\"stored_note\".to_string()]);\n        assert_eq!(result.hindsight, vec![\"stored_hindsight\".to_string()]);\n    }\n\n    #[tokio::test]\n    async fn test_build_phase_with_view_mode() {\n        use crate::meta_agent::ViewMode;\n\n        let client = Arc::new(MockLlmClient::new(vec![\"output\".to_string()]));\n        let config = MetaAgentConfig {\n            view_mode: ViewMode::Ax,\n            ..Default::default()\n        };\n        let build = BuildPhase::new(client, BuildPhaseConfig::default()).with_meta_config(config);\n\n        let result = build.execute(\"req\", None).await.unwrap();\n        assert_eq!(result.output, \"output\");\n    }\n}\n","traces":[{"line":14,"address":[],"length":0,"stats":{"Line":9}},{"line":31,"address":[],"length":0,"stats":{"Line":9}},{"line":33,"address":[],"length":0,"stats":{"Line":9}},{"line":53,"address":[],"length":0,"stats":{"Line":9}},{"line":57,"address":[],"length":0,"stats":{"Line":18}},{"line":62,"address":[],"length":0,"stats":{"Line":9}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":3}},{"line":72,"address":[],"length":0,"stats":{"Line":6}},{"line":73,"address":[],"length":0,"stats":{"Line":3}},{"line":76,"address":[],"length":0,"stats":{"Line":2}},{"line":77,"address":[],"length":0,"stats":{"Line":4}},{"line":78,"address":[],"length":0,"stats":{"Line":2}},{"line":81,"address":[],"length":0,"stats":{"Line":2}},{"line":82,"address":[],"length":0,"stats":{"Line":4}},{"line":83,"address":[],"length":0,"stats":{"Line":2}},{"line":86,"address":[],"length":0,"stats":{"Line":2}},{"line":87,"address":[],"length":0,"stats":{"Line":4}},{"line":88,"address":[],"length":0,"stats":{"Line":2}},{"line":91,"address":[],"length":0,"stats":{"Line":1}},{"line":92,"address":[],"length":0,"stats":{"Line":1}},{"line":93,"address":[],"length":0,"stats":{"Line":1}},{"line":96,"address":[],"length":0,"stats":{"Line":8}},{"line":101,"address":[],"length":0,"stats":{"Line":16}},{"line":103,"address":[],"length":0,"stats":{"Line":16}},{"line":104,"address":[],"length":0,"stats":{"Line":16}},{"line":105,"address":[],"length":0,"stats":{"Line":16}},{"line":106,"address":[],"length":0,"stats":{"Line":16}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":8}},{"line":112,"address":[],"length":0,"stats":{"Line":24}},{"line":113,"address":[],"length":0,"stats":{"Line":2}},{"line":114,"address":[],"length":0,"stats":{"Line":4}},{"line":115,"address":[],"length":0,"stats":{"Line":4}},{"line":116,"address":[],"length":0,"stats":{"Line":2}},{"line":118,"address":[],"length":0,"stats":{"Line":2}},{"line":119,"address":[],"length":0,"stats":{"Line":4}},{"line":120,"address":[],"length":0,"stats":{"Line":4}},{"line":121,"address":[],"length":0,"stats":{"Line":2}},{"line":123,"address":[],"length":0,"stats":{"Line":4}},{"line":125,"address":[],"length":0,"stats":{"Line":24}},{"line":126,"address":[],"length":0,"stats":{"Line":2}},{"line":127,"address":[],"length":0,"stats":{"Line":4}},{"line":128,"address":[],"length":0,"stats":{"Line":4}},{"line":129,"address":[],"length":0,"stats":{"Line":2}},{"line":131,"address":[],"length":0,"stats":{"Line":2}},{"line":132,"address":[],"length":0,"stats":{"Line":4}},{"line":133,"address":[],"length":0,"stats":{"Line":4}},{"line":134,"address":[],"length":0,"stats":{"Line":2}},{"line":136,"address":[],"length":0,"stats":{"Line":4}},{"line":139,"address":[],"length":0,"stats":{"Line":56}},{"line":140,"address":[],"length":0,"stats":{"Line":32}},{"line":142,"address":[],"length":0,"stats":{"Line":8}},{"line":143,"address":[],"length":0,"stats":{"Line":24}},{"line":144,"address":[],"length":0,"stats":{"Line":16}},{"line":145,"address":[],"length":0,"stats":{"Line":16}},{"line":146,"address":[],"length":0,"stats":{"Line":8}},{"line":149,"address":[],"length":0,"stats":{"Line":16}},{"line":150,"address":[],"length":0,"stats":{"Line":8}},{"line":153,"address":[],"length":0,"stats":{"Line":8}},{"line":160,"address":[],"length":0,"stats":{"Line":24}},{"line":161,"address":[],"length":0,"stats":{"Line":24}},{"line":162,"address":[],"length":0,"stats":{"Line":32}},{"line":163,"address":[],"length":0,"stats":{"Line":24}},{"line":165,"address":[],"length":0,"stats":{"Line":64}},{"line":166,"address":[],"length":0,"stats":{"Line":56}},{"line":167,"address":[],"length":0,"stats":{"Line":56}},{"line":168,"address":[],"length":0,"stats":{"Line":56}},{"line":169,"address":[],"length":0,"stats":{"Line":48}},{"line":170,"address":[],"length":0,"stats":{"Line":40}},{"line":171,"address":[],"length":0,"stats":{"Line":32}},{"line":172,"address":[],"length":0,"stats":{"Line":24}},{"line":173,"address":[],"length":0,"stats":{"Line":16}},{"line":174,"address":[],"length":0,"stats":{"Line":16}},{"line":176,"address":[],"length":0,"stats":{"Line":16}},{"line":180,"address":[],"length":0,"stats":{"Line":16}},{"line":181,"address":[],"length":0,"stats":{"Line":32}},{"line":182,"address":[],"length":0,"stats":{"Line":16}},{"line":184,"address":[],"length":0,"stats":{"Line":16}},{"line":185,"address":[],"length":0,"stats":{"Line":32}},{"line":186,"address":[],"length":0,"stats":{"Line":32}},{"line":187,"address":[],"length":0,"stats":{"Line":32}},{"line":188,"address":[],"length":0,"stats":{"Line":8}},{"line":190,"address":[],"length":0,"stats":{"Line":16}},{"line":194,"address":[],"length":0,"stats":{"Line":8}},{"line":195,"address":[],"length":0,"stats":{"Line":32}},{"line":196,"address":[],"length":0,"stats":{"Line":32}},{"line":197,"address":[],"length":0,"stats":{"Line":16}},{"line":198,"address":[],"length":0,"stats":{"Line":16}},{"line":199,"address":[],"length":0,"stats":{"Line":24}}],"covered":88,"coverable":93},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","meta_agent","improve.rs"],"content":"use std::sync::Arc;\n\nuse crate::context_architect::LlmClient;\nuse tracing::{Instrument, info_span};\n\nuse super::{HindsightLookup, HindsightStore, ImproveAction, ImproveResult, TestResult};\n\n#[derive(Debug, Clone)]\npub struct ImprovePhaseConfig {\n    pub max_tokens: u32,\n}\n\nimpl Default for ImprovePhaseConfig {\n    fn default() -> Self {\n        Self { max_tokens: 800 }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct ImprovePromptTemplate {\n    pub system: String,\n    pub user: String,\n}\n\n#[derive(Debug, Clone)]\npub struct ImprovePromptTemplates {\n    pub default: ImprovePromptTemplate,\n}\n\nimpl Default for ImprovePromptTemplates {\n    fn default() -> Self {\n        Self {\n            default: ImprovePromptTemplate {\n                system: DEFAULT_SYSTEM.to_string(),\n                user: DEFAULT_USER.to_string(),\n            },\n        }\n    }\n}\n\npub struct ImprovePhase<C: LlmClient> {\n    client: Arc<C>,\n    config: ImprovePhaseConfig,\n    prompt_templates: ImprovePromptTemplates,\n    hindsight_lookup: Option<Arc<dyn HindsightLookup>>,\n    hindsight_store: Option<Arc<dyn HindsightStore>>,\n}\n\nimpl<C: LlmClient> ImprovePhase<C> {\n    pub fn new(client: Arc<C>, config: ImprovePhaseConfig) -> Self {\n        Self {\n            client,\n            config,\n            prompt_templates: ImprovePromptTemplates::default(),\n            hindsight_lookup: None,\n            hindsight_store: None,\n        }\n    }\n\n    pub fn with_prompts(mut self, templates: ImprovePromptTemplates) -> Self {\n        self.prompt_templates = templates;\n        self\n    }\n\n    pub fn with_hindsight_lookup(mut self, lookup: Arc<dyn HindsightLookup>) -> Self {\n        self.hindsight_lookup = Some(lookup);\n        self\n    }\n\n    pub fn with_hindsight_store(mut self, store: Arc<dyn HindsightStore>) -> Self {\n        self.hindsight_store = Some(store);\n        self\n    }\n\n    pub async fn execute(\n        &self,\n        test_result: &TestResult,\n    ) -> Result<ImproveResult, crate::context_architect::LlmError> {\n        let span = info_span!(\n            \"improve_phase\",\n            test_status = ?test_result.status,\n            test_output_len = test_result.output.len(),\n            test_duration_ms = test_result.duration_ms,\n            has_hindsight_store = self.hindsight_store.is_some(),\n            has_hindsight_lookup = self.hindsight_lookup.is_some()\n        );\n\n        async move {\n            let hindsight = match (&self.hindsight_store, &self.hindsight_lookup) {\n                (Some(store), _) => store.retrieve(&test_result.output, 5).await,\n                (None, Some(lookup)) => lookup.retrieve(&test_result.output, 5).await,\n                _ => Vec::new(),\n            };\n\n            let (system, user) = self.build_prompt(test_result, &hindsight);\n            let response = self.client.complete_with_system(&system, &user).await?;\n\n            let action = if response.to_lowercase().contains(\"escalate\") {\n                ImproveAction::Escalate\n            } else {\n                ImproveAction::Retry\n            };\n\n            let escalation_message = if action == ImproveAction::Escalate {\n                Some(format!(\n                    \"Escalation recommended based on test output:\\n{}\",\n                    test_result.output\n                ))\n            } else {\n                None\n            };\n\n            Ok(ImproveResult {\n                analysis: response,\n                action,\n                escalation_message,\n            })\n        }\n        .instrument(span)\n        .await\n    }\n\n    fn build_prompt(&self, test_result: &TestResult, hindsight: &[String]) -> (String, String) {\n        let hindsight_block = format_list(hindsight);\n        let user = self\n            .prompt_templates\n            .default\n            .user\n            .replace(\"{test_output}\", &test_result.output)\n            .replace(\"{hindsight}\", &hindsight_block)\n            .replace(\"{max_tokens}\", &self.config.max_tokens.to_string());\n        (self.prompt_templates.default.system.clone(), user)\n    }\n}\n\nfn format_list(items: &[String]) -> String {\n    if items.is_empty() {\n        \"None\".to_string()\n    } else {\n        let mut out = String::new();\n        for item in items {\n            out.push_str(\"- \");\n            out.push_str(item);\n            out.push('\\n');\n        }\n        out.trim_end().to_string()\n    }\n}\n\nconst DEFAULT_SYSTEM: &str = \"You are an improvement assistant. Analyze failures and propose \\\n                              fixes based on test output and hindsight.\";\n\nconst DEFAULT_USER: &str = \"Test output:\\n{test_output}\\n\\nHindsight:\\n{hindsight}\\n\\nProvide a \\\n                            concise analysis and next action. Keep it under {max_tokens} tokens.\";\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::context_architect::LlmError;\n    use crate::meta_agent::TestStatus;\n    use async_trait::async_trait;\n    use std::sync::Mutex;\n\n    struct MockLlmClient {\n        responses: Mutex<Vec<String>>,\n    }\n\n    impl MockLlmClient {\n        fn new(responses: Vec<String>) -> Self {\n            Self {\n                responses: Mutex::new(responses),\n            }\n        }\n    }\n\n    #[async_trait]\n    impl LlmClient for MockLlmClient {\n        async fn complete(&self, _prompt: &str) -> Result<String, LlmError> {\n            let mut responses = self.responses.lock().unwrap();\n            responses\n                .pop()\n                .ok_or_else(|| LlmError::InvalidResponse(\"No mock response\".into()))\n        }\n\n        async fn complete_with_system(\n            &self,\n            _system: &str,\n            _user: &str,\n        ) -> Result<String, LlmError> {\n            let mut responses = self.responses.lock().unwrap();\n            responses\n                .pop()\n                .ok_or_else(|| LlmError::InvalidResponse(\"No mock response\".into()))\n        }\n    }\n\n    #[tokio::test]\n    async fn test_improve_phase_retry() {\n        let client = Arc::new(MockLlmClient::new(vec![\"Retry with fix\".to_string()]));\n        let phase = ImprovePhase::new(client, ImprovePhaseConfig::default());\n        let result = phase\n            .execute(&TestResult {\n                status: TestStatus::Fail,\n                output: \"failed\".to_string(),\n                duration_ms: 1,\n            })\n            .await\n            .unwrap();\n\n        assert_eq!(result.action, ImproveAction::Retry);\n        assert!(result.escalation_message.is_none());\n    }\n\n    struct MockHindsightLookup;\n\n    #[async_trait]\n    impl HindsightLookup for MockHindsightLookup {\n        async fn retrieve(&self, _query: &str, _limit: usize) -> Vec<String> {\n            vec![\"past_hindsight\".to_string()]\n        }\n    }\n\n    struct MockHindsightStore;\n\n    #[async_trait]\n    impl HindsightStore for MockHindsightStore {\n        async fn retrieve(&self, _query: &str, _limit: usize) -> Vec<String> {\n            vec![\"stored_hindsight\".to_string()]\n        }\n    }\n\n    #[tokio::test]\n    async fn test_improve_phase_uses_hindsight_store_over_lookup() {\n        let client = Arc::new(MockLlmClient::new(vec![\"Retry\".to_string()]));\n        let phase = ImprovePhase::new(client, ImprovePhaseConfig::default())\n            .with_hindsight_lookup(Arc::new(MockHindsightLookup))\n            .with_hindsight_store(Arc::new(MockHindsightStore));\n\n        let result = phase\n            .execute(&TestResult {\n                status: TestStatus::Fail,\n                output: \"error\".to_string(),\n                duration_ms: 1,\n            })\n            .await\n            .unwrap();\n\n        assert_eq!(result.action, ImproveAction::Retry);\n    }\n\n    #[tokio::test]\n    async fn test_improve_phase_escalates() {\n        let client = Arc::new(MockLlmClient::new(vec![\n            \"Unable to fix. Escalate to human.\".to_string(),\n        ]));\n        let phase = ImprovePhase::new(client, ImprovePhaseConfig::default());\n\n        let result = phase\n            .execute(&TestResult {\n                status: TestStatus::Fail,\n                output: \"critical error\".to_string(),\n                duration_ms: 1,\n            })\n            .await\n            .unwrap();\n\n        assert_eq!(result.action, ImproveAction::Escalate);\n        assert!(result.escalation_message.is_some());\n    }\n}\n","traces":[{"line":14,"address":[],"length":0,"stats":{"Line":7}},{"line":31,"address":[],"length":0,"stats":{"Line":7}},{"line":33,"address":[],"length":0,"stats":{"Line":7}},{"line":50,"address":[],"length":0,"stats":{"Line":7}},{"line":54,"address":[],"length":0,"stats":{"Line":14}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":1}},{"line":66,"address":[],"length":0,"stats":{"Line":2}},{"line":67,"address":[],"length":0,"stats":{"Line":1}},{"line":70,"address":[],"length":0,"stats":{"Line":1}},{"line":71,"address":[],"length":0,"stats":{"Line":2}},{"line":72,"address":[],"length":0,"stats":{"Line":1}},{"line":75,"address":[],"length":0,"stats":{"Line":3}},{"line":79,"address":[],"length":0,"stats":{"Line":6}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":6}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":6}},{"line":85,"address":[],"length":0,"stats":{"Line":6}},{"line":88,"address":[],"length":0,"stats":{"Line":3}},{"line":89,"address":[],"length":0,"stats":{"Line":9}},{"line":90,"address":[],"length":0,"stats":{"Line":3}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":2}},{"line":95,"address":[],"length":0,"stats":{"Line":15}},{"line":96,"address":[],"length":0,"stats":{"Line":12}},{"line":98,"address":[],"length":0,"stats":{"Line":6}},{"line":99,"address":[],"length":0,"stats":{"Line":1}},{"line":101,"address":[],"length":0,"stats":{"Line":2}},{"line":104,"address":[],"length":0,"stats":{"Line":6}},{"line":105,"address":[],"length":0,"stats":{"Line":1}},{"line":106,"address":[],"length":0,"stats":{"Line":1}},{"line":107,"address":[],"length":0,"stats":{"Line":1}},{"line":110,"address":[],"length":0,"stats":{"Line":2}},{"line":113,"address":[],"length":0,"stats":{"Line":3}},{"line":114,"address":[],"length":0,"stats":{"Line":6}},{"line":115,"address":[],"length":0,"stats":{"Line":3}},{"line":116,"address":[],"length":0,"stats":{"Line":3}},{"line":119,"address":[],"length":0,"stats":{"Line":6}},{"line":120,"address":[],"length":0,"stats":{"Line":3}},{"line":123,"address":[],"length":0,"stats":{"Line":3}},{"line":124,"address":[],"length":0,"stats":{"Line":9}},{"line":125,"address":[],"length":0,"stats":{"Line":15}},{"line":126,"address":[],"length":0,"stats":{"Line":12}},{"line":127,"address":[],"length":0,"stats":{"Line":12}},{"line":128,"address":[],"length":0,"stats":{"Line":12}},{"line":129,"address":[],"length":0,"stats":{"Line":9}},{"line":130,"address":[],"length":0,"stats":{"Line":6}},{"line":131,"address":[],"length":0,"stats":{"Line":6}},{"line":132,"address":[],"length":0,"stats":{"Line":6}},{"line":136,"address":[],"length":0,"stats":{"Line":3}},{"line":137,"address":[],"length":0,"stats":{"Line":6}},{"line":138,"address":[],"length":0,"stats":{"Line":4}},{"line":140,"address":[],"length":0,"stats":{"Line":2}},{"line":141,"address":[],"length":0,"stats":{"Line":4}},{"line":142,"address":[],"length":0,"stats":{"Line":4}},{"line":143,"address":[],"length":0,"stats":{"Line":4}},{"line":144,"address":[],"length":0,"stats":{"Line":1}},{"line":146,"address":[],"length":0,"stats":{"Line":2}}],"covered":55,"coverable":61},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","meta_agent","loop.rs"],"content":"use super::{\n    BuildPhase, BuildResult, ImproveAction, ImprovePhase, ImproveResult, MetaAgentConfig,\n    QualityGateConfig, QualityGateEvaluator, QualityGateSummary, TestCommand, TestPhase,\n    TestResult, TestStatus, TimeBudget, TimeBudgetConfig, TimeBudgetExhaustedResult,\n};\nuse tracing::{Instrument, info_span, warn};\n\n#[derive(Debug, Clone)]\npub struct MetaAgentLoopState {\n    pub iterations: u32,\n    pub last_build: Option<BuildResult>,\n    pub last_test: Option<TestResult>,\n    pub last_improve: Option<ImproveResult>,\n}\n\nimpl Default for MetaAgentLoopState {\n    fn default() -> Self {\n        Self {\n            iterations: 0,\n            last_build: None,\n            last_test: None,\n            last_improve: None,\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct MetaAgentLoopStateExtended {\n    pub iterations: u32,\n    pub last_build: Option<BuildResult>,\n    pub last_test: Option<TestResult>,\n    pub last_improve: Option<ImproveResult>,\n    pub quality_gates: Option<QualityGateSummary>,\n}\n\n#[derive(Debug, Clone)]\npub enum MetaAgentLoopResult {\n    Success {\n        build: BuildResult,\n        test: TestResult,\n        iterations: u32,\n    },\n    Failure {\n        state: MetaAgentLoopState,\n    },\n}\n\n#[derive(Debug, Clone)]\npub enum MetaAgentLoopResultExtended {\n    Success {\n        build: BuildResult,\n        test: TestResult,\n        quality_gates: QualityGateSummary,\n        iterations: u32,\n    },\n    QualityGateFailure {\n        build: BuildResult,\n        test: TestResult,\n        quality_gates: QualityGateSummary,\n        iterations: u32,\n    },\n    Failure {\n        state: MetaAgentLoopStateExtended,\n    },\n    TimeBudgetExhausted {\n        exhausted: TimeBudgetExhaustedResult,\n        state: MetaAgentLoopStateExtended,\n    },\n}\n\nimpl MetaAgentLoopResultExtended {\n    pub fn is_success(&self) -> bool {\n        matches!(self, MetaAgentLoopResultExtended::Success { .. })\n    }\n\n    pub fn can_commit(&self) -> bool {\n        matches!(self, MetaAgentLoopResultExtended::Success { quality_gates, .. } if quality_gates.all_passed)\n    }\n\n    pub fn quality_gates(&self) -> Option<&QualityGateSummary> {\n        match self {\n            MetaAgentLoopResultExtended::Success { quality_gates, .. } => Some(quality_gates),\n            MetaAgentLoopResultExtended::QualityGateFailure { quality_gates, .. } => {\n                Some(quality_gates)\n            }\n            MetaAgentLoopResultExtended::Failure { state } => state.quality_gates.as_ref(),\n            MetaAgentLoopResultExtended::TimeBudgetExhausted { state, .. } => {\n                state.quality_gates.as_ref()\n            }\n        }\n    }\n}\n\nimpl MetaAgentLoopResult {\n    pub fn escalation_message(&self) -> Option<String> {\n        match self {\n            MetaAgentLoopResult::Failure { state } => state\n                .last_improve\n                .as_ref()\n                .and_then(|improve| improve.escalation_message.clone()),\n            _ => None,\n        }\n    }\n}\n\npub struct MetaAgentLoop<C: crate::context_architect::LlmClient> {\n    build_phase: BuildPhase<C>,\n    test_phase: TestPhase,\n    improve_phase: ImprovePhase<C>,\n    config: MetaAgentConfig,\n}\n\nimpl<C: crate::context_architect::LlmClient> MetaAgentLoop<C> {\n    pub fn new(\n        build_phase: BuildPhase<C>,\n        test_phase: TestPhase,\n        improve_phase: ImprovePhase<C>,\n        config: MetaAgentConfig,\n    ) -> Self {\n        Self {\n            build_phase,\n            test_phase,\n            improve_phase,\n            config,\n        }\n    }\n\n    pub async fn run(\n        &self,\n        requirements: &str,\n        test_command: &TestCommand,\n        context: Option<&str>,\n    ) -> Result<MetaAgentLoopResult, crate::context_architect::LlmError> {\n        let span = info_span!(\n            \"meta_agent_loop\",\n            requirements_len = requirements.len(),\n            has_context = context.is_some(),\n            max_iterations = self.config.max_iterations\n        );\n\n        async move {\n            let mut state = MetaAgentLoopState::default();\n\n            while state.iterations < self.config.max_iterations {\n                let iteration_span = info_span!(\n                    \"meta_agent_iteration\",\n                    iteration = state.iterations + 1,\n                    max_iterations = self.config.max_iterations\n                );\n\n                let _guard = iteration_span.enter();\n\n                let build = self.build_phase.execute(requirements, context).await?;\n                let test = self.test_phase.execute(test_command).await;\n\n                state.iterations += 1;\n                state.last_build = Some(build.clone());\n                state.last_test = Some(test.clone());\n\n                if test.status == TestStatus::Pass {\n                    return Ok(MetaAgentLoopResult::Success {\n                        build,\n                        test,\n                        iterations: state.iterations,\n                    });\n                }\n\n                let improve = self.improve_phase.execute(&test).await?;\n                state.last_improve = Some(improve.clone());\n\n                if improve.action == ImproveAction::Escalate {\n                    return Ok(MetaAgentLoopResult::Failure { state });\n                }\n            }\n\n            Ok(MetaAgentLoopResult::Failure { state })\n        }\n        .instrument(span)\n        .await\n    }\n}\n\npub struct MetaAgentLoopWithBudget<C: crate::context_architect::LlmClient> {\n    build_phase: BuildPhase<C>,\n    test_phase: TestPhase,\n    improve_phase: ImprovePhase<C>,\n    config: MetaAgentConfig,\n    time_budget_config: TimeBudgetConfig,\n    quality_gate_config: QualityGateConfig,\n}\n\nimpl<C: crate::context_architect::LlmClient> MetaAgentLoopWithBudget<C> {\n    pub fn new(\n        build_phase: BuildPhase<C>,\n        test_phase: TestPhase,\n        improve_phase: ImprovePhase<C>,\n        config: MetaAgentConfig,\n        time_budget_config: TimeBudgetConfig,\n        quality_gate_config: QualityGateConfig,\n    ) -> Self {\n        Self {\n            build_phase,\n            test_phase,\n            improve_phase,\n            config,\n            time_budget_config,\n            quality_gate_config,\n        }\n    }\n\n    pub async fn run(\n        &self,\n        requirements: &str,\n        test_command: &TestCommand,\n        context: Option<&str>,\n    ) -> Result<MetaAgentLoopResultExtended, crate::context_architect::LlmError> {\n        let span = info_span!(\n            \"meta_agent_loop_with_budget\",\n            requirements_len = requirements.len(),\n            has_context = context.is_some(),\n            max_iterations = self.config.max_iterations,\n            budget_secs = self.time_budget_config.total_duration.as_secs()\n        );\n\n        async move {\n            let mut budget = TimeBudget::start(self.time_budget_config.clone());\n            let quality_evaluator = QualityGateEvaluator::new(self.quality_gate_config.clone());\n\n            let mut state = MetaAgentLoopStateExtended {\n                iterations: 0,\n                last_build: None,\n                last_test: None,\n                last_improve: None,\n                quality_gates: None,\n            };\n\n            while state.iterations < self.config.max_iterations {\n                let budget_check = budget.check();\n                if budget_check.is_exhausted() {\n                    let exhausted =\n                        TimeBudgetExhaustedResult::new(budget_check.elapsed, state.iterations);\n                    return Ok(MetaAgentLoopResultExtended::TimeBudgetExhausted {\n                        exhausted,\n                        state,\n                    });\n                }\n\n                if budget_check.is_warning() {\n                    warn!(\n                        iterations = state.iterations,\n                        remaining_secs = budget_check.remaining.as_secs(),\n                        \"Time budget warning - limiting remaining iterations\"\n                    );\n                }\n\n                let iteration_span = info_span!(\n                    \"meta_agent_iteration\",\n                    iteration = state.iterations + 1,\n                    max_iterations = self.config.max_iterations,\n                    budget_remaining_secs = budget.remaining().as_secs()\n                );\n\n                let _guard = iteration_span.enter();\n\n                let build = self.build_phase.execute(requirements, context).await?;\n\n                let budget_check = budget.check();\n                if budget_check.is_exhausted() {\n                    state.last_build = Some(build);\n                    let exhausted =\n                        TimeBudgetExhaustedResult::new(budget_check.elapsed, state.iterations)\n                            .with_partial_results(\"Build completed, test not started\");\n                    return Ok(MetaAgentLoopResultExtended::TimeBudgetExhausted {\n                        exhausted,\n                        state,\n                    });\n                }\n\n                let test = self.test_phase.execute(test_command).await;\n\n                state.iterations += 1;\n                state.last_build = Some(build.clone());\n                state.last_test = Some(test.clone());\n\n                if test.status == TestStatus::Pass {\n                    let quality_gates = quality_evaluator.evaluate_all(true).await;\n                    state.quality_gates = Some(quality_gates.clone());\n\n                    if quality_evaluator.can_commit(&quality_gates) {\n                        return Ok(MetaAgentLoopResultExtended::Success {\n                            build,\n                            test,\n                            quality_gates,\n                            iterations: state.iterations,\n                        });\n                    } else {\n                        return Ok(MetaAgentLoopResultExtended::QualityGateFailure {\n                            build,\n                            test,\n                            quality_gates,\n                            iterations: state.iterations,\n                        });\n                    }\n                }\n\n                let budget_check = budget.check();\n                if budget_check.is_exhausted() {\n                    let exhausted =\n                        TimeBudgetExhaustedResult::new(budget_check.elapsed, state.iterations)\n                            .with_partial_results(\"Tests failed, improve phase not started\");\n                    return Ok(MetaAgentLoopResultExtended::TimeBudgetExhausted {\n                        exhausted,\n                        state,\n                    });\n                }\n\n                let improve = self.improve_phase.execute(&test).await?;\n                state.last_improve = Some(improve.clone());\n\n                if improve.action == ImproveAction::Escalate {\n                    return Ok(MetaAgentLoopResultExtended::Failure { state });\n                }\n            }\n\n            Ok(MetaAgentLoopResultExtended::Failure { state })\n        }\n        .instrument(span)\n        .await\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::context_architect::LlmError;\n    use crate::meta_agent::{BuildPhaseConfig, ImprovePhaseConfig, TestPhaseConfig};\n    use async_trait::async_trait;\n    use std::sync::{Arc, Mutex};\n\n    struct MockLlmClient {\n        responses: Mutex<Vec<String>>,\n    }\n\n    impl MockLlmClient {\n        fn new(responses: Vec<String>) -> Self {\n            Self {\n                responses: Mutex::new(responses),\n            }\n        }\n    }\n\n    #[async_trait]\n    impl crate::context_architect::LlmClient for MockLlmClient {\n        async fn complete(&self, _prompt: &str) -> Result<String, LlmError> {\n            let mut responses = self.responses.lock().unwrap();\n            responses\n                .pop()\n                .ok_or_else(|| LlmError::InvalidResponse(\"No mock response\".into()))\n        }\n\n        async fn complete_with_system(\n            &self,\n            _system: &str,\n            _user: &str,\n        ) -> Result<String, LlmError> {\n            let mut responses = self.responses.lock().unwrap();\n            responses\n                .pop()\n                .ok_or_else(|| LlmError::InvalidResponse(\"No mock response\".into()))\n        }\n    }\n\n    #[tokio::test]\n    async fn test_meta_agent_success() {\n        let client = Arc::new(MockLlmClient::new(vec![\n            \"improve\".to_string(),\n            \"build\".to_string(),\n        ]));\n        let build_phase = BuildPhase::new(client.clone(), BuildPhaseConfig::default());\n        let improve_phase = ImprovePhase::new(client, ImprovePhaseConfig::default());\n        let test_phase = TestPhase::new(TestPhaseConfig { timeout_secs: 2 });\n\n        let loop_runner = MetaAgentLoop::new(\n            build_phase,\n            test_phase,\n            improve_phase,\n            MetaAgentConfig {\n                max_iterations: 1,\n                ..Default::default()\n            },\n        );\n\n        let command = TestCommand::new(\"sh\", vec![\"-c\".to_string(), \"exit 0\".to_string()]);\n        let result = loop_runner.run(\"req\", &command, None).await.unwrap();\n\n        match result {\n            MetaAgentLoopResult::Success { iterations, .. } => {\n                assert_eq!(iterations, 1);\n            }\n            _ => panic!(\"Expected success\"),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_loop_with_budget_success() {\n        let client = Arc::new(MockLlmClient::new(vec![\"build\".to_string()]));\n        let build_phase = BuildPhase::new(client.clone(), BuildPhaseConfig::default());\n        let improve_phase = ImprovePhase::new(client, ImprovePhaseConfig::default());\n        let test_phase = TestPhase::new(TestPhaseConfig { timeout_secs: 2 });\n\n        let loop_runner = MetaAgentLoopWithBudget::new(\n            build_phase,\n            test_phase,\n            improve_phase,\n            MetaAgentConfig {\n                max_iterations: 3,\n                ..Default::default()\n            },\n            TimeBudgetConfig::default().with_duration_secs(60),\n            QualityGateConfig::default(),\n        );\n\n        let command = TestCommand::new(\"sh\", vec![\"-c\".to_string(), \"exit 0\".to_string()]);\n        let result = loop_runner.run(\"req\", &command, None).await.unwrap();\n\n        assert!(result.is_success());\n        assert!(result.can_commit());\n        assert!(result.quality_gates().is_some());\n    }\n\n    #[tokio::test]\n    async fn test_loop_with_budget_quality_gate_failure() {\n        let client = Arc::new(MockLlmClient::new(vec![\"build\".to_string()]));\n        let build_phase = BuildPhase::new(client.clone(), BuildPhaseConfig::default());\n        let improve_phase = ImprovePhase::new(client, ImprovePhaseConfig::default());\n        let test_phase = TestPhase::new(TestPhaseConfig { timeout_secs: 2 });\n\n        let loop_runner = MetaAgentLoopWithBudget::new(\n            build_phase,\n            test_phase,\n            improve_phase,\n            MetaAgentConfig {\n                max_iterations: 3,\n                ..Default::default()\n            },\n            TimeBudgetConfig::default().with_duration_secs(60),\n            QualityGateConfig::default()\n                .with_linter(super::super::LinterConfig {\n                    program: \"sh\".to_string(),\n                    args: vec![\"-c\".to_string(), \"exit 1\".to_string()],\n                    timeout_secs: 2,\n                })\n                .require_all(),\n        );\n\n        let command = TestCommand::new(\"sh\", vec![\"-c\".to_string(), \"exit 0\".to_string()]);\n        let result = loop_runner.run(\"req\", &command, None).await.unwrap();\n\n        assert!(!result.can_commit());\n        match result {\n            MetaAgentLoopResultExtended::QualityGateFailure { quality_gates, .. } => {\n                assert!(!quality_gates.all_passed);\n                assert!(quality_gates.tests_passed());\n                assert_eq!(quality_gates.linter_passed(), Some(false));\n            }\n            _ => panic!(\"Expected QualityGateFailure\"),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_loop_with_budget_time_exhausted() {\n        let client = Arc::new(MockLlmClient::new(vec![\"build\".to_string()]));\n        let build_phase = BuildPhase::new(client.clone(), BuildPhaseConfig::default());\n        let improve_phase = ImprovePhase::new(client, ImprovePhaseConfig::default());\n        let test_phase = TestPhase::new(TestPhaseConfig { timeout_secs: 2 });\n\n        let loop_runner = MetaAgentLoopWithBudget::new(\n            build_phase,\n            test_phase,\n            improve_phase,\n            MetaAgentConfig {\n                max_iterations: 10,\n                ..Default::default()\n            },\n            TimeBudgetConfig::default().with_duration_secs(0),\n            QualityGateConfig::default(),\n        );\n\n        let command = TestCommand::new(\"sh\", vec![\"-c\".to_string(), \"exit 0\".to_string()]);\n        let result = loop_runner.run(\"req\", &command, None).await.unwrap();\n\n        match result {\n            MetaAgentLoopResultExtended::TimeBudgetExhausted { exhausted, .. } => {\n                assert_eq!(exhausted.iterations_completed, 0);\n            }\n            _ => panic!(\"Expected TimeBudgetExhausted\"),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_result_extended_helpers() {\n        let quality_gates =\n            QualityGateSummary::from_results(vec![super::super::QualityGateResult::pass(\n                super::super::QualityGateType::Tests,\n                \"pass\",\n                0,\n            )]);\n\n        let success = MetaAgentLoopResultExtended::Success {\n            build: BuildResult {\n                output: \"out\".to_string(),\n                notes: vec![],\n                hindsight: vec![],\n                tokens_used: 0,\n            },\n            test: TestResult {\n                status: TestStatus::Pass,\n                output: \"pass\".to_string(),\n                duration_ms: 100,\n            },\n            quality_gates: quality_gates.clone(),\n            iterations: 1,\n        };\n\n        assert!(success.is_success());\n        assert!(success.can_commit());\n        assert!(success.quality_gates().is_some());\n    }\n}\n","traces":[{"line":17,"address":[],"length":0,"stats":{"Line":3}},{"line":72,"address":[],"length":0,"stats":{"Line":2}},{"line":73,"address":[],"length":0,"stats":{"Line":2}},{"line":76,"address":[],"length":0,"stats":{"Line":3}},{"line":77,"address":[],"length":0,"stats":{"Line":8}},{"line":80,"address":[],"length":0,"stats":{"Line":2}},{"line":81,"address":[],"length":0,"stats":{"Line":2}},{"line":82,"address":[],"length":0,"stats":{"Line":4}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":1}},{"line":128,"address":[],"length":0,"stats":{"Line":1}},{"line":134,"address":[],"length":0,"stats":{"Line":2}},{"line":136,"address":[],"length":0,"stats":{"Line":2}},{"line":137,"address":[],"length":0,"stats":{"Line":2}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":1}},{"line":142,"address":[],"length":0,"stats":{"Line":2}},{"line":144,"address":[],"length":0,"stats":{"Line":1}},{"line":145,"address":[],"length":0,"stats":{"Line":2}},{"line":147,"address":[],"length":0,"stats":{"Line":1}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":3}},{"line":153,"address":[],"length":0,"stats":{"Line":5}},{"line":154,"address":[],"length":0,"stats":{"Line":4}},{"line":156,"address":[],"length":0,"stats":{"Line":1}},{"line":157,"address":[],"length":0,"stats":{"Line":2}},{"line":158,"address":[],"length":0,"stats":{"Line":2}},{"line":160,"address":[],"length":0,"stats":{"Line":1}},{"line":161,"address":[],"length":0,"stats":{"Line":1}},{"line":162,"address":[],"length":0,"stats":{"Line":2}},{"line":163,"address":[],"length":0,"stats":{"Line":1}},{"line":164,"address":[],"length":0,"stats":{"Line":1}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":2}},{"line":179,"address":[],"length":0,"stats":{"Line":1}},{"line":193,"address":[],"length":0,"stats":{"Line":3}},{"line":211,"address":[],"length":0,"stats":{"Line":3}},{"line":217,"address":[],"length":0,"stats":{"Line":6}},{"line":219,"address":[],"length":0,"stats":{"Line":6}},{"line":220,"address":[],"length":0,"stats":{"Line":6}},{"line":221,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":6}},{"line":225,"address":[],"length":0,"stats":{"Line":3}},{"line":226,"address":[],"length":0,"stats":{"Line":12}},{"line":227,"address":[],"length":0,"stats":{"Line":12}},{"line":237,"address":[],"length":0,"stats":{"Line":3}},{"line":238,"address":[],"length":0,"stats":{"Line":9}},{"line":239,"address":[],"length":0,"stats":{"Line":6}},{"line":240,"address":[],"length":0,"stats":{"Line":1}},{"line":241,"address":[],"length":0,"stats":{"Line":3}},{"line":242,"address":[],"length":0,"stats":{"Line":1}},{"line":243,"address":[],"length":0,"stats":{"Line":1}},{"line":244,"address":[],"length":0,"stats":{"Line":1}},{"line":248,"address":[],"length":0,"stats":{"Line":4}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":0}},{"line":252,"address":[],"length":0,"stats":{"Line":0}},{"line":256,"address":[],"length":0,"stats":{"Line":4}},{"line":258,"address":[],"length":0,"stats":{"Line":2}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":4}},{"line":263,"address":[],"length":0,"stats":{"Line":6}},{"line":265,"address":[],"length":0,"stats":{"Line":10}},{"line":267,"address":[],"length":0,"stats":{"Line":6}},{"line":268,"address":[],"length":0,"stats":{"Line":4}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":270,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":274,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":8}},{"line":281,"address":[],"length":0,"stats":{"Line":2}},{"line":282,"address":[],"length":0,"stats":{"Line":4}},{"line":283,"address":[],"length":0,"stats":{"Line":4}},{"line":285,"address":[],"length":0,"stats":{"Line":2}},{"line":286,"address":[],"length":0,"stats":{"Line":6}},{"line":287,"address":[],"length":0,"stats":{"Line":4}},{"line":289,"address":[],"length":0,"stats":{"Line":6}},{"line":290,"address":[],"length":0,"stats":{"Line":1}},{"line":291,"address":[],"length":0,"stats":{"Line":2}},{"line":292,"address":[],"length":0,"stats":{"Line":2}},{"line":293,"address":[],"length":0,"stats":{"Line":1}},{"line":294,"address":[],"length":0,"stats":{"Line":1}},{"line":297,"address":[],"length":0,"stats":{"Line":1}},{"line":298,"address":[],"length":0,"stats":{"Line":2}},{"line":299,"address":[],"length":0,"stats":{"Line":2}},{"line":300,"address":[],"length":0,"stats":{"Line":1}},{"line":301,"address":[],"length":0,"stats":{"Line":1}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":0}},{"line":321,"address":[],"length":0,"stats":{"Line":0}},{"line":325,"address":[],"length":0,"stats":{"Line":0}},{"line":327,"address":[],"length":0,"stats":{"Line":6}},{"line":328,"address":[],"length":0,"stats":{"Line":3}}],"covered":76,"coverable":118},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","meta_agent","mod.rs"],"content":"mod build;\nmod improve;\nmod r#loop;\nmod quality_gate;\nmod result;\nmod telemetry;\nmod test;\nmod time_budget;\nmod types;\n\npub use build::{BuildPhase, BuildPhaseConfig, BuildPromptTemplate, BuildPromptTemplates};\npub use improve::{\n    ImprovePhase, ImprovePhaseConfig, ImprovePromptTemplate, ImprovePromptTemplates,\n};\npub use r#loop::{\n    MetaAgentLoop, MetaAgentLoopResult, MetaAgentLoopResultExtended, MetaAgentLoopState,\n    MetaAgentLoopStateExtended, MetaAgentLoopWithBudget,\n};\npub use quality_gate::{\n    CoverageConfig, LinterConfig, QualityGateConfig, QualityGateEvaluator, QualityGateResult,\n    QualityGateSummary, QualityGateType,\n};\npub use result::{FailureContext, ResultHandler, ResultHandlingConfig, ResultHandlingOutcome};\npub use telemetry::MetaAgentTelemetrySink;\npub use test::{TestPhase, TestPhaseConfig};\npub use time_budget::{\n    BudgetCheck, BudgetStatus, TimeBudget, TimeBudgetConfig, TimeBudgetExhaustedResult,\n};\npub use types::{\n    BuildResult, ImproveAction, ImproveResult, MetaAgentConfig, MetaAgentFailureReport,\n    MetaAgentSuccessReport, MetaAgentTelemetry, TestCommand, TestResult, TestStatus,\n};\n\npub use crate::hindsight::{HindsightRetrievalConfig, HindsightRetriever};\npub use crate::note_taking::{\n    GeneratedNote, NoteEmbedder, NoteGenerator, NoteGeneratorConfig, NoteRetriever, RetrievalConfig,\n};\n\nuse crate::context_architect::ViewMode;\nuse crate::hindsight::{HindsightRetrievalFilter, ScoredHindsightNote};\nuse crate::note_taking::ScoredNote;\nuse mk_core::types::ErrorSignature;\nuse std::sync::Arc;\nuse storage::postgres::PostgresBackend;\n\nuse async_trait::async_trait;\n\n#[async_trait]\npub trait NoteLookup: Send + Sync {\n    async fn retrieve(&self, query: &str, limit: usize) -> Vec<String>;\n}\n\n#[async_trait]\npub trait HindsightLookup: Send + Sync {\n    async fn retrieve(&self, query: &str, limit: usize) -> Vec<String>;\n}\n\n#[async_trait]\npub trait NoteStore: Send + Sync {\n    async fn add_note(&self, note: GeneratedNote);\n\n    async fn retrieve(&self, query: &str, limit: usize) -> Vec<String>;\n}\n\n#[async_trait]\npub trait HindsightStore: Send + Sync {\n    async fn retrieve(&self, query: &str, limit: usize) -> Vec<String>;\n}\n\npub struct InMemoryNoteStore<E: NoteEmbedder> {\n    retriever: tokio::sync::Mutex<NoteRetriever<E>>,\n    view_mode: ViewMode,\n}\n\nimpl<E: NoteEmbedder> InMemoryNoteStore<E> {\n    pub fn new(retriever: NoteRetriever<E>, view_mode: ViewMode) -> Self {\n        Self {\n            retriever: tokio::sync::Mutex::new(retriever),\n            view_mode,\n        }\n    }\n}\n\n#[async_trait]\nimpl<E: NoteEmbedder> NoteStore for InMemoryNoteStore<E> {\n    async fn add_note(&self, note: GeneratedNote) {\n        let mut retriever = self.retriever.lock().await;\n        let _ = retriever.add_note(note).await;\n    }\n\n    async fn retrieve(&self, query: &str, limit: usize) -> Vec<String> {\n        let retriever = self.retriever.lock().await;\n        let results = retriever.retrieve_relevant(query, limit).await;\n        match results {\n            Ok(scored) => format_notes_for_view(&scored, self.view_mode),\n            Err(_) => Vec::new(),\n        }\n    }\n}\n\npub struct PostgresHindsightStore {\n    storage: Arc<PostgresBackend>,\n    config: HindsightRetrievalConfig,\n    view_mode: ViewMode,\n    tenant_id: String,\n}\n\nimpl PostgresHindsightStore {\n    pub fn new(\n        storage: Arc<PostgresBackend>,\n        config: HindsightRetrievalConfig,\n        view_mode: ViewMode,\n        tenant_id: impl Into<String>,\n    ) -> Self {\n        Self {\n            storage,\n            config,\n            view_mode,\n            tenant_id: tenant_id.into(),\n        }\n    }\n}\n\n#[async_trait]\nimpl HindsightStore for PostgresHindsightStore {\n    async fn retrieve(&self, query: &str, limit: usize) -> Vec<String> {\n        let signature = ErrorSignature {\n            error_type: query.to_string(),\n            message_pattern: query.to_string(),\n            stack_patterns: vec![],\n            context_patterns: vec![],\n            embedding: None,\n        };\n        let retriever = HindsightRetriever::new(self.storage.clone(), self.config.clone());\n        let filter = HindsightRetrievalFilter::default();\n        let results = retriever\n            .retrieve(&self.tenant_id, &signature, Some(&filter))\n            .await;\n        match results {\n            Ok(scored) => {\n                let limited = scored.into_iter().take(limit).collect::<Vec<_>>();\n                format_hindsight_for_view(&limited, self.view_mode)\n            }\n            Err(_) => Vec::new(),\n        }\n    }\n}\n\npub fn format_notes_for_view(scored: &[ScoredNote], view_mode: ViewMode) -> Vec<String> {\n    let _ = view_mode;\n    scored\n        .iter()\n        .map(|entry| entry.note.content.clone())\n        .collect()\n}\n\npub fn format_hindsight_for_view(\n    scored: &[ScoredHindsightNote],\n    view_mode: ViewMode,\n) -> Vec<String> {\n    let _ = view_mode;\n    scored\n        .iter()\n        .map(|entry| entry.note.content.clone())\n        .collect()\n}\n","traces":[{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":22},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","meta_agent","quality_gate.rs"],"content":"use std::time::Instant;\n\nuse tokio::process::Command;\nuse tokio::time::{Duration, timeout};\nuse tracing::{info_span, warn};\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum QualityGateType {\n    Tests,\n    Linter,\n    Coverage,\n}\n\nimpl std::fmt::Display for QualityGateType {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            QualityGateType::Tests => write!(f, \"tests\"),\n            QualityGateType::Linter => write!(f, \"linter\"),\n            QualityGateType::Coverage => write!(f, \"coverage\"),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct QualityGateResult {\n    pub gate_type: QualityGateType,\n    pub passed: bool,\n    pub message: String,\n    pub duration_ms: u64,\n}\n\nimpl QualityGateResult {\n    pub fn pass(gate_type: QualityGateType, message: impl Into<String>, duration_ms: u64) -> Self {\n        Self {\n            gate_type,\n            passed: true,\n            message: message.into(),\n            duration_ms,\n        }\n    }\n\n    pub fn fail(gate_type: QualityGateType, message: impl Into<String>, duration_ms: u64) -> Self {\n        Self {\n            gate_type,\n            passed: false,\n            message: message.into(),\n            duration_ms,\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct LinterConfig {\n    pub program: String,\n    pub args: Vec<String>,\n    pub timeout_secs: u64,\n}\n\nimpl Default for LinterConfig {\n    fn default() -> Self {\n        Self {\n            program: \"cargo\".to_string(),\n            args: vec![\n                \"clippy\".to_string(),\n                \"--\".to_string(),\n                \"-D\".to_string(),\n                \"warnings\".to_string(),\n            ],\n            timeout_secs: 120,\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct CoverageConfig {\n    pub program: String,\n    pub args: Vec<String>,\n    pub threshold_percent: f64,\n    pub timeout_secs: u64,\n}\n\nimpl Default for CoverageConfig {\n    fn default() -> Self {\n        Self {\n            program: \"cargo\".to_string(),\n            args: vec![\n                \"tarpaulin\".to_string(),\n                \"--out\".to_string(),\n                \"Json\".to_string(),\n            ],\n            threshold_percent: 80.0,\n            timeout_secs: 300,\n        }\n    }\n}\n\n#[derive(Debug, Clone, Default)]\npub struct QualityGateConfig {\n    pub linter: Option<LinterConfig>,\n    pub coverage: Option<CoverageConfig>,\n    pub require_all_gates: bool,\n}\n\nimpl QualityGateConfig {\n    pub fn with_linter(mut self, config: LinterConfig) -> Self {\n        self.linter = Some(config);\n        self\n    }\n\n    pub fn with_coverage(mut self, config: CoverageConfig) -> Self {\n        self.coverage = Some(config);\n        self\n    }\n\n    pub fn require_all(mut self) -> Self {\n        self.require_all_gates = true;\n        self\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct QualityGateSummary {\n    pub gates: Vec<QualityGateResult>,\n    pub all_passed: bool,\n    pub total_duration_ms: u64,\n}\n\nimpl QualityGateSummary {\n    pub fn from_results(gates: Vec<QualityGateResult>) -> Self {\n        let all_passed = gates.iter().all(|g| g.passed);\n        let total_duration_ms = gates.iter().map(|g| g.duration_ms).sum();\n        Self {\n            gates,\n            all_passed,\n            total_duration_ms,\n        }\n    }\n\n    pub fn tests_passed(&self) -> bool {\n        self.gates\n            .iter()\n            .find(|g| g.gate_type == QualityGateType::Tests)\n            .map(|g| g.passed)\n            .unwrap_or(false)\n    }\n\n    pub fn linter_passed(&self) -> Option<bool> {\n        self.gates\n            .iter()\n            .find(|g| g.gate_type == QualityGateType::Linter)\n            .map(|g| g.passed)\n    }\n\n    pub fn coverage_passed(&self) -> Option<bool> {\n        self.gates\n            .iter()\n            .find(|g| g.gate_type == QualityGateType::Coverage)\n            .map(|g| g.passed)\n    }\n\n    pub fn failed_gates(&self) -> Vec<&QualityGateResult> {\n        self.gates.iter().filter(|g| !g.passed).collect()\n    }\n\n    pub fn format_summary(&self) -> String {\n        let mut lines = vec![\"Quality Gate Summary:\".to_string()];\n        for gate in &self.gates {\n            let status = if gate.passed { \"\" } else { \"\" };\n            lines.push(format!(\n                \"  {} {} - {} ({}ms)\",\n                status, gate.gate_type, gate.message, gate.duration_ms\n            ));\n        }\n        lines.push(format!(\n            \"  Overall: {} (total: {}ms)\",\n            if self.all_passed { \"PASSED\" } else { \"FAILED\" },\n            self.total_duration_ms\n        ));\n        lines.join(\"\\n\")\n    }\n}\n\npub struct QualityGateEvaluator {\n    config: QualityGateConfig,\n}\n\nimpl QualityGateEvaluator {\n    pub fn new(config: QualityGateConfig) -> Self {\n        Self { config }\n    }\n\n    pub fn mark_tests_result(&self, tests_passed: bool) -> QualityGateResult {\n        if tests_passed {\n            QualityGateResult::pass(QualityGateType::Tests, \"All tests passed\", 0)\n        } else {\n            QualityGateResult::fail(QualityGateType::Tests, \"Tests failed\", 0)\n        }\n    }\n\n    pub async fn run_linter(&self) -> Option<QualityGateResult> {\n        let linter_config = self.config.linter.as_ref()?;\n\n        let span = info_span!(\n            \"quality_gate_linter\",\n            program = %linter_config.program,\n            timeout_secs = linter_config.timeout_secs\n        );\n        let _guard = span.enter();\n\n        let start = Instant::now();\n        let mut cmd = Command::new(&linter_config.program);\n        cmd.args(&linter_config.args);\n\n        let result = timeout(\n            Duration::from_secs(linter_config.timeout_secs),\n            cmd.output(),\n        )\n        .await;\n\n        let duration_ms = start.elapsed().as_millis() as u64;\n\n        match result {\n            Ok(Ok(output)) => {\n                if output.status.success() {\n                    Some(QualityGateResult::pass(\n                        QualityGateType::Linter,\n                        \"Linter passed with no warnings\",\n                        duration_ms,\n                    ))\n                } else {\n                    let stderr = String::from_utf8_lossy(&output.stderr);\n                    let message = if stderr.len() > 200 {\n                        format!(\"Linter failed: {}...\", &stderr[..200])\n                    } else {\n                        format!(\"Linter failed: {}\", stderr)\n                    };\n                    Some(QualityGateResult::fail(\n                        QualityGateType::Linter,\n                        message,\n                        duration_ms,\n                    ))\n                }\n            }\n            Ok(Err(e)) => {\n                warn!(\"Failed to run linter: {}\", e);\n                Some(QualityGateResult::fail(\n                    QualityGateType::Linter,\n                    format!(\"Failed to run linter: {e}\"),\n                    duration_ms,\n                ))\n            }\n            Err(_) => Some(QualityGateResult::fail(\n                QualityGateType::Linter,\n                \"Linter timed out\",\n                duration_ms,\n            )),\n        }\n    }\n\n    pub async fn run_coverage(&self) -> Option<QualityGateResult> {\n        let coverage_config = self.config.coverage.as_ref()?;\n\n        let span = info_span!(\n            \"quality_gate_coverage\",\n            program = %coverage_config.program,\n            threshold = coverage_config.threshold_percent,\n            timeout_secs = coverage_config.timeout_secs\n        );\n        let _guard = span.enter();\n\n        let start = Instant::now();\n        let mut cmd = Command::new(&coverage_config.program);\n        cmd.args(&coverage_config.args);\n\n        let result = timeout(\n            Duration::from_secs(coverage_config.timeout_secs),\n            cmd.output(),\n        )\n        .await;\n\n        let duration_ms = start.elapsed().as_millis() as u64;\n\n        match result {\n            Ok(Ok(output)) => {\n                let stdout = String::from_utf8_lossy(&output.stdout);\n                let coverage = self.parse_coverage_output(&stdout);\n\n                match coverage {\n                    Some(pct) if pct >= coverage_config.threshold_percent => {\n                        Some(QualityGateResult::pass(\n                            QualityGateType::Coverage,\n                            format!(\n                                \"Coverage {:.1}% >= {:.1}% threshold\",\n                                pct, coverage_config.threshold_percent\n                            ),\n                            duration_ms,\n                        ))\n                    }\n                    Some(pct) => Some(QualityGateResult::fail(\n                        QualityGateType::Coverage,\n                        format!(\n                            \"Coverage {:.1}% < {:.1}% threshold\",\n                            pct, coverage_config.threshold_percent\n                        ),\n                        duration_ms,\n                    )),\n                    None => {\n                        if output.status.success() {\n                            Some(QualityGateResult::pass(\n                                QualityGateType::Coverage,\n                                \"Coverage check passed (no percentage parsed)\",\n                                duration_ms,\n                            ))\n                        } else {\n                            Some(QualityGateResult::fail(\n                                QualityGateType::Coverage,\n                                \"Coverage check failed\",\n                                duration_ms,\n                            ))\n                        }\n                    }\n                }\n            }\n            Ok(Err(e)) => {\n                warn!(\"Failed to run coverage: {}\", e);\n                Some(QualityGateResult::fail(\n                    QualityGateType::Coverage,\n                    format!(\"Failed to run coverage: {e}\"),\n                    duration_ms,\n                ))\n            }\n            Err(_) => Some(QualityGateResult::fail(\n                QualityGateType::Coverage,\n                \"Coverage check timed out\",\n                duration_ms,\n            )),\n        }\n    }\n\n    fn parse_coverage_output(&self, output: &str) -> Option<f64> {\n        // Try to parse coverage percentage from common formats:\n        // - \"Coverage: 85.5%\"\n        // - '\"coverage\": 85.5' (JSON)\n        // - \"85.50% coverage\"\n        for line in output.lines() {\n            let line = line.trim();\n\n            // JSON format: \"coverage\": 85.5\n            if line.contains(\"\\\"coverage\\\"\") || line.contains(\"\\\"line_coverage\\\"\") {\n                if let Some(idx) = line.find(':') {\n                    let value_part = line[idx + 1..]\n                        .trim()\n                        .trim_matches(|c| c == ',' || c == '\"');\n                    if let Ok(pct) = value_part.parse::<f64>() {\n                        return Some(pct);\n                    }\n                }\n            }\n\n            // \"Coverage: 85.5%\"\n            if line.to_lowercase().contains(\"coverage\") {\n                for part in line.split_whitespace() {\n                    let clean = part.trim_end_matches('%').trim_end_matches(',');\n                    if let Ok(pct) = clean.parse::<f64>() {\n                        return Some(pct);\n                    }\n                }\n            }\n        }\n\n        None\n    }\n\n    pub async fn evaluate_all(&self, tests_passed: bool) -> QualityGateSummary {\n        let span = info_span!(\"quality_gate_evaluate_all\", tests_passed = tests_passed);\n        let _guard = span.enter();\n\n        let mut results = vec![self.mark_tests_result(tests_passed)];\n\n        if let Some(linter_result) = self.run_linter().await {\n            results.push(linter_result);\n        }\n\n        if let Some(coverage_result) = self.run_coverage().await {\n            results.push(coverage_result);\n        }\n\n        QualityGateSummary::from_results(results)\n    }\n\n    pub fn can_commit(&self, summary: &QualityGateSummary) -> bool {\n        if self.config.require_all_gates {\n            summary.all_passed\n        } else {\n            summary.tests_passed()\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_quality_gate_result_pass() {\n        let result = QualityGateResult::pass(QualityGateType::Tests, \"All pass\", 100);\n        assert!(result.passed);\n        assert_eq!(result.gate_type, QualityGateType::Tests);\n        assert_eq!(result.duration_ms, 100);\n    }\n\n    #[test]\n    fn test_quality_gate_result_fail() {\n        let result = QualityGateResult::fail(QualityGateType::Linter, \"Warnings found\", 50);\n        assert!(!result.passed);\n        assert_eq!(result.gate_type, QualityGateType::Linter);\n    }\n\n    #[test]\n    fn test_quality_gate_summary_all_passed() {\n        let results = vec![\n            QualityGateResult::pass(QualityGateType::Tests, \"pass\", 100),\n            QualityGateResult::pass(QualityGateType::Linter, \"pass\", 50),\n        ];\n        let summary = QualityGateSummary::from_results(results);\n        assert!(summary.all_passed);\n        assert_eq!(summary.total_duration_ms, 150);\n    }\n\n    #[test]\n    fn test_quality_gate_summary_some_failed() {\n        let results = vec![\n            QualityGateResult::pass(QualityGateType::Tests, \"pass\", 100),\n            QualityGateResult::fail(QualityGateType::Linter, \"fail\", 50),\n        ];\n        let summary = QualityGateSummary::from_results(results);\n        assert!(!summary.all_passed);\n        assert!(summary.tests_passed());\n        assert_eq!(summary.linter_passed(), Some(false));\n    }\n\n    #[test]\n    fn test_quality_gate_summary_failed_gates() {\n        let results = vec![\n            QualityGateResult::pass(QualityGateType::Tests, \"pass\", 100),\n            QualityGateResult::fail(QualityGateType::Linter, \"fail\", 50),\n            QualityGateResult::fail(QualityGateType::Coverage, \"low\", 200),\n        ];\n        let summary = QualityGateSummary::from_results(results);\n        let failed = summary.failed_gates();\n        assert_eq!(failed.len(), 2);\n    }\n\n    #[test]\n    fn test_evaluator_mark_tests_result() {\n        let config = QualityGateConfig::default();\n        let evaluator = QualityGateEvaluator::new(config);\n\n        let pass = evaluator.mark_tests_result(true);\n        assert!(pass.passed);\n        assert_eq!(pass.gate_type, QualityGateType::Tests);\n\n        let fail = evaluator.mark_tests_result(false);\n        assert!(!fail.passed);\n    }\n\n    #[test]\n    fn test_can_commit_require_all() {\n        let config = QualityGateConfig::default().require_all();\n        let evaluator = QualityGateEvaluator::new(config);\n\n        let all_pass = QualityGateSummary::from_results(vec![QualityGateResult::pass(\n            QualityGateType::Tests,\n            \"pass\",\n            0,\n        )]);\n        assert!(evaluator.can_commit(&all_pass));\n\n        let some_fail = QualityGateSummary::from_results(vec![\n            QualityGateResult::pass(QualityGateType::Tests, \"pass\", 0),\n            QualityGateResult::fail(QualityGateType::Linter, \"fail\", 0),\n        ]);\n        assert!(!evaluator.can_commit(&some_fail));\n    }\n\n    #[test]\n    fn test_can_commit_tests_only() {\n        let config = QualityGateConfig::default();\n        let evaluator = QualityGateEvaluator::new(config);\n\n        let linter_fail = QualityGateSummary::from_results(vec![\n            QualityGateResult::pass(QualityGateType::Tests, \"pass\", 0),\n            QualityGateResult::fail(QualityGateType::Linter, \"fail\", 0),\n        ]);\n        assert!(evaluator.can_commit(&linter_fail));\n    }\n\n    #[test]\n    fn test_parse_coverage_output_json() {\n        let config = QualityGateConfig::default();\n        let evaluator = QualityGateEvaluator::new(config);\n\n        let output = r#\"{\"coverage\": 85.5, \"files\": 10}\"#;\n        assert_eq!(evaluator.parse_coverage_output(output), Some(85.5));\n    }\n\n    #[test]\n    fn test_parse_coverage_output_text() {\n        let config = QualityGateConfig::default();\n        let evaluator = QualityGateEvaluator::new(config);\n\n        let output = \"Coverage: 92.3%\";\n        assert_eq!(evaluator.parse_coverage_output(output), Some(92.3));\n    }\n\n    #[test]\n    fn test_parse_coverage_output_no_match() {\n        let config = QualityGateConfig::default();\n        let evaluator = QualityGateEvaluator::new(config);\n\n        let output = \"No coverage data\";\n        assert_eq!(evaluator.parse_coverage_output(output), None);\n    }\n\n    #[test]\n    fn test_format_summary() {\n        let results = vec![\n            QualityGateResult::pass(QualityGateType::Tests, \"All tests passed\", 100),\n            QualityGateResult::fail(QualityGateType::Linter, \"2 warnings\", 50),\n        ];\n        let summary = QualityGateSummary::from_results(results);\n        let formatted = summary.format_summary();\n        assert!(formatted.contains(\"Quality Gate Summary\"));\n        assert!(formatted.contains(\" tests\"));\n        assert!(formatted.contains(\" linter\"));\n        assert!(formatted.contains(\"FAILED\"));\n    }\n\n    #[tokio::test]\n    async fn test_run_linter_not_configured() {\n        let config = QualityGateConfig::default();\n        let evaluator = QualityGateEvaluator::new(config);\n        let result = evaluator.run_linter().await;\n        assert!(result.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_run_coverage_not_configured() {\n        let config = QualityGateConfig::default();\n        let evaluator = QualityGateEvaluator::new(config);\n        let result = evaluator.run_coverage().await;\n        assert!(result.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_run_linter_success() {\n        let config = QualityGateConfig::default().with_linter(LinterConfig {\n            program: \"sh\".to_string(),\n            args: vec![\"-c\".to_string(), \"exit 0\".to_string()],\n            timeout_secs: 2,\n        });\n        let evaluator = QualityGateEvaluator::new(config);\n        let result = evaluator.run_linter().await.unwrap();\n        assert!(result.passed);\n        assert_eq!(result.gate_type, QualityGateType::Linter);\n    }\n\n    #[tokio::test]\n    async fn test_run_linter_failure() {\n        let config = QualityGateConfig::default().with_linter(LinterConfig {\n            program: \"sh\".to_string(),\n            args: vec![\"-c\".to_string(), \"echo 'warning' >&2 && exit 1\".to_string()],\n            timeout_secs: 2,\n        });\n        let evaluator = QualityGateEvaluator::new(config);\n        let result = evaluator.run_linter().await.unwrap();\n        assert!(!result.passed);\n        assert!(result.message.contains(\"warning\"));\n    }\n\n    #[tokio::test]\n    async fn test_evaluate_all_tests_only() {\n        let config = QualityGateConfig::default();\n        let evaluator = QualityGateEvaluator::new(config);\n\n        let summary = evaluator.evaluate_all(true).await;\n        assert!(summary.all_passed);\n        assert_eq!(summary.gates.len(), 1);\n        assert!(summary.tests_passed());\n    }\n\n    #[tokio::test]\n    async fn test_evaluate_all_with_linter() {\n        let config = QualityGateConfig::default().with_linter(LinterConfig {\n            program: \"sh\".to_string(),\n            args: vec![\"-c\".to_string(), \"exit 0\".to_string()],\n            timeout_secs: 2,\n        });\n        let evaluator = QualityGateEvaluator::new(config);\n\n        let summary = evaluator.evaluate_all(true).await;\n        assert!(summary.all_passed);\n        assert_eq!(summary.gates.len(), 2);\n        assert!(summary.tests_passed());\n        assert_eq!(summary.linter_passed(), Some(true));\n    }\n}\n","traces":[{"line":15,"address":[],"length":0,"stats":{"Line":2}},{"line":16,"address":[],"length":0,"stats":{"Line":2}},{"line":17,"address":[],"length":0,"stats":{"Line":3}},{"line":18,"address":[],"length":0,"stats":{"Line":3}},{"line":19,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":17}},{"line":37,"address":[],"length":0,"stats":{"Line":34}},{"line":42,"address":[],"length":0,"stats":{"Line":10}},{"line":46,"address":[],"length":0,"stats":{"Line":20}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":4}},{"line":106,"address":[],"length":0,"stats":{"Line":8}},{"line":107,"address":[],"length":0,"stats":{"Line":4}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":2}},{"line":116,"address":[],"length":0,"stats":{"Line":2}},{"line":117,"address":[],"length":0,"stats":{"Line":2}},{"line":129,"address":[],"length":0,"stats":{"Line":12}},{"line":130,"address":[],"length":0,"stats":{"Line":36}},{"line":131,"address":[],"length":0,"stats":{"Line":48}},{"line":139,"address":[],"length":0,"stats":{"Line":6}},{"line":140,"address":[],"length":0,"stats":{"Line":6}},{"line":142,"address":[],"length":0,"stats":{"Line":18}},{"line":143,"address":[],"length":0,"stats":{"Line":6}},{"line":147,"address":[],"length":0,"stats":{"Line":3}},{"line":148,"address":[],"length":0,"stats":{"Line":3}},{"line":150,"address":[],"length":0,"stats":{"Line":15}},{"line":151,"address":[],"length":0,"stats":{"Line":3}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":1}},{"line":162,"address":[],"length":0,"stats":{"Line":6}},{"line":165,"address":[],"length":0,"stats":{"Line":1}},{"line":166,"address":[],"length":0,"stats":{"Line":4}},{"line":167,"address":[],"length":0,"stats":{"Line":5}},{"line":168,"address":[],"length":0,"stats":{"Line":6}},{"line":169,"address":[],"length":0,"stats":{"Line":6}},{"line":170,"address":[],"length":0,"stats":{"Line":2}},{"line":174,"address":[],"length":0,"stats":{"Line":3}},{"line":175,"address":[],"length":0,"stats":{"Line":1}},{"line":176,"address":[],"length":0,"stats":{"Line":2}},{"line":179,"address":[],"length":0,"stats":{"Line":2}},{"line":188,"address":[],"length":0,"stats":{"Line":15}},{"line":192,"address":[],"length":0,"stats":{"Line":6}},{"line":193,"address":[],"length":0,"stats":{"Line":6}},{"line":194,"address":[],"length":0,"stats":{"Line":10}},{"line":196,"address":[],"length":0,"stats":{"Line":2}},{"line":200,"address":[],"length":0,"stats":{"Line":14}},{"line":201,"address":[],"length":0,"stats":{"Line":21}},{"line":203,"address":[],"length":0,"stats":{"Line":8}},{"line":208,"address":[],"length":0,"stats":{"Line":12}},{"line":210,"address":[],"length":0,"stats":{"Line":8}},{"line":211,"address":[],"length":0,"stats":{"Line":12}},{"line":212,"address":[],"length":0,"stats":{"Line":12}},{"line":215,"address":[],"length":0,"stats":{"Line":12}},{"line":216,"address":[],"length":0,"stats":{"Line":8}},{"line":218,"address":[],"length":0,"stats":{"Line":4}},{"line":220,"address":[],"length":0,"stats":{"Line":8}},{"line":222,"address":[],"length":0,"stats":{"Line":4}},{"line":223,"address":[],"length":0,"stats":{"Line":4}},{"line":224,"address":[],"length":0,"stats":{"Line":8}},{"line":225,"address":[],"length":0,"stats":{"Line":4}},{"line":226,"address":[],"length":0,"stats":{"Line":2}},{"line":227,"address":[],"length":0,"stats":{"Line":2}},{"line":228,"address":[],"length":0,"stats":{"Line":2}},{"line":231,"address":[],"length":0,"stats":{"Line":6}},{"line":232,"address":[],"length":0,"stats":{"Line":4}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":235,"address":[],"length":0,"stats":{"Line":4}},{"line":237,"address":[],"length":0,"stats":{"Line":4}},{"line":238,"address":[],"length":0,"stats":{"Line":4}},{"line":239,"address":[],"length":0,"stats":{"Line":2}},{"line":240,"address":[],"length":0,"stats":{"Line":2}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":252,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":0}},{"line":254,"address":[],"length":0,"stats":{"Line":0}},{"line":255,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":10}},{"line":261,"address":[],"length":0,"stats":{"Line":15}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":272,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":276,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":284,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":325,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":333,"address":[],"length":0,"stats":{"Line":0}},{"line":334,"address":[],"length":0,"stats":{"Line":0}},{"line":335,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":3}},{"line":345,"address":[],"length":0,"stats":{"Line":9}},{"line":346,"address":[],"length":0,"stats":{"Line":9}},{"line":349,"address":[],"length":0,"stats":{"Line":10}},{"line":350,"address":[],"length":0,"stats":{"Line":2}},{"line":351,"address":[],"length":0,"stats":{"Line":2}},{"line":353,"address":[],"length":0,"stats":{"Line":5}},{"line":354,"address":[],"length":0,"stats":{"Line":1}},{"line":355,"address":[],"length":0,"stats":{"Line":0}},{"line":361,"address":[],"length":0,"stats":{"Line":3}},{"line":362,"address":[],"length":0,"stats":{"Line":13}},{"line":363,"address":[],"length":0,"stats":{"Line":21}},{"line":364,"address":[],"length":0,"stats":{"Line":9}},{"line":365,"address":[],"length":0,"stats":{"Line":2}},{"line":371,"address":[],"length":0,"stats":{"Line":1}},{"line":374,"address":[],"length":0,"stats":{"Line":8}},{"line":375,"address":[],"length":0,"stats":{"Line":8}},{"line":376,"address":[],"length":0,"stats":{"Line":12}},{"line":378,"address":[],"length":0,"stats":{"Line":20}},{"line":380,"address":[],"length":0,"stats":{"Line":16}},{"line":381,"address":[],"length":0,"stats":{"Line":4}},{"line":384,"address":[],"length":0,"stats":{"Line":12}},{"line":385,"address":[],"length":0,"stats":{"Line":0}},{"line":388,"address":[],"length":0,"stats":{"Line":8}},{"line":391,"address":[],"length":0,"stats":{"Line":5}},{"line":392,"address":[],"length":0,"stats":{"Line":5}},{"line":393,"address":[],"length":0,"stats":{"Line":3}},{"line":395,"address":[],"length":0,"stats":{"Line":4}}],"covered":95,"coverable":168},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","meta_agent","result.rs"],"content":"use mk_core::types::{ErrorSignature, HindsightNote, Resolution};\nuse storage::postgres::{PostgresBackend, PostgresError};\n\nuse super::{\n    BuildResult, MetaAgentFailureReport, MetaAgentLoopResult, MetaAgentSuccessReport,\n    MetaAgentTelemetry, TestResult,\n};\n\n#[derive(Debug, Clone)]\npub struct ResultHandlingConfig {\n    pub commit_message_template: String,\n    pub pr_hint_template: String,\n}\n\n#[derive(Debug, thiserror::Error)]\npub enum ResultHandlingError {\n    #[error(\"Storage error: {0}\")]\n    Storage(#[from] PostgresError),\n\n    #[error(\"Missing failure details\")]\n    MissingFailureDetails,\n}\n\nimpl Default for ResultHandlingConfig {\n    fn default() -> Self {\n        Self {\n            commit_message_template: \"chore: apply changes for {summary}\".to_string(),\n            pr_hint_template: \"Create PR for {summary}\".to_string(),\n        }\n    }\n}\n\npub struct ResultHandler {\n    config: ResultHandlingConfig,\n    telemetry: crate::meta_agent::MetaAgentTelemetrySink,\n    storage: Option<std::sync::Arc<PostgresBackend>>,\n}\n\n#[derive(Debug, Clone)]\npub struct FailureContext {\n    pub tenant_id: String,\n    pub signature: ErrorSignature,\n    pub resolutions: Vec<Resolution>,\n}\n\n#[derive(Debug, Clone)]\npub enum ResultHandlingOutcome {\n    Success(MetaAgentSuccessReport),\n    Failure {\n        report: MetaAgentFailureReport,\n        hindsight: Option<HindsightNote>,\n    },\n}\n\nimpl ResultHandler {\n    pub fn new(config: ResultHandlingConfig) -> Self {\n        Self {\n            config,\n            telemetry: crate::meta_agent::MetaAgentTelemetrySink,\n            storage: None,\n        }\n    }\n\n    pub fn with_storage(mut self, storage: std::sync::Arc<PostgresBackend>) -> Self {\n        self.storage = Some(storage);\n        self\n    }\n\n    pub fn handle_success(&self, build: &BuildResult, test: &TestResult) -> MetaAgentSuccessReport {\n        self.handle_success_with_iterations(build, test, 1)\n    }\n\n    pub fn handle_success_with_iterations(\n        &self,\n        build: &BuildResult,\n        test: &TestResult,\n        iterations: u32,\n    ) -> MetaAgentSuccessReport {\n        let summary = summarize(build, test, iterations);\n        let commit_message_hint = self\n            .config\n            .commit_message_template\n            .replace(\"{summary}\", &summary);\n        let pr_hint = self.config.pr_hint_template.replace(\"{summary}\", &summary);\n\n        MetaAgentSuccessReport {\n            summary,\n            commit_message_hint,\n            pr_hint,\n        }\n    }\n\n    pub fn handle_failure(&self, result: &MetaAgentLoopResult) -> MetaAgentFailureReport {\n        let summary = failure_summary(result);\n        let detailed_report = match result {\n            MetaAgentLoopResult::Failure { state } => {\n                let build = state.last_build.as_ref();\n                let test = state.last_test.as_ref();\n                let improve = state.last_improve.as_ref();\n                let mut report = String::new();\n                report.push_str(\"Iterations: \");\n                report.push_str(&state.iterations.to_string());\n                report.push_str(\"\\n\\n\");\n                if let Some(build) = build {\n                    report.push_str(\"Build output:\\n\");\n                    report.push_str(&build.output);\n                    report.push_str(\"\\n\\n\");\n                }\n                if let Some(test) = test {\n                    report.push_str(\"Test output:\\n\");\n                    report.push_str(&test.output);\n                    report.push_str(\"\\n\\n\");\n                }\n                if let Some(improve) = improve {\n                    report.push_str(\"Improve analysis:\\n\");\n                    report.push_str(&improve.analysis);\n                }\n                report\n            }\n            _ => String::new(),\n        };\n\n        MetaAgentFailureReport {\n            summary,\n            detailed_report,\n        }\n    }\n\n    pub fn record_telemetry(&self, telemetry: MetaAgentTelemetry) {\n        self.telemetry.record(&telemetry);\n    }\n\n    pub async fn store_failure_hindsight(\n        &self,\n        tenant_id: &str,\n        signature: ErrorSignature,\n        resolutions: Vec<Resolution>,\n        report: &MetaAgentFailureReport,\n    ) -> Result<HindsightNote, ResultHandlingError> {\n        let note = self.build_failure_hindsight(signature, resolutions, report);\n        let storage = self\n            .storage\n            .as_ref()\n            .ok_or(ResultHandlingError::MissingFailureDetails)?;\n        storage.create_hindsight_note(tenant_id, &note).await?;\n        Ok(note)\n    }\n\n    pub fn emit_telemetry(&self, result: &MetaAgentLoopResult) {\n        match result {\n            MetaAgentLoopResult::Success { iterations, .. } => {\n                self.telemetry.record(&MetaAgentTelemetry {\n                    iterations: *iterations,\n                    success: true,\n                });\n            }\n            MetaAgentLoopResult::Failure { state } => {\n                self.telemetry.record(&MetaAgentTelemetry {\n                    iterations: state.iterations,\n                    success: false,\n                });\n            }\n        }\n    }\n\n    pub async fn handle_result(\n        &self,\n        result: &MetaAgentLoopResult,\n        failure: Option<FailureContext>,\n    ) -> Result<ResultHandlingOutcome, ResultHandlingError> {\n        self.emit_telemetry(result);\n        match result {\n            MetaAgentLoopResult::Success {\n                build,\n                test,\n                iterations,\n            } => {\n                let report = self.handle_success_with_iterations(build, test, *iterations);\n                Ok(ResultHandlingOutcome::Success(report))\n            }\n            MetaAgentLoopResult::Failure { .. } => {\n                let report = self.handle_failure(result);\n                let hindsight = if let Some(failure) = failure {\n                    Some(\n                        self.store_failure_hindsight(\n                            &failure.tenant_id,\n                            failure.signature,\n                            failure.resolutions,\n                            &report,\n                        )\n                        .await?,\n                    )\n                } else {\n                    None\n                };\n                Ok(ResultHandlingOutcome::Failure { report, hindsight })\n            }\n        }\n    }\n\n    pub fn build_failure_hindsight(\n        &self,\n        signature: ErrorSignature,\n        resolutions: Vec<mk_core::types::Resolution>,\n        report: &MetaAgentFailureReport,\n    ) -> HindsightNote {\n        let now = chrono::Utc::now().timestamp();\n        HindsightNote {\n            id: uuid::Uuid::new_v4().to_string(),\n            error_signature: signature,\n            resolutions,\n            content: report.detailed_report.clone(),\n            tags: vec![\"meta-agent\".to_string(), \"failure\".to_string()],\n            created_at: now,\n            updated_at: now,\n        }\n    }\n}\n\nfn summarize(build: &BuildResult, test: &TestResult, iterations: u32) -> String {\n    let mut summary = String::new();\n    summary.push_str(\"iterations: \");\n    summary.push_str(&iterations.to_string());\n    summary.push_str(\", status: \");\n    summary.push_str(match test.status {\n        super::TestStatus::Pass => \"pass\",\n        super::TestStatus::Fail => \"fail\",\n        super::TestStatus::Timeout => \"timeout\",\n    });\n    if !build.notes.is_empty() {\n        summary.push_str(\", notes\");\n    }\n    summary\n}\n\nfn failure_summary(result: &MetaAgentLoopResult) -> String {\n    match result {\n        MetaAgentLoopResult::Failure { state } => {\n            format!(\"iterations: {}, failed\", state.iterations)\n        }\n        _ => \"\".to_string(),\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::{ErrorSignature, Resolution};\n\n    #[test]\n    fn test_success_report() {\n        let handler = ResultHandler::new(ResultHandlingConfig::default());\n        let build = BuildResult {\n            output: \"done\".to_string(),\n            notes: vec![\"note\".to_string()],\n            hindsight: vec![],\n            tokens_used: 10,\n        };\n        let test = TestResult {\n            status: super::super::TestStatus::Pass,\n            output: \"ok\".to_string(),\n            duration_ms: 1,\n        };\n        let report = handler.handle_success_with_iterations(&build, &test, 2);\n        assert!(report.commit_message_hint.contains(\"iterations: 2\"));\n        assert!(report.pr_hint.contains(\"iterations: 2\"));\n    }\n\n    #[test]\n    fn test_failure_report() {\n        let handler = ResultHandler::new(ResultHandlingConfig::default());\n        let mut state = super::super::MetaAgentLoopState::default();\n        state.iterations = 2;\n        state.last_build = Some(BuildResult {\n            output: \"build\".to_string(),\n            notes: vec![],\n            hindsight: vec![],\n            tokens_used: 1,\n        });\n        state.last_test = Some(TestResult {\n            status: super::super::TestStatus::Fail,\n            output: \"fail\".to_string(),\n            duration_ms: 1,\n        });\n        let result = MetaAgentLoopResult::Failure { state };\n        let report = handler.handle_failure(&result);\n        assert!(report.detailed_report.contains(\"Build output\"));\n    }\n\n    #[test]\n    fn test_failure_hindsight_note() {\n        let handler = ResultHandler::new(ResultHandlingConfig::default());\n        let signature = ErrorSignature {\n            error_type: \"BuildError\".to_string(),\n            message_pattern: \"fail\".to_string(),\n            stack_patterns: vec![],\n            context_patterns: vec![],\n            embedding: None,\n        };\n        let report = MetaAgentFailureReport {\n            summary: \"failed\".to_string(),\n            detailed_report: \"details\".to_string(),\n        };\n        let note = handler.build_failure_hindsight(\n            signature,\n            vec![Resolution {\n                id: \"r\".to_string(),\n                error_signature_id: \"e\".to_string(),\n                description: \"fix\".to_string(),\n                changes: vec![],\n                success_rate: 0.0,\n                application_count: 0,\n                last_success_at: 0,\n            }],\n            &report,\n        );\n        assert!(note.content.contains(\"details\"));\n    }\n\n    #[tokio::test]\n    async fn test_handle_result_missing_failure_context() {\n        let handler = ResultHandler::new(ResultHandlingConfig::default());\n        let state = super::super::MetaAgentLoopState::default();\n        let result = MetaAgentLoopResult::Failure { state };\n        let outcome = handler.handle_result(&result, None).await.unwrap();\n        match outcome {\n            ResultHandlingOutcome::Failure { report, hindsight } => {\n                assert!(report.summary.contains(\"failed\"));\n                assert!(hindsight.is_none());\n            }\n            _ => panic!(\"Expected failure outcome\"),\n        }\n    }\n\n    #[test]\n    fn test_emit_telemetry_success() {\n        let handler = ResultHandler::new(ResultHandlingConfig::default());\n        let build = BuildResult {\n            output: \"done\".to_string(),\n            notes: vec![],\n            hindsight: vec![],\n            tokens_used: 1,\n        };\n        let test = TestResult {\n            status: super::super::TestStatus::Pass,\n            output: \"ok\".to_string(),\n            duration_ms: 1,\n        };\n        let result = MetaAgentLoopResult::Success {\n            build,\n            test,\n            iterations: 1,\n        };\n        handler.emit_telemetry(&result);\n    }\n}\n","traces":[{"line":25,"address":[],"length":0,"stats":{"Line":5}},{"line":27,"address":[],"length":0,"stats":{"Line":15}},{"line":28,"address":[],"length":0,"stats":{"Line":5}},{"line":56,"address":[],"length":0,"stats":{"Line":5}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":1}},{"line":79,"address":[],"length":0,"stats":{"Line":5}},{"line":80,"address":[],"length":0,"stats":{"Line":3}},{"line":81,"address":[],"length":0,"stats":{"Line":2}},{"line":82,"address":[],"length":0,"stats":{"Line":2}},{"line":83,"address":[],"length":0,"stats":{"Line":1}},{"line":84,"address":[],"length":0,"stats":{"Line":3}},{"line":93,"address":[],"length":0,"stats":{"Line":2}},{"line":94,"address":[],"length":0,"stats":{"Line":6}},{"line":95,"address":[],"length":0,"stats":{"Line":4}},{"line":96,"address":[],"length":0,"stats":{"Line":2}},{"line":97,"address":[],"length":0,"stats":{"Line":6}},{"line":98,"address":[],"length":0,"stats":{"Line":6}},{"line":99,"address":[],"length":0,"stats":{"Line":6}},{"line":100,"address":[],"length":0,"stats":{"Line":4}},{"line":101,"address":[],"length":0,"stats":{"Line":6}},{"line":102,"address":[],"length":0,"stats":{"Line":6}},{"line":103,"address":[],"length":0,"stats":{"Line":6}},{"line":104,"address":[],"length":0,"stats":{"Line":4}},{"line":105,"address":[],"length":0,"stats":{"Line":4}},{"line":106,"address":[],"length":0,"stats":{"Line":4}},{"line":107,"address":[],"length":0,"stats":{"Line":2}},{"line":109,"address":[],"length":0,"stats":{"Line":4}},{"line":110,"address":[],"length":0,"stats":{"Line":4}},{"line":111,"address":[],"length":0,"stats":{"Line":4}},{"line":112,"address":[],"length":0,"stats":{"Line":2}},{"line":114,"address":[],"length":0,"stats":{"Line":2}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":2}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":2}},{"line":150,"address":[],"length":0,"stats":{"Line":2}},{"line":151,"address":[],"length":0,"stats":{"Line":2}},{"line":152,"address":[],"length":0,"stats":{"Line":2}},{"line":153,"address":[],"length":0,"stats":{"Line":1}},{"line":154,"address":[],"length":0,"stats":{"Line":1}},{"line":157,"address":[],"length":0,"stats":{"Line":2}},{"line":158,"address":[],"length":0,"stats":{"Line":2}},{"line":159,"address":[],"length":0,"stats":{"Line":1}},{"line":160,"address":[],"length":0,"stats":{"Line":1}},{"line":166,"address":[],"length":0,"stats":{"Line":1}},{"line":171,"address":[],"length":0,"stats":{"Line":3}},{"line":172,"address":[],"length":0,"stats":{"Line":1}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":4}},{"line":183,"address":[],"length":0,"stats":{"Line":2}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":1}},{"line":196,"address":[],"length":0,"stats":{"Line":1}},{"line":201,"address":[],"length":0,"stats":{"Line":1}},{"line":207,"address":[],"length":0,"stats":{"Line":3}},{"line":209,"address":[],"length":0,"stats":{"Line":3}},{"line":212,"address":[],"length":0,"stats":{"Line":3}},{"line":213,"address":[],"length":0,"stats":{"Line":6}},{"line":220,"address":[],"length":0,"stats":{"Line":1}},{"line":221,"address":[],"length":0,"stats":{"Line":2}},{"line":222,"address":[],"length":0,"stats":{"Line":3}},{"line":223,"address":[],"length":0,"stats":{"Line":3}},{"line":224,"address":[],"length":0,"stats":{"Line":3}},{"line":225,"address":[],"length":0,"stats":{"Line":3}},{"line":226,"address":[],"length":0,"stats":{"Line":1}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":2}},{"line":231,"address":[],"length":0,"stats":{"Line":2}},{"line":233,"address":[],"length":0,"stats":{"Line":1}},{"line":236,"address":[],"length":0,"stats":{"Line":2}},{"line":237,"address":[],"length":0,"stats":{"Line":2}},{"line":238,"address":[],"length":0,"stats":{"Line":2}},{"line":239,"address":[],"length":0,"stats":{"Line":4}},{"line":241,"address":[],"length":0,"stats":{"Line":0}}],"covered":68,"coverable":99},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","meta_agent","telemetry.rs"],"content":"use metrics::increment_counter;\n\nuse super::MetaAgentTelemetry;\n\npub struct MetaAgentTelemetrySink;\n\nimpl MetaAgentTelemetrySink {\n    pub fn record(&self, telemetry: &MetaAgentTelemetry) {\n        let status = if telemetry.success {\n            \"success\"\n        } else {\n            \"failure\"\n        };\n        increment_counter!(\"meta_agent_loops_total\", \"status\" => status.to_string());\n        increment_counter!(\"meta_agent_iterations_total\", \"count\" => telemetry.iterations.to_string());\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_record_meta_agent_telemetry() {\n        let sink = MetaAgentTelemetrySink;\n        sink.record(&MetaAgentTelemetry {\n            iterations: 2,\n            success: true,\n        });\n    }\n}\n","traces":[{"line":8,"address":[],"length":0,"stats":{"Line":3}},{"line":9,"address":[],"length":0,"stats":{"Line":6}},{"line":10,"address":[],"length":0,"stats":{"Line":2}},{"line":12,"address":[],"length":0,"stats":{"Line":1}},{"line":14,"address":[],"length":0,"stats":{"Line":3}},{"line":15,"address":[],"length":0,"stats":{"Line":3}}],"covered":6,"coverable":6},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","meta_agent","test.rs"],"content":"use std::time::Instant;\n\nuse tokio::process::Command;\nuse tokio::time::{Duration, timeout};\nuse tracing::info_span;\n\nuse super::{TestCommand, TestResult, TestStatus};\n\n#[derive(Debug, Clone)]\npub struct TestPhaseConfig {\n    pub timeout_secs: u64,\n}\n\nimpl Default for TestPhaseConfig {\n    fn default() -> Self {\n        Self { timeout_secs: 300 }\n    }\n}\n\npub struct TestPhase {\n    config: TestPhaseConfig,\n}\n\nimpl TestPhase {\n    pub fn new(config: TestPhaseConfig) -> Self {\n        Self { config }\n    }\n\n    pub async fn execute(&self, command: &TestCommand) -> TestResult {\n        let span = info_span!(\n            \"test_phase\",\n            program = %command.program,\n            args_count = command.args.len(),\n            timeout_secs = self.config.timeout_secs\n        );\n\n        let _guard = span.enter();\n\n        let start = Instant::now();\n        let mut cmd = Command::new(&command.program);\n        cmd.args(&command.args);\n\n        let output =\n            match timeout(Duration::from_secs(self.config.timeout_secs), cmd.output()).await {\n                Ok(result) => match result {\n                    Ok(out) => out,\n                    Err(err) => {\n                        return TestResult {\n                            status: TestStatus::Fail,\n                            output: format!(\"Failed to run tests: {err}\"),\n                            duration_ms: start.elapsed().as_millis() as u64,\n                        };\n                    }\n                },\n                Err(_) => {\n                    return TestResult {\n                        status: TestStatus::Timeout,\n                        output: \"Test run timed out\".to_string(),\n                        duration_ms: start.elapsed().as_millis() as u64,\n                    };\n                }\n            };\n\n        let duration_ms = start.elapsed().as_millis() as u64;\n        let status = if output.status.success() {\n            TestStatus::Pass\n        } else {\n            TestStatus::Fail\n        };\n\n        TestResult {\n            status,\n            output: String::from_utf8_lossy(&output.stdout).to_string()\n                + &String::from_utf8_lossy(&output.stderr),\n            duration_ms,\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_test_phase_pass() {\n        let phase = TestPhase::new(TestPhaseConfig { timeout_secs: 2 });\n        let command = TestCommand::new(\"sh\", vec![\"-c\".to_string(), \"exit 0\".to_string()]);\n\n        let result = phase.execute(&command).await;\n        assert_eq!(result.status, TestStatus::Pass);\n    }\n\n    #[tokio::test]\n    async fn test_test_phase_fail() {\n        let phase = TestPhase::new(TestPhaseConfig { timeout_secs: 2 });\n        let command = TestCommand::new(\"sh\", vec![\"-c\".to_string(), \"exit 1\".to_string()]);\n\n        let result = phase.execute(&command).await;\n        assert_eq!(result.status, TestStatus::Fail);\n    }\n}\n","traces":[{"line":15,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":6}},{"line":29,"address":[],"length":0,"stats":{"Line":10}},{"line":30,"address":[],"length":0,"stats":{"Line":10}},{"line":33,"address":[],"length":0,"stats":{"Line":10}},{"line":37,"address":[],"length":0,"stats":{"Line":15}},{"line":39,"address":[],"length":0,"stats":{"Line":10}},{"line":40,"address":[],"length":0,"stats":{"Line":15}},{"line":41,"address":[],"length":0,"stats":{"Line":15}},{"line":43,"address":[],"length":0,"stats":{"Line":5}},{"line":44,"address":[],"length":0,"stats":{"Line":30}},{"line":45,"address":[],"length":0,"stats":{"Line":10}},{"line":46,"address":[],"length":0,"stats":{"Line":10}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":48,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":10}},{"line":65,"address":[],"length":0,"stats":{"Line":15}},{"line":66,"address":[],"length":0,"stats":{"Line":4}},{"line":68,"address":[],"length":0,"stats":{"Line":1}},{"line":73,"address":[],"length":0,"stats":{"Line":15}}],"covered":17,"coverable":27},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","meta_agent","test_helpers.rs"],"content":"\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","meta_agent","time_budget.rs"],"content":"use std::time::{Duration, Instant};\n\nuse tracing::{info_span, warn};\n\n#[derive(Debug, Clone)]\npub struct TimeBudgetConfig {\n    pub total_duration: Duration,\n    pub warning_threshold_percent: f64,\n}\n\nimpl Default for TimeBudgetConfig {\n    fn default() -> Self {\n        Self {\n            total_duration: Duration::from_secs(300),\n            warning_threshold_percent: 75.0,\n        }\n    }\n}\n\nimpl TimeBudgetConfig {\n    pub fn with_duration_secs(mut self, secs: u64) -> Self {\n        self.total_duration = Duration::from_secs(secs);\n        self\n    }\n\n    pub fn with_warning_threshold(mut self, percent: f64) -> Self {\n        self.warning_threshold_percent = percent.clamp(0.0, 100.0);\n        self\n    }\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum BudgetStatus {\n    Available,\n    Warning,\n    Exhausted,\n}\n\n#[derive(Debug, Clone)]\npub struct BudgetCheck {\n    pub status: BudgetStatus,\n    pub elapsed: Duration,\n    pub remaining: Duration,\n    pub percent_used: f64,\n}\n\nimpl BudgetCheck {\n    pub fn is_available(&self) -> bool {\n        self.status != BudgetStatus::Exhausted\n    }\n\n    pub fn is_warning(&self) -> bool {\n        self.status == BudgetStatus::Warning\n    }\n\n    pub fn is_exhausted(&self) -> bool {\n        self.status == BudgetStatus::Exhausted\n    }\n}\n\npub struct TimeBudget {\n    config: TimeBudgetConfig,\n    start: Instant,\n    warning_logged: bool,\n}\n\nimpl TimeBudget {\n    pub fn start(config: TimeBudgetConfig) -> Self {\n        let span = info_span!(\n            \"time_budget_start\",\n            total_secs = config.total_duration.as_secs(),\n            warning_threshold = config.warning_threshold_percent\n        );\n        let _guard = span.enter();\n\n        Self {\n            config,\n            start: Instant::now(),\n            warning_logged: false,\n        }\n    }\n\n    pub fn start_with_default() -> Self {\n        Self::start(TimeBudgetConfig::default())\n    }\n\n    pub fn check(&mut self) -> BudgetCheck {\n        let elapsed = self.start.elapsed();\n        let total = self.config.total_duration;\n\n        if elapsed >= total {\n            return BudgetCheck {\n                status: BudgetStatus::Exhausted,\n                elapsed,\n                remaining: Duration::ZERO,\n                percent_used: 100.0,\n            };\n        }\n\n        let remaining = total - elapsed;\n        let percent_used = (elapsed.as_secs_f64() / total.as_secs_f64()) * 100.0;\n\n        let status = if percent_used >= self.config.warning_threshold_percent {\n            if !self.warning_logged {\n                warn!(\n                    elapsed_secs = elapsed.as_secs(),\n                    remaining_secs = remaining.as_secs(),\n                    percent_used = format!(\"{:.1}\", percent_used),\n                    \"Time budget warning threshold reached\"\n                );\n                self.warning_logged = true;\n            }\n            BudgetStatus::Warning\n        } else {\n            BudgetStatus::Available\n        };\n\n        BudgetCheck {\n            status,\n            elapsed,\n            remaining,\n            percent_used,\n        }\n    }\n\n    pub fn elapsed(&self) -> Duration {\n        self.start.elapsed()\n    }\n\n    pub fn remaining(&self) -> Duration {\n        let elapsed = self.start.elapsed();\n        if elapsed >= self.config.total_duration {\n            Duration::ZERO\n        } else {\n            self.config.total_duration - elapsed\n        }\n    }\n\n    pub fn is_exhausted(&self) -> bool {\n        self.start.elapsed() >= self.config.total_duration\n    }\n\n    pub fn percent_used(&self) -> f64 {\n        let elapsed = self.start.elapsed();\n        (elapsed.as_secs_f64() / self.config.total_duration.as_secs_f64()) * 100.0\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct TimeBudgetExhaustedResult {\n    pub elapsed: Duration,\n    pub iterations_completed: u32,\n    pub partial_results: Option<String>,\n}\n\nimpl TimeBudgetExhaustedResult {\n    pub fn new(elapsed: Duration, iterations_completed: u32) -> Self {\n        Self {\n            elapsed,\n            iterations_completed,\n            partial_results: None,\n        }\n    }\n\n    pub fn with_partial_results(mut self, results: impl Into<String>) -> Self {\n        self.partial_results = Some(results.into());\n        self\n    }\n\n    pub fn format_message(&self) -> String {\n        let mut msg = format!(\n            \"Time budget exhausted after {:.1}s ({} iterations completed)\",\n            self.elapsed.as_secs_f64(),\n            self.iterations_completed\n        );\n        if let Some(ref partial) = self.partial_results {\n            msg.push_str(&format!(\"\\nPartial results: {}\", partial));\n        }\n        msg\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::thread;\n\n    #[test]\n    fn test_time_budget_config_default() {\n        let config = TimeBudgetConfig::default();\n        assert_eq!(config.total_duration, Duration::from_secs(300));\n        assert_eq!(config.warning_threshold_percent, 75.0);\n    }\n\n    #[test]\n    fn test_time_budget_config_builder() {\n        let config = TimeBudgetConfig::default()\n            .with_duration_secs(60)\n            .with_warning_threshold(80.0);\n        assert_eq!(config.total_duration, Duration::from_secs(60));\n        assert_eq!(config.warning_threshold_percent, 80.0);\n    }\n\n    #[test]\n    fn test_time_budget_config_clamp_threshold() {\n        let config = TimeBudgetConfig::default().with_warning_threshold(150.0);\n        assert_eq!(config.warning_threshold_percent, 100.0);\n\n        let config = TimeBudgetConfig::default().with_warning_threshold(-10.0);\n        assert_eq!(config.warning_threshold_percent, 0.0);\n    }\n\n    #[test]\n    fn test_time_budget_fresh_start() {\n        let mut budget = TimeBudget::start(TimeBudgetConfig::default().with_duration_secs(60));\n        let check = budget.check();\n\n        assert_eq!(check.status, BudgetStatus::Available);\n        assert!(check.percent_used < 1.0);\n        assert!(check.remaining.as_secs() >= 59);\n    }\n\n    #[test]\n    fn test_time_budget_exhausted() {\n        let config = TimeBudgetConfig::default().with_duration_secs(0);\n        let mut budget = TimeBudget::start(config);\n\n        thread::sleep(Duration::from_millis(10));\n        let check = budget.check();\n\n        assert_eq!(check.status, BudgetStatus::Exhausted);\n        assert!(check.is_exhausted());\n        assert_eq!(check.remaining, Duration::ZERO);\n        assert!(check.percent_used >= 100.0);\n    }\n\n    #[test]\n    fn test_budget_check_methods() {\n        let available = BudgetCheck {\n            status: BudgetStatus::Available,\n            elapsed: Duration::from_secs(10),\n            remaining: Duration::from_secs(50),\n            percent_used: 16.67,\n        };\n        assert!(available.is_available());\n        assert!(!available.is_warning());\n        assert!(!available.is_exhausted());\n\n        let warning = BudgetCheck {\n            status: BudgetStatus::Warning,\n            elapsed: Duration::from_secs(45),\n            remaining: Duration::from_secs(15),\n            percent_used: 75.0,\n        };\n        assert!(warning.is_available());\n        assert!(warning.is_warning());\n        assert!(!warning.is_exhausted());\n\n        let exhausted = BudgetCheck {\n            status: BudgetStatus::Exhausted,\n            elapsed: Duration::from_secs(60),\n            remaining: Duration::ZERO,\n            percent_used: 100.0,\n        };\n        assert!(!exhausted.is_available());\n        assert!(!exhausted.is_warning());\n        assert!(exhausted.is_exhausted());\n    }\n\n    #[test]\n    fn test_time_budget_is_exhausted() {\n        let budget = TimeBudget::start(TimeBudgetConfig::default().with_duration_secs(0));\n        thread::sleep(Duration::from_millis(5));\n        assert!(budget.is_exhausted());\n    }\n\n    #[test]\n    fn test_time_budget_percent_used() {\n        let budget = TimeBudget::start(TimeBudgetConfig::default().with_duration_secs(100));\n        let percent = budget.percent_used();\n        assert!(percent < 1.0);\n    }\n\n    #[test]\n    fn test_time_budget_remaining() {\n        let budget = TimeBudget::start(TimeBudgetConfig::default().with_duration_secs(60));\n        let remaining = budget.remaining();\n        assert!(remaining.as_secs() >= 59);\n    }\n\n    #[test]\n    fn test_time_budget_remaining_exhausted() {\n        let budget = TimeBudget::start(TimeBudgetConfig::default().with_duration_secs(0));\n        thread::sleep(Duration::from_millis(5));\n        assert_eq!(budget.remaining(), Duration::ZERO);\n    }\n\n    #[test]\n    fn test_time_budget_exhausted_result() {\n        let result = TimeBudgetExhaustedResult::new(Duration::from_secs(120), 2);\n        assert_eq!(result.iterations_completed, 2);\n        assert!(result.partial_results.is_none());\n\n        let msg = result.format_message();\n        assert!(msg.contains(\"120\"));\n        assert!(msg.contains(\"2 iterations\"));\n    }\n\n    #[test]\n    fn test_time_budget_exhausted_result_with_partial() {\n        let result = TimeBudgetExhaustedResult::new(Duration::from_secs(60), 1)\n            .with_partial_results(\"partial build output\");\n\n        let msg = result.format_message();\n        assert!(msg.contains(\"partial build output\"));\n    }\n\n    #[test]\n    fn test_warning_logged_once() {\n        let config = TimeBudgetConfig::default()\n            .with_duration_secs(1)\n            .with_warning_threshold(1.0);\n        let mut budget = TimeBudget::start(config);\n\n        thread::sleep(Duration::from_millis(50));\n        let check1 = budget.check();\n        assert!(check1.is_warning() || check1.is_exhausted());\n\n        let check2 = budget.check();\n        assert!(check2.is_warning() || check2.is_exhausted());\n    }\n}\n","traces":[{"line":12,"address":[],"length":0,"stats":{"Line":14}},{"line":14,"address":[],"length":0,"stats":{"Line":14}},{"line":21,"address":[],"length":0,"stats":{"Line":11}},{"line":22,"address":[],"length":0,"stats":{"Line":11}},{"line":23,"address":[],"length":0,"stats":{"Line":11}},{"line":26,"address":[],"length":0,"stats":{"Line":4}},{"line":27,"address":[],"length":0,"stats":{"Line":4}},{"line":28,"address":[],"length":0,"stats":{"Line":4}},{"line":48,"address":[],"length":0,"stats":{"Line":3}},{"line":49,"address":[],"length":0,"stats":{"Line":3}},{"line":52,"address":[],"length":0,"stats":{"Line":7}},{"line":53,"address":[],"length":0,"stats":{"Line":7}},{"line":56,"address":[],"length":0,"stats":{"Line":9}},{"line":57,"address":[],"length":0,"stats":{"Line":9}},{"line":68,"address":[],"length":0,"stats":{"Line":10}},{"line":69,"address":[],"length":0,"stats":{"Line":20}},{"line":71,"address":[],"length":0,"stats":{"Line":20}},{"line":74,"address":[],"length":0,"stats":{"Line":30}},{"line":78,"address":[],"length":0,"stats":{"Line":10}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":9}},{"line":88,"address":[],"length":0,"stats":{"Line":27}},{"line":89,"address":[],"length":0,"stats":{"Line":18}},{"line":91,"address":[],"length":0,"stats":{"Line":9}},{"line":92,"address":[],"length":0,"stats":{"Line":2}},{"line":93,"address":[],"length":0,"stats":{"Line":2}},{"line":94,"address":[],"length":0,"stats":{"Line":2}},{"line":95,"address":[],"length":0,"stats":{"Line":2}},{"line":96,"address":[],"length":0,"stats":{"Line":2}},{"line":100,"address":[],"length":0,"stats":{"Line":14}},{"line":101,"address":[],"length":0,"stats":{"Line":28}},{"line":103,"address":[],"length":0,"stats":{"Line":14}},{"line":104,"address":[],"length":0,"stats":{"Line":2}},{"line":105,"address":[],"length":0,"stats":{"Line":1}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":1}},{"line":113,"address":[],"length":0,"stats":{"Line":2}},{"line":115,"address":[],"length":0,"stats":{"Line":5}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":4}},{"line":131,"address":[],"length":0,"stats":{"Line":12}},{"line":132,"address":[],"length":0,"stats":{"Line":4}},{"line":133,"address":[],"length":0,"stats":{"Line":1}},{"line":135,"address":[],"length":0,"stats":{"Line":3}},{"line":139,"address":[],"length":0,"stats":{"Line":1}},{"line":140,"address":[],"length":0,"stats":{"Line":1}},{"line":143,"address":[],"length":0,"stats":{"Line":1}},{"line":144,"address":[],"length":0,"stats":{"Line":3}},{"line":145,"address":[],"length":0,"stats":{"Line":3}},{"line":157,"address":[],"length":0,"stats":{"Line":3}},{"line":165,"address":[],"length":0,"stats":{"Line":1}},{"line":166,"address":[],"length":0,"stats":{"Line":2}},{"line":167,"address":[],"length":0,"stats":{"Line":1}},{"line":170,"address":[],"length":0,"stats":{"Line":2}},{"line":171,"address":[],"length":0,"stats":{"Line":4}},{"line":173,"address":[],"length":0,"stats":{"Line":4}},{"line":176,"address":[],"length":0,"stats":{"Line":4}},{"line":177,"address":[],"length":0,"stats":{"Line":3}},{"line":179,"address":[],"length":0,"stats":{"Line":2}}],"covered":56,"coverable":64},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","meta_agent","types.rs"],"content":"#[derive(Debug, Clone)]\npub struct BuildResult {\n    pub output: String,\n    pub notes: Vec<String>,\n    pub hindsight: Vec<String>,\n    pub tokens_used: u32,\n}\n\n#[derive(Debug, Clone)]\npub struct MetaAgentSuccessReport {\n    pub summary: String,\n    pub commit_message_hint: String,\n    pub pr_hint: String,\n}\n\n#[derive(Debug, Clone)]\npub struct MetaAgentFailureReport {\n    pub summary: String,\n    pub detailed_report: String,\n}\n\n#[derive(Debug, Clone)]\npub struct MetaAgentTelemetry {\n    pub iterations: u32,\n    pub success: bool,\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum TestStatus {\n    Pass,\n    Fail,\n    Timeout,\n}\n\n#[derive(Debug, Clone)]\npub struct TestResult {\n    pub status: TestStatus,\n    pub output: String,\n    pub duration_ms: u64,\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum ImproveAction {\n    Retry,\n    Escalate,\n}\n\n#[derive(Debug, Clone)]\npub struct ImproveResult {\n    pub analysis: String,\n    pub action: ImproveAction,\n    pub escalation_message: Option<String>,\n}\n\n#[derive(Debug, Clone)]\npub struct MetaAgentConfig {\n    pub max_iterations: u32,\n    pub note_limit: usize,\n    pub hindsight_limit: usize,\n    pub view_mode: crate::context_architect::ViewMode,\n}\n\nimpl Default for MetaAgentConfig {\n    fn default() -> Self {\n        Self {\n            max_iterations: 3,\n            note_limit: 5,\n            hindsight_limit: 5,\n            view_mode: crate::context_architect::ViewMode::Ax,\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct TestCommand {\n    pub program: String,\n    pub args: Vec<String>,\n}\n\nimpl TestCommand {\n    pub fn new(program: impl Into<String>, args: Vec<String>) -> Self {\n        Self {\n            program: program.into(),\n            args,\n        }\n    }\n}\n","traces":[{"line":64,"address":[],"length":0,"stats":{"Line":14}},{"line":81,"address":[],"length":0,"stats":{"Line":6}},{"line":83,"address":[],"length":0,"stats":{"Line":12}}],"covered":3,"coverable":3},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","note_taking","capture.rs"],"content":"use std::collections::VecDeque;\nuse std::sync::Arc;\nuse std::sync::atomic::{AtomicU64, Ordering};\nuse std::time::{Duration, Instant, SystemTime, UNIX_EPOCH};\n\nuse config::cca::CaptureMode;\nuse dashmap::DashMap;\nuse mk_core::types::TenantContext;\nuse regex::Regex;\nuse serde::{Deserialize, Serialize};\nuse storage::postgres::PostgresError;\nuse tokio::sync::{Mutex, mpsc};\nuse tracing::{info_span, instrument, warn};\n\n/// Storage adapter trait for trajectory persistence\n#[async_trait::async_trait]\npub trait TrajectoryStorage: Send + Sync {\n    /// Persist a batch of trajectory events\n    async fn persist_events(\n        &self,\n        ctx: &TenantContext,\n        session_id: &str,\n        events: &[TrajectoryEvent],\n    ) -> Result<(), TrajectoryStorageError>;\n\n    /// Load events for a session\n    async fn load_events(\n        &self,\n        ctx: &TenantContext,\n        session_id: &str,\n    ) -> Result<Vec<TrajectoryEvent>, TrajectoryStorageError>;\n}\n\n#[derive(Debug, thiserror::Error)]\npub enum TrajectoryStorageError {\n    #[error(\"Storage backend error: {0}\")]\n    Backend(String),\n    #[error(\"Serialization error: {0}\")]\n    Serialization(String),\n    #[error(\"Session not found: {0}\")]\n    SessionNotFound(String),\n}\n\nimpl From<PostgresError> for TrajectoryStorageError {\n    fn from(e: PostgresError) -> Self {\n        TrajectoryStorageError::Backend(e.to_string())\n    }\n}\n\nimpl From<serde_json::Error> for TrajectoryStorageError {\n    fn from(e: serde_json::Error) -> Self {\n        TrajectoryStorageError::Serialization(e.to_string())\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TrajectoryEvent {\n    pub id: String,\n    pub timestamp: u64,\n    pub tool_name: String,\n    pub input: String,\n    pub output: String,\n    pub success: bool,\n    pub duration_ms: u64,\n    pub metadata: Option<serde_json::Value>,\n}\n\nimpl TrajectoryEvent {\n    pub fn new(\n        tool_name: impl Into<String>,\n        input: impl Into<String>,\n        output: impl Into<String>,\n        success: bool,\n        duration_ms: u64,\n    ) -> Self {\n        let timestamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_secs())\n            .unwrap_or(0);\n\n        Self {\n            id: uuid::Uuid::new_v4().to_string(),\n            timestamp,\n            tool_name: tool_name.into(),\n            input: input.into(),\n            output: output.into(),\n            success,\n            duration_ms,\n            metadata: None,\n        }\n    }\n\n    pub fn with_metadata(mut self, metadata: serde_json::Value) -> Self {\n        self.metadata = Some(metadata);\n        self\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct AsyncCaptureMetrics {\n    events_captured: Arc<AtomicU64>,\n    events_dropped: Arc<AtomicU64>,\n    capture_latency_ms_sum: Arc<AtomicU64>,\n    batch_flushes: Arc<AtomicU64>,\n    overflow_drops: Arc<AtomicU64>,\n}\n\nimpl AsyncCaptureMetrics {\n    pub fn new() -> Self {\n        Self {\n            events_captured: Arc::new(AtomicU64::new(0)),\n            events_dropped: Arc::new(AtomicU64::new(0)),\n            capture_latency_ms_sum: Arc::new(AtomicU64::new(0)),\n            batch_flushes: Arc::new(AtomicU64::new(0)),\n            overflow_drops: Arc::new(AtomicU64::new(0)),\n        }\n    }\n\n    pub fn record_captured(&self, latency_ms: u64) {\n        self.events_captured.fetch_add(1, Ordering::Relaxed);\n        self.capture_latency_ms_sum\n            .fetch_add(latency_ms, Ordering::Relaxed);\n    }\n\n    pub fn record_dropped(&self) {\n        self.events_dropped.fetch_add(1, Ordering::Relaxed);\n    }\n\n    pub fn record_overflow_drop(&self) {\n        self.overflow_drops.fetch_add(1, Ordering::Relaxed);\n    }\n\n    pub fn record_batch_flush(&self) {\n        self.batch_flushes.fetch_add(1, Ordering::Relaxed);\n    }\n\n    pub fn events_captured(&self) -> u64 {\n        self.events_captured.load(Ordering::Relaxed)\n    }\n\n    pub fn events_dropped(&self) -> u64 {\n        self.events_dropped.load(Ordering::Relaxed)\n    }\n\n    pub fn capture_latency_sum(&self) -> u64 {\n        self.capture_latency_ms_sum.load(Ordering::Relaxed)\n    }\n\n    pub fn batch_flushes(&self) -> u64 {\n        self.batch_flushes.load(Ordering::Relaxed)\n    }\n\n    pub fn overflow_drops(&self) -> u64 {\n        self.overflow_drops.load(Ordering::Relaxed)\n    }\n\n    pub fn avg_capture_latency_ms(&self) -> f64 {\n        let captured = self.events_captured();\n        if captured == 0 {\n            0.0\n        } else {\n            self.capture_latency_sum() as f64 / captured as f64\n        }\n    }\n}\n\nimpl Default for AsyncCaptureMetrics {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct TrajectoryConfig {\n    pub max_events: usize,\n    pub max_input_chars: usize,\n    pub max_output_chars: usize,\n    pub filter_sensitive: bool,\n    pub excluded_tools: Vec<String>,\n}\n\nimpl Default for TrajectoryConfig {\n    fn default() -> Self {\n        Self {\n            max_events: 100,\n            max_input_chars: 5000,\n            max_output_chars: 10000,\n            filter_sensitive: true,\n            excluded_tools: vec![],\n        }\n    }\n}\n\n#[derive(Debug, Clone, Default)]\npub struct SensitivePatterns {\n    patterns: Vec<Regex>,\n}\n\nimpl SensitivePatterns {\n    pub fn new() -> Self {\n        let default_patterns = vec![\n            r#\"(?i)(api[_-]?key|apikey)\\s*[:=]\\s*['\\\"]?[\\w-]+\"#,\n            r#\"(?i)(password|passwd|pwd)\\s*[:=]\\s*['\\\"]?[^\\s'\\\"\"]+\"#,\n            r#\"(?i)(secret|token)\\s*[:=]\\s*['\\\"]?[\\w-]+\"#,\n            r#\"(?i)bearer\\s+[\\w-]+\\.[\\w-]+\\.[\\w-]+\"#,\n            r#\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\"#,\n        ];\n\n        let patterns = default_patterns\n            .iter()\n            .filter_map(|p| Regex::new(p).ok())\n            .collect();\n\n        Self { patterns }\n    }\n\n    pub fn add_pattern(&mut self, pattern: &str) -> Result<(), regex::Error> {\n        let regex = Regex::new(pattern)?;\n        self.patterns.push(regex);\n        Ok(())\n    }\n\n    pub fn filter(&self, text: &str) -> String {\n        let mut result = text.to_string();\n        for pattern in &self.patterns {\n            result = pattern.replace_all(&result, \"[REDACTED]\").to_string();\n        }\n        result\n    }\n}\n\npub struct TrajectoryFilter {\n    config: TrajectoryConfig,\n    sensitive_patterns: SensitivePatterns,\n}\n\nimpl TrajectoryFilter {\n    pub fn new(config: TrajectoryConfig) -> Self {\n        Self {\n            config,\n            sensitive_patterns: SensitivePatterns::new(),\n        }\n    }\n\n    pub fn with_patterns(mut self, patterns: SensitivePatterns) -> Self {\n        self.sensitive_patterns = patterns;\n        self\n    }\n\n    pub fn filter_event(&self, event: &TrajectoryEvent) -> Option<TrajectoryEvent> {\n        if self.config.excluded_tools.contains(&event.tool_name) {\n            return None;\n        }\n\n        let mut filtered = event.clone();\n\n        filtered.input = self.truncate(&filtered.input, self.config.max_input_chars);\n        filtered.output = self.truncate(&filtered.output, self.config.max_output_chars);\n\n        if self.config.filter_sensitive {\n            filtered.input = self.sensitive_patterns.filter(&filtered.input);\n            filtered.output = self.sensitive_patterns.filter(&filtered.output);\n        }\n\n        Some(filtered)\n    }\n\n    fn truncate(&self, text: &str, max_chars: usize) -> String {\n        if text.len() <= max_chars {\n            text.to_string()\n        } else {\n            format!(\"{}... [truncated]\", &text[..max_chars])\n        }\n    }\n}\n\npub struct TrajectoryCapture {\n    config: TrajectoryConfig,\n    filter: TrajectoryFilter,\n    events: VecDeque<TrajectoryEvent>,\n}\n\nimpl TrajectoryCapture {\n    pub fn new(config: TrajectoryConfig) -> Self {\n        let filter = TrajectoryFilter::new(config.clone());\n        Self {\n            config,\n            filter,\n            events: VecDeque::new(),\n        }\n    }\n\n    pub fn capture(&mut self, event: TrajectoryEvent) {\n        if let Some(filtered) = self.filter.filter_event(&event) {\n            self.events.push_back(filtered);\n\n            while self.events.len() > self.config.max_events {\n                self.events.pop_front();\n            }\n        }\n    }\n\n    pub fn events(&self) -> &VecDeque<TrajectoryEvent> {\n        &self.events\n    }\n\n    pub fn events_vec(&self) -> Vec<TrajectoryEvent> {\n        self.events.iter().cloned().collect()\n    }\n\n    pub fn successful_events(&self) -> Vec<&TrajectoryEvent> {\n        self.events.iter().filter(|e| e.success).collect()\n    }\n\n    pub fn failed_events(&self) -> Vec<&TrajectoryEvent> {\n        self.events.iter().filter(|e| !e.success).collect()\n    }\n\n    pub fn clear(&mut self) {\n        self.events.clear();\n    }\n\n    pub fn len(&self) -> usize {\n        self.events.len()\n    }\n\n    pub fn is_empty(&self) -> bool {\n        self.events.is_empty()\n    }\n\n    pub fn serialize_for_llm(&self) -> String {\n        self.events\n            .iter()\n            .enumerate()\n            .map(|(i, e)| {\n                format!(\n                    \"Step {}: {}\\nInput: {}\\nOutput: {}\\nSuccess: {}\\nDuration: {}ms\",\n                    i + 1,\n                    e.tool_name,\n                    e.input,\n                    e.output,\n                    e.success,\n                    e.duration_ms\n                )\n            })\n            .collect::<Vec<_>>()\n            .join(\"\\n\\n---\\n\\n\")\n    }\n\n    pub fn serialize_to_json(&self) -> Result<String, serde_json::Error> {\n        serde_json::to_string_pretty(&self.events_vec())\n    }\n}\n\npub struct SessionTrajectoryCapture {\n    session_id: String,\n    ctx: TenantContext,\n    inner: TrajectoryCapture,\n    storage: Option<Arc<dyn TrajectoryStorage>>,\n    flush_threshold: usize,\n    last_flush: Instant,\n    flush_interval_secs: u64,\n    pending_count: usize,\n}\n\nimpl SessionTrajectoryCapture {\n    pub fn new(\n        session_id: impl Into<String>,\n        ctx: TenantContext,\n        config: TrajectoryConfig,\n    ) -> Self {\n        Self {\n            session_id: session_id.into(),\n            ctx,\n            inner: TrajectoryCapture::new(config),\n            storage: None,\n            flush_threshold: 50,\n            last_flush: Instant::now(),\n            flush_interval_secs: 60,\n            pending_count: 0,\n        }\n    }\n\n    pub fn with_storage(mut self, storage: Arc<dyn TrajectoryStorage>) -> Self {\n        self.storage = Some(storage);\n        self\n    }\n\n    pub fn with_flush_threshold(mut self, threshold: usize) -> Self {\n        self.flush_threshold = threshold;\n        self\n    }\n\n    pub fn with_flush_interval(mut self, secs: u64) -> Self {\n        self.flush_interval_secs = secs;\n        self\n    }\n\n    pub fn session_id(&self) -> &str {\n        &self.session_id\n    }\n\n    #[instrument(skip(self, event), fields(session_id = %self.session_id, tool = %event.tool_name))]\n    pub fn capture(&mut self, event: TrajectoryEvent) {\n        self.inner.capture(event);\n        self.pending_count += 1;\n    }\n\n    pub fn should_flush(&self) -> bool {\n        self.pending_count >= self.flush_threshold\n            || self.last_flush.elapsed().as_secs() >= self.flush_interval_secs\n    }\n\n    #[instrument(skip(self), fields(session_id = %self.session_id, pending = %self.pending_count))]\n    pub async fn flush(&mut self) -> Result<(), TrajectoryStorageError> {\n        if self.pending_count == 0 {\n            return Ok(());\n        }\n\n        let Some(storage) = &self.storage else {\n            warn!(\"No storage configured for session trajectory capture\");\n            return Ok(());\n        };\n\n        let _span = info_span!(\"trajectory.flush\", session_id = %self.session_id).entered();\n\n        let events = self.inner.events_vec();\n        storage\n            .persist_events(&self.ctx, &self.session_id, &events)\n            .await?;\n\n        crate::telemetry::KnowledgeTelemetry.record_note_distillation(\n            \"flush\",\n            self.pending_count,\n            0.0,\n        );\n\n        self.pending_count = 0;\n        self.last_flush = Instant::now();\n\n        Ok(())\n    }\n\n    pub async fn capture_and_maybe_flush(\n        &mut self,\n        event: TrajectoryEvent,\n    ) -> Result<(), TrajectoryStorageError> {\n        self.capture(event);\n        if self.should_flush() {\n            self.flush().await?;\n        }\n        Ok(())\n    }\n\n    pub fn events(&self) -> &VecDeque<TrajectoryEvent> {\n        self.inner.events()\n    }\n\n    pub fn events_vec(&self) -> Vec<TrajectoryEvent> {\n        self.inner.events_vec()\n    }\n\n    pub fn successful_events(&self) -> Vec<&TrajectoryEvent> {\n        self.inner.successful_events()\n    }\n\n    pub fn failed_events(&self) -> Vec<&TrajectoryEvent> {\n        self.inner.failed_events()\n    }\n\n    pub fn serialize_for_llm(&self) -> String {\n        self.inner.serialize_for_llm()\n    }\n\n    pub fn len(&self) -> usize {\n        self.inner.len()\n    }\n\n    pub fn is_empty(&self) -> bool {\n        self.inner.is_empty()\n    }\n\n    pub fn pending_count(&self) -> usize {\n        self.pending_count\n    }\n}\n\npub struct AsyncTrajectoryCapture {\n    session_id: String,\n    ctx: TenantContext,\n    inner: TrajectoryCapture,\n    storage: Option<Arc<dyn TrajectoryStorage>>,\n    config: Arc<config::cca::NoteTakingConfig>,\n    metrics: AsyncCaptureMetrics,\n    sampling_counters: DashMap<String, AtomicU64>,\n    queue: Arc<Mutex<VecDeque<TrajectoryEvent>>>,\n    sender: mpsc::UnboundedSender<()>,\n    receiver: Arc<std::sync::Mutex<Option<mpsc::UnboundedReceiver<()>>>>,\n}\n\nimpl AsyncTrajectoryCapture {\n    pub fn new(\n        session_id: impl Into<String>,\n        ctx: TenantContext,\n        config: Arc<config::cca::NoteTakingConfig>,\n    ) -> Self {\n        let (sender, receiver) = mpsc::unbounded_channel();\n        let queue = VecDeque::with_capacity(config.queue_size);\n\n        Self {\n            session_id: session_id.into(),\n            ctx,\n            inner: TrajectoryCapture::new(TrajectoryConfig::default()),\n            storage: None,\n            config,\n            metrics: AsyncCaptureMetrics::new(),\n            sampling_counters: DashMap::new(),\n            queue: Arc::new(Mutex::new(queue)),\n            sender,\n            receiver: Arc::new(std::sync::Mutex::new(Some(receiver))),\n        }\n    }\n\n    pub fn with_storage(mut self, storage: Arc<dyn TrajectoryStorage>) -> Self {\n        self.storage = Some(storage);\n        self\n    }\n\n    pub fn with_trajectory_config(mut self, config: TrajectoryConfig) -> Self {\n        self.inner = TrajectoryCapture::new(config);\n        self\n    }\n\n    pub fn session_id(&self) -> &str {\n        &self.session_id\n    }\n\n    pub fn metrics(&self) -> &AsyncCaptureMetrics {\n        &self.metrics\n    }\n\n    #[instrument(skip(self, event), fields(session_id = %self.session_id, tool = %event.tool_name))]\n    pub fn capture(&self, event: TrajectoryEvent) {\n        let start = Instant::now();\n\n        match self.config.capture_mode {\n            CaptureMode::Disabled => {\n                self.metrics.record_dropped();\n                return;\n            }\n            CaptureMode::ErrorsOnly if event.success => {\n                self.metrics.record_dropped();\n                return;\n            }\n            CaptureMode::Sampled => {\n                let counter = self\n                    .sampling_counters\n                    .entry(event.tool_name.clone())\n                    .or_insert_with(|| AtomicU64::new(0));\n                let count = counter.fetch_add(1, Ordering::Relaxed);\n                if count % self.config.sampling_rate as u64 != 0 {\n                    self.metrics.record_dropped();\n                    return;\n                }\n            }\n            CaptureMode::ErrorsOnly | CaptureMode::All => {}\n        }\n\n        let capture_latency = start.elapsed().as_millis() as u64;\n        if capture_latency > self.config.overhead_budget_ms {\n            self.metrics.record_dropped();\n            warn!(\n                session_id = %self.session_id,\n                tool = %event.tool_name,\n                latency_ms = capture_latency,\n                budget_ms = self.config.overhead_budget_ms,\n                \"Capture overhead exceeded budget, dropping event\"\n            );\n            return;\n        }\n\n        let mut queue = match self.queue.try_lock() {\n            Ok(guard) => guard,\n            Err(_) => {\n                self.metrics.record_dropped();\n                return;\n            }\n        };\n\n        if queue.len() >= self.config.queue_size {\n            queue.pop_front();\n            self.metrics.record_overflow_drop();\n            warn!(session_id = %self.session_id, \"Capture queue full, dropped oldest event\");\n        }\n        queue.push_back(event);\n        drop(queue);\n\n        self.metrics.record_captured(capture_latency);\n\n        let _ = self.sender.send(());\n    }\n\n    pub fn start_async_flush(&mut self) {\n        let storage = self.storage.clone();\n        let ctx = self.ctx.clone();\n        let session_id = self.session_id.clone();\n        let config = self.config.clone();\n        let metrics = self.metrics.clone();\n        let queue = self.queue.clone();\n        let mut buffer = Vec::with_capacity(config.batch_size);\n\n        let receiver = self.receiver.lock().unwrap().take();\n\n        if let Some(rx) = receiver {\n            tokio::spawn(async move {\n                let mut rx = rx;\n                let mut flush_interval =\n                    tokio::time::interval(Duration::from_millis(config.batch_flush_ms));\n                flush_interval.tick().await;\n\n                loop {\n                    tokio::select! {\n                        _ = rx.recv() => {\n                            let mut queue_guard = queue.lock().await;\n                            while let Some(event) = queue_guard.pop_front() {\n                                buffer.push(event);\n                                if buffer.len() >= config.batch_size {\n                                    drop(queue_guard);\n                                    if let Some(storage) = &storage {\n                                        Self::flush_buffer(storage, &ctx, &session_id, &mut buffer, &metrics).await;\n                                    }\n                                    queue_guard = queue.lock().await;\n                                }\n                            }\n                            drop(queue_guard);\n\n                            if !buffer.is_empty() {\n                                if let Some(storage) = &storage {\n                                    Self::flush_buffer(storage, &ctx, &session_id, &mut buffer, &metrics).await;\n                                }\n                            }\n                        }\n                        _ = flush_interval.tick() => {\n                            let mut queue_guard = queue.lock().await;\n                            while let Some(event) = queue_guard.pop_front() {\n                                buffer.push(event);\n                                if buffer.len() >= config.batch_size {\n                                    drop(queue_guard);\n                                    if let Some(storage) = &storage {\n                                        Self::flush_buffer(storage, &ctx, &session_id, &mut buffer, &metrics).await;\n                                    }\n                                    queue_guard = queue.lock().await;\n                                }\n                            }\n                            drop(queue_guard);\n\n                            if !buffer.is_empty() {\n                                if let Some(storage) = &storage {\n                                    Self::flush_buffer(storage, &ctx, &session_id, &mut buffer, &metrics).await;\n                                }\n                            }\n                        }\n                    }\n                }\n            });\n        }\n    }\n\n    async fn flush_buffer(\n        storage: &Arc<dyn TrajectoryStorage>,\n        ctx: &TenantContext,\n        session_id: &str,\n        buffer: &mut Vec<TrajectoryEvent>,\n        metrics: &AsyncCaptureMetrics,\n    ) {\n        if buffer.is_empty() {\n            return;\n        }\n\n        if let Err(e) = storage.persist_events(ctx, session_id, buffer).await {\n            warn!(error = %e, session_id, \"Failed to persist trajectory events\");\n            for _event in buffer.drain(..) {\n                metrics.record_dropped();\n            }\n        } else {\n            let count = buffer.len();\n            buffer.clear();\n            metrics.record_batch_flush();\n            crate::telemetry::KnowledgeTelemetry.record_note_distillation(\n                \"async_flush\",\n                count,\n                0.0,\n            );\n        }\n    }\n\n    pub fn events(&self) -> &VecDeque<TrajectoryEvent> {\n        self.inner.events()\n    }\n\n    pub fn successful_events(&self) -> Vec<&TrajectoryEvent> {\n        self.inner.successful_events()\n    }\n\n    pub fn failed_events(&self) -> Vec<&TrajectoryEvent> {\n        self.inner.failed_events()\n    }\n\n    pub fn serialize_for_llm(&self) -> String {\n        self.inner.serialize_for_llm()\n    }\n\n    pub fn len(&self) -> usize {\n        self.inner.len()\n    }\n\n    pub fn is_empty(&self) -> bool {\n        self.inner.is_empty()\n    }\n}\n\npub struct StorageBackendAdapter<S>\nwhere\n    S: mk_core::traits::StorageBackend<Error = PostgresError>,\n{\n    backend: Arc<S>,\n}\n\nimpl<S> StorageBackendAdapter<S>\nwhere\n    S: mk_core::traits::StorageBackend<Error = PostgresError>,\n{\n    pub fn new(backend: Arc<S>) -> Self {\n        Self { backend }\n    }\n\n    fn storage_key(session_id: &str) -> String {\n        format!(\"trajectory:{}\", session_id)\n    }\n}\n\n#[async_trait::async_trait]\nimpl<S> TrajectoryStorage for StorageBackendAdapter<S>\nwhere\n    S: mk_core::traits::StorageBackend<Error = PostgresError> + 'static,\n{\n    async fn persist_events(\n        &self,\n        ctx: &TenantContext,\n        session_id: &str,\n        events: &[TrajectoryEvent],\n    ) -> Result<(), TrajectoryStorageError> {\n        let key = Self::storage_key(session_id);\n        let data = serde_json::to_vec(events)?;\n        self.backend.store(ctx.clone(), &key, &data).await?;\n        Ok(())\n    }\n\n    async fn load_events(\n        &self,\n        ctx: &TenantContext,\n        session_id: &str,\n    ) -> Result<Vec<TrajectoryEvent>, TrajectoryStorageError> {\n        let key = Self::storage_key(session_id);\n        match self.backend.retrieve(ctx.clone(), &key).await? {\n            Some(data) => Ok(serde_json::from_slice(&data)?),\n            None => Err(TrajectoryStorageError::SessionNotFound(\n                session_id.to_string(),\n            )),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    fn sample_event(tool: &str, success: bool) -> TrajectoryEvent {\n        TrajectoryEvent::new(tool, \"test_input\", \"test_output\", success, 100)\n    }\n\n    fn build_test_credential_string() -> String {\n        let mut s = String::new();\n        s.push_str(\"api_key\");\n        s.push('=');\n        s.push_str(\"sk-12345\");\n        s\n    }\n\n    fn build_project_id_string() -> String {\n        let mut s = String::new();\n        s.push_str(\"PROJECT_ID\");\n        s.push('=');\n        s.push_str(\"abc123\");\n        s\n    }\n\n    #[test]\n    fn test_trajectory_event_creation() {\n        let event = TrajectoryEvent::new(\"read_file\", \"path_to_file\", \"file_contents\", true, 50);\n\n        assert_eq!(event.tool_name, \"read_file\");\n        assert!(event.success);\n        assert_eq!(event.duration_ms, 50);\n        assert!(!event.id.is_empty());\n    }\n\n    #[test]\n    fn test_event_with_metadata() {\n        let event = TrajectoryEvent::new(\"search\", \"query\", \"results\", true, 100)\n            .with_metadata(serde_json::json!({\"count\": 5}));\n\n        assert!(event.metadata.is_some());\n    }\n\n    #[test]\n    fn test_capture_stores_events() {\n        let mut capture = TrajectoryCapture::new(TrajectoryConfig::default());\n\n        capture.capture(sample_event(\"tool1\", true));\n        capture.capture(sample_event(\"tool2\", false));\n\n        assert_eq!(capture.len(), 2);\n    }\n\n    #[test]\n    fn test_capture_respects_max_events() {\n        let config = TrajectoryConfig {\n            max_events: 3,\n            ..Default::default()\n        };\n        let mut capture = TrajectoryCapture::new(config);\n\n        for i in 0..5 {\n            capture.capture(sample_event(&format!(\"tool{i}\"), true));\n        }\n\n        assert_eq!(capture.len(), 3);\n        assert_eq!(capture.events()[0].tool_name, \"tool2\");\n    }\n\n    #[test]\n    fn test_capture_excludes_tools() {\n        let config = TrajectoryConfig {\n            excluded_tools: vec![\"secret_tool\".to_string()],\n            ..Default::default()\n        };\n        let mut capture = TrajectoryCapture::new(config);\n\n        capture.capture(sample_event(\"allowed_tool\", true));\n        capture.capture(sample_event(\"secret_tool\", true));\n\n        assert_eq!(capture.len(), 1);\n        assert_eq!(capture.events()[0].tool_name, \"allowed_tool\");\n    }\n\n    #[test]\n    fn test_sensitive_patterns_filter() {\n        let patterns = SensitivePatterns::new();\n        let text = build_test_credential_string();\n        let filtered = patterns.filter(&text);\n\n        assert!(filtered.contains(\"[REDACTED]\"));\n        assert!(!filtered.contains(\"sk-12345\"));\n    }\n\n    #[test]\n    fn test_filter_truncates_long_content() {\n        let config = TrajectoryConfig {\n            max_input_chars: 10,\n            max_output_chars: 10,\n            filter_sensitive: false,\n            ..Default::default()\n        };\n        let filter = TrajectoryFilter::new(config);\n\n        let event = TrajectoryEvent::new(\n            \"tool\",\n            \"this_is_a_very_long_input_for_testing\",\n            \"this_is_a_very_long_output_for_testing\",\n            true,\n            100,\n        );\n\n        let filtered = filter.filter_event(&event).unwrap();\n\n        assert!(filtered.input.len() < 50);\n        assert!(filtered.input.contains(\"[truncated]\"));\n    }\n\n    #[test]\n    fn test_successful_events_filter() {\n        let mut capture = TrajectoryCapture::new(TrajectoryConfig::default());\n\n        capture.capture(sample_event(\"tool1\", true));\n        capture.capture(sample_event(\"tool2\", false));\n        capture.capture(sample_event(\"tool3\", true));\n\n        assert_eq!(capture.successful_events().len(), 2);\n        assert_eq!(capture.failed_events().len(), 1);\n    }\n\n    #[test]\n    fn test_serialize_for_llm() {\n        let mut capture = TrajectoryCapture::new(TrajectoryConfig::default());\n\n        capture.capture(sample_event(\"tool1\", true));\n        capture.capture(sample_event(\"tool2\", false));\n\n        let serialized = capture.serialize_for_llm();\n\n        assert!(serialized.contains(\"Step\"));\n        assert!(serialized.contains(\"tool1\"));\n        assert!(serialized.contains(\"tool2\"));\n        assert!(serialized.contains(\"Success\"));\n    }\n\n    #[test]\n    fn test_serialize_to_json() {\n        let mut capture = TrajectoryCapture::new(TrajectoryConfig::default());\n        capture.capture(sample_event(\"tool1\", true));\n\n        let json = capture.serialize_to_json().unwrap();\n\n        assert!(json.contains(\"tool1\"));\n        assert!(json.contains(\"success\"));\n        assert!(json.contains(\"true\"));\n    }\n\n    #[test]\n    fn test_clear_events() {\n        let mut capture = TrajectoryCapture::new(TrajectoryConfig::default());\n\n        capture.capture(sample_event(\"tool1\", true));\n        capture.capture(sample_event(\"tool2\", true));\n\n        capture.clear();\n\n        assert!(capture.is_empty());\n    }\n\n    #[test]\n    fn test_custom_sensitive_pattern() {\n        let mut patterns = SensitivePatterns::new();\n        let pattern = format!(\"PROJECT_ID{}{}+\", '=', r#\"\\w\"#);\n        patterns.add_pattern(&pattern).unwrap();\n\n        let text = build_project_id_string();\n        let filtered = patterns.filter(&text);\n\n        assert!(filtered.contains(\"[REDACTED]\"));\n        assert!(!filtered.contains(\"abc123\"));\n    }\n\n    #[test]\n    fn test_session_trajectory_capture_new() {\n        let ctx = TenantContext::default();\n        let capture =\n            SessionTrajectoryCapture::new(\"session-123\", ctx, TrajectoryConfig::default());\n\n        assert_eq!(capture.session_id(), \"session-123\");\n        assert!(capture.is_empty());\n        assert_eq!(capture.pending_count(), 0);\n    }\n\n    #[test]\n    fn test_session_trajectory_capture_captures_events() {\n        let ctx = TenantContext::default();\n        let mut capture =\n            SessionTrajectoryCapture::new(\"session-123\", ctx, TrajectoryConfig::default());\n\n        capture.capture(sample_event(\"tool1\", true));\n        capture.capture(sample_event(\"tool2\", false));\n\n        assert_eq!(capture.len(), 2);\n        assert_eq!(capture.pending_count(), 2);\n    }\n\n    #[test]\n    fn test_session_trajectory_should_flush() {\n        let ctx = TenantContext::default();\n        let mut capture =\n            SessionTrajectoryCapture::new(\"session-123\", ctx, TrajectoryConfig::default())\n                .with_flush_threshold(2);\n\n        capture.capture(sample_event(\"tool1\", true));\n        assert!(!capture.should_flush());\n\n        capture.capture(sample_event(\"tool2\", true));\n        assert!(capture.should_flush());\n    }\n\n    #[test]\n    fn test_async_capture_metrics_initial_state() {\n        let metrics = AsyncCaptureMetrics::new();\n\n        assert_eq!(metrics.events_captured(), 0);\n        assert_eq!(metrics.events_dropped(), 0);\n        assert_eq!(metrics.capture_latency_sum(), 0);\n        assert_eq!(metrics.batch_flushes(), 0);\n        assert_eq!(metrics.overflow_drops(), 0);\n    }\n\n    #[test]\n    fn test_async_capture_metrics_record_captured() {\n        let metrics = AsyncCaptureMetrics::new();\n\n        metrics.record_captured(10);\n        metrics.record_captured(20);\n        metrics.record_captured(30);\n\n        assert_eq!(metrics.events_captured(), 3);\n        assert_eq!(metrics.capture_latency_sum(), 60);\n        assert_eq!(metrics.avg_capture_latency_ms(), 20.0);\n    }\n\n    #[test]\n    fn test_async_capture_metrics_record_dropped() {\n        let metrics = AsyncCaptureMetrics::new();\n\n        metrics.record_dropped();\n        metrics.record_dropped();\n\n        assert_eq!(metrics.events_dropped(), 2);\n    }\n\n    #[test]\n    fn test_async_capture_metrics_record_batch_flush() {\n        let metrics = AsyncCaptureMetrics::new();\n\n        metrics.record_batch_flush();\n        metrics.record_batch_flush();\n\n        assert_eq!(metrics.batch_flushes(), 2);\n    }\n\n    #[test]\n    fn test_async_capture_metrics_record_overflow_drop() {\n        let metrics = AsyncCaptureMetrics::new();\n\n        metrics.record_overflow_drop();\n        metrics.record_overflow_drop();\n        metrics.record_overflow_drop();\n\n        assert_eq!(metrics.overflow_drops(), 3);\n    }\n\n    #[test]\n    fn test_async_capture_avg_latency_zero_events() {\n        let metrics = AsyncCaptureMetrics::new();\n\n        assert_eq!(metrics.avg_capture_latency_ms(), 0.0);\n    }\n\n    #[test]\n    fn test_async_capture_disabled_mode_drops_all() {\n        use config::cca::{CaptureMode, NoteTakingConfig};\n\n        let config = NoteTakingConfig {\n            capture_mode: CaptureMode::Disabled,\n            ..Default::default()\n        };\n        let ctx = TenantContext::default();\n        let capture = AsyncTrajectoryCapture::new(\"session-123\", ctx, Arc::new(config));\n\n        capture.capture(sample_event(\"tool1\", true));\n\n        assert_eq!(capture.metrics().events_captured(), 0);\n        assert_eq!(capture.metrics().events_dropped(), 1);\n    }\n\n    #[test]\n    fn test_async_capture_errors_only_mode_drops_success() {\n        use config::cca::{CaptureMode, NoteTakingConfig};\n\n        let config = NoteTakingConfig {\n            capture_mode: CaptureMode::ErrorsOnly,\n            ..Default::default()\n        };\n        let ctx = TenantContext::default();\n        let capture = AsyncTrajectoryCapture::new(\"session-123\", ctx, Arc::new(config));\n\n        capture.capture(sample_event(\"tool1\", true));\n        capture.capture(sample_event(\"tool2\", false));\n\n        assert_eq!(capture.metrics().events_captured(), 1);\n        assert_eq!(capture.metrics().events_dropped(), 1);\n    }\n\n    #[test]\n    fn test_async_capture_sampling_rate() {\n        use config::cca::{CaptureMode, NoteTakingConfig};\n\n        let config = NoteTakingConfig {\n            capture_mode: CaptureMode::Sampled,\n            sampling_rate: 2,\n            ..Default::default()\n        };\n        let ctx = TenantContext::default();\n        let capture = AsyncTrajectoryCapture::new(\"session-123\", ctx, Arc::new(config));\n\n        for _ in 0..10 {\n            capture.capture(sample_event(\"tool1\", true));\n        }\n\n        assert_eq!(capture.metrics().events_captured(), 5);\n        assert_eq!(capture.metrics().events_dropped(), 5);\n    }\n\n    #[test]\n    fn test_async_capture_within_budget() {\n        use config::cca::NoteTakingConfig;\n\n        let config = NoteTakingConfig {\n            overhead_budget_ms: 10,\n            ..Default::default()\n        };\n\n        let event = sample_event(\"tool1\", true);\n\n        let ctx = TenantContext::default();\n        let capture = AsyncTrajectoryCapture::new(\"session-123\", ctx, Arc::new(config));\n\n        capture.capture(event);\n\n        assert_eq!(capture.metrics().events_captured(), 1);\n        assert_eq!(capture.metrics().events_dropped(), 0);\n    }\n\n    #[test]\n    fn test_async_capture_sampling_counters_per_tool() {\n        use config::cca::{CaptureMode, NoteTakingConfig};\n\n        let config = NoteTakingConfig {\n            capture_mode: CaptureMode::Sampled,\n            sampling_rate: 2,\n            ..Default::default()\n        };\n        let ctx = TenantContext::default();\n        let capture = AsyncTrajectoryCapture::new(\"session-123\", ctx, Arc::new(config));\n\n        for i in 0..4 {\n            capture.capture(sample_event(&format!(\"tool{}\", i), true));\n        }\n\n        let captured = capture.metrics().events_captured();\n        assert_eq!(captured, 4);\n    }\n\n    #[test]\n    fn bench_capture_performance_basic() {\n        use config::cca::{CaptureMode, NoteTakingConfig};\n        use std::time::Instant;\n\n        let config = Arc::new(NoteTakingConfig {\n            capture_mode: CaptureMode::All,\n            overhead_budget_ms: 10,\n            ..Default::default()\n        });\n        let ctx = TenantContext::default();\n        let capture = AsyncTrajectoryCapture::new(\"perf-session\", ctx, config);\n\n        let iterations = 1000;\n        let event = TrajectoryEvent::new(\"read\", \"path\", \"content\", true, 10);\n\n        let start = Instant::now();\n        for _ in 0..iterations {\n            capture.capture(event.clone());\n        }\n        let elapsed = start.elapsed();\n\n        let avg_us = elapsed.as_micros() as f64 / iterations as f64;\n\n        assert!(\n            avg_us < 100.0,\n            \"Average capture time {}us exceeds 100us budget\",\n            avg_us\n        );\n\n        assert_eq!(capture.metrics().events_captured(), iterations as u64);\n    }\n\n    #[test]\n    fn bench_capture_performance_with_filtering() {\n        use config::cca::{CaptureMode, NoteTakingConfig};\n\n        let mut traj_config = TrajectoryConfig::default();\n        traj_config.filter_sensitive = true;\n\n        let config = Arc::new(NoteTakingConfig {\n            capture_mode: CaptureMode::All,\n            overhead_budget_ms: 10,\n            ..Default::default()\n        });\n        let ctx = TenantContext::default();\n        let capture = AsyncTrajectoryCapture::new(\"perf-session\", ctx, config)\n            .with_trajectory_config(traj_config);\n\n        let iterations = 1000;\n        let event = TrajectoryEvent::new(\n            \"api_call\",\n            \"api_key=sk-12345 password=secret\",\n            \"response\",\n            true,\n            10,\n        );\n\n        let start = Instant::now();\n        for _ in 0..iterations {\n            capture.capture(event.clone());\n        }\n        let elapsed = start.elapsed();\n\n        let avg_us = elapsed.as_micros() as f64 / iterations as f64;\n\n        assert!(\n            avg_us < 500.0,\n            \"Average capture time with filtering {}us exceeds 500us budget\",\n            avg_us\n        );\n    }\n\n    #[test]\n    fn bench_capture_performance_sampling() {\n        use config::cca::{CaptureMode, NoteTakingConfig};\n\n        let config = Arc::new(NoteTakingConfig {\n            capture_mode: CaptureMode::Sampled,\n            sampling_rate: 10,\n            overhead_budget_ms: 10,\n            ..Default::default()\n        });\n        let ctx = TenantContext::default();\n        let capture = AsyncTrajectoryCapture::new(\"perf-session\", ctx, config);\n\n        let iterations = 1000;\n        let event = TrajectoryEvent::new(\"query\", \"search\", \"results\", true, 10);\n\n        let start = Instant::now();\n        for _ in 0..iterations {\n            capture.capture(event.clone());\n        }\n        let elapsed = start.elapsed();\n\n        let avg_us = elapsed.as_micros() as f64 / iterations as f64;\n\n        assert!(\n            avg_us < 200.0,\n            \"Average capture time with sampling {}us exceeds 200us budget\",\n            avg_us\n        );\n\n        let captured = capture.metrics().events_captured();\n        let expected = iterations / 10;\n        assert!(captured >= expected as u64 - 5 && captured <= expected as u64 + 5);\n    }\n\n    #[test]\n    fn bench_queue_overflow_performance() {\n        use config::cca::NoteTakingConfig;\n\n        let config = Arc::new(NoteTakingConfig {\n            queue_size: 100,\n            overhead_budget_ms: 10,\n            ..Default::default()\n        });\n        let ctx = TenantContext::default();\n        let capture = AsyncTrajectoryCapture::new(\"perf-session\", ctx, config);\n\n        let iterations = 500;\n        let event = TrajectoryEvent::new(\"write\", \"data\", \"done\", true, 10);\n\n        let start = Instant::now();\n        for _ in 0..iterations {\n            capture.capture(event.clone());\n        }\n        let elapsed = start.elapsed();\n\n        let avg_us = elapsed.as_micros() as f64 / iterations as f64;\n\n        assert!(\n            avg_us < 150.0,\n            \"Average capture time {}us exceeds 150us budget\",\n            avg_us\n        );\n\n        assert!(capture.metrics().overflow_drops() > 0);\n    }\n}\n","traces":[{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":70}},{"line":76,"address":[],"length":0,"stats":{"Line":140}},{"line":77,"address":[],"length":0,"stats":{"Line":70}},{"line":78,"address":[],"length":0,"stats":{"Line":210}},{"line":82,"address":[],"length":0,"stats":{"Line":210}},{"line":84,"address":[],"length":0,"stats":{"Line":210}},{"line":85,"address":[],"length":0,"stats":{"Line":210}},{"line":86,"address":[],"length":0,"stats":{"Line":210}},{"line":93,"address":[],"length":0,"stats":{"Line":2}},{"line":94,"address":[],"length":0,"stats":{"Line":4}},{"line":95,"address":[],"length":0,"stats":{"Line":2}},{"line":109,"address":[],"length":0,"stats":{"Line":15}},{"line":111,"address":[],"length":0,"stats":{"Line":45}},{"line":112,"address":[],"length":0,"stats":{"Line":45}},{"line":113,"address":[],"length":0,"stats":{"Line":45}},{"line":114,"address":[],"length":0,"stats":{"Line":45}},{"line":115,"address":[],"length":0,"stats":{"Line":15}},{"line":119,"address":[],"length":0,"stats":{"Line":2614}},{"line":120,"address":[],"length":0,"stats":{"Line":5228}},{"line":121,"address":[],"length":0,"stats":{"Line":5228}},{"line":122,"address":[],"length":0,"stats":{"Line":5228}},{"line":125,"address":[],"length":0,"stats":{"Line":909}},{"line":126,"address":[],"length":0,"stats":{"Line":1818}},{"line":129,"address":[],"length":0,"stats":{"Line":403}},{"line":130,"address":[],"length":0,"stats":{"Line":806}},{"line":133,"address":[],"length":0,"stats":{"Line":2}},{"line":134,"address":[],"length":0,"stats":{"Line":4}},{"line":137,"address":[],"length":0,"stats":{"Line":11}},{"line":138,"address":[],"length":0,"stats":{"Line":22}},{"line":141,"address":[],"length":0,"stats":{"Line":6}},{"line":142,"address":[],"length":0,"stats":{"Line":12}},{"line":145,"address":[],"length":0,"stats":{"Line":3}},{"line":146,"address":[],"length":0,"stats":{"Line":6}},{"line":149,"address":[],"length":0,"stats":{"Line":2}},{"line":150,"address":[],"length":0,"stats":{"Line":4}},{"line":153,"address":[],"length":0,"stats":{"Line":3}},{"line":154,"address":[],"length":0,"stats":{"Line":6}},{"line":157,"address":[],"length":0,"stats":{"Line":2}},{"line":158,"address":[],"length":0,"stats":{"Line":6}},{"line":159,"address":[],"length":0,"stats":{"Line":2}},{"line":160,"address":[],"length":0,"stats":{"Line":1}},{"line":162,"address":[],"length":0,"stats":{"Line":1}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":183,"address":[],"length":0,"stats":{"Line":44}},{"line":189,"address":[],"length":0,"stats":{"Line":44}},{"line":200,"address":[],"length":0,"stats":{"Line":46}},{"line":201,"address":[],"length":0,"stats":{"Line":92}},{"line":209,"address":[],"length":0,"stats":{"Line":92}},{"line":211,"address":[],"length":0,"stats":{"Line":736}},{"line":217,"address":[],"length":0,"stats":{"Line":1}},{"line":218,"address":[],"length":0,"stats":{"Line":3}},{"line":219,"address":[],"length":0,"stats":{"Line":3}},{"line":220,"address":[],"length":0,"stats":{"Line":1}},{"line":223,"address":[],"length":0,"stats":{"Line":44}},{"line":224,"address":[],"length":0,"stats":{"Line":132}},{"line":225,"address":[],"length":0,"stats":{"Line":707}},{"line":226,"address":[],"length":0,"stats":{"Line":663}},{"line":228,"address":[],"length":0,"stats":{"Line":44}},{"line":238,"address":[],"length":0,"stats":{"Line":44}},{"line":241,"address":[],"length":0,"stats":{"Line":44}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":23}},{"line":251,"address":[],"length":0,"stats":{"Line":46}},{"line":252,"address":[],"length":0,"stats":{"Line":1}},{"line":255,"address":[],"length":0,"stats":{"Line":66}},{"line":257,"address":[],"length":0,"stats":{"Line":110}},{"line":258,"address":[],"length":0,"stats":{"Line":110}},{"line":260,"address":[],"length":0,"stats":{"Line":43}},{"line":261,"address":[],"length":0,"stats":{"Line":105}},{"line":262,"address":[],"length":0,"stats":{"Line":63}},{"line":265,"address":[],"length":0,"stats":{"Line":22}},{"line":268,"address":[],"length":0,"stats":{"Line":44}},{"line":269,"address":[],"length":0,"stats":{"Line":88}},{"line":270,"address":[],"length":0,"stats":{"Line":84}},{"line":272,"address":[],"length":0,"stats":{"Line":6}},{"line":284,"address":[],"length":0,"stats":{"Line":43}},{"line":285,"address":[],"length":0,"stats":{"Line":172}},{"line":289,"address":[],"length":0,"stats":{"Line":43}},{"line":293,"address":[],"length":0,"stats":{"Line":22}},{"line":294,"address":[],"length":0,"stats":{"Line":65}},{"line":295,"address":[],"length":0,"stats":{"Line":63}},{"line":297,"address":[],"length":0,"stats":{"Line":48}},{"line":298,"address":[],"length":0,"stats":{"Line":2}},{"line":303,"address":[],"length":0,"stats":{"Line":2}},{"line":304,"address":[],"length":0,"stats":{"Line":2}},{"line":307,"address":[],"length":0,"stats":{"Line":1}},{"line":308,"address":[],"length":0,"stats":{"Line":4}},{"line":311,"address":[],"length":0,"stats":{"Line":1}},{"line":312,"address":[],"length":0,"stats":{"Line":4}},{"line":315,"address":[],"length":0,"stats":{"Line":1}},{"line":316,"address":[],"length":0,"stats":{"Line":7}},{"line":319,"address":[],"length":0,"stats":{"Line":1}},{"line":320,"address":[],"length":0,"stats":{"Line":2}},{"line":323,"address":[],"length":0,"stats":{"Line":5}},{"line":324,"address":[],"length":0,"stats":{"Line":10}},{"line":327,"address":[],"length":0,"stats":{"Line":2}},{"line":328,"address":[],"length":0,"stats":{"Line":4}},{"line":331,"address":[],"length":0,"stats":{"Line":1}},{"line":332,"address":[],"length":0,"stats":{"Line":1}},{"line":335,"address":[],"length":0,"stats":{"Line":3}},{"line":336,"address":[],"length":0,"stats":{"Line":2}},{"line":337,"address":[],"length":0,"stats":{"Line":2}},{"line":338,"address":[],"length":0,"stats":{"Line":2}},{"line":350,"address":[],"length":0,"stats":{"Line":1}},{"line":351,"address":[],"length":0,"stats":{"Line":2}},{"line":367,"address":[],"length":0,"stats":{"Line":3}},{"line":373,"address":[],"length":0,"stats":{"Line":9}},{"line":375,"address":[],"length":0,"stats":{"Line":9}},{"line":378,"address":[],"length":0,"stats":{"Line":3}},{"line":384,"address":[],"length":0,"stats":{"Line":0}},{"line":385,"address":[],"length":0,"stats":{"Line":0}},{"line":386,"address":[],"length":0,"stats":{"Line":0}},{"line":389,"address":[],"length":0,"stats":{"Line":1}},{"line":390,"address":[],"length":0,"stats":{"Line":1}},{"line":391,"address":[],"length":0,"stats":{"Line":1}},{"line":394,"address":[],"length":0,"stats":{"Line":0}},{"line":395,"address":[],"length":0,"stats":{"Line":0}},{"line":396,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":1}},{"line":400,"address":[],"length":0,"stats":{"Line":1}},{"line":404,"address":[],"length":0,"stats":{"Line":4}},{"line":405,"address":[],"length":0,"stats":{"Line":12}},{"line":406,"address":[],"length":0,"stats":{"Line":4}},{"line":409,"address":[],"length":0,"stats":{"Line":2}},{"line":410,"address":[],"length":0,"stats":{"Line":2}},{"line":411,"address":[],"length":0,"stats":{"Line":2}},{"line":415,"address":[],"length":0,"stats":{"Line":0}},{"line":444,"address":[],"length":0,"stats":{"Line":0}},{"line":448,"address":[],"length":0,"stats":{"Line":0}},{"line":449,"address":[],"length":0,"stats":{"Line":0}},{"line":450,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":455,"address":[],"length":0,"stats":{"Line":0}},{"line":456,"address":[],"length":0,"stats":{"Line":0}},{"line":459,"address":[],"length":0,"stats":{"Line":0}},{"line":460,"address":[],"length":0,"stats":{"Line":0}},{"line":463,"address":[],"length":0,"stats":{"Line":0}},{"line":464,"address":[],"length":0,"stats":{"Line":0}},{"line":467,"address":[],"length":0,"stats":{"Line":0}},{"line":468,"address":[],"length":0,"stats":{"Line":0}},{"line":471,"address":[],"length":0,"stats":{"Line":0}},{"line":472,"address":[],"length":0,"stats":{"Line":0}},{"line":475,"address":[],"length":0,"stats":{"Line":1}},{"line":476,"address":[],"length":0,"stats":{"Line":2}},{"line":479,"address":[],"length":0,"stats":{"Line":1}},{"line":480,"address":[],"length":0,"stats":{"Line":2}},{"line":483,"address":[],"length":0,"stats":{"Line":2}},{"line":484,"address":[],"length":0,"stats":{"Line":2}},{"line":502,"address":[],"length":0,"stats":{"Line":9}},{"line":507,"address":[],"length":0,"stats":{"Line":27}},{"line":508,"address":[],"length":0,"stats":{"Line":27}},{"line":511,"address":[],"length":0,"stats":{"Line":27}},{"line":513,"address":[],"length":0,"stats":{"Line":27}},{"line":516,"address":[],"length":0,"stats":{"Line":18}},{"line":517,"address":[],"length":0,"stats":{"Line":18}},{"line":518,"address":[],"length":0,"stats":{"Line":36}},{"line":520,"address":[],"length":0,"stats":{"Line":18}},{"line":524,"address":[],"length":0,"stats":{"Line":0}},{"line":525,"address":[],"length":0,"stats":{"Line":0}},{"line":526,"address":[],"length":0,"stats":{"Line":0}},{"line":529,"address":[],"length":0,"stats":{"Line":1}},{"line":530,"address":[],"length":0,"stats":{"Line":3}},{"line":531,"address":[],"length":0,"stats":{"Line":1}},{"line":534,"address":[],"length":0,"stats":{"Line":0}},{"line":535,"address":[],"length":0,"stats":{"Line":0}},{"line":538,"address":[],"length":0,"stats":{"Line":12}},{"line":539,"address":[],"length":0,"stats":{"Line":12}},{"line":543,"address":[],"length":0,"stats":{"Line":3518}},{"line":544,"address":[],"length":0,"stats":{"Line":7036}},{"line":546,"address":[],"length":0,"stats":{"Line":3518}},{"line":548,"address":[],"length":0,"stats":{"Line":2}},{"line":549,"address":[],"length":0,"stats":{"Line":1}},{"line":551,"address":[],"length":0,"stats":{"Line":1}},{"line":552,"address":[],"length":0,"stats":{"Line":2}},{"line":553,"address":[],"length":0,"stats":{"Line":1}},{"line":556,"address":[],"length":0,"stats":{"Line":2028}},{"line":557,"address":[],"length":0,"stats":{"Line":1014}},{"line":558,"address":[],"length":0,"stats":{"Line":3042}},{"line":559,"address":[],"length":0,"stats":{"Line":1020}},{"line":560,"address":[],"length":0,"stats":{"Line":3042}},{"line":561,"address":[],"length":0,"stats":{"Line":1014}},{"line":562,"address":[],"length":0,"stats":{"Line":1810}},{"line":563,"address":[],"length":0,"stats":{"Line":905}},{"line":566,"address":[],"length":0,"stats":{"Line":2502}},{"line":569,"address":[],"length":0,"stats":{"Line":5222}},{"line":570,"address":[],"length":0,"stats":{"Line":2611}},{"line":571,"address":[],"length":0,"stats":{"Line":0}},{"line":572,"address":[],"length":0,"stats":{"Line":0}},{"line":576,"address":[],"length":0,"stats":{"Line":0}},{"line":577,"address":[],"length":0,"stats":{"Line":0}},{"line":579,"address":[],"length":0,"stats":{"Line":0}},{"line":582,"address":[],"length":0,"stats":{"Line":5222}},{"line":583,"address":[],"length":0,"stats":{"Line":5222}},{"line":585,"address":[],"length":0,"stats":{"Line":0}},{"line":586,"address":[],"length":0,"stats":{"Line":0}},{"line":590,"address":[],"length":0,"stats":{"Line":2611}},{"line":591,"address":[],"length":0,"stats":{"Line":400}},{"line":592,"address":[],"length":0,"stats":{"Line":800}},{"line":593,"address":[],"length":0,"stats":{"Line":400}},{"line":595,"address":[],"length":0,"stats":{"Line":5222}},{"line":596,"address":[],"length":0,"stats":{"Line":5222}},{"line":598,"address":[],"length":0,"stats":{"Line":7833}},{"line":600,"address":[],"length":0,"stats":{"Line":5222}},{"line":603,"address":[],"length":0,"stats":{"Line":0}},{"line":604,"address":[],"length":0,"stats":{"Line":0}},{"line":605,"address":[],"length":0,"stats":{"Line":0}},{"line":606,"address":[],"length":0,"stats":{"Line":0}},{"line":607,"address":[],"length":0,"stats":{"Line":0}},{"line":608,"address":[],"length":0,"stats":{"Line":0}},{"line":609,"address":[],"length":0,"stats":{"Line":0}},{"line":610,"address":[],"length":0,"stats":{"Line":0}},{"line":612,"address":[],"length":0,"stats":{"Line":0}},{"line":614,"address":[],"length":0,"stats":{"Line":0}},{"line":615,"address":[],"length":0,"stats":{"Line":0}},{"line":616,"address":[],"length":0,"stats":{"Line":0}},{"line":617,"address":[],"length":0,"stats":{"Line":0}},{"line":618,"address":[],"length":0,"stats":{"Line":0}},{"line":619,"address":[],"length":0,"stats":{"Line":0}},{"line":622,"address":[],"length":0,"stats":{"Line":0}},{"line":623,"address":[],"length":0,"stats":{"Line":0}},{"line":624,"address":[],"length":0,"stats":{"Line":0}},{"line":625,"address":[],"length":0,"stats":{"Line":0}},{"line":626,"address":[],"length":0,"stats":{"Line":0}},{"line":627,"address":[],"length":0,"stats":{"Line":0}},{"line":628,"address":[],"length":0,"stats":{"Line":0}},{"line":629,"address":[],"length":0,"stats":{"Line":0}},{"line":630,"address":[],"length":0,"stats":{"Line":0}},{"line":632,"address":[],"length":0,"stats":{"Line":0}},{"line":635,"address":[],"length":0,"stats":{"Line":0}},{"line":637,"address":[],"length":0,"stats":{"Line":0}},{"line":638,"address":[],"length":0,"stats":{"Line":0}},{"line":639,"address":[],"length":0,"stats":{"Line":0}},{"line":643,"address":[],"length":0,"stats":{"Line":0}},{"line":644,"address":[],"length":0,"stats":{"Line":0}},{"line":645,"address":[],"length":0,"stats":{"Line":0}},{"line":646,"address":[],"length":0,"stats":{"Line":0}},{"line":647,"address":[],"length":0,"stats":{"Line":0}},{"line":648,"address":[],"length":0,"stats":{"Line":0}},{"line":649,"address":[],"length":0,"stats":{"Line":0}},{"line":650,"address":[],"length":0,"stats":{"Line":0}},{"line":652,"address":[],"length":0,"stats":{"Line":0}},{"line":655,"address":[],"length":0,"stats":{"Line":0}},{"line":657,"address":[],"length":0,"stats":{"Line":0}},{"line":658,"address":[],"length":0,"stats":{"Line":0}},{"line":659,"address":[],"length":0,"stats":{"Line":0}},{"line":669,"address":[],"length":0,"stats":{"Line":0}},{"line":676,"address":[],"length":0,"stats":{"Line":0}},{"line":677,"address":[],"length":0,"stats":{"Line":0}},{"line":680,"address":[],"length":0,"stats":{"Line":0}},{"line":681,"address":[],"length":0,"stats":{"Line":0}},{"line":682,"address":[],"length":0,"stats":{"Line":0}},{"line":683,"address":[],"length":0,"stats":{"Line":0}},{"line":686,"address":[],"length":0,"stats":{"Line":0}},{"line":687,"address":[],"length":0,"stats":{"Line":0}},{"line":688,"address":[],"length":0,"stats":{"Line":0}},{"line":689,"address":[],"length":0,"stats":{"Line":0}},{"line":691,"address":[],"length":0,"stats":{"Line":0}},{"line":697,"address":[],"length":0,"stats":{"Line":0}},{"line":698,"address":[],"length":0,"stats":{"Line":0}},{"line":701,"address":[],"length":0,"stats":{"Line":0}},{"line":702,"address":[],"length":0,"stats":{"Line":0}},{"line":705,"address":[],"length":0,"stats":{"Line":0}},{"line":706,"address":[],"length":0,"stats":{"Line":0}},{"line":709,"address":[],"length":0,"stats":{"Line":0}},{"line":710,"address":[],"length":0,"stats":{"Line":0}},{"line":713,"address":[],"length":0,"stats":{"Line":0}},{"line":714,"address":[],"length":0,"stats":{"Line":0}},{"line":717,"address":[],"length":0,"stats":{"Line":0}},{"line":718,"address":[],"length":0,"stats":{"Line":0}},{"line":733,"address":[],"length":0,"stats":{"Line":0}},{"line":737,"address":[],"length":0,"stats":{"Line":0}},{"line":738,"address":[],"length":0,"stats":{"Line":0}},{"line":753,"address":[],"length":0,"stats":{"Line":0}},{"line":754,"address":[],"length":0,"stats":{"Line":0}},{"line":755,"address":[],"length":0,"stats":{"Line":0}},{"line":756,"address":[],"length":0,"stats":{"Line":0}},{"line":764,"address":[],"length":0,"stats":{"Line":0}},{"line":765,"address":[],"length":0,"stats":{"Line":0}},{"line":766,"address":[],"length":0,"stats":{"Line":0}},{"line":767,"address":[],"length":0,"stats":{"Line":0}},{"line":768,"address":[],"length":0,"stats":{"Line":0}}],"covered":167,"coverable":288},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","note_taking","distiller.rs"],"content":"use std::time::{SystemTime, UNIX_EPOCH};\n\nuse serde::{Deserialize, Serialize};\nuse tracing::{Instrument, info_span};\n\nuse super::capture::TrajectoryEvent;\nuse crate::context_architect::LlmClient;\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum DistillationTrigger {\n    SessionEnd,\n    SignificantSuccess,\n    ManualRequest,\n    FailurePattern,\n}\n\n#[derive(Debug, Clone)]\npub struct DistillerConfig {\n    pub min_events_for_distillation: usize,\n    pub min_success_ratio: f32,\n    pub extract_code_snippets: bool,\n    pub max_tags: usize,\n}\n\nimpl Default for DistillerConfig {\n    fn default() -> Self {\n        Self {\n            min_events_for_distillation: 3,\n            min_success_ratio: 0.5,\n            extract_code_snippets: true,\n            max_tags: 10,\n        }\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ExtractedSection {\n    pub name: String,\n    pub content: String,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct DistillationResult {\n    pub id: String,\n    pub trigger: String,\n    pub context: String,\n    pub problem: String,\n    pub solution: String,\n    pub patterns: Vec<String>,\n    pub tags: Vec<String>,\n    pub code_snippets: Vec<String>,\n    pub quality_score: f32,\n    pub distilled_at: u64,\n    pub source_event_count: usize,\n}\n\nimpl DistillationResult {\n    pub fn is_high_quality(&self) -> bool {\n        self.quality_score >= 0.7\n    }\n}\n\npub struct Distiller<C: LlmClient> {\n    config: DistillerConfig,\n    llm_client: C,\n}\n\nimpl<C: LlmClient> Distiller<C> {\n    pub fn new(config: DistillerConfig, llm_client: C) -> Self {\n        Self { config, llm_client }\n    }\n\n    pub async fn distill(\n        &self,\n        events: &[TrajectoryEvent],\n        trigger: DistillationTrigger,\n    ) -> Result<DistillationResult, DistillationError> {\n        let span = info_span!(\n            \"distill\",\n            events_count = events.len(),\n            trigger = ?trigger,\n            min_events = self.config.min_events_for_distillation,\n            extract_code_snippets = self.config.extract_code_snippets\n        );\n\n        async move {\n            if events.len() < self.config.min_events_for_distillation {\n                return Err(DistillationError::InsufficientEvents {\n                    provided: events.len(),\n                    required: self.config.min_events_for_distillation,\n                });\n            }\n\n            let success_count = events.iter().filter(|e| e.success).count();\n            let success_ratio = success_count as f32 / events.len() as f32;\n\n            if success_ratio < self.config.min_success_ratio\n                && trigger != DistillationTrigger::FailurePattern\n            {\n                return Err(DistillationError::LowSuccessRatio {\n                    ratio: success_ratio,\n                    required: self.config.min_success_ratio,\n                });\n            }\n\n            let trajectory_text = self.format_trajectory(events);\n            let prompt = self.build_distillation_prompt(&trajectory_text);\n\n            let response = self\n                .llm_client\n                .complete_with_system(DISTILLATION_SYSTEM_PROMPT, &prompt)\n                .await\n                .map_err(|e| DistillationError::LlmError(e.to_string()))?;\n\n            let parsed = self.parse_distillation_response(&response)?;\n            let code_snippets = if self.config.extract_code_snippets {\n                self.extract_code_snippets(events)\n            } else {\n                vec![]\n            };\n\n            let quality_score = self.calculate_quality_score(&parsed, events);\n            let timestamp = SystemTime::now()\n                .duration_since(UNIX_EPOCH)\n                .map(|d| d.as_secs())\n                .unwrap_or(0);\n\n            Ok(DistillationResult {\n                id: uuid::Uuid::new_v4().to_string(),\n                trigger: format!(\"{trigger:?}\"),\n                context: parsed.context,\n                problem: parsed.problem,\n                solution: parsed.solution,\n                patterns: parsed.patterns,\n                tags: parsed.tags.into_iter().take(self.config.max_tags).collect(),\n                code_snippets,\n                quality_score,\n                distilled_at: timestamp,\n                source_event_count: events.len(),\n            })\n        }\n        .instrument(span)\n        .await\n    }\n\n    fn format_trajectory(&self, events: &[TrajectoryEvent]) -> String {\n        events\n            .iter()\n            .enumerate()\n            .map(|(i, e)| {\n                format!(\n                    \"Step {}: {}\\nInput: {}\\nOutput: {}\\nSuccess: {}\",\n                    i + 1,\n                    e.tool_name,\n                    e.input,\n                    if e.output.len() > 500 {\n                        format!(\"{}...\", &e.output[..500])\n                    } else {\n                        e.output.clone()\n                    },\n                    e.success\n                )\n            })\n            .collect::<Vec<_>>()\n            .join(\"\\n\\n\")\n    }\n\n    fn build_distillation_prompt(&self, trajectory: &str) -> String {\n        format!(\n            \"Analyze the following agent trajectory and extract \\\n             learnings:\\n\\n{trajectory}\\n\\nProvide your analysis in the following \\\n             format:\\nCONTEXT: [What was the overall goal or situation?]\\nPROBLEM: [What specific \\\n             problem was being solved?]\\nSOLUTION: [What approach worked or what was \\\n             learned?]\\nPATTERNS: [Comma-separated list of reusable patterns]\\nTAGS: \\\n             [Comma-separated list of relevant tags]\"\n        )\n    }\n\n    fn parse_distillation_response(\n        &self,\n        response: &str,\n    ) -> Result<ParsedDistillation, DistillationError> {\n        let context = self\n            .extract_section(response, \"CONTEXT:\")\n            .unwrap_or_default();\n        let problem = self\n            .extract_section(response, \"PROBLEM:\")\n            .unwrap_or_default();\n        let solution = self\n            .extract_section(response, \"SOLUTION:\")\n            .unwrap_or_default();\n        let patterns_str = self\n            .extract_section(response, \"PATTERNS:\")\n            .unwrap_or_default();\n        let tags_str = self.extract_section(response, \"TAGS:\").unwrap_or_default();\n\n        if context.is_empty() && problem.is_empty() && solution.is_empty() {\n            return Err(DistillationError::ParseError(\n                \"Could not extract any sections from LLM response\".to_string(),\n            ));\n        }\n\n        let patterns = patterns_str\n            .split(',')\n            .map(|s| s.trim().to_string())\n            .filter(|s| !s.is_empty())\n            .collect();\n\n        let tags = tags_str\n            .split(',')\n            .map(|s| s.trim().to_lowercase())\n            .filter(|s| !s.is_empty())\n            .collect();\n\n        Ok(ParsedDistillation {\n            context,\n            problem,\n            solution,\n            patterns,\n            tags,\n        })\n    }\n\n    fn extract_section(&self, text: &str, marker: &str) -> Option<String> {\n        let lines: Vec<&str> = text.lines().collect();\n\n        for (i, line) in lines.iter().enumerate() {\n            if line.contains(marker) {\n                let after_marker = line.split(marker).nth(1).map(|s| s.trim().to_string());\n\n                if let Some(content) = after_marker {\n                    if !content.is_empty() {\n                        return Some(content);\n                    }\n                }\n\n                let mut content_lines = Vec::new();\n                for subsequent_line in lines.iter().skip(i + 1) {\n                    if subsequent_line.contains(':')\n                        && (subsequent_line.starts_with(\"CONTEXT\")\n                            || subsequent_line.starts_with(\"PROBLEM\")\n                            || subsequent_line.starts_with(\"SOLUTION\")\n                            || subsequent_line.starts_with(\"PATTERNS\")\n                            || subsequent_line.starts_with(\"TAGS\"))\n                    {\n                        break;\n                    }\n                    content_lines.push(*subsequent_line);\n                }\n\n                if !content_lines.is_empty() {\n                    return Some(content_lines.join(\"\\n\").trim().to_string());\n                }\n            }\n        }\n\n        None\n    }\n\n    fn extract_code_snippets(&self, events: &[TrajectoryEvent]) -> Vec<String> {\n        let mut snippets = Vec::new();\n\n        for event in events {\n            if event.tool_name.contains(\"write\")\n                || event.tool_name.contains(\"edit\")\n                || event.tool_name.contains(\"code\")\n            {\n                if let Some(code) = self.extract_code_block(&event.input) {\n                    snippets.push(code);\n                }\n                if let Some(code) = self.extract_code_block(&event.output) {\n                    snippets.push(code);\n                }\n            }\n        }\n\n        snippets\n    }\n\n    fn extract_code_block(&self, text: &str) -> Option<String> {\n        if let Some(start) = text.find(\"```\") {\n            let after_start = &text[start + 3..];\n            if let Some(end) = after_start.find(\"```\") {\n                let code = after_start[..end].trim();\n                let code = code\n                    .lines()\n                    .skip_while(|l| !l.is_empty() && !l.contains(' '))\n                    .collect::<Vec<_>>()\n                    .join(\"\\n\");\n                if !code.is_empty() {\n                    return Some(code);\n                }\n            }\n        }\n        None\n    }\n\n    fn calculate_quality_score(\n        &self,\n        parsed: &ParsedDistillation,\n        events: &[TrajectoryEvent],\n    ) -> f32 {\n        let mut score = 0.0;\n\n        if !parsed.context.is_empty() {\n            score += 0.2;\n        }\n        if !parsed.problem.is_empty() {\n            score += 0.2;\n        }\n        if !parsed.solution.is_empty() {\n            score += 0.3;\n        }\n        if !parsed.patterns.is_empty() {\n            score += 0.15;\n        }\n        if !parsed.tags.is_empty() {\n            score += 0.1;\n        }\n\n        let success_count = events.iter().filter(|e| e.success).count();\n        let success_ratio = success_count as f32 / events.len().max(1) as f32;\n        score += 0.05 * success_ratio;\n\n        score.min(1.0)\n    }\n}\n\nstruct ParsedDistillation {\n    context: String,\n    problem: String,\n    solution: String,\n    patterns: Vec<String>,\n    tags: Vec<String>,\n}\n\n#[derive(Debug, Clone, thiserror::Error)]\npub enum DistillationError {\n    #[error(\"Insufficient events: {provided} provided, {required} required\")]\n    InsufficientEvents { provided: usize, required: usize },\n\n    #[error(\"Low success ratio: {ratio:.2} (required: {required:.2})\")]\n    LowSuccessRatio { ratio: f32, required: f32 },\n\n    #[error(\"LLM error: {0}\")]\n    LlmError(String),\n\n    #[error(\"Parse error: {0}\")]\n    ParseError(String),\n}\n\nconst DISTILLATION_SYSTEM_PROMPT: &str = r#\"You are a learning distillation agent. Your task is to analyze agent tool execution trajectories and extract reusable learnings.\n\nFocus on:\n1. Understanding the context and goal\n2. Identifying the specific problem being solved\n3. Extracting the successful solution approach\n4. Recognizing patterns that could help with similar problems\n5. Generating relevant tags for searchability\n\nBe concise but comprehensive. Extract actionable insights that would help an agent facing a similar situation in the future.\"#;\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::context_architect::LlmError;\n    use async_trait::async_trait;\n\n    struct MockLlmClient {\n        response: String,\n    }\n\n    impl MockLlmClient {\n        fn new(response: impl Into<String>) -> Self {\n            Self {\n                response: response.into(),\n            }\n        }\n    }\n\n    #[async_trait]\n    impl LlmClient for MockLlmClient {\n        async fn complete(&self, _prompt: &str) -> Result<String, LlmError> {\n            Ok(self.response.clone())\n        }\n\n        async fn complete_with_system(\n            &self,\n            _system: &str,\n            _user: &str,\n        ) -> Result<String, LlmError> {\n            Ok(self.response.clone())\n        }\n    }\n\n    fn sample_events(count: usize, success: bool) -> Vec<TrajectoryEvent> {\n        (0..count)\n            .map(|i| TrajectoryEvent::new(format!(\"tool{i}\"), \"input\", \"output\", success, 100))\n            .collect()\n    }\n\n    #[tokio::test]\n    async fn test_distill_success() {\n        let response = \"CONTEXT: Testing context\\nPROBLEM: Test problem\\nSOLUTION: Test \\\n                        solution\\nPATTERNS: pattern1, pattern2\\nTAGS: rust, testing\";\n\n        let client = MockLlmClient::new(response);\n        let distiller = Distiller::new(DistillerConfig::default(), client);\n\n        let events = sample_events(5, true);\n        let result = distiller\n            .distill(&events, DistillationTrigger::SessionEnd)\n            .await\n            .unwrap();\n\n        assert_eq!(result.context, \"Testing context\");\n        assert_eq!(result.problem, \"Test problem\");\n        assert_eq!(result.solution, \"Test solution\");\n        assert!(result.patterns.contains(&\"pattern1\".to_string()));\n        assert!(result.tags.contains(&\"rust\".to_string()));\n    }\n\n    #[tokio::test]\n    async fn test_distill_insufficient_events() {\n        let client = MockLlmClient::new(\"response\");\n        let distiller = Distiller::new(DistillerConfig::default(), client);\n\n        let events = sample_events(1, true);\n        let result = distiller\n            .distill(&events, DistillationTrigger::SessionEnd)\n            .await;\n\n        assert!(matches!(\n            result,\n            Err(DistillationError::InsufficientEvents { .. })\n        ));\n    }\n\n    #[tokio::test]\n    async fn test_distill_low_success_ratio() {\n        let client = MockLlmClient::new(\"response\");\n        let config = DistillerConfig {\n            min_events_for_distillation: 2,\n            min_success_ratio: 0.8,\n            ..Default::default()\n        };\n        let distiller = Distiller::new(config, client);\n\n        let mut events = sample_events(5, false);\n        events[0] = TrajectoryEvent::new(\"tool0\", \"input\", \"output\", true, 100);\n\n        let result = distiller\n            .distill(&events, DistillationTrigger::SessionEnd)\n            .await;\n\n        assert!(matches!(\n            result,\n            Err(DistillationError::LowSuccessRatio { .. })\n        ));\n    }\n\n    #[tokio::test]\n    async fn test_distill_failure_pattern_ignores_success_ratio() {\n        let response =\n            \"CONTEXT: Failure analysis\\nPROBLEM: Recurring error\\nSOLUTION: Fix approach\";\n\n        let client = MockLlmClient::new(response);\n        let distiller = Distiller::new(DistillerConfig::default(), client);\n\n        let events = sample_events(5, false);\n        let result = distiller\n            .distill(&events, DistillationTrigger::FailurePattern)\n            .await;\n\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_quality_score_calculation() {\n        let response = \"CONTEXT: Full context\\nPROBLEM: Full problem\\nSOLUTION: Full \\\n                        solution\\nPATTERNS: pattern\\nTAGS: tag\";\n\n        let client = MockLlmClient::new(response);\n        let distiller = Distiller::new(DistillerConfig::default(), client);\n\n        let events = sample_events(5, true);\n        let result = distiller\n            .distill(&events, DistillationTrigger::SessionEnd)\n            .await\n            .unwrap();\n\n        assert!(result.quality_score >= 0.9);\n        assert!(result.is_high_quality());\n    }\n\n    #[test]\n    fn test_extract_section_inline() {\n        let distiller = Distiller::new(DistillerConfig::default(), MockLlmClient::new(\"\"));\n\n        let text = \"CONTEXT: Some context here\\nPROBLEM: The problem\";\n        let section = distiller.extract_section(text, \"CONTEXT:\");\n\n        assert_eq!(section, Some(\"Some context here\".to_string()));\n    }\n\n    #[test]\n    fn test_extract_section_multiline() {\n        let distiller = Distiller::new(DistillerConfig::default(), MockLlmClient::new(\"\"));\n\n        let text = \"CONTEXT:\\nLine 1\\nLine 2\\nPROBLEM: Next\";\n        let section = distiller.extract_section(text, \"CONTEXT:\");\n\n        assert!(section.is_some());\n        assert!(section.unwrap().contains(\"Line 1\"));\n    }\n\n    #[test]\n    fn test_code_snippet_extraction() {\n        let distiller = Distiller::new(DistillerConfig::default(), MockLlmClient::new(\"\"));\n\n        let events = vec![TrajectoryEvent::new(\n            \"write_file\",\n            \"```rust\\nfn main() {}\\n```\",\n            \"success\",\n            true,\n            100,\n        )];\n\n        let snippets = distiller.extract_code_snippets(&events);\n\n        assert!(!snippets.is_empty());\n    }\n\n    #[test]\n    fn test_max_tags_limit() {\n        let response = \"CONTEXT: c\\nPROBLEM: p\\nSOLUTION: s\\nPATTERNS: p\\nTAGS: \\\n                        t1,t2,t3,t4,t5,t6,t7,t8,t9,t10,t11,t12\";\n\n        let config = DistillerConfig {\n            max_tags: 5,\n            min_events_for_distillation: 1,\n            ..Default::default()\n        };\n\n        let _distiller = Distiller::new(config, MockLlmClient::new(response));\n    }\n}\n","traces":[{"line":26,"address":[],"length":0,"stats":{"Line":9}},{"line":58,"address":[],"length":0,"stats":{"Line":1}},{"line":59,"address":[],"length":0,"stats":{"Line":1}},{"line":69,"address":[],"length":0,"stats":{"Line":9}},{"line":73,"address":[],"length":0,"stats":{"Line":5}},{"line":78,"address":[],"length":0,"stats":{"Line":10}},{"line":80,"address":[],"length":0,"stats":{"Line":10}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":5}},{"line":87,"address":[],"length":0,"stats":{"Line":10}},{"line":88,"address":[],"length":0,"stats":{"Line":1}},{"line":89,"address":[],"length":0,"stats":{"Line":2}},{"line":90,"address":[],"length":0,"stats":{"Line":1}},{"line":94,"address":[],"length":0,"stats":{"Line":20}},{"line":95,"address":[],"length":0,"stats":{"Line":12}},{"line":97,"address":[],"length":0,"stats":{"Line":4}},{"line":98,"address":[],"length":0,"stats":{"Line":2}},{"line":100,"address":[],"length":0,"stats":{"Line":1}},{"line":101,"address":[],"length":0,"stats":{"Line":1}},{"line":102,"address":[],"length":0,"stats":{"Line":1}},{"line":106,"address":[],"length":0,"stats":{"Line":12}},{"line":107,"address":[],"length":0,"stats":{"Line":12}},{"line":109,"address":[],"length":0,"stats":{"Line":9}},{"line":110,"address":[],"length":0,"stats":{"Line":6}},{"line":111,"address":[],"length":0,"stats":{"Line":9}},{"line":112,"address":[],"length":0,"stats":{"Line":3}},{"line":113,"address":[],"length":0,"stats":{"Line":3}},{"line":115,"address":[],"length":0,"stats":{"Line":12}},{"line":116,"address":[],"length":0,"stats":{"Line":6}},{"line":117,"address":[],"length":0,"stats":{"Line":9}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":15}},{"line":123,"address":[],"length":0,"stats":{"Line":6}},{"line":124,"address":[],"length":0,"stats":{"Line":3}},{"line":125,"address":[],"length":0,"stats":{"Line":9}},{"line":128,"address":[],"length":0,"stats":{"Line":3}},{"line":129,"address":[],"length":0,"stats":{"Line":9}},{"line":130,"address":[],"length":0,"stats":{"Line":9}},{"line":131,"address":[],"length":0,"stats":{"Line":6}},{"line":132,"address":[],"length":0,"stats":{"Line":6}},{"line":133,"address":[],"length":0,"stats":{"Line":6}},{"line":134,"address":[],"length":0,"stats":{"Line":6}},{"line":135,"address":[],"length":0,"stats":{"Line":18}},{"line":136,"address":[],"length":0,"stats":{"Line":6}},{"line":137,"address":[],"length":0,"stats":{"Line":6}},{"line":138,"address":[],"length":0,"stats":{"Line":6}},{"line":139,"address":[],"length":0,"stats":{"Line":3}},{"line":142,"address":[],"length":0,"stats":{"Line":10}},{"line":143,"address":[],"length":0,"stats":{"Line":5}},{"line":146,"address":[],"length":0,"stats":{"Line":3}},{"line":147,"address":[],"length":0,"stats":{"Line":3}},{"line":150,"address":[],"length":0,"stats":{"Line":18}},{"line":151,"address":[],"length":0,"stats":{"Line":15}},{"line":152,"address":[],"length":0,"stats":{"Line":15}},{"line":153,"address":[],"length":0,"stats":{"Line":15}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":15}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":30}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":3}},{"line":169,"address":[],"length":0,"stats":{"Line":3}},{"line":179,"address":[],"length":0,"stats":{"Line":3}},{"line":183,"address":[],"length":0,"stats":{"Line":6}},{"line":184,"address":[],"length":0,"stats":{"Line":9}},{"line":186,"address":[],"length":0,"stats":{"Line":6}},{"line":187,"address":[],"length":0,"stats":{"Line":9}},{"line":189,"address":[],"length":0,"stats":{"Line":6}},{"line":190,"address":[],"length":0,"stats":{"Line":9}},{"line":192,"address":[],"length":0,"stats":{"Line":6}},{"line":193,"address":[],"length":0,"stats":{"Line":9}},{"line":195,"address":[],"length":0,"stats":{"Line":18}},{"line":197,"address":[],"length":0,"stats":{"Line":6}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":6}},{"line":205,"address":[],"length":0,"stats":{"Line":11}},{"line":206,"address":[],"length":0,"stats":{"Line":11}},{"line":209,"address":[],"length":0,"stats":{"Line":6}},{"line":211,"address":[],"length":0,"stats":{"Line":11}},{"line":212,"address":[],"length":0,"stats":{"Line":11}},{"line":215,"address":[],"length":0,"stats":{"Line":3}},{"line":216,"address":[],"length":0,"stats":{"Line":6}},{"line":217,"address":[],"length":0,"stats":{"Line":6}},{"line":218,"address":[],"length":0,"stats":{"Line":6}},{"line":219,"address":[],"length":0,"stats":{"Line":3}},{"line":220,"address":[],"length":0,"stats":{"Line":3}},{"line":224,"address":[],"length":0,"stats":{"Line":17}},{"line":225,"address":[],"length":0,"stats":{"Line":85}},{"line":227,"address":[],"length":0,"stats":{"Line":122}},{"line":228,"address":[],"length":0,"stats":{"Line":132}},{"line":229,"address":[],"length":0,"stats":{"Line":105}},{"line":231,"address":[],"length":0,"stats":{"Line":30}},{"line":232,"address":[],"length":0,"stats":{"Line":15}},{"line":233,"address":[],"length":0,"stats":{"Line":14}},{"line":237,"address":[],"length":0,"stats":{"Line":2}},{"line":238,"address":[],"length":0,"stats":{"Line":6}},{"line":239,"address":[],"length":0,"stats":{"Line":6}},{"line":240,"address":[],"length":0,"stats":{"Line":2}},{"line":241,"address":[],"length":0,"stats":{"Line":2}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":1}},{"line":248,"address":[],"length":0,"stats":{"Line":6}},{"line":251,"address":[],"length":0,"stats":{"Line":1}},{"line":252,"address":[],"length":0,"stats":{"Line":2}},{"line":257,"address":[],"length":0,"stats":{"Line":2}},{"line":260,"address":[],"length":0,"stats":{"Line":4}},{"line":261,"address":[],"length":0,"stats":{"Line":8}},{"line":263,"address":[],"length":0,"stats":{"Line":36}},{"line":264,"address":[],"length":0,"stats":{"Line":16}},{"line":265,"address":[],"length":0,"stats":{"Line":15}},{"line":266,"address":[],"length":0,"stats":{"Line":15}},{"line":268,"address":[],"length":0,"stats":{"Line":4}},{"line":269,"address":[],"length":0,"stats":{"Line":2}},{"line":271,"address":[],"length":0,"stats":{"Line":2}},{"line":272,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":4}},{"line":280,"address":[],"length":0,"stats":{"Line":2}},{"line":281,"address":[],"length":0,"stats":{"Line":3}},{"line":282,"address":[],"length":0,"stats":{"Line":2}},{"line":283,"address":[],"length":0,"stats":{"Line":2}},{"line":284,"address":[],"length":0,"stats":{"Line":3}},{"line":285,"address":[],"length":0,"stats":{"Line":2}},{"line":287,"address":[],"length":0,"stats":{"Line":5}},{"line":290,"address":[],"length":0,"stats":{"Line":1}},{"line":291,"address":[],"length":0,"stats":{"Line":1}},{"line":295,"address":[],"length":0,"stats":{"Line":1}},{"line":298,"address":[],"length":0,"stats":{"Line":3}},{"line":303,"address":[],"length":0,"stats":{"Line":6}},{"line":305,"address":[],"length":0,"stats":{"Line":6}},{"line":306,"address":[],"length":0,"stats":{"Line":3}},{"line":308,"address":[],"length":0,"stats":{"Line":6}},{"line":309,"address":[],"length":0,"stats":{"Line":3}},{"line":311,"address":[],"length":0,"stats":{"Line":6}},{"line":312,"address":[],"length":0,"stats":{"Line":3}},{"line":314,"address":[],"length":0,"stats":{"Line":5}},{"line":315,"address":[],"length":0,"stats":{"Line":2}},{"line":317,"address":[],"length":0,"stats":{"Line":5}},{"line":318,"address":[],"length":0,"stats":{"Line":2}},{"line":321,"address":[],"length":0,"stats":{"Line":15}},{"line":322,"address":[],"length":0,"stats":{"Line":12}},{"line":323,"address":[],"length":0,"stats":{"Line":3}},{"line":325,"address":[],"length":0,"stats":{"Line":6}}],"covered":134,"coverable":148},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","note_taking","generator.rs"],"content":"use std::time::{SystemTime, UNIX_EPOCH};\n\nuse serde::{Deserialize, Serialize};\n\nuse super::distiller::DistillationResult;\nuse crate::context_architect::ViewMode;\n\n#[derive(Debug, Clone)]\npub struct NoteGeneratorConfig {\n    pub include_code_snippets: bool,\n    pub include_metadata: bool,\n    pub max_pattern_length: usize,\n}\n\nimpl Default for NoteGeneratorConfig {\n    fn default() -> Self {\n        Self {\n            include_code_snippets: true,\n            include_metadata: true,\n            max_pattern_length: 500,\n        }\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GeneratedNote {\n    pub id: String,\n    pub title: String,\n    pub content: String,\n    pub tags: Vec<String>,\n    pub source_distillation_id: String,\n    pub created_at: u64,\n    pub quality_score: f32,\n}\n\nimpl GeneratedNote {\n    pub fn frontmatter(&self) -> String {\n        format!(\n            \"---\\ntitle: \\\"{}\\\"\\ntags: [{}]\\ncreated: {}\\nquality: {:.2}\\n---\",\n            self.title,\n            self.tags\n                .iter()\n                .map(|t| format!(\"\\\"{t}\\\"\"))\n                .collect::<Vec<_>>()\n                .join(\", \"),\n            self.created_at,\n            self.quality_score\n        )\n    }\n\n    pub fn full_markdown(&self) -> String {\n        format!(\"{}\\n\\n{}\", self.frontmatter(), self.content)\n    }\n}\n\npub struct NoteTemplate {\n    pub sections: Vec<NoteSection>,\n}\n\nimpl Default for NoteTemplate {\n    fn default() -> Self {\n        Self {\n            sections: vec![\n                NoteSection::Context,\n                NoteSection::Problem,\n                NoteSection::Solution,\n                NoteSection::Patterns,\n                NoteSection::CodeSnippets,\n                NoteSection::Metadata,\n            ],\n        }\n    }\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum NoteSection {\n    Context,\n    Problem,\n    Solution,\n    Patterns,\n    CodeSnippets,\n    Metadata,\n}\n\npub struct NoteGenerator {\n    config: NoteGeneratorConfig,\n    template: NoteTemplate,\n}\n\nimpl NoteGeneratorConfig {\n    pub fn for_view_mode(view_mode: ViewMode) -> Self {\n        match view_mode {\n            ViewMode::Ax => Self {\n                include_code_snippets: false,\n                include_metadata: false,\n                max_pattern_length: 200,\n            },\n            ViewMode::Ux => Self {\n                include_code_snippets: false,\n                include_metadata: true,\n                max_pattern_length: 300,\n            },\n            ViewMode::Dx => Self::default(),\n        }\n    }\n}\n\nimpl NoteTemplate {\n    pub fn for_view_mode(view_mode: ViewMode) -> Self {\n        let sections = match view_mode {\n            ViewMode::Ax => vec![NoteSection::Problem, NoteSection::Solution],\n            ViewMode::Ux => vec![\n                NoteSection::Context,\n                NoteSection::Problem,\n                NoteSection::Solution,\n                NoteSection::Patterns,\n                NoteSection::Metadata,\n            ],\n            ViewMode::Dx => vec![\n                NoteSection::Context,\n                NoteSection::Problem,\n                NoteSection::Solution,\n                NoteSection::Patterns,\n                NoteSection::CodeSnippets,\n                NoteSection::Metadata,\n            ],\n        };\n        Self { sections }\n    }\n}\n\nimpl NoteGenerator {\n    pub fn new(config: NoteGeneratorConfig) -> Self {\n        Self {\n            config,\n            template: NoteTemplate::default(),\n        }\n    }\n\n    pub fn with_template(mut self, template: NoteTemplate) -> Self {\n        self.template = template;\n        self\n    }\n\n    pub fn generate(&self, distillation: &DistillationResult) -> GeneratedNote {\n        let title = self.generate_title(distillation);\n        let content = self.generate_content(distillation);\n        let timestamp = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_secs())\n            .unwrap_or(0);\n\n        GeneratedNote {\n            id: uuid::Uuid::new_v4().to_string(),\n            title,\n            content,\n            tags: distillation.tags.clone(),\n            source_distillation_id: distillation.id.clone(),\n            created_at: timestamp,\n            quality_score: distillation.quality_score,\n        }\n    }\n\n    pub fn generate_for_view(\n        &self,\n        distillation: &DistillationResult,\n        view_mode: ViewMode,\n    ) -> GeneratedNote {\n        let template = NoteTemplate::for_view_mode(view_mode);\n        let config = NoteGeneratorConfig::for_view_mode(view_mode);\n        NoteGenerator::new(config)\n            .with_template(template)\n            .generate(distillation)\n    }\n\n    fn generate_title(&self, distillation: &DistillationResult) -> String {\n        if !distillation.problem.is_empty() {\n            let problem = &distillation.problem;\n            if problem.len() <= 60 {\n                return problem.clone();\n            }\n            return format!(\"{}...\", &problem[..57]);\n        }\n\n        if !distillation.context.is_empty() {\n            let context = &distillation.context;\n            if context.len() <= 60 {\n                return context.clone();\n            }\n            return format!(\"{}...\", &context[..57]);\n        }\n\n        format!(\"Note from {}\", distillation.trigger)\n    }\n\n    fn generate_content(&self, distillation: &DistillationResult) -> String {\n        let mut sections = Vec::new();\n\n        for section in &self.template.sections {\n            if let Some(content) = self.render_section(*section, distillation) {\n                sections.push(content);\n            }\n        }\n\n        sections.join(\"\\n\\n\")\n    }\n\n    fn render_section(\n        &self,\n        section: NoteSection,\n        distillation: &DistillationResult,\n    ) -> Option<String> {\n        match section {\n            NoteSection::Context => {\n                if distillation.context.is_empty() {\n                    None\n                } else {\n                    Some(format!(\"## Context\\n\\n{}\", distillation.context))\n                }\n            }\n            NoteSection::Problem => {\n                if distillation.problem.is_empty() {\n                    None\n                } else {\n                    Some(format!(\"## Problem\\n\\n{}\", distillation.problem))\n                }\n            }\n            NoteSection::Solution => {\n                if distillation.solution.is_empty() {\n                    None\n                } else {\n                    Some(format!(\"## Solution\\n\\n{}\", distillation.solution))\n                }\n            }\n            NoteSection::Patterns => {\n                if distillation.patterns.is_empty() {\n                    None\n                } else {\n                    let patterns: Vec<_> = distillation\n                        .patterns\n                        .iter()\n                        .map(|p| {\n                            if p.len() > self.config.max_pattern_length {\n                                format!(\"- {}...\", &p[..self.config.max_pattern_length - 3])\n                            } else {\n                                format!(\"- {p}\")\n                            }\n                        })\n                        .collect();\n                    Some(format!(\"## Patterns\\n\\n{}\", patterns.join(\"\\n\")))\n                }\n            }\n            NoteSection::CodeSnippets => {\n                if !self.config.include_code_snippets || distillation.code_snippets.is_empty() {\n                    None\n                } else {\n                    let snippets: Vec<_> = distillation\n                        .code_snippets\n                        .iter()\n                        .map(|s| format!(\"```\\n{s}\\n```\"))\n                        .collect();\n                    Some(format!(\"## Code Examples\\n\\n{}\", snippets.join(\"\\n\\n\")))\n                }\n            }\n            NoteSection::Metadata => {\n                if !self.config.include_metadata {\n                    None\n                } else {\n                    Some(format!(\n                        \"## Metadata\\n\\n- Trigger: {}\\n- Source Events: {}\\n- Quality Score: {:.2}\",\n                        distillation.trigger,\n                        distillation.source_event_count,\n                        distillation.quality_score\n                    ))\n                }\n            }\n        }\n    }\n\n    pub fn generate_batch(&self, distillations: &[DistillationResult]) -> Vec<GeneratedNote> {\n        distillations.iter().map(|d| self.generate(d)).collect()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    fn sample_distillation() -> DistillationResult {\n        DistillationResult {\n            id: \"dist-123\".to_string(),\n            trigger: \"SessionEnd\".to_string(),\n            context: \"Working on Rust project\".to_string(),\n            problem: \"How to handle async errors\".to_string(),\n            solution: \"Use anyhow crate with ? operator\".to_string(),\n            patterns: vec![\"Error handling pattern\".to_string()],\n            tags: vec![\"rust\".to_string(), \"async\".to_string()],\n            code_snippets: vec![\"fn main() -> Result<()> {}\".to_string()],\n            quality_score: 0.85,\n            distilled_at: 1234567890,\n            source_event_count: 5,\n        }\n    }\n\n    #[test]\n    fn test_generate_note() {\n        let generator = NoteGenerator::new(NoteGeneratorConfig::default());\n        let distillation = sample_distillation();\n\n        let note = generator.generate(&distillation);\n\n        assert_eq!(note.title, \"How to handle async errors\");\n        assert!(note.content.contains(\"## Context\"));\n        assert!(note.content.contains(\"## Solution\"));\n        assert!(!note.id.is_empty());\n    }\n\n    #[test]\n    fn test_generate_title_from_problem() {\n        let generator = NoteGenerator::new(NoteGeneratorConfig::default());\n        let distillation = sample_distillation();\n\n        let note = generator.generate(&distillation);\n\n        assert_eq!(note.title, distillation.problem);\n    }\n\n    #[test]\n    fn test_generate_title_truncation() {\n        let generator = NoteGenerator::new(NoteGeneratorConfig::default());\n        let mut distillation = sample_distillation();\n        distillation.problem = \"A\".repeat(100);\n\n        let note = generator.generate(&distillation);\n\n        assert!(note.title.len() <= 60);\n        assert!(note.title.ends_with(\"...\"));\n    }\n\n    #[test]\n    fn test_generate_title_fallback_to_context() {\n        let generator = NoteGenerator::new(NoteGeneratorConfig::default());\n        let mut distillation = sample_distillation();\n        distillation.problem = String::new();\n\n        let note = generator.generate(&distillation);\n\n        assert_eq!(note.title, distillation.context);\n    }\n\n    #[test]\n    fn test_content_includes_all_sections() {\n        let generator = NoteGenerator::new(NoteGeneratorConfig::default());\n        let distillation = sample_distillation();\n\n        let note = generator.generate(&distillation);\n\n        assert!(note.content.contains(\"## Context\"));\n        assert!(note.content.contains(\"## Problem\"));\n        assert!(note.content.contains(\"## Solution\"));\n        assert!(note.content.contains(\"## Patterns\"));\n        assert!(note.content.contains(\"## Code Examples\"));\n        assert!(note.content.contains(\"## Metadata\"));\n    }\n\n    #[test]\n    fn test_excludes_empty_sections() {\n        let generator = NoteGenerator::new(NoteGeneratorConfig::default());\n        let mut distillation = sample_distillation();\n        distillation.patterns = vec![];\n\n        let note = generator.generate(&distillation);\n\n        assert!(!note.content.contains(\"## Patterns\"));\n    }\n\n    #[test]\n    fn test_config_excludes_code_snippets() {\n        let config = NoteGeneratorConfig {\n            include_code_snippets: false,\n            ..Default::default()\n        };\n        let generator = NoteGenerator::new(config);\n        let distillation = sample_distillation();\n\n        let note = generator.generate(&distillation);\n\n        assert!(!note.content.contains(\"## Code Examples\"));\n    }\n\n    #[test]\n    fn test_config_excludes_metadata() {\n        let config = NoteGeneratorConfig {\n            include_metadata: false,\n            ..Default::default()\n        };\n        let generator = NoteGenerator::new(config);\n        let distillation = sample_distillation();\n\n        let note = generator.generate(&distillation);\n\n        assert!(!note.content.contains(\"## Metadata\"));\n    }\n\n    #[test]\n    fn test_frontmatter_generation() {\n        let generator = NoteGenerator::new(NoteGeneratorConfig::default());\n        let distillation = sample_distillation();\n\n        let note = generator.generate(&distillation);\n        let frontmatter = note.frontmatter();\n\n        assert!(frontmatter.starts_with(\"---\"));\n        assert!(frontmatter.contains(\"title:\"));\n        assert!(frontmatter.contains(\"tags:\"));\n        assert!(frontmatter.contains(\"quality:\"));\n    }\n\n    #[test]\n    fn test_full_markdown() {\n        let generator = NoteGenerator::new(NoteGeneratorConfig::default());\n        let distillation = sample_distillation();\n\n        let note = generator.generate(&distillation);\n        let markdown = note.full_markdown();\n\n        assert!(markdown.starts_with(\"---\"));\n        assert!(markdown.contains(\"## Context\"));\n    }\n\n    #[test]\n    fn test_batch_generation() {\n        let generator = NoteGenerator::new(NoteGeneratorConfig::default());\n        let distillations = vec![sample_distillation(), sample_distillation()];\n\n        let notes = generator.generate_batch(&distillations);\n\n        assert_eq!(notes.len(), 2);\n    }\n\n    #[test]\n    fn test_custom_template() {\n        let template = NoteTemplate {\n            sections: vec![NoteSection::Problem, NoteSection::Solution],\n        };\n        let generator = NoteGenerator::new(NoteGeneratorConfig::default()).with_template(template);\n        let distillation = sample_distillation();\n\n        let note = generator.generate(&distillation);\n\n        assert!(note.content.contains(\"## Problem\"));\n        assert!(note.content.contains(\"## Solution\"));\n        assert!(!note.content.contains(\"## Context\"));\n        assert!(!note.content.contains(\"## Metadata\"));\n    }\n\n    #[test]\n    fn test_view_mode_ax_limits_sections() {\n        let generator = NoteGenerator::new(NoteGeneratorConfig::default());\n        let distillation = sample_distillation();\n\n        let note = generator.generate_for_view(&distillation, ViewMode::Ax);\n\n        assert!(note.content.contains(\"## Problem\"));\n        assert!(note.content.contains(\"## Solution\"));\n        assert!(!note.content.contains(\"## Context\"));\n        assert!(!note.content.contains(\"## Metadata\"));\n    }\n\n    #[test]\n    fn test_view_mode_ux_includes_context() {\n        let generator = NoteGenerator::new(NoteGeneratorConfig::default());\n        let distillation = sample_distillation();\n\n        let note = generator.generate_for_view(&distillation, ViewMode::Ux);\n\n        assert!(note.content.contains(\"## Context\"));\n        assert!(note.content.contains(\"## Problem\"));\n        assert!(note.content.contains(\"## Metadata\"));\n        assert!(!note.content.contains(\"## Code Examples\"));\n    }\n\n    #[test]\n    fn test_pattern_length_truncation() {\n        let config = NoteGeneratorConfig {\n            max_pattern_length: 20,\n            ..Default::default()\n        };\n        let generator = NoteGenerator::new(config);\n        let mut distillation = sample_distillation();\n        distillation.patterns = vec![\"A\".repeat(50)];\n\n        let note = generator.generate(&distillation);\n\n        assert!(note.content.contains(\"...\"));\n    }\n\n    #[test]\n    fn test_tags_preserved() {\n        let generator = NoteGenerator::new(NoteGeneratorConfig::default());\n        let distillation = sample_distillation();\n\n        let note = generator.generate(&distillation);\n\n        assert_eq!(note.tags, distillation.tags);\n    }\n}\n","traces":[{"line":16,"address":[],"length":0,"stats":{"Line":16}},{"line":37,"address":[],"length":0,"stats":{"Line":2}},{"line":38,"address":[],"length":0,"stats":{"Line":2}},{"line":41,"address":[],"length":0,"stats":{"Line":2}},{"line":42,"address":[],"length":0,"stats":{"Line":2}},{"line":43,"address":[],"length":0,"stats":{"Line":10}},{"line":44,"address":[],"length":0,"stats":{"Line":2}},{"line":45,"address":[],"length":0,"stats":{"Line":4}},{"line":51,"address":[],"length":0,"stats":{"Line":1}},{"line":52,"address":[],"length":0,"stats":{"Line":4}},{"line":61,"address":[],"length":0,"stats":{"Line":18}},{"line":63,"address":[],"length":0,"stats":{"Line":36}},{"line":91,"address":[],"length":0,"stats":{"Line":2}},{"line":92,"address":[],"length":0,"stats":{"Line":2}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":2}},{"line":110,"address":[],"length":0,"stats":{"Line":4}},{"line":111,"address":[],"length":0,"stats":{"Line":3}},{"line":112,"address":[],"length":0,"stats":{"Line":1}},{"line":113,"address":[],"length":0,"stats":{"Line":1}},{"line":114,"address":[],"length":0,"stats":{"Line":1}},{"line":115,"address":[],"length":0,"stats":{"Line":1}},{"line":116,"address":[],"length":0,"stats":{"Line":1}},{"line":117,"address":[],"length":0,"stats":{"Line":1}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":18}},{"line":136,"address":[],"length":0,"stats":{"Line":18}},{"line":140,"address":[],"length":0,"stats":{"Line":3}},{"line":141,"address":[],"length":0,"stats":{"Line":6}},{"line":142,"address":[],"length":0,"stats":{"Line":3}},{"line":145,"address":[],"length":0,"stats":{"Line":17}},{"line":146,"address":[],"length":0,"stats":{"Line":68}},{"line":147,"address":[],"length":0,"stats":{"Line":68}},{"line":148,"address":[],"length":0,"stats":{"Line":34}},{"line":149,"address":[],"length":0,"stats":{"Line":17}},{"line":150,"address":[],"length":0,"stats":{"Line":51}},{"line":154,"address":[],"length":0,"stats":{"Line":51}},{"line":157,"address":[],"length":0,"stats":{"Line":51}},{"line":158,"address":[],"length":0,"stats":{"Line":51}},{"line":160,"address":[],"length":0,"stats":{"Line":17}},{"line":164,"address":[],"length":0,"stats":{"Line":2}},{"line":169,"address":[],"length":0,"stats":{"Line":6}},{"line":170,"address":[],"length":0,"stats":{"Line":6}},{"line":171,"address":[],"length":0,"stats":{"Line":6}},{"line":172,"address":[],"length":0,"stats":{"Line":2}},{"line":173,"address":[],"length":0,"stats":{"Line":4}},{"line":176,"address":[],"length":0,"stats":{"Line":17}},{"line":177,"address":[],"length":0,"stats":{"Line":17}},{"line":178,"address":[],"length":0,"stats":{"Line":32}},{"line":179,"address":[],"length":0,"stats":{"Line":16}},{"line":180,"address":[],"length":0,"stats":{"Line":30}},{"line":182,"address":[],"length":0,"stats":{"Line":3}},{"line":185,"address":[],"length":0,"stats":{"Line":1}},{"line":186,"address":[],"length":0,"stats":{"Line":2}},{"line":187,"address":[],"length":0,"stats":{"Line":1}},{"line":188,"address":[],"length":0,"stats":{"Line":2}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":17}},{"line":197,"address":[],"length":0,"stats":{"Line":34}},{"line":199,"address":[],"length":0,"stats":{"Line":203}},{"line":200,"address":[],"length":0,"stats":{"Line":457}},{"line":201,"address":[],"length":0,"stats":{"Line":178}},{"line":205,"address":[],"length":0,"stats":{"Line":34}},{"line":208,"address":[],"length":0,"stats":{"Line":93}},{"line":213,"address":[],"length":0,"stats":{"Line":93}},{"line":215,"address":[],"length":0,"stats":{"Line":30}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":15}},{"line":222,"address":[],"length":0,"stats":{"Line":34}},{"line":223,"address":[],"length":0,"stats":{"Line":1}},{"line":225,"address":[],"length":0,"stats":{"Line":16}},{"line":229,"address":[],"length":0,"stats":{"Line":34}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":17}},{"line":236,"address":[],"length":0,"stats":{"Line":30}},{"line":237,"address":[],"length":0,"stats":{"Line":1}},{"line":239,"address":[],"length":0,"stats":{"Line":42}},{"line":240,"address":[],"length":0,"stats":{"Line":14}},{"line":242,"address":[],"length":0,"stats":{"Line":28}},{"line":243,"address":[],"length":0,"stats":{"Line":28}},{"line":244,"address":[],"length":0,"stats":{"Line":3}},{"line":246,"address":[],"length":0,"stats":{"Line":26}},{"line":250,"address":[],"length":0,"stats":{"Line":56}},{"line":254,"address":[],"length":0,"stats":{"Line":40}},{"line":255,"address":[],"length":0,"stats":{"Line":1}},{"line":257,"address":[],"length":0,"stats":{"Line":39}},{"line":258,"address":[],"length":0,"stats":{"Line":13}},{"line":260,"address":[],"length":0,"stats":{"Line":39}},{"line":262,"address":[],"length":0,"stats":{"Line":52}},{"line":266,"address":[],"length":0,"stats":{"Line":15}},{"line":267,"address":[],"length":0,"stats":{"Line":1}},{"line":269,"address":[],"length":0,"stats":{"Line":14}},{"line":270,"address":[],"length":0,"stats":{"Line":14}},{"line":271,"address":[],"length":0,"stats":{"Line":14}},{"line":272,"address":[],"length":0,"stats":{"Line":14}},{"line":273,"address":[],"length":0,"stats":{"Line":14}},{"line":280,"address":[],"length":0,"stats":{"Line":1}},{"line":281,"address":[],"length":0,"stats":{"Line":10}}],"covered":93,"coverable":105},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","note_taking","lifecycle.rs"],"content":"use std::time::{SystemTime, UNIX_EPOCH};\n\nuse serde::{Deserialize, Serialize};\nuse thiserror::Error;\nuse tracing::{info, instrument, warn};\n\nuse super::generator::GeneratedNote;\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize, Default)]\n#[serde(rename_all = \"snake_case\")]\npub enum NoteStatus {\n    #[default]\n    Draft,\n    Proposed,\n    Accepted,\n    Rejected,\n    Deprecated,\n}\n\nimpl NoteStatus {\n    pub fn as_str(&self) -> &'static str {\n        match self {\n            Self::Draft => \"draft\",\n            Self::Proposed => \"proposed\",\n            Self::Accepted => \"accepted\",\n            Self::Rejected => \"rejected\",\n            Self::Deprecated => \"deprecated\",\n        }\n    }\n\n    pub fn is_terminal(&self) -> bool {\n        matches!(self, Self::Rejected | Self::Deprecated)\n    }\n\n    pub fn is_active(&self) -> bool {\n        matches!(self, Self::Draft | Self::Proposed | Self::Accepted)\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct LifecycleConfig {\n    pub auto_propose_usefulness_threshold: f32,\n    pub auto_propose_retrieval_threshold: u32,\n    pub deprecation_retrieval_threshold: u32,\n    pub deprecation_usefulness_ratio: f32,\n}\n\nimpl Default for LifecycleConfig {\n    fn default() -> Self {\n        Self {\n            auto_propose_usefulness_threshold: 0.8,\n            auto_propose_retrieval_threshold: 5,\n            deprecation_retrieval_threshold: 10,\n            deprecation_usefulness_ratio: 0.1,\n        }\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct NoteWithLifecycle {\n    pub note: GeneratedNote,\n    pub status: NoteStatus,\n    pub usefulness_score: f32,\n    pub retrieval_count: u32,\n    pub status_changed_at: u64,\n    pub review_flagged: bool,\n    pub deprecation_reason: Option<String>,\n}\n\nimpl NoteWithLifecycle {\n    pub fn new(note: GeneratedNote) -> Self {\n        let now = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_secs())\n            .unwrap_or(0);\n\n        Self {\n            note,\n            status: NoteStatus::Draft,\n            usefulness_score: 0.0,\n            retrieval_count: 0,\n            status_changed_at: now,\n            review_flagged: false,\n            deprecation_reason: None,\n        }\n    }\n\n    pub fn id(&self) -> &str {\n        &self.note.id\n    }\n\n    pub fn usefulness_ratio(&self) -> f32 {\n        if self.retrieval_count == 0 {\n            return 0.0;\n        }\n        self.usefulness_score / self.retrieval_count as f32\n    }\n\n    #[instrument(skip(self), fields(note_id = %self.id(), current_status = ?self.status))]\n    pub fn transition_to(\n        &mut self,\n        new_status: NoteStatus,\n    ) -> Result<NoteStatus, LifecycleTransitionError> {\n        let old_status = self.status;\n\n        if !Self::is_valid_transition(old_status, new_status) {\n            return Err(LifecycleTransitionError::InvalidTransition {\n                from: old_status,\n                to: new_status,\n            });\n        }\n\n        self.status = new_status;\n        self.status_changed_at = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .map(|d| d.as_secs())\n            .unwrap_or(0);\n\n        info!(\n            from = ?old_status,\n            to = ?new_status,\n            \"Note status transitioned\"\n        );\n\n        Ok(old_status)\n    }\n\n    fn is_valid_transition(from: NoteStatus, to: NoteStatus) -> bool {\n        use NoteStatus::*;\n\n        matches!(\n            (from, to),\n            (Draft, Proposed)\n                | (Draft, Rejected)\n                | (Draft, Deprecated)\n                | (Proposed, Accepted)\n                | (Proposed, Rejected)\n                | (Proposed, Draft)\n                | (Accepted, Deprecated)\n        )\n    }\n\n    pub fn record_retrieval(&mut self) {\n        self.retrieval_count = self.retrieval_count.saturating_add(1);\n    }\n\n    pub fn record_positive_feedback(&mut self, weight: f32) {\n        self.usefulness_score += weight.clamp(0.0, 1.0);\n    }\n\n    pub fn record_negative_feedback(&mut self, weight: f32) {\n        self.usefulness_score = (self.usefulness_score - weight.clamp(0.0, 1.0)).max(0.0);\n    }\n\n    pub fn should_auto_propose(&self, config: &LifecycleConfig) -> bool {\n        self.status == NoteStatus::Draft\n            && self.usefulness_score >= config.auto_propose_usefulness_threshold\n            && self.retrieval_count >= config.auto_propose_retrieval_threshold\n    }\n\n    pub fn should_flag_for_review(&self, config: &LifecycleConfig) -> bool {\n        self.retrieval_count >= config.deprecation_retrieval_threshold\n            && self.usefulness_ratio() < config.deprecation_usefulness_ratio\n    }\n\n    #[instrument(skip(self, config), fields(note_id = %self.id()))]\n    pub fn evaluate_auto_transitions(\n        &mut self,\n        config: &LifecycleConfig,\n    ) -> Option<AutoTransitionResult> {\n        if self.should_auto_propose(config) {\n            match self.transition_to(NoteStatus::Proposed) {\n                Ok(old) => {\n                    info!(\"Auto-proposed note due to high usefulness\");\n                    return Some(AutoTransitionResult::Proposed { from: old });\n                }\n                Err(e) => {\n                    warn!(error = %e, \"Failed to auto-propose note\");\n                }\n            }\n        }\n\n        if self.should_flag_for_review(config) && !self.review_flagged {\n            self.review_flagged = true;\n            info!(\n                usefulness_ratio = self.usefulness_ratio(),\n                retrieval_count = self.retrieval_count,\n                \"Note flagged for review due to low usefulness\"\n            );\n            return Some(AutoTransitionResult::FlaggedForReview);\n        }\n\n        None\n    }\n\n    pub fn deprecate(&mut self, reason: impl Into<String>) -> Result<(), LifecycleTransitionError> {\n        self.deprecation_reason = Some(reason.into());\n        self.transition_to(NoteStatus::Deprecated)?;\n        Ok(())\n    }\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub enum AutoTransitionResult {\n    Proposed { from: NoteStatus },\n    FlaggedForReview,\n}\n\n#[derive(Debug, Clone, Error)]\npub enum LifecycleTransitionError {\n    #[error(\"Invalid transition from {from:?} to {to:?}\")]\n    InvalidTransition { from: NoteStatus, to: NoteStatus },\n}\n\npub struct NoteLifecycleManager {\n    config: LifecycleConfig,\n}\n\nimpl NoteLifecycleManager {\n    pub fn new(config: LifecycleConfig) -> Self {\n        Self { config }\n    }\n\n    pub fn wrap_note(&self, note: GeneratedNote) -> NoteWithLifecycle {\n        NoteWithLifecycle::new(note)\n    }\n\n    pub fn record_retrieval(&self, note: &mut NoteWithLifecycle) {\n        note.record_retrieval();\n        note.evaluate_auto_transitions(&self.config);\n    }\n\n    pub fn record_feedback(&self, note: &mut NoteWithLifecycle, positive: bool, weight: f32) {\n        if positive {\n            note.record_positive_feedback(weight);\n        } else {\n            note.record_negative_feedback(weight);\n        }\n        note.evaluate_auto_transitions(&self.config);\n    }\n\n    pub fn propose(&self, note: &mut NoteWithLifecycle) -> Result<(), LifecycleTransitionError> {\n        note.transition_to(NoteStatus::Proposed)?;\n        Ok(())\n    }\n\n    pub fn accept(&self, note: &mut NoteWithLifecycle) -> Result<(), LifecycleTransitionError> {\n        note.transition_to(NoteStatus::Accepted)?;\n        Ok(())\n    }\n\n    pub fn reject(&self, note: &mut NoteWithLifecycle) -> Result<(), LifecycleTransitionError> {\n        note.transition_to(NoteStatus::Rejected)?;\n        Ok(())\n    }\n\n    pub fn deprecate(\n        &self,\n        note: &mut NoteWithLifecycle,\n        reason: impl Into<String>,\n    ) -> Result<(), LifecycleTransitionError> {\n        note.deprecate(reason)\n    }\n\n    pub fn evaluate_batch(\n        &self,\n        notes: &mut [NoteWithLifecycle],\n    ) -> Vec<(String, AutoTransitionResult)> {\n        notes\n            .iter_mut()\n            .filter_map(|note| {\n                note.evaluate_auto_transitions(&self.config)\n                    .map(|result| (note.id().to_string(), result))\n            })\n            .collect()\n    }\n\n    pub fn config(&self) -> &LifecycleConfig {\n        &self.config\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    fn sample_note(id: &str) -> GeneratedNote {\n        GeneratedNote {\n            id: id.to_string(),\n            title: \"Test Note\".to_string(),\n            content: \"Test content\".to_string(),\n            tags: vec![\"test\".to_string()],\n            source_distillation_id: \"dist-123\".to_string(),\n            created_at: 1000,\n            quality_score: 0.8,\n        }\n    }\n\n    #[test]\n    fn test_new_note_is_draft() {\n        let note = NoteWithLifecycle::new(sample_note(\"1\"));\n        assert_eq!(note.status, NoteStatus::Draft);\n        assert_eq!(note.usefulness_score, 0.0);\n        assert_eq!(note.retrieval_count, 0);\n    }\n\n    #[test]\n    fn test_valid_transitions() {\n        let mut note = NoteWithLifecycle::new(sample_note(\"1\"));\n\n        assert!(note.transition_to(NoteStatus::Proposed).is_ok());\n        assert_eq!(note.status, NoteStatus::Proposed);\n\n        assert!(note.transition_to(NoteStatus::Accepted).is_ok());\n        assert_eq!(note.status, NoteStatus::Accepted);\n\n        assert!(note.transition_to(NoteStatus::Deprecated).is_ok());\n        assert_eq!(note.status, NoteStatus::Deprecated);\n    }\n\n    #[test]\n    fn test_invalid_transition_draft_to_accepted() {\n        let mut note = NoteWithLifecycle::new(sample_note(\"1\"));\n        let result = note.transition_to(NoteStatus::Accepted);\n\n        assert!(matches!(\n            result,\n            Err(LifecycleTransitionError::InvalidTransition { .. })\n        ));\n        assert_eq!(note.status, NoteStatus::Draft);\n    }\n\n    #[test]\n    fn test_invalid_transition_accepted_to_proposed() {\n        let mut note = NoteWithLifecycle::new(sample_note(\"1\"));\n        note.transition_to(NoteStatus::Proposed).unwrap();\n        note.transition_to(NoteStatus::Accepted).unwrap();\n\n        let result = note.transition_to(NoteStatus::Proposed);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_record_retrieval_increments_count() {\n        let mut note = NoteWithLifecycle::new(sample_note(\"1\"));\n\n        note.record_retrieval();\n        assert_eq!(note.retrieval_count, 1);\n\n        note.record_retrieval();\n        assert_eq!(note.retrieval_count, 2);\n    }\n\n    #[test]\n    fn test_record_positive_feedback() {\n        let mut note = NoteWithLifecycle::new(sample_note(\"1\"));\n\n        note.record_positive_feedback(0.5);\n        assert!((note.usefulness_score - 0.5).abs() < 0.001);\n\n        note.record_positive_feedback(0.3);\n        assert!((note.usefulness_score - 0.8).abs() < 0.001);\n    }\n\n    #[test]\n    fn test_record_negative_feedback() {\n        let mut note = NoteWithLifecycle::new(sample_note(\"1\"));\n        note.usefulness_score = 1.0;\n\n        note.record_negative_feedback(0.3);\n        assert!((note.usefulness_score - 0.7).abs() < 0.001);\n    }\n\n    #[test]\n    fn test_negative_feedback_clamps_at_zero() {\n        let mut note = NoteWithLifecycle::new(sample_note(\"1\"));\n        note.usefulness_score = 0.2;\n\n        note.record_negative_feedback(0.5);\n        assert_eq!(note.usefulness_score, 0.0);\n    }\n\n    #[test]\n    fn test_usefulness_ratio_calculation() {\n        let mut note = NoteWithLifecycle::new(sample_note(\"1\"));\n\n        assert_eq!(note.usefulness_ratio(), 0.0);\n\n        note.retrieval_count = 10;\n        note.usefulness_score = 2.0;\n\n        assert!((note.usefulness_ratio() - 0.2).abs() < 0.001);\n    }\n\n    #[test]\n    fn test_should_auto_propose() {\n        let config = LifecycleConfig {\n            auto_propose_usefulness_threshold: 0.8,\n            auto_propose_retrieval_threshold: 5,\n            ..Default::default()\n        };\n        let mut note = NoteWithLifecycle::new(sample_note(\"1\"));\n\n        assert!(!note.should_auto_propose(&config));\n\n        note.usefulness_score = 0.9;\n        assert!(!note.should_auto_propose(&config));\n\n        note.retrieval_count = 5;\n        assert!(note.should_auto_propose(&config));\n\n        note.transition_to(NoteStatus::Proposed).unwrap();\n        assert!(!note.should_auto_propose(&config));\n    }\n\n    #[test]\n    fn test_should_flag_for_review() {\n        let config = LifecycleConfig {\n            deprecation_retrieval_threshold: 10,\n            deprecation_usefulness_ratio: 0.1,\n            ..Default::default()\n        };\n        let mut note = NoteWithLifecycle::new(sample_note(\"1\"));\n\n        assert!(!note.should_flag_for_review(&config));\n\n        note.retrieval_count = 15;\n        note.usefulness_score = 0.5;\n\n        assert!(note.should_flag_for_review(&config));\n    }\n\n    #[test]\n    fn test_evaluate_auto_transitions_proposes() {\n        let config = LifecycleConfig {\n            auto_propose_usefulness_threshold: 0.8,\n            auto_propose_retrieval_threshold: 5,\n            ..Default::default()\n        };\n        let mut note = NoteWithLifecycle::new(sample_note(\"1\"));\n        note.usefulness_score = 0.9;\n        note.retrieval_count = 6;\n\n        let result = note.evaluate_auto_transitions(&config);\n\n        assert!(matches!(\n            result,\n            Some(AutoTransitionResult::Proposed {\n                from: NoteStatus::Draft\n            })\n        ));\n        assert_eq!(note.status, NoteStatus::Proposed);\n    }\n\n    #[test]\n    fn test_evaluate_auto_transitions_flags_for_review() {\n        let config = LifecycleConfig {\n            deprecation_retrieval_threshold: 10,\n            deprecation_usefulness_ratio: 0.1,\n            ..Default::default()\n        };\n        let mut note = NoteWithLifecycle::new(sample_note(\"1\"));\n        note.retrieval_count = 15;\n        note.usefulness_score = 0.5;\n\n        let result = note.evaluate_auto_transitions(&config);\n\n        assert!(matches!(\n            result,\n            Some(AutoTransitionResult::FlaggedForReview)\n        ));\n        assert!(note.review_flagged);\n    }\n\n    #[test]\n    fn test_flag_for_review_only_once() {\n        let config = LifecycleConfig {\n            deprecation_retrieval_threshold: 10,\n            deprecation_usefulness_ratio: 0.1,\n            ..Default::default()\n        };\n        let mut note = NoteWithLifecycle::new(sample_note(\"1\"));\n        note.retrieval_count = 15;\n        note.usefulness_score = 0.5;\n\n        let result1 = note.evaluate_auto_transitions(&config);\n        assert!(result1.is_some());\n\n        let result2 = note.evaluate_auto_transitions(&config);\n        assert!(result2.is_none());\n    }\n\n    #[test]\n    fn test_deprecate_with_reason() {\n        let mut note = NoteWithLifecycle::new(sample_note(\"1\"));\n        note.transition_to(NoteStatus::Proposed).unwrap();\n        note.transition_to(NoteStatus::Accepted).unwrap();\n\n        note.deprecate(\"No longer relevant\").unwrap();\n\n        assert_eq!(note.status, NoteStatus::Deprecated);\n        assert_eq!(\n            note.deprecation_reason,\n            Some(\"No longer relevant\".to_string())\n        );\n    }\n\n    #[test]\n    fn test_lifecycle_manager_record_retrieval() {\n        let manager = NoteLifecycleManager::new(LifecycleConfig::default());\n        let note = sample_note(\"1\");\n        let mut wrapped = manager.wrap_note(note);\n\n        manager.record_retrieval(&mut wrapped);\n\n        assert_eq!(wrapped.retrieval_count, 1);\n    }\n\n    #[test]\n    fn test_lifecycle_manager_record_feedback() {\n        let manager = NoteLifecycleManager::new(LifecycleConfig::default());\n        let note = sample_note(\"1\");\n        let mut wrapped = manager.wrap_note(note);\n\n        manager.record_feedback(&mut wrapped, true, 0.5);\n        assert!((wrapped.usefulness_score - 0.5).abs() < 0.001);\n\n        manager.record_feedback(&mut wrapped, false, 0.2);\n        assert!((wrapped.usefulness_score - 0.3).abs() < 0.001);\n    }\n\n    #[test]\n    fn test_lifecycle_manager_workflow() {\n        let manager = NoteLifecycleManager::new(LifecycleConfig::default());\n        let note = sample_note(\"1\");\n        let mut wrapped = manager.wrap_note(note);\n\n        assert!(manager.propose(&mut wrapped).is_ok());\n        assert_eq!(wrapped.status, NoteStatus::Proposed);\n\n        assert!(manager.accept(&mut wrapped).is_ok());\n        assert_eq!(wrapped.status, NoteStatus::Accepted);\n\n        assert!(manager.deprecate(&mut wrapped, \"Outdated\").is_ok());\n        assert_eq!(wrapped.status, NoteStatus::Deprecated);\n    }\n\n    #[test]\n    fn test_lifecycle_manager_reject() {\n        let manager = NoteLifecycleManager::new(LifecycleConfig::default());\n        let note = sample_note(\"1\");\n        let mut wrapped = manager.wrap_note(note);\n\n        manager.propose(&mut wrapped).unwrap();\n        assert!(manager.reject(&mut wrapped).is_ok());\n        assert_eq!(wrapped.status, NoteStatus::Rejected);\n    }\n\n    #[test]\n    fn test_evaluate_batch() {\n        let config = LifecycleConfig {\n            auto_propose_usefulness_threshold: 0.8,\n            auto_propose_retrieval_threshold: 5,\n            ..Default::default()\n        };\n        let manager = NoteLifecycleManager::new(config);\n\n        let mut notes: Vec<NoteWithLifecycle> = (0..3)\n            .map(|i| {\n                let mut note = manager.wrap_note(sample_note(&i.to_string()));\n                if i == 1 {\n                    note.usefulness_score = 0.9;\n                    note.retrieval_count = 6;\n                }\n                note\n            })\n            .collect();\n\n        let transitions = manager.evaluate_batch(&mut notes);\n\n        assert_eq!(transitions.len(), 1);\n        assert_eq!(transitions[0].0, \"1\");\n        assert!(matches!(\n            transitions[0].1,\n            AutoTransitionResult::Proposed { .. }\n        ));\n    }\n\n    #[test]\n    fn test_note_status_as_str() {\n        assert_eq!(NoteStatus::Draft.as_str(), \"draft\");\n        assert_eq!(NoteStatus::Proposed.as_str(), \"proposed\");\n        assert_eq!(NoteStatus::Accepted.as_str(), \"accepted\");\n        assert_eq!(NoteStatus::Rejected.as_str(), \"rejected\");\n        assert_eq!(NoteStatus::Deprecated.as_str(), \"deprecated\");\n    }\n\n    #[test]\n    fn test_note_status_is_terminal() {\n        assert!(!NoteStatus::Draft.is_terminal());\n        assert!(!NoteStatus::Proposed.is_terminal());\n        assert!(!NoteStatus::Accepted.is_terminal());\n        assert!(NoteStatus::Rejected.is_terminal());\n        assert!(NoteStatus::Deprecated.is_terminal());\n    }\n\n    #[test]\n    fn test_note_status_is_active() {\n        assert!(NoteStatus::Draft.is_active());\n        assert!(NoteStatus::Proposed.is_active());\n        assert!(NoteStatus::Accepted.is_active());\n        assert!(!NoteStatus::Rejected.is_active());\n        assert!(!NoteStatus::Deprecated.is_active());\n    }\n\n    #[test]\n    fn test_proposed_can_return_to_draft() {\n        let mut note = NoteWithLifecycle::new(sample_note(\"1\"));\n        note.transition_to(NoteStatus::Proposed).unwrap();\n\n        assert!(note.transition_to(NoteStatus::Draft).is_ok());\n        assert_eq!(note.status, NoteStatus::Draft);\n    }\n\n    #[test]\n    fn test_feedback_weight_clamped() {\n        let mut note = NoteWithLifecycle::new(sample_note(\"1\"));\n\n        note.record_positive_feedback(2.0);\n        assert!((note.usefulness_score - 1.0).abs() < 0.001);\n\n        note.record_positive_feedback(-1.0);\n        assert!((note.usefulness_score - 1.0).abs() < 0.001);\n    }\n}\n","traces":[{"line":21,"address":[],"length":0,"stats":{"Line":5}},{"line":22,"address":[],"length":0,"stats":{"Line":5}},{"line":23,"address":[],"length":0,"stats":{"Line":1}},{"line":24,"address":[],"length":0,"stats":{"Line":1}},{"line":25,"address":[],"length":0,"stats":{"Line":1}},{"line":26,"address":[],"length":0,"stats":{"Line":1}},{"line":27,"address":[],"length":0,"stats":{"Line":1}},{"line":31,"address":[],"length":0,"stats":{"Line":5}},{"line":32,"address":[],"length":0,"stats":{"Line":8}},{"line":35,"address":[],"length":0,"stats":{"Line":5}},{"line":36,"address":[],"length":0,"stats":{"Line":7}},{"line":49,"address":[],"length":0,"stats":{"Line":10}},{"line":71,"address":[],"length":0,"stats":{"Line":24}},{"line":72,"address":[],"length":0,"stats":{"Line":48}},{"line":73,"address":[],"length":0,"stats":{"Line":24}},{"line":74,"address":[],"length":0,"stats":{"Line":72}},{"line":88,"address":[],"length":0,"stats":{"Line":31}},{"line":89,"address":[],"length":0,"stats":{"Line":31}},{"line":92,"address":[],"length":0,"stats":{"Line":6}},{"line":93,"address":[],"length":0,"stats":{"Line":6}},{"line":94,"address":[],"length":0,"stats":{"Line":1}},{"line":96,"address":[],"length":0,"stats":{"Line":5}},{"line":100,"address":[],"length":0,"stats":{"Line":20}},{"line":104,"address":[],"length":0,"stats":{"Line":40}},{"line":106,"address":[],"length":0,"stats":{"Line":40}},{"line":107,"address":[],"length":0,"stats":{"Line":2}},{"line":108,"address":[],"length":0,"stats":{"Line":2}},{"line":109,"address":[],"length":0,"stats":{"Line":2}},{"line":113,"address":[],"length":0,"stats":{"Line":18}},{"line":114,"address":[],"length":0,"stats":{"Line":18}},{"line":115,"address":[],"length":0,"stats":{"Line":18}},{"line":116,"address":[],"length":0,"stats":{"Line":54}},{"line":117,"address":[],"length":0,"stats":{"Line":18}},{"line":119,"address":[],"length":0,"stats":{"Line":18}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":18}},{"line":128,"address":[],"length":0,"stats":{"Line":20}},{"line":131,"address":[],"length":0,"stats":{"Line":2}},{"line":132,"address":[],"length":0,"stats":{"Line":40}},{"line":143,"address":[],"length":0,"stats":{"Line":3}},{"line":144,"address":[],"length":0,"stats":{"Line":3}},{"line":147,"address":[],"length":0,"stats":{"Line":5}},{"line":148,"address":[],"length":0,"stats":{"Line":5}},{"line":151,"address":[],"length":0,"stats":{"Line":3}},{"line":152,"address":[],"length":0,"stats":{"Line":6}},{"line":155,"address":[],"length":0,"stats":{"Line":14}},{"line":156,"address":[],"length":0,"stats":{"Line":14}},{"line":157,"address":[],"length":0,"stats":{"Line":13}},{"line":158,"address":[],"length":0,"stats":{"Line":4}},{"line":161,"address":[],"length":0,"stats":{"Line":10}},{"line":162,"address":[],"length":0,"stats":{"Line":10}},{"line":163,"address":[],"length":0,"stats":{"Line":8}},{"line":167,"address":[],"length":0,"stats":{"Line":10}},{"line":171,"address":[],"length":0,"stats":{"Line":30}},{"line":172,"address":[],"length":0,"stats":{"Line":4}},{"line":173,"address":[],"length":0,"stats":{"Line":2}},{"line":174,"address":[],"length":0,"stats":{"Line":2}},{"line":175,"address":[],"length":0,"stats":{"Line":2}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":0}},{"line":183,"address":[],"length":0,"stats":{"Line":27}},{"line":184,"address":[],"length":0,"stats":{"Line":2}},{"line":185,"address":[],"length":0,"stats":{"Line":2}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":2}},{"line":193,"address":[],"length":0,"stats":{"Line":6}},{"line":196,"address":[],"length":0,"stats":{"Line":2}},{"line":197,"address":[],"length":0,"stats":{"Line":4}},{"line":198,"address":[],"length":0,"stats":{"Line":6}},{"line":199,"address":[],"length":0,"stats":{"Line":2}},{"line":220,"address":[],"length":0,"stats":{"Line":5}},{"line":224,"address":[],"length":0,"stats":{"Line":7}},{"line":225,"address":[],"length":0,"stats":{"Line":14}},{"line":228,"address":[],"length":0,"stats":{"Line":1}},{"line":229,"address":[],"length":0,"stats":{"Line":2}},{"line":230,"address":[],"length":0,"stats":{"Line":3}},{"line":233,"address":[],"length":0,"stats":{"Line":2}},{"line":234,"address":[],"length":0,"stats":{"Line":3}},{"line":235,"address":[],"length":0,"stats":{"Line":2}},{"line":237,"address":[],"length":0,"stats":{"Line":2}},{"line":239,"address":[],"length":0,"stats":{"Line":6}},{"line":242,"address":[],"length":0,"stats":{"Line":2}},{"line":243,"address":[],"length":0,"stats":{"Line":6}},{"line":244,"address":[],"length":0,"stats":{"Line":2}},{"line":247,"address":[],"length":0,"stats":{"Line":1}},{"line":248,"address":[],"length":0,"stats":{"Line":3}},{"line":249,"address":[],"length":0,"stats":{"Line":1}},{"line":252,"address":[],"length":0,"stats":{"Line":1}},{"line":253,"address":[],"length":0,"stats":{"Line":3}},{"line":254,"address":[],"length":0,"stats":{"Line":1}},{"line":257,"address":[],"length":0,"stats":{"Line":1}},{"line":262,"address":[],"length":0,"stats":{"Line":3}},{"line":265,"address":[],"length":0,"stats":{"Line":1}},{"line":269,"address":[],"length":0,"stats":{"Line":1}},{"line":271,"address":[],"length":0,"stats":{"Line":4}},{"line":272,"address":[],"length":0,"stats":{"Line":9}},{"line":273,"address":[],"length":0,"stats":{"Line":6}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}}],"covered":93,"coverable":100},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","note_taking","mod.rs"],"content":"//! # Note-Taking Agent\n//!\n//! Trajectory distillation to Markdown documentation.\n//! Captures agent tool executions, distills learnings, and generates reusable\n//! notes.\n\nmod capture;\nmod distiller;\nmod generator;\nmod lifecycle;\nmod retrieval;\n\npub use capture::{\n    AsyncCaptureMetrics, AsyncTrajectoryCapture, SensitivePatterns, SessionTrajectoryCapture,\n    StorageBackendAdapter, TrajectoryCapture, TrajectoryConfig, TrajectoryEvent, TrajectoryFilter,\n    TrajectoryStorage, TrajectoryStorageError,\n};\npub use distiller::{\n    DistillationResult, DistillationTrigger, Distiller, DistillerConfig, ExtractedSection,\n};\npub use generator::{GeneratedNote, NoteGenerator, NoteGeneratorConfig, NoteTemplate};\npub use lifecycle::{\n    AutoTransitionResult, LifecycleConfig, LifecycleTransitionError, NoteLifecycleManager,\n    NoteStatus, NoteWithLifecycle,\n};\n\npub type NoteViewMode = crate::context_architect::ViewMode;\npub use retrieval::{\n    NoteEmbedder, NoteIndex, NoteRetriever, RetrievalConfig, RetrievalFilter, ScoredNote,\n};\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","note_taking","retrieval.rs"],"content":"use std::collections::HashMap;\n\nuse super::generator::GeneratedNote;\n\n#[derive(Debug, Clone)]\npub struct RetrievalConfig {\n    pub default_limit: usize,\n    pub relevance_threshold: f32,\n    pub recency_weight: f32,\n    pub success_weight: f32,\n    pub enable_tag_filtering: bool,\n}\n\nimpl Default for RetrievalConfig {\n    fn default() -> Self {\n        Self {\n            default_limit: 10,\n            relevance_threshold: 0.5,\n            recency_weight: 0.2,\n            success_weight: 0.1,\n            enable_tag_filtering: true,\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct RetrievalFilter {\n    pub tags: Option<Vec<String>>,\n    pub min_quality_score: Option<f32>,\n    pub created_after: Option<u64>,\n    pub created_before: Option<u64>,\n}\n\nimpl Default for RetrievalFilter {\n    fn default() -> Self {\n        Self {\n            tags: None,\n            min_quality_score: None,\n            created_after: None,\n            created_before: None,\n        }\n    }\n}\n\nimpl RetrievalFilter {\n    pub fn with_tags(mut self, tags: Vec<String>) -> Self {\n        self.tags = Some(tags);\n        self\n    }\n\n    pub fn with_min_quality(mut self, score: f32) -> Self {\n        self.min_quality_score = Some(score);\n        self\n    }\n\n    pub fn with_recency(mut self, after: u64) -> Self {\n        self.created_after = Some(after);\n        self\n    }\n\n    pub fn created_between(mut self, after: u64, before: u64) -> Self {\n        self.created_after = Some(after);\n        self.created_before = Some(before);\n        self\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct ScoredNote {\n    pub note: GeneratedNote,\n    pub relevance_score: f32,\n    pub recency_score: f32,\n    pub combined_score: f32,\n}\n\nimpl ScoredNote {\n    pub fn new(\n        note: GeneratedNote,\n        relevance_score: f32,\n        recency_score: f32,\n        config: &RetrievalConfig,\n    ) -> Self {\n        let combined_score = Self::compute_combined_score(\n            relevance_score,\n            recency_score,\n            note.quality_score,\n            config,\n        );\n\n        Self {\n            note,\n            relevance_score,\n            recency_score,\n            combined_score,\n        }\n    }\n\n    fn compute_combined_score(\n        relevance: f32,\n        recency: f32,\n        quality: f32,\n        config: &RetrievalConfig,\n    ) -> f32 {\n        let relevance_weight = 1.0 - config.recency_weight - config.success_weight;\n        relevance * relevance_weight\n            + recency * config.recency_weight\n            + quality * config.success_weight\n    }\n}\n\npub struct NoteIndex {\n    notes: HashMap<String, (GeneratedNote, Vec<f32>)>,\n    config: RetrievalConfig,\n}\n\nimpl NoteIndex {\n    pub fn new(config: RetrievalConfig) -> Self {\n        Self {\n            notes: HashMap::new(),\n            config,\n        }\n    }\n\n    pub fn add_note(&mut self, note: GeneratedNote, embedding: Vec<f32>) {\n        self.notes.insert(note.id.clone(), (note, embedding));\n    }\n\n    pub fn remove_note(&mut self, note_id: &str) -> Option<GeneratedNote> {\n        self.notes.remove(note_id).map(|(note, _)| note)\n    }\n\n    pub fn get_note(&self, note_id: &str) -> Option<&GeneratedNote> {\n        self.notes.get(note_id).map(|(note, _)| note)\n    }\n\n    pub fn note_count(&self) -> usize {\n        self.notes.len()\n    }\n\n    pub fn retrieve_relevant(\n        &self,\n        query_embedding: &[f32],\n        limit: usize,\n        filter: Option<&RetrievalFilter>,\n    ) -> Vec<ScoredNote> {\n        let now = std::time::SystemTime::now()\n            .duration_since(std::time::UNIX_EPOCH)\n            .map(|d| d.as_secs())\n            .unwrap_or(0);\n\n        let mut scored: Vec<ScoredNote> = self\n            .notes\n            .values()\n            .filter(|(note, _)| self.matches_filter(note, filter))\n            .map(|(note, embedding)| {\n                let relevance = cosine_similarity(query_embedding, embedding);\n                let recency = self.compute_recency_score(note.created_at, now);\n                ScoredNote::new(note.clone(), relevance, recency, &self.config)\n            })\n            .filter(|scored| scored.relevance_score >= self.config.relevance_threshold)\n            .collect();\n\n        scored.sort_by(|a, b| {\n            b.combined_score\n                .partial_cmp(&a.combined_score)\n                .unwrap_or(std::cmp::Ordering::Equal)\n        });\n\n        scored.truncate(limit);\n        scored\n    }\n\n    fn matches_filter(&self, note: &GeneratedNote, filter: Option<&RetrievalFilter>) -> bool {\n        let filter = match filter {\n            Some(f) => f,\n            None => return true,\n        };\n\n        if let Some(min_quality) = filter.min_quality_score {\n            if note.quality_score < min_quality {\n                return false;\n            }\n        }\n\n        if let Some(after) = filter.created_after {\n            if note.created_at < after {\n                return false;\n            }\n        }\n\n        if let Some(before) = filter.created_before {\n            if note.created_at > before {\n                return false;\n            }\n        }\n\n        if self.config.enable_tag_filtering {\n            if let Some(ref required_tags) = filter.tags {\n                if !required_tags.is_empty() {\n                    let has_matching_tag = required_tags.iter().any(|t| note.tags.contains(t));\n                    if !has_matching_tag {\n                        return false;\n                    }\n                }\n            }\n        }\n\n        true\n    }\n\n    fn compute_recency_score(&self, created_at: u64, now: u64) -> f32 {\n        if now <= created_at {\n            return 1.0;\n        }\n\n        let age_seconds = (now - created_at) as f32;\n        let one_week = 604800.0_f32;\n\n        let score = 1.0 - (age_seconds / one_week).min(1.0);\n        score.max(0.0)\n    }\n}\n\nfn cosine_similarity(a: &[f32], b: &[f32]) -> f32 {\n    if a.len() != b.len() || a.is_empty() {\n        return 0.0;\n    }\n\n    let dot: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();\n    let norm_a: f32 = a.iter().map(|x| x * x).sum::<f32>().sqrt();\n    let norm_b: f32 = b.iter().map(|x| x * x).sum::<f32>().sqrt();\n\n    if norm_a == 0.0 || norm_b == 0.0 {\n        return 0.0;\n    }\n\n    dot / (norm_a * norm_b)\n}\n\npub struct NoteRetriever<E> {\n    index: NoteIndex,\n    embedder: E,\n}\n\nimpl<E: NoteEmbedder> NoteRetriever<E> {\n    pub fn new(config: RetrievalConfig, embedder: E) -> Self {\n        Self {\n            index: NoteIndex::new(config),\n            embedder,\n        }\n    }\n\n    pub async fn add_note(&mut self, note: GeneratedNote) -> Result<(), E::Error> {\n        let text = format!(\"{}\\n{}\", note.title, note.content);\n        let embedding = self.embedder.embed(&text).await?;\n        self.index.add_note(note, embedding);\n        Ok(())\n    }\n\n    pub async fn retrieve_relevant(\n        &self,\n        query: &str,\n        limit: usize,\n    ) -> Result<Vec<ScoredNote>, E::Error> {\n        let query_embedding = self.embedder.embed(query).await?;\n        Ok(self.index.retrieve_relevant(&query_embedding, limit, None))\n    }\n\n    pub async fn retrieve_with_filter(\n        &self,\n        query: &str,\n        limit: usize,\n        filter: &RetrievalFilter,\n    ) -> Result<Vec<ScoredNote>, E::Error> {\n        let query_embedding = self.embedder.embed(query).await?;\n        Ok(self\n            .index\n            .retrieve_relevant(&query_embedding, limit, Some(filter)))\n    }\n\n    pub fn note_count(&self) -> usize {\n        self.index.note_count()\n    }\n\n    pub fn get_note(&self, note_id: &str) -> Option<&GeneratedNote> {\n        self.index.get_note(note_id)\n    }\n\n    pub fn remove_note(&mut self, note_id: &str) -> Option<GeneratedNote> {\n        self.index.remove_note(note_id)\n    }\n}\n\n#[async_trait::async_trait]\npub trait NoteEmbedder: Send + Sync {\n    type Error: std::error::Error + Send + Sync;\n\n    async fn embed(&self, text: &str) -> Result<Vec<f32>, Self::Error>;\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    fn sample_note(id: &str, title: &str, quality: f32, created_at: u64) -> GeneratedNote {\n        GeneratedNote {\n            id: id.to_string(),\n            title: title.to_string(),\n            content: format!(\"Content for {title}\"),\n            tags: vec![\"rust\".to_string(), \"async\".to_string()],\n            source_distillation_id: format!(\"dist-{id}\"),\n            created_at,\n            quality_score: quality,\n        }\n    }\n\n    fn sample_embedding() -> Vec<f32> {\n        vec![0.1, 0.2, 0.3, 0.4, 0.5]\n    }\n\n    fn query_embedding_similar() -> Vec<f32> {\n        vec![0.1, 0.2, 0.3, 0.4, 0.5]\n    }\n\n    fn query_embedding_different() -> Vec<f32> {\n        vec![-0.5, -0.4, -0.3, -0.2, -0.1]\n    }\n\n    #[test]\n    fn test_note_index_add_and_get() {\n        let mut index = NoteIndex::new(RetrievalConfig::default());\n        let note = sample_note(\"1\", \"Test Note\", 0.8, 1000);\n\n        index.add_note(note.clone(), sample_embedding());\n\n        assert_eq!(index.note_count(), 1);\n        assert!(index.get_note(\"1\").is_some());\n        assert_eq!(index.get_note(\"1\").unwrap().title, \"Test Note\");\n    }\n\n    #[test]\n    fn test_note_index_remove() {\n        let mut index = NoteIndex::new(RetrievalConfig::default());\n        let note = sample_note(\"1\", \"Test Note\", 0.8, 1000);\n        index.add_note(note, sample_embedding());\n\n        let removed = index.remove_note(\"1\");\n\n        assert!(removed.is_some());\n        assert_eq!(index.note_count(), 0);\n        assert!(index.get_note(\"1\").is_none());\n    }\n\n    #[test]\n    fn test_retrieve_relevant_returns_similar_notes() {\n        let config = RetrievalConfig {\n            relevance_threshold: 0.0,\n            ..Default::default()\n        };\n        let mut index = NoteIndex::new(config);\n\n        let note = sample_note(\"1\", \"Async error handling\", 0.8, 1000);\n        index.add_note(note, sample_embedding());\n\n        let results = index.retrieve_relevant(&query_embedding_similar(), 10, None);\n\n        assert_eq!(results.len(), 1);\n        assert!(results[0].relevance_score > 0.9);\n    }\n\n    #[test]\n    fn test_retrieve_relevant_filters_by_threshold() {\n        let config = RetrievalConfig {\n            relevance_threshold: 0.9,\n            ..Default::default()\n        };\n        let mut index = NoteIndex::new(config);\n\n        let note = sample_note(\"1\", \"Async error handling\", 0.8, 1000);\n        index.add_note(note, sample_embedding());\n\n        let results = index.retrieve_relevant(&query_embedding_different(), 10, None);\n\n        assert!(results.is_empty());\n    }\n\n    #[test]\n    fn test_retrieve_relevant_respects_limit() {\n        let config = RetrievalConfig {\n            relevance_threshold: 0.0,\n            ..Default::default()\n        };\n        let mut index = NoteIndex::new(config);\n\n        for i in 0..5 {\n            let note = sample_note(&format!(\"{i}\"), &format!(\"Note {i}\"), 0.8, 1000);\n            index.add_note(note, sample_embedding());\n        }\n\n        let results = index.retrieve_relevant(&query_embedding_similar(), 2, None);\n\n        assert_eq!(results.len(), 2);\n    }\n\n    #[test]\n    fn test_retrieve_with_quality_filter() {\n        let config = RetrievalConfig {\n            relevance_threshold: 0.0,\n            ..Default::default()\n        };\n        let mut index = NoteIndex::new(config);\n\n        index.add_note(\n            sample_note(\"1\", \"Low quality\", 0.3, 1000),\n            sample_embedding(),\n        );\n        index.add_note(\n            sample_note(\"2\", \"High quality\", 0.9, 1000),\n            sample_embedding(),\n        );\n\n        let filter = RetrievalFilter::default().with_min_quality(0.5);\n        let results = index.retrieve_relevant(&query_embedding_similar(), 10, Some(&filter));\n\n        assert_eq!(results.len(), 1);\n        assert_eq!(results[0].note.id, \"2\");\n    }\n\n    #[test]\n    fn test_retrieve_with_tag_filter() {\n        let config = RetrievalConfig {\n            relevance_threshold: 0.0,\n            enable_tag_filtering: true,\n            ..Default::default()\n        };\n        let mut index = NoteIndex::new(config);\n\n        let mut note1 = sample_note(\"1\", \"Rust note\", 0.8, 1000);\n        note1.tags = vec![\"rust\".to_string()];\n\n        let mut note2 = sample_note(\"2\", \"Python note\", 0.8, 1000);\n        note2.tags = vec![\"python\".to_string()];\n\n        index.add_note(note1, sample_embedding());\n        index.add_note(note2, sample_embedding());\n\n        let filter = RetrievalFilter::default().with_tags(vec![\"python\".to_string()]);\n        let results = index.retrieve_relevant(&query_embedding_similar(), 10, Some(&filter));\n\n        assert_eq!(results.len(), 1);\n        assert_eq!(results[0].note.id, \"2\");\n    }\n\n    #[test]\n    fn test_retrieve_with_recency_filter() {\n        let config = RetrievalConfig {\n            relevance_threshold: 0.0,\n            ..Default::default()\n        };\n        let mut index = NoteIndex::new(config);\n\n        index.add_note(sample_note(\"1\", \"Old note\", 0.8, 1000), sample_embedding());\n        index.add_note(sample_note(\"2\", \"New note\", 0.8, 5000), sample_embedding());\n\n        let filter = RetrievalFilter::default().with_recency(3000);\n        let results = index.retrieve_relevant(&query_embedding_similar(), 10, Some(&filter));\n\n        assert_eq!(results.len(), 1);\n        assert_eq!(results[0].note.id, \"2\");\n    }\n\n    #[test]\n    fn test_retrieve_with_date_range_filter() {\n        let config = RetrievalConfig {\n            relevance_threshold: 0.0,\n            ..Default::default()\n        };\n        let mut index = NoteIndex::new(config);\n\n        index.add_note(sample_note(\"1\", \"Too old\", 0.8, 1000), sample_embedding());\n        index.add_note(sample_note(\"2\", \"In range\", 0.8, 3000), sample_embedding());\n        index.add_note(sample_note(\"3\", \"Too new\", 0.8, 5000), sample_embedding());\n\n        let filter = RetrievalFilter::default().created_between(2000, 4000);\n        let results = index.retrieve_relevant(&query_embedding_similar(), 10, Some(&filter));\n\n        assert_eq!(results.len(), 1);\n        assert_eq!(results[0].note.id, \"2\");\n    }\n\n    #[test]\n    fn test_scoring_includes_recency() {\n        let config = RetrievalConfig {\n            relevance_threshold: 0.0,\n            recency_weight: 0.3,\n            success_weight: 0.1,\n            ..Default::default()\n        };\n        let mut index = NoteIndex::new(config);\n\n        let now = std::time::SystemTime::now()\n            .duration_since(std::time::UNIX_EPOCH)\n            .unwrap()\n            .as_secs();\n\n        index.add_note(\n            sample_note(\"1\", \"Old note\", 0.8, now - 604800),\n            sample_embedding(),\n        );\n        index.add_note(sample_note(\"2\", \"New note\", 0.8, now), sample_embedding());\n\n        let results = index.retrieve_relevant(&query_embedding_similar(), 10, None);\n\n        assert_eq!(results.len(), 2);\n        assert!(results[0].recency_score > results[1].recency_score);\n        assert_eq!(results[0].note.id, \"2\");\n    }\n\n    #[test]\n    fn test_scoring_includes_quality() {\n        let config = RetrievalConfig {\n            relevance_threshold: 0.0,\n            recency_weight: 0.0,\n            success_weight: 0.5,\n            ..Default::default()\n        };\n        let mut index = NoteIndex::new(config);\n\n        let now = std::time::SystemTime::now()\n            .duration_since(std::time::UNIX_EPOCH)\n            .unwrap()\n            .as_secs();\n\n        index.add_note(\n            sample_note(\"1\", \"Low quality\", 0.3, now),\n            sample_embedding(),\n        );\n        index.add_note(\n            sample_note(\"2\", \"High quality\", 0.9, now),\n            sample_embedding(),\n        );\n\n        let results = index.retrieve_relevant(&query_embedding_similar(), 10, None);\n\n        assert_eq!(results.len(), 2);\n        assert_eq!(results[0].note.id, \"2\");\n    }\n\n    #[test]\n    fn test_cosine_similarity_identical() {\n        let a = vec![1.0, 0.0, 0.0];\n        let b = vec![1.0, 0.0, 0.0];\n\n        let sim = cosine_similarity(&a, &b);\n\n        assert!((sim - 1.0).abs() < 0.001);\n    }\n\n    #[test]\n    fn test_cosine_similarity_orthogonal() {\n        let a = vec![1.0, 0.0, 0.0];\n        let b = vec![0.0, 1.0, 0.0];\n\n        let sim = cosine_similarity(&a, &b);\n\n        assert!(sim.abs() < 0.001);\n    }\n\n    #[test]\n    fn test_cosine_similarity_opposite() {\n        let a = vec![1.0, 0.0, 0.0];\n        let b = vec![-1.0, 0.0, 0.0];\n\n        let sim = cosine_similarity(&a, &b);\n\n        assert!((sim - (-1.0)).abs() < 0.001);\n    }\n\n    #[test]\n    fn test_cosine_similarity_different_lengths() {\n        let a = vec![1.0, 0.0];\n        let b = vec![1.0, 0.0, 0.0];\n\n        let sim = cosine_similarity(&a, &b);\n\n        assert_eq!(sim, 0.0);\n    }\n\n    #[test]\n    fn test_cosine_similarity_empty() {\n        let a: Vec<f32> = vec![];\n        let b: Vec<f32> = vec![];\n\n        let sim = cosine_similarity(&a, &b);\n\n        assert_eq!(sim, 0.0);\n    }\n\n    #[test]\n    fn test_scored_note_combined_score() {\n        let config = RetrievalConfig {\n            recency_weight: 0.2,\n            success_weight: 0.1,\n            ..Default::default()\n        };\n        let note = sample_note(\"1\", \"Test\", 0.8, 1000);\n\n        let scored = ScoredNote::new(note, 0.9, 0.5, &config);\n\n        let expected = 0.9 * 0.7 + 0.5 * 0.2 + 0.8 * 0.1;\n        assert!((scored.combined_score - expected).abs() < 0.001);\n    }\n\n    #[test]\n    fn test_retrieval_filter_builder() {\n        let filter = RetrievalFilter::default()\n            .with_tags(vec![\"rust\".to_string()])\n            .with_min_quality(0.7)\n            .with_recency(1000);\n\n        assert_eq!(filter.tags, Some(vec![\"rust\".to_string()]));\n        assert_eq!(filter.min_quality_score, Some(0.7));\n        assert_eq!(filter.created_after, Some(1000));\n    }\n\n    struct MockEmbedder;\n\n    #[derive(Debug)]\n    struct MockError;\n\n    impl std::fmt::Display for MockError {\n        fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n            write!(f, \"MockError\")\n        }\n    }\n\n    impl std::error::Error for MockError {}\n\n    #[async_trait::async_trait]\n    impl NoteEmbedder for MockEmbedder {\n        type Error = MockError;\n\n        async fn embed(&self, _text: &str) -> Result<Vec<f32>, Self::Error> {\n            Ok(vec![0.1, 0.2, 0.3, 0.4, 0.5])\n        }\n    }\n\n    #[tokio::test]\n    async fn test_note_retriever_add_and_retrieve() {\n        let config = RetrievalConfig {\n            relevance_threshold: 0.0,\n            ..Default::default()\n        };\n        let mut retriever = NoteRetriever::new(config, MockEmbedder);\n\n        let note = sample_note(\"1\", \"Async error handling\", 0.8, 1000);\n        retriever.add_note(note).await.unwrap();\n\n        assert_eq!(retriever.note_count(), 1);\n\n        let results = retriever\n            .retrieve_relevant(\"async errors\", 10)\n            .await\n            .unwrap();\n        assert_eq!(results.len(), 1);\n    }\n\n    #[tokio::test]\n    async fn test_note_retriever_with_filter() {\n        let config = RetrievalConfig {\n            relevance_threshold: 0.0,\n            ..Default::default()\n        };\n        let mut retriever = NoteRetriever::new(config, MockEmbedder);\n\n        let note = sample_note(\"1\", \"Test\", 0.9, 1000);\n        retriever.add_note(note).await.unwrap();\n\n        let filter = RetrievalFilter::default().with_min_quality(0.8);\n        let results = retriever\n            .retrieve_with_filter(\"test\", 10, &filter)\n            .await\n            .unwrap();\n\n        assert_eq!(results.len(), 1);\n    }\n\n    #[tokio::test]\n    async fn test_note_retriever_get_and_remove() {\n        let config = RetrievalConfig::default();\n        let mut retriever = NoteRetriever::new(config, MockEmbedder);\n\n        let note = sample_note(\"1\", \"Test\", 0.8, 1000);\n        retriever.add_note(note).await.unwrap();\n\n        assert!(retriever.get_note(\"1\").is_some());\n\n        let removed = retriever.remove_note(\"1\");\n        assert!(removed.is_some());\n        assert!(retriever.get_note(\"1\").is_none());\n    }\n}\n","traces":[{"line":15,"address":[],"length":0,"stats":{"Line":15}},{"line":35,"address":[],"length":0,"stats":{"Line":6}},{"line":46,"address":[],"length":0,"stats":{"Line":2}},{"line":47,"address":[],"length":0,"stats":{"Line":4}},{"line":48,"address":[],"length":0,"stats":{"Line":2}},{"line":51,"address":[],"length":0,"stats":{"Line":3}},{"line":52,"address":[],"length":0,"stats":{"Line":3}},{"line":53,"address":[],"length":0,"stats":{"Line":3}},{"line":56,"address":[],"length":0,"stats":{"Line":2}},{"line":57,"address":[],"length":0,"stats":{"Line":2}},{"line":58,"address":[],"length":0,"stats":{"Line":2}},{"line":61,"address":[],"length":0,"stats":{"Line":1}},{"line":62,"address":[],"length":0,"stats":{"Line":1}},{"line":63,"address":[],"length":0,"stats":{"Line":1}},{"line":64,"address":[],"length":0,"stats":{"Line":1}},{"line":77,"address":[],"length":0,"stats":{"Line":18}},{"line":84,"address":[],"length":0,"stats":{"Line":18}},{"line":85,"address":[],"length":0,"stats":{"Line":18}},{"line":86,"address":[],"length":0,"stats":{"Line":18}},{"line":87,"address":[],"length":0,"stats":{"Line":18}},{"line":98,"address":[],"length":0,"stats":{"Line":18}},{"line":104,"address":[],"length":0,"stats":{"Line":36}},{"line":105,"address":[],"length":0,"stats":{"Line":54}},{"line":106,"address":[],"length":0,"stats":{"Line":36}},{"line":107,"address":[],"length":0,"stats":{"Line":18}},{"line":117,"address":[],"length":0,"stats":{"Line":14}},{"line":119,"address":[],"length":0,"stats":{"Line":14}},{"line":124,"address":[],"length":0,"stats":{"Line":25}},{"line":125,"address":[],"length":0,"stats":{"Line":125}},{"line":128,"address":[],"length":0,"stats":{"Line":2}},{"line":129,"address":[],"length":0,"stats":{"Line":8}},{"line":132,"address":[],"length":0,"stats":{"Line":5}},{"line":133,"address":[],"length":0,"stats":{"Line":20}},{"line":136,"address":[],"length":0,"stats":{"Line":3}},{"line":137,"address":[],"length":0,"stats":{"Line":6}},{"line":140,"address":[],"length":0,"stats":{"Line":11}},{"line":146,"address":[],"length":0,"stats":{"Line":22}},{"line":147,"address":[],"length":0,"stats":{"Line":11}},{"line":148,"address":[],"length":0,"stats":{"Line":33}},{"line":151,"address":[],"length":0,"stats":{"Line":33}},{"line":152,"address":[],"length":0,"stats":{"Line":11}},{"line":154,"address":[],"length":0,"stats":{"Line":99}},{"line":155,"address":[],"length":0,"stats":{"Line":28}},{"line":156,"address":[],"length":0,"stats":{"Line":68}},{"line":157,"address":[],"length":0,"stats":{"Line":85}},{"line":158,"address":[],"length":0,"stats":{"Line":102}},{"line":160,"address":[],"length":0,"stats":{"Line":45}},{"line":163,"address":[],"length":0,"stats":{"Line":28}},{"line":164,"address":[],"length":0,"stats":{"Line":6}},{"line":165,"address":[],"length":0,"stats":{"Line":12}},{"line":166,"address":[],"length":0,"stats":{"Line":12}},{"line":169,"address":[],"length":0,"stats":{"Line":33}},{"line":170,"address":[],"length":0,"stats":{"Line":11}},{"line":173,"address":[],"length":0,"stats":{"Line":22}},{"line":174,"address":[],"length":0,"stats":{"Line":32}},{"line":175,"address":[],"length":0,"stats":{"Line":20}},{"line":176,"address":[],"length":0,"stats":{"Line":12}},{"line":179,"address":[],"length":0,"stats":{"Line":13}},{"line":180,"address":[],"length":0,"stats":{"Line":3}},{"line":181,"address":[],"length":0,"stats":{"Line":1}},{"line":185,"address":[],"length":0,"stats":{"Line":14}},{"line":186,"address":[],"length":0,"stats":{"Line":5}},{"line":187,"address":[],"length":0,"stats":{"Line":2}},{"line":191,"address":[],"length":0,"stats":{"Line":9}},{"line":192,"address":[],"length":0,"stats":{"Line":2}},{"line":193,"address":[],"length":0,"stats":{"Line":1}},{"line":197,"address":[],"length":0,"stats":{"Line":6}},{"line":198,"address":[],"length":0,"stats":{"Line":8}},{"line":199,"address":[],"length":0,"stats":{"Line":2}},{"line":200,"address":[],"length":0,"stats":{"Line":12}},{"line":201,"address":[],"length":0,"stats":{"Line":2}},{"line":202,"address":[],"length":0,"stats":{"Line":1}},{"line":208,"address":[],"length":0,"stats":{"Line":5}},{"line":211,"address":[],"length":0,"stats":{"Line":17}},{"line":212,"address":[],"length":0,"stats":{"Line":17}},{"line":213,"address":[],"length":0,"stats":{"Line":3}},{"line":216,"address":[],"length":0,"stats":{"Line":28}},{"line":217,"address":[],"length":0,"stats":{"Line":28}},{"line":219,"address":[],"length":0,"stats":{"Line":28}},{"line":220,"address":[],"length":0,"stats":{"Line":28}},{"line":224,"address":[],"length":0,"stats":{"Line":22}},{"line":225,"address":[],"length":0,"stats":{"Line":108}},{"line":226,"address":[],"length":0,"stats":{"Line":2}},{"line":229,"address":[],"length":0,"stats":{"Line":368}},{"line":230,"address":[],"length":0,"stats":{"Line":328}},{"line":231,"address":[],"length":0,"stats":{"Line":328}},{"line":233,"address":[],"length":0,"stats":{"Line":40}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":40}},{"line":246,"address":[],"length":0,"stats":{"Line":3}},{"line":248,"address":[],"length":0,"stats":{"Line":6}},{"line":253,"address":[],"length":0,"stats":{"Line":6}},{"line":254,"address":[],"length":0,"stats":{"Line":9}},{"line":255,"address":[],"length":0,"stats":{"Line":12}},{"line":256,"address":[],"length":0,"stats":{"Line":12}},{"line":257,"address":[],"length":0,"stats":{"Line":3}},{"line":260,"address":[],"length":0,"stats":{"Line":1}},{"line":265,"address":[],"length":0,"stats":{"Line":4}},{"line":266,"address":[],"length":0,"stats":{"Line":4}},{"line":269,"address":[],"length":0,"stats":{"Line":1}},{"line":275,"address":[],"length":0,"stats":{"Line":4}},{"line":276,"address":[],"length":0,"stats":{"Line":2}},{"line":277,"address":[],"length":0,"stats":{"Line":2}},{"line":278,"address":[],"length":0,"stats":{"Line":3}},{"line":281,"address":[],"length":0,"stats":{"Line":1}},{"line":282,"address":[],"length":0,"stats":{"Line":2}},{"line":285,"address":[],"length":0,"stats":{"Line":2}},{"line":286,"address":[],"length":0,"stats":{"Line":6}},{"line":289,"address":[],"length":0,"stats":{"Line":1}},{"line":290,"address":[],"length":0,"stats":{"Line":3}}],"covered":109,"coverable":110},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","opencode.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","pointer.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","pool.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","postgres.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","procedural.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","providers.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","qdrant.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","redis.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","repository.rs"],"content":"use async_trait::async_trait;\nuse git2::{Repository, Signature};\nuse mk_core::traits::KnowledgeRepository;\nuse mk_core::types::{KnowledgeEntry, KnowledgeLayer, KnowledgeType};\nuse std::path::PathBuf;\nuse thiserror::Error;\nuse walkdir::WalkDir;\n\n#[derive(Error, Debug)]\npub enum RepositoryError {\n    #[error(\"Git error: {0}\")]\n    Git(#[from] git2::Error),\n    #[error(\"IO error: {0}\")]\n    Io(#[from] std::io::Error),\n    #[error(\"Invalid path: {0}\")]\n    InvalidPath(String),\n    #[error(\"Serialization error: {0}\")]\n    Serialization(#[from] serde_json::Error),\n}\n\npub struct GitRepository {\n    root_path: PathBuf,\n}\n\nimpl GitRepository {\n    pub fn new(root_path: impl Into<PathBuf>) -> Result<Self, RepositoryError> {\n        let root_path = root_path.into();\n        if !root_path.exists() {\n            std::fs::create_dir_all(&root_path)?;\n        }\n\n        if Repository::open(&root_path).is_err() {\n            Repository::init(&root_path)?;\n        }\n\n        Ok(Self { root_path })\n    }\n\n    fn resolve_path(\n        &self,\n        ctx: &mk_core::types::TenantContext,\n        layer: KnowledgeLayer,\n        path: &str,\n    ) -> PathBuf {\n        let layer_dir = match layer {\n            KnowledgeLayer::Company => \"company\",\n            KnowledgeLayer::Org => \"org\",\n            KnowledgeLayer::Team => \"team\",\n            KnowledgeLayer::Project => \"project\",\n        };\n        self.root_path\n            .join(ctx.tenant_id.as_str())\n            .join(layer_dir)\n            .join(path)\n    }\n\n    pub fn commit(&self, message: &str) -> Result<String, RepositoryError> {\n        let span = tracing::info_span!(\"knowledge_commit\", message = %message);\n        let _enter = span.enter();\n\n        let repo = Repository::open(&self.root_path)?;\n        let mut index = repo.index()?;\n        index.add_all([\"*\"].iter(), git2::IndexAddOption::DEFAULT, None)?;\n        index.write()?;\n\n        let tree_id = index.write_tree()?;\n        let tree = repo.find_tree(tree_id)?;\n\n        let sig = repo\n            .signature()\n            .or_else(|_| Signature::now(\"Aeterna\", \"system@aeterna.ai\"))?;\n\n        let parent_commit = match repo.head() {\n            Ok(head) => Some(head.peel_to_commit()?),\n            Err(_) => None,\n        };\n\n        let parents = match &parent_commit {\n            Some(c) => vec![c],\n            None => vec![],\n        };\n\n        let commit_id = repo.commit(Some(\"HEAD\"), &sig, &sig, message, &tree, &parents)?;\n\n        Ok(commit_id.to_string())\n    }\n\n    pub fn get_head_commit_sync(&self) -> Result<Option<String>, RepositoryError> {\n        let repo = Repository::open(&self.root_path)?;\n        match repo.head() {\n            Ok(head) => Ok(Some(head.peel_to_commit()?.id().to_string())),\n            Err(_) => Ok(None),\n        }\n    }\n\n    pub fn root_path(&self) -> &std::path::Path {\n        &self.root_path\n    }\n\n    pub async fn get_by_path(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        path: &str,\n    ) -> Result<Option<KnowledgeEntry>, RepositoryError> {\n        for layer in [\n            KnowledgeLayer::Company,\n            KnowledgeLayer::Org,\n            KnowledgeLayer::Team,\n            KnowledgeLayer::Project,\n        ] {\n            if let Some(entry) = self.get(ctx.clone(), layer, path).await? {\n                return Ok(Some(entry));\n            }\n        }\n        Ok(None)\n    }\n}\n\n#[async_trait]\nimpl KnowledgeRepository for GitRepository {\n    type Error = RepositoryError;\n\n    async fn get_head_commit(\n        &self,\n        _ctx: mk_core::types::TenantContext,\n    ) -> Result<Option<String>, Self::Error> {\n        self.get_head_commit_sync()\n    }\n\n    async fn get_affected_items(\n        &self,\n        _ctx: mk_core::types::TenantContext,\n        since_commit: &str,\n    ) -> Result<Vec<(KnowledgeLayer, String)>, Self::Error> {\n        let repo = Repository::open(&self.root_path)?;\n        let from_obj = repo.revparse_single(since_commit)?;\n        let from_commit = from_obj.peel_to_commit()?;\n        let from_tree = from_commit.tree()?;\n\n        let head = repo.head()?.peel_to_commit()?;\n        let head_tree = head.tree()?;\n\n        let diff = repo.diff_tree_to_tree(Some(&from_tree), Some(&head_tree), None)?;\n        let mut affected = Vec::new();\n\n        diff.foreach(\n            &mut |delta, _| {\n                if let Some(path) = delta.new_file().path().and_then(|p| p.to_str()) {\n                    let parts: Vec<&str> = path.split('/').collect();\n                    if parts.len() >= 2 {\n                        let layer = match parts[0] {\n                            \"company\" => KnowledgeLayer::Company,\n                            \"org\" => KnowledgeLayer::Org,\n                            \"team\" => KnowledgeLayer::Team,\n                            \"project\" => KnowledgeLayer::Project,\n                            _ => return true,\n                        };\n                        let inner_path = parts[1..].join(\"/\");\n                        affected.push((layer, inner_path));\n                    }\n                }\n                true\n            },\n            None,\n            None,\n            None,\n        )?;\n\n        Ok(affected)\n    }\n\n    async fn get(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        layer: KnowledgeLayer,\n        path: &str,\n    ) -> Result<Option<KnowledgeEntry>, Self::Error> {\n        let full_path = self.resolve_path(&ctx, layer, path);\n        if !full_path.exists() {\n            return Ok(None);\n        }\n\n        let metadata_path = full_path.with_extension(\"metadata.json\");\n\n        let content = tokio::fs::read_to_string(&full_path).await?;\n\n        let commit_hash = {\n            let repo = Repository::open(&self.root_path)?;\n            let mut revwalk = repo.revwalk()?;\n            revwalk.push_head().ok();\n            revwalk.next().transpose()?.map(|id| id.to_string())\n        };\n\n        let (kind, status, summaries, metadata, author, updated_at) = if metadata_path.exists() {\n            let meta_content = tokio::fs::read_to_string(&metadata_path).await?;\n            let meta: serde_json::Value = serde_json::from_str(&meta_content)?;\n            (\n                serde_json::from_value(meta[\"kind\"].clone()).unwrap_or(KnowledgeType::Spec),\n                serde_json::from_value(meta[\"status\"].clone())\n                    .unwrap_or(mk_core::types::KnowledgeStatus::Accepted),\n                serde_json::from_value(meta[\"summaries\"].clone()).unwrap_or_default(),\n                serde_json::from_value(meta[\"metadata\"].clone()).unwrap_or_default(),\n                serde_json::from_value(meta[\"author\"].clone()).unwrap_or_default(),\n                meta[\"updated_at\"]\n                    .as_i64()\n                    .unwrap_or_else(|| chrono::Utc::now().timestamp()),\n            )\n        } else {\n            (\n                KnowledgeType::Spec,\n                mk_core::types::KnowledgeStatus::Accepted,\n                std::collections::HashMap::new(),\n                std::collections::HashMap::new(),\n                None,\n                chrono::Utc::now().timestamp(),\n            )\n        };\n\n        Ok(Some(KnowledgeEntry {\n            path: path.to_string(),\n            content,\n            layer,\n            kind,\n            status,\n            summaries,\n            metadata,\n            commit_hash,\n            author,\n            updated_at,\n        }))\n    }\n\n    async fn store(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        entry: KnowledgeEntry,\n        message: &str,\n    ) -> Result<String, Self::Error> {\n        let full_path = self.resolve_path(&ctx, entry.layer, &entry.path);\n        let metadata_path = full_path.with_extension(\"metadata.json\");\n\n        if let Some(parent) = full_path.parent() {\n            tokio::fs::create_dir_all(parent).await?;\n        }\n\n        tokio::fs::write(&full_path, entry.content).await?;\n\n        let meta = serde_json::json!({\n            \"kind\": entry.kind,\n            \"status\": entry.status,\n            \"summaries\": entry.summaries,\n            \"metadata\": entry.metadata,\n            \"author\": entry.author,\n            \"updated_at\": entry.updated_at,\n        });\n        tokio::fs::write(&metadata_path, serde_json::to_string(&meta)?).await?;\n\n        self.commit(message)\n    }\n\n    async fn list(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        layer: KnowledgeLayer,\n        prefix: &str,\n    ) -> Result<Vec<KnowledgeEntry>, Self::Error> {\n        let tenant_path = self.root_path.join(ctx.tenant_id.as_str());\n        let layer_path = match layer {\n            KnowledgeLayer::Company => tenant_path.join(\"company\"),\n            KnowledgeLayer::Org => tenant_path.join(\"org\"),\n            KnowledgeLayer::Team => tenant_path.join(\"team\"),\n            KnowledgeLayer::Project => tenant_path.join(\"project\"),\n        };\n\n        if !layer_path.exists() {\n            return Ok(vec![]);\n        }\n\n        let mut entries = Vec::new();\n        for entry in WalkDir::new(&layer_path)\n            .into_iter()\n            .filter_map(|e| e.ok())\n            .filter(|e| {\n                e.file_type().is_file() && !e.path().to_string_lossy().ends_with(\".metadata.json\")\n            })\n        {\n            let path = entry.path();\n            let relative_path = path\n                .strip_prefix(&layer_path)\n                .map_err(|_| RepositoryError::InvalidPath(path.to_string_lossy().into_owned()))?;\n\n            if relative_path.to_string_lossy().starts_with(prefix) {\n                if let Some(ke) = self\n                    .get(ctx.clone(), layer, &relative_path.to_string_lossy())\n                    .await?\n                {\n                    entries.push(ke);\n                }\n            }\n        }\n\n        Ok(entries)\n    }\n\n    async fn delete(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        layer: KnowledgeLayer,\n        path: &str,\n        message: &str,\n    ) -> Result<String, Self::Error> {\n        let full_path = self.resolve_path(&ctx, layer, path);\n        let metadata_path = full_path.with_extension(\"metadata.json\");\n\n        if full_path.exists() {\n            tokio::fs::remove_file(full_path).await?;\n            if metadata_path.exists() {\n                tokio::fs::remove_file(metadata_path).await?;\n            }\n            self.commit(message)\n        } else {\n            Ok(String::new())\n        }\n    }\n\n    async fn search(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        query: &str,\n        layers: Vec<KnowledgeLayer>,\n        limit: usize,\n    ) -> Result<Vec<KnowledgeEntry>, Self::Error> {\n        let mut results = Vec::new();\n        for layer in layers {\n            let entries = self.list(ctx.clone(), layer, \"\").await?;\n            for entry in entries {\n                if entry.content.contains(query) || entry.path.contains(query) {\n                    results.push(entry);\n                }\n                if results.len() >= limit {\n                    return Ok(results);\n                }\n            }\n        }\n        Ok(results)\n    }\n\n    fn root_path(&self) -> Option<std::path::PathBuf> {\n        Some(self.root_path.clone())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use tempfile::tempdir;\n\n    #[tokio::test]\n    async fn test_git_repository_lifecycle() -> Result<(), Box<dyn std::error::Error>> {\n        let dir = tempdir()?;\n        let repo = GitRepository::new(dir.path())?;\n        let tenant_id = mk_core::types::TenantId::new(\"c1\".into()).unwrap();\n        let user_id = mk_core::types::UserId::new(\"u1\".into()).unwrap();\n        let ctx = mk_core::types::TenantContext::new(tenant_id, user_id);\n\n        let entry = KnowledgeEntry {\n            path: \"test.md\".to_string(),\n            content: \"hello world\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: mk_core::types::KnowledgeStatus::Draft,\n            summaries: std::collections::HashMap::new(),\n            metadata: std::collections::HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: chrono::Utc::now().timestamp(),\n        };\n\n        repo.store(ctx.clone(), entry.clone(), \"initial commit\")\n            .await?;\n\n        let retrieved = repo\n            .get(ctx.clone(), KnowledgeLayer::Project, \"test.md\")\n            .await?;\n        assert!(retrieved.is_some());\n        let retrieved = retrieved.unwrap();\n        assert_eq!(retrieved.content, \"hello world\");\n        assert_eq!(retrieved.status, mk_core::types::KnowledgeStatus::Draft);\n\n        let list = repo.list(ctx.clone(), KnowledgeLayer::Project, \"\").await?;\n        assert_eq!(list.len(), 1);\n\n        repo.delete(\n            ctx.clone(),\n            KnowledgeLayer::Project,\n            \"test.md\",\n            \"delete file\",\n        )\n        .await?;\n        let after_delete = repo.get(ctx, KnowledgeLayer::Project, \"test.md\").await?;\n        assert!(after_delete.is_none());\n\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_git_repository_isolation() -> Result<(), Box<dyn std::error::Error>> {\n        let dir = tempdir()?;\n        let repo = GitRepository::new(dir.path())?;\n\n        let tenant_a = mk_core::types::TenantId::new(\"tenant_a\".into()).unwrap();\n        let user_a = mk_core::types::UserId::new(\"user_a\".into()).unwrap();\n        let ctx_a = mk_core::types::TenantContext::new(tenant_a, user_a);\n\n        let tenant_b = mk_core::types::TenantId::new(\"tenant_b\".into()).unwrap();\n        let user_b = mk_core::types::UserId::new(\"user_b\".into()).unwrap();\n        let ctx_b = mk_core::types::TenantContext::new(tenant_b, user_b);\n\n        let entry = KnowledgeEntry {\n            path: \"secret.md\".to_string(),\n            content: \"tenant a secret\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: mk_core::types::KnowledgeStatus::Accepted,\n            summaries: std::collections::HashMap::new(),\n            metadata: std::collections::HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: chrono::Utc::now().timestamp(),\n        };\n\n        repo.store(ctx_a.clone(), entry, \"tenant a commit\").await?;\n\n        let retrieved_b = repo\n            .get(ctx_b.clone(), KnowledgeLayer::Project, \"secret.md\")\n            .await?;\n        assert!(\n            retrieved_b.is_none(),\n            \"Tenant B should not see Tenant A data\"\n        );\n\n        let retrieved_a = repo\n            .get(ctx_a.clone(), KnowledgeLayer::Project, \"secret.md\")\n            .await?;\n        assert!(retrieved_a.is_some());\n        assert_eq!(retrieved_a.unwrap().content, \"tenant a secret\");\n\n        let list_b = repo.list(ctx_b, KnowledgeLayer::Project, \"\").await?;\n        assert!(list_b.is_empty(), \"Tenant B list should be empty\");\n\n        let list_a = repo.list(ctx_a, KnowledgeLayer::Project, \"\").await?;\n        assert_eq!(list_a.len(), 1, \"Tenant A should see its entry\");\n\n        Ok(())\n    }\n}\n","traces":[{"line":26,"address":[],"length":0,"stats":{"Line":10}},{"line":27,"address":[],"length":0,"stats":{"Line":30}},{"line":28,"address":[],"length":0,"stats":{"Line":10}},{"line":29,"address":[],"length":0,"stats":{"Line":2}},{"line":32,"address":[],"length":0,"stats":{"Line":20}},{"line":33,"address":[],"length":0,"stats":{"Line":20}},{"line":36,"address":[],"length":0,"stats":{"Line":10}},{"line":39,"address":[],"length":0,"stats":{"Line":41}},{"line":45,"address":[],"length":0,"stats":{"Line":82}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":48,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":41}},{"line":51,"address":[],"length":0,"stats":{"Line":164}},{"line":52,"address":[],"length":0,"stats":{"Line":164}},{"line":53,"address":[],"length":0,"stats":{"Line":82}},{"line":54,"address":[],"length":0,"stats":{"Line":41}},{"line":57,"address":[],"length":0,"stats":{"Line":14}},{"line":58,"address":[],"length":0,"stats":{"Line":28}},{"line":59,"address":[],"length":0,"stats":{"Line":42}},{"line":61,"address":[],"length":0,"stats":{"Line":42}},{"line":62,"address":[],"length":0,"stats":{"Line":42}},{"line":63,"address":[],"length":0,"stats":{"Line":70}},{"line":64,"address":[],"length":0,"stats":{"Line":28}},{"line":66,"address":[],"length":0,"stats":{"Line":42}},{"line":67,"address":[],"length":0,"stats":{"Line":56}},{"line":69,"address":[],"length":0,"stats":{"Line":28}},{"line":71,"address":[],"length":0,"stats":{"Line":14}},{"line":73,"address":[],"length":0,"stats":{"Line":28}},{"line":74,"address":[],"length":0,"stats":{"Line":15}},{"line":75,"address":[],"length":0,"stats":{"Line":9}},{"line":78,"address":[],"length":0,"stats":{"Line":28}},{"line":79,"address":[],"length":0,"stats":{"Line":15}},{"line":80,"address":[],"length":0,"stats":{"Line":9}},{"line":83,"address":[],"length":0,"stats":{"Line":126}},{"line":85,"address":[],"length":0,"stats":{"Line":14}},{"line":88,"address":[],"length":0,"stats":{"Line":8}},{"line":89,"address":[],"length":0,"stats":{"Line":24}},{"line":90,"address":[],"length":0,"stats":{"Line":8}},{"line":91,"address":[],"length":0,"stats":{"Line":40}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":1}},{"line":148,"address":[],"length":0,"stats":{"Line":6}},{"line":149,"address":[],"length":0,"stats":{"Line":5}},{"line":150,"address":[],"length":0,"stats":{"Line":1}},{"line":151,"address":[],"length":0,"stats":{"Line":1}},{"line":152,"address":[],"length":0,"stats":{"Line":1}},{"line":153,"address":[],"length":0,"stats":{"Line":1}},{"line":154,"address":[],"length":0,"stats":{"Line":1}},{"line":155,"address":[],"length":0,"stats":{"Line":1}},{"line":156,"address":[],"length":0,"stats":{"Line":1}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":50}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":58}},{"line":283,"address":[],"length":0,"stats":{"Line":29}},{"line":284,"address":[],"length":0,"stats":{"Line":76}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":0}}],"covered":51,"coverable":73},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","scheduler.rs"],"content":"use crate::governance::GovernanceEngine;\nuse config::config::{DeploymentConfig, JobConfig};\nuse mk_core::traits::KnowledgeRepository;\nuse mk_core::types::{DriftResult, EventStatus, KnowledgeLayer, TenantContext, UnitType, UserId};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse std::time::Duration;\nuse storage::JobSkipReason;\nuse storage::redis::RedisStorage;\nuse tokio::time;\n\npub struct GovernanceScheduler {\n    pub engine: Arc<GovernanceEngine>,\n    pub repository: Arc<dyn KnowledgeRepository<Error = crate::repository::RepositoryError>>,\n    pub deployment_config: DeploymentConfig,\n    pub quick_scan_interval: Duration,\n    pub semantic_scan_interval: Duration,\n    pub report_interval: Duration,\n    pub dlq_processing_interval: Duration,\n    pub redis: Option<Arc<RedisStorage>>,\n    pub job_config: JobConfig,\n}\n\nimpl GovernanceScheduler {\n    pub fn new(\n        engine: Arc<GovernanceEngine>,\n        repository: Arc<dyn KnowledgeRepository<Error = crate::repository::RepositoryError>>,\n        deployment_config: DeploymentConfig,\n        quick_scan_interval: Duration,\n        semantic_scan_interval: Duration,\n        report_interval: Duration,\n    ) -> Self {\n        Self {\n            engine,\n            repository,\n            deployment_config,\n            quick_scan_interval,\n            semantic_scan_interval,\n            report_interval,\n            dlq_processing_interval: Duration::from_secs(300),\n            redis: None,\n            job_config: JobConfig::default(),\n        }\n    }\n\n    pub fn with_dlq_interval(mut self, interval: Duration) -> Self {\n        self.dlq_processing_interval = interval;\n        self\n    }\n\n    pub fn with_redis(mut self, redis: Arc<RedisStorage>) -> Self {\n        self.redis = Some(redis);\n        self\n    }\n\n    pub fn with_job_config(mut self, config: JobConfig) -> Self {\n        self.job_config = config;\n        self\n    }\n\n    pub async fn start(&self) {\n        if self.deployment_config.mode == \"remote\" {\n            tracing::info!(\"Governance scheduler disabled in Remote mode\");\n            return;\n        }\n\n        let mut quick_interval = time::interval(self.quick_scan_interval);\n        let mut semantic_interval = time::interval(self.semantic_scan_interval);\n        let mut report_interval = time::interval(self.report_interval);\n        let mut dlq_interval = time::interval(self.dlq_processing_interval);\n\n        loop {\n            tokio::select! {\n                _ = quick_interval.tick() => {\n                    let _ = self.run_job(\"quick_drift_scan\", \"all\", self.run_batch_drift_scan()).await;\n                }\n                _ = semantic_interval.tick() => {\n                    if self.deployment_config.mode != \"hybrid\" {\n                        let _ = self.run_job(\"semantic_analysis\", \"all\", self.run_semantic_analysis_job()).await;\n                    } else {\n                        tracing::debug!(\"Skipping local semantic analysis in Hybrid mode (relying on remote)\");\n                    }\n                }\n                _ = report_interval.tick() => {\n                    if self.deployment_config.mode == \"local\" {\n                        let _ = self.run_job(\"weekly_report\", \"all\", self.run_weekly_report_job()).await;\n                    }\n                }\n                _ = dlq_interval.tick() => {\n                    let _ = self.run_job(\"dlq_processing\", \"all\", self.run_dlq_processing_job()).await;\n                }\n            }\n        }\n    }\n\n    pub async fn run_job<F>(&self, name: &str, tenant_id: &str, job_future: F) -> anyhow::Result<()>\n    where\n        F: std::future::Future<Output = anyhow::Result<()>>,\n    {\n        if name.contains(\"TRIGGER_FAILURE\") {\n            return Err(anyhow::anyhow!(\"TRIGGER_FAILURE: Forced job failure\"));\n        }\n\n        if let Some(redis) = &self.redis {\n            if let Err(skip_reason) = self.check_job_can_run(redis, name).await {\n                tracing::info!(\n                    job_name = name,\n                    tenant_id = tenant_id,\n                    reason = %skip_reason,\n                    \"Job skipped\"\n                );\n                return Ok(());\n            }\n\n            let lock_key = self.job_config.lock_key(name);\n            match redis\n                .acquire_lock(&lock_key, self.job_config.lock_ttl_seconds)\n                .await\n            {\n                Ok(Some(lock_result)) => {\n                    let result = self\n                        .execute_job_with_lock(\n                            redis,\n                            name,\n                            tenant_id,\n                            &lock_result.lock_token,\n                            &lock_key,\n                            job_future,\n                        )\n                        .await;\n\n                    if let Err(e) = redis.release_lock(&lock_key, &lock_result.lock_token).await {\n                        tracing::warn!(\n                            job_name = name,\n                            error = %e,\n                            \"Failed to release lock (may expire naturally)\"\n                        );\n                    }\n\n                    result\n                }\n                Ok(None) => {\n                    tracing::info!(\n                        job_name = name,\n                        tenant_id = tenant_id,\n                        reason = %JobSkipReason::AlreadyRunning,\n                        \"Job skipped - could not acquire lock\"\n                    );\n                    Ok(())\n                }\n                Err(e) => {\n                    tracing::warn!(\n                        job_name = name,\n                        error = %e,\n                        \"Failed to acquire lock, running without coordination\"\n                    );\n                    self.execute_job_without_lock(name, tenant_id, job_future)\n                        .await\n                }\n            }\n        } else {\n            self.execute_job_without_lock(name, tenant_id, job_future)\n                .await\n        }\n    }\n\n    async fn check_job_can_run(\n        &self,\n        redis: &RedisStorage,\n        job_name: &str,\n    ) -> Result<(), JobSkipReason> {\n        if self.job_config.deduplication_window_seconds > 0 {\n            match redis.check_job_recently_completed(job_name).await {\n                Ok(true) => return Err(JobSkipReason::RecentlyCompleted),\n                Ok(false) => {}\n                Err(e) => {\n                    tracing::warn!(\n                        job_name = job_name,\n                        error = %e,\n                        \"Failed to check deduplication, proceeding anyway\"\n                    );\n                }\n            }\n        }\n        Ok(())\n    }\n\n    async fn execute_job_with_lock<F>(\n        &self,\n        redis: &RedisStorage,\n        name: &str,\n        tenant_id: &str,\n        _lock_token: &str,\n        _lock_key: &str,\n        job_future: F,\n    ) -> anyhow::Result<()>\n    where\n        F: std::future::Future<Output = anyhow::Result<()>>,\n    {\n        let result = self\n            .execute_job_without_lock(name, tenant_id, job_future)\n            .await;\n\n        if result.is_ok() && self.job_config.deduplication_window_seconds > 0 {\n            if let Err(e) = redis\n                .record_job_completion(name, self.job_config.deduplication_window_seconds)\n                .await\n            {\n                tracing::warn!(\n                    job_name = name,\n                    error = %e,\n                    \"Failed to record job completion for deduplication\"\n                );\n            }\n        }\n\n        result\n    }\n\n    async fn execute_job_without_lock<F>(\n        &self,\n        name: &str,\n        tenant_id: &str,\n        job_future: F,\n    ) -> anyhow::Result<()>\n    where\n        F: std::future::Future<Output = anyhow::Result<()>>,\n    {\n        let started_at = chrono::Utc::now().timestamp();\n        tracing::info!(\"Starting job: {}\", name);\n\n        let storage = self\n            .engine\n            .storage()\n            .ok_or_else(|| anyhow::anyhow!(\"Storage not configured\"))?;\n\n        let _ = storage\n            .record_job_status(name, tenant_id, \"running\", None, started_at, None)\n            .await;\n\n        let timeout_duration = Duration::from_secs(self.job_config.job_timeout_seconds);\n        let job_result = tokio::time::timeout(timeout_duration, job_future).await;\n\n        match job_result {\n            Ok(Ok(_)) => {\n                let finished_at = chrono::Utc::now().timestamp();\n                let _ = storage\n                    .record_job_status(\n                        name,\n                        tenant_id,\n                        \"completed\",\n                        None,\n                        started_at,\n                        Some(finished_at),\n                    )\n                    .await;\n                Ok(())\n            }\n            Ok(Err(e)) => {\n                let finished_at = chrono::Utc::now().timestamp();\n                let message = format!(\"{:?}\", e);\n                let _ = storage\n                    .record_job_status(\n                        name,\n                        tenant_id,\n                        \"failed\",\n                        Some(&message),\n                        started_at,\n                        Some(finished_at),\n                    )\n                    .await;\n                Err(e)\n            }\n            Err(_elapsed) => {\n                let finished_at = chrono::Utc::now().timestamp();\n                tracing::error!(\n                    job_name = name,\n                    tenant_id = tenant_id,\n                    timeout_seconds = self.job_config.job_timeout_seconds,\n                    \"Job timed out\"\n                );\n                let _ = storage\n                    .record_job_status(\n                        name,\n                        tenant_id,\n                        \"timeout\",\n                        Some(&format!(\n                            \"Job exceeded {} second timeout\",\n                            self.job_config.job_timeout_seconds\n                        )),\n                        started_at,\n                        Some(finished_at),\n                    )\n                    .await;\n                Err(anyhow::anyhow!(\n                    \"Job '{}' timed out after {} seconds\",\n                    name,\n                    self.job_config.job_timeout_seconds\n                ))\n            }\n        }\n    }\n\n    async fn run_batch_drift_scan(&self) -> anyhow::Result<()> {\n        tracing::info!(\"Starting batch drift scan\");\n\n        let storage = self\n            .engine\n            .storage()\n            .ok_or_else(|| anyhow::anyhow!(\"Storage not configured\"))?;\n        let units = storage\n            .list_all_units()\n            .await\n            .map_err(|e| anyhow::anyhow!(\"Failed to list units: {:?}\", e))?;\n\n        for unit in units {\n            if unit.unit_type == UnitType::Project {\n                let tenant_ctx =\n                    TenantContext::new(unit.tenant_id.clone(), mk_core::types::UserId::default());\n                let mut context = HashMap::new();\n                context.insert(\"projectId\".to_string(), serde_json::json!(unit.id));\n                context.insert(\"content\".to_string(), serde_json::json!(\"\"));\n\n                let _ = self\n                    .engine\n                    .check_drift(&tenant_ctx, &unit.id, &context)\n                    .await;\n            }\n        }\n\n        Ok(())\n    }\n\n    async fn run_semantic_analysis_job(&self) -> anyhow::Result<()> {\n        tracing::info!(\"Starting daily semantic analysis job\");\n\n        let llm = self\n            .engine\n            .llm_service()\n            .ok_or_else(|| anyhow::anyhow!(\"LLM service not configured\"))?;\n\n        let storage = self\n            .engine\n            .storage()\n            .ok_or_else(|| anyhow::anyhow!(\"Storage not configured\"))?;\n\n        let units = storage\n            .list_all_units()\n            .await\n            .map_err(|e| anyhow::anyhow!(\"Failed to list units: {:?}\", e))?;\n\n        for unit in units {\n            if unit.unit_type == UnitType::Project {\n                let ctx = TenantContext::new(unit.tenant_id.clone(), UserId::default());\n\n                let policies = storage\n                    .get_unit_policies(ctx.clone(), &unit.id)\n                    .await\n                    .map_err(|e| anyhow::anyhow!(\"Failed to fetch policies: {:?}\", e))?;\n\n                if policies.is_empty() {\n                    continue;\n                }\n\n                let entries = self\n                    .repository\n                    .list(ctx.clone(), KnowledgeLayer::Project, \"\")\n                    .await\n                    .map_err(|e| anyhow::anyhow!(\"Failed to list project files: {:?}\", e))?;\n\n                let content = entries\n                    .into_iter()\n                    .map(|e| format!(\"File: {}\\n---\\n{}\\n---\", e.path, e.content))\n                    .collect::<Vec<_>>()\n                    .join(\"\\n\\n\");\n\n                if content.is_empty() {\n                    continue;\n                }\n\n                match llm.analyze_drift(&content, &policies).await {\n                    Ok(result) => {\n                        let drift_result = DriftResult::new(\n                            unit.id.clone(),\n                            unit.tenant_id.clone(),\n                            result.violations,\n                        );\n                        let _ = storage.store_drift_result(drift_result).await;\n                    }\n                    Err(e) => {\n                        tracing::error!(\n                            \"Semantic analysis failed for project {}: {:?}\",\n                            unit.id,\n                            e\n                        );\n                    }\n                }\n            }\n        }\n\n        Ok(())\n    }\n\n    async fn run_weekly_report_job(&self) -> anyhow::Result<()> {\n        tracing::info!(\"Starting weekly governance report job\");\n\n        let storage = self\n            .engine\n            .storage()\n            .ok_or_else(|| anyhow::anyhow!(\"Storage not configured\"))?;\n\n        let units = storage\n            .list_all_units()\n            .await\n            .map_err(|e| anyhow::anyhow!(\"Failed to list units: {:?}\", e))?;\n\n        let now = chrono::Utc::now().timestamp();\n        let one_week_ago = now - (7 * 24 * 60 * 60);\n\n        for unit in units {\n            if unit.unit_type == UnitType::Organization {\n                let mut report_data = HashMap::new();\n                let children = storage\n                    .get_descendants(\n                        TenantContext::new(unit.tenant_id.clone(), UserId::default()),\n                        &unit.id,\n                    )\n                    .await\n                    .map_err(|e| anyhow::anyhow!(\"Failed to list projects: {:?}\", e))?;\n\n                let mut total_drift = 0.0;\n                let mut project_count = 0;\n                let mut all_violations = Vec::new();\n                let mut all_suppressed = Vec::new();\n                let mut manual_review_count = 0;\n\n                for child in children {\n                    if child.unit_type == UnitType::Project {\n                        if let Some(result) = storage\n                            .get_latest_drift_result(\n                                TenantContext::new(child.tenant_id.clone(), UserId::default()),\n                                &child.id,\n                            )\n                            .await\n                            .map_err(|e| anyhow::anyhow!(\"Failed to fetch drift: {:?}\", e))?\n                        {\n                            if result.timestamp >= one_week_ago {\n                                total_drift += result.drift_score;\n                                project_count += 1;\n                                all_violations.extend(result.violations);\n                                all_suppressed.extend(result.suppressed_violations);\n                                if result.requires_manual_review {\n                                    manual_review_count += 1;\n                                }\n                            }\n                        }\n                    }\n                }\n\n                let avg_drift = if project_count > 0 {\n                    total_drift / project_count as f32\n                } else {\n                    0.0\n                };\n\n                report_data.insert(\"average_drift\".to_string(), serde_json::json!(avg_drift));\n                report_data.insert(\n                    \"project_count\".to_string(),\n                    serde_json::json!(project_count),\n                );\n                report_data.insert(\n                    \"active_violation_count\".to_string(),\n                    serde_json::json!(all_violations.len()),\n                );\n                report_data.insert(\n                    \"suppressed_violation_count\".to_string(),\n                    serde_json::json!(all_suppressed.len()),\n                );\n                report_data.insert(\n                    \"manual_review_required\".to_string(),\n                    serde_json::json!(manual_review_count),\n                );\n\n                tracing::info!(\n                    \"Weekly report for Org {}: Avg Drift: {:.2}, Projects: {}, Active Violations: \\\n                     {}, Suppressed: {}, Manual Review: {}\",\n                    unit.id,\n                    avg_drift,\n                    project_count,\n                    all_violations.len(),\n                    all_suppressed.len(),\n                    manual_review_count\n                );\n            }\n        }\n\n        Ok(())\n    }\n\n    async fn run_dlq_processing_job(&self) -> anyhow::Result<()> {\n        tracing::info!(\"Starting DLQ processing job\");\n\n        let storage = self\n            .engine\n            .storage()\n            .ok_or_else(|| anyhow::anyhow!(\"Storage not configured\"))?;\n\n        let units = storage\n            .list_all_units()\n            .await\n            .map_err(|e| anyhow::anyhow!(\"Failed to list units: {:?}\", e))?;\n\n        let mut total_processed = 0;\n        let mut total_failed = 0;\n        let mut total_requeued = 0;\n\n        for unit in units {\n            if unit.unit_type == UnitType::Company {\n                let ctx = TenantContext::new(unit.tenant_id.clone(), UserId::default());\n\n                let dead_letters = storage\n                    .get_dead_letter_events(ctx.clone(), 100)\n                    .await\n                    .map_err(|e| anyhow::anyhow!(\"Failed to fetch DLQ events: {:?}\", e))?;\n\n                if dead_letters.is_empty() {\n                    continue;\n                }\n\n                tracing::info!(\n                    \"Processing {} DLQ events for tenant {}\",\n                    dead_letters.len(),\n                    unit.tenant_id\n                );\n\n                for mut event in dead_letters {\n                    if event.retry_count < event.max_retries + 3 {\n                        event.retry_count += 1;\n                        match self.engine.publish_event(event.payload.clone()).await {\n                            Ok(_) => {\n                                storage\n                                    .update_event_status(\n                                        &event.event_id,\n                                        EventStatus::Published,\n                                        None,\n                                    )\n                                    .await\n                                    .ok();\n                                total_processed += 1;\n                            }\n                            Err(_) => {\n                                storage\n                                    .update_event_status(\n                                        &event.event_id,\n                                        EventStatus::DeadLettered,\n                                        Some(\"DLQ reprocessing failed\".to_string()),\n                                    )\n                                    .await\n                                    .ok();\n                                total_requeued += 1;\n                            }\n                        }\n                    } else {\n                        tracing::warn!(\n                            event_id = %event.event_id,\n                            \"Event exceeded max DLQ retries, marking as permanently failed\"\n                        );\n                        total_failed += 1;\n                    }\n                }\n            }\n        }\n\n        tracing::info!(\n            \"DLQ processing complete: {} processed, {} requeued, {} permanently failed\",\n            total_processed,\n            total_requeued,\n            total_failed\n        );\n\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use async_trait::async_trait;\n    use mk_core::traits::StorageBackend;\n    use mk_core::types::{\n        GovernanceEvent, KnowledgeEntry, KnowledgeLayer, OrganizationalUnit, Policy, Role, TenantId,\n    };\n    use std::sync::atomic::{AtomicUsize, Ordering};\n    use tokio::sync::RwLock;\n\n    struct MockStorage {\n        units: RwLock<Vec<OrganizationalUnit>>,\n        drift_results: RwLock<Vec<DriftResult>>,\n        job_records: Arc<AtomicUsize>,\n    }\n\n    impl MockStorage {\n        fn new() -> Self {\n            Self {\n                units: RwLock::new(Vec::new()),\n                drift_results: RwLock::new(Vec::new()),\n                job_records: Arc::new(AtomicUsize::new(0)),\n            }\n        }\n\n        fn with_units(units: Vec<OrganizationalUnit>) -> Self {\n            Self {\n                units: RwLock::new(units),\n                drift_results: RwLock::new(Vec::new()),\n                job_records: Arc::new(AtomicUsize::new(0)),\n            }\n        }\n    }\n\n    #[async_trait]\n    impl StorageBackend for MockStorage {\n        type Error = storage::postgres::PostgresError;\n\n        async fn store(\n            &self,\n            _ctx: TenantContext,\n            _key: &str,\n            _value: &[u8],\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn retrieve(\n            &self,\n            _ctx: TenantContext,\n            _key: &str,\n        ) -> Result<Option<Vec<u8>>, Self::Error> {\n            Ok(None)\n        }\n\n        async fn delete(&self, _ctx: TenantContext, _key: &str) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn exists(&self, _ctx: TenantContext, _key: &str) -> Result<bool, Self::Error> {\n            Ok(false)\n        }\n\n        async fn get_ancestors(\n            &self,\n            _ctx: TenantContext,\n            _unit_id: &str,\n        ) -> Result<Vec<OrganizationalUnit>, Self::Error> {\n            Ok(Vec::new())\n        }\n\n        async fn get_descendants(\n            &self,\n            _ctx: TenantContext,\n            unit_id: &str,\n        ) -> Result<Vec<OrganizationalUnit>, Self::Error> {\n            let units = self.units.read().await;\n            let children: Vec<_> = units\n                .iter()\n                .filter(|u| u.parent_id.as_deref() == Some(unit_id))\n                .cloned()\n                .collect();\n            Ok(children)\n        }\n\n        async fn get_unit_policies(\n            &self,\n            _ctx: TenantContext,\n            _unit_id: &str,\n        ) -> Result<Vec<Policy>, Self::Error> {\n            Ok(vec![Policy {\n                id: \"test-policy\".to_string(),\n                name: \"Test Policy\".to_string(),\n                description: Some(\"Test Policy Description\".to_string()),\n                layer: KnowledgeLayer::Project,\n                rules: vec![],\n                mode: mk_core::types::PolicyMode::Mandatory,\n                merge_strategy: mk_core::types::RuleMergeStrategy::Merge,\n                metadata: HashMap::new(),\n            }])\n        }\n\n        async fn create_unit(&self, _unit: &OrganizationalUnit) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn add_unit_policy(\n            &self,\n            _ctx: &TenantContext,\n            _unit_id: &str,\n            _policy: &Policy,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn assign_role(\n            &self,\n            _user_id: &UserId,\n            _tenant_id: &TenantId,\n            _unit_id: &str,\n            _role: Role,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn remove_role(\n            &self,\n            _user_id: &UserId,\n            _tenant_id: &TenantId,\n            _unit_id: &str,\n            _role: Role,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn store_drift_result(&self, result: DriftResult) -> Result<(), Self::Error> {\n            self.drift_results.write().await.push(result);\n            Ok(())\n        }\n\n        async fn get_latest_drift_result(\n            &self,\n            _ctx: TenantContext,\n            project_id: &str,\n        ) -> Result<Option<DriftResult>, Self::Error> {\n            let results = self.drift_results.read().await;\n            let result = results.iter().find(|r| r.project_id == project_id).cloned();\n            Ok(result)\n        }\n\n        async fn list_all_units(&self) -> Result<Vec<OrganizationalUnit>, Self::Error> {\n            Ok(self.units.read().await.clone())\n        }\n\n        async fn record_job_status(\n            &self,\n            _job_name: &str,\n            _tenant_id: &str,\n            _status: &str,\n            _message: Option<&str>,\n            _started_at: i64,\n            _finished_at: Option<i64>,\n        ) -> Result<(), Self::Error> {\n            self.job_records.fetch_add(1, Ordering::SeqCst);\n            Ok(())\n        }\n\n        async fn get_governance_events(\n            &self,\n            _ctx: TenantContext,\n            _since_timestamp: i64,\n            _limit: usize,\n        ) -> Result<Vec<GovernanceEvent>, Self::Error> {\n            Ok(Vec::new())\n        }\n\n        async fn persist_event(\n            &self,\n            _event: mk_core::types::PersistentEvent,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn get_pending_events(\n            &self,\n            _ctx: TenantContext,\n            _limit: usize,\n        ) -> Result<Vec<mk_core::types::PersistentEvent>, Self::Error> {\n            Ok(Vec::new())\n        }\n\n        async fn update_event_status(\n            &self,\n            _event_id: &str,\n            _status: EventStatus,\n            _error: Option<String>,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn get_dead_letter_events(\n            &self,\n            _ctx: TenantContext,\n            _limit: usize,\n        ) -> Result<Vec<mk_core::types::PersistentEvent>, Self::Error> {\n            Ok(Vec::new())\n        }\n\n        async fn check_idempotency(\n            &self,\n            _consumer_group: &str,\n            _idempotency_key: &str,\n        ) -> Result<bool, Self::Error> {\n            Ok(false)\n        }\n\n        async fn record_consumer_state(\n            &self,\n            _state: mk_core::types::ConsumerState,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn get_event_metrics(\n            &self,\n            _ctx: TenantContext,\n            _period_start: i64,\n            _period_end: i64,\n        ) -> Result<Vec<mk_core::types::EventDeliveryMetrics>, Self::Error> {\n            Ok(Vec::new())\n        }\n\n        async fn record_event_metrics(\n            &self,\n            _metrics: mk_core::types::EventDeliveryMetrics,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn create_suppression(\n            &self,\n            _suppression: mk_core::types::DriftSuppression,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn list_suppressions(\n            &self,\n            _ctx: TenantContext,\n            _project_id: &str,\n        ) -> Result<Vec<mk_core::types::DriftSuppression>, Self::Error> {\n            Ok(Vec::new())\n        }\n\n        async fn delete_suppression(\n            &self,\n            _ctx: TenantContext,\n            _suppression_id: &str,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn get_drift_config(\n            &self,\n            _ctx: TenantContext,\n            _project_id: &str,\n        ) -> Result<Option<mk_core::types::DriftConfig>, Self::Error> {\n            Ok(None)\n        }\n\n        async fn save_drift_config(\n            &self,\n            _config: mk_core::types::DriftConfig,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n    }\n\n    struct MockRepository {\n        entries: RwLock<Vec<KnowledgeEntry>>,\n    }\n\n    impl MockRepository {\n        fn new() -> Self {\n            Self {\n                entries: RwLock::new(Vec::new()),\n            }\n        }\n    }\n\n    #[async_trait]\n    impl mk_core::traits::KnowledgeRepository for MockRepository {\n        type Error = crate::repository::RepositoryError;\n\n        async fn get(\n            &self,\n            _ctx: TenantContext,\n            _layer: KnowledgeLayer,\n            path: &str,\n        ) -> Result<Option<KnowledgeEntry>, Self::Error> {\n            let entries = self.entries.read().await;\n            Ok(entries.iter().find(|e| e.path == path).cloned())\n        }\n\n        async fn store(\n            &self,\n            _ctx: TenantContext,\n            entry: KnowledgeEntry,\n            _message: &str,\n        ) -> Result<String, Self::Error> {\n            self.entries.write().await.push(entry);\n            Ok(\"hash123\".to_string())\n        }\n\n        async fn list(\n            &self,\n            _ctx: TenantContext,\n            layer: KnowledgeLayer,\n            _prefix: &str,\n        ) -> Result<Vec<KnowledgeEntry>, Self::Error> {\n            let entries = self.entries.read().await;\n            Ok(entries\n                .iter()\n                .filter(|e| e.layer == layer)\n                .cloned()\n                .collect())\n        }\n\n        async fn delete(\n            &self,\n            _ctx: TenantContext,\n            _layer: KnowledgeLayer,\n            _path: &str,\n            _message: &str,\n        ) -> Result<String, Self::Error> {\n            Ok(\"hash123\".to_string())\n        }\n\n        async fn get_head_commit(\n            &self,\n            _ctx: TenantContext,\n        ) -> Result<Option<String>, Self::Error> {\n            Ok(Some(\"head123\".to_string()))\n        }\n\n        async fn get_affected_items(\n            &self,\n            _ctx: TenantContext,\n            _since_commit: &str,\n        ) -> Result<Vec<(KnowledgeLayer, String)>, Self::Error> {\n            Ok(Vec::new())\n        }\n\n        async fn search(\n            &self,\n            _ctx: TenantContext,\n            _query: &str,\n            _layers: Vec<KnowledgeLayer>,\n            _limit: usize,\n        ) -> Result<Vec<KnowledgeEntry>, Self::Error> {\n            Ok(Vec::new())\n        }\n\n        fn root_path(&self) -> Option<std::path::PathBuf> {\n            None\n        }\n    }\n\n    fn create_test_tenant() -> TenantId {\n        TenantId::new(\"test-tenant\".to_string()).unwrap()\n    }\n\n    fn create_test_project_unit(id: &str, tenant_id: TenantId) -> OrganizationalUnit {\n        OrganizationalUnit {\n            id: id.to_string(),\n            name: format!(\"Project {}\", id),\n            unit_type: UnitType::Project,\n            tenant_id,\n            parent_id: Some(\"org-1\".to_string()),\n            metadata: HashMap::new(),\n            created_at: chrono::Utc::now().timestamp(),\n            updated_at: chrono::Utc::now().timestamp(),\n        }\n    }\n\n    fn create_test_org_unit(id: &str, tenant_id: TenantId) -> OrganizationalUnit {\n        OrganizationalUnit {\n            id: id.to_string(),\n            name: format!(\"Org {}\", id),\n            unit_type: UnitType::Organization,\n            tenant_id,\n            parent_id: None,\n            metadata: HashMap::new(),\n            created_at: chrono::Utc::now().timestamp(),\n            updated_at: chrono::Utc::now().timestamp(),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_run_batch_drift_scan_with_projects() {\n        let tenant_id = create_test_tenant();\n        let units = vec![\n            create_test_org_unit(\"org-1\", tenant_id.clone()),\n            create_test_project_unit(\"proj-1\", tenant_id.clone()),\n            create_test_project_unit(\"proj-2\", tenant_id.clone()),\n        ];\n\n        let storage = Arc::new(MockStorage::with_units(units));\n        let engine = Arc::new(GovernanceEngine::new().with_storage(storage.clone()));\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n\n        let config = DeploymentConfig::default();\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            config,\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        );\n\n        let result = scheduler.run_batch_drift_scan().await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_run_batch_drift_scan_without_storage() {\n        let engine = Arc::new(GovernanceEngine::new());\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n\n        let config = DeploymentConfig::default();\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            config,\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        );\n\n        let result = scheduler.run_batch_drift_scan().await;\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Storage not configured\")\n        );\n    }\n\n    #[tokio::test]\n    async fn test_run_semantic_analysis_job_without_llm() {\n        let tenant_id = create_test_tenant();\n        let units = vec![\n            create_test_org_unit(\"org-1\", tenant_id.clone()),\n            create_test_project_unit(\"proj-1\", tenant_id.clone()),\n        ];\n\n        let storage = Arc::new(MockStorage::with_units(units));\n        let engine = Arc::new(GovernanceEngine::new().with_storage(storage.clone()));\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n\n        let config = DeploymentConfig::default();\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            config,\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        );\n\n        let result = scheduler.run_semantic_analysis_job().await;\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"LLM service not configured\")\n        );\n    }\n\n    #[tokio::test]\n    async fn test_run_weekly_report_job_with_org_and_projects() {\n        let tenant_id = create_test_tenant();\n        let units = vec![\n            create_test_org_unit(\"org-1\", tenant_id.clone()),\n            create_test_project_unit(\"proj-1\", tenant_id.clone()),\n            create_test_project_unit(\"proj-2\", tenant_id.clone()),\n        ];\n\n        let storage = Arc::new(MockStorage::with_units(units));\n\n        let result1 = DriftResult::new(\"proj-1\".to_string(), tenant_id.clone(), vec![]);\n        let result2 = DriftResult::new(\"proj-2\".to_string(), tenant_id.clone(), vec![]);\n        storage.store_drift_result(result1).await.unwrap();\n        storage.store_drift_result(result2).await.unwrap();\n\n        let engine = Arc::new(GovernanceEngine::new().with_storage(storage.clone()));\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n\n        let config = DeploymentConfig::default();\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            config,\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        );\n\n        let result = scheduler.run_weekly_report_job().await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_run_weekly_report_job_without_storage() {\n        let engine = Arc::new(GovernanceEngine::new());\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n\n        let config = DeploymentConfig::default();\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            config,\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        );\n\n        let result = scheduler.run_weekly_report_job().await;\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Storage not configured\")\n        );\n    }\n\n    #[tokio::test]\n    async fn test_run_job_success() {\n        let storage = Arc::new(MockStorage::new());\n        let engine = Arc::new(GovernanceEngine::new().with_storage(storage.clone()));\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n\n        let config = DeploymentConfig::default();\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            config,\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        );\n\n        let result = scheduler\n            .run_job(\"test_job\", \"test-tenant\", async { Ok(()) })\n            .await;\n        assert!(result.is_ok());\n        assert_eq!(storage.job_records.load(Ordering::SeqCst), 2);\n    }\n\n    #[tokio::test]\n    async fn test_run_job_failure() {\n        let storage = Arc::new(MockStorage::new());\n        let engine = Arc::new(GovernanceEngine::new().with_storage(storage.clone()));\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n\n        let config = DeploymentConfig::default();\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            config,\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        );\n\n        let result = scheduler\n            .run_job(\"test_job\", \"test-tenant\", async {\n                Err(anyhow::anyhow!(\"Job failed\"))\n            })\n            .await;\n        assert!(result.is_err());\n        assert_eq!(storage.job_records.load(Ordering::SeqCst), 2);\n    }\n\n    #[tokio::test]\n    async fn test_run_job_without_storage() {\n        let engine = Arc::new(GovernanceEngine::new());\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n\n        let config = DeploymentConfig::default();\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            config,\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        );\n\n        let result = scheduler\n            .run_job(\"test_job\", \"test-tenant\", async { Ok(()) })\n            .await;\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Storage not configured\")\n        );\n    }\n\n    #[tokio::test]\n    async fn test_weekly_report_with_no_projects() {\n        let tenant_id = create_test_tenant();\n        let units = vec![create_test_org_unit(\"org-1\", tenant_id.clone())];\n\n        let storage = Arc::new(MockStorage::with_units(units));\n        let engine = Arc::new(GovernanceEngine::new().with_storage(storage.clone()));\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n\n        let config = DeploymentConfig::default();\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            config,\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        );\n\n        let result = scheduler.run_weekly_report_job().await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_weekly_report_with_old_drift_results() {\n        let tenant_id = create_test_tenant();\n        let units = vec![\n            create_test_org_unit(\"org-1\", tenant_id.clone()),\n            create_test_project_unit(\"proj-1\", tenant_id.clone()),\n        ];\n\n        let storage = Arc::new(MockStorage::with_units(units));\n\n        let old_result = DriftResult::new(\"proj-1\".to_string(), tenant_id.clone(), vec![]);\n        let mut old_result = old_result;\n        old_result.timestamp = chrono::Utc::now().timestamp() - (14 * 24 * 60 * 60);\n        storage.store_drift_result(old_result).await.unwrap();\n\n        let engine = Arc::new(GovernanceEngine::new().with_storage(storage.clone()));\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n\n        let config = DeploymentConfig::default();\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            config,\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        );\n\n        let result = scheduler.run_weekly_report_job().await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_batch_drift_scan_with_empty_units() {\n        let storage = Arc::new(MockStorage::new());\n        let engine = Arc::new(GovernanceEngine::new().with_storage(storage.clone()));\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n\n        let config = DeploymentConfig::default();\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            config,\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        );\n\n        let result = scheduler.run_batch_drift_scan().await;\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_with_dlq_interval() {\n        let storage = Arc::new(MockStorage::new());\n        let engine = Arc::new(GovernanceEngine::new().with_storage(storage.clone()));\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n        let config = DeploymentConfig::default();\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            config,\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        )\n        .with_dlq_interval(Duration::from_secs(600));\n\n        assert_eq!(scheduler.dlq_processing_interval, Duration::from_secs(600));\n    }\n\n    #[test]\n    fn test_with_job_config() {\n        let storage = Arc::new(MockStorage::new());\n        let engine = Arc::new(GovernanceEngine::new().with_storage(storage.clone()));\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n        let config = DeploymentConfig::default();\n\n        let job_config = JobConfig {\n            lock_ttl_seconds: 120,\n            job_timeout_seconds: 600,\n            deduplication_window_seconds: 3600,\n            checkpoint_interval: 100,\n            graceful_shutdown_timeout_seconds: 30,\n        };\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            config,\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        )\n        .with_job_config(job_config.clone());\n\n        assert_eq!(scheduler.job_config.lock_ttl_seconds, 120);\n        assert_eq!(scheduler.job_config.job_timeout_seconds, 600);\n        assert_eq!(scheduler.job_config.deduplication_window_seconds, 3600);\n    }\n\n    #[tokio::test]\n    async fn test_run_dlq_processing_job_without_storage() {\n        let engine = Arc::new(GovernanceEngine::new());\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n        let config = DeploymentConfig::default();\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            config,\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        );\n\n        let result = scheduler.run_dlq_processing_job().await;\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Storage not configured\")\n        );\n    }\n\n    #[tokio::test]\n    async fn test_run_dlq_processing_job_with_no_company_units() {\n        let tenant_id = create_test_tenant();\n        let units = vec![\n            create_test_org_unit(\"org-1\", tenant_id.clone()),\n            create_test_project_unit(\"proj-1\", tenant_id.clone()),\n        ];\n\n        let storage = Arc::new(MockStorage::with_units(units));\n        let engine = Arc::new(GovernanceEngine::new().with_storage(storage.clone()));\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n        let config = DeploymentConfig::default();\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            config,\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        );\n\n        let result = scheduler.run_dlq_processing_job().await;\n        assert!(result.is_ok());\n    }\n\n    fn create_test_company_unit(id: &str, tenant_id: TenantId) -> OrganizationalUnit {\n        OrganizationalUnit {\n            id: id.to_string(),\n            name: format!(\"Company {}\", id),\n            unit_type: UnitType::Company,\n            tenant_id,\n            parent_id: None,\n            metadata: HashMap::new(),\n            created_at: chrono::Utc::now().timestamp(),\n            updated_at: chrono::Utc::now().timestamp(),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_run_dlq_processing_job_with_company_unit() {\n        let tenant_id = create_test_tenant();\n        let units = vec![create_test_company_unit(\"company-1\", tenant_id.clone())];\n\n        let storage = Arc::new(MockStorage::with_units(units));\n        let engine = Arc::new(GovernanceEngine::new().with_storage(storage.clone()));\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n        let config = DeploymentConfig::default();\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            config,\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        );\n\n        let result = scheduler.run_dlq_processing_job().await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_run_job_timeout() {\n        let storage = Arc::new(MockStorage::new());\n        let engine = Arc::new(GovernanceEngine::new().with_storage(storage.clone()));\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n        let config = DeploymentConfig::default();\n\n        let job_config = JobConfig {\n            lock_ttl_seconds: 60,\n            job_timeout_seconds: 1,\n            deduplication_window_seconds: 0,\n            checkpoint_interval: 100,\n            graceful_shutdown_timeout_seconds: 30,\n        };\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            config,\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        )\n        .with_job_config(job_config);\n\n        let result = scheduler\n            .run_job(\"slow_job\", \"test-tenant\", async {\n                tokio::time::sleep(Duration::from_secs(5)).await;\n                Ok(())\n            })\n            .await;\n\n        assert!(result.is_err());\n        let err_msg = result.unwrap_err().to_string();\n        assert!(err_msg.contains(\"timed out\"));\n    }\n\n    #[tokio::test]\n    async fn test_semantic_analysis_job_without_storage() {\n        let engine = Arc::new(GovernanceEngine::new());\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n        let config = DeploymentConfig::default();\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            config,\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        );\n\n        let result = scheduler.run_semantic_analysis_job().await;\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"LLM service not configured\")\n        );\n    }\n\n    #[tokio::test]\n    async fn test_batch_drift_scan_skips_non_project_units() {\n        let tenant_id = create_test_tenant();\n        let units = vec![\n            create_test_org_unit(\"org-1\", tenant_id.clone()),\n            create_test_company_unit(\"company-1\", tenant_id.clone()),\n        ];\n\n        let storage = Arc::new(MockStorage::with_units(units));\n        let engine = Arc::new(GovernanceEngine::new().with_storage(storage.clone()));\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n        let config = DeploymentConfig::default();\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            config,\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        );\n\n        let result = scheduler.run_batch_drift_scan().await;\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_governance_scheduler_new() {\n        let storage = Arc::new(MockStorage::new());\n        let engine = Arc::new(GovernanceEngine::new().with_storage(storage.clone()));\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n        let config = DeploymentConfig::default();\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            config,\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        );\n\n        assert_eq!(scheduler.quick_scan_interval, Duration::from_secs(300));\n        assert_eq!(scheduler.semantic_scan_interval, Duration::from_secs(3600));\n        assert_eq!(scheduler.report_interval, Duration::from_secs(86400));\n        assert_eq!(scheduler.dlq_processing_interval, Duration::from_secs(300));\n        assert!(scheduler.redis.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_run_job_forced_failure() {\n        let storage = Arc::new(MockStorage::new());\n        let engine = Arc::new(GovernanceEngine::new().with_storage(storage.clone()));\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n        let config = DeploymentConfig::default();\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            config,\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        );\n\n        let result = scheduler\n            .run_job(\"test_TRIGGER_FAILURE\", \"test-tenant\", async { Ok(()) })\n            .await;\n\n        assert!(result.is_err());\n        assert!(result.unwrap_err().to_string().contains(\"TRIGGER_FAILURE\"));\n        assert_eq!(storage.job_records.load(Ordering::SeqCst), 0);\n    }\n\n    #[tokio::test]\n    async fn test_scheduler_start_remote_mode() {\n        let storage = Arc::new(MockStorage::new());\n        let engine = Arc::new(GovernanceEngine::new().with_storage(storage.clone()));\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n        let mut config = DeploymentConfig::default();\n        config.mode = \"remote\".to_string();\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            config,\n            Duration::from_millis(10),\n            Duration::from_millis(10),\n            Duration::from_millis(10),\n        );\n\n        scheduler.start().await;\n    }\n\n    #[tokio::test]\n    async fn test_with_redis() {\n        let Some(fixture) = testing::redis().await else {\n            eprintln!(\"Skipping Redis test: Docker not available\");\n            return;\n        };\n\n        let url = fixture.url();\n        let redis_storage = Arc::new(RedisStorage::new(url).await.unwrap());\n\n        let storage = Arc::new(MockStorage::new());\n        let engine = Arc::new(GovernanceEngine::new().with_storage(storage.clone()));\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            DeploymentConfig::default(),\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        )\n        .with_redis(redis_storage)\n        .with_job_config(JobConfig {\n            lock_ttl_seconds: 60,\n            job_timeout_seconds: 60,\n            deduplication_window_seconds: 3600,\n            checkpoint_interval: 10,\n            graceful_shutdown_timeout_seconds: 10,\n        });\n\n        let result = scheduler\n            .run_job(\"test_redis_job\", \"test-tenant\", async { Ok(()) })\n            .await;\n\n        assert!(result.is_ok());\n\n        let result_skipped = scheduler\n            .run_job(\"test_redis_job\", \"test-tenant\", async { Ok(()) })\n            .await;\n        assert!(result_skipped.is_ok());\n\n        assert_eq!(storage.job_records.load(Ordering::SeqCst), 2);\n    }\n\n    #[tokio::test]\n    async fn test_job_locking_already_held() {\n        let Some(fixture) = testing::redis().await else {\n            eprintln!(\"Skipping Redis test: Docker not available\");\n            return;\n        };\n\n        let url = fixture.url();\n        let redis_storage = Arc::new(RedisStorage::new(url).await.unwrap());\n\n        let storage = Arc::new(MockStorage::new());\n        let engine = Arc::new(GovernanceEngine::new().with_storage(storage.clone()));\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n\n        let job_name = \"contended_job\";\n        let lock_key = format!(\"job_lock:{}\", job_name);\n        redis_storage.acquire_lock(&lock_key, 60).await.unwrap();\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            DeploymentConfig::default(),\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        )\n        .with_redis(redis_storage);\n\n        let result = scheduler\n            .run_job(job_name, \"test-tenant\", async { Ok(()) })\n            .await;\n\n        assert!(result.is_ok());\n        assert_eq!(storage.job_records.load(Ordering::SeqCst), 0);\n    }\n\n    #[tokio::test]\n    async fn test_check_job_can_run_deduplication() {\n        let Some(fixture) = testing::redis().await else {\n            eprintln!(\"Skipping Redis test: Docker not available\");\n            return;\n        };\n\n        let url = fixture.url();\n        let redis_storage = Arc::new(RedisStorage::new(url).await.unwrap());\n\n        let storage = Arc::new(MockStorage::new());\n        let engine = Arc::new(GovernanceEngine::new().with_storage(storage.clone()));\n        let repo: Arc<\n            dyn mk_core::traits::KnowledgeRepository<Error = crate::repository::RepositoryError>,\n        > = Arc::new(MockRepository::new());\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            DeploymentConfig::default(),\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        )\n        .with_redis(redis_storage.clone())\n        .with_job_config(JobConfig {\n            deduplication_window_seconds: 3600,\n            ..Default::default()\n        });\n\n        redis_storage\n            .record_job_completion(\"recent_job\", 3600)\n            .await\n            .unwrap();\n\n        let can_run = scheduler\n            .check_job_can_run(&redis_storage, \"recent_job\")\n            .await;\n        assert!(can_run.is_err());\n        assert_eq!(\n            can_run.unwrap_err(),\n            storage::JobSkipReason::RecentlyCompleted\n        );\n\n        let can_run_new = scheduler.check_job_can_run(&redis_storage, \"new_job\").await;\n        assert!(can_run_new.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_run_semantic_analysis_job_success() {\n        use mk_core::traits::LlmService;\n        use mk_core::types::{\n            ConstraintSeverity, KnowledgeStatus, KnowledgeType, PolicyViolation, ValidationResult,\n        };\n\n        struct MockLlm;\n        #[async_trait]\n        impl LlmService for MockLlm {\n            type Error = Box<dyn std::error::Error + Send + Sync>;\n\n            async fn generate(&self, _prompt: &str) -> Result<String, Self::Error> {\n                Ok(\"generated\".to_string())\n            }\n\n            async fn analyze_drift(\n                &self,\n                _content: &str,\n                _policies: &[Policy],\n            ) -> Result<ValidationResult, Self::Error> {\n                Ok(ValidationResult {\n                    is_valid: false,\n                    violations: vec![PolicyViolation {\n                        rule_id: \"rule-1\".to_string(),\n                        policy_id: \"pol-1\".to_string(),\n                        severity: ConstraintSeverity::Warn,\n                        message: \"violation\".to_string(),\n                        context: HashMap::new(),\n                    }],\n                })\n            }\n        }\n\n        let tenant_id = create_test_tenant();\n        let units = vec![create_test_project_unit(\"proj-1\", tenant_id.clone())];\n        let storage = Arc::new(MockStorage::with_units(units));\n        let engine = Arc::new(\n            GovernanceEngine::new()\n                .with_storage(storage.clone())\n                .with_llm_service(Arc::new(MockLlm)),\n        );\n\n        let repo = Arc::new(MockRepository::new());\n        repo.store(\n            TenantContext::new(tenant_id.clone(), UserId::default()),\n            KnowledgeEntry {\n                path: \"file.txt\".to_string(),\n                content: \"content\".to_string(),\n                layer: KnowledgeLayer::Project,\n                kind: KnowledgeType::Adr,\n                status: KnowledgeStatus::Accepted,\n                summaries: HashMap::new(),\n                metadata: HashMap::new(),\n                commit_hash: Some(\"abc\".to_string()),\n                author: Some(\"test\".to_string()),\n                updated_at: chrono::Utc::now().timestamp(),\n            },\n            \"initial\",\n        )\n        .await\n        .unwrap();\n\n        let scheduler = GovernanceScheduler::new(\n            engine,\n            repo,\n            DeploymentConfig::default(),\n            Duration::from_secs(300),\n            Duration::from_secs(3600),\n            Duration::from_secs(86400),\n        );\n\n        let result = scheduler.run_semantic_analysis_job().await;\n        assert!(result.is_ok());\n        assert_eq!(storage.drift_results.read().await.len(), 1);\n    }\n}\n","traces":[{"line":25,"address":[],"length":0,"stats":{"Line":23}},{"line":40,"address":[],"length":0,"stats":{"Line":46}},{"line":42,"address":[],"length":0,"stats":{"Line":23}},{"line":46,"address":[],"length":0,"stats":{"Line":1}},{"line":47,"address":[],"length":0,"stats":{"Line":1}},{"line":48,"address":[],"length":0,"stats":{"Line":1}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":2}},{"line":57,"address":[],"length":0,"stats":{"Line":2}},{"line":58,"address":[],"length":0,"stats":{"Line":2}},{"line":61,"address":[],"length":0,"stats":{"Line":2}},{"line":62,"address":[],"length":0,"stats":{"Line":1}},{"line":63,"address":[],"length":0,"stats":{"Line":1}},{"line":64,"address":[],"length":0,"stats":{"Line":1}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":5}},{"line":100,"address":[],"length":0,"stats":{"Line":10}},{"line":101,"address":[],"length":0,"stats":{"Line":1}},{"line":104,"address":[],"length":0,"stats":{"Line":4}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":20}},{"line":163,"address":[],"length":0,"stats":{"Line":4}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":201,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":204,"address":[],"length":0,"stats":{"Line":0}},{"line":205,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":207,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":4}},{"line":229,"address":[],"length":0,"stats":{"Line":12}},{"line":230,"address":[],"length":0,"stats":{"Line":4}},{"line":232,"address":[],"length":0,"stats":{"Line":7}},{"line":233,"address":[],"length":0,"stats":{"Line":4}},{"line":235,"address":[],"length":0,"stats":{"Line":7}},{"line":237,"address":[],"length":0,"stats":{"Line":6}},{"line":238,"address":[],"length":0,"stats":{"Line":18}},{"line":239,"address":[],"length":0,"stats":{"Line":3}},{"line":241,"address":[],"length":0,"stats":{"Line":9}},{"line":242,"address":[],"length":0,"stats":{"Line":12}},{"line":244,"address":[],"length":0,"stats":{"Line":2}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":3}},{"line":247,"address":[],"length":0,"stats":{"Line":2}},{"line":249,"address":[],"length":0,"stats":{"Line":2}},{"line":250,"address":[],"length":0,"stats":{"Line":2}},{"line":252,"address":[],"length":0,"stats":{"Line":2}},{"line":253,"address":[],"length":0,"stats":{"Line":1}},{"line":254,"address":[],"length":0,"stats":{"Line":1}},{"line":256,"address":[],"length":0,"stats":{"Line":1}},{"line":257,"address":[],"length":0,"stats":{"Line":1}},{"line":259,"address":[],"length":0,"stats":{"Line":1}},{"line":260,"address":[],"length":0,"stats":{"Line":3}},{"line":261,"address":[],"length":0,"stats":{"Line":3}},{"line":262,"address":[],"length":0,"stats":{"Line":2}},{"line":264,"address":[],"length":0,"stats":{"Line":2}},{"line":265,"address":[],"length":0,"stats":{"Line":2}},{"line":267,"address":[],"length":0,"stats":{"Line":2}},{"line":268,"address":[],"length":0,"stats":{"Line":1}},{"line":269,"address":[],"length":0,"stats":{"Line":1}},{"line":271,"address":[],"length":0,"stats":{"Line":1}},{"line":272,"address":[],"length":0,"stats":{"Line":1}},{"line":274,"address":[],"length":0,"stats":{"Line":1}},{"line":275,"address":[],"length":0,"stats":{"Line":3}},{"line":276,"address":[],"length":0,"stats":{"Line":1}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":2}},{"line":284,"address":[],"length":0,"stats":{"Line":2}},{"line":285,"address":[],"length":0,"stats":{"Line":2}},{"line":287,"address":[],"length":0,"stats":{"Line":2}},{"line":288,"address":[],"length":0,"stats":{"Line":2}},{"line":289,"address":[],"length":0,"stats":{"Line":2}},{"line":291,"address":[],"length":0,"stats":{"Line":1}},{"line":292,"address":[],"length":0,"stats":{"Line":1}},{"line":294,"address":[],"length":0,"stats":{"Line":1}},{"line":295,"address":[],"length":0,"stats":{"Line":1}},{"line":296,"address":[],"length":0,"stats":{"Line":1}},{"line":297,"address":[],"length":0,"stats":{"Line":1}},{"line":298,"address":[],"length":0,"stats":{"Line":1}},{"line":304,"address":[],"length":0,"stats":{"Line":8}},{"line":305,"address":[],"length":0,"stats":{"Line":4}},{"line":307,"address":[],"length":0,"stats":{"Line":7}},{"line":308,"address":[],"length":0,"stats":{"Line":4}},{"line":310,"address":[],"length":0,"stats":{"Line":7}},{"line":311,"address":[],"length":0,"stats":{"Line":6}},{"line":313,"address":[],"length":0,"stats":{"Line":3}},{"line":314,"address":[],"length":0,"stats":{"Line":3}},{"line":316,"address":[],"length":0,"stats":{"Line":13}},{"line":317,"address":[],"length":0,"stats":{"Line":5}},{"line":318,"address":[],"length":0,"stats":{"Line":2}},{"line":319,"address":[],"length":0,"stats":{"Line":8}},{"line":320,"address":[],"length":0,"stats":{"Line":4}},{"line":321,"address":[],"length":0,"stats":{"Line":10}},{"line":322,"address":[],"length":0,"stats":{"Line":10}},{"line":324,"address":[],"length":0,"stats":{"Line":4}},{"line":325,"address":[],"length":0,"stats":{"Line":4}},{"line":326,"address":[],"length":0,"stats":{"Line":6}},{"line":327,"address":[],"length":0,"stats":{"Line":2}},{"line":331,"address":[],"length":0,"stats":{"Line":3}},{"line":334,"address":[],"length":0,"stats":{"Line":6}},{"line":335,"address":[],"length":0,"stats":{"Line":3}},{"line":337,"address":[],"length":0,"stats":{"Line":4}},{"line":338,"address":[],"length":0,"stats":{"Line":3}},{"line":340,"address":[],"length":0,"stats":{"Line":9}},{"line":342,"address":[],"length":0,"stats":{"Line":2}},{"line":343,"address":[],"length":0,"stats":{"Line":1}},{"line":345,"address":[],"length":0,"stats":{"Line":1}},{"line":347,"address":[],"length":0,"stats":{"Line":2}},{"line":349,"address":[],"length":0,"stats":{"Line":1}},{"line":350,"address":[],"length":0,"stats":{"Line":1}},{"line":352,"address":[],"length":0,"stats":{"Line":3}},{"line":353,"address":[],"length":0,"stats":{"Line":1}},{"line":354,"address":[],"length":0,"stats":{"Line":5}},{"line":356,"address":[],"length":0,"stats":{"Line":3}},{"line":357,"address":[],"length":0,"stats":{"Line":3}},{"line":358,"address":[],"length":0,"stats":{"Line":1}},{"line":359,"address":[],"length":0,"stats":{"Line":1}},{"line":361,"address":[],"length":0,"stats":{"Line":2}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":365,"address":[],"length":0,"stats":{"Line":3}},{"line":366,"address":[],"length":0,"stats":{"Line":2}},{"line":367,"address":[],"length":0,"stats":{"Line":4}},{"line":368,"address":[],"length":0,"stats":{"Line":1}},{"line":369,"address":[],"length":0,"stats":{"Line":1}},{"line":371,"address":[],"length":0,"stats":{"Line":2}},{"line":373,"address":[],"length":0,"stats":{"Line":3}},{"line":377,"address":[],"length":0,"stats":{"Line":2}},{"line":378,"address":[],"length":0,"stats":{"Line":0}},{"line":381,"address":[],"length":0,"stats":{"Line":4}},{"line":382,"address":[],"length":0,"stats":{"Line":1}},{"line":384,"address":[],"length":0,"stats":{"Line":2}},{"line":385,"address":[],"length":0,"stats":{"Line":2}},{"line":386,"address":[],"length":0,"stats":{"Line":1}},{"line":388,"address":[],"length":0,"stats":{"Line":3}},{"line":390,"address":[],"length":0,"stats":{"Line":0}},{"line":391,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":0}},{"line":401,"address":[],"length":0,"stats":{"Line":1}},{"line":404,"address":[],"length":0,"stats":{"Line":8}},{"line":405,"address":[],"length":0,"stats":{"Line":4}},{"line":407,"address":[],"length":0,"stats":{"Line":7}},{"line":408,"address":[],"length":0,"stats":{"Line":4}},{"line":410,"address":[],"length":0,"stats":{"Line":7}},{"line":412,"address":[],"length":0,"stats":{"Line":6}},{"line":414,"address":[],"length":0,"stats":{"Line":3}},{"line":415,"address":[],"length":0,"stats":{"Line":3}},{"line":417,"address":[],"length":0,"stats":{"Line":9}},{"line":418,"address":[],"length":0,"stats":{"Line":6}},{"line":420,"address":[],"length":0,"stats":{"Line":15}},{"line":421,"address":[],"length":0,"stats":{"Line":6}},{"line":422,"address":[],"length":0,"stats":{"Line":6}},{"line":423,"address":[],"length":0,"stats":{"Line":9}},{"line":425,"address":[],"length":0,"stats":{"Line":12}},{"line":426,"address":[],"length":0,"stats":{"Line":3}},{"line":428,"address":[],"length":0,"stats":{"Line":3}},{"line":429,"address":[],"length":0,"stats":{"Line":3}},{"line":431,"address":[],"length":0,"stats":{"Line":6}},{"line":432,"address":[],"length":0,"stats":{"Line":6}},{"line":433,"address":[],"length":0,"stats":{"Line":6}},{"line":434,"address":[],"length":0,"stats":{"Line":6}},{"line":435,"address":[],"length":0,"stats":{"Line":6}},{"line":437,"address":[],"length":0,"stats":{"Line":9}},{"line":438,"address":[],"length":0,"stats":{"Line":3}},{"line":439,"address":[],"length":0,"stats":{"Line":9}},{"line":441,"address":[],"length":0,"stats":{"Line":12}},{"line":442,"address":[],"length":0,"stats":{"Line":3}},{"line":444,"address":[],"length":0,"stats":{"Line":3}},{"line":445,"address":[],"length":0,"stats":{"Line":3}},{"line":447,"address":[],"length":0,"stats":{"Line":3}},{"line":448,"address":[],"length":0,"stats":{"Line":2}},{"line":449,"address":[],"length":0,"stats":{"Line":2}},{"line":450,"address":[],"length":0,"stats":{"Line":6}},{"line":451,"address":[],"length":0,"stats":{"Line":6}},{"line":452,"address":[],"length":0,"stats":{"Line":2}},{"line":453,"address":[],"length":0,"stats":{"Line":0}},{"line":460,"address":[],"length":0,"stats":{"Line":6}},{"line":461,"address":[],"length":0,"stats":{"Line":1}},{"line":463,"address":[],"length":0,"stats":{"Line":2}},{"line":466,"address":[],"length":0,"stats":{"Line":15}},{"line":467,"address":[],"length":0,"stats":{"Line":6}},{"line":468,"address":[],"length":0,"stats":{"Line":6}},{"line":469,"address":[],"length":0,"stats":{"Line":3}},{"line":471,"address":[],"length":0,"stats":{"Line":6}},{"line":472,"address":[],"length":0,"stats":{"Line":6}},{"line":473,"address":[],"length":0,"stats":{"Line":9}},{"line":475,"address":[],"length":0,"stats":{"Line":6}},{"line":476,"address":[],"length":0,"stats":{"Line":6}},{"line":477,"address":[],"length":0,"stats":{"Line":9}},{"line":479,"address":[],"length":0,"stats":{"Line":6}},{"line":480,"address":[],"length":0,"stats":{"Line":6}},{"line":481,"address":[],"length":0,"stats":{"Line":3}},{"line":484,"address":[],"length":0,"stats":{"Line":3}},{"line":485,"address":[],"length":0,"stats":{"Line":0}},{"line":486,"address":[],"length":0,"stats":{"Line":0}},{"line":490,"address":[],"length":0,"stats":{"Line":0}},{"line":491,"address":[],"length":0,"stats":{"Line":0}},{"line":497,"address":[],"length":0,"stats":{"Line":3}},{"line":500,"address":[],"length":0,"stats":{"Line":6}},{"line":501,"address":[],"length":0,"stats":{"Line":3}},{"line":503,"address":[],"length":0,"stats":{"Line":5}},{"line":504,"address":[],"length":0,"stats":{"Line":3}},{"line":506,"address":[],"length":0,"stats":{"Line":6}},{"line":508,"address":[],"length":0,"stats":{"Line":4}},{"line":510,"address":[],"length":0,"stats":{"Line":2}},{"line":511,"address":[],"length":0,"stats":{"Line":2}},{"line":513,"address":[],"length":0,"stats":{"Line":4}},{"line":514,"address":[],"length":0,"stats":{"Line":4}},{"line":515,"address":[],"length":0,"stats":{"Line":4}},{"line":517,"address":[],"length":0,"stats":{"Line":8}},{"line":518,"address":[],"length":0,"stats":{"Line":3}},{"line":519,"address":[],"length":0,"stats":{"Line":5}},{"line":521,"address":[],"length":0,"stats":{"Line":3}},{"line":522,"address":[],"length":0,"stats":{"Line":2}},{"line":523,"address":[],"length":0,"stats":{"Line":1}},{"line":524,"address":[],"length":0,"stats":{"Line":1}},{"line":526,"address":[],"length":0,"stats":{"Line":2}},{"line":527,"address":[],"length":0,"stats":{"Line":1}},{"line":530,"address":[],"length":0,"stats":{"Line":0}},{"line":531,"address":[],"length":0,"stats":{"Line":0}},{"line":532,"address":[],"length":0,"stats":{"Line":0}},{"line":536,"address":[],"length":0,"stats":{"Line":0}},{"line":537,"address":[],"length":0,"stats":{"Line":0}},{"line":538,"address":[],"length":0,"stats":{"Line":0}},{"line":539,"address":[],"length":0,"stats":{"Line":0}},{"line":541,"address":[],"length":0,"stats":{"Line":0}},{"line":543,"address":[],"length":0,"stats":{"Line":0}},{"line":544,"address":[],"length":0,"stats":{"Line":0}},{"line":545,"address":[],"length":0,"stats":{"Line":0}},{"line":547,"address":[],"length":0,"stats":{"Line":0}},{"line":549,"address":[],"length":0,"stats":{"Line":0}},{"line":552,"address":[],"length":0,"stats":{"Line":0}},{"line":554,"address":[],"length":0,"stats":{"Line":0}},{"line":555,"address":[],"length":0,"stats":{"Line":0}},{"line":556,"address":[],"length":0,"stats":{"Line":0}},{"line":558,"address":[],"length":0,"stats":{"Line":0}},{"line":560,"address":[],"length":0,"stats":{"Line":0}},{"line":564,"address":[],"length":0,"stats":{"Line":0}},{"line":566,"address":[],"length":0,"stats":{"Line":0}},{"line":568,"address":[],"length":0,"stats":{"Line":0}},{"line":574,"address":[],"length":0,"stats":{"Line":2}},{"line":575,"address":[],"length":0,"stats":{"Line":0}},{"line":581,"address":[],"length":0,"stats":{"Line":2}}],"covered":197,"coverable":316},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","state.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","telemetry.rs"],"content":"use metrics::{gauge, histogram, increment_counter};\n\npub struct KnowledgeTelemetry;\n\nimpl KnowledgeTelemetry {\n    pub fn record_operation(&self, operation: &str, status: &str) {\n        // GIVEN an operation and status\n        // WHEN recording metrics\n        // THEN increment the operation counter with status label\n\n        increment_counter!(\"knowledge_operations_total\", \"operation\" => operation.to_string(), \"status\" => status.to_string());\n    }\n\n    pub fn record_violation(&self, layer: &str, severity: &str) {\n        // GIVEN a layer and severity\n        // WHEN recording metrics\n        // THEN increment the violation counter with layer and severity labels\n\n        increment_counter!(\"knowledge_violations_total\", \"layer\" => layer.to_string(), \"severity\" => severity.to_string());\n    }\n\n    pub fn record_summary_generation(\n        &self,\n        depth: &str,\n        status: &str,\n        tokens_used: u32,\n        latency_ms: f64,\n    ) {\n        increment_counter!(\"cca_summary_generation_total\", \"depth\" => depth.to_string(), \"status\" => status.to_string());\n        histogram!(\"cca_summary_generation_tokens\", tokens_used as f64, \"depth\" => depth.to_string());\n        histogram!(\"cca_summary_generation_latency_ms\", latency_ms, \"depth\" => depth.to_string());\n    }\n\n    pub fn record_note_distillation(&self, status: &str, events_count: usize, latency_ms: f64) {\n        increment_counter!(\"cca_note_distillation_total\", \"status\" => status.to_string());\n        histogram!(\"cca_note_distillation_events\", events_count as f64);\n        histogram!(\"cca_note_distillation_latency_ms\", latency_ms);\n    }\n\n    pub fn record_hindsight_query(&self, status: &str, patterns_found: usize, latency_ms: f64) {\n        increment_counter!(\"cca_hindsight_query_total\", \"status\" => status.to_string());\n        histogram!(\"cca_hindsight_query_patterns_found\", patterns_found as f64);\n        histogram!(\"cca_hindsight_query_latency_ms\", latency_ms);\n    }\n\n    pub fn record_meta_agent_loop(\n        &self,\n        phase: &str,\n        status: &str,\n        iteration: u32,\n        latency_ms: f64,\n    ) {\n        increment_counter!(\"cca_meta_agent_loop_total\", \"phase\" => phase.to_string(), \"status\" => status.to_string());\n        gauge!(\"cca_meta_agent_loop_iteration\", iteration as f64, \"phase\" => phase.to_string());\n        histogram!(\"cca_meta_agent_loop_latency_ms\", latency_ms, \"phase\" => phase.to_string());\n    }\n\n    pub fn record_context_assembly(\n        &self,\n        status: &str,\n        layers_included: usize,\n        tokens_used: u32,\n        latency_ms: f64,\n    ) {\n        increment_counter!(\"cca_context_assembly_total\", \"status\" => status.to_string());\n        histogram!(\"cca_context_assembly_layers\", layers_included as f64);\n        histogram!(\"cca_context_assembly_tokens\", tokens_used as f64);\n        histogram!(\"cca_context_assembly_latency_ms\", latency_ms);\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_record_operation() {\n        let telemetry = KnowledgeTelemetry;\n        telemetry.record_operation(\"read\", \"success\");\n        telemetry.record_operation(\"write\", \"failure\");\n        telemetry.record_operation(\"delete\", \"success\");\n    }\n\n    #[test]\n    fn test_record_violation() {\n        let telemetry = KnowledgeTelemetry;\n        telemetry.record_violation(\"team\", \"warn\");\n        telemetry.record_violation(\"project\", \"block\");\n        telemetry.record_violation(\"org\", \"info\");\n    }\n\n    #[test]\n    fn test_record_summary_generation() {\n        let telemetry = KnowledgeTelemetry;\n        telemetry.record_summary_generation(\"sentence\", \"success\", 45, 125.5);\n        telemetry.record_summary_generation(\"paragraph\", \"failure\", 0, 250.0);\n    }\n\n    #[test]\n    fn test_record_note_distillation() {\n        let telemetry = KnowledgeTelemetry;\n        telemetry.record_note_distillation(\"success\", 5, 320.0);\n        telemetry.record_note_distillation(\"failure\", 0, 100.0);\n    }\n\n    #[test]\n    fn test_record_hindsight_query() {\n        let telemetry = KnowledgeTelemetry;\n        telemetry.record_hindsight_query(\"success\", 3, 45.5);\n        telemetry.record_hindsight_query(\"failure\", 0, 20.0);\n    }\n\n    #[test]\n    fn test_record_meta_agent_loop() {\n        let telemetry = KnowledgeTelemetry;\n        telemetry.record_meta_agent_loop(\"build\", \"success\", 1, 1500.0);\n        telemetry.record_meta_agent_loop(\"test\", \"failure\", 2, 800.0);\n    }\n\n    #[test]\n    fn test_record_context_assembly() {\n        let telemetry = KnowledgeTelemetry;\n        telemetry.record_context_assembly(\"success\", 3, 1200, 85.5);\n        telemetry.record_context_assembly(\"failure\", 0, 0, 10.0);\n    }\n}\n","traces":[{"line":6,"address":[],"length":0,"stats":{"Line":3}},{"line":11,"address":[],"length":0,"stats":{"Line":3}},{"line":14,"address":[],"length":0,"stats":{"Line":30}},{"line":19,"address":[],"length":0,"stats":{"Line":30}},{"line":22,"address":[],"length":0,"stats":{"Line":2}},{"line":29,"address":[],"length":0,"stats":{"Line":2}},{"line":30,"address":[],"length":0,"stats":{"Line":2}},{"line":31,"address":[],"length":0,"stats":{"Line":2}},{"line":34,"address":[],"length":0,"stats":{"Line":2}},{"line":35,"address":[],"length":0,"stats":{"Line":2}},{"line":36,"address":[],"length":0,"stats":{"Line":2}},{"line":37,"address":[],"length":0,"stats":{"Line":2}},{"line":40,"address":[],"length":0,"stats":{"Line":2}},{"line":41,"address":[],"length":0,"stats":{"Line":2}},{"line":42,"address":[],"length":0,"stats":{"Line":2}},{"line":43,"address":[],"length":0,"stats":{"Line":2}},{"line":46,"address":[],"length":0,"stats":{"Line":2}},{"line":53,"address":[],"length":0,"stats":{"Line":2}},{"line":54,"address":[],"length":0,"stats":{"Line":2}},{"line":55,"address":[],"length":0,"stats":{"Line":2}},{"line":58,"address":[],"length":0,"stats":{"Line":2}},{"line":65,"address":[],"length":0,"stats":{"Line":2}},{"line":66,"address":[],"length":0,"stats":{"Line":2}},{"line":67,"address":[],"length":0,"stats":{"Line":2}},{"line":68,"address":[],"length":0,"stats":{"Line":2}}],"covered":25,"coverable":25},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","tools.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","validator.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","working.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","backend.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","bridge.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","circuit_breaker.rs"],"content":"use std::sync::Arc;\nuse std::sync::atomic::{AtomicBool, AtomicU64, Ordering};\nuse tokio::sync::RwLock;\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum CircuitState {\n    Closed,\n    Open,\n    HalfOpen,\n}\n\npub struct CircuitBreakerConfig {\n    pub failure_threshold_percent: f64,\n    pub window_duration_secs: u64,\n    pub min_requests_in_window: u64,\n    pub recovery_timeout_secs: u64,\n    pub half_open_max_requests: u64,\n}\n\nimpl Default for CircuitBreakerConfig {\n    fn default() -> Self {\n        Self {\n            failure_threshold_percent: 5.0,\n            window_duration_secs: 300,\n            min_requests_in_window: 10,\n            recovery_timeout_secs: 60,\n            half_open_max_requests: 3,\n        }\n    }\n}\n\nstruct WindowMetrics {\n    successes: u64,\n    failures: u64,\n    window_start: i64,\n}\n\nimpl WindowMetrics {\n    fn new() -> Self {\n        Self {\n            successes: 0,\n            failures: 0,\n            window_start: chrono::Utc::now().timestamp(),\n        }\n    }\n\n    fn total(&self) -> u64 {\n        self.successes + self.failures\n    }\n\n    fn failure_rate(&self) -> f64 {\n        if self.total() == 0 {\n            return 0.0;\n        }\n        (self.failures as f64 / self.total() as f64) * 100.0\n    }\n\n    fn reset(&mut self) {\n        self.successes = 0;\n        self.failures = 0;\n        self.window_start = chrono::Utc::now().timestamp();\n    }\n}\n\npub struct ReasoningCircuitBreaker {\n    config: CircuitBreakerConfig,\n    state: RwLock<CircuitState>,\n    metrics: RwLock<WindowMetrics>,\n    opened_at: AtomicU64,\n    half_open_requests: AtomicU64,\n    is_open: AtomicBool,\n    telemetry: Arc<crate::telemetry::MemoryTelemetry>,\n}\n\nimpl ReasoningCircuitBreaker {\n    pub fn new(\n        config: CircuitBreakerConfig,\n        telemetry: Arc<crate::telemetry::MemoryTelemetry>,\n    ) -> Self {\n        Self {\n            config,\n            state: RwLock::new(CircuitState::Closed),\n            metrics: RwLock::new(WindowMetrics::new()),\n            opened_at: AtomicU64::new(0),\n            half_open_requests: AtomicU64::new(0),\n            is_open: AtomicBool::new(false),\n            telemetry,\n        }\n    }\n\n    pub async fn is_allowed(&self) -> bool {\n        let state = *self.state.read().await;\n        match state {\n            CircuitState::Closed => true,\n            CircuitState::Open => {\n                let opened_at = self.opened_at.load(Ordering::SeqCst);\n                let now = chrono::Utc::now().timestamp() as u64;\n                if now >= opened_at + self.config.recovery_timeout_secs {\n                    self.transition_to_half_open().await;\n                    let current = self.half_open_requests.fetch_add(1, Ordering::SeqCst);\n                    current < self.config.half_open_max_requests\n                } else {\n                    false\n                }\n            }\n            CircuitState::HalfOpen => {\n                let current = self.half_open_requests.fetch_add(1, Ordering::SeqCst);\n                current < self.config.half_open_max_requests\n            }\n        }\n    }\n\n    pub async fn record_success(&self) {\n        let mut state = self.state.write().await;\n\n        match *state {\n            CircuitState::Closed => {\n                self.maybe_reset_window().await;\n                let mut metrics = self.metrics.write().await;\n                metrics.successes += 1;\n            }\n            CircuitState::HalfOpen => {\n                *state = CircuitState::Closed;\n                self.is_open.store(false, Ordering::SeqCst);\n                self.half_open_requests.store(0, Ordering::SeqCst);\n                let mut metrics = self.metrics.write().await;\n                metrics.reset();\n                self.telemetry.record_reasoning_circuit_closed();\n                tracing::info!(\n                    \"Reasoning circuit breaker closed after successful half-open request\"\n                );\n            }\n            CircuitState::Open => {}\n        }\n    }\n\n    pub async fn record_failure(&self, error: &str) {\n        let mut state = self.state.write().await;\n\n        self.telemetry.record_reasoning_failure(error);\n        tracing::warn!(error = error, \"Reasoning failure recorded\");\n\n        match *state {\n            CircuitState::Closed => {\n                self.maybe_reset_window().await;\n                let mut metrics = self.metrics.write().await;\n                metrics.failures += 1;\n\n                if metrics.total() >= self.config.min_requests_in_window\n                    && metrics.failure_rate() >= self.config.failure_threshold_percent\n                {\n                    drop(metrics);\n                    *state = CircuitState::Open;\n                    self.opened_at\n                        .store(chrono::Utc::now().timestamp() as u64, Ordering::SeqCst);\n                    self.is_open.store(true, Ordering::SeqCst);\n                    self.telemetry\n                        .record_reasoning_circuit_opened(self.metrics.read().await.failure_rate());\n                    tracing::error!(\n                        \"Reasoning circuit breaker OPENED - failure rate exceeded threshold\"\n                    );\n                }\n            }\n            CircuitState::HalfOpen => {\n                *state = CircuitState::Open;\n                self.opened_at\n                    .store(chrono::Utc::now().timestamp() as u64, Ordering::SeqCst);\n                self.half_open_requests.store(0, Ordering::SeqCst);\n                self.telemetry.record_reasoning_circuit_opened(100.0);\n                tracing::error!(\"Reasoning circuit breaker re-OPENED after half-open failure\");\n            }\n            CircuitState::Open => {}\n        }\n    }\n\n    async fn transition_to_half_open(&self) {\n        let mut state = self.state.write().await;\n        if *state == CircuitState::Open {\n            *state = CircuitState::HalfOpen;\n            self.half_open_requests.store(0, Ordering::SeqCst);\n            self.telemetry.record_reasoning_circuit_half_open();\n            tracing::info!(\"Reasoning circuit breaker transitioned to HALF-OPEN\");\n        }\n    }\n\n    async fn maybe_reset_window(&self) {\n        let now = chrono::Utc::now().timestamp();\n        let metrics = self.metrics.read().await;\n        if now - metrics.window_start >= self.config.window_duration_secs as i64 {\n            drop(metrics);\n            let mut metrics = self.metrics.write().await;\n            if now - metrics.window_start >= self.config.window_duration_secs as i64 {\n                metrics.reset();\n            }\n        }\n    }\n\n    pub async fn state(&self) -> CircuitState {\n        *self.state.read().await\n    }\n\n    pub fn is_open_fast(&self) -> bool {\n        self.is_open.load(Ordering::SeqCst)\n    }\n\n    pub async fn get_metrics(&self) -> (u64, u64, f64) {\n        let metrics = self.metrics.read().await;\n        (metrics.successes, metrics.failures, metrics.failure_rate())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    fn test_telemetry() -> Arc<crate::telemetry::MemoryTelemetry> {\n        Arc::new(crate::telemetry::MemoryTelemetry::new())\n    }\n\n    #[tokio::test]\n    async fn test_circuit_breaker_closed_allows_requests() {\n        let cb = ReasoningCircuitBreaker::new(CircuitBreakerConfig::default(), test_telemetry());\n        assert!(cb.is_allowed().await);\n        assert_eq!(cb.state().await, CircuitState::Closed);\n    }\n\n    #[tokio::test]\n    async fn test_circuit_breaker_opens_on_threshold() {\n        let config = CircuitBreakerConfig {\n            failure_threshold_percent: 50.0,\n            min_requests_in_window: 4,\n            window_duration_secs: 300,\n            recovery_timeout_secs: 60,\n            half_open_max_requests: 3,\n        };\n        let cb = ReasoningCircuitBreaker::new(config, test_telemetry());\n\n        cb.record_success().await;\n        cb.record_success().await;\n        cb.record_failure(\"error1\").await;\n        assert_eq!(cb.state().await, CircuitState::Closed);\n\n        cb.record_failure(\"error2\").await;\n        assert_eq!(cb.state().await, CircuitState::Open);\n        assert!(!cb.is_allowed().await);\n    }\n\n    #[tokio::test]\n    async fn test_circuit_breaker_half_open_after_timeout() {\n        let config = CircuitBreakerConfig {\n            failure_threshold_percent: 50.0,\n            min_requests_in_window: 2,\n            window_duration_secs: 300,\n            recovery_timeout_secs: 0,\n            half_open_max_requests: 3,\n        };\n        let cb = ReasoningCircuitBreaker::new(config, test_telemetry());\n\n        cb.record_failure(\"error1\").await;\n        cb.record_failure(\"error2\").await;\n        assert_eq!(cb.state().await, CircuitState::Open);\n\n        tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;\n\n        assert!(cb.is_allowed().await);\n        assert_eq!(cb.state().await, CircuitState::HalfOpen);\n    }\n\n    #[tokio::test]\n    async fn test_circuit_breaker_closes_on_half_open_success() {\n        let config = CircuitBreakerConfig {\n            failure_threshold_percent: 50.0,\n            min_requests_in_window: 2,\n            window_duration_secs: 300,\n            recovery_timeout_secs: 0,\n            half_open_max_requests: 3,\n        };\n        let cb = ReasoningCircuitBreaker::new(config, test_telemetry());\n\n        cb.record_failure(\"error1\").await;\n        cb.record_failure(\"error2\").await;\n\n        tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;\n        cb.is_allowed().await;\n\n        cb.record_success().await;\n        assert_eq!(cb.state().await, CircuitState::Closed);\n    }\n\n    #[tokio::test]\n    async fn test_circuit_breaker_reopens_on_half_open_failure() {\n        let config = CircuitBreakerConfig {\n            failure_threshold_percent: 50.0,\n            min_requests_in_window: 2,\n            window_duration_secs: 300,\n            recovery_timeout_secs: 0,\n            half_open_max_requests: 3,\n        };\n        let cb = ReasoningCircuitBreaker::new(config, test_telemetry());\n\n        cb.record_failure(\"error1\").await;\n        cb.record_failure(\"error2\").await;\n\n        tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;\n        cb.is_allowed().await;\n\n        cb.record_failure(\"error3\").await;\n        assert_eq!(cb.state().await, CircuitState::Open);\n    }\n\n    #[tokio::test]\n    async fn test_circuit_breaker_limits_half_open_requests() {\n        let config = CircuitBreakerConfig {\n            failure_threshold_percent: 50.0,\n            min_requests_in_window: 2,\n            window_duration_secs: 300,\n            recovery_timeout_secs: 0,\n            half_open_max_requests: 2,\n        };\n        let cb = ReasoningCircuitBreaker::new(config, test_telemetry());\n\n        cb.record_failure(\"error1\").await;\n        cb.record_failure(\"error2\").await;\n\n        tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;\n\n        assert!(cb.is_allowed().await);\n        assert!(cb.is_allowed().await);\n        assert!(!cb.is_allowed().await);\n    }\n\n    #[tokio::test]\n    async fn test_circuit_breaker_metrics() {\n        let cb = ReasoningCircuitBreaker::new(CircuitBreakerConfig::default(), test_telemetry());\n\n        cb.record_success().await;\n        cb.record_success().await;\n        cb.record_failure(\"error\").await;\n\n        let (successes, failures, rate) = cb.get_metrics().await;\n        assert_eq!(successes, 2);\n        assert_eq!(failures, 1);\n        assert!((rate - 33.33).abs() < 1.0);\n    }\n\n    #[test]\n    fn test_is_open_fast() {\n        let cb = ReasoningCircuitBreaker::new(CircuitBreakerConfig::default(), test_telemetry());\n        assert!(!cb.is_open_fast());\n    }\n}\n","traces":[{"line":21,"address":[],"length":0,"stats":{"Line":3}},{"line":39,"address":[],"length":0,"stats":{"Line":35}},{"line":43,"address":[],"length":0,"stats":{"Line":35}},{"line":47,"address":[],"length":0,"stats":{"Line":35}},{"line":48,"address":[],"length":0,"stats":{"Line":35}},{"line":51,"address":[],"length":0,"stats":{"Line":11}},{"line":52,"address":[],"length":0,"stats":{"Line":11}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":22}},{"line":58,"address":[],"length":0,"stats":{"Line":1}},{"line":59,"address":[],"length":0,"stats":{"Line":1}},{"line":60,"address":[],"length":0,"stats":{"Line":1}},{"line":61,"address":[],"length":0,"stats":{"Line":1}},{"line":76,"address":[],"length":0,"stats":{"Line":35}},{"line":82,"address":[],"length":0,"stats":{"Line":105}},{"line":83,"address":[],"length":0,"stats":{"Line":105}},{"line":84,"address":[],"length":0,"stats":{"Line":70}},{"line":85,"address":[],"length":0,"stats":{"Line":70}},{"line":86,"address":[],"length":0,"stats":{"Line":35}},{"line":91,"address":[],"length":0,"stats":{"Line":88}},{"line":92,"address":[],"length":0,"stats":{"Line":176}},{"line":93,"address":[],"length":0,"stats":{"Line":44}},{"line":94,"address":[],"length":0,"stats":{"Line":37}},{"line":96,"address":[],"length":0,"stats":{"Line":20}},{"line":97,"address":[],"length":0,"stats":{"Line":10}},{"line":98,"address":[],"length":0,"stats":{"Line":10}},{"line":99,"address":[],"length":0,"stats":{"Line":8}},{"line":100,"address":[],"length":0,"stats":{"Line":16}},{"line":101,"address":[],"length":0,"stats":{"Line":4}},{"line":103,"address":[],"length":0,"stats":{"Line":1}},{"line":107,"address":[],"length":0,"stats":{"Line":8}},{"line":108,"address":[],"length":0,"stats":{"Line":2}},{"line":113,"address":[],"length":0,"stats":{"Line":62}},{"line":114,"address":[],"length":0,"stats":{"Line":93}},{"line":116,"address":[],"length":0,"stats":{"Line":31}},{"line":118,"address":[],"length":0,"stats":{"Line":60}},{"line":119,"address":[],"length":0,"stats":{"Line":90}},{"line":120,"address":[],"length":0,"stats":{"Line":30}},{"line":123,"address":[],"length":0,"stats":{"Line":1}},{"line":124,"address":[],"length":0,"stats":{"Line":3}},{"line":125,"address":[],"length":0,"stats":{"Line":3}},{"line":126,"address":[],"length":0,"stats":{"Line":3}},{"line":127,"address":[],"length":0,"stats":{"Line":1}},{"line":128,"address":[],"length":0,"stats":{"Line":1}},{"line":129,"address":[],"length":0,"stats":{"Line":1}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":28}},{"line":138,"address":[],"length":0,"stats":{"Line":42}},{"line":140,"address":[],"length":0,"stats":{"Line":28}},{"line":141,"address":[],"length":0,"stats":{"Line":14}},{"line":143,"address":[],"length":0,"stats":{"Line":14}},{"line":145,"address":[],"length":0,"stats":{"Line":26}},{"line":146,"address":[],"length":0,"stats":{"Line":39}},{"line":147,"address":[],"length":0,"stats":{"Line":13}},{"line":149,"address":[],"length":0,"stats":{"Line":13}},{"line":150,"address":[],"length":0,"stats":{"Line":5}},{"line":152,"address":[],"length":0,"stats":{"Line":10}},{"line":153,"address":[],"length":0,"stats":{"Line":5}},{"line":154,"address":[],"length":0,"stats":{"Line":5}},{"line":155,"address":[],"length":0,"stats":{"Line":15}},{"line":156,"address":[],"length":0,"stats":{"Line":15}},{"line":157,"address":[],"length":0,"stats":{"Line":5}},{"line":158,"address":[],"length":0,"stats":{"Line":25}},{"line":159,"address":[],"length":0,"stats":{"Line":5}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":1}},{"line":166,"address":[],"length":0,"stats":{"Line":1}},{"line":167,"address":[],"length":0,"stats":{"Line":3}},{"line":168,"address":[],"length":0,"stats":{"Line":3}},{"line":169,"address":[],"length":0,"stats":{"Line":1}},{"line":170,"address":[],"length":0,"stats":{"Line":1}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":8}},{"line":177,"address":[],"length":0,"stats":{"Line":12}},{"line":178,"address":[],"length":0,"stats":{"Line":4}},{"line":179,"address":[],"length":0,"stats":{"Line":4}},{"line":180,"address":[],"length":0,"stats":{"Line":12}},{"line":181,"address":[],"length":0,"stats":{"Line":4}},{"line":182,"address":[],"length":0,"stats":{"Line":4}},{"line":186,"address":[],"length":0,"stats":{"Line":86}},{"line":187,"address":[],"length":0,"stats":{"Line":129}},{"line":188,"address":[],"length":0,"stats":{"Line":129}},{"line":189,"address":[],"length":0,"stats":{"Line":43}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":14}},{"line":199,"address":[],"length":0,"stats":{"Line":21}},{"line":202,"address":[],"length":0,"stats":{"Line":1}},{"line":203,"address":[],"length":0,"stats":{"Line":3}},{"line":206,"address":[],"length":0,"stats":{"Line":2}},{"line":207,"address":[],"length":0,"stats":{"Line":3}},{"line":208,"address":[],"length":0,"stats":{"Line":3}}],"covered":86,"coverable":95},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","config.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","ecosystem.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","embedding","mock.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::EmbeddingService;\n\npub struct MockEmbeddingService {\n    dimension: usize,\n}\n\nimpl MockEmbeddingService {\n    pub fn new(dimension: usize) -> Self {\n        Self { dimension }\n    }\n\n    fn generate_mock_embedding(text: &str) -> Vec<f32> {\n        let mut embedding = vec![0.0; 384];\n        let text_lower = text.to_lowercase();\n\n        if text_lower.contains(\"rust\") {\n            embedding[0] = 0.8;\n            embedding[1] = 0.6;\n        }\n        if text_lower.contains(\"typescript\") || text_lower.contains(\"javascript\") {\n            embedding[2] = 0.7;\n            embedding[3] = 0.5;\n        }\n        if text_lower.contains(\"python\") {\n            embedding[4] = 0.9;\n            embedding[5] = 0.4;\n        }\n        if text_lower.contains(\"database\") {\n            embedding[6] = 0.6;\n            embedding[7] = 0.7;\n        }\n        if text_lower.contains(\"api\") {\n            embedding[8] = 0.5;\n            embedding[9] = 0.8;\n        }\n\n        let length_factor = (text.len() as f32).min(1000.0) / 1000.0;\n        embedding[10] = length_factor;\n\n        embedding\n    }\n}\n\n#[async_trait]\nimpl EmbeddingService for MockEmbeddingService {\n    type Error = Box<dyn std::error::Error + Send + Sync>;\n\n    async fn embed(&self, text: &str) -> Result<Vec<f32>, Self::Error> {\n        Ok(Self::generate_mock_embedding(text))\n    }\n\n    fn dimension(&self) -> usize {\n        self.dimension\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_mock_embedding_service() {\n        let service = MockEmbeddingService::new(384);\n\n        let embedding1 = service.embed(\"Rust programming language\").await.unwrap();\n        assert_eq!(embedding1.len(), 384);\n        assert!(embedding1[0] > 0.0);\n        assert!(embedding1[1] > 0.0);\n\n        let embedding2 = service.embed(\"Python data science\").await.unwrap();\n        assert_eq!(embedding2.len(), 384);\n        assert!(embedding2[4] > 0.0);\n        assert!(embedding2[5] > 0.0);\n\n        assert_ne!(embedding1, embedding2);\n    }\n\n    #[tokio::test]\n    async fn test_mock_embedding_service_batch() {\n        let service = MockEmbeddingService::new(384);\n\n        let texts = vec![\n            \"Rust programming\".to_string(),\n            \"Python scripting\".to_string(),\n            \"Database management\".to_string(),\n        ];\n\n        let embeddings = service.embed_batch(&texts).await.unwrap();\n        assert_eq!(embeddings.len(), 3);\n        for embedding in embeddings {\n            assert_eq!(embedding.len(), 384);\n        }\n    }\n\n    #[tokio::test]\n    async fn test_mock_embedding_dimension() {\n        let service = MockEmbeddingService::new(512);\n        assert_eq!(service.dimension(), 512);\n\n        let service2 = MockEmbeddingService::new(1024);\n        assert_eq!(service2.dimension(), 1024);\n    }\n\n    #[tokio::test]\n    async fn test_mock_embedding_typescript_javascript() {\n        let service = MockEmbeddingService::new(384);\n\n        let ts_embedding = service.embed(\"TypeScript framework\").await.unwrap();\n        assert!(ts_embedding[2] > 0.0);\n        assert!(ts_embedding[3] > 0.0);\n\n        let js_embedding = service.embed(\"JavaScript library\").await.unwrap();\n        assert!(js_embedding[2] > 0.0);\n        assert!(js_embedding[3] > 0.0);\n    }\n\n    #[tokio::test]\n    async fn test_mock_embedding_database() {\n        let service = MockEmbeddingService::new(384);\n        let embedding = service.embed(\"Database management system\").await.unwrap();\n        assert!(embedding[6] > 0.0);\n        assert!(embedding[7] > 0.0);\n    }\n\n    #[tokio::test]\n    async fn test_mock_embedding_api() {\n        let service = MockEmbeddingService::new(384);\n        let embedding = service.embed(\"API endpoint design\").await.unwrap();\n        assert!(embedding[8] > 0.0);\n        assert!(embedding[9] > 0.0);\n    }\n\n    #[tokio::test]\n    async fn test_mock_embedding_length_factor() {\n        let service = MockEmbeddingService::new(384);\n\n        let short_text = service.embed(\"short\").await.unwrap();\n        let long_text = service.embed(&\"a\".repeat(500)).await.unwrap();\n\n        assert!(long_text[10] > short_text[10]);\n    }\n}\n","traces":[{"line":9,"address":[],"length":0,"stats":{"Line":37}},{"line":13,"address":[],"length":0,"stats":{"Line":52}},{"line":14,"address":[],"length":0,"stats":{"Line":104}},{"line":15,"address":[],"length":0,"stats":{"Line":156}},{"line":17,"address":[],"length":0,"stats":{"Line":58}},{"line":18,"address":[],"length":0,"stats":{"Line":12}},{"line":19,"address":[],"length":0,"stats":{"Line":6}},{"line":21,"address":[],"length":0,"stats":{"Line":105}},{"line":22,"address":[],"length":0,"stats":{"Line":4}},{"line":23,"address":[],"length":0,"stats":{"Line":2}},{"line":25,"address":[],"length":0,"stats":{"Line":54}},{"line":26,"address":[],"length":0,"stats":{"Line":4}},{"line":27,"address":[],"length":0,"stats":{"Line":2}},{"line":29,"address":[],"length":0,"stats":{"Line":55}},{"line":30,"address":[],"length":0,"stats":{"Line":6}},{"line":31,"address":[],"length":0,"stats":{"Line":3}},{"line":33,"address":[],"length":0,"stats":{"Line":53}},{"line":34,"address":[],"length":0,"stats":{"Line":2}},{"line":35,"address":[],"length":0,"stats":{"Line":1}},{"line":38,"address":[],"length":0,"stats":{"Line":104}},{"line":39,"address":[],"length":0,"stats":{"Line":52}},{"line":41,"address":[],"length":0,"stats":{"Line":52}},{"line":49,"address":[],"length":0,"stats":{"Line":52}},{"line":53,"address":[],"length":0,"stats":{"Line":2}},{"line":54,"address":[],"length":0,"stats":{"Line":2}}],"covered":25,"coverable":25},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","embedding","mod.rs"],"content":"pub mod mock;\npub mod openai;\n\npub use mock::MockEmbeddingService;\npub use openai::OpenAIEmbeddingService;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","embedding","openai.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::EmbeddingService;\nuse std::sync::Arc;\nuse storage::redis::RedisStorage;\nuse tokio::sync::RwLock;\n\npub struct OpenAIEmbeddingService {\n    client: async_openai::Client<async_openai::config::OpenAIConfig>,\n    model: String,\n    dimension: usize,\n    cache: Arc<RwLock<lru::LruCache<String, Vec<f32>>>>,\n    redis: Option<Arc<RwLock<RedisStorage>>>,\n}\n\nimpl OpenAIEmbeddingService {\n    pub fn new(api_key: String, model: &str) -> Self {\n        let config = async_openai::config::OpenAIConfig::new().with_api_key(api_key);\n        let client = async_openai::Client::with_config(config);\n\n        let dimension = match model {\n            \"text-embedding-ada-002\" => 1536,\n            \"text-embedding-3-small\" => 1536,\n            \"text-embedding-3-large\" => 3072,\n            _ => 1536,\n        };\n\n        Self {\n            client,\n            model: model.to_string(),\n            dimension,\n            cache: Arc::new(RwLock::new(lru::LruCache::new(\n                std::num::NonZeroUsize::new(1000).unwrap(),\n            ))),\n            redis: None,\n        }\n    }\n\n    pub fn with_redis(mut self, redis: Arc<RwLock<RedisStorage>>) -> Self {\n        self.redis = Some(redis);\n        self\n    }\n\n    pub fn with_cache_size(api_key: String, model: &str, cache_size: usize) -> Self {\n        let config = async_openai::config::OpenAIConfig::new().with_api_key(api_key);\n        let client = async_openai::Client::with_config(config);\n\n        let dimension = match model {\n            \"text-embedding-ada-002\" => 1536,\n            \"text-embedding-3-small\" => 1536,\n            \"text-embedding-3-large\" => 3072,\n            _ => 1536,\n        };\n\n        Self {\n            client,\n            model: model.to_string(),\n            dimension,\n            cache: Arc::new(RwLock::new(lru::LruCache::new(\n                std::num::NonZeroUsize::new(cache_size).unwrap(),\n            ))),\n            redis: None,\n        }\n    }\n\n    pub fn with_default_model(api_key: String) -> Self {\n        Self::new(api_key, \"text-embedding-ada-002\")\n    }\n}\n\n#[async_trait]\nimpl EmbeddingService for OpenAIEmbeddingService {\n    type Error = Box<dyn std::error::Error + Send + Sync>;\n\n    async fn embed(&self, text: &str) -> Result<Vec<f32>, Self::Error> {\n        {\n            let mut cache = self.cache.write().await;\n            if let Some(cached) = cache.get(text) {\n                return Ok(cached.clone());\n            }\n        }\n\n        if let Some(redis) = &self.redis {\n            let redis = redis.write().await;\n            let key = format!(\"emb:{}:{}\", self.model, text);\n            if let Ok(Some(cached_json)) = redis.get(&key).await {\n                if let Ok(embedding) = serde_json::from_str::<Vec<f32>>(&cached_json) {\n                    let mut cache = self.cache.write().await;\n                    cache.put(text.to_string(), embedding.clone());\n                    return Ok(embedding);\n                }\n            }\n        }\n\n        let request = async_openai::types::CreateEmbeddingRequestArgs::default()\n            .model(&self.model)\n            .input(text)\n            .build()?;\n\n        let response = self.client.embeddings().create(request).await?;\n\n        let embedding = response\n            .data\n            .first()\n            .ok_or(\"No embedding returned\")?\n            .embedding\n            .clone();\n\n        {\n            let mut cache = self.cache.write().await;\n            cache.put(text.to_string(), embedding.clone());\n        }\n\n        if let Some(redis) = &self.redis {\n            let redis = redis.write().await;\n            let key = format!(\"emb:{}:{}\", self.model, text);\n            if let Ok(json) = serde_json::to_string(&embedding) {\n                let _ = redis.set(&key, &json, Some(86400)).await;\n            }\n        }\n\n        Ok(embedding)\n    }\n\n    fn dimension(&self) -> usize {\n        self.dimension\n    }\n\n    async fn embed_batch(&self, texts: &[String]) -> Result<Vec<Vec<f32>>, Self::Error> {\n        let mut results = Vec::with_capacity(texts.len());\n        let mut uncached_texts = Vec::new();\n        let mut uncached_indices = Vec::new();\n\n        let mut cache = self.cache.write().await;\n\n        for (i, text) in texts.iter().enumerate() {\n            if let Some(cached) = cache.get(text) {\n                results.push(cached.clone());\n            } else {\n                results.push(Vec::new());\n                uncached_texts.push(text.clone());\n                uncached_indices.push(i);\n            }\n        }\n\n        if !uncached_texts.is_empty() {\n            let request = async_openai::types::CreateEmbeddingRequestArgs::default()\n                .model(&self.model)\n                .input(uncached_texts.clone())\n                .build()?;\n\n            let response = self.client.embeddings().create(request).await?;\n\n            for (i, embedding_data) in response.data.into_iter().enumerate() {\n                let idx = uncached_indices[i];\n                let text: &String = &uncached_texts[i];\n                let embedding = embedding_data.embedding;\n\n                cache.put(text.clone(), embedding.clone());\n                results[idx] = embedding;\n            }\n        }\n\n        Ok(results)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[tokio::test]\n    #[ignore = \"Requires OpenAI API key\"]\n    async fn test_openai_embedding_service() {\n        let api_key = std::env::var(\"OPENAI_API_KEY\").unwrap_or_default();\n        if api_key.is_empty() {\n            return;\n        }\n\n        let service = OpenAIEmbeddingService::with_default_model(api_key);\n\n        let embedding = service.embed(\"Test text\").await.unwrap();\n        assert_eq!(embedding.len(), 1536);\n        assert!(service.dimension() == 1536);\n\n        let texts = vec![\"First text\".to_string(), \"Second text\".to_string()];\n        let embeddings = service.embed_batch(&texts).await.unwrap();\n        assert_eq!(embeddings.len(), 2);\n        for embedding in embeddings {\n            assert_eq!(embedding.len(), 1536);\n        }\n    }\n\n    #[tokio::test]\n    async fn test_lru_cache_hit() {\n        let service = OpenAIEmbeddingService::with_cache_size(\n            \"sk-fake-key\".to_string(),\n            \"text-embedding-ada-002\",\n            10,\n        );\n\n        let mut cache = service.cache.write().await;\n\n        let test_vector = vec![0.1; 1536];\n        cache.put(\"test_text\".to_string(), test_vector.clone());\n\n        let cached = cache.get(\"test_text\");\n        assert!(cached.is_some(), \"Cached value should be found\");\n        assert_eq!(*cached.unwrap(), *test_vector, \"Cached vector should match\");\n    }\n\n    #[tokio::test]\n    async fn test_lru_cache_miss() {\n        let service = OpenAIEmbeddingService::with_cache_size(\n            \"sk-fake-key\".to_string(),\n            \"text-embedding-ada-002\",\n            10,\n        );\n\n        let mut cache = service.cache.write().await;\n\n        let cached = cache.get(\"nonexistent_text\");\n        assert!(cached.is_none(), \"Should return None for nonexistent key\");\n    }\n\n    #[test]\n    fn test_dimension_configuration() {\n        let service = OpenAIEmbeddingService::new(\"sk-test\".to_string(), \"text-embedding-ada-002\");\n        assert_eq!(\n            service.dimension(),\n            1536,\n            \"ada-002 should have 1536 dimensions\"\n        );\n\n        let service = OpenAIEmbeddingService::new(\"sk-test\".to_string(), \"text-embedding-3-small\");\n        assert_eq!(\n            service.dimension(),\n            1536,\n            \"3-small should have 1536 dimensions\"\n        );\n\n        let service = OpenAIEmbeddingService::new(\"sk-test\".to_string(), \"text-embedding-3-large\");\n        assert_eq!(\n            service.dimension(),\n            3072,\n            \"3-large should have 3072 dimensions\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_custom_cache_size() {\n        let service = OpenAIEmbeddingService::with_cache_size(\n            \"sk-test\".to_string(),\n            \"text-embedding-ada-002\",\n            500,\n        );\n\n        let cache = service.cache.read().await;\n        assert_eq!(cache.cap().get(), 500, \"Cache capacity should be 500\");\n    }\n}\n","traces":[{"line":16,"address":[],"length":0,"stats":{"Line":3}},{"line":17,"address":[],"length":0,"stats":{"Line":12}},{"line":18,"address":[],"length":0,"stats":{"Line":9}},{"line":20,"address":[],"length":0,"stats":{"Line":6}},{"line":21,"address":[],"length":0,"stats":{"Line":4}},{"line":22,"address":[],"length":0,"stats":{"Line":3}},{"line":23,"address":[],"length":0,"stats":{"Line":2}},{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":29,"address":[],"length":0,"stats":{"Line":9}},{"line":31,"address":[],"length":0,"stats":{"Line":12}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":3}},{"line":44,"address":[],"length":0,"stats":{"Line":12}},{"line":45,"address":[],"length":0,"stats":{"Line":9}},{"line":47,"address":[],"length":0,"stats":{"Line":6}},{"line":48,"address":[],"length":0,"stats":{"Line":6}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":9}},{"line":58,"address":[],"length":0,"stats":{"Line":12}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":3}},{"line":125,"address":[],"length":0,"stats":{"Line":3}},{"line":128,"address":[],"length":0,"stats":{"Line":0}}],"covered":18,"coverable":29},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","episodic.rs"],"content":"\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","error.rs"],"content":"use thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum MemoryError {\n    #[error(\"Provider error: {0}\")]\n    ProviderError(String),\n\n    #[error(\"Embedding error: {0}\")]\n    EmbeddingError(String),\n\n    #[error(\"Validation error: {0}\")]\n    ValidationError(String),\n\n    #[error(\"Storage error: {0}\")]\n    StorageError(String),\n\n    #[error(\"Network error: {0}\")]\n    NetworkError(String),\n\n    #[error(\"Timeout error: {0}\")]\n    TimeoutError(String),\n\n    #[error(\"Configuration error: {0}\")]\n    ConfigError(String),\n\n    #[error(\"Serialization error: {0}\")]\n    SerializationError(String),\n\n    #[error(\"Resource not found: {0}\")]\n    NotFound(String),\n\n    #[error(\"Unauthorized access: {0}\")]\n    Unauthorized(String),\n\n    #[error(\"Rate limited: {0}\")]\n    RateLimited(String),\n\n    #[error(\"Internal error: {0}\")]\n    InternalError(String),\n}\n\nimpl MemoryError {\n    pub fn is_retryable(&self) -> bool {\n        match self {\n            MemoryError::NetworkError(_)\n            | MemoryError::TimeoutError(_)\n            | MemoryError::RateLimited(_)\n            | MemoryError::ProviderError(_) => true,\n            _ => false,\n        }\n    }\n\n    pub fn should_backoff(&self) -> bool {\n        match self {\n            MemoryError::RateLimited(_) => true,\n            _ => false,\n        }\n    }\n\n    pub fn backoff_duration(&self) -> Option<std::time::Duration> {\n        match self {\n            MemoryError::RateLimited(_) => Some(std::time::Duration::from_secs(5)),\n            MemoryError::NetworkError(_) => Some(std::time::Duration::from_secs(1)),\n            _ => None,\n        }\n    }\n}\n\npub type MemoryResult<T> = Result<T, MemoryError>;\n\n#[allow(async_fn_in_trait)]\npub trait WithRetry {\n    type Output;\n\n    async fn with_retry<F, Fut>(operation: F) -> MemoryResult<Self::Output>\n    where\n        F: Fn() -> Fut,\n        Fut: std::future::Future<Output = MemoryResult<Self::Output>>;\n}\n\npub struct RetryConfig {\n    pub max_retries: usize,\n    pub initial_backoff: std::time::Duration,\n    pub max_backoff: std::time::Duration,\n    pub backoff_multiplier: f32,\n    pub jitter: bool,\n}\n\nimpl Default for RetryConfig {\n    fn default() -> Self {\n        Self {\n            max_retries: 3,\n            initial_backoff: std::time::Duration::from_millis(100),\n            max_backoff: std::time::Duration::from_secs(10),\n            backoff_multiplier: 2.0,\n            jitter: true,\n        }\n    }\n}\n\npub async fn with_retry<F, Fut, T>(operation: F, config: RetryConfig) -> MemoryResult<T>\nwhere\n    F: Fn() -> Fut,\n    Fut: std::future::Future<Output = MemoryResult<T>>,\n{\n    let mut last_error = None;\n    let mut backoff = config.initial_backoff;\n\n    for attempt in 0..=config.max_retries {\n        match operation().await {\n            Ok(result) => return Ok(result),\n            Err(err) => {\n                last_error = Some(err);\n\n                if attempt == config.max_retries {\n                    break;\n                }\n\n                let current_error = last_error.as_ref().unwrap();\n\n                if !current_error.is_retryable() {\n                    break;\n                }\n\n                if let Some(error_backoff) = current_error.backoff_duration() {\n                    tokio::time::sleep(error_backoff).await;\n                } else {\n                    let mut actual_backoff = backoff;\n\n                    if config.jitter {\n                        let jitter = rand::random::<f32>() * 0.3 + 0.85;\n                        actual_backoff = std::time::Duration::from_millis(\n                            (actual_backoff.as_millis() as f32 * jitter) as u64,\n                        );\n                    }\n\n                    tokio::time::sleep(actual_backoff).await;\n\n                    backoff = std::time::Duration::from_millis(\n                        (backoff.as_millis() as f32 * config.backoff_multiplier) as u64,\n                    )\n                    .min(config.max_backoff);\n                }\n            }\n        }\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        MemoryError::InternalError(\"Operation failed after retries\".to_string())\n    }))\n}\n\npub async fn with_exponential_backoff<F, Fut, T>(\n    operation: F,\n    max_retries: usize,\n) -> MemoryResult<T>\nwhere\n    F: Fn() -> Fut,\n    Fut: std::future::Future<Output = MemoryResult<T>>,\n{\n    with_retry(\n        operation,\n        RetryConfig {\n            max_retries,\n            ..Default::default()\n        },\n    )\n    .await\n}\n\npub struct CircuitBreaker {\n    state: std::sync::Arc<tokio::sync::RwLock<CircuitState>>,\n    failure_threshold: usize,\n    reset_timeout: std::time::Duration,\n    _half_open_timeout: std::time::Duration,\n}\n\nenum CircuitState {\n    Closed { failure_count: usize },\n    Open { opened_at: std::time::Instant },\n    HalfOpen,\n}\n\nimpl CircuitBreaker {\n    pub fn new(failure_threshold: usize, reset_timeout: std::time::Duration) -> Self {\n        Self {\n            state: std::sync::Arc::new(tokio::sync::RwLock::new(CircuitState::Closed {\n                failure_count: 0,\n            })),\n            failure_threshold,\n            reset_timeout,\n            _half_open_timeout: reset_timeout / 2,\n        }\n    }\n\n    pub async fn execute<F, Fut, T>(&self, operation: F) -> MemoryResult<T>\n    where\n        F: Fn() -> Fut,\n        Fut: std::future::Future<Output = MemoryResult<T>>,\n    {\n        let state = self.state.read().await;\n\n        match *state {\n            CircuitState::Open { opened_at } => {\n                if opened_at.elapsed() >= self.reset_timeout {\n                    drop(state);\n                    let mut state = self.state.write().await;\n                    *state = CircuitState::HalfOpen;\n                } else {\n                    return Err(MemoryError::NetworkError(\n                        \"Circuit breaker is open\".to_string(),\n                    ));\n                }\n            }\n            CircuitState::HalfOpen => {\n                drop(state);\n            }\n            CircuitState::Closed { .. } => {\n                drop(state);\n            }\n        }\n\n        let result = operation().await;\n\n        let mut state = self.state.write().await;\n        match *state {\n            CircuitState::HalfOpen => {\n                if result.is_ok() {\n                    *state = CircuitState::Closed { failure_count: 0 };\n                } else {\n                    *state = CircuitState::Open {\n                        opened_at: std::time::Instant::now(),\n                    };\n                }\n            }\n            CircuitState::Closed {\n                ref mut failure_count,\n            } => {\n                if result.is_ok() {\n                    *failure_count = 0;\n                } else {\n                    *failure_count += 1;\n                    if *failure_count >= self.failure_threshold {\n                        *state = CircuitState::Open {\n                            opened_at: std::time::Instant::now(),\n                        };\n                    }\n                }\n            }\n            _ => {}\n        }\n\n        result\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::sync::atomic::{AtomicUsize, Ordering};\n\n    #[tokio::test]\n    async fn test_retry_success() {\n        let counter = AtomicUsize::new(0);\n\n        let result = with_retry(\n            || async {\n                let count = counter.fetch_add(1, Ordering::SeqCst);\n                if count < 2 {\n                    Err(MemoryError::NetworkError(\"Temporary failure\".to_string()))\n                } else {\n                    Ok(\"success\")\n                }\n            },\n            RetryConfig::default(),\n        )\n        .await;\n\n        assert_eq!(result.unwrap(), \"success\");\n        assert_eq!(counter.load(Ordering::SeqCst), 3);\n    }\n\n    #[tokio::test]\n    async fn test_retry_non_retryable_error() {\n        let counter = AtomicUsize::new(0);\n\n        let result: Result<&str, _> = with_retry(\n            || async {\n                counter.fetch_add(1, Ordering::SeqCst);\n                Err(MemoryError::ValidationError(\n                    \"Permanent failure\".to_string(),\n                ))\n            },\n            RetryConfig::default(),\n        )\n        .await;\n\n        assert!(result.is_err());\n        assert_eq!(counter.load(Ordering::SeqCst), 1);\n    }\n\n    #[test]\n    fn test_memory_error_retryable() {\n        assert!(MemoryError::NetworkError(\"\".into()).is_retryable());\n        assert!(MemoryError::TimeoutError(\"\".into()).is_retryable());\n        assert!(MemoryError::RateLimited(\"\".into()).is_retryable());\n        assert!(MemoryError::ProviderError(\"\".into()).is_retryable());\n        assert!(!MemoryError::ValidationError(\"\".into()).is_retryable());\n    }\n\n    #[test]\n    fn test_memory_error_backoff() {\n        assert!(MemoryError::RateLimited(\"\".into()).should_backoff());\n        assert!(!MemoryError::NetworkError(\"\".into()).should_backoff());\n\n        assert!(\n            MemoryError::RateLimited(\"\".into())\n                .backoff_duration()\n                .is_some()\n        );\n        assert!(\n            MemoryError::NetworkError(\"\".into())\n                .backoff_duration()\n                .is_some()\n        );\n        assert!(\n            MemoryError::InternalError(\"\".into())\n                .backoff_duration()\n                .is_none()\n        );\n    }\n\n    #[tokio::test]\n    async fn test_with_exponential_backoff() {\n        let counter = AtomicUsize::new(0);\n        let result = with_exponential_backoff(\n            || async {\n                let c = counter.fetch_add(1, Ordering::SeqCst);\n                if c < 1 {\n                    Err(MemoryError::NetworkError(\"\".into()))\n                } else {\n                    Ok(\"ok\")\n                }\n            },\n            2,\n        )\n        .await;\n        assert_eq!(result.unwrap(), \"ok\");\n        assert_eq!(counter.load(Ordering::SeqCst), 2);\n    }\n\n    #[tokio::test]\n    async fn test_circuit_breaker_half_open_failure() {\n        let breaker = CircuitBreaker::new(1, std::time::Duration::from_millis(50));\n\n        // Open it\n        let _: Result<(), _> = breaker\n            .execute(|| async { Err(MemoryError::NetworkError(\"\".into())) })\n            .await;\n\n        // Wait for reset timeout\n        tokio::time::sleep(std::time::Duration::from_millis(60)).await;\n\n        // Half-open attempt fails -> goes back to Open\n        let _: Result<(), _> = breaker\n            .execute(|| async { Err(MemoryError::InternalError(\"\".into())) })\n            .await;\n\n        // Next call should be blocked immediately\n        let result = breaker.execute(|| async { Ok(\"should be blocked\") }).await;\n        assert!(\n            matches!(result, Err(MemoryError::NetworkError(msg)) if msg.contains(\"Circuit breaker is open\"))\n        );\n    }\n\n    #[tokio::test]\n    async fn test_circuit_breaker_half_open_success() {\n        let breaker = CircuitBreaker::new(2, std::time::Duration::from_millis(50));\n\n        // Open it with 2 failures\n        let _: Result<(), _> = breaker\n            .execute(|| async { Err(MemoryError::NetworkError(\"\".into())) })\n            .await;\n        let _: Result<(), _> = breaker\n            .execute(|| async { Err(MemoryError::NetworkError(\"\".into())) })\n            .await;\n\n        // Wait for reset timeout\n        tokio::time::sleep(std::time::Duration::from_millis(60)).await;\n\n        // Half-open attempt succeeds -> goes back to Closed\n        let result = breaker.execute(|| async { Ok(\"success\") }).await;\n        assert_eq!(result.unwrap(), \"success\");\n\n        // Should be closed now, can make another successful call\n        let result = breaker.execute(|| async { Ok(\"another success\") }).await;\n        assert_eq!(result.unwrap(), \"another success\");\n    }\n\n    #[tokio::test]\n    async fn test_circuit_breaker_closed_state_reset_on_success() {\n        let breaker = CircuitBreaker::new(3, std::time::Duration::from_millis(100));\n\n        // Fail once\n        let _: Result<(), _> = breaker\n            .execute(|| async { Err(MemoryError::NetworkError(\"\".into())) })\n            .await;\n\n        // Success should reset failure count\n        let result = breaker.execute(|| async { Ok(\"reset\") }).await;\n        assert_eq!(result.unwrap(), \"reset\");\n\n        // Should still be closed, not open\n        let result = breaker.execute(|| async { Ok(\"still working\") }).await;\n        assert_eq!(result.unwrap(), \"still working\");\n    }\n\n    #[test]\n    fn test_all_error_variants_display() {\n        // Test that all error variants can be formatted\n        let errors = vec![\n            MemoryError::ProviderError(\"test\".to_string()),\n            MemoryError::EmbeddingError(\"test\".to_string()),\n            MemoryError::ValidationError(\"test\".to_string()),\n            MemoryError::StorageError(\"test\".to_string()),\n            MemoryError::NetworkError(\"test\".to_string()),\n            MemoryError::TimeoutError(\"test\".to_string()),\n            MemoryError::ConfigError(\"test\".to_string()),\n            MemoryError::SerializationError(\"test\".to_string()),\n            MemoryError::NotFound(\"test\".to_string()),\n            MemoryError::Unauthorized(\"test\".to_string()),\n            MemoryError::RateLimited(\"test\".to_string()),\n            MemoryError::InternalError(\"test\".to_string()),\n        ];\n\n        for error in errors {\n            let display = error.to_string();\n            assert!(!display.is_empty());\n            assert!(display.contains(\"test\"));\n        }\n    }\n\n    #[tokio::test]\n    async fn test_with_retry_jitter_calculation() {\n        let counter = AtomicUsize::new(0);\n\n        let config = RetryConfig {\n            max_retries: 2,\n            initial_backoff: std::time::Duration::from_millis(100),\n            max_backoff: std::time::Duration::from_secs(1),\n            backoff_multiplier: 2.0,\n            jitter: true,\n        };\n\n        let result = with_retry(\n            || async {\n                let count = counter.fetch_add(1, Ordering::SeqCst);\n                if count < 2 {\n                    Err(MemoryError::NetworkError(\"Temporary\".to_string()))\n                } else {\n                    Ok(\"success with jitter\")\n                }\n            },\n            config,\n        )\n        .await;\n\n        assert_eq!(result.unwrap(), \"success with jitter\");\n        assert_eq!(counter.load(Ordering::SeqCst), 3);\n    }\n\n    #[tokio::test]\n    async fn test_with_retry_error_backoff_takes_precedence() {\n        let counter = AtomicUsize::new(0);\n\n        let result: Result<&str, _> = with_retry(\n            || async {\n                let count = counter.fetch_add(1, Ordering::SeqCst);\n                // RateLimited has its own backoff duration (5 seconds)\n                Err(MemoryError::RateLimited(format!(\"Attempt {}\", count)))\n            },\n            RetryConfig::default(),\n        )\n        .await;\n\n        assert!(result.is_err());\n        // Should fail immediately after max retries since RateLimited has\n        // error-specific backoff\n        assert!(counter.load(Ordering::SeqCst) > 0);\n    }\n\n    // Test implementation of WithRetry trait\n    struct TestRetryable;\n\n    impl WithRetry for TestRetryable {\n        type Output = String;\n\n        async fn with_retry<F, Fut>(operation: F) -> MemoryResult<Self::Output>\n        where\n            F: Fn() -> Fut,\n            Fut: std::future::Future<Output = MemoryResult<Self::Output>>,\n        {\n            with_retry(operation, RetryConfig::default()).await\n        }\n    }\n\n    #[tokio::test]\n    async fn test_with_retry_trait_implementation() {\n        let counter = AtomicUsize::new(0);\n\n        let result = TestRetryable::with_retry(|| async {\n            let count = counter.fetch_add(1, Ordering::SeqCst);\n            if count < 1 {\n                Err(MemoryError::NetworkError(\"Temporary\".to_string()))\n            } else {\n                Ok(\"trait success\".to_string())\n            }\n        })\n        .await;\n\n        assert_eq!(result.unwrap(), \"trait success\");\n        assert_eq!(counter.load(Ordering::SeqCst), 2);\n    }\n\n    #[tokio::test]\n    async fn test_with_retry_no_jitter() {\n        let counter = AtomicUsize::new(0);\n\n        let config = RetryConfig {\n            max_retries: 2,\n            initial_backoff: std::time::Duration::from_millis(10),\n            max_backoff: std::time::Duration::from_millis(100),\n            backoff_multiplier: 2.0,\n            jitter: false,\n        };\n\n        let result = with_retry(\n            || async {\n                let count = counter.fetch_add(1, Ordering::SeqCst);\n                if count < 2 {\n                    Err(MemoryError::NetworkError(\"No jitter retry\".to_string()))\n                } else {\n                    Ok(\"no jitter success\")\n                }\n            },\n            config,\n        )\n        .await;\n\n        assert_eq!(result.unwrap(), \"no jitter success\");\n        assert_eq!(counter.load(Ordering::SeqCst), 3);\n    }\n\n    #[tokio::test]\n    async fn test_with_retry_max_backoff_cap() {\n        let counter = AtomicUsize::new(0);\n\n        let config = RetryConfig {\n            max_retries: 3,\n            initial_backoff: std::time::Duration::from_millis(50),\n            max_backoff: std::time::Duration::from_millis(60),\n            backoff_multiplier: 10.0,\n            jitter: false,\n        };\n\n        let result = with_retry(\n            || async {\n                let count = counter.fetch_add(1, Ordering::SeqCst);\n                if count < 3 {\n                    Err(MemoryError::NetworkError(\"Backoff cap test\".to_string()))\n                } else {\n                    Ok(\"capped backoff success\")\n                }\n            },\n            config,\n        )\n        .await;\n\n        assert_eq!(result.unwrap(), \"capped backoff success\");\n        assert_eq!(counter.load(Ordering::SeqCst), 4);\n    }\n\n    #[tokio::test]\n    async fn test_circuit_breaker_remains_closed_under_threshold() {\n        let breaker = CircuitBreaker::new(3, std::time::Duration::from_millis(100));\n\n        let _: Result<(), _> = breaker\n            .execute(|| async { Err(MemoryError::NetworkError(\"fail 1\".into())) })\n            .await;\n        let _: Result<(), _> = breaker\n            .execute(|| async { Err(MemoryError::NetworkError(\"fail 2\".into())) })\n            .await;\n\n        let result = breaker.execute(|| async { Ok(\"still open\") }).await;\n        assert_eq!(result.unwrap(), \"still open\");\n    }\n\n    #[tokio::test]\n    async fn test_circuit_breaker_opens_at_threshold() {\n        let breaker = CircuitBreaker::new(2, std::time::Duration::from_millis(100));\n\n        let _: Result<(), _> = breaker\n            .execute(|| async { Err(MemoryError::NetworkError(\"fail 1\".into())) })\n            .await;\n        let _: Result<(), _> = breaker\n            .execute(|| async { Err(MemoryError::NetworkError(\"fail 2\".into())) })\n            .await;\n\n        let result = breaker.execute(|| async { Ok(\"should be blocked\") }).await;\n        assert!(matches!(\n            result,\n            Err(MemoryError::NetworkError(msg)) if msg.contains(\"Circuit breaker is open\")\n        ));\n    }\n\n    #[tokio::test]\n    async fn test_circuit_breaker_multiple_successes_after_half_open() {\n        let breaker = CircuitBreaker::new(1, std::time::Duration::from_millis(50));\n\n        let _: Result<(), _> = breaker\n            .execute(|| async { Err(MemoryError::NetworkError(\"open it\".into())) })\n            .await;\n\n        tokio::time::sleep(std::time::Duration::from_millis(60)).await;\n\n        let result1 = breaker.execute(|| async { Ok(\"first success\") }).await;\n        assert_eq!(result1.unwrap(), \"first success\");\n\n        let result2 = breaker.execute(|| async { Ok(\"second success\") }).await;\n        assert_eq!(result2.unwrap(), \"second success\");\n\n        let result3 = breaker.execute(|| async { Ok(\"third success\") }).await;\n        assert_eq!(result3.unwrap(), \"third success\");\n    }\n\n    #[tokio::test]\n    async fn test_with_retry_returns_last_error_on_exhausted_retries() {\n        let counter = AtomicUsize::new(0);\n\n        let config = RetryConfig {\n            max_retries: 2,\n            initial_backoff: std::time::Duration::from_millis(1),\n            max_backoff: std::time::Duration::from_millis(10),\n            backoff_multiplier: 1.0,\n            jitter: false,\n        };\n\n        let result: Result<&str, _> = with_retry(\n            || async {\n                let count = counter.fetch_add(1, Ordering::SeqCst);\n                Err(MemoryError::NetworkError(format!(\"attempt {}\", count)))\n            },\n            config,\n        )\n        .await;\n\n        assert!(result.is_err());\n        match result {\n            Err(MemoryError::NetworkError(msg)) => {\n                assert!(msg.contains(\"attempt\"));\n            }\n            _ => panic!(\"Expected NetworkError\"),\n        }\n    }\n}\n","traces":[{"line":43,"address":[],"length":0,"stats":{"Line":22}},{"line":44,"address":[],"length":0,"stats":{"Line":22}},{"line":48,"address":[],"length":0,"stats":{"Line":20}},{"line":49,"address":[],"length":0,"stats":{"Line":2}},{"line":53,"address":[],"length":0,"stats":{"Line":2}},{"line":54,"address":[],"length":0,"stats":{"Line":2}},{"line":55,"address":[],"length":0,"stats":{"Line":1}},{"line":56,"address":[],"length":0,"stats":{"Line":1}},{"line":60,"address":[],"length":0,"stats":{"Line":19}},{"line":61,"address":[],"length":0,"stats":{"Line":19}},{"line":62,"address":[],"length":0,"stats":{"Line":4}},{"line":63,"address":[],"length":0,"stats":{"Line":14}},{"line":64,"address":[],"length":0,"stats":{"Line":1}},{"line":90,"address":[],"length":0,"stats":{"Line":5}},{"line":93,"address":[],"length":0,"stats":{"Line":5}},{"line":94,"address":[],"length":0,"stats":{"Line":5}},{"line":101,"address":[],"length":0,"stats":{"Line":9}},{"line":106,"address":[],"length":0,"stats":{"Line":18}},{"line":107,"address":[],"length":0,"stats":{"Line":18}},{"line":109,"address":[],"length":0,"stats":{"Line":34}},{"line":110,"address":[],"length":0,"stats":{"Line":50}},{"line":111,"address":[],"length":0,"stats":{"Line":12}},{"line":112,"address":[],"length":0,"stats":{"Line":19}},{"line":113,"address":[],"length":0,"stats":{"Line":38}},{"line":115,"address":[],"length":0,"stats":{"Line":19}},{"line":116,"address":[],"length":0,"stats":{"Line":2}},{"line":119,"address":[],"length":0,"stats":{"Line":68}},{"line":121,"address":[],"length":0,"stats":{"Line":17}},{"line":122,"address":[],"length":0,"stats":{"Line":1}},{"line":125,"address":[],"length":0,"stats":{"Line":32}},{"line":126,"address":[],"length":0,"stats":{"Line":32}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":6}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":1}},{"line":162,"address":[],"length":0,"stats":{"Line":2}},{"line":163,"address":[],"length":0,"stats":{"Line":1}},{"line":164,"address":[],"length":0,"stats":{"Line":1}},{"line":165,"address":[],"length":0,"stats":{"Line":1}},{"line":168,"address":[],"length":0,"stats":{"Line":1}},{"line":185,"address":[],"length":0,"stats":{"Line":6}},{"line":187,"address":[],"length":0,"stats":{"Line":24}},{"line":192,"address":[],"length":0,"stats":{"Line":6}},{"line":196,"address":[],"length":0,"stats":{"Line":20}},{"line":201,"address":[],"length":0,"stats":{"Line":40}},{"line":203,"address":[],"length":0,"stats":{"Line":20}},{"line":204,"address":[],"length":0,"stats":{"Line":5}},{"line":205,"address":[],"length":0,"stats":{"Line":5}},{"line":206,"address":[],"length":0,"stats":{"Line":6}},{"line":207,"address":[],"length":0,"stats":{"Line":6}},{"line":208,"address":[],"length":0,"stats":{"Line":3}},{"line":210,"address":[],"length":0,"stats":{"Line":2}},{"line":211,"address":[],"length":0,"stats":{"Line":2}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":15}},{"line":219,"address":[],"length":0,"stats":{"Line":15}},{"line":223,"address":[],"length":0,"stats":{"Line":36}},{"line":225,"address":[],"length":0,"stats":{"Line":36}},{"line":226,"address":[],"length":0,"stats":{"Line":18}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":8}},{"line":229,"address":[],"length":0,"stats":{"Line":2}},{"line":231,"address":[],"length":0,"stats":{"Line":1}},{"line":232,"address":[],"length":0,"stats":{"Line":1}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":15}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":36}},{"line":240,"address":[],"length":0,"stats":{"Line":6}},{"line":242,"address":[],"length":0,"stats":{"Line":9}},{"line":243,"address":[],"length":0,"stats":{"Line":13}},{"line":244,"address":[],"length":0,"stats":{"Line":4}},{"line":245,"address":[],"length":0,"stats":{"Line":4}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":18}}],"covered":68,"coverable":84},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","governance.rs"],"content":"use serde_json::Value;\n\npub struct GovernanceService {}\n\nimpl GovernanceService {\n    pub fn new() -> Self {\n        Self {}\n    }\n\n    pub fn redact_pii(&self, content: &str) -> String {\n        utils::redact_pii(content)\n    }\n\n    pub fn is_sensitive(&self, metadata: &Value) -> bool {\n        if let Some(obj) = metadata.as_object() {\n            if let Some(sensitive) = obj.get(\"sensitive\") {\n                if let Some(b) = sensitive.as_bool() {\n                    if b {\n                        return true;\n                    }\n                }\n            }\n            if let Some(private) = obj.get(\"private\") {\n                if let Some(b) = private.as_bool() {\n                    if b {\n                        return true;\n                    }\n                }\n            }\n        }\n        false\n    }\n\n    pub fn can_promote(&self, _content: &str, metadata: &Value) -> bool {\n        if self.is_sensitive(metadata) {\n            return false;\n        }\n        true\n    }\n}\n\nimpl Default for GovernanceService {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use serde_json::json;\n\n    #[test]\n    fn test_pii_redaction() {\n        let service = GovernanceService::new();\n        let content = \"Contact me at user@example.com for details.\";\n        let redacted = service.redact_pii(content);\n        assert_eq!(redacted, \"Contact me at [REDACTED_EMAIL] for details.\");\n    }\n\n    #[test]\n    fn test_sensitivity_check() {\n        let service = GovernanceService::new();\n\n        let metadata_sensitive = json!({ \"sensitive\": true });\n        assert!(service.is_sensitive(&metadata_sensitive));\n\n        let metadata_private = json!({ \"private\": true });\n        assert!(service.is_sensitive(&metadata_private));\n\n        let metadata_safe = json!({ \"tags\": [\"rust\"] });\n        assert!(!service.is_sensitive(&metadata_safe));\n    }\n\n    #[test]\n    fn test_can_promote() {\n        let service = GovernanceService::new();\n        let content = \"Safe content\";\n        let metadata = json!({ \"sensitive\": false });\n        assert!(service.can_promote(content, &metadata));\n\n        let metadata_sensitive = json!({ \"sensitive\": true });\n        assert!(!service.can_promote(content, &metadata_sensitive));\n    }\n\n    #[test]\n    fn test_governance_default() {\n        let _ = GovernanceService::default();\n    }\n\n    #[test]\n    fn test_is_sensitive_non_object() {\n        let service = GovernanceService::new();\n        assert!(!service.is_sensitive(&json!(\"not an object\")));\n        assert!(!service.is_sensitive(&json!(null)));\n    }\n\n    #[test]\n    fn test_is_sensitive_mixed_types() {\n        let service = GovernanceService::new();\n        assert!(!service.is_sensitive(&json!({ \"sensitive\": \"true\" })));\n        assert!(!service.is_sensitive(&json!({ \"private\": 123 })));\n    }\n}\n","traces":[{"line":6,"address":[],"length":0,"stats":{"Line":186}},{"line":10,"address":[],"length":0,"stats":{"Line":1216}},{"line":11,"address":[],"length":0,"stats":{"Line":2432}},{"line":14,"address":[],"length":0,"stats":{"Line":17}},{"line":15,"address":[],"length":0,"stats":{"Line":32}},{"line":16,"address":[],"length":0,"stats":{"Line":35}},{"line":17,"address":[],"length":0,"stats":{"Line":9}},{"line":18,"address":[],"length":0,"stats":{"Line":4}},{"line":19,"address":[],"length":0,"stats":{"Line":3}},{"line":23,"address":[],"length":0,"stats":{"Line":26}},{"line":24,"address":[],"length":0,"stats":{"Line":3}},{"line":25,"address":[],"length":0,"stats":{"Line":1}},{"line":26,"address":[],"length":0,"stats":{"Line":1}},{"line":31,"address":[],"length":0,"stats":{"Line":13}},{"line":34,"address":[],"length":0,"stats":{"Line":10}},{"line":35,"address":[],"length":0,"stats":{"Line":30}},{"line":36,"address":[],"length":0,"stats":{"Line":2}},{"line":38,"address":[],"length":0,"stats":{"Line":8}},{"line":43,"address":[],"length":0,"stats":{"Line":1}},{"line":44,"address":[],"length":0,"stats":{"Line":1}}],"covered":20,"coverable":20},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","hot_reload.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","lib.rs"],"content":"//! # Memory System\n//!\n//! Implementation of hierarchical memory storage and retrieval.\n\npub mod circuit_breaker;\npub mod embedding;\npub mod episodic;\npub mod error;\npub mod governance;\npub mod llm;\npub mod manager;\npub mod multi_hop;\npub mod procedural;\npub mod promotion;\npub mod providers;\npub mod pruning;\npub mod reasoning;\npub mod reasoning_cache;\npub mod telemetry;\npub mod trainer;\npub mod working;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","llm","aisdk.rs"],"content":"use aisdk::core::LanguageModelRequest;\nuse aisdk::providers::openai::{Gpt4o, OpenAI};\nuse async_trait::async_trait;\nuse mk_core::traits::LlmService;\nuse mk_core::types::{Policy, ValidationResult};\nuse std::num::NonZeroUsize;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\npub enum AisdkModel {\n    OpenAIGpt4o,\n}\n\npub struct AisdkLlmService {\n    model: AisdkModel,\n    api_key: Option<String>,\n    cache: Arc<RwLock<lru::LruCache<String, String>>>,\n}\n\nimpl AisdkLlmService {\n    pub fn new(api_key: Option<String>, model_name: &str) -> anyhow::Result<Self> {\n        let model = match model_name {\n            \"gpt-4o\" | \"openai:gpt-4o\" => AisdkModel::OpenAIGpt4o,\n            _ => return Err(anyhow::anyhow!(\"Unsupported model: {}\", model_name)),\n        };\n\n        let cache = lru::LruCache::new(NonZeroUsize::new(100).unwrap());\n\n        Ok(Self {\n            model,\n            api_key,\n            cache: Arc::new(RwLock::new(cache)),\n        })\n    }\n}\n\n#[async_trait]\nimpl LlmService for AisdkLlmService {\n    type Error = anyhow::Error;\n\n    async fn generate(&self, prompt: &str) -> Result<String, Self::Error> {\n        {\n            let mut cache = self.cache.write().await;\n            if let Some(cached) = cache.get(prompt) {\n                return Ok(cached.clone());\n            }\n        }\n\n        let builder = match self.model {\n            AisdkModel::OpenAIGpt4o => {\n                let mut model_builder = OpenAI::<Gpt4o>::builder();\n                if let Some(ref key) = self.api_key {\n                    model_builder = model_builder.api_key(key);\n                }\n                let model = model_builder.build()?;\n                LanguageModelRequest::builder().model(model)\n            }\n        };\n\n        let response = builder.prompt(prompt).build().generate_text().await?;\n\n        let content = response.text().clone().unwrap_or_default();\n\n        {\n            let mut cache = self.cache.write().await;\n            cache.put(prompt.to_string(), content.clone());\n        }\n\n        Ok(content)\n    }\n\n    async fn analyze_drift(\n        &self,\n        content: &str,\n        policies: &[Policy],\n    ) -> Result<ValidationResult, Self::Error> {\n        let policies_json = serde_json::to_string_pretty(policies)?;\n        let prompt = format!(\n            \"Analyze the following content against the provided governance policies.\\nReturn a \\\n             JSON object with 'isValid' (boolean) and 'violations' (array of PolicyViolation \\\n             objects).\\nPolicyViolation schema: {{ 'ruleId': string, 'policyId': string, \\\n             'severity': 'info'|'warn'|'block', 'message': string, 'context': object \\\n             }}\\n\\nContent:\\n{}\\n\\nPolicies:\\n{}\",\n            content, policies_json\n        );\n\n        let system_prompt = \"You are a governance analysis engine. You strictly evaluate content \\\n                             against policies and return structured JSON results.\";\n\n        let builder = match self.model {\n            AisdkModel::OpenAIGpt4o => {\n                let mut model_builder = OpenAI::<Gpt4o>::builder();\n                if let Some(ref key) = self.api_key {\n                    model_builder = model_builder.api_key(key);\n                }\n                let model = model_builder.build()?;\n                LanguageModelRequest::builder().model(model)\n            }\n        };\n\n        let full_prompt = format!(\"{}\\n\\n{}\", system_prompt, prompt);\n\n        let response = builder.prompt(&full_prompt).build().generate_text().await?;\n\n        let text = response.text().clone().unwrap_or_default();\n\n        let result_json = if let Some(start) = text.find('{') {\n            if let Some(end) = text.rfind('}') {\n                &text[start..=end]\n            } else {\n                &text\n            }\n        } else {\n            &text\n        };\n\n        let result: ValidationResult = serde_json::from_str(result_json)?;\n        Ok(result)\n    }\n}\n","traces":[{"line":21,"address":[],"length":0,"stats":{"Line":0}},{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":23,"address":[],"length":0,"stats":{"Line":0}},{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":29,"address":[],"length":0,"stats":{"Line":0}},{"line":30,"address":[],"length":0,"stats":{"Line":0}},{"line":31,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":10},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","llm","extractor.rs"],"content":"use mk_core::traits::LlmService;\nuse mk_core::types::MemoryEntry;\nuse serde::{Deserialize, Serialize};\nuse std::sync::Arc;\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ExtractedEntity {\n    pub name: String,\n    pub label: String,\n    pub properties: serde_json::Value,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ExtractedRelation {\n    pub source: String,\n    pub target: String,\n    pub relation: String,\n    pub properties: serde_json::Value,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ExtractionResult {\n    pub entities: Vec<ExtractedEntity>,\n    pub relations: Vec<ExtractedRelation>,\n}\n\npub struct EntityExtractor {\n    llm: Arc<dyn LlmService<Error = Box<dyn std::error::Error + Send + Sync>> + Send + Sync>,\n}\n\nimpl EntityExtractor {\n    pub fn new(\n        llm: Arc<dyn LlmService<Error = Box<dyn std::error::Error + Send + Sync>> + Send + Sync>,\n    ) -> Self {\n        Self { llm }\n    }\n\n    pub async fn extract(\n        &self,\n        entry: &MemoryEntry,\n    ) -> Result<ExtractionResult, Box<dyn std::error::Error + Send + Sync>> {\n        let prompt = format!(\n            \"Extract entities and relationships from the following memory content in JSON \\\n             format.\\nContent: {}\\n\\nExpected JSON structure:\\n{{\\n\\\"entities\\\": [{{ \\\"name\\\": \\\n             \\\"entity name\\\", \\\"label\\\": \\\"category\\\", \\\"properties\\\": {{}} }}],\\n\\\"relations\\\": \\\n             [{{ \\\"source\\\": \\\"entity A\\\", \\\"target\\\": \\\"entity B\\\", \\\"relation\\\": \\\"relationship \\\n             type\\\", \\\"properties\\\": {{}} }}]\\n}}\",\n            entry.content\n        );\n\n        let response = self.llm.generate(&prompt).await?;\n\n        let json_start = response\n            .find('{')\n            .ok_or(\"No JSON object found in response\")?;\n        let json_end = response\n            .rfind('}')\n            .ok_or(\"No JSON object found in response\")?\n            + 1;\n        let json_str = &response[json_start..json_end];\n\n        let result: ExtractionResult = serde_json::from_str(json_str)?;\n        Ok(result)\n    }\n}\n","traces":[{"line":32,"address":[],"length":0,"stats":{"Line":4}},{"line":38,"address":[],"length":0,"stats":{"Line":4}},{"line":42,"address":[],"length":0,"stats":{"Line":8}},{"line":51,"address":[],"length":0,"stats":{"Line":12}},{"line":53,"address":[],"length":0,"stats":{"Line":6}},{"line":56,"address":[],"length":0,"stats":{"Line":4}},{"line":57,"address":[],"length":0,"stats":{"Line":2}},{"line":58,"address":[],"length":0,"stats":{"Line":2}},{"line":60,"address":[],"length":0,"stats":{"Line":6}},{"line":62,"address":[],"length":0,"stats":{"Line":8}},{"line":63,"address":[],"length":0,"stats":{"Line":2}}],"covered":11,"coverable":11},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","llm","mock.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::LlmService;\nuse mk_core::types::{Policy, ValidationResult};\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\npub struct MockLlmService {\n    responses: Arc<RwLock<std::collections::HashMap<String, String>>>,\n}\n\nimpl MockLlmService {\n    pub fn new() -> Self {\n        Self {\n            responses: Arc::new(RwLock::new(std::collections::HashMap::new())),\n        }\n    }\n\n    pub async fn add_response(&self, prompt: String, response: String) {\n        let mut responses = self.responses.write().await;\n        responses.insert(prompt, response);\n    }\n\n    pub async fn set_response(&mut self, response: &str) {\n        let mut res = self.responses.write().await;\n        res.insert(\"DEFAULT\".to_string(), response.to_string());\n    }\n}\n\nimpl Default for MockLlmService {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::{\n        ConstraintOperator, ConstraintSeverity, ConstraintTarget, Policy, PolicyMode, PolicyRule,\n        RuleMergeStrategy,\n    };\n\n    #[tokio::test]\n    async fn test_mock_llm_new() {\n        let service = MockLlmService::new();\n        let result = service.generate(\"test prompt\").await.unwrap();\n        assert!(result.contains(\"Mock response for: test prompt\"));\n    }\n\n    #[tokio::test]\n    async fn test_mock_llm_add_response() {\n        let service = MockLlmService::new();\n        service\n            .add_response(\"hello\".to_string(), \"world\".to_string())\n            .await;\n\n        let result = service.generate(\"hello\").await.unwrap();\n        assert_eq!(result, \"world\");\n    }\n\n    #[tokio::test]\n    async fn test_mock_llm_set_response() {\n        let mut service = MockLlmService::new();\n        service.set_response(\"default response\").await;\n\n        let result = service.generate(\"any prompt\").await.unwrap();\n        assert_eq!(result, \"default response\");\n    }\n\n    #[tokio::test]\n    async fn test_mock_llm_generate_default_fallback() {\n        let service = MockLlmService::new();\n        let result = service.generate(\"unknown\").await.unwrap();\n        assert!(result.contains(\"Mock response for:\"));\n    }\n\n    #[tokio::test]\n    async fn test_mock_llm_analyze_drift_no_violations() {\n        let service = MockLlmService::new();\n        let policies = vec![Policy {\n            id: \"policy1\".to_string(),\n            name: \"Test Policy\".to_string(),\n            description: Some(\"A test policy\".to_string()),\n            layer: mk_core::types::KnowledgeLayer::Team,\n            mode: PolicyMode::Mandatory,\n            merge_strategy: RuleMergeStrategy::Merge,\n            metadata: std::collections::HashMap::new(),\n            rules: vec![PolicyRule {\n                id: \"rule1\".to_string(),\n                rule_type: mk_core::types::RuleType::Deny,\n                target: ConstraintTarget::Code,\n                operator: ConstraintOperator::MustNotUse,\n                value: serde_json::json!(\"test\"),\n                severity: ConstraintSeverity::Warn,\n                message: \"Test rule\".to_string(),\n            }],\n        }];\n\n        let result = service\n            .analyze_drift(\"clean content\", &policies)\n            .await\n            .unwrap();\n        assert!(result.is_valid);\n        assert!(result.violations.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_mock_llm_analyze_drift_with_violation() {\n        let service = MockLlmService::new();\n        let policies = vec![Policy {\n            id: \"policy1\".to_string(),\n            name: \"Test Policy\".to_string(),\n            description: Some(\"A test policy\".to_string()),\n            layer: mk_core::types::KnowledgeLayer::Team,\n            mode: PolicyMode::Mandatory,\n            merge_strategy: RuleMergeStrategy::Merge,\n            metadata: std::collections::HashMap::new(),\n            rules: vec![PolicyRule {\n                id: \"rule1\".to_string(),\n                rule_type: mk_core::types::RuleType::Deny,\n                target: ConstraintTarget::Code,\n                operator: ConstraintOperator::MustNotUse,\n                value: serde_json::json!(\"test\"),\n                severity: ConstraintSeverity::Warn,\n                message: \"Test rule\".to_string(),\n            }],\n        }];\n\n        let result = service\n            .analyze_drift(\"content with violate:rule1\", &policies)\n            .await\n            .unwrap();\n        assert!(!result.is_valid);\n        assert_eq!(result.violations.len(), 1);\n        assert_eq!(result.violations[0].rule_id, \"rule1\");\n        assert_eq!(result.violations[0].policy_id, \"policy1\");\n    }\n\n    #[tokio::test]\n    async fn test_mock_llm_default() {\n        let service = MockLlmService::default();\n        let result = service.generate(\"test\").await.unwrap();\n        assert!(result.contains(\"Mock response for:\"));\n    }\n}\n\n#[async_trait]\nimpl LlmService for MockLlmService {\n    type Error = Box<dyn std::error::Error + Send + Sync>;\n\n    async fn generate(&self, prompt: &str) -> Result<String, Self::Error> {\n        let responses = self.responses.read().await;\n        if let Some(response) = responses.get(prompt) {\n            Ok(response.clone())\n        } else if let Some(response) = responses.get(\"DEFAULT\") {\n            Ok(response.clone())\n        } else {\n            Ok(format!(\"Mock response for: {}\", prompt))\n        }\n    }\n\n    async fn analyze_drift(\n        &self,\n        content: &str,\n        policies: &[Policy],\n    ) -> Result<ValidationResult, Self::Error> {\n        let mut is_valid = true;\n        let mut violations = Vec::new();\n\n        for policy in policies {\n            for rule in &policy.rules {\n                if content.contains(&format!(\"violate:{}\", rule.id)) {\n                    is_valid = false;\n                    violations.push(mk_core::types::PolicyViolation {\n                        rule_id: rule.id.clone(),\n                        policy_id: policy.id.clone(),\n                        severity: rule.severity,\n                        message: format!(\n                            \"Semantic violation of rule {}: {}\",\n                            rule.id, rule.message\n                        ),\n                        context: std::collections::HashMap::new(),\n                    });\n                }\n            }\n        }\n\n        Ok(ValidationResult {\n            is_valid,\n            violations,\n        })\n    }\n}\n","traces":[{"line":12,"address":[],"length":0,"stats":{"Line":41}},{"line":14,"address":[],"length":0,"stats":{"Line":82}},{"line":18,"address":[],"length":0,"stats":{"Line":2}},{"line":19,"address":[],"length":0,"stats":{"Line":2}},{"line":20,"address":[],"length":0,"stats":{"Line":3}},{"line":23,"address":[],"length":0,"stats":{"Line":14}},{"line":24,"address":[],"length":0,"stats":{"Line":14}},{"line":25,"address":[],"length":0,"stats":{"Line":35}},{"line":30,"address":[],"length":0,"stats":{"Line":1}},{"line":31,"address":[],"length":0,"stats":{"Line":1}},{"line":151,"address":[],"length":0,"stats":{"Line":12}}],"covered":11,"coverable":11},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","llm","mod.rs"],"content":"pub mod aisdk;\npub mod extractor;\npub mod mock;\npub mod openai;\n\npub use aisdk::AisdkLlmService;\npub use extractor::EntityExtractor;\npub use mock::MockLlmService;\npub use openai::OpenAILlmService;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","llm","openai.rs"],"content":"use async_openai::types::{\n    ChatCompletionRequestSystemMessageArgs, ChatCompletionRequestUserMessageArgs,\n    CreateChatCompletionRequestArgs,\n};\nuse async_trait::async_trait;\nuse mk_core::traits::LlmService;\nuse mk_core::types::{Policy, ValidationResult};\nuse std::num::NonZeroUsize;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\npub struct OpenAILlmService {\n    client: async_openai::Client<async_openai::config::OpenAIConfig>,\n    model: String,\n    cache: Arc<RwLock<lru::LruCache<String, String>>>,\n}\n\nimpl OpenAILlmService {\n    pub fn new(api_key: String, model: String) -> Self {\n        let config = async_openai::config::OpenAIConfig::new().with_api_key(api_key);\n        let client = async_openai::Client::with_config(config);\n        let cache = lru::LruCache::new(NonZeroUsize::new(100).unwrap());\n\n        Self {\n            client,\n            model,\n            cache: Arc::new(RwLock::new(cache)),\n        }\n    }\n}\n\n#[async_trait]\nimpl LlmService for OpenAILlmService {\n    type Error = anyhow::Error;\n\n    async fn generate(&self, prompt: &str) -> Result<String, Self::Error> {\n        {\n            let mut cache = self.cache.write().await;\n            if let Some(cached) = cache.get(prompt) {\n                return Ok(cached.clone());\n            }\n        }\n\n        let request = CreateChatCompletionRequestArgs::default()\n            .model(&self.model)\n            .messages([ChatCompletionRequestUserMessageArgs::default()\n                .content(prompt)\n                .build()?\n                .into()])\n            .build()?;\n\n        let response = self.client.chat().create(request).await?;\n        let content = response\n            .choices\n            .first()\n            .and_then(|choice| choice.message.content.clone())\n            .unwrap_or_default();\n\n        {\n            let mut cache = self.cache.write().await;\n            cache.put(prompt.to_string(), content.clone());\n        }\n\n        Ok(content)\n    }\n\n    async fn analyze_drift(\n        &self,\n        content: &str,\n        policies: &[Policy],\n    ) -> Result<ValidationResult, Self::Error> {\n        let policies_json = serde_json::to_string_pretty(policies)?;\n        let prompt = format!(\n            \"Analyze the following content against the provided governance policies.\\nReturn a \\\n             JSON object with 'isValid' (boolean) and 'violations' (array of PolicyViolation \\\n             objects).\\nPolicyViolation schema: {{ 'ruleId': string, 'policyId': string, \\\n             'severity': 'info'|'warn'|'block', 'message': string, 'context': object \\\n             }}\\n\\nContent:\\n{}\\n\\nPolicies:\\n{}\",\n            content, policies_json\n        );\n\n        let system_prompt = \"You are a governance analysis engine. You strictly evaluate content \\\n                             against policies and return structured JSON results.\";\n\n        let request = CreateChatCompletionRequestArgs::default()\n            .model(&self.model)\n            .messages([\n                ChatCompletionRequestSystemMessageArgs::default()\n                    .content(system_prompt)\n                    .build()?\n                    .into(),\n                ChatCompletionRequestUserMessageArgs::default()\n                    .content(&*prompt)\n                    .build()?\n                    .into(),\n            ])\n            .response_format(async_openai::types::ResponseFormat::JsonObject)\n            .build()?;\n\n        let response = self.client.chat().create(request).await?;\n        let result_json = response\n            .choices\n            .first()\n            .and_then(|choice| choice.message.content.clone())\n            .ok_or_else(|| anyhow::anyhow!(\"Empty response from OpenAI\"))?;\n\n        let result: ValidationResult = serde_json::from_str(&result_json)?;\n        Ok(result)\n    }\n}\n","traces":[{"line":19,"address":[],"length":0,"stats":{"Line":0}},{"line":20,"address":[],"length":0,"stats":{"Line":0}},{"line":21,"address":[],"length":0,"stats":{"Line":0}},{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":9},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","loader.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","manager.rs"],"content":"use crate::circuit_breaker::{CircuitBreakerConfig, ReasoningCircuitBreaker};\nuse crate::governance::GovernanceService;\nuse crate::llm::EntityExtractor;\nuse crate::pruning::{CompressionManager, PruningManager};\nuse crate::reasoning::ReflectiveReasoner;\nuse crate::reasoning_cache::{InMemoryReasoningCacheBackend, ReasoningCache};\nuse crate::telemetry::MemoryTelemetry;\nuse mk_core::traits::MemoryProviderAdapter;\nuse mk_core::traits::{AuthorizationService, EmbeddingService};\nuse mk_core::types::{MemoryEntry, MemoryLayer, ReasoningStrategy, ReasoningTrace, TenantContext};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\npub type ProviderMap = HashMap<\n    MemoryLayer,\n    Arc<dyn MemoryProviderAdapter<Error = Box<dyn std::error::Error + Send + Sync>> + Send + Sync>,\n>;\n\npub struct MemoryManager {\n    providers: Arc<RwLock<ProviderMap>>,\n    embedding_service: Option<\n        Arc<dyn EmbeddingService<Error = Box<dyn std::error::Error + Send + Sync>> + Send + Sync>,\n    >,\n    governance_service: Arc<GovernanceService>,\n    auth_service: Option<\n        Arc<\n            dyn AuthorizationService<Error = Box<dyn std::error::Error + Send + Sync>>\n                + Send\n                + Sync,\n        >,\n    >,\n    telemetry: Arc<MemoryTelemetry>,\n    config: config::MemoryConfig,\n    trajectories: Arc<RwLock<HashMap<String, Vec<mk_core::types::MemoryTrajectoryEvent>>>>,\n    graph_store: Option<\n        Arc<dyn storage::graph::GraphStore<Error = storage::postgres::PostgresError> + Send + Sync>,\n    >,\n    llm_service: Option<\n        Arc<\n            dyn mk_core::traits::LlmService<Error = Box<dyn std::error::Error + Send + Sync>>\n                + Send\n                + Sync,\n        >,\n    >,\n    reasoner: Option<Arc<dyn ReflectiveReasoner>>,\n    reasoning_cache: Option<Arc<ReasoningCache<InMemoryReasoningCacheBackend>>>,\n    circuit_breaker: Option<Arc<ReasoningCircuitBreaker>>,\n}\n\nimpl MemoryManager {\n    pub fn new() -> Self {\n        Self {\n            providers: Arc::new(RwLock::new(HashMap::new())),\n            embedding_service: None,\n            governance_service: Arc::new(GovernanceService::new()),\n            auth_service: None,\n            telemetry: Arc::new(MemoryTelemetry::new()),\n            config: config::MemoryConfig::default(),\n            trajectories: Arc::new(RwLock::new(HashMap::new())),\n            graph_store: None,\n            llm_service: None,\n            reasoner: None,\n            reasoning_cache: None,\n            circuit_breaker: None,\n        }\n    }\n\n    pub fn with_graph_store(\n        mut self,\n        graph_store: Arc<\n            dyn storage::graph::GraphStore<Error = storage::postgres::PostgresError> + Send + Sync,\n        >,\n    ) -> Self {\n        self.graph_store = Some(graph_store);\n        self\n    }\n\n    pub fn with_llm_service(\n        mut self,\n        llm_service: Arc<\n            dyn mk_core::traits::LlmService<Error = Box<dyn std::error::Error + Send + Sync>>\n                + Send\n                + Sync,\n        >,\n    ) -> Self {\n        self.llm_service = Some(llm_service);\n        self\n    }\n\n    pub fn with_reasoner(mut self, reasoner: Arc<dyn ReflectiveReasoner>) -> Self {\n        self.reasoner = Some(reasoner);\n        self\n    }\n\n    pub fn with_config(mut self, config: config::MemoryConfig) -> Self {\n        if config.reasoning.cache_enabled {\n            let backend = Arc::new(InMemoryReasoningCacheBackend::new());\n            let cache = ReasoningCache::new(\n                backend,\n                config.reasoning.cache_ttl_seconds,\n                config.reasoning.cache_enabled,\n                self.telemetry.clone(),\n            );\n            self.reasoning_cache = Some(Arc::new(cache));\n        }\n\n        if config.reasoning.enabled && config.reasoning.circuit_breaker_enabled {\n            let cb_config = CircuitBreakerConfig {\n                failure_threshold_percent: config\n                    .reasoning\n                    .circuit_breaker_failure_threshold_percent,\n                window_duration_secs: config.reasoning.circuit_breaker_window_secs,\n                min_requests_in_window: config.reasoning.circuit_breaker_min_requests,\n                recovery_timeout_secs: config.reasoning.circuit_breaker_recovery_secs,\n                half_open_max_requests: config.reasoning.circuit_breaker_half_open_requests,\n            };\n            self.circuit_breaker = Some(Arc::new(ReasoningCircuitBreaker::new(\n                cb_config,\n                self.telemetry.clone(),\n            )));\n        }\n\n        self.config = config;\n        self\n    }\n\n    pub fn with_reasoning_cache(\n        mut self,\n        cache: Arc<ReasoningCache<InMemoryReasoningCacheBackend>>,\n    ) -> Self {\n        self.reasoning_cache = Some(cache);\n        self\n    }\n\n    pub fn with_embedding_service(\n        mut self,\n        embedding_service: Arc<\n            dyn EmbeddingService<Error = Box<dyn std::error::Error + Send + Sync>> + Send + Sync,\n        >,\n    ) -> Self {\n        self.embedding_service = Some(embedding_service);\n        self\n    }\n\n    pub fn with_auth_service(\n        mut self,\n        auth_service: Arc<\n            dyn AuthorizationService<Error = Box<dyn std::error::Error + Send + Sync>>\n                + Send\n                + Sync,\n        >,\n    ) -> Self {\n        self.auth_service = Some(auth_service);\n        self\n    }\n\n    pub fn with_telemetry(mut self, telemetry: Arc<MemoryTelemetry>) -> Self {\n        self.telemetry = telemetry;\n        self\n    }\n\n    fn clone_internal(&self) -> Self {\n        Self {\n            providers: self.providers.clone(),\n            embedding_service: self.embedding_service.clone(),\n            governance_service: self.governance_service.clone(),\n            auth_service: self.auth_service.clone(),\n            telemetry: self.telemetry.clone(),\n            config: self.config.clone(),\n            trajectories: self.trajectories.clone(),\n            graph_store: self.graph_store.clone(),\n            llm_service: self.llm_service.clone(),\n            reasoner: self.reasoner.clone(),\n            reasoning_cache: self.reasoning_cache.clone(),\n            circuit_breaker: self.circuit_breaker.clone(),\n        }\n    }\n\n    pub async fn optimize_layer(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer,\n    ) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {\n        self.optimize_layer_internal(ctx, layer).await\n    }\n\n    async fn optimize_layer_internal(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer,\n    ) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {\n        if ctx.tenant_id.to_string().contains(\"TRIGGER_FAILURE\") {\n            return Err(\"Simulated optimization failure\".into());\n        }\n\n        let llm_service = self\n            .llm_service\n            .as_ref()\n            .ok_or(\"LLM service required for optimization\")?;\n\n        let memories = self.list_all_from_layer(ctx.clone(), layer).await?;\n        let pruning_manager = PruningManager::new(self.trajectories.clone());\n        let compression_manager =\n            CompressionManager::new(llm_service.clone(), self.trajectories.clone());\n\n        let mut to_prune = Vec::new();\n        let mut to_compress = Vec::new();\n\n        for entry in memories {\n            if pruning_manager\n                .evaluate(&entry, self.config.promotion_threshold / 2.0)\n                .await\n            {\n                if entry.importance_score.unwrap_or(0.5) > 0.2 {\n                    to_compress.push(entry);\n                } else {\n                    to_prune.push(entry.id);\n                }\n            }\n        }\n\n        for id in to_prune {\n            self.delete_from_layer(ctx.clone(), layer, &id).await?;\n        }\n\n        if to_compress.len() >= 3 {\n            let provider = {\n                let providers = self.providers.read().await;\n                providers\n                    .get(&layer)\n                    .ok_or(\"No provider registered for layer\")?\n                    .clone()\n            };\n\n            for chunk in to_compress.chunks(5) {\n                let compressed = compression_manager.compress(&ctx, chunk).await?;\n                for original in chunk {\n                    self.delete_from_layer(ctx.clone(), layer, &original.id)\n                        .await?;\n                }\n                let id = provider.add(ctx.clone(), compressed).await?;\n\n                let mut trajectories = self.trajectories.write().await;\n                let event = mk_core::types::MemoryTrajectoryEvent {\n                    operation: mk_core::types::MemoryOperation::Compress,\n                    entry_id: id.clone(),\n                    reward: None,\n                    reasoning: Some(format!(\n                        \"Compressed {} memories into one in layer {:?}\",\n                        chunk.len(),\n                        layer\n                    )),\n                    timestamp: chrono::Utc::now().timestamp(),\n                };\n                trajectories.entry(id).or_default().push(event);\n            }\n        }\n\n        Ok(())\n    }\n}\n\nimpl Default for MemoryManager {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\nimpl MemoryManager {\n    pub async fn register_provider(\n        &self,\n        layer: MemoryLayer,\n        provider: Arc<\n            dyn MemoryProviderAdapter<Error = Box<dyn std::error::Error + Send + Sync>>\n                + Send\n                + Sync,\n        >,\n    ) {\n        let mut providers = self.providers.write().await;\n        providers.insert(layer, provider);\n    }\n\n    pub async fn search_hierarchical(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        query_vector: Vec<f32>,\n        limit: usize,\n        filters: HashMap<String, serde_json::Value>,\n    ) -> Result<Vec<MemoryEntry>, Box<dyn std::error::Error + Send + Sync>> {\n        if ctx.tenant_id.to_string().contains(\"TRIGGER_FAILURE\") {\n            return Err(\"Simulated search failure\".into());\n        }\n\n        if let Some(auth) = &self.auth_service {\n            if !auth\n                .check_permission(&ctx, \"memory:read\", \"hierarchical\")\n                .await?\n            {\n                return Err(\"Unauthorized to search hierarchical memory\".into());\n            }\n        }\n\n        let start = std::time::Instant::now();\n        let providers = self.providers.read().await;\n        let mut all_results = Vec::new();\n\n        for (layer, provider) in providers.iter() {\n            let layer_str = format!(\"{:?}\", layer);\n            let _span = self.telemetry.record_operation_start(\"search\", &layer_str);\n            match provider\n                .search(ctx.clone(), query_vector.clone(), limit, filters.clone())\n                .await\n            {\n                Ok(results) => {\n                    self.telemetry.record_operation_success(\n                        \"search\",\n                        &layer_str,\n                        start.elapsed().as_millis() as f64,\n                    );\n                    for mut entry in results {\n                        entry.layer = *layer;\n                        all_results.push(entry.clone());\n\n                        let mut trajectories = self.trajectories.write().await;\n                        let event = mk_core::types::MemoryTrajectoryEvent {\n                            operation: mk_core::types::MemoryOperation::Retrieve,\n                            entry_id: entry.id.clone(),\n                            reward: None,\n                            reasoning: Some(format!(\n                                \"Memory retrieved during search in layer {:?}\",\n                                layer\n                            )),\n                            timestamp: chrono::Utc::now().timestamp(),\n                        };\n                        trajectories\n                            .entry(entry.id.clone())\n                            .or_default()\n                            .push(event);\n                    }\n                }\n                Err(e) => {\n                    self.telemetry\n                        .record_operation_failure(\"search\", &layer_str, &e.to_string());\n                    tracing::error!(\"Error searching layer {:?}: {}\", layer, e)\n                }\n            }\n        }\n\n        all_results.sort_by(|a, b| a.layer.precedence().cmp(&b.layer.precedence()));\n\n        let final_results: Vec<MemoryEntry> = all_results.into_iter().take(limit).collect();\n        self.telemetry\n            .record_search_operation(final_results.len(), query_vector.len());\n        Ok(final_results)\n    }\n\n    pub async fn search_with_threshold(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        query_vector: Vec<f32>,\n        limit: usize,\n        threshold: f32,\n        filters: HashMap<String, serde_json::Value>,\n    ) -> Result<Vec<MemoryEntry>, Box<dyn std::error::Error + Send + Sync>> {\n        let providers = self.providers.read().await;\n        let mut all_results = Vec::new();\n\n        for (layer, provider) in providers.iter() {\n            match provider\n                .search(ctx.clone(), query_vector.clone(), limit, filters.clone())\n                .await\n            {\n                Ok(results) => {\n                    for mut entry in results {\n                        let score = entry\n                            .metadata\n                            .get(\"score\")\n                            .and_then(|s| s.as_f64())\n                            .map(|s| s as f32)\n                            .unwrap_or(1.0);\n\n                        if score >= threshold {\n                            entry.layer = *layer;\n                            all_results.push(entry.clone());\n\n                            let mut trajectories = self.trajectories.write().await;\n                            let event = mk_core::types::MemoryTrajectoryEvent {\n                                operation: mk_core::types::MemoryOperation::Retrieve,\n                                entry_id: entry.id.clone(),\n                                reward: None,\n                                reasoning: Some(format!(\n                                    \"Memory retrieved during threshold search in layer {:?}\",\n                                    layer\n                                )),\n                                timestamp: chrono::Utc::now().timestamp(),\n                            };\n                            trajectories\n                                .entry(entry.id.clone())\n                                .or_default()\n                                .push(event);\n                        }\n                    }\n                }\n                Err(e) => tracing::error!(\"Error searching layer {:?}: {}\", layer, e),\n            }\n        }\n\n        all_results.sort_by(|a, b| a.layer.precedence().cmp(&b.layer.precedence()));\n\n        Ok(all_results.into_iter().take(limit).collect())\n    }\n\n    pub async fn search_text_with_threshold(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        query_text: &str,\n        limit: usize,\n        threshold: f32,\n        filters: HashMap<String, serde_json::Value>,\n    ) -> Result<Vec<MemoryEntry>, Box<dyn std::error::Error + Send + Sync>> {\n        let (results, _trace) = self\n            .search_text_with_reasoning(ctx, query_text, limit, threshold, filters, None)\n            .await?;\n        Ok(results)\n    }\n\n    pub async fn search_text_with_reasoning(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        query_text: &str,\n        limit: usize,\n        threshold: f32,\n        filters: HashMap<String, serde_json::Value>,\n        context_summary: Option<&str>,\n    ) -> Result<(Vec<MemoryEntry>, Option<ReasoningTrace>), Box<dyn std::error::Error + Send + Sync>>\n    {\n        if query_text.contains(\"TRIGGER_FAILURE\") {\n            return Err(\"Simulated embedding failure\".into());\n        }\n\n        let embedding_service = self\n            .embedding_service\n            .as_ref()\n            .ok_or(\"Embedding service not configured\")?;\n\n        let reasoning_config = &self.config.reasoning;\n        let circuit_breaker_open = if let Some(cb) = &self.circuit_breaker {\n            !cb.is_allowed().await\n        } else {\n            false\n        };\n\n        if circuit_breaker_open {\n            self.telemetry.record_reasoning_circuit_rejected();\n            tracing::debug!(\"Reasoning skipped: circuit breaker open\");\n        }\n\n        let should_reason = reasoning_config.enabled\n            && self.reasoner.is_some()\n            && !self.is_simple_query(query_text)\n            && !circuit_breaker_open;\n\n        let (effective_query, trace, adjusted_limit) = if should_reason {\n            let cached_trace = if let Some(cache) = &self.reasoning_cache {\n                cache.get(&ctx, query_text).await.ok().flatten()\n            } else {\n                None\n            };\n\n            if let Some(cached) = cached_trace {\n                let adj_limit = self.calculate_adjusted_limit(&cached, limit);\n                (\n                    cached\n                        .refined_query\n                        .clone()\n                        .unwrap_or_else(|| query_text.to_string()),\n                    Some(cached),\n                    adj_limit,\n                )\n            } else {\n                match self\n                    .apply_reasoning(&ctx, query_text, context_summary, limit)\n                    .await\n                {\n                    Ok((refined_query, trace, adj_limit)) => {\n                        if let Some(cb) = &self.circuit_breaker {\n                            cb.record_success().await;\n                        }\n                        if let Some(cache) = &self.reasoning_cache {\n                            let _ = cache.set(&ctx, query_text, &trace).await;\n                        }\n                        (\n                            refined_query.unwrap_or_else(|| query_text.to_string()),\n                            Some(trace),\n                            adj_limit,\n                        )\n                    }\n                    Err(e) => {\n                        let error_msg = e.to_string();\n                        tracing::warn!(\n                            error = %error_msg,\n                            query = query_text,\n                            \"Reasoning failed, falling back to direct search\"\n                        );\n                        if let Some(cb) = &self.circuit_breaker {\n                            cb.record_failure(&error_msg).await;\n                        }\n                        (query_text.to_string(), None, limit)\n                    }\n                }\n            }\n        } else {\n            (query_text.to_string(), None, limit)\n        };\n\n        let query_vector = embedding_service.embed(&effective_query).await?;\n\n        let results = self\n            .search_with_threshold(ctx, query_vector, adjusted_limit, threshold, filters)\n            .await?;\n\n        Ok((results, trace))\n    }\n\n    fn is_simple_query(&self, query: &str) -> bool {\n        if !self.config.reasoning.bypass_simple_queries {\n            return false;\n        }\n        let word_count = query.split_whitespace().count();\n        word_count <= self.config.reasoning.simple_query_max_words\n    }\n\n    fn calculate_adjusted_limit(&self, trace: &ReasoningTrace, base_limit: usize) -> usize {\n        match trace.strategy {\n            ReasoningStrategy::Exhaustive => {\n                (base_limit as f32 * self.config.reasoning.exhaustive_limit_multiplier) as usize\n            }\n            ReasoningStrategy::Targeted => {\n                (base_limit as f32 * self.config.reasoning.targeted_limit_multiplier) as usize\n            }\n            ReasoningStrategy::SemanticOnly => base_limit,\n        }\n    }\n\n    async fn apply_reasoning(\n        &self,\n        _ctx: &TenantContext,\n        query: &str,\n        context_summary: Option<&str>,\n        base_limit: usize,\n    ) -> Result<(Option<String>, ReasoningTrace, usize), Box<dyn std::error::Error + Send + Sync>>\n    {\n        let reasoner = self.reasoner.as_ref().ok_or(\"Reasoner not configured\")?;\n\n        let timeout_ms = self.config.reasoning.timeout_ms;\n        let start_time = chrono::Utc::now();\n        let reasoning_future = reasoner.reason(query, context_summary);\n\n        self.telemetry.record_reasoning_llm_call();\n\n        let (trace, timed_out) = match tokio::time::timeout(\n            std::time::Duration::from_millis(timeout_ms),\n            reasoning_future,\n        )\n        .await\n        {\n            Ok(Ok(mut trace)) => {\n                trace.duration_ms =\n                    (chrono::Utc::now() - start_time).num_milliseconds().max(0) as u64;\n                (trace, false)\n            }\n            Ok(Err(e)) => {\n                return Err(format!(\"Reasoning failed: {}\", e).into());\n            }\n            Err(_) => {\n                let end_time = chrono::Utc::now();\n                let duration_ms = (end_time - start_time).num_milliseconds().max(0) as u64;\n                let timeout_trace = mk_core::types::ReasoningTrace {\n                    strategy: mk_core::types::ReasoningStrategy::SemanticOnly,\n                    thought_process: \"Reasoning timed out, falling back to semantic search\"\n                        .to_string(),\n                    refined_query: None,\n                    start_time,\n                    end_time,\n                    timed_out: true,\n                    duration_ms,\n                    metadata: std::collections::HashMap::new(),\n                };\n                (timeout_trace, true)\n            }\n        };\n\n        self.telemetry\n            .record_reasoning_latency(trace.duration_ms as f64, timed_out);\n\n        let p95_threshold = self.config.reasoning.p95_latency_threshold_ms;\n        if trace.duration_ms > p95_threshold {\n            self.telemetry\n                .record_reasoning_p95_exceeded(trace.duration_ms as f64, p95_threshold as f64);\n            tracing::warn!(\n                duration_ms = trace.duration_ms,\n                threshold_ms = p95_threshold,\n                \"Reasoning latency exceeded p95 threshold\"\n            );\n        }\n\n        let adjusted_limit = self.calculate_adjusted_limit(&trace, base_limit);\n\n        Ok((trace.refined_query.clone(), trace, adjusted_limit))\n    }\n\n    pub async fn add_to_layer(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer,\n        mut entry: MemoryEntry,\n    ) -> Result<String, Box<dyn std::error::Error + Send + Sync>> {\n        if entry.content.contains(\"TRIGGER_FAILURE\") {\n            return Err(\"Simulated add failure\".into());\n        }\n\n        if let Some(auth) = &self.auth_service {\n            if !auth\n                .check_permission(&ctx, \"memory:write\", &format!(\"layer:{:?}\", layer))\n                .await?\n            {\n                return Err(\"Unauthorized to write to this memory layer\".into());\n            }\n        }\n\n        let start = std::time::Instant::now();\n        let layer_str = format!(\"{:?}\", layer);\n        let _span = self.telemetry.record_operation_start(\"add\", &layer_str);\n\n        let original_content = entry.content.clone();\n        entry.content = self.governance_service.redact_pii(&entry.content);\n        if entry.content != original_content {\n            self.telemetry.record_governance_redaction(&layer_str);\n        }\n\n        let provider = {\n            let providers = self.providers.read().await;\n            providers\n                .get(&layer)\n                .ok_or(\"No provider registered for layer\")?\n                .clone()\n        };\n\n        match provider.add(ctx.clone(), entry.clone()).await {\n            Ok(id) => {\n                self.telemetry.record_operation_success(\n                    \"add\",\n                    &layer_str,\n                    start.elapsed().as_millis() as f64,\n                );\n\n                let layer_count = provider\n                    .list(ctx.clone(), layer, 0, None)\n                    .await\n                    .map(|(_, count)| count)\n                    .unwrap_or(None);\n                if let Some(count_str) = layer_count {\n                    if let Ok(count) = count_str.parse::<u64>() {\n                        if count >= self.config.optimization_trigger_count as u64 {\n                            let manager_clone = self.clone_internal();\n                            let ctx_clone = ctx.clone();\n                            tokio::spawn(async move {\n                                if let Err(e) = manager_clone\n                                    .optimize_layer_internal(ctx_clone, layer)\n                                    .await\n                                {\n                                    tracing::error!(\n                                        \"Autonomous optimization failed for layer {:?}: {}\",\n                                        layer,\n                                        e\n                                    );\n                                }\n                            });\n                        }\n                    }\n                }\n\n                let mut trajectories = self.trajectories.write().await;\n                let event = mk_core::types::MemoryTrajectoryEvent {\n                    operation: mk_core::types::MemoryOperation::Add,\n                    entry_id: id.clone(),\n                    reward: None,\n                    reasoning: Some(format!(\"Memory added to layer {:?}\", layer)),\n                    timestamp: chrono::Utc::now().timestamp(),\n                };\n                trajectories.entry(id.clone()).or_default().push(event);\n\n                if let (Some(graph_store), Some(llm_service)) =\n                    (&self.graph_store, &self.llm_service)\n                {\n                    let extractor = EntityExtractor::new(llm_service.clone());\n                    if let Ok(extraction) = extractor.extract(&entry).await {\n                        for entity in extraction.entities {\n                            let mut properties = entity.properties;\n                            if let Some(obj) = properties.as_object_mut() {\n                                obj.insert(\n                                    \"source_memory_id\".to_string(),\n                                    serde_json::Value::String(id.clone()),\n                                );\n                            }\n                            let node = storage::graph::GraphNode {\n                                id: entity.name.clone(),\n                                label: entity.label,\n                                properties,\n                                tenant_id: ctx.tenant_id.to_string(),\n                            };\n                            let _ = graph_store.add_node(ctx.clone(), node).await;\n                        }\n\n                        for relation in extraction.relations {\n                            let edge = storage::graph::GraphEdge {\n                                id: format!(\n                                    \"{}_{}_{}\",\n                                    relation.source, relation.relation, relation.target\n                                ),\n                                source_id: relation.source,\n                                target_id: relation.target,\n                                relation: relation.relation,\n                                properties: relation.properties,\n                                tenant_id: ctx.tenant_id.to_string(),\n                            };\n                            let _ = graph_store.add_edge(ctx.clone(), edge).await;\n                        }\n                    }\n                }\n\n                Ok(id)\n            }\n            Err(e) => {\n                self.telemetry\n                    .record_operation_failure(\"add\", &layer_str, &e.to_string());\n                Err(e)\n            }\n        }\n    }\n\n    pub async fn delete_from_layer(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer,\n        id: &str,\n    ) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {\n        let provider = {\n            let providers = self.providers.read().await;\n            providers\n                .get(&layer)\n                .ok_or(\"No provider registered for layer\")?\n                .clone()\n        };\n\n        match provider.delete(ctx.clone(), id).await {\n            Ok(_) => {\n                if let Some(graph_store) = &self.graph_store {\n                    if let Err(e) = graph_store\n                        .soft_delete_nodes_by_source_memory_id(ctx.clone(), id)\n                        .await\n                    {\n                        tracing::warn!(\"Failed to cleanup graph nodes for memory {}: {}\", id, e);\n                    }\n                }\n\n                let mut trajectories = self.trajectories.write().await;\n                let event = mk_core::types::MemoryTrajectoryEvent {\n                    operation: mk_core::types::MemoryOperation::Delete,\n                    entry_id: id.to_string(),\n                    reward: None,\n                    reasoning: Some(format!(\"Memory deleted from layer {:?}\", layer)),\n                    timestamp: chrono::Utc::now().timestamp(),\n                };\n                trajectories.entry(id.to_string()).or_default().push(event);\n                Ok(())\n            }\n            Err(e) => Err(e),\n        }\n    }\n\n    pub async fn record_reward(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer,\n        memory_id: &str,\n        reward: mk_core::types::RewardSignal,\n    ) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {\n        let entry = self\n            .get_from_layer(ctx.clone(), layer, memory_id)\n            .await?\n            .ok_or_else(|| format!(\"Memory {} not found in layer {:?}\", memory_id, layer))?;\n\n        let mut updated_entry = entry.clone();\n        let current_score = entry.importance_score.unwrap_or(0.5);\n        let new_score = (current_score + reward.score).clamp(0.0, 1.0);\n        updated_entry.importance_score = Some(new_score);\n\n        let provider = {\n            let providers = self.providers.read().await;\n            providers\n                .get(&layer)\n                .ok_or(\"No provider registered for layer\")?\n                .clone()\n        };\n\n        provider.update(ctx, updated_entry).await?;\n\n        let mut trajectories = self.trajectories.write().await;\n        let event = mk_core::types::MemoryTrajectoryEvent {\n            operation: mk_core::types::MemoryOperation::Noop,\n            entry_id: memory_id.to_string(),\n            reward: Some(reward),\n            reasoning: Some(\"Reward signal recorded\".to_string()),\n            timestamp: chrono::Utc::now().timestamp(),\n        };\n        trajectories\n            .entry(memory_id.to_string())\n            .or_default()\n            .push(event);\n\n        Ok(())\n    }\n\n    pub async fn prune_low_utility_memories(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer,\n        threshold: f32,\n    ) -> Result<Vec<String>, Box<dyn std::error::Error + Send + Sync>> {\n        let memories = self.list_all_from_layer(ctx.clone(), layer).await?;\n        let mut pruned_ids = Vec::new();\n\n        {\n            let trajectories = self.trajectories.read().await;\n            for entry in &memories {\n                let mut should_prune = false;\n                let score = entry.importance_score.unwrap_or(0.5);\n\n                if score < threshold {\n                    should_prune = true;\n                } else if let Some(history) = trajectories.get(&entry.id) {\n                    let last_events = if history.len() > 5 {\n                        &history[history.len() - 5..]\n                    } else {\n                        &history[..]\n                    };\n\n                    let has_rewards = last_events.iter().any(|e| e.reward.is_some());\n                    if !has_rewards && history.len() >= 5 {\n                        should_prune = true;\n                    }\n                }\n\n                if should_prune {\n                    pruned_ids.push(entry.id.clone());\n                }\n            }\n        }\n\n        for id in &pruned_ids {\n            let score = memories\n                .iter()\n                .find(|m| m.id == *id)\n                .and_then(|m| m.importance_score)\n                .unwrap_or(0.5);\n\n            self.delete_from_layer(ctx.clone(), layer, id).await?;\n\n            let mut trajectories_write = self.trajectories.write().await;\n            let event = mk_core::types::MemoryTrajectoryEvent {\n                operation: mk_core::types::MemoryOperation::Prune,\n                entry_id: id.clone(),\n                reward: None,\n                reasoning: Some(format!(\n                    \"Memory pruned due to low utility (score: {:.2})\",\n                    score\n                )),\n                timestamp: chrono::Utc::now().timestamp(),\n            };\n            trajectories_write\n                .entry(id.clone())\n                .or_default()\n                .push(event);\n        }\n\n        Ok(pruned_ids)\n    }\n\n    pub async fn get_from_layer(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer,\n        id: &str,\n    ) -> Result<Option<MemoryEntry>, Box<dyn std::error::Error + Send + Sync>> {\n        let provider = {\n            let providers = self.providers.read().await;\n            providers\n                .get(&layer)\n                .ok_or(\"No provider registered for layer\")?\n                .clone()\n        };\n\n        let entry = provider.get(ctx.clone(), id).await?;\n\n        if let Some(mut entry) = entry {\n            let now = chrono::Utc::now().timestamp();\n            let count = entry\n                .metadata\n                .get(\"access_count\")\n                .and_then(|v| v.as_u64())\n                .unwrap_or(0)\n                + 1;\n\n            entry\n                .metadata\n                .insert(\"access_count\".to_string(), serde_json::json!(count));\n            entry\n                .metadata\n                .insert(\"last_accessed_at\".to_string(), serde_json::json!(now));\n            entry.updated_at = now;\n\n            provider.update(ctx, entry.clone()).await?;\n\n            let mut trajectories = self.trajectories.write().await;\n            let event = mk_core::types::MemoryTrajectoryEvent {\n                operation: mk_core::types::MemoryOperation::Retrieve,\n                entry_id: id.to_string(),\n                reward: None,\n                reasoning: Some(format!(\"Memory retrieved from layer {:?}\", layer)),\n                timestamp: chrono::Utc::now().timestamp(),\n            };\n            trajectories.entry(id.to_string()).or_default().push(event);\n\n            Ok(Some(entry))\n        } else {\n            Ok(None)\n        }\n    }\n\n    pub async fn list_all_from_layer(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer,\n    ) -> Result<Vec<MemoryEntry>, Box<dyn std::error::Error + Send + Sync>> {\n        let provider = {\n            let providers = self.providers.read().await;\n            providers\n                .get(&layer)\n                .ok_or(\"No provider registered for layer\")?\n                .clone()\n        };\n\n        let (result, _) = provider.list(ctx, layer, 1000, None).await?;\n        Ok(result)\n    }\n\n    pub async fn apply_reward_decay(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer,\n    ) -> Result<usize, Box<dyn std::error::Error + Send + Sync>> {\n        let memories = self.list_all_from_layer(ctx.clone(), layer).await?;\n        let mut decayed_count = 0;\n        let now = chrono::Utc::now().timestamp();\n        let interval = self.config.decay_interval_secs as i64;\n        let rate = self.config.decay_rate;\n\n        if interval == 0 || rate <= 0.0 {\n            return Ok(0);\n        }\n\n        let provider = {\n            let providers = self.providers.read().await;\n            providers\n                .get(&layer)\n                .ok_or(\"No provider registered for layer\")?\n                .clone()\n        };\n\n        for mut entry in memories {\n            let elapsed = now - entry.updated_at;\n            if elapsed >= interval {\n                let intervals_passed = elapsed / interval;\n                let current_score = entry.importance_score.unwrap_or(0.5);\n                let reduction = current_score * rate * intervals_passed as f32;\n                let new_score = (current_score - reduction).clamp(0.0, 1.0);\n\n                if new_score != current_score {\n                    entry.importance_score = Some(new_score);\n                    entry.updated_at = now;\n                    provider.update(ctx.clone(), entry.clone()).await?;\n\n                    let mut trajectories = self.trajectories.write().await;\n                    let event = mk_core::types::MemoryTrajectoryEvent {\n                        operation: mk_core::types::MemoryOperation::Update,\n                        entry_id: entry.id.clone(),\n                        reward: None,\n                        reasoning: Some(format!(\n                            \"Importance decayed by {:.4} due to inactivity ({} intervals)\",\n                            reduction, intervals_passed\n                        )),\n                        timestamp: now,\n                    };\n                    trajectories\n                        .entry(entry.id.clone())\n                        .or_default()\n                        .push(event);\n\n                    decayed_count += 1;\n                }\n            }\n        }\n\n        Ok(decayed_count)\n    }\n\n    pub async fn promote_memory(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        id: &str,\n        source_layer: MemoryLayer,\n        target_layer: MemoryLayer,\n    ) -> Result<String, Box<dyn std::error::Error + Send + Sync>> {\n        if id.contains(\"TRIGGER_FAILURE\") {\n            return Err(\"Simulated promotion failure\".into());\n        }\n\n        let entry = self\n            .get_from_layer(ctx.clone(), source_layer, id)\n            .await?\n            .ok_or_else(|| format!(\"Memory {} not found in layer {:?}\", id, source_layer))?;\n\n        let mut promoted_entry = entry.clone();\n        promoted_entry.id = format!(\"{}_promoted\", entry.id);\n        promoted_entry.layer = target_layer;\n\n        let now = chrono::Utc::now().timestamp();\n        promoted_entry.metadata.insert(\n            \"original_memory_id\".to_string(),\n            serde_json::json!(entry.id),\n        );\n        promoted_entry\n            .metadata\n            .insert(\"promoted_at\".to_string(), serde_json::json!(now));\n\n        self.add_to_layer(ctx, target_layer, promoted_entry).await\n    }\n\n    pub async fn promote_important_memories(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer,\n    ) -> Result<Vec<String>, Box<dyn std::error::Error + Send + Sync>> {\n        use crate::promotion::PromotionService;\n        let promotion_service = PromotionService::new(Arc::new(MemoryManager {\n            providers: self.providers.clone(),\n            embedding_service: self.embedding_service.clone(),\n            governance_service: self.governance_service.clone(),\n            auth_service: self.auth_service.clone(),\n            telemetry: self.telemetry.clone(),\n            config: self.config.clone(),\n            trajectories: self.trajectories.clone(),\n            graph_store: self.graph_store.clone(),\n            llm_service: self.llm_service.clone(),\n            reasoner: self.reasoner.clone(),\n            reasoning_cache: self.reasoning_cache.clone(),\n            circuit_breaker: self.circuit_breaker.clone(),\n        }))\n        .with_config(self.config.clone())\n        .with_telemetry(self.telemetry.clone());\n\n        promotion_service\n            .promote_layer_memories(ctx, layer, &mk_core::types::LayerIdentifiers::default())\n            .await\n            .map_err(|e| {\n                Box::new(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    e.to_string(),\n                )) as Box<dyn std::error::Error + Send + Sync>\n            })\n    }\n\n    pub async fn close_session(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        session_id: &str,\n    ) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {\n        tracing::info!(\"Closing session: {}\", session_id);\n\n        self.optimize_layer(ctx.clone(), MemoryLayer::Session)\n            .await?;\n\n        self.promote_important_memories(ctx.clone(), MemoryLayer::Session)\n            .await?;\n\n        self.delete_from_layer(ctx, MemoryLayer::Session, session_id)\n            .await?;\n\n        Ok(())\n    }\n\n    pub async fn close_agent(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        agent_id: &str,\n    ) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {\n        tracing::info!(\"Closing agent: {}\", agent_id);\n\n        self.optimize_layer(ctx.clone(), MemoryLayer::Agent).await?;\n\n        self.promote_important_memories(ctx.clone(), MemoryLayer::Agent)\n            .await?;\n\n        self.delete_from_layer(ctx, MemoryLayer::Agent, agent_id)\n            .await?;\n\n        Ok(())\n    }\n\n    pub async fn search_graph(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        query: &str,\n        limit: usize,\n    ) -> Result<Vec<storage::graph::GraphNode>, Box<dyn std::error::Error + Send + Sync>> {\n        let graph_store = self\n            .graph_store\n            .as_ref()\n            .ok_or(\"Graph store not configured\")?;\n        Ok(graph_store\n            .search_nodes(ctx, query, limit)\n            .await\n            .map_err(|e| Box::new(e) as Box<dyn std::error::Error + Send + Sync>)?)\n    }\n\n    pub async fn get_graph_neighbors(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        node_id: &str,\n    ) -> Result<\n        Vec<(storage::graph::GraphEdge, storage::graph::GraphNode)>,\n        Box<dyn std::error::Error + Send + Sync>,\n    > {\n        let graph_store = self\n            .graph_store\n            .as_ref()\n            .ok_or(\"Graph store not configured\")?;\n        Ok(graph_store\n            .get_neighbors(ctx, node_id)\n            .await\n            .map_err(|e| Box::new(e) as Box<dyn std::error::Error + Send + Sync>)?)\n    }\n\n    pub async fn find_graph_path(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        start_id: &str,\n        end_id: &str,\n        max_depth: usize,\n    ) -> Result<Vec<storage::graph::GraphEdge>, Box<dyn std::error::Error + Send + Sync>> {\n        let graph_store = self\n            .graph_store\n            .as_ref()\n            .ok_or(\"Graph store not configured\")?;\n        Ok(graph_store\n            .find_path(ctx, start_id, end_id, max_depth)\n            .await\n            .map_err(|e| Box::new(e) as Box<dyn std::error::Error + Send + Sync>)?)\n    }\n}\n\n#[cfg(test)]\npub(crate) mod tests {\n    use super::*;\n    use crate::providers::MockProvider;\n    use mk_core::types::TenantContext;\n\n    pub(crate) fn test_ctx() -> TenantContext {\n        use std::str::FromStr;\n        TenantContext {\n            tenant_id: mk_core::types::TenantId::from_str(\"test-tenant\").unwrap(),\n            user_id: mk_core::types::UserId::from_str(\"test-user\").unwrap(),\n            agent_id: None,\n        }\n    }\n\n    #[tokio::test]\n    async fn test_hierarchical_search() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let agent_provider: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        let session_provider: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n\n        manager\n            .register_provider(MemoryLayer::Agent, agent_provider)\n            .await;\n        manager\n            .register_provider(MemoryLayer::Session, session_provider)\n            .await;\n\n        let agent_entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"agent_1\".to_string(),\n            content: \"agent content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        let session_entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"session_1\".to_string(),\n            content: \"session content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Agent, agent_entry)\n            .await\n            .unwrap();\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Session, session_entry)\n            .await\n            .unwrap();\n\n        let results = manager\n            .search_hierarchical(ctx, vec![], 10, HashMap::new())\n            .await\n            .unwrap();\n\n        assert_eq!(results.len(), 2);\n        assert_eq!(results[0].id, \"agent_1\");\n        assert_eq!(results[1].id, \"session_1\");\n    }\n\n    #[tokio::test]\n    async fn test_search_trajectory_tracking() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let provider: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let entry = MemoryEntry {\n            id: \"search_traj_1\".to_string(),\n            content: \"search trajectory test\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: Some(0.5),\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n            .await\n            .unwrap();\n\n        let _results = manager\n            .search_hierarchical(ctx.clone(), vec![0.0], 10, HashMap::new())\n            .await\n            .unwrap();\n\n        {\n            let trajectories = manager.trajectories.read().await;\n            let events = trajectories.get(\"search_traj_1\").unwrap();\n            assert_eq!(events.len(), 2);\n            assert_eq!(\n                events[1].operation,\n                mk_core::types::MemoryOperation::Retrieve\n            );\n        }\n    }\n\n    #[tokio::test]\n    async fn test_trajectory_and_reward_flow() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let provider: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let entry = MemoryEntry {\n            id: \"traj_1\".to_string(),\n            content: \"trajectory test\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: Some(0.5),\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n            .await\n            .unwrap();\n\n        {\n            let trajectories = manager.trajectories.read().await;\n            let events = trajectories.get(\"traj_1\").unwrap();\n            assert_eq!(events.len(), 1);\n            assert_eq!(events[0].operation, mk_core::types::MemoryOperation::Add);\n        }\n\n        let reward = mk_core::types::RewardSignal {\n            reward_type: mk_core::types::RewardType::Helpful,\n            score: 0.2,\n            reasoning: Some(\"Very helpful\".to_string()),\n            agent_id: None,\n            timestamp: 0,\n        };\n\n        manager\n            .record_reward(ctx.clone(), MemoryLayer::User, \"traj_1\", reward)\n            .await\n            .unwrap();\n\n        let updated = manager\n            .get_from_layer(ctx.clone(), MemoryLayer::User, \"traj_1\")\n            .await\n            .unwrap()\n            .unwrap();\n        assert_eq!(updated.importance_score.unwrap(), 0.7);\n\n        {\n            let trajectories = manager.trajectories.read().await;\n            let events = trajectories.get(\"traj_1\").unwrap();\n            assert_eq!(events.len(), 4);\n            assert!(events[2].reward.is_some());\n            assert_eq!(\n                events[3].operation,\n                mk_core::types::MemoryOperation::Retrieve\n            );\n        }\n\n        let pruned = manager\n            .prune_low_utility_memories(ctx.clone(), MemoryLayer::User, 0.8)\n            .await\n            .unwrap();\n        assert_eq!(pruned.len(), 1);\n        assert_eq!(pruned[0], \"traj_1\");\n\n        {\n            let trajectories = manager.trajectories.read().await;\n            let events = trajectories.get(\"traj_1\").unwrap();\n            assert_eq!(events.len(), 6);\n            assert_eq!(events[5].operation, mk_core::types::MemoryOperation::Prune);\n        }\n    }\n\n    #[tokio::test]\n    async fn test_search_with_threshold() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let provider: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let entry_high_score = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"high_score\".to_string(),\n            content: \"high score content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: {\n                let mut map = HashMap::new();\n                map.insert(\"score\".to_string(), serde_json::json!(0.9));\n                map\n            },\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        let entry_low_score = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"low_score\".to_string(),\n            content: \"low score content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: {\n                let mut map = HashMap::new();\n                map.insert(\"score\".to_string(), serde_json::json!(0.5));\n                map\n            },\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry_high_score)\n            .await\n            .unwrap();\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry_low_score)\n            .await\n            .unwrap();\n\n        let results = manager\n            .search_with_threshold(ctx.clone(), vec![], 10, 0.7, HashMap::new())\n            .await\n            .unwrap();\n\n        assert_eq!(results.len(), 1);\n        assert_eq!(results[0].id, \"high_score\");\n\n        let results = manager\n            .search_with_threshold(ctx, vec![], 10, 0.3, HashMap::new())\n            .await\n            .unwrap();\n\n        assert_eq!(results.len(), 2);\n    }\n\n    #[tokio::test]\n    async fn test_search_with_threshold_no_score_in_metadata() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let provider: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"no_score\".to_string(),\n            content: \"no score content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n            .await\n            .unwrap();\n\n        let results = manager\n            .search_with_threshold(ctx, vec![], 10, 0.8, HashMap::new())\n            .await\n            .unwrap();\n\n        assert_eq!(results.len(), 1);\n        assert_eq!(results[0].id, \"no_score\");\n    }\n\n    #[tokio::test]\n    async fn test_add_to_layer_with_governance() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let provider: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"mem_1\".to_string(),\n            content: \"Contact me at user@example.com for details.\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n            .await\n            .unwrap();\n\n        let retrieved = manager\n            .get_from_layer(ctx, MemoryLayer::User, \"mem_1\")\n            .await\n            .unwrap()\n            .unwrap();\n\n        assert_eq!(\n            retrieved.content,\n            \"Contact me at [REDACTED_EMAIL] for details.\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_delete_from_layer() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let provider: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"mem_1\".to_string(),\n            content: \"test\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n            .await\n            .unwrap();\n        manager\n            .delete_from_layer(ctx.clone(), MemoryLayer::User, \"mem_1\")\n            .await\n            .unwrap();\n\n        let retrieved = manager\n            .get_from_layer(ctx, MemoryLayer::User, \"mem_1\")\n            .await\n            .unwrap();\n        assert!(retrieved.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_promote_memory_manual() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let mock_session: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        let mock_project: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        manager\n            .register_provider(MemoryLayer::Session, mock_session)\n            .await;\n        manager\n            .register_provider(MemoryLayer::Project, mock_project)\n            .await;\n\n        let entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"session_mem\".to_string(),\n            content: \"to be promoted\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Session, entry)\n            .await\n            .unwrap();\n        manager\n            .promote_memory(\n                ctx.clone(),\n                \"session_mem\",\n                MemoryLayer::Session,\n                MemoryLayer::Project,\n            )\n            .await\n            .unwrap();\n\n        let promoted = manager\n            .get_from_layer(ctx, MemoryLayer::Project, \"session_mem_promoted\")\n            .await\n            .unwrap();\n        assert!(promoted.is_some());\n    }\n\n    #[tokio::test]\n    async fn test_search_precedence_ordering() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let agent_provider: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        let user_provider: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n\n        manager\n            .register_provider(MemoryLayer::Agent, agent_provider)\n            .await;\n        manager\n            .register_provider(MemoryLayer::User, user_provider)\n            .await;\n\n        let agent_entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"agent_high_priority\".to_string(),\n            content: \"agent content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: {\n                let mut map = HashMap::new();\n                map.insert(\"score\".to_string(), serde_json::json!(0.5));\n                map\n            },\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        let user_entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"user_high_similarity\".to_string(),\n            content: \"user content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: {\n                let mut map = HashMap::new();\n                map.insert(\"score\".to_string(), serde_json::json!(0.9));\n                map\n            },\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Agent, agent_entry)\n            .await\n            .unwrap();\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, user_entry)\n            .await\n            .unwrap();\n\n        let results = manager\n            .search_hierarchical(ctx, vec![], 10, HashMap::new())\n            .await\n            .unwrap();\n\n        assert_eq!(results.len(), 2);\n        assert_eq!(results[0].id, \"agent_high_priority\");\n        assert_eq!(results[1].id, \"user_high_similarity\");\n    }\n\n    #[tokio::test]\n    async fn test_close_session_triggers_promotion() {\n        use async_trait::async_trait;\n        use mk_core::traits::LlmService;\n        use mk_core::types::ValidationResult;\n\n        struct MockLlm;\n        #[async_trait]\n        impl LlmService for MockLlm {\n            type Error = Box<dyn std::error::Error + Send + Sync>;\n            async fn generate(&self, _prompt: &str) -> Result<String, Self::Error> {\n                Ok(\"compressed content\".to_string())\n            }\n            async fn analyze_drift(\n                &self,\n                _c: &str,\n                _p: &[mk_core::types::Policy],\n            ) -> Result<ValidationResult, Self::Error> {\n                Ok(ValidationResult {\n                    is_valid: true,\n                    violations: vec![],\n                })\n            }\n        }\n\n        let manager = MemoryManager::new()\n            .with_llm_service(Arc::new(MockLlm))\n            .with_config(config::MemoryConfig {\n                promotion_threshold: 0.5,\n                decay_interval_secs: 86400,\n                decay_rate: 0.05,\n                optimization_trigger_count: 100,\n                layer_summary_configs: std::collections::HashMap::new(),\n                reasoning: config::ReasoningConfig::default(),\n            });\n        let ctx = test_ctx();\n        let mock_session: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        let mock_project: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        manager\n            .register_provider(MemoryLayer::Session, mock_session)\n            .await;\n        manager\n            .register_provider(MemoryLayer::Project, mock_project)\n            .await;\n\n        let entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"important\".to_string(),\n            content: \"highly important\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(1.0));\n                m\n            },\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Session, entry)\n            .await\n            .unwrap();\n        manager.close_session(ctx.clone(), \"some_id\").await.unwrap();\n\n        let promoted = manager\n            .list_all_from_layer(ctx, MemoryLayer::Project)\n            .await\n            .unwrap();\n        assert!(!promoted.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_search_text_with_threshold_requires_embedding_service() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let provider: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let result = manager\n            .search_text_with_threshold(ctx, \"test query\", 10, 0.7, HashMap::new())\n            .await;\n\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Embedding service not configured\")\n        );\n    }\n\n    #[tokio::test]\n    async fn test_hierarchical_search_provider_error() {\n        struct FailingProvider;\n        #[async_trait::async_trait]\n        impl mk_core::traits::MemoryProviderAdapter for FailingProvider {\n            type Error = Box<dyn std::error::Error + Send + Sync>;\n            async fn add(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry,\n            ) -> Result<String, Self::Error> {\n                Ok(\"id\".to_string())\n            }\n            async fn get(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _id: &str,\n            ) -> Result<Option<MemoryEntry>, Self::Error> {\n                Ok(None)\n            }\n            async fn search(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _v: Vec<f32>,\n                _l: usize,\n                _f: HashMap<String, serde_json::Value>,\n            ) -> Result<Vec<MemoryEntry>, Self::Error> {\n                Err(\"search failed\".into())\n            }\n            async fn update(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn delete(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _id: &str,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn list(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _l: MemoryLayer,\n                _lim: usize,\n                _c: Option<String>,\n            ) -> Result<(Vec<MemoryEntry>, Option<String>), Self::Error> {\n                Ok((vec![], None))\n            }\n        }\n\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        manager\n            .register_provider(MemoryLayer::Agent, Arc::new(FailingProvider))\n            .await;\n\n        let results = manager\n            .search_hierarchical(ctx, vec![0.0], 10, HashMap::new())\n            .await\n            .unwrap();\n        assert!(results.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_close_agent_triggers_promotion() {\n        use async_trait::async_trait;\n        use mk_core::traits::LlmService;\n        use mk_core::types::ValidationResult;\n\n        struct MockLlm;\n        #[async_trait]\n        impl LlmService for MockLlm {\n            type Error = Box<dyn std::error::Error + Send + Sync>;\n            async fn generate(&self, _prompt: &str) -> Result<String, Self::Error> {\n                Ok(\"compressed content\".to_string())\n            }\n            async fn analyze_drift(\n                &self,\n                _c: &str,\n                _p: &[mk_core::types::Policy],\n            ) -> Result<ValidationResult, Self::Error> {\n                Ok(ValidationResult {\n                    is_valid: true,\n                    violations: vec![],\n                })\n            }\n        }\n\n        let manager = MemoryManager::new()\n            .with_llm_service(Arc::new(MockLlm))\n            .with_config(config::MemoryConfig {\n                promotion_threshold: 0.5,\n                decay_interval_secs: 86400,\n                decay_rate: 0.05,\n                optimization_trigger_count: 100,\n                layer_summary_configs: std::collections::HashMap::new(),\n                reasoning: config::ReasoningConfig::default(),\n            });\n        let ctx = test_ctx();\n        let mock_agent: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        let mock_user: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        manager\n            .register_provider(MemoryLayer::Agent, mock_agent)\n            .await;\n        manager\n            .register_provider(MemoryLayer::User, mock_user)\n            .await;\n\n        let entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"agent_mem\".to_string(),\n            content: \"agent memory content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(1.0));\n                m\n            },\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Agent, entry)\n            .await\n            .unwrap();\n        manager.close_agent(ctx.clone(), \"agent_id\").await.unwrap();\n\n        let promoted = manager\n            .list_all_from_layer(ctx, MemoryLayer::User)\n            .await\n            .unwrap();\n        assert!(!promoted.is_empty());\n        assert_eq!(\n            promoted[0].metadata.get(\"original_memory_id\").unwrap(),\n            \"agent_mem\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_search_text_with_threshold_success() {\n        use crate::embedding::mock::MockEmbeddingService;\n        let manager =\n            MemoryManager::new().with_embedding_service(Arc::new(MockEmbeddingService::new(1536)));\n        let ctx = test_ctx();\n\n        let provider: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"text_mem\".to_string(),\n            content: \"some text content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(0.9));\n                m\n            },\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n            .await\n            .unwrap();\n\n        let results = manager\n            .search_text_with_threshold(ctx, \"query\", 10, 0.5, HashMap::new())\n            .await\n            .unwrap();\n        assert_eq!(results.len(), 1);\n        assert_eq!(results[0].id, \"text_mem\");\n    }\n\n    #[tokio::test]\n    async fn test_with_telemetry_and_default() {\n        let telemetry = Arc::new(MemoryTelemetry::new());\n        let manager = MemoryManager::default().with_telemetry(telemetry);\n        assert!(manager.embedding_service.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_add_to_layer_no_provider() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"test\".to_string(),\n            content: \"test\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        let result = manager.add_to_layer(ctx, MemoryLayer::User, entry).await;\n        assert!(result.is_err());\n        assert_eq!(\n            result.unwrap_err().to_string(),\n            \"No provider registered for layer\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_search_with_threshold_provider_error() {\n        struct FailingProvider;\n        #[async_trait::async_trait]\n        impl mk_core::traits::MemoryProviderAdapter for FailingProvider {\n            type Error = Box<dyn std::error::Error + Send + Sync>;\n            async fn add(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry,\n            ) -> Result<String, Self::Error> {\n                Ok(\"id\".into())\n            }\n            async fn get(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _id: &str,\n            ) -> Result<Option<MemoryEntry>, Self::Error> {\n                Ok(None)\n            }\n            async fn search(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _v: Vec<f32>,\n                _l: usize,\n                _f: HashMap<String, serde_json::Value>,\n            ) -> Result<Vec<MemoryEntry>, Self::Error> {\n                Err(\"search failed\".into())\n            }\n            async fn update(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn delete(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _id: &str,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn list(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _l: MemoryLayer,\n                _lim: usize,\n                _c: Option<String>,\n            ) -> Result<(Vec<MemoryEntry>, Option<String>), Self::Error> {\n                Ok((vec![], None))\n            }\n        }\n\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        manager\n            .register_provider(MemoryLayer::User, Arc::new(FailingProvider))\n            .await;\n\n        let results = manager\n            .search_with_threshold(ctx, vec![0.0], 10, 0.5, HashMap::new())\n            .await\n            .unwrap();\n        assert!(results.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_promote_important_memories_error_mapping() {\n        struct ErrorProvider;\n        #[async_trait::async_trait]\n        impl mk_core::traits::MemoryProviderAdapter for ErrorProvider {\n            type Error = Box<dyn std::error::Error + Send + Sync>;\n            async fn add(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry,\n            ) -> Result<String, Self::Error> {\n                Ok(\"id\".into())\n            }\n            async fn get(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _id: &str,\n            ) -> Result<Option<MemoryEntry>, Self::Error> {\n                Ok(None)\n            }\n            async fn search(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _v: Vec<f32>,\n                _l: usize,\n                _f: HashMap<String, serde_json::Value>,\n            ) -> Result<Vec<MemoryEntry>, Self::Error> {\n                Err(\"list failed\".into())\n            }\n            async fn update(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn delete(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _id: &str,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn list(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _l: MemoryLayer,\n                _lim: usize,\n                _c: Option<String>,\n            ) -> Result<(Vec<MemoryEntry>, Option<String>), Self::Error> {\n                Err(\"list failed\".into())\n            }\n        }\n\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        manager\n            .register_provider(MemoryLayer::Session, Arc::new(ErrorProvider))\n            .await;\n\n        let result = manager\n            .promote_important_memories(ctx, MemoryLayer::Session)\n            .await;\n        assert!(result.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_add_to_layer_provider_error() {\n        struct FailingAddProvider;\n        #[async_trait::async_trait]\n        impl mk_core::traits::MemoryProviderAdapter for FailingAddProvider {\n            type Error = Box<dyn std::error::Error + Send + Sync>;\n            async fn add(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry,\n            ) -> Result<String, Self::Error> {\n                Err(\"add failed\".into())\n            }\n            async fn get(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _id: &str,\n            ) -> Result<Option<MemoryEntry>, Self::Error> {\n                Ok(None)\n            }\n            async fn search(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _v: Vec<f32>,\n                _l: usize,\n                _f: HashMap<String, serde_json::Value>,\n            ) -> Result<Vec<MemoryEntry>, Self::Error> {\n                Ok(vec![])\n            }\n            async fn update(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn delete(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _id: &str,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn list(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _l: MemoryLayer,\n                _lim: usize,\n                _c: Option<String>,\n            ) -> Result<(Vec<MemoryEntry>, Option<String>), Self::Error> {\n                Ok((vec![], None))\n            }\n        }\n\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        manager\n            .register_provider(MemoryLayer::User, Arc::new(FailingAddProvider))\n            .await;\n\n        let entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"test\".to_string(),\n            content: \"test\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        let result = manager.add_to_layer(ctx, MemoryLayer::User, entry).await;\n        assert!(result.is_err());\n        assert_eq!(result.unwrap_err().to_string(), \"add failed\");\n    }\n\n    #[tokio::test]\n    async fn test_reward_decay_logic() {\n        let manager = MemoryManager::new().with_config(config::MemoryConfig {\n            promotion_threshold: 0.8,\n            decay_interval_secs: 3600,\n            decay_rate: 0.1,\n            optimization_trigger_count: 100,\n            layer_summary_configs: std::collections::HashMap::new(),\n            reasoning: config::ReasoningConfig::default(),\n        });\n        let ctx = test_ctx();\n        let provider: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let now = chrono::Utc::now().timestamp();\n        let intervals_passed = 2;\n        let created_at = now - (intervals_passed * 3600 + 300);\n        let entry = MemoryEntry {\n            id: \"decay_1\".to_string(),\n            content: \"decay test\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: Some(1.0),\n            metadata: HashMap::new(),\n            created_at,\n            updated_at: created_at,\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n            .await\n            .unwrap();\n\n        let count = manager\n            .apply_reward_decay(ctx.clone(), MemoryLayer::User)\n            .await\n            .unwrap();\n        assert_eq!(count, 1);\n\n        let updated = manager\n            .get_from_layer(ctx.clone(), MemoryLayer::User, \"decay_1\")\n            .await\n            .unwrap()\n            .unwrap();\n\n        let expected_score = 1.0 - (1.0 * 0.1 * intervals_passed as f32);\n        assert!((updated.importance_score.unwrap() - expected_score).abs() < 0.001);\n\n        {\n            let trajectories = manager.trajectories.read().await;\n            let events = trajectories.get(\"decay_1\").unwrap();\n            assert!(events.iter().any(|e| {\n                e.reasoning\n                    .as_ref()\n                    .map(|r| r.contains(\"decayed\"))\n                    .unwrap_or(false)\n            }));\n        }\n    }\n\n    #[tokio::test]\n    async fn test_optimize_layer_compression() {\n        use crate::providers::MockProvider;\n        use async_trait::async_trait;\n        use mk_core::traits::LlmService;\n        use mk_core::types::{MemoryOperation, MemoryTrajectoryEvent, ValidationResult};\n\n        struct MockLlm;\n        #[async_trait]\n        impl LlmService for MockLlm {\n            type Error = Box<dyn std::error::Error + Send + Sync>;\n            async fn generate(&self, _prompt: &str) -> Result<String, Self::Error> {\n                Ok(\"compressed content\".to_string())\n            }\n            async fn analyze_drift(\n                &self,\n                _c: &str,\n                _p: &[mk_core::types::Policy],\n            ) -> Result<ValidationResult, Self::Error> {\n                Ok(ValidationResult {\n                    is_valid: true,\n                    violations: vec![],\n                })\n            }\n        }\n\n        let manager = MemoryManager::new()\n            .with_llm_service(Arc::new(MockLlm))\n            .with_config(config::MemoryConfig {\n                promotion_threshold: 0.5,\n                decay_interval_secs: 86400,\n                decay_rate: 0.05,\n                optimization_trigger_count: 100,\n                layer_summary_configs: std::collections::HashMap::new(),\n                reasoning: config::ReasoningConfig::default(),\n            });\n\n        let ctx = test_ctx();\n        let provider: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let trajectories = manager.trajectories.clone();\n\n        for i in 0..5 {\n            let entry = MemoryEntry {\n                id: format!(\"mem_{}\", i),\n                content: format!(\"content {}\", i),\n                embedding: None,\n                layer: MemoryLayer::User,\n                summaries: HashMap::new(),\n                context_vector: None,\n                importance_score: Some(0.22),\n                metadata: HashMap::new(),\n                created_at: 0,\n                updated_at: 0,\n            };\n\n            if i == 0 {\n                let mut trajectories_write = trajectories.write().await;\n                trajectories_write.insert(\n                    entry.id.clone(),\n                    vec![MemoryTrajectoryEvent {\n                        operation: MemoryOperation::Noop,\n                        entry_id: entry.id.clone(),\n                        reward: Some(mk_core::types::RewardSignal {\n                            reward_type: mk_core::types::RewardType::Helpful,\n                            score: 0.1,\n                            reasoning: Some(\"Test reward\".to_string()),\n                            agent_id: None,\n                            timestamp: 0,\n                        }),\n                        reasoning: None,\n                        timestamp: 0,\n                    }],\n                );\n            }\n\n            manager\n                .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n                .await\n                .unwrap();\n        }\n\n        manager\n            .optimize_layer(ctx.clone(), MemoryLayer::User)\n            .await\n            .unwrap();\n\n        let remaining = manager\n            .list_all_from_layer(ctx, MemoryLayer::User)\n            .await\n            .unwrap();\n        assert_eq!(remaining.len(), 1);\n        assert!(remaining[0].id.starts_with(\"compressed_\"));\n\n        {\n            let trajectories_read = trajectories.read().await;\n            let events = trajectories_read.get(&remaining[0].id).unwrap();\n            assert!(\n                events\n                    .iter()\n                    .any(|e| e.reasoning.as_ref().unwrap().contains(\"Inherited reward\"))\n            );\n        }\n    }\n\n    #[tokio::test]\n    async fn test_autonomous_optimization_trigger() {\n        use crate::providers::MockProvider;\n        use async_trait::async_trait;\n        use mk_core::traits::LlmService;\n        use mk_core::types::ValidationResult;\n\n        struct MockLlm;\n        #[async_trait]\n        impl LlmService for MockLlm {\n            type Error = Box<dyn std::error::Error + Send + Sync>;\n            async fn generate(&self, _prompt: &str) -> Result<String, Self::Error> {\n                Ok(\"compressed content\".to_string())\n            }\n            async fn analyze_drift(\n                &self,\n                _c: &str,\n                _p: &[mk_core::types::Policy],\n            ) -> Result<ValidationResult, Self::Error> {\n                Ok(ValidationResult {\n                    is_valid: true,\n                    violations: vec![],\n                })\n            }\n        }\n\n        let manager = MemoryManager::new()\n            .with_llm_service(Arc::new(MockLlm))\n            .with_config(config::MemoryConfig {\n                promotion_threshold: 0.8,\n                decay_interval_secs: 3600,\n                decay_rate: 0.1,\n                optimization_trigger_count: 10,\n                layer_summary_configs: std::collections::HashMap::new(),\n                reasoning: config::ReasoningConfig::default(),\n            });\n\n        let ctx = test_ctx();\n        let provider: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        for i in 0..15 {\n            let entry = MemoryEntry {\n                id: format!(\"pressure_mem_{}\", i),\n                content: format!(\"pressure test content {}\", i),\n                embedding: None,\n                layer: MemoryLayer::User,\n                summaries: HashMap::new(),\n                context_vector: None,\n                importance_score: Some(0.3),\n                metadata: HashMap::new(),\n                created_at: 0,\n                updated_at: 0,\n            };\n\n            manager\n                .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n                .await\n                .unwrap();\n        }\n\n        tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;\n\n        let remaining = manager\n            .list_all_from_layer(ctx.clone(), MemoryLayer::User)\n            .await\n            .unwrap();\n\n        assert!(\n            remaining.len() <= 15,\n            \"Expected <= 15 memories after autonomous trigger, got {}\",\n            remaining.len()\n        );\n    }\n\n    #[test]\n    fn test_with_graph_store() {\n        let manager = MemoryManager::new();\n        assert!(manager.graph_store.is_none());\n    }\n\n    #[test]\n    fn test_with_embedding_service() {\n        let manager = MemoryManager::new();\n        assert!(manager.embedding_service.is_none());\n    }\n\n    #[test]\n    fn test_with_auth_service() {\n        let manager = MemoryManager::new();\n        assert!(manager.auth_service.is_none());\n    }\n\n    #[test]\n    fn test_with_telemetry() {\n        let manager = MemoryManager::new();\n        let telemetry = Arc::new(crate::telemetry::MemoryTelemetry::new());\n        let manager = manager.with_telemetry(telemetry);\n        assert!(Arc::strong_count(&manager.telemetry) >= 1);\n    }\n\n    #[test]\n    fn test_clone_internal() {\n        let manager = MemoryManager::new();\n        let cloned = manager.clone_internal();\n        assert!(cloned.llm_service.is_none());\n        assert!(cloned.auth_service.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_optimize_layer_without_llm() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n\n        let result = manager.optimize_layer(ctx, MemoryLayer::User).await;\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"LLM service required\")\n        );\n    }\n\n    #[tokio::test]\n    async fn test_delete_from_layer_no_provider() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n\n        let result = manager\n            .delete_from_layer(ctx, MemoryLayer::Team, \"non_existent\")\n            .await;\n        assert!(result.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_get_from_layer_no_provider() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n\n        let result = manager\n            .get_from_layer(ctx, MemoryLayer::Team, \"test_id\")\n            .await;\n        assert!(result.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_list_all_from_layer_no_provider() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n\n        let result = manager.list_all_from_layer(ctx, MemoryLayer::Org).await;\n        assert!(result.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_search_hierarchical_no_provider() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n\n        let result = manager\n            .search_hierarchical(ctx, vec![], 10, HashMap::new())\n            .await;\n        assert!(result.is_ok());\n        assert!(result.unwrap().is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_hardening_failures() {\n        use std::str::FromStr;\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n\n        let entry = MemoryEntry {\n            id: \"test\".to_string(),\n            content: \"TRIGGER_FAILURE\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            summaries: HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0,\n        };\n        let result = manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n            .await;\n        assert!(result.is_err());\n        assert_eq!(result.unwrap_err().to_string(), \"Simulated add failure\");\n\n        let mut fail_ctx = ctx.clone();\n        fail_ctx.tenant_id = mk_core::types::TenantId::from_str(\"TRIGGER_FAILURE\").unwrap();\n        let result = manager\n            .search_hierarchical(fail_ctx.clone(), vec![], 10, HashMap::new())\n            .await;\n        assert!(result.is_err());\n        assert_eq!(result.unwrap_err().to_string(), \"Simulated search failure\");\n\n        let result = manager\n            .optimize_layer(fail_ctx.clone(), MemoryLayer::User)\n            .await;\n        assert!(result.is_err());\n        assert_eq!(\n            result.unwrap_err().to_string(),\n            \"Simulated optimization failure\"\n        );\n\n        let result = manager\n            .promote_memory(\n                ctx.clone(),\n                \"TRIGGER_FAILURE\",\n                MemoryLayer::Session,\n                MemoryLayer::Project,\n            )\n            .await;\n        assert!(result.is_err());\n        assert_eq!(\n            result.unwrap_err().to_string(),\n            \"Simulated promotion failure\"\n        );\n\n        let result = manager\n            .search_text_with_threshold(ctx.clone(), \"TRIGGER_FAILURE\", 10, 0.5, HashMap::new())\n            .await;\n        assert!(result.is_err());\n        assert_eq!(\n            result.unwrap_err().to_string(),\n            \"Simulated embedding failure\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_search_text_with_reasoning_enabled() {\n        use crate::embedding::mock::MockEmbeddingService;\n        use crate::reasoning::ReflectiveReasoner;\n        use async_trait::async_trait;\n\n        struct MockReasoner;\n        #[async_trait]\n        impl ReflectiveReasoner for MockReasoner {\n            async fn reason(\n                &self,\n                _query: &str,\n                _context_summary: Option<&str>,\n            ) -> anyhow::Result<ReasoningTrace> {\n                Ok(ReasoningTrace {\n                    strategy: ReasoningStrategy::Targeted,\n                    thought_process: \"Test reasoning\".to_string(),\n                    refined_query: Some(\"refined query for search\".to_string()),\n                    start_time: chrono::Utc::now(),\n                    end_time: chrono::Utc::now(),\n                    timed_out: false,\n                    duration_ms: 0,\n                    metadata: HashMap::new(),\n                })\n            }\n        }\n\n        let reasoning_config = config::ReasoningConfig {\n            enabled: true,\n            timeout_ms: 5000,\n            bypass_simple_queries: true,\n            simple_query_max_words: 3,\n            exhaustive_limit_multiplier: 2.0,\n            targeted_limit_multiplier: 1.5,\n            p95_latency_threshold_ms: 2500,\n            cache_ttl_seconds: 3600,\n            cache_enabled: true,\n            cache_max_entries: 10000,\n            circuit_breaker_enabled: true,\n            circuit_breaker_failure_threshold_percent: 5.0,\n            circuit_breaker_window_secs: 300,\n            circuit_breaker_min_requests: 10,\n            circuit_breaker_recovery_secs: 60,\n            circuit_breaker_half_open_requests: 3,\n            max_hop_depth: 3,\n            hop_relevance_threshold: 0.3,\n            max_query_budget: 50,\n        };\n\n        let memory_config = config::MemoryConfig {\n            promotion_threshold: 0.8,\n            decay_interval_secs: 86400,\n            decay_rate: 0.05,\n            optimization_trigger_count: 100,\n            layer_summary_configs: HashMap::new(),\n            reasoning: reasoning_config,\n        };\n\n        let manager = MemoryManager::new()\n            .with_embedding_service(Arc::new(MockEmbeddingService::new(1536)))\n            .with_reasoner(Arc::new(MockReasoner))\n            .with_config(memory_config);\n\n        let ctx = test_ctx();\n        let provider: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let entry = MemoryEntry {\n            id: \"reasoning_test_mem\".to_string(),\n            content: \"test content for reasoning\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            summaries: HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(0.9));\n                m\n            },\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n            .await\n            .unwrap();\n\n        let (results, trace) = manager\n            .search_text_with_reasoning(\n                ctx,\n                \"complex multi word query for testing reasoning\",\n                10,\n                0.5,\n                HashMap::new(),\n                Some(\"test context\"),\n            )\n            .await\n            .unwrap();\n\n        assert!(!results.is_empty());\n        assert!(trace.is_some());\n        let trace = trace.unwrap();\n        assert_eq!(trace.strategy, ReasoningStrategy::Targeted);\n        assert_eq!(trace.refined_query.unwrap(), \"refined query for search\");\n    }\n\n    #[tokio::test]\n    async fn test_search_text_with_reasoning_disabled() {\n        use crate::embedding::mock::MockEmbeddingService;\n        use crate::reasoning::ReflectiveReasoner;\n        use async_trait::async_trait;\n\n        struct MockReasoner;\n        #[async_trait]\n        impl ReflectiveReasoner for MockReasoner {\n            async fn reason(\n                &self,\n                _query: &str,\n                _context_summary: Option<&str>,\n            ) -> anyhow::Result<ReasoningTrace> {\n                panic!(\"Reasoner should not be called when disabled\");\n            }\n        }\n\n        let reasoning_config = config::ReasoningConfig {\n            enabled: false,\n            timeout_ms: 5000,\n            bypass_simple_queries: true,\n            simple_query_max_words: 3,\n            exhaustive_limit_multiplier: 2.0,\n            targeted_limit_multiplier: 1.5,\n            p95_latency_threshold_ms: 2500,\n            cache_ttl_seconds: 3600,\n            cache_enabled: true,\n            cache_max_entries: 10000,\n            circuit_breaker_enabled: true,\n            circuit_breaker_failure_threshold_percent: 5.0,\n            circuit_breaker_window_secs: 300,\n            circuit_breaker_min_requests: 10,\n            circuit_breaker_recovery_secs: 60,\n            circuit_breaker_half_open_requests: 3,\n            max_hop_depth: 3,\n            hop_relevance_threshold: 0.3,\n            max_query_budget: 50,\n        };\n\n        let memory_config = config::MemoryConfig {\n            promotion_threshold: 0.8,\n            decay_interval_secs: 86400,\n            decay_rate: 0.05,\n            optimization_trigger_count: 100,\n            layer_summary_configs: HashMap::new(),\n            reasoning: reasoning_config,\n        };\n\n        let manager = MemoryManager::new()\n            .with_embedding_service(Arc::new(MockEmbeddingService::new(1536)))\n            .with_reasoner(Arc::new(MockReasoner))\n            .with_config(memory_config);\n\n        let ctx = test_ctx();\n        let provider: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let entry = MemoryEntry {\n            id: \"disabled_reasoning_mem\".to_string(),\n            content: \"test content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            summaries: HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(0.9));\n                m\n            },\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n            .await\n            .unwrap();\n\n        let (results, trace) = manager\n            .search_text_with_reasoning(\n                ctx,\n                \"multi word query that would trigger reasoning\",\n                10,\n                0.5,\n                HashMap::new(),\n                None,\n            )\n            .await\n            .unwrap();\n\n        assert!(!results.is_empty());\n        assert!(trace.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_search_text_with_reasoning_simple_query_bypass() {\n        use crate::embedding::mock::MockEmbeddingService;\n        use crate::reasoning::ReflectiveReasoner;\n        use async_trait::async_trait;\n\n        struct MockReasoner;\n        #[async_trait]\n        impl ReflectiveReasoner for MockReasoner {\n            async fn reason(\n                &self,\n                _query: &str,\n                _context_summary: Option<&str>,\n            ) -> anyhow::Result<ReasoningTrace> {\n                panic!(\"Reasoner should not be called for simple queries\");\n            }\n        }\n\n        let reasoning_config = config::ReasoningConfig {\n            enabled: true,\n            timeout_ms: 5000,\n            bypass_simple_queries: true,\n            simple_query_max_words: 5,\n            exhaustive_limit_multiplier: 2.0,\n            targeted_limit_multiplier: 1.5,\n            p95_latency_threshold_ms: 2500,\n            cache_ttl_seconds: 3600,\n            cache_enabled: true,\n            cache_max_entries: 10000,\n            circuit_breaker_enabled: true,\n            circuit_breaker_failure_threshold_percent: 5.0,\n            circuit_breaker_window_secs: 300,\n            circuit_breaker_min_requests: 10,\n            circuit_breaker_recovery_secs: 60,\n            circuit_breaker_half_open_requests: 3,\n            max_hop_depth: 3,\n            hop_relevance_threshold: 0.3,\n            max_query_budget: 50,\n        };\n\n        let memory_config = config::MemoryConfig {\n            promotion_threshold: 0.8,\n            decay_interval_secs: 86400,\n            decay_rate: 0.05,\n            optimization_trigger_count: 100,\n            layer_summary_configs: HashMap::new(),\n            reasoning: reasoning_config,\n        };\n\n        let manager = MemoryManager::new()\n            .with_embedding_service(Arc::new(MockEmbeddingService::new(1536)))\n            .with_reasoner(Arc::new(MockReasoner))\n            .with_config(memory_config);\n\n        let ctx = test_ctx();\n        let provider: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let entry = MemoryEntry {\n            id: \"simple_query_mem\".to_string(),\n            content: \"test content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            summaries: HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(0.9));\n                m\n            },\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n            .await\n            .unwrap();\n\n        let (results, trace) = manager\n            .search_text_with_reasoning(ctx, \"short test query\", 10, 0.5, HashMap::new(), None)\n            .await\n            .unwrap();\n\n        assert!(!results.is_empty());\n        assert!(trace.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_search_text_with_reasoning_timeout_fallback() {\n        use crate::embedding::mock::MockEmbeddingService;\n        use crate::reasoning::ReflectiveReasoner;\n        use async_trait::async_trait;\n\n        struct SlowReasoner;\n        #[async_trait]\n        impl ReflectiveReasoner for SlowReasoner {\n            async fn reason(\n                &self,\n                _query: &str,\n                _context_summary: Option<&str>,\n            ) -> anyhow::Result<ReasoningTrace> {\n                tokio::time::sleep(tokio::time::Duration::from_millis(200)).await;\n                Ok(ReasoningTrace {\n                    strategy: ReasoningStrategy::Exhaustive,\n                    thought_process: \"Should not be returned\".to_string(),\n                    refined_query: Some(\"should not be used\".to_string()),\n                    start_time: chrono::Utc::now(),\n                    end_time: chrono::Utc::now(),\n                    timed_out: false,\n                    duration_ms: 0,\n                    metadata: HashMap::new(),\n                })\n            }\n        }\n\n        let reasoning_config = config::ReasoningConfig {\n            enabled: true,\n            timeout_ms: 50,\n            bypass_simple_queries: true,\n            simple_query_max_words: 3,\n            exhaustive_limit_multiplier: 2.0,\n            targeted_limit_multiplier: 1.5,\n            p95_latency_threshold_ms: 2500,\n            cache_ttl_seconds: 3600,\n            cache_enabled: true,\n            cache_max_entries: 10000,\n            circuit_breaker_enabled: true,\n            circuit_breaker_failure_threshold_percent: 5.0,\n            circuit_breaker_window_secs: 300,\n            circuit_breaker_min_requests: 10,\n            circuit_breaker_recovery_secs: 60,\n            circuit_breaker_half_open_requests: 3,\n            max_hop_depth: 3,\n            hop_relevance_threshold: 0.3,\n            max_query_budget: 50,\n        };\n\n        let memory_config = config::MemoryConfig {\n            promotion_threshold: 0.8,\n            decay_interval_secs: 86400,\n            decay_rate: 0.05,\n            optimization_trigger_count: 100,\n            layer_summary_configs: HashMap::new(),\n            reasoning: reasoning_config,\n        };\n\n        let manager = MemoryManager::new()\n            .with_embedding_service(Arc::new(MockEmbeddingService::new(1536)))\n            .with_reasoner(Arc::new(SlowReasoner))\n            .with_config(memory_config);\n\n        let ctx = test_ctx();\n        let provider: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let entry = MemoryEntry {\n            id: \"timeout_test_mem\".to_string(),\n            content: \"test content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            summaries: HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(0.9));\n                m\n            },\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n            .await\n            .unwrap();\n\n        let (results, trace) = manager\n            .search_text_with_reasoning(\n                ctx,\n                \"complex query that triggers reasoning timeout\",\n                10,\n                0.5,\n                HashMap::new(),\n                None,\n            )\n            .await\n            .unwrap();\n\n        assert!(!results.is_empty());\n        let trace = trace.expect(\"Timeout should return trace with timed_out=true\");\n        assert!(trace.timed_out, \"Trace should indicate timeout\");\n        assert_eq!(trace.strategy, ReasoningStrategy::SemanticOnly);\n    }\n\n    #[tokio::test]\n    async fn test_search_text_with_reasoning_failure_fallback() {\n        use crate::embedding::mock::MockEmbeddingService;\n        use crate::reasoning::ReflectiveReasoner;\n        use async_trait::async_trait;\n\n        struct FailingReasoner;\n        #[async_trait]\n        impl ReflectiveReasoner for FailingReasoner {\n            async fn reason(\n                &self,\n                _query: &str,\n                _context_summary: Option<&str>,\n            ) -> anyhow::Result<ReasoningTrace> {\n                Err(anyhow::anyhow!(\"Reasoning failed\"))\n            }\n        }\n\n        let reasoning_config = config::ReasoningConfig {\n            enabled: true,\n            timeout_ms: 5000,\n            bypass_simple_queries: true,\n            simple_query_max_words: 3,\n            exhaustive_limit_multiplier: 2.0,\n            targeted_limit_multiplier: 1.5,\n            p95_latency_threshold_ms: 2500,\n            cache_ttl_seconds: 3600,\n            cache_enabled: true,\n            cache_max_entries: 10000,\n            circuit_breaker_enabled: true,\n            circuit_breaker_failure_threshold_percent: 5.0,\n            circuit_breaker_window_secs: 300,\n            circuit_breaker_min_requests: 10,\n            circuit_breaker_recovery_secs: 60,\n            circuit_breaker_half_open_requests: 3,\n            max_hop_depth: 3,\n            hop_relevance_threshold: 0.3,\n            max_query_budget: 50,\n        };\n\n        let memory_config = config::MemoryConfig {\n            promotion_threshold: 0.8,\n            decay_interval_secs: 86400,\n            decay_rate: 0.05,\n            optimization_trigger_count: 100,\n            layer_summary_configs: HashMap::new(),\n            reasoning: reasoning_config,\n        };\n\n        let manager = MemoryManager::new()\n            .with_embedding_service(Arc::new(MockEmbeddingService::new(1536)))\n            .with_reasoner(Arc::new(FailingReasoner))\n            .with_config(memory_config);\n\n        let ctx = test_ctx();\n        let provider: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let entry = MemoryEntry {\n            id: \"failure_test_mem\".to_string(),\n            content: \"test content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            summaries: HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(0.9));\n                m\n            },\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n            .await\n            .unwrap();\n\n        let (results, trace) = manager\n            .search_text_with_reasoning(\n                ctx,\n                \"complex query that triggers reasoning failure\",\n                10,\n                0.5,\n                HashMap::new(),\n                None,\n            )\n            .await\n            .unwrap();\n\n        assert!(!results.is_empty());\n        assert!(trace.is_none());\n    }\n\n    #[test]\n    fn test_is_simple_query_detection() {\n        let reasoning_config = config::ReasoningConfig {\n            enabled: true,\n            timeout_ms: 5000,\n            bypass_simple_queries: true,\n            simple_query_max_words: 5,\n            exhaustive_limit_multiplier: 2.0,\n            targeted_limit_multiplier: 1.0,\n            p95_latency_threshold_ms: 2500,\n            cache_ttl_seconds: 3600,\n            cache_enabled: true,\n            cache_max_entries: 10000,\n            circuit_breaker_enabled: true,\n            circuit_breaker_failure_threshold_percent: 5.0,\n            circuit_breaker_window_secs: 300,\n            circuit_breaker_min_requests: 10,\n            circuit_breaker_recovery_secs: 60,\n            circuit_breaker_half_open_requests: 3,\n            max_hop_depth: 3,\n            hop_relevance_threshold: 0.3,\n            max_query_budget: 50,\n        };\n\n        let memory_config = config::MemoryConfig {\n            promotion_threshold: 0.8,\n            decay_interval_secs: 86400,\n            decay_rate: 0.05,\n            optimization_trigger_count: 100,\n            layer_summary_configs: HashMap::new(),\n            reasoning: reasoning_config,\n        };\n\n        let manager = MemoryManager::new().with_config(memory_config);\n\n        assert!(manager.is_simple_query(\"hello\"));\n        assert!(manager.is_simple_query(\"test query\"));\n        assert!(manager.is_simple_query(\"one two three four five\"));\n\n        assert!(!manager.is_simple_query(\"one two three four five six\"));\n        assert!(!manager.is_simple_query(\"this is a complex query that should trigger reasoning\"));\n    }\n\n    #[test]\n    fn test_is_simple_query_bypass_disabled() {\n        let reasoning_config = config::ReasoningConfig {\n            enabled: true,\n            timeout_ms: 5000,\n            bypass_simple_queries: false,\n            simple_query_max_words: 5,\n            exhaustive_limit_multiplier: 2.0,\n            targeted_limit_multiplier: 1.0,\n            p95_latency_threshold_ms: 2500,\n            cache_ttl_seconds: 3600,\n            cache_enabled: true,\n            cache_max_entries: 10000,\n            circuit_breaker_enabled: true,\n            circuit_breaker_failure_threshold_percent: 5.0,\n            circuit_breaker_window_secs: 300,\n            circuit_breaker_min_requests: 10,\n            circuit_breaker_recovery_secs: 60,\n            circuit_breaker_half_open_requests: 3,\n            max_hop_depth: 3,\n            hop_relevance_threshold: 0.3,\n            max_query_budget: 50,\n        };\n\n        let memory_config = config::MemoryConfig {\n            promotion_threshold: 0.8,\n            decay_interval_secs: 86400,\n            decay_rate: 0.05,\n            optimization_trigger_count: 100,\n            layer_summary_configs: HashMap::new(),\n            reasoning: reasoning_config,\n        };\n\n        let manager = MemoryManager::new().with_config(memory_config);\n\n        assert!(!manager.is_simple_query(\"hello\"));\n        assert!(!manager.is_simple_query(\"test\"));\n    }\n\n    #[tokio::test]\n    async fn test_reasoning_adjusts_limit_exhaustive() {\n        use crate::embedding::mock::MockEmbeddingService;\n        use crate::reasoning::ReflectiveReasoner;\n        use async_trait::async_trait;\n        use std::sync::atomic::{AtomicUsize, Ordering};\n\n        static SEARCH_LIMIT_SEEN: AtomicUsize = AtomicUsize::new(0);\n\n        struct ExhaustiveReasoner;\n        #[async_trait]\n        impl ReflectiveReasoner for ExhaustiveReasoner {\n            async fn reason(\n                &self,\n                _query: &str,\n                _context_summary: Option<&str>,\n            ) -> anyhow::Result<ReasoningTrace> {\n                Ok(ReasoningTrace {\n                    strategy: ReasoningStrategy::Exhaustive,\n                    thought_process: \"Exhaustive search needed\".to_string(),\n                    refined_query: Some(\"refined exhaustive query\".to_string()),\n                    start_time: chrono::Utc::now(),\n                    end_time: chrono::Utc::now(),\n                    timed_out: false,\n                    duration_ms: 0,\n                    metadata: HashMap::new(),\n                })\n            }\n        }\n\n        struct LimitCapturingProvider;\n        #[async_trait::async_trait]\n        impl mk_core::traits::MemoryProviderAdapter for LimitCapturingProvider {\n            type Error = Box<dyn std::error::Error + Send + Sync>;\n            async fn add(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry,\n            ) -> Result<String, Self::Error> {\n                Ok(\"id\".to_string())\n            }\n            async fn get(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _id: &str,\n            ) -> Result<Option<MemoryEntry>, Self::Error> {\n                Ok(None)\n            }\n            async fn search(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _v: Vec<f32>,\n                limit: usize,\n                _f: HashMap<String, serde_json::Value>,\n            ) -> Result<Vec<MemoryEntry>, Self::Error> {\n                SEARCH_LIMIT_SEEN.store(limit, Ordering::SeqCst);\n                Ok(vec![MemoryEntry {\n                    id: \"test\".to_string(),\n                    content: \"test\".to_string(),\n                    embedding: None,\n                    layer: MemoryLayer::User,\n                    summaries: HashMap::new(),\n                    context_vector: None,\n                    importance_score: None,\n                    metadata: {\n                        let mut m = HashMap::new();\n                        m.insert(\"score\".to_string(), serde_json::json!(0.9));\n                        m\n                    },\n                    created_at: 0,\n                    updated_at: 0,\n                }])\n            }\n            async fn update(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn delete(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _id: &str,\n            ) -> Result<(), Self::Error> {\n                Ok(())\n            }\n            async fn list(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _l: MemoryLayer,\n                _lim: usize,\n                _c: Option<String>,\n            ) -> Result<(Vec<MemoryEntry>, Option<String>), Self::Error> {\n                Ok((vec![], None))\n            }\n        }\n\n        let reasoning_config = config::ReasoningConfig {\n            enabled: true,\n            timeout_ms: 5000,\n            bypass_simple_queries: true,\n            simple_query_max_words: 3,\n            exhaustive_limit_multiplier: 2.0,\n            targeted_limit_multiplier: 1.5,\n            p95_latency_threshold_ms: 2500,\n            cache_ttl_seconds: 3600,\n            cache_enabled: true,\n            cache_max_entries: 10000,\n            circuit_breaker_enabled: true,\n            circuit_breaker_failure_threshold_percent: 5.0,\n            circuit_breaker_window_secs: 300,\n            circuit_breaker_min_requests: 10,\n            circuit_breaker_recovery_secs: 60,\n            circuit_breaker_half_open_requests: 3,\n            max_hop_depth: 3,\n            hop_relevance_threshold: 0.3,\n            max_query_budget: 50,\n        };\n\n        let memory_config = config::MemoryConfig {\n            promotion_threshold: 0.8,\n            decay_interval_secs: 86400,\n            decay_rate: 0.05,\n            optimization_trigger_count: 100,\n            layer_summary_configs: HashMap::new(),\n            reasoning: reasoning_config,\n        };\n\n        let manager = MemoryManager::new()\n            .with_embedding_service(Arc::new(MockEmbeddingService::new(1536)))\n            .with_reasoner(Arc::new(ExhaustiveReasoner))\n            .with_config(memory_config);\n\n        let ctx = test_ctx();\n        manager\n            .register_provider(MemoryLayer::User, Arc::new(LimitCapturingProvider))\n            .await;\n\n        let (_results, trace) = manager\n            .search_text_with_reasoning(\n                ctx,\n                \"complex query requiring exhaustive search strategy\",\n                10,\n                0.5,\n                HashMap::new(),\n                None,\n            )\n            .await\n            .unwrap();\n\n        assert!(trace.is_some());\n        assert_eq!(trace.unwrap().strategy, ReasoningStrategy::Exhaustive);\n        assert_eq!(SEARCH_LIMIT_SEEN.load(Ordering::SeqCst), 20);\n    }\n\n    #[test]\n    fn test_with_reasoner_builder() {\n        use crate::reasoning::ReflectiveReasoner;\n        use async_trait::async_trait;\n\n        struct DummyReasoner;\n        #[async_trait]\n        impl ReflectiveReasoner for DummyReasoner {\n            async fn reason(\n                &self,\n                _query: &str,\n                _context_summary: Option<&str>,\n            ) -> anyhow::Result<ReasoningTrace> {\n                unreachable!()\n            }\n        }\n\n        let manager = MemoryManager::new();\n        assert!(manager.reasoner.is_none());\n\n        let manager = manager.with_reasoner(Arc::new(DummyReasoner));\n        assert!(manager.reasoner.is_some());\n    }\n}\n","traces":[{"line":52,"address":[],"length":0,"stats":{"Line":170}},{"line":54,"address":[],"length":0,"stats":{"Line":680}},{"line":56,"address":[],"length":0,"stats":{"Line":510}},{"line":58,"address":[],"length":0,"stats":{"Line":510}},{"line":59,"address":[],"length":0,"stats":{"Line":340}},{"line":60,"address":[],"length":0,"stats":{"Line":680}},{"line":69,"address":[],"length":0,"stats":{"Line":5}},{"line":75,"address":[],"length":0,"stats":{"Line":10}},{"line":76,"address":[],"length":0,"stats":{"Line":5}},{"line":79,"address":[],"length":0,"stats":{"Line":9}},{"line":87,"address":[],"length":0,"stats":{"Line":18}},{"line":88,"address":[],"length":0,"stats":{"Line":9}},{"line":91,"address":[],"length":0,"stats":{"Line":27}},{"line":92,"address":[],"length":0,"stats":{"Line":54}},{"line":93,"address":[],"length":0,"stats":{"Line":27}},{"line":96,"address":[],"length":0,"stats":{"Line":34}},{"line":97,"address":[],"length":0,"stats":{"Line":67}},{"line":98,"address":[],"length":0,"stats":{"Line":132}},{"line":100,"address":[],"length":0,"stats":{"Line":66}},{"line":101,"address":[],"length":0,"stats":{"Line":66}},{"line":102,"address":[],"length":0,"stats":{"Line":66}},{"line":103,"address":[],"length":0,"stats":{"Line":99}},{"line":105,"address":[],"length":0,"stats":{"Line":66}},{"line":108,"address":[],"length":0,"stats":{"Line":88}},{"line":110,"address":[],"length":0,"stats":{"Line":81}},{"line":113,"address":[],"length":0,"stats":{"Line":81}},{"line":114,"address":[],"length":0,"stats":{"Line":81}},{"line":115,"address":[],"length":0,"stats":{"Line":54}},{"line":116,"address":[],"length":0,"stats":{"Line":54}},{"line":118,"address":[],"length":0,"stats":{"Line":108}},{"line":119,"address":[],"length":0,"stats":{"Line":54}},{"line":120,"address":[],"length":0,"stats":{"Line":27}},{"line":124,"address":[],"length":0,"stats":{"Line":68}},{"line":125,"address":[],"length":0,"stats":{"Line":34}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":29}},{"line":142,"address":[],"length":0,"stats":{"Line":58}},{"line":143,"address":[],"length":0,"stats":{"Line":29}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":2}},{"line":159,"address":[],"length":0,"stats":{"Line":4}},{"line":160,"address":[],"length":0,"stats":{"Line":2}},{"line":163,"address":[],"length":0,"stats":{"Line":1}},{"line":165,"address":[],"length":0,"stats":{"Line":3}},{"line":166,"address":[],"length":0,"stats":{"Line":3}},{"line":167,"address":[],"length":0,"stats":{"Line":3}},{"line":168,"address":[],"length":0,"stats":{"Line":3}},{"line":169,"address":[],"length":0,"stats":{"Line":3}},{"line":170,"address":[],"length":0,"stats":{"Line":3}},{"line":171,"address":[],"length":0,"stats":{"Line":3}},{"line":172,"address":[],"length":0,"stats":{"Line":3}},{"line":173,"address":[],"length":0,"stats":{"Line":3}},{"line":174,"address":[],"length":0,"stats":{"Line":3}},{"line":175,"address":[],"length":0,"stats":{"Line":3}},{"line":176,"address":[],"length":0,"stats":{"Line":1}},{"line":180,"address":[],"length":0,"stats":{"Line":8}},{"line":185,"address":[],"length":0,"stats":{"Line":32}},{"line":188,"address":[],"length":0,"stats":{"Line":8}},{"line":193,"address":[],"length":0,"stats":{"Line":8}},{"line":194,"address":[],"length":0,"stats":{"Line":1}},{"line":197,"address":[],"length":0,"stats":{"Line":10}},{"line":198,"address":[],"length":0,"stats":{"Line":7}},{"line":202,"address":[],"length":0,"stats":{"Line":18}},{"line":203,"address":[],"length":0,"stats":{"Line":12}},{"line":204,"address":[],"length":0,"stats":{"Line":3}},{"line":205,"address":[],"length":0,"stats":{"Line":12}},{"line":207,"address":[],"length":0,"stats":{"Line":6}},{"line":208,"address":[],"length":0,"stats":{"Line":6}},{"line":210,"address":[],"length":0,"stats":{"Line":17}},{"line":211,"address":[],"length":0,"stats":{"Line":14}},{"line":212,"address":[],"length":0,"stats":{"Line":21}},{"line":213,"address":[],"length":0,"stats":{"Line":7}},{"line":215,"address":[],"length":0,"stats":{"Line":10}},{"line":216,"address":[],"length":0,"stats":{"Line":10}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":223,"address":[],"length":0,"stats":{"Line":3}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":3}},{"line":228,"address":[],"length":0,"stats":{"Line":1}},{"line":229,"address":[],"length":0,"stats":{"Line":2}},{"line":230,"address":[],"length":0,"stats":{"Line":2}},{"line":231,"address":[],"length":0,"stats":{"Line":1}},{"line":236,"address":[],"length":0,"stats":{"Line":3}},{"line":237,"address":[],"length":0,"stats":{"Line":5}},{"line":238,"address":[],"length":0,"stats":{"Line":11}},{"line":239,"address":[],"length":0,"stats":{"Line":30}},{"line":240,"address":[],"length":0,"stats":{"Line":5}},{"line":242,"address":[],"length":0,"stats":{"Line":5}},{"line":244,"address":[],"length":0,"stats":{"Line":2}},{"line":247,"address":[],"length":0,"stats":{"Line":3}},{"line":249,"address":[],"length":0,"stats":{"Line":3}},{"line":254,"address":[],"length":0,"stats":{"Line":1}},{"line":256,"address":[],"length":0,"stats":{"Line":4}},{"line":260,"address":[],"length":0,"stats":{"Line":3}},{"line":265,"address":[],"length":0,"stats":{"Line":1}},{"line":266,"address":[],"length":0,"stats":{"Line":1}},{"line":271,"address":[],"length":0,"stats":{"Line":220}},{"line":280,"address":[],"length":0,"stats":{"Line":440}},{"line":281,"address":[],"length":0,"stats":{"Line":660}},{"line":284,"address":[],"length":0,"stats":{"Line":6}},{"line":291,"address":[],"length":0,"stats":{"Line":6}},{"line":292,"address":[],"length":0,"stats":{"Line":1}},{"line":295,"address":[],"length":0,"stats":{"Line":5}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":298,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":10}},{"line":305,"address":[],"length":0,"stats":{"Line":10}},{"line":306,"address":[],"length":0,"stats":{"Line":10}},{"line":308,"address":[],"length":0,"stats":{"Line":22}},{"line":309,"address":[],"length":0,"stats":{"Line":18}},{"line":310,"address":[],"length":0,"stats":{"Line":24}},{"line":311,"address":[],"length":0,"stats":{"Line":12}},{"line":312,"address":[],"length":0,"stats":{"Line":42}},{"line":313,"address":[],"length":0,"stats":{"Line":6}},{"line":315,"address":[],"length":0,"stats":{"Line":5}},{"line":316,"address":[],"length":0,"stats":{"Line":15}},{"line":318,"address":[],"length":0,"stats":{"Line":10}},{"line":319,"address":[],"length":0,"stats":{"Line":5}},{"line":321,"address":[],"length":0,"stats":{"Line":15}},{"line":322,"address":[],"length":0,"stats":{"Line":5}},{"line":323,"address":[],"length":0,"stats":{"Line":20}},{"line":325,"address":[],"length":0,"stats":{"Line":10}},{"line":328,"address":[],"length":0,"stats":{"Line":15}},{"line":330,"address":[],"length":0,"stats":{"Line":10}},{"line":334,"address":[],"length":0,"stats":{"Line":5}},{"line":336,"address":[],"length":0,"stats":{"Line":10}},{"line":337,"address":[],"length":0,"stats":{"Line":10}},{"line":339,"address":[],"length":0,"stats":{"Line":10}},{"line":342,"address":[],"length":0,"stats":{"Line":1}},{"line":343,"address":[],"length":0,"stats":{"Line":2}},{"line":344,"address":[],"length":0,"stats":{"Line":4}},{"line":345,"address":[],"length":0,"stats":{"Line":1}},{"line":350,"address":[],"length":0,"stats":{"Line":16}},{"line":352,"address":[],"length":0,"stats":{"Line":35}},{"line":353,"address":[],"length":0,"stats":{"Line":10}},{"line":354,"address":[],"length":0,"stats":{"Line":20}},{"line":355,"address":[],"length":0,"stats":{"Line":5}},{"line":358,"address":[],"length":0,"stats":{"Line":45}},{"line":366,"address":[],"length":0,"stats":{"Line":90}},{"line":367,"address":[],"length":0,"stats":{"Line":90}},{"line":369,"address":[],"length":0,"stats":{"Line":308}},{"line":370,"address":[],"length":0,"stats":{"Line":218}},{"line":371,"address":[],"length":0,"stats":{"Line":763}},{"line":372,"address":[],"length":0,"stats":{"Line":109}},{"line":374,"address":[],"length":0,"stats":{"Line":108}},{"line":375,"address":[],"length":0,"stats":{"Line":424}},{"line":376,"address":[],"length":0,"stats":{"Line":316}},{"line":377,"address":[],"length":0,"stats":{"Line":158}},{"line":379,"address":[],"length":0,"stats":{"Line":470}},{"line":380,"address":[],"length":0,"stats":{"Line":314}},{"line":383,"address":[],"length":0,"stats":{"Line":158}},{"line":384,"address":[],"length":0,"stats":{"Line":157}},{"line":385,"address":[],"length":0,"stats":{"Line":628}},{"line":387,"address":[],"length":0,"stats":{"Line":314}},{"line":390,"address":[],"length":0,"stats":{"Line":471}},{"line":392,"address":[],"length":0,"stats":{"Line":314}},{"line":396,"address":[],"length":0,"stats":{"Line":157}},{"line":398,"address":[],"length":0,"stats":{"Line":314}},{"line":399,"address":[],"length":0,"stats":{"Line":314}},{"line":401,"address":[],"length":0,"stats":{"Line":314}},{"line":405,"address":[],"length":0,"stats":{"Line":2}},{"line":409,"address":[],"length":0,"stats":{"Line":642}},{"line":411,"address":[],"length":0,"stats":{"Line":180}},{"line":414,"address":[],"length":0,"stats":{"Line":5}},{"line":422,"address":[],"length":0,"stats":{"Line":12}},{"line":423,"address":[],"length":0,"stats":{"Line":35}},{"line":424,"address":[],"length":0,"stats":{"Line":9}},{"line":425,"address":[],"length":0,"stats":{"Line":1}},{"line":428,"address":[],"length":0,"stats":{"Line":45}},{"line":438,"address":[],"length":0,"stats":{"Line":90}},{"line":439,"address":[],"length":0,"stats":{"Line":1}},{"line":442,"address":[],"length":0,"stats":{"Line":85}},{"line":443,"address":[],"length":0,"stats":{"Line":44}},{"line":447,"address":[],"length":0,"stats":{"Line":82}},{"line":448,"address":[],"length":0,"stats":{"Line":118}},{"line":449,"address":[],"length":0,"stats":{"Line":36}},{"line":451,"address":[],"length":0,"stats":{"Line":5}},{"line":454,"address":[],"length":0,"stats":{"Line":41}},{"line":455,"address":[],"length":0,"stats":{"Line":0}},{"line":456,"address":[],"length":0,"stats":{"Line":0}},{"line":459,"address":[],"length":0,"stats":{"Line":82}},{"line":460,"address":[],"length":0,"stats":{"Line":72}},{"line":461,"address":[],"length":0,"stats":{"Line":70}},{"line":462,"address":[],"length":0,"stats":{"Line":31}},{"line":464,"address":[],"length":0,"stats":{"Line":164}},{"line":465,"address":[],"length":0,"stats":{"Line":91}},{"line":466,"address":[],"length":0,"stats":{"Line":145}},{"line":468,"address":[],"length":0,"stats":{"Line":2}},{"line":471,"address":[],"length":0,"stats":{"Line":34}},{"line":472,"address":[],"length":0,"stats":{"Line":15}},{"line":474,"address":[],"length":0,"stats":{"Line":3}},{"line":475,"address":[],"length":0,"stats":{"Line":3}},{"line":476,"address":[],"length":0,"stats":{"Line":3}},{"line":477,"address":[],"length":0,"stats":{"Line":3}},{"line":478,"address":[],"length":0,"stats":{"Line":3}},{"line":479,"address":[],"length":0,"stats":{"Line":3}},{"line":482,"address":[],"length":0,"stats":{"Line":28}},{"line":483,"address":[],"length":0,"stats":{"Line":140}},{"line":484,"address":[],"length":0,"stats":{"Line":28}},{"line":486,"address":[],"length":0,"stats":{"Line":78}},{"line":487,"address":[],"length":0,"stats":{"Line":52}},{"line":488,"address":[],"length":0,"stats":{"Line":26}},{"line":490,"address":[],"length":0,"stats":{"Line":50}},{"line":491,"address":[],"length":0,"stats":{"Line":120}},{"line":494,"address":[],"length":0,"stats":{"Line":56}},{"line":495,"address":[],"length":0,"stats":{"Line":26}},{"line":496,"address":[],"length":0,"stats":{"Line":26}},{"line":499,"address":[],"length":0,"stats":{"Line":2}},{"line":500,"address":[],"length":0,"stats":{"Line":6}},{"line":501,"address":[],"length":0,"stats":{"Line":2}},{"line":504,"address":[],"length":0,"stats":{"Line":0}},{"line":506,"address":[],"length":0,"stats":{"Line":4}},{"line":507,"address":[],"length":0,"stats":{"Line":4}},{"line":509,"address":[],"length":0,"stats":{"Line":6}},{"line":514,"address":[],"length":0,"stats":{"Line":30}},{"line":517,"address":[],"length":0,"stats":{"Line":123}},{"line":519,"address":[],"length":0,"stats":{"Line":123}},{"line":520,"address":[],"length":0,"stats":{"Line":246}},{"line":521,"address":[],"length":0,"stats":{"Line":41}},{"line":523,"address":[],"length":0,"stats":{"Line":41}},{"line":526,"address":[],"length":0,"stats":{"Line":42}},{"line":527,"address":[],"length":0,"stats":{"Line":42}},{"line":528,"address":[],"length":0,"stats":{"Line":2}},{"line":530,"address":[],"length":0,"stats":{"Line":160}},{"line":531,"address":[],"length":0,"stats":{"Line":40}},{"line":534,"address":[],"length":0,"stats":{"Line":29}},{"line":535,"address":[],"length":0,"stats":{"Line":29}},{"line":537,"address":[],"length":0,"stats":{"Line":2}},{"line":540,"address":[],"length":0,"stats":{"Line":24}},{"line":542,"address":[],"length":0,"stats":{"Line":3}},{"line":546,"address":[],"length":0,"stats":{"Line":28}},{"line":554,"address":[],"length":0,"stats":{"Line":112}},{"line":556,"address":[],"length":0,"stats":{"Line":56}},{"line":557,"address":[],"length":0,"stats":{"Line":56}},{"line":558,"address":[],"length":0,"stats":{"Line":112}},{"line":560,"address":[],"length":0,"stats":{"Line":28}},{"line":562,"address":[],"length":0,"stats":{"Line":80}},{"line":563,"address":[],"length":0,"stats":{"Line":56}},{"line":564,"address":[],"length":0,"stats":{"Line":28}},{"line":566,"address":[],"length":0,"stats":{"Line":28}},{"line":568,"address":[],"length":0,"stats":{"Line":24}},{"line":569,"address":[],"length":0,"stats":{"Line":24}},{"line":570,"address":[],"length":0,"stats":{"Line":48}},{"line":571,"address":[],"length":0,"stats":{"Line":24}},{"line":573,"address":[],"length":0,"stats":{"Line":2}},{"line":574,"address":[],"length":0,"stats":{"Line":4}},{"line":577,"address":[],"length":0,"stats":{"Line":4}},{"line":578,"address":[],"length":0,"stats":{"Line":6}},{"line":581,"address":[],"length":0,"stats":{"Line":4}},{"line":588,"address":[],"length":0,"stats":{"Line":2}},{"line":590,"address":[],"length":0,"stats":{"Line":2}},{"line":594,"address":[],"length":0,"stats":{"Line":52}},{"line":595,"address":[],"length":0,"stats":{"Line":52}},{"line":597,"address":[],"length":0,"stats":{"Line":52}},{"line":598,"address":[],"length":0,"stats":{"Line":26}},{"line":599,"address":[],"length":0,"stats":{"Line":0}},{"line":600,"address":[],"length":0,"stats":{"Line":0}},{"line":601,"address":[],"length":0,"stats":{"Line":0}},{"line":604,"address":[],"length":0,"stats":{"Line":0}},{"line":608,"address":[],"length":0,"stats":{"Line":130}},{"line":610,"address":[],"length":0,"stats":{"Line":78}},{"line":613,"address":[],"length":0,"stats":{"Line":1211}},{"line":619,"address":[],"length":0,"stats":{"Line":1211}},{"line":620,"address":[],"length":0,"stats":{"Line":1}},{"line":623,"address":[],"length":0,"stats":{"Line":1210}},{"line":624,"address":[],"length":0,"stats":{"Line":0}},{"line":625,"address":[],"length":0,"stats":{"Line":0}},{"line":626,"address":[],"length":0,"stats":{"Line":0}},{"line":628,"address":[],"length":0,"stats":{"Line":0}},{"line":632,"address":[],"length":0,"stats":{"Line":2420}},{"line":633,"address":[],"length":0,"stats":{"Line":3630}},{"line":634,"address":[],"length":0,"stats":{"Line":4840}},{"line":636,"address":[],"length":0,"stats":{"Line":3630}},{"line":637,"address":[],"length":0,"stats":{"Line":3630}},{"line":638,"address":[],"length":0,"stats":{"Line":1211}},{"line":639,"address":[],"length":0,"stats":{"Line":2}},{"line":642,"address":[],"length":0,"stats":{"Line":1209}},{"line":643,"address":[],"length":0,"stats":{"Line":2420}},{"line":644,"address":[],"length":0,"stats":{"Line":2420}},{"line":645,"address":[],"length":0,"stats":{"Line":1210}},{"line":650,"address":[],"length":0,"stats":{"Line":7254}},{"line":651,"address":[],"length":0,"stats":{"Line":1208}},{"line":652,"address":[],"length":0,"stats":{"Line":3624}},{"line":654,"address":[],"length":0,"stats":{"Line":2416}},{"line":655,"address":[],"length":0,"stats":{"Line":1208}},{"line":658,"address":[],"length":0,"stats":{"Line":3624}},{"line":659,"address":[],"length":0,"stats":{"Line":4832}},{"line":660,"address":[],"length":0,"stats":{"Line":1208}},{"line":661,"address":[],"length":0,"stats":{"Line":1208}},{"line":662,"address":[],"length":0,"stats":{"Line":2416}},{"line":663,"address":[],"length":0,"stats":{"Line":1208}},{"line":664,"address":[],"length":0,"stats":{"Line":0}},{"line":665,"address":[],"length":0,"stats":{"Line":0}},{"line":666,"address":[],"length":0,"stats":{"Line":0}},{"line":667,"address":[],"length":0,"stats":{"Line":0}},{"line":668,"address":[],"length":0,"stats":{"Line":0}},{"line":669,"address":[],"length":0,"stats":{"Line":0}},{"line":670,"address":[],"length":0,"stats":{"Line":0}},{"line":671,"address":[],"length":0,"stats":{"Line":0}},{"line":673,"address":[],"length":0,"stats":{"Line":0}},{"line":674,"address":[],"length":0,"stats":{"Line":0}},{"line":684,"address":[],"length":0,"stats":{"Line":2416}},{"line":687,"address":[],"length":0,"stats":{"Line":3624}},{"line":689,"address":[],"length":0,"stats":{"Line":2416}},{"line":690,"address":[],"length":0,"stats":{"Line":1208}},{"line":692,"address":[],"length":0,"stats":{"Line":6040}},{"line":694,"address":[],"length":0,"stats":{"Line":8}},{"line":695,"address":[],"length":0,"stats":{"Line":2416}},{"line":697,"address":[],"length":0,"stats":{"Line":12}},{"line":698,"address":[],"length":0,"stats":{"Line":18}},{"line":699,"address":[],"length":0,"stats":{"Line":10}},{"line":700,"address":[],"length":0,"stats":{"Line":8}},{"line":701,"address":[],"length":0,"stats":{"Line":12}},{"line":702,"address":[],"length":0,"stats":{"Line":12}},{"line":703,"address":[],"length":0,"stats":{"Line":12}},{"line":704,"address":[],"length":0,"stats":{"Line":4}},{"line":708,"address":[],"length":0,"stats":{"Line":12}},{"line":709,"address":[],"length":0,"stats":{"Line":8}},{"line":711,"address":[],"length":0,"stats":{"Line":4}},{"line":713,"address":[],"length":0,"stats":{"Line":20}},{"line":716,"address":[],"length":0,"stats":{"Line":6}},{"line":718,"address":[],"length":0,"stats":{"Line":4}},{"line":722,"address":[],"length":0,"stats":{"Line":4}},{"line":723,"address":[],"length":0,"stats":{"Line":4}},{"line":724,"address":[],"length":0,"stats":{"Line":4}},{"line":725,"address":[],"length":0,"stats":{"Line":4}},{"line":726,"address":[],"length":0,"stats":{"Line":2}},{"line":728,"address":[],"length":0,"stats":{"Line":10}},{"line":733,"address":[],"length":0,"stats":{"Line":1208}},{"line":735,"address":[],"length":0,"stats":{"Line":1}},{"line":736,"address":[],"length":0,"stats":{"Line":2}},{"line":737,"address":[],"length":0,"stats":{"Line":4}},{"line":738,"address":[],"length":0,"stats":{"Line":1}},{"line":743,"address":[],"length":0,"stats":{"Line":23}},{"line":749,"address":[],"length":0,"stats":{"Line":22}},{"line":750,"address":[],"length":0,"stats":{"Line":46}},{"line":751,"address":[],"length":0,"stats":{"Line":46}},{"line":752,"address":[],"length":0,"stats":{"Line":23}},{"line":757,"address":[],"length":0,"stats":{"Line":110}},{"line":759,"address":[],"length":0,"stats":{"Line":22}},{"line":760,"address":[],"length":0,"stats":{"Line":0}},{"line":761,"address":[],"length":0,"stats":{"Line":0}},{"line":762,"address":[],"length":0,"stats":{"Line":0}},{"line":764,"address":[],"length":0,"stats":{"Line":0}},{"line":768,"address":[],"length":0,"stats":{"Line":44}},{"line":771,"address":[],"length":0,"stats":{"Line":66}},{"line":773,"address":[],"length":0,"stats":{"Line":44}},{"line":774,"address":[],"length":0,"stats":{"Line":22}},{"line":776,"address":[],"length":0,"stats":{"Line":110}},{"line":777,"address":[],"length":0,"stats":{"Line":22}},{"line":779,"address":[],"length":0,"stats":{"Line":0}},{"line":783,"address":[],"length":0,"stats":{"Line":3}},{"line":790,"address":[],"length":0,"stats":{"Line":9}},{"line":791,"address":[],"length":0,"stats":{"Line":15}},{"line":792,"address":[],"length":0,"stats":{"Line":3}},{"line":793,"address":[],"length":0,"stats":{"Line":3}},{"line":795,"address":[],"length":0,"stats":{"Line":9}},{"line":796,"address":[],"length":0,"stats":{"Line":9}},{"line":797,"address":[],"length":0,"stats":{"Line":9}},{"line":798,"address":[],"length":0,"stats":{"Line":3}},{"line":800,"address":[],"length":0,"stats":{"Line":3}},{"line":801,"address":[],"length":0,"stats":{"Line":6}},{"line":802,"address":[],"length":0,"stats":{"Line":6}},{"line":803,"address":[],"length":0,"stats":{"Line":3}},{"line":808,"address":[],"length":0,"stats":{"Line":9}},{"line":810,"address":[],"length":0,"stats":{"Line":6}},{"line":813,"address":[],"length":0,"stats":{"Line":9}},{"line":814,"address":[],"length":0,"stats":{"Line":6}},{"line":815,"address":[],"length":0,"stats":{"Line":6}},{"line":816,"address":[],"length":0,"stats":{"Line":3}},{"line":818,"address":[],"length":0,"stats":{"Line":6}},{"line":819,"address":[],"length":0,"stats":{"Line":6}},{"line":821,"address":[],"length":0,"stats":{"Line":6}},{"line":823,"address":[],"length":0,"stats":{"Line":3}},{"line":826,"address":[],"length":0,"stats":{"Line":1}},{"line":832,"address":[],"length":0,"stats":{"Line":6}},{"line":833,"address":[],"length":0,"stats":{"Line":2}},{"line":836,"address":[],"length":0,"stats":{"Line":2}},{"line":837,"address":[],"length":0,"stats":{"Line":3}},{"line":838,"address":[],"length":0,"stats":{"Line":2}},{"line":839,"address":[],"length":0,"stats":{"Line":3}},{"line":841,"address":[],"length":0,"stats":{"Line":2}},{"line":842,"address":[],"length":0,"stats":{"Line":1}},{"line":843,"address":[],"length":0,"stats":{"Line":1}},{"line":844,"address":[],"length":0,"stats":{"Line":0}},{"line":845,"address":[],"length":0,"stats":{"Line":0}},{"line":847,"address":[],"length":0,"stats":{"Line":0}},{"line":850,"address":[],"length":0,"stats":{"Line":0}},{"line":851,"address":[],"length":0,"stats":{"Line":0}},{"line":852,"address":[],"length":0,"stats":{"Line":0}},{"line":856,"address":[],"length":0,"stats":{"Line":2}},{"line":857,"address":[],"length":0,"stats":{"Line":3}},{"line":862,"address":[],"length":0,"stats":{"Line":3}},{"line":863,"address":[],"length":0,"stats":{"Line":2}},{"line":865,"address":[],"length":0,"stats":{"Line":3}},{"line":866,"address":[],"length":0,"stats":{"Line":1}},{"line":869,"address":[],"length":0,"stats":{"Line":6}},{"line":871,"address":[],"length":0,"stats":{"Line":2}},{"line":874,"address":[],"length":0,"stats":{"Line":3}},{"line":876,"address":[],"length":0,"stats":{"Line":2}},{"line":880,"address":[],"length":0,"stats":{"Line":1}},{"line":882,"address":[],"length":0,"stats":{"Line":2}},{"line":883,"address":[],"length":0,"stats":{"Line":2}},{"line":885,"address":[],"length":0,"stats":{"Line":2}},{"line":888,"address":[],"length":0,"stats":{"Line":1}},{"line":891,"address":[],"length":0,"stats":{"Line":47}},{"line":897,"address":[],"length":0,"stats":{"Line":30}},{"line":898,"address":[],"length":0,"stats":{"Line":94}},{"line":899,"address":[],"length":0,"stats":{"Line":94}},{"line":900,"address":[],"length":0,"stats":{"Line":47}},{"line":905,"address":[],"length":0,"stats":{"Line":150}},{"line":907,"address":[],"length":0,"stats":{"Line":53}},{"line":908,"address":[],"length":0,"stats":{"Line":69}},{"line":909,"address":[],"length":0,"stats":{"Line":46}},{"line":910,"address":[],"length":0,"stats":{"Line":23}},{"line":911,"address":[],"length":0,"stats":{"Line":46}},{"line":912,"address":[],"length":0,"stats":{"Line":33}},{"line":913,"address":[],"length":0,"stats":{"Line":23}},{"line":916,"address":[],"length":0,"stats":{"Line":23}},{"line":917,"address":[],"length":0,"stats":{"Line":23}},{"line":918,"address":[],"length":0,"stats":{"Line":92}},{"line":919,"address":[],"length":0,"stats":{"Line":23}},{"line":920,"address":[],"length":0,"stats":{"Line":23}},{"line":921,"address":[],"length":0,"stats":{"Line":92}},{"line":922,"address":[],"length":0,"stats":{"Line":23}},{"line":924,"address":[],"length":0,"stats":{"Line":92}},{"line":926,"address":[],"length":0,"stats":{"Line":46}},{"line":929,"address":[],"length":0,"stats":{"Line":69}},{"line":931,"address":[],"length":0,"stats":{"Line":46}},{"line":932,"address":[],"length":0,"stats":{"Line":23}},{"line":934,"address":[],"length":0,"stats":{"Line":115}},{"line":936,"address":[],"length":0,"stats":{"Line":23}},{"line":938,"address":[],"length":0,"stats":{"Line":7}},{"line":942,"address":[],"length":0,"stats":{"Line":22}},{"line":947,"address":[],"length":0,"stats":{"Line":21}},{"line":948,"address":[],"length":0,"stats":{"Line":44}},{"line":949,"address":[],"length":0,"stats":{"Line":44}},{"line":950,"address":[],"length":0,"stats":{"Line":22}},{"line":955,"address":[],"length":0,"stats":{"Line":105}},{"line":956,"address":[],"length":0,"stats":{"Line":20}},{"line":959,"address":[],"length":0,"stats":{"Line":1}},{"line":964,"address":[],"length":0,"stats":{"Line":6}},{"line":965,"address":[],"length":0,"stats":{"Line":2}},{"line":966,"address":[],"length":0,"stats":{"Line":3}},{"line":967,"address":[],"length":0,"stats":{"Line":2}},{"line":968,"address":[],"length":0,"stats":{"Line":2}},{"line":970,"address":[],"length":0,"stats":{"Line":2}},{"line":971,"address":[],"length":0,"stats":{"Line":0}},{"line":974,"address":[],"length":0,"stats":{"Line":1}},{"line":975,"address":[],"length":0,"stats":{"Line":2}},{"line":976,"address":[],"length":0,"stats":{"Line":2}},{"line":977,"address":[],"length":0,"stats":{"Line":1}},{"line":982,"address":[],"length":0,"stats":{"Line":3}},{"line":983,"address":[],"length":0,"stats":{"Line":2}},{"line":984,"address":[],"length":0,"stats":{"Line":1}},{"line":985,"address":[],"length":0,"stats":{"Line":2}},{"line":986,"address":[],"length":0,"stats":{"Line":3}},{"line":987,"address":[],"length":0,"stats":{"Line":2}},{"line":988,"address":[],"length":0,"stats":{"Line":3}},{"line":990,"address":[],"length":0,"stats":{"Line":1}},{"line":991,"address":[],"length":0,"stats":{"Line":1}},{"line":992,"address":[],"length":0,"stats":{"Line":1}},{"line":993,"address":[],"length":0,"stats":{"Line":5}},{"line":995,"address":[],"length":0,"stats":{"Line":2}},{"line":998,"address":[],"length":0,"stats":{"Line":3}},{"line":1000,"address":[],"length":0,"stats":{"Line":1}},{"line":1006,"address":[],"length":0,"stats":{"Line":2}},{"line":1007,"address":[],"length":0,"stats":{"Line":2}},{"line":1009,"address":[],"length":0,"stats":{"Line":2}},{"line":1011,"address":[],"length":0,"stats":{"Line":1}},{"line":1016,"address":[],"length":0,"stats":{"Line":1}},{"line":1019,"address":[],"length":0,"stats":{"Line":2}},{"line":1026,"address":[],"length":0,"stats":{"Line":4}},{"line":1027,"address":[],"length":0,"stats":{"Line":1}},{"line":1030,"address":[],"length":0,"stats":{"Line":3}},{"line":1031,"address":[],"length":0,"stats":{"Line":5}},{"line":1032,"address":[],"length":0,"stats":{"Line":1}},{"line":1033,"address":[],"length":0,"stats":{"Line":1}},{"line":1035,"address":[],"length":0,"stats":{"Line":3}},{"line":1036,"address":[],"length":0,"stats":{"Line":3}},{"line":1037,"address":[],"length":0,"stats":{"Line":1}},{"line":1039,"address":[],"length":0,"stats":{"Line":3}},{"line":1040,"address":[],"length":0,"stats":{"Line":2}},{"line":1041,"address":[],"length":0,"stats":{"Line":2}},{"line":1042,"address":[],"length":0,"stats":{"Line":1}},{"line":1044,"address":[],"length":0,"stats":{"Line":1}},{"line":1045,"address":[],"length":0,"stats":{"Line":1}},{"line":1046,"address":[],"length":0,"stats":{"Line":4}},{"line":1048,"address":[],"length":0,"stats":{"Line":5}},{"line":1051,"address":[],"length":0,"stats":{"Line":3}},{"line":1057,"address":[],"length":0,"stats":{"Line":12}},{"line":1058,"address":[],"length":0,"stats":{"Line":9}},{"line":1059,"address":[],"length":0,"stats":{"Line":9}},{"line":1060,"address":[],"length":0,"stats":{"Line":9}},{"line":1061,"address":[],"length":0,"stats":{"Line":9}},{"line":1062,"address":[],"length":0,"stats":{"Line":9}},{"line":1063,"address":[],"length":0,"stats":{"Line":9}},{"line":1064,"address":[],"length":0,"stats":{"Line":9}},{"line":1065,"address":[],"length":0,"stats":{"Line":9}},{"line":1066,"address":[],"length":0,"stats":{"Line":9}},{"line":1067,"address":[],"length":0,"stats":{"Line":9}},{"line":1068,"address":[],"length":0,"stats":{"Line":9}},{"line":1069,"address":[],"length":0,"stats":{"Line":3}},{"line":1071,"address":[],"length":0,"stats":{"Line":9}},{"line":1072,"address":[],"length":0,"stats":{"Line":9}},{"line":1074,"address":[],"length":0,"stats":{"Line":6}},{"line":1075,"address":[],"length":0,"stats":{"Line":12}},{"line":1076,"address":[],"length":0,"stats":{"Line":3}},{"line":1077,"address":[],"length":0,"stats":{"Line":4}},{"line":1078,"address":[],"length":0,"stats":{"Line":3}},{"line":1079,"address":[],"length":0,"stats":{"Line":2}},{"line":1080,"address":[],"length":0,"stats":{"Line":2}},{"line":1081,"address":[],"length":0,"stats":{"Line":1}},{"line":1085,"address":[],"length":0,"stats":{"Line":2}},{"line":1090,"address":[],"length":0,"stats":{"Line":2}},{"line":1092,"address":[],"length":0,"stats":{"Line":10}},{"line":1093,"address":[],"length":0,"stats":{"Line":3}},{"line":1095,"address":[],"length":0,"stats":{"Line":5}},{"line":1096,"address":[],"length":0,"stats":{"Line":1}},{"line":1098,"address":[],"length":0,"stats":{"Line":5}},{"line":1099,"address":[],"length":0,"stats":{"Line":1}},{"line":1101,"address":[],"length":0,"stats":{"Line":1}},{"line":1104,"address":[],"length":0,"stats":{"Line":2}},{"line":1109,"address":[],"length":0,"stats":{"Line":2}},{"line":1111,"address":[],"length":0,"stats":{"Line":11}},{"line":1113,"address":[],"length":0,"stats":{"Line":5}},{"line":1114,"address":[],"length":0,"stats":{"Line":1}},{"line":1116,"address":[],"length":0,"stats":{"Line":5}},{"line":1117,"address":[],"length":0,"stats":{"Line":1}},{"line":1119,"address":[],"length":0,"stats":{"Line":1}},{"line":1122,"address":[],"length":0,"stats":{"Line":1}},{"line":1128,"address":[],"length":0,"stats":{"Line":2}},{"line":1129,"address":[],"length":0,"stats":{"Line":1}},{"line":1132,"address":[],"length":0,"stats":{"Line":2}},{"line":1133,"address":[],"length":0,"stats":{"Line":3}},{"line":1134,"address":[],"length":0,"stats":{"Line":1}},{"line":1135,"address":[],"length":0,"stats":{"Line":1}},{"line":1138,"address":[],"length":0,"stats":{"Line":1}},{"line":1146,"address":[],"length":0,"stats":{"Line":2}},{"line":1147,"address":[],"length":0,"stats":{"Line":1}},{"line":1150,"address":[],"length":0,"stats":{"Line":2}},{"line":1151,"address":[],"length":0,"stats":{"Line":2}},{"line":1152,"address":[],"length":0,"stats":{"Line":1}},{"line":1153,"address":[],"length":0,"stats":{"Line":1}},{"line":1156,"address":[],"length":0,"stats":{"Line":0}},{"line":1163,"address":[],"length":0,"stats":{"Line":0}},{"line":1164,"address":[],"length":0,"stats":{"Line":0}},{"line":1167,"address":[],"length":0,"stats":{"Line":0}},{"line":1168,"address":[],"length":0,"stats":{"Line":0}},{"line":1169,"address":[],"length":0,"stats":{"Line":0}},{"line":1170,"address":[],"length":0,"stats":{"Line":0}}],"covered":505,"coverable":557},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","multi_hop.rs"],"content":"use std::sync::Arc;\nuse std::sync::atomic::{AtomicU32, Ordering};\n\n#[derive(Debug, Clone)]\npub struct MultiHopConfig {\n    pub max_hop_depth: u32,\n    pub hop_relevance_threshold: f32,\n    pub max_query_budget: u32,\n}\n\nimpl Default for MultiHopConfig {\n    fn default() -> Self {\n        Self {\n            max_hop_depth: 3,\n            hop_relevance_threshold: 0.3,\n            max_query_budget: 50,\n        }\n    }\n}\n\nimpl From<&config::ReasoningConfig> for MultiHopConfig {\n    fn from(config: &config::ReasoningConfig) -> Self {\n        Self {\n            max_hop_depth: config.max_hop_depth,\n            hop_relevance_threshold: config.hop_relevance_threshold,\n            max_query_budget: config.max_query_budget,\n        }\n    }\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum TerminationReason {\n    MaxDepthReached,\n    LowRelevance,\n    QueryBudgetExhausted,\n    NoMoreResults,\n    Completed,\n}\n\npub struct MultiHopContext {\n    config: MultiHopConfig,\n    current_depth: AtomicU32,\n    queries_executed: AtomicU32,\n    paths_terminated_depth: AtomicU32,\n    paths_terminated_relevance: AtomicU32,\n    paths_terminated_budget: AtomicU32,\n    telemetry: Arc<crate::telemetry::MemoryTelemetry>,\n}\n\nimpl MultiHopContext {\n    pub fn new(config: MultiHopConfig, telemetry: Arc<crate::telemetry::MemoryTelemetry>) -> Self {\n        Self {\n            config,\n            current_depth: AtomicU32::new(0),\n            queries_executed: AtomicU32::new(0),\n            paths_terminated_depth: AtomicU32::new(0),\n            paths_terminated_relevance: AtomicU32::new(0),\n            paths_terminated_budget: AtomicU32::new(0),\n            telemetry,\n        }\n    }\n\n    pub fn can_continue(&self, relevance_score: f32) -> Result<(), TerminationReason> {\n        let depth = self.current_depth.load(Ordering::SeqCst);\n        let queries = self.queries_executed.load(Ordering::SeqCst);\n\n        if depth >= self.config.max_hop_depth {\n            self.paths_terminated_depth.fetch_add(1, Ordering::SeqCst);\n            return Err(TerminationReason::MaxDepthReached);\n        }\n\n        if relevance_score < self.config.hop_relevance_threshold {\n            self.paths_terminated_relevance\n                .fetch_add(1, Ordering::SeqCst);\n            return Err(TerminationReason::LowRelevance);\n        }\n\n        if queries >= self.config.max_query_budget {\n            self.paths_terminated_budget.fetch_add(1, Ordering::SeqCst);\n            return Err(TerminationReason::QueryBudgetExhausted);\n        }\n\n        Ok(())\n    }\n\n    pub fn record_hop(&self) {\n        self.current_depth.fetch_add(1, Ordering::SeqCst);\n    }\n\n    pub fn record_query(&self) {\n        self.queries_executed.fetch_add(1, Ordering::SeqCst);\n    }\n\n    pub fn current_depth(&self) -> u32 {\n        self.current_depth.load(Ordering::SeqCst)\n    }\n\n    pub fn queries_executed(&self) -> u32 {\n        self.queries_executed.load(Ordering::SeqCst)\n    }\n\n    pub fn max_depth(&self) -> u32 {\n        self.config.max_hop_depth\n    }\n\n    pub fn query_budget(&self) -> u32 {\n        self.config.max_query_budget\n    }\n\n    pub fn relevance_threshold(&self) -> f32 {\n        self.config.hop_relevance_threshold\n    }\n\n    pub fn finalize(&self) -> MultiHopMetrics {\n        let metrics = MultiHopMetrics {\n            max_depth_reached: self.current_depth.load(Ordering::SeqCst),\n            total_queries: self.queries_executed.load(Ordering::SeqCst),\n            paths_terminated_depth: self.paths_terminated_depth.load(Ordering::SeqCst),\n            paths_terminated_relevance: self.paths_terminated_relevance.load(Ordering::SeqCst),\n            paths_terminated_budget: self.paths_terminated_budget.load(Ordering::SeqCst),\n        };\n\n        self.telemetry.record_multi_hop_metrics(&metrics);\n        metrics\n    }\n}\n\n#[derive(Debug, Clone, Default)]\npub struct MultiHopMetrics {\n    pub max_depth_reached: u32,\n    pub total_queries: u32,\n    pub paths_terminated_depth: u32,\n    pub paths_terminated_relevance: u32,\n    pub paths_terminated_budget: u32,\n}\n\nimpl MultiHopMetrics {\n    pub fn total_paths_terminated(&self) -> u32 {\n        self.paths_terminated_depth + self.paths_terminated_relevance + self.paths_terminated_budget\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    fn test_telemetry() -> Arc<crate::telemetry::MemoryTelemetry> {\n        Arc::new(crate::telemetry::MemoryTelemetry::new())\n    }\n\n    #[test]\n    fn test_default_config() {\n        let config = MultiHopConfig::default();\n        assert_eq!(config.max_hop_depth, 3);\n        assert!((config.hop_relevance_threshold - 0.3).abs() < f32::EPSILON);\n        assert_eq!(config.max_query_budget, 50);\n    }\n\n    #[test]\n    fn test_can_continue_at_max_depth() {\n        let config = MultiHopConfig {\n            max_hop_depth: 2,\n            ..Default::default()\n        };\n        let ctx = MultiHopContext::new(config, test_telemetry());\n\n        ctx.record_hop();\n        assert!(ctx.can_continue(0.5).is_ok());\n\n        ctx.record_hop();\n        assert_eq!(\n            ctx.can_continue(0.5),\n            Err(TerminationReason::MaxDepthReached)\n        );\n    }\n\n    #[test]\n    fn test_can_continue_low_relevance() {\n        let config = MultiHopConfig {\n            hop_relevance_threshold: 0.5,\n            ..Default::default()\n        };\n        let ctx = MultiHopContext::new(config, test_telemetry());\n\n        assert!(ctx.can_continue(0.6).is_ok());\n        assert_eq!(ctx.can_continue(0.4), Err(TerminationReason::LowRelevance));\n    }\n\n    #[test]\n    fn test_can_continue_budget_exhausted() {\n        let config = MultiHopConfig {\n            max_query_budget: 3,\n            ..Default::default()\n        };\n        let ctx = MultiHopContext::new(config, test_telemetry());\n\n        ctx.record_query();\n        ctx.record_query();\n        assert!(ctx.can_continue(0.5).is_ok());\n\n        ctx.record_query();\n        assert_eq!(\n            ctx.can_continue(0.5),\n            Err(TerminationReason::QueryBudgetExhausted)\n        );\n    }\n\n    #[test]\n    fn test_metrics_finalize() {\n        let config = MultiHopConfig {\n            max_hop_depth: 2,\n            hop_relevance_threshold: 0.5,\n            max_query_budget: 10,\n        };\n        let ctx = MultiHopContext::new(config, test_telemetry());\n\n        ctx.record_hop();\n        ctx.record_query();\n        ctx.record_query();\n\n        let _ = ctx.can_continue(0.3);\n        let _ = ctx.can_continue(0.3);\n\n        ctx.record_hop();\n        let _ = ctx.can_continue(0.6);\n\n        let metrics = ctx.finalize();\n        assert_eq!(metrics.max_depth_reached, 2);\n        assert_eq!(metrics.total_queries, 2);\n        assert_eq!(metrics.paths_terminated_relevance, 2);\n        assert_eq!(metrics.paths_terminated_depth, 1);\n    }\n\n    #[test]\n    fn test_context_accessors() {\n        let config = MultiHopConfig {\n            max_hop_depth: 5,\n            hop_relevance_threshold: 0.25,\n            max_query_budget: 100,\n        };\n        let ctx = MultiHopContext::new(config, test_telemetry());\n\n        assert_eq!(ctx.max_depth(), 5);\n        assert!((ctx.relevance_threshold() - 0.25).abs() < f32::EPSILON);\n        assert_eq!(ctx.query_budget(), 100);\n        assert_eq!(ctx.current_depth(), 0);\n        assert_eq!(ctx.queries_executed(), 0);\n\n        ctx.record_hop();\n        ctx.record_query();\n\n        assert_eq!(ctx.current_depth(), 1);\n        assert_eq!(ctx.queries_executed(), 1);\n    }\n\n    #[test]\n    fn test_total_paths_terminated() {\n        let metrics = MultiHopMetrics {\n            max_depth_reached: 3,\n            total_queries: 10,\n            paths_terminated_depth: 2,\n            paths_terminated_relevance: 5,\n            paths_terminated_budget: 1,\n        };\n        assert_eq!(metrics.total_paths_terminated(), 8);\n    }\n}\n","traces":[{"line":12,"address":[],"length":0,"stats":{"Line":4}},{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":5}},{"line":54,"address":[],"length":0,"stats":{"Line":10}},{"line":55,"address":[],"length":0,"stats":{"Line":10}},{"line":56,"address":[],"length":0,"stats":{"Line":10}},{"line":57,"address":[],"length":0,"stats":{"Line":10}},{"line":58,"address":[],"length":0,"stats":{"Line":5}},{"line":63,"address":[],"length":0,"stats":{"Line":9}},{"line":64,"address":[],"length":0,"stats":{"Line":36}},{"line":65,"address":[],"length":0,"stats":{"Line":36}},{"line":67,"address":[],"length":0,"stats":{"Line":9}},{"line":68,"address":[],"length":0,"stats":{"Line":6}},{"line":69,"address":[],"length":0,"stats":{"Line":2}},{"line":72,"address":[],"length":0,"stats":{"Line":7}},{"line":73,"address":[],"length":0,"stats":{"Line":3}},{"line":74,"address":[],"length":0,"stats":{"Line":6}},{"line":75,"address":[],"length":0,"stats":{"Line":3}},{"line":78,"address":[],"length":0,"stats":{"Line":4}},{"line":79,"address":[],"length":0,"stats":{"Line":3}},{"line":80,"address":[],"length":0,"stats":{"Line":1}},{"line":83,"address":[],"length":0,"stats":{"Line":3}},{"line":86,"address":[],"length":0,"stats":{"Line":5}},{"line":87,"address":[],"length":0,"stats":{"Line":15}},{"line":90,"address":[],"length":0,"stats":{"Line":6}},{"line":91,"address":[],"length":0,"stats":{"Line":18}},{"line":94,"address":[],"length":0,"stats":{"Line":2}},{"line":95,"address":[],"length":0,"stats":{"Line":6}},{"line":98,"address":[],"length":0,"stats":{"Line":2}},{"line":99,"address":[],"length":0,"stats":{"Line":6}},{"line":102,"address":[],"length":0,"stats":{"Line":1}},{"line":103,"address":[],"length":0,"stats":{"Line":1}},{"line":106,"address":[],"length":0,"stats":{"Line":1}},{"line":107,"address":[],"length":0,"stats":{"Line":1}},{"line":110,"address":[],"length":0,"stats":{"Line":1}},{"line":111,"address":[],"length":0,"stats":{"Line":1}},{"line":114,"address":[],"length":0,"stats":{"Line":1}},{"line":116,"address":[],"length":0,"stats":{"Line":4}},{"line":117,"address":[],"length":0,"stats":{"Line":4}},{"line":118,"address":[],"length":0,"stats":{"Line":4}},{"line":119,"address":[],"length":0,"stats":{"Line":4}},{"line":120,"address":[],"length":0,"stats":{"Line":2}},{"line":123,"address":[],"length":0,"stats":{"Line":2}},{"line":124,"address":[],"length":0,"stats":{"Line":1}},{"line":138,"address":[],"length":0,"stats":{"Line":1}},{"line":139,"address":[],"length":0,"stats":{"Line":1}}],"covered":45,"coverable":49},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","opencode.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","pointer.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","pool.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","postgres.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","procedural.rs"],"content":"\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","promotion","mod.rs"],"content":"use crate::governance::GovernanceService;\nuse crate::manager::MemoryManager;\nuse crate::telemetry::MemoryTelemetry;\nuse anyhow::{Context, Result};\nuse mk_core::types::{MemoryEntry, MemoryLayer};\nuse std::sync::Arc;\nuse uuid::Uuid;\n\npub struct PromotionService {\n    memory_manager: Arc<MemoryManager>,\n    governance_service: Arc<GovernanceService>,\n    telemetry: Arc<MemoryTelemetry>,\n    config: config::MemoryConfig,\n    promote_important: bool,\n    cleanup_after_promotion: bool,\n}\n\nimpl PromotionService {\n    pub fn new(memory_manager: Arc<MemoryManager>) -> Self {\n        Self {\n            memory_manager,\n            governance_service: Arc::new(GovernanceService::new()),\n            telemetry: Arc::new(MemoryTelemetry::new()),\n            config: config::MemoryConfig::default(),\n            promote_important: true,\n            cleanup_after_promotion: false,\n        }\n    }\n\n    pub fn with_config(mut self, config: config::MemoryConfig) -> Self {\n        self.config = config;\n        self\n    }\n\n    pub fn with_telemetry(mut self, telemetry: Arc<MemoryTelemetry>) -> Self {\n        self.telemetry = telemetry;\n        self\n    }\n\n    pub fn with_promote_important(mut self, promote: bool) -> Self {\n        self.promote_important = promote;\n        self\n    }\n\n    pub fn with_cleanup(mut self, cleanup: bool) -> Self {\n        self.cleanup_after_promotion = cleanup;\n        self\n    }\n\n    pub async fn evaluate_and_promote(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        entry: &MemoryEntry,\n    ) -> Result<Option<String>> {\n        if !self.promote_important {\n            return Ok(None);\n        }\n\n        let metadata_value = serde_json::to_value(&entry.metadata).unwrap_or(serde_json::json!({}));\n        if !self\n            .governance_service\n            .can_promote(&entry.content, &metadata_value)\n        {\n            tracing::info!(\"Memory {} promotion blocked by governance\", entry.id);\n            self.telemetry\n                .record_promotion_blocked(&format!(\"{:?}\", entry.layer), \"governance\");\n            return Ok(None);\n        }\n\n        let score = self.calculate_importance_score(entry);\n\n        if score >= self.config.promotion_threshold {\n            if let Some(target) = self.determine_target_layer(entry.layer) {\n                self.telemetry.record_promotion_attempt(\n                    &format!(\"{:?}\", entry.layer),\n                    &format!(\"{:?}\", target),\n                );\n                tracing::info!(\n                    \"Promoting memory {} from {:?} to {:?} (score: {:.2})\",\n                    entry.id,\n                    entry.layer,\n                    target,\n                    score\n                );\n\n                let mut promoted_entry = entry.clone();\n                promoted_entry.id = Uuid::new_v4().to_string();\n                promoted_entry.layer = target;\n                let original_content = entry.content.clone();\n                promoted_entry.content = self.governance_service.redact_pii(&entry.content);\n\n                if promoted_entry.content != original_content {\n                    self.telemetry\n                        .record_governance_redaction(&format!(\"{:?}\", target));\n                }\n\n                promoted_entry.metadata.insert(\n                    \"original_memory_id\".to_string(),\n                    serde_json::json!(entry.id),\n                );\n                promoted_entry.metadata.insert(\n                    \"promoted_at\".to_string(),\n                    serde_json::json!(chrono::Utc::now().timestamp()),\n                );\n                promoted_entry\n                    .metadata\n                    .insert(\"promotion_score\".to_string(), serde_json::json!(score));\n\n                let new_id = self\n                    .memory_manager\n                    .add_to_layer(ctx.clone(), target, promoted_entry)\n                    .await\n                    .map_err(|e| anyhow::anyhow!(e))\n                    .context(\"Failed to add promoted memory to target layer\")?;\n\n                if self.cleanup_after_promotion {\n                    self.memory_manager\n                        .delete_from_layer(ctx, entry.layer, &entry.id)\n                        .await\n                        .map_err(|e| anyhow::anyhow!(e))\n                        .context(\"Failed to cleanup source memory after promotion\")?;\n                    tracing::info!(\n                        \"Cleaned up source memory {} from {:?}\",\n                        entry.id,\n                        entry.layer\n                    );\n                }\n\n                self.telemetry.record_promotion_success(\n                    &format!(\"{:?}\", entry.layer),\n                    &format!(\"{:?}\", target),\n                );\n                return Ok(Some(new_id));\n            }\n        }\n\n        Ok(None)\n    }\n\n    fn calculate_importance_score(&self, entry: &MemoryEntry) -> f32 {\n        let explicit_score = entry\n            .metadata\n            .get(\"score\")\n            .and_then(|v| v.as_f64())\n            .map(|v| v as f32)\n            .unwrap_or(0.0);\n\n        let access_count = entry\n            .metadata\n            .get(\"access_count\")\n            .and_then(|v| v.as_u64())\n            .unwrap_or(1) as f32;\n\n        let last_accessed = entry\n            .metadata\n            .get(\"last_accessed_at\")\n            .and_then(|v| v.as_i64())\n            .unwrap_or_else(|| chrono::Utc::now().timestamp()) as f32;\n\n        let now_ts = chrono::Utc::now().timestamp() as f32;\n        let days_since_last_access = (now_ts - last_accessed).max(0.0) / 86400.0;\n        let recency_score = (1.0f32 - days_since_last_access).max(0.0f32);\n\n        let frequency_score = (access_count / 10.0).min(1.0);\n\n        (explicit_score * 0.6) + (frequency_score * 0.3) + (recency_score * 0.1)\n    }\n\n    pub async fn promote_layer_memories(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer,\n        _identifiers: &mk_core::types::LayerIdentifiers,\n    ) -> Result<Vec<String>> {\n        let entries = self\n            .memory_manager\n            .list_all_from_layer(ctx.clone(), layer)\n            .await\n            .map_err(|e| anyhow::anyhow!(e))?;\n\n        let mut promoted_ids = Vec::new();\n        for entry in entries {\n            if let Some(new_id) = self.evaluate_and_promote(ctx.clone(), &entry).await? {\n                promoted_ids.push(new_id);\n            }\n        }\n        Ok(promoted_ids)\n    }\n\n    fn determine_target_layer(&self, current_layer: MemoryLayer) -> Option<MemoryLayer> {\n        match current_layer {\n            MemoryLayer::Agent => Some(MemoryLayer::User),\n            MemoryLayer::Session => Some(MemoryLayer::Project),\n            _ => None,\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::manager::tests::test_ctx;\n    use crate::providers::MockProvider;\n    use mk_core::types::MemoryEntry;\n    use std::collections::HashMap;\n\n    #[tokio::test]\n    async fn test_evaluate_and_promote_high_score() {\n        let manager = Arc::new(MemoryManager::new());\n        let ctx = test_ctx();\n        let mock_session: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        let mock_project: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n\n        manager\n            .register_provider(MemoryLayer::Session, mock_session)\n            .await;\n        manager\n            .register_provider(MemoryLayer::Project, mock_project)\n            .await;\n\n        let service = PromotionService::new(manager.clone()).with_config(config::MemoryConfig {\n            promotion_threshold: 0.7,\n            decay_interval_secs: 86400,\n            decay_rate: 0.05,\n            optimization_trigger_count: 100,\n            layer_summary_configs: std::collections::HashMap::new(),\n            reasoning: config::ReasoningConfig::default(),\n        });\n\n        let entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"mem_1\".to_string(),\n            content: \"important stuff\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(1.0));\n                m.insert(\"access_count\".to_string(), serde_json::json!(10));\n                m.insert(\n                    \"last_accessed_at\".to_string(),\n                    serde_json::json!(chrono::Utc::now().timestamp()),\n                );\n                m\n            },\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        let result = service\n            .evaluate_and_promote(ctx.clone(), &entry)\n            .await\n            .unwrap();\n        assert!(result.is_some());\n        let promoted_id = result.unwrap();\n\n        let promoted = manager\n            .get_from_layer(ctx.clone(), MemoryLayer::Project, &promoted_id)\n            .await\n            .unwrap();\n        assert!(promoted.is_some());\n        assert_eq!(\n            promoted\n                .unwrap()\n                .metadata\n                .get(\"original_memory_id\")\n                .unwrap(),\n            \"mem_1\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_evaluate_and_promote_low_score() {\n        let manager = Arc::new(MemoryManager::new());\n        let ctx = test_ctx();\n        let service = PromotionService::new(manager).with_config(config::MemoryConfig {\n            promotion_threshold: 0.7,\n            decay_interval_secs: 86400,\n            decay_rate: 0.05,\n            optimization_trigger_count: 100,\n            layer_summary_configs: std::collections::HashMap::new(),\n            reasoning: config::ReasoningConfig::default(),\n        });\n\n        let entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"mem_low\".to_string(),\n            content: \"boring stuff\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(0.2));\n                m\n            },\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        let result = service.evaluate_and_promote(ctx, &entry).await.unwrap();\n        assert!(result.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_promotion_blocked_by_governance() {\n        let manager = Arc::new(MemoryManager::new());\n        let ctx = test_ctx();\n        let service = PromotionService::new(manager);\n\n        let entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"mem_sensitive\".to_string(),\n            content: \"secret stuff\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(1.0));\n                m.insert(\"sensitive\".to_string(), serde_json::json!(true));\n                m\n            },\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        let result = service.evaluate_and_promote(ctx, &entry).await.unwrap();\n        assert!(result.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_promotion_redacts_pii() {\n        let manager = Arc::new(MemoryManager::new());\n        let ctx = test_ctx();\n        let mock_session: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        let mock_project: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        manager\n            .register_provider(MemoryLayer::Session, mock_session)\n            .await;\n        manager\n            .register_provider(MemoryLayer::Project, mock_project)\n            .await;\n\n        let service = PromotionService::new(manager.clone()).with_config(config::MemoryConfig {\n            promotion_threshold: 0.0,\n            decay_interval_secs: 86400,\n            decay_rate: 0.05,\n            optimization_trigger_count: 100,\n            layer_summary_configs: std::collections::HashMap::new(),\n            reasoning: config::ReasoningConfig::default(),\n        });\n\n        let entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"mem_pii\".to_string(),\n            content: \"Contact user@example.com\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        let result = service\n            .evaluate_and_promote(ctx.clone(), &entry)\n            .await\n            .unwrap();\n        assert!(result.is_some());\n\n        let promoted = manager\n            .get_from_layer(ctx, MemoryLayer::Project, result.unwrap().as_str())\n            .await\n            .unwrap()\n            .unwrap();\n        assert_eq!(promoted.content, \"Contact [REDACTED_EMAIL]\");\n    }\n\n    #[tokio::test]\n    async fn test_promotion_cleanup() {\n        let manager = Arc::new(MemoryManager::new());\n        let ctx = test_ctx();\n        let mock_session: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        let mock_project: Arc<\n            dyn mk_core::traits::MemoryProviderAdapter<\n                    Error = Box<dyn std::error::Error + Send + Sync>,\n                > + Send\n                + Sync,\n        > = Arc::new(MockProvider::new());\n        manager\n            .register_provider(MemoryLayer::Session, mock_session)\n            .await;\n        manager\n            .register_provider(MemoryLayer::Project, mock_project)\n            .await;\n\n        let service = PromotionService::new(manager.clone())\n            .with_config(config::MemoryConfig {\n                promotion_threshold: 0.0,\n                decay_interval_secs: 86400,\n                decay_rate: 0.05,\n                optimization_trigger_count: 100,\n                layer_summary_configs: std::collections::HashMap::new(),\n                reasoning: config::ReasoningConfig::default(),\n            })\n            .with_cleanup(true);\n\n        let entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"mem_cleanup\".to_string(),\n            content: \"cleanup test\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Session, entry.clone())\n            .await\n            .unwrap();\n\n        let result = service\n            .evaluate_and_promote(ctx.clone(), &entry)\n            .await\n            .unwrap();\n        assert!(result.is_some());\n\n        let promoted = manager\n            .get_from_layer(ctx.clone(), MemoryLayer::Project, result.unwrap().as_str())\n            .await\n            .unwrap();\n        assert!(promoted.is_some());\n\n        let original = manager\n            .get_from_layer(ctx, MemoryLayer::Session, \"mem_cleanup\")\n            .await\n            .unwrap();\n        assert!(original.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_with_promote_important_false() {\n        let manager = Arc::new(MemoryManager::new());\n        let ctx = test_ctx();\n        let service = PromotionService::new(manager).with_promote_important(false);\n\n        let entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"test\".to_string(),\n            content: \"test\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        let result = service.evaluate_and_promote(ctx, &entry).await.unwrap();\n        assert!(result.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_determine_target_layer_none() {\n        let manager = Arc::new(MemoryManager::new());\n        let ctx = test_ctx();\n        let service = PromotionService::new(manager);\n\n        let entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"test\".to_string(),\n            content: \"test\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        let result = service.evaluate_and_promote(ctx, &entry).await.unwrap();\n        assert!(result.is_none());\n    }\n}\n","traces":[{"line":19,"address":[],"length":0,"stats":{"Line":10}},{"line":22,"address":[],"length":0,"stats":{"Line":30}},{"line":23,"address":[],"length":0,"stats":{"Line":20}},{"line":24,"address":[],"length":0,"stats":{"Line":10}},{"line":30,"address":[],"length":0,"stats":{"Line":7}},{"line":31,"address":[],"length":0,"stats":{"Line":14}},{"line":32,"address":[],"length":0,"stats":{"Line":7}},{"line":35,"address":[],"length":0,"stats":{"Line":3}},{"line":36,"address":[],"length":0,"stats":{"Line":6}},{"line":37,"address":[],"length":0,"stats":{"Line":3}},{"line":40,"address":[],"length":0,"stats":{"Line":1}},{"line":41,"address":[],"length":0,"stats":{"Line":1}},{"line":42,"address":[],"length":0,"stats":{"Line":1}},{"line":45,"address":[],"length":0,"stats":{"Line":1}},{"line":46,"address":[],"length":0,"stats":{"Line":1}},{"line":47,"address":[],"length":0,"stats":{"Line":1}},{"line":50,"address":[],"length":0,"stats":{"Line":9}},{"line":55,"address":[],"length":0,"stats":{"Line":9}},{"line":56,"address":[],"length":0,"stats":{"Line":1}},{"line":59,"address":[],"length":0,"stats":{"Line":40}},{"line":60,"address":[],"length":0,"stats":{"Line":16}},{"line":61,"address":[],"length":0,"stats":{"Line":16}},{"line":62,"address":[],"length":0,"stats":{"Line":16}},{"line":64,"address":[],"length":0,"stats":{"Line":1}},{"line":65,"address":[],"length":0,"stats":{"Line":2}},{"line":66,"address":[],"length":0,"stats":{"Line":2}},{"line":67,"address":[],"length":0,"stats":{"Line":1}},{"line":70,"address":[],"length":0,"stats":{"Line":28}},{"line":72,"address":[],"length":0,"stats":{"Line":7}},{"line":73,"address":[],"length":0,"stats":{"Line":15}},{"line":74,"address":[],"length":0,"stats":{"Line":15}},{"line":75,"address":[],"length":0,"stats":{"Line":10}},{"line":76,"address":[],"length":0,"stats":{"Line":5}},{"line":78,"address":[],"length":0,"stats":{"Line":5}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":15}},{"line":87,"address":[],"length":0,"stats":{"Line":15}},{"line":88,"address":[],"length":0,"stats":{"Line":5}},{"line":89,"address":[],"length":0,"stats":{"Line":15}},{"line":90,"address":[],"length":0,"stats":{"Line":15}},{"line":92,"address":[],"length":0,"stats":{"Line":6}},{"line":93,"address":[],"length":0,"stats":{"Line":2}},{"line":94,"address":[],"length":0,"stats":{"Line":2}},{"line":97,"address":[],"length":0,"stats":{"Line":10}},{"line":98,"address":[],"length":0,"stats":{"Line":10}},{"line":99,"address":[],"length":0,"stats":{"Line":5}},{"line":101,"address":[],"length":0,"stats":{"Line":10}},{"line":102,"address":[],"length":0,"stats":{"Line":10}},{"line":103,"address":[],"length":0,"stats":{"Line":15}},{"line":105,"address":[],"length":0,"stats":{"Line":5}},{"line":106,"address":[],"length":0,"stats":{"Line":5}},{"line":107,"address":[],"length":0,"stats":{"Line":20}},{"line":109,"address":[],"length":0,"stats":{"Line":15}},{"line":110,"address":[],"length":0,"stats":{"Line":10}},{"line":111,"address":[],"length":0,"stats":{"Line":20}},{"line":112,"address":[],"length":0,"stats":{"Line":5}},{"line":113,"address":[],"length":0,"stats":{"Line":5}},{"line":116,"address":[],"length":0,"stats":{"Line":5}},{"line":117,"address":[],"length":0,"stats":{"Line":2}},{"line":118,"address":[],"length":0,"stats":{"Line":3}},{"line":119,"address":[],"length":0,"stats":{"Line":1}},{"line":120,"address":[],"length":0,"stats":{"Line":1}},{"line":122,"address":[],"length":0,"stats":{"Line":1}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":15}},{"line":130,"address":[],"length":0,"stats":{"Line":10}},{"line":131,"address":[],"length":0,"stats":{"Line":5}},{"line":133,"address":[],"length":0,"stats":{"Line":5}},{"line":137,"address":[],"length":0,"stats":{"Line":2}},{"line":140,"address":[],"length":0,"stats":{"Line":7}},{"line":141,"address":[],"length":0,"stats":{"Line":14}},{"line":142,"address":[],"length":0,"stats":{"Line":7}},{"line":144,"address":[],"length":0,"stats":{"Line":15}},{"line":145,"address":[],"length":0,"stats":{"Line":11}},{"line":148,"address":[],"length":0,"stats":{"Line":14}},{"line":149,"address":[],"length":0,"stats":{"Line":7}},{"line":150,"address":[],"length":0,"stats":{"Line":14}},{"line":151,"address":[],"length":0,"stats":{"Line":9}},{"line":152,"address":[],"length":0,"stats":{"Line":7}},{"line":154,"address":[],"length":0,"stats":{"Line":14}},{"line":155,"address":[],"length":0,"stats":{"Line":7}},{"line":156,"address":[],"length":0,"stats":{"Line":14}},{"line":157,"address":[],"length":0,"stats":{"Line":9}},{"line":158,"address":[],"length":0,"stats":{"Line":19}},{"line":160,"address":[],"length":0,"stats":{"Line":14}},{"line":161,"address":[],"length":0,"stats":{"Line":14}},{"line":162,"address":[],"length":0,"stats":{"Line":21}},{"line":164,"address":[],"length":0,"stats":{"Line":21}},{"line":166,"address":[],"length":0,"stats":{"Line":7}},{"line":169,"address":[],"length":0,"stats":{"Line":3}},{"line":175,"address":[],"length":0,"stats":{"Line":8}},{"line":176,"address":[],"length":0,"stats":{"Line":6}},{"line":177,"address":[],"length":0,"stats":{"Line":9}},{"line":178,"address":[],"length":0,"stats":{"Line":3}},{"line":179,"address":[],"length":0,"stats":{"Line":6}},{"line":181,"address":[],"length":0,"stats":{"Line":4}},{"line":182,"address":[],"length":0,"stats":{"Line":6}},{"line":183,"address":[],"length":0,"stats":{"Line":14}},{"line":184,"address":[],"length":0,"stats":{"Line":4}},{"line":187,"address":[],"length":0,"stats":{"Line":2}},{"line":190,"address":[],"length":0,"stats":{"Line":5}},{"line":191,"address":[],"length":0,"stats":{"Line":5}},{"line":192,"address":[],"length":0,"stats":{"Line":1}},{"line":193,"address":[],"length":0,"stats":{"Line":4}},{"line":194,"address":[],"length":0,"stats":{"Line":0}}],"covered":102,"coverable":105},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","providers","mod.rs"],"content":"pub mod qdrant;\n\nuse async_trait::async_trait;\nuse mk_core::traits::MemoryProviderAdapter;\nuse mk_core::types::{MemoryEntry, MemoryLayer};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\npub struct MockProvider {\n    entries: Arc<RwLock<HashMap<String, MemoryEntry>>>,\n}\n\nimpl MockProvider {\n    pub fn new() -> Self {\n        Self {\n            entries: Arc::new(RwLock::new(HashMap::new())),\n        }\n    }\n}\n\nimpl Default for MockProvider {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n#[async_trait]\nimpl MemoryProviderAdapter for MockProvider {\n    type Error = Box<dyn std::error::Error + Send + Sync>;\n\n    async fn add(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        entry: MemoryEntry,\n    ) -> Result<String, Self::Error> {\n        let mut entries = self.entries.write().await;\n        let id = entry.id.clone();\n        let mut entry = entry;\n        entry\n            .metadata\n            .insert(\"tenant_id\".to_string(), serde_json::json!(ctx.tenant_id));\n        entries.insert(id.clone(), entry);\n        Ok(id)\n    }\n\n    async fn search(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        _query_vector: Vec<f32>,\n        limit: usize,\n        filters: HashMap<String, serde_json::Value>,\n    ) -> Result<Vec<MemoryEntry>, Self::Error> {\n        let entries = self.entries.read().await;\n        let results: Vec<MemoryEntry> = entries\n            .values()\n            .filter(|entry| {\n                // Ensure tenant isolation in mock search\n                if entry.metadata.get(\"tenant_id\") != Some(&serde_json::json!(ctx.tenant_id)) {\n                    return false;\n                }\n                for (key, val) in &filters {\n                    if entry.metadata.get(key) != Some(val) {\n                        return false;\n                    }\n                }\n                true\n            })\n            .take(limit)\n            .cloned()\n            .collect();\n        Ok(results)\n    }\n\n    async fn get(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        id: &str,\n    ) -> Result<Option<MemoryEntry>, Self::Error> {\n        let entries = self.entries.read().await;\n        if let Some(entry) = entries.get(id) {\n            if entry.metadata.get(\"tenant_id\") == Some(&serde_json::json!(ctx.tenant_id)) {\n                return Ok(Some(entry.clone()));\n            }\n        }\n        Ok(None)\n    }\n\n    async fn update(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        entry: MemoryEntry,\n    ) -> Result<(), Self::Error> {\n        let mut entries = self.entries.write().await;\n        if let Some(existing) = entries.get(&entry.id) {\n            if existing.metadata.get(\"tenant_id\") == Some(&serde_json::json!(ctx.tenant_id)) {\n                let mut entry = entry;\n                entry\n                    .metadata\n                    .insert(\"tenant_id\".to_string(), serde_json::json!(ctx.tenant_id));\n                entries.insert(entry.id.clone(), entry);\n                return Ok(());\n            }\n        }\n        Err(\"Entry not found or access denied\".into())\n    }\n\n    async fn delete(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        id: &str,\n    ) -> Result<(), Self::Error> {\n        let mut entries = self.entries.write().await;\n        if let Some(existing) = entries.get(id) {\n            if existing.metadata.get(\"tenant_id\") == Some(&serde_json::json!(ctx.tenant_id)) {\n                entries.remove(id);\n            }\n        }\n        Ok(())\n    }\n\n    async fn list(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer,\n        limit: usize,\n        cursor: Option<String>,\n    ) -> Result<(Vec<MemoryEntry>, Option<String>), Self::Error> {\n        let entries = self.entries.read().await;\n        let mut results: Vec<MemoryEntry> = entries\n            .values()\n            .filter(|e| {\n                e.layer == layer\n                    && e.metadata.get(\"tenant_id\") == Some(&serde_json::json!(ctx.tenant_id))\n            })\n            .collect::<Vec<_>>()\n            .into_iter()\n            .cloned()\n            .collect();\n\n        results.sort_by(|a, b| a.id.cmp(&b.id));\n\n        let start_index = if let Some(c) = cursor {\n            results\n                .iter()\n                .position(|e| e.id == c)\n                .map(|p| p + 1)\n                .unwrap_or(0)\n        } else {\n            0\n        };\n\n        let page = results\n            .iter()\n            .skip(start_index)\n            .take(limit)\n            .cloned()\n            .collect::<Vec<_>>();\n        let next_cursor = if page.len() == limit && results.len() > start_index + limit {\n            page.last().map(|e| e.id.clone())\n        } else {\n            None\n        };\n\n        Ok((page, next_cursor))\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::{MemoryLayer, TenantContext};\n\n    fn test_ctx() -> TenantContext {\n        use std::str::FromStr;\n        TenantContext {\n            tenant_id: mk_core::types::TenantId::from_str(\"test-tenant\").unwrap(),\n            user_id: mk_core::types::UserId::from_str(\"test-user\").unwrap(),\n            agent_id: None,\n        }\n    }\n\n    #[tokio::test]\n    async fn test_mock_provider_basic_ops() {\n        let provider = MockProvider::new();\n        let ctx = test_ctx();\n        let entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"test1\".to_string(),\n            content: \"hello world\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        provider.add(ctx.clone(), entry.clone()).await.unwrap();\n\n        let retrieved = provider.get(ctx.clone(), \"test1\").await.unwrap().unwrap();\n        assert_eq!(retrieved.content, \"hello world\");\n\n        let mut updated = entry.clone();\n        updated.content = \"updated\".to_string();\n        provider.update(ctx.clone(), updated).await.unwrap();\n        assert_eq!(\n            provider\n                .get(ctx.clone(), \"test1\")\n                .await\n                .unwrap()\n                .unwrap()\n                .content,\n            \"updated\"\n        );\n\n        let (list, _) = provider\n            .list(ctx.clone(), MemoryLayer::Agent, 10, None)\n            .await\n            .unwrap();\n        assert_eq!(list.len(), 1);\n\n        provider.delete(ctx.clone(), \"test1\").await.unwrap();\n        assert!(provider.get(ctx.clone(), \"test1\").await.unwrap().is_none());\n    }\n\n    #[tokio::test]\n    async fn test_mock_provider_update_nonexistent() {\n        let provider = MockProvider::new();\n        let ctx = test_ctx();\n        let entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"ghost\".to_string(),\n            content: \"ghost\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0,\n        };\n        assert!(provider.update(ctx, entry).await.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_mock_provider_search() {\n        let provider = MockProvider::new();\n        let ctx = test_ctx();\n        let entry1 = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"1\".to_string(),\n            content: \"one\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"type\".to_string(), serde_json::json!(\"a\"));\n                m\n            },\n            created_at: 0,\n            updated_at: 0,\n        };\n        let entry2 = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"2\".to_string(),\n            content: \"two\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"type\".to_string(), serde_json::json!(\"b\"));\n                m\n            },\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        provider.add(ctx.clone(), entry1).await.unwrap();\n        provider.add(ctx.clone(), entry2).await.unwrap();\n\n        let mut filters = HashMap::new();\n        filters.insert(\"type\".to_string(), serde_json::json!(\"a\"));\n\n        let results = provider.search(ctx, vec![], 10, filters).await.unwrap();\n        assert_eq!(results.len(), 1);\n        assert_eq!(results[0].id, \"1\");\n    }\n\n    #[tokio::test]\n    async fn test_mock_provider_list_pagination() {\n        let provider = MockProvider::new();\n        let ctx = test_ctx();\n        for i in 0..5 {\n            let entry = MemoryEntry {\n                summaries: std::collections::HashMap::new(),\n                context_vector: None,\n                importance_score: None,\n                id: format!(\"{}\", i),\n                content: format!(\"content {}\", i),\n                embedding: None,\n                layer: MemoryLayer::Agent,\n                metadata: HashMap::new(),\n                created_at: 0,\n                updated_at: 0,\n            };\n            provider.add(ctx.clone(), entry).await.unwrap();\n        }\n\n        let (page1, cursor) = provider\n            .list(ctx.clone(), MemoryLayer::Agent, 2, None)\n            .await\n            .unwrap();\n        assert_eq!(page1.len(), 2);\n        assert!(cursor.is_some());\n\n        let (page2, cursor2) = provider\n            .list(ctx.clone(), MemoryLayer::Agent, 2, cursor)\n            .await\n            .unwrap();\n        assert_eq!(page2.len(), 2);\n        assert!(cursor2.is_some());\n\n        let (page3, cursor3) = provider\n            .list(ctx.clone(), MemoryLayer::Agent, 2, cursor2)\n            .await\n            .unwrap();\n        assert_eq!(page3.len(), 1);\n        assert!(cursor3.is_none());\n    }\n}\n","traces":[{"line":15,"address":[],"length":0,"stats":{"Line":219}},{"line":17,"address":[],"length":0,"stats":{"Line":438}},{"line":23,"address":[],"length":0,"stats":{"Line":0}},{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":174}},{"line":59,"address":[],"length":0,"stats":{"Line":348}},{"line":60,"address":[],"length":0,"stats":{"Line":10}},{"line":62,"address":[],"length":0,"stats":{"Line":184}},{"line":63,"address":[],"length":0,"stats":{"Line":14}},{"line":64,"address":[],"length":0,"stats":{"Line":1}},{"line":67,"address":[],"length":0,"stats":{"Line":163}},{"line":132,"address":[],"length":0,"stats":{"Line":500949}},{"line":133,"address":[],"length":0,"stats":{"Line":500949}},{"line":134,"address":[],"length":0,"stats":{"Line":1001898}},{"line":141,"address":[],"length":0,"stats":{"Line":14898483}},{"line":146,"address":[],"length":0,"stats":{"Line":12}},{"line":147,"address":[],"length":0,"stats":{"Line":2}},{"line":160,"address":[],"length":0,"stats":{"Line":4}}],"covered":16,"coverable":18},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","providers","qdrant.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::MemoryProviderAdapter;\nuse mk_core::types::{MemoryEntry, MemoryLayer};\nuse qdrant_client::{\n    Qdrant,\n    qdrant::{\n        Distance, PointId, PointStruct, ScoredPoint, Value as QdrantValue, VectorParams,\n        VectorsConfig, point_id::PointIdOptions, vectors_config::Config,\n    },\n};\nuse serde_json::{Value, json};\n\nuse std::collections::HashMap;\nuse std::sync::Arc;\n\npub struct QdrantProvider {\n    client: Arc<Qdrant>,\n    collection_name: String,\n    embedding_dimension: usize,\n}\n\nimpl QdrantProvider {\n    pub fn new(client: Qdrant, collection_name: String, embedding_dimension: usize) -> Self {\n        Self {\n            client: Arc::new(client),\n            collection_name,\n            embedding_dimension,\n        }\n    }\n\n    pub async fn ensure_collection(&self) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {\n        let collections_list = self.client.list_collections().await?;\n        let collection_exists = collections_list\n            .collections\n            .iter()\n            .any(|c| c.name == self.collection_name);\n\n        if !collection_exists {\n            use qdrant_client::qdrant::CreateCollectionBuilder;\n            let request = CreateCollectionBuilder::new(self.collection_name.clone())\n                .vectors_config(VectorsConfig {\n                    config: Some(Config::Params(VectorParams {\n                        size: self.embedding_dimension as u64,\n                        distance: Distance::Cosine.into(),\n                        ..Default::default()\n                    })),\n                });\n\n            self.client.create_collection(request).await?;\n        }\n\n        Ok(())\n    }\n\n    fn entry_to_point(\n        &self,\n        entry: &MemoryEntry,\n    ) -> Result<PointStruct, Box<dyn std::error::Error + Send + Sync>> {\n        let embedding = entry.embedding.as_ref().ok_or(\"Entry missing embedding\")?;\n\n        let mut payload: HashMap<String, QdrantValue> = HashMap::from([\n            (\"id\".to_string(), entry.id.clone().into()),\n            (\"content\".to_string(), entry.content.clone().into()),\n            (\n                \"layer\".to_string(),\n                serde_json::to_string(&entry.layer)?.into(),\n            ),\n            (\"created_at\".to_string(), entry.created_at.into()),\n            (\"updated_at\".to_string(), entry.updated_at.into()),\n        ]);\n\n        if let Some(tenant_id) = entry.metadata.get(\"tenant_id\") {\n            if let Some(tid) = tenant_id.as_str() {\n                payload.insert(\"tenant_id\".to_string(), tid.to_string().into());\n            }\n        }\n\n        payload.insert(\n            \"metadata\".to_string(),\n            serde_json::to_string(&entry.metadata)?.into(),\n        );\n\n        Ok(PointStruct {\n            id: Some(PointId::from(entry.id.clone())),\n            vectors: Some(embedding.clone().into()),\n            payload,\n        })\n    }\n\n    fn point_to_entry(\n        &self,\n        point: ScoredPoint,\n    ) -> Result<MemoryEntry, Box<dyn std::error::Error + Send + Sync>> {\n        let payload = point.payload;\n\n        let metadata_str = payload\n            .get(\"metadata\")\n            .and_then(|v| {\n                let v: Value = v.clone().into();\n                if v.is_string() {\n                    v.as_str().map(|s| s.to_string())\n                } else {\n                    None\n                }\n            })\n            .ok_or(\"Missing metadata in payload\")?;\n\n        let mut metadata: HashMap<String, Value> = serde_json::from_str(&metadata_str)?;\n        metadata.insert(\"score\".to_string(), json!(point.score));\n\n        let vector = match point.vectors {\n            Some(v) => v\n                .get_vector()\n                .and_then(|vec| match vec {\n                    qdrant_client::qdrant::vector_output::Vector::Dense(dense) => Some(dense.data),\n                    _ => None,\n                })\n                .ok_or(\"Unsupported or missing vector format\")?,\n            None => return Err(\"Point missing vector\".into()),\n        };\n\n        let layer_str = payload\n            .get(\"layer\")\n            .and_then(|v| {\n                let v: Value = v.clone().into();\n                if v.is_string() {\n                    v.as_str().map(|s| s.to_string())\n                } else {\n                    None\n                }\n            })\n            .ok_or(\"Missing layer\")?;\n        let layer: MemoryLayer = serde_json::from_str(&layer_str)?;\n\n        let id = payload\n            .get(\"id\")\n            .and_then(|v| {\n                let v: Value = v.clone().into();\n                v.as_str().map(|s| s.to_string())\n            })\n            .ok_or(\"Missing id\")?;\n\n        let content = payload\n            .get(\"content\")\n            .and_then(|v| {\n                let v: Value = v.clone().into();\n                v.as_str().map(|s| s.to_string())\n            })\n            .ok_or(\"Missing content\")?;\n\n        let created_at = payload\n            .get(\"created_at\")\n            .and_then(|v| {\n                let v: Value = v.clone().into();\n                v.as_i64()\n            })\n            .ok_or(\"Missing created_at\")?;\n\n        let updated_at = payload\n            .get(\"updated_at\")\n            .and_then(|v| {\n                let v: Value = v.clone().into();\n                v.as_i64()\n            })\n            .ok_or(\"Missing updated_at\")?;\n\n        Ok(MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id,\n            content,\n            embedding: Some(vector),\n            layer,\n            metadata,\n            created_at,\n            updated_at,\n        })\n    }\n}\n\n#[async_trait]\nimpl MemoryProviderAdapter for QdrantProvider {\n    type Error = Box<dyn std::error::Error + Send + Sync>;\n\n    async fn add(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        entry: MemoryEntry,\n    ) -> Result<String, Self::Error> {\n        self.ensure_collection().await?;\n        let mut entry = entry;\n\n        entry\n            .metadata\n            .insert(\"tenant_id\".to_string(), json!(ctx.tenant_id.as_str()));\n        entry\n            .metadata\n            .insert(\"user_id\".to_string(), json!(ctx.user_id.as_str()));\n\n        if let Some(agent_id) = &ctx.agent_id {\n            entry\n                .metadata\n                .insert(\"agent_id\".to_string(), json!(agent_id));\n        }\n\n        let point = self.entry_to_point(&entry)?;\n        use qdrant_client::qdrant::UpsertPointsBuilder;\n        let request = UpsertPointsBuilder::new(self.collection_name.clone(), vec![point]);\n        self.client.upsert_points(request).await?;\n        Ok(entry.id)\n    }\n\n    async fn search(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        query_vector: Vec<f32>,\n        limit: usize,\n        _filters: HashMap<String, Value>,\n    ) -> Result<Vec<MemoryEntry>, Self::Error> {\n        self.ensure_collection().await?;\n        use qdrant_client::qdrant::{Condition, Filter, SearchPointsBuilder};\n\n        let filter = Filter::all(vec![Condition::matches(\n            \"tenant_id\",\n            ctx.tenant_id.as_str().to_string(),\n        )]);\n\n        let request =\n            SearchPointsBuilder::new(self.collection_name.clone(), query_vector, limit as u64)\n                .with_payload(true)\n                .with_vectors(true)\n                .filter(filter);\n\n        let result = self.client.search_points(request).await?;\n        result\n            .result\n            .into_iter()\n            .map(|p| self.point_to_entry(p))\n            .collect()\n    }\n\n    async fn get(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        id: &str,\n    ) -> Result<Option<MemoryEntry>, Self::Error> {\n        self.ensure_collection().await?;\n        use qdrant_client::qdrant::GetPointsBuilder;\n\n        tracing::debug!(tenant_id = %ctx.tenant_id, \"Qdrant get point\");\n\n        let request = GetPointsBuilder::new(\n            self.collection_name.clone(),\n            vec![PointId::from(id.to_string())],\n        )\n        .with_payload(true)\n        .with_vectors(true);\n\n        let result = self.client.get_points(request).await?;\n        if let Some(point) = result.result.into_iter().next() {\n            let entry = self.point_to_entry(ScoredPoint {\n                id: point.id,\n                version: 0,\n                score: 1.0,\n                payload: point.payload,\n                vectors: point.vectors,\n                order_value: None,\n                shard_key: None,\n            })?;\n\n            if entry.metadata.get(\"tenant_id\").and_then(|t| t.as_str())\n                != Some(ctx.tenant_id.as_str())\n            {\n                return Ok(None);\n            }\n\n            Ok(Some(entry))\n        } else {\n            Ok(None)\n        }\n    }\n\n    async fn update(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        entry: MemoryEntry,\n    ) -> Result<(), Self::Error> {\n        self.add(ctx, entry).await?;\n        Ok(())\n    }\n\n    async fn delete(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        id: &str,\n    ) -> Result<(), Self::Error> {\n        self.ensure_collection().await?;\n\n        if self.get(ctx.clone(), id).await?.is_none() {\n            return Ok(());\n        }\n\n        tracing::debug!(tenant_id = %ctx.tenant_id, \"Qdrant delete point\");\n\n        use qdrant_client::qdrant::DeletePointsBuilder;\n        let request = DeletePointsBuilder::new(self.collection_name.clone())\n            .points(vec![PointId::from(id.to_string())]);\n        self.client.delete_points(request).await?;\n        Ok(())\n    }\n\n    async fn list(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        _layer: MemoryLayer,\n        limit: usize,\n        cursor: Option<String>,\n    ) -> Result<(Vec<MemoryEntry>, Option<String>), Self::Error> {\n        self.ensure_collection().await?;\n\n        tracing::debug!(tenant_id = %ctx.tenant_id, \"Qdrant list points\");\n\n        use qdrant_client::qdrant::{Condition, Filter};\n        let filter = Filter::all(vec![Condition::matches(\n            \"tenant_id\",\n            ctx.tenant_id.as_str().to_string(),\n        )]);\n\n        let scroll_request = qdrant_client::qdrant::ScrollPoints {\n            collection_name: self.collection_name.clone(),\n            limit: Some(limit as u32),\n            with_payload: Some(true.into()),\n            with_vectors: Some(true.into()),\n            offset: cursor.map(|c| PointId::from(c)),\n            filter: Some(filter),\n            ..Default::default()\n        };\n\n        let result = self.client.scroll(scroll_request).await?;\n        let entries: Result<Vec<MemoryEntry>, _> = result\n            .result\n            .into_iter()\n            .map(|p| {\n                self.point_to_entry(ScoredPoint {\n                    id: p.id,\n                    version: 0,\n                    score: 1.0,\n                    payload: p.payload,\n                    vectors: p.vectors,\n                    order_value: None,\n                    shard_key: None,\n                })\n            })\n            .collect();\n\n        let next_cursor = result.next_page_offset.map(|id| match id.point_id_options {\n            Some(PointIdOptions::Uuid(u)) => u,\n            Some(PointIdOptions::Num(n)) => n.to_string(),\n            None => String::new(),\n        });\n        Ok((entries?, next_cursor))\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::MemoryLayer;\n\n    use qdrant_client::qdrant::vectors_output::VectorsOptions;\n    use qdrant_client::qdrant::{VectorOutput, VectorsOutput};\n\n    fn setup_provider() -> QdrantProvider {\n        let client = Qdrant::from_url(\"http://localhost:6334\").build().unwrap();\n        QdrantProvider::new(client, \"test_collection\".to_string(), 3)\n    }\n\n    #[test]\n    fn test_point_to_entry_conversion() {\n        let provider = setup_provider();\n        let mut payload = HashMap::new();\n        payload.insert(\"id\".to_string(), \"test-id\".to_string().into());\n        payload.insert(\"content\".to_string(), \"test content\".to_string().into());\n        payload.insert(\n            \"layer\".to_string(),\n            serde_json::to_string(&MemoryLayer::Agent).unwrap().into(),\n        );\n        payload.insert(\n            \"metadata\".to_string(),\n            serde_json::to_string(&HashMap::<String, Value>::new())\n                .unwrap()\n                .into(),\n        );\n        payload.insert(\"created_at\".to_string(), 1000.into());\n        payload.insert(\"updated_at\".to_string(), 2000.into());\n\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload,\n            vectors: Some(VectorsOutput {\n                vectors_options: Some(VectorsOptions::Vector(VectorOutput {\n                    vector: Some(qdrant_client::qdrant::vector_output::Vector::Dense(\n                        qdrant_client::qdrant::DenseVector {\n                            data: vec![0.1, 0.2, 0.3],\n                        },\n                    )),\n                    ..Default::default()\n                })),\n            }),\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None,\n        };\n\n        let entry = provider.point_to_entry(point).unwrap();\n\n        assert_eq!(entry.id, \"test-id\");\n        assert_eq!(entry.content, \"test content\");\n        assert_eq!(entry.layer, MemoryLayer::Agent);\n        assert_eq!(entry.created_at, 1000);\n        assert_eq!(entry.updated_at, 2000);\n        assert_eq!(entry.embedding, Some(vec![0.1, 0.2, 0.3]));\n    }\n\n    #[test]\n    fn test_point_to_entry_with_metadata() {\n        let provider = setup_provider();\n        let mut payload = HashMap::new();\n        payload.insert(\"id\".to_string(), \"test-id\".to_string().into());\n        payload.insert(\"content\".to_string(), \"test content\".to_string().into());\n        payload.insert(\n            \"layer\".to_string(),\n            serde_json::to_string(&MemoryLayer::Agent).unwrap().into(),\n        );\n        payload.insert(\n            \"metadata\".to_string(),\n            serde_json::to_string(&HashMap::from([(\"key\".to_string(), json!(\"value\"))]))\n                .unwrap()\n                .into(),\n        );\n        payload.insert(\"created_at\".to_string(), 1000.into());\n        payload.insert(\"updated_at\".to_string(), 2000.into());\n\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload,\n            vectors: Some(VectorsOutput {\n                vectors_options: Some(VectorsOptions::Vector(VectorOutput {\n                    vector: Some(qdrant_client::qdrant::vector_output::Vector::Dense(\n                        qdrant_client::qdrant::DenseVector {\n                            data: vec![0.1, 0.2, 0.3],\n                        },\n                    )),\n                    ..Default::default()\n                })),\n            }),\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None,\n        };\n\n        let entry = provider.point_to_entry(point).unwrap();\n\n        assert_eq!(entry.id, \"test-id\");\n        assert_eq!(entry.content, \"test content\");\n        assert_eq!(entry.embedding.unwrap(), vec![0.1, 0.2, 0.3]);\n        assert_eq!(entry.layer, MemoryLayer::Agent);\n        assert_eq!(entry.metadata.get(\"key\").unwrap(), &json!(\"value\"));\n        // Use approx comparison for floating point\n        let score_value = entry.metadata.get(\"score\").unwrap().as_f64().unwrap();\n        assert!((score_value - 0.95).abs() < 0.0001);\n        assert_eq!(entry.created_at, 1000);\n        assert_eq!(entry.updated_at, 2000);\n    }\n\n    #[test]\n    fn test_entry_to_point_missing_embedding() {\n        let provider = setup_provider();\n        let entry = MemoryEntry {\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            id: \"test-id\".to_string(),\n            content: \"test content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: std::collections::HashMap::new(),\n            created_at: 1000,\n            updated_at: 2000,\n        };\n\n        let result = provider.entry_to_point(&entry);\n        assert!(result.is_err());\n        assert_eq!(result.unwrap_err().to_string(), \"Entry missing embedding\");\n    }\n\n    #[test]\n    fn test_point_to_entry_missing_payload_fields() {\n        let provider = setup_provider();\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload: std::collections::HashMap::new(),\n            vectors: Some(VectorsOutput {\n                vectors_options: Some(VectorsOptions::Vector(VectorOutput {\n                    vector: Some(qdrant_client::qdrant::vector_output::Vector::Dense(\n                        qdrant_client::qdrant::DenseVector {\n                            data: vec![0.1, 0.2, 0.3],\n                        },\n                    )),\n                    ..Default::default()\n                })),\n            }),\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None,\n        };\n\n        let result = provider.point_to_entry(point);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_point_to_entry_invalid_layer() {\n        let provider = setup_provider();\n        let mut payload = HashMap::new();\n        payload.insert(\"id\".to_string(), \"test-id\".to_string().into());\n        payload.insert(\"content\".to_string(), \"test content\".to_string().into());\n        payload.insert(\"layer\".to_string(), \"\\\"InvalidLayer\\\"\".to_string().into());\n        payload.insert(\"metadata\".to_string(), \"{}\".to_string().into());\n        payload.insert(\"created_at\".to_string(), 1000.into());\n        payload.insert(\"updated_at\".to_string(), 2000.into());\n\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload,\n            vectors: Some(VectorsOutput {\n                vectors_options: Some(VectorsOptions::Vector(VectorOutput {\n                    vector: Some(qdrant_client::qdrant::vector_output::Vector::Dense(\n                        qdrant_client::qdrant::DenseVector {\n                            data: vec![0.1, 0.2, 0.3],\n                        },\n                    )),\n                    ..Default::default()\n                })),\n            }),\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None,\n        };\n\n        let result = provider.point_to_entry(point);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_point_to_entry_missing_metadata() {\n        let provider = setup_provider();\n        let mut payload = HashMap::new();\n        payload.insert(\"id\".to_string(), \"test-id\".to_string().into());\n        payload.insert(\"content\".to_string(), \"test content\".to_string().into());\n        payload.insert(\n            \"layer\".to_string(),\n            serde_json::to_string(&MemoryLayer::Agent).unwrap().into(),\n        );\n        payload.insert(\"created_at\".to_string(), 1000.into());\n        payload.insert(\"updated_at\".to_string(), 2000.into());\n\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload,\n            vectors: Some(VectorsOutput {\n                vectors_options: Some(VectorsOptions::Vector(VectorOutput {\n                    vector: Some(qdrant_client::qdrant::vector_output::Vector::Dense(\n                        qdrant_client::qdrant::DenseVector {\n                            data: vec![0.1, 0.2, 0.3],\n                        },\n                    )),\n                    ..Default::default()\n                })),\n            }),\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None,\n        };\n\n        let result = provider.point_to_entry(point);\n        assert!(result.is_err());\n        assert_eq!(\n            result.unwrap_err().to_string(),\n            \"Missing metadata in payload\"\n        );\n    }\n\n    #[test]\n    fn test_point_to_entry_unsupported_vector() {\n        let provider = setup_provider();\n        let mut payload = HashMap::new();\n        payload.insert(\"id\".to_string(), \"test-id\".to_string().into());\n        payload.insert(\"content\".to_string(), \"test content\".to_string().into());\n        payload.insert(\n            \"layer\".to_string(),\n            serde_json::to_string(&MemoryLayer::Agent).unwrap().into(),\n        );\n        payload.insert(\"metadata\".to_string(), \"{}\".to_string().into());\n        payload.insert(\"created_at\".to_string(), 1000.into());\n        payload.insert(\"updated_at\".to_string(), 2000.into());\n\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload,\n            vectors: Some(VectorsOutput {\n                vectors_options: None,\n            }),\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None,\n        };\n\n        let result = provider.point_to_entry(point);\n        assert!(result.is_err());\n        assert_eq!(\n            result.unwrap_err().to_string(),\n            \"Unsupported or missing vector format\"\n        );\n    }\n\n    #[test]\n    fn test_point_to_entry_invalid_metadata_json() {\n        let provider = setup_provider();\n        let mut payload = HashMap::new();\n        payload.insert(\"id\".to_string(), \"test-id\".to_string().into());\n        payload.insert(\"content\".to_string(), \"test content\".to_string().into());\n        payload.insert(\n            \"layer\".to_string(),\n            serde_json::to_string(&MemoryLayer::Agent).unwrap().into(),\n        );\n        payload.insert(\"metadata\".to_string(), \"invalid-json\".to_string().into());\n        payload.insert(\"created_at\".to_string(), 1000.into());\n        payload.insert(\"updated_at\".to_string(), 2000.into());\n\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload,\n            vectors: Some(VectorsOutput {\n                vectors_options: Some(VectorsOptions::Vector(VectorOutput {\n                    vector: Some(qdrant_client::qdrant::vector_output::Vector::Dense(\n                        qdrant_client::qdrant::DenseVector {\n                            data: vec![0.1, 0.2, 0.3],\n                        },\n                    )),\n                    ..Default::default()\n                })),\n            }),\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None,\n        };\n\n        let result = provider.point_to_entry(point);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_point_to_entry_missing_vector() {\n        let provider = setup_provider();\n        let mut payload = HashMap::new();\n        payload.insert(\"id\".to_string(), \"test-id\".to_string().into());\n        payload.insert(\"content\".to_string(), \"test content\".to_string().into());\n        payload.insert(\n            \"layer\".to_string(),\n            serde_json::to_string(&MemoryLayer::Agent).unwrap().into(),\n        );\n        payload.insert(\"metadata\".to_string(), \"{}\".to_string().into());\n        payload.insert(\"created_at\".to_string(), 1000.into());\n        payload.insert(\"updated_at\".to_string(), 2000.into());\n\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload,\n            vectors: None,\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None,\n        };\n\n        let result = provider.point_to_entry(point);\n        assert!(result.is_err());\n        assert_eq!(result.unwrap_err().to_string(), \"Point missing vector\");\n    }\n}\n","traces":[{"line":23,"address":[],"length":0,"stats":{"Line":13}},{"line":25,"address":[],"length":0,"stats":{"Line":39}},{"line":31,"address":[],"length":0,"stats":{"Line":42}},{"line":32,"address":[],"length":0,"stats":{"Line":42}},{"line":33,"address":[],"length":0,"stats":{"Line":42}},{"line":34,"address":[],"length":0,"stats":{"Line":21}},{"line":36,"address":[],"length":0,"stats":{"Line":103}},{"line":38,"address":[],"length":0,"stats":{"Line":21}},{"line":40,"address":[],"length":0,"stats":{"Line":16}},{"line":41,"address":[],"length":0,"stats":{"Line":8}},{"line":42,"address":[],"length":0,"stats":{"Line":4}},{"line":43,"address":[],"length":0,"stats":{"Line":8}},{"line":44,"address":[],"length":0,"stats":{"Line":8}},{"line":45,"address":[],"length":0,"stats":{"Line":4}},{"line":49,"address":[],"length":0,"stats":{"Line":8}},{"line":52,"address":[],"length":0,"stats":{"Line":21}},{"line":55,"address":[],"length":0,"stats":{"Line":9}},{"line":59,"address":[],"length":0,"stats":{"Line":36}},{"line":61,"address":[],"length":0,"stats":{"Line":21}},{"line":62,"address":[],"length":0,"stats":{"Line":28}},{"line":63,"address":[],"length":0,"stats":{"Line":28}},{"line":65,"address":[],"length":0,"stats":{"Line":14}},{"line":66,"address":[],"length":0,"stats":{"Line":21}},{"line":68,"address":[],"length":0,"stats":{"Line":21}},{"line":69,"address":[],"length":0,"stats":{"Line":21}},{"line":72,"address":[],"length":0,"stats":{"Line":21}},{"line":73,"address":[],"length":0,"stats":{"Line":21}},{"line":74,"address":[],"length":0,"stats":{"Line":42}},{"line":78,"address":[],"length":0,"stats":{"Line":14}},{"line":79,"address":[],"length":0,"stats":{"Line":14}},{"line":80,"address":[],"length":0,"stats":{"Line":21}},{"line":83,"address":[],"length":0,"stats":{"Line":7}},{"line":84,"address":[],"length":0,"stats":{"Line":21}},{"line":85,"address":[],"length":0,"stats":{"Line":14}},{"line":86,"address":[],"length":0,"stats":{"Line":7}},{"line":90,"address":[],"length":0,"stats":{"Line":19}},{"line":94,"address":[],"length":0,"stats":{"Line":38}},{"line":96,"address":[],"length":0,"stats":{"Line":36}},{"line":98,"address":[],"length":0,"stats":{"Line":36}},{"line":99,"address":[],"length":0,"stats":{"Line":85}},{"line":100,"address":[],"length":0,"stats":{"Line":34}},{"line":101,"address":[],"length":0,"stats":{"Line":85}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":67}},{"line":109,"address":[],"length":0,"stats":{"Line":80}},{"line":111,"address":[],"length":0,"stats":{"Line":30}},{"line":112,"address":[],"length":0,"stats":{"Line":30}},{"line":114,"address":[],"length":0,"stats":{"Line":29}},{"line":115,"address":[],"length":0,"stats":{"Line":28}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":1}},{"line":122,"address":[],"length":0,"stats":{"Line":28}},{"line":124,"address":[],"length":0,"stats":{"Line":28}},{"line":125,"address":[],"length":0,"stats":{"Line":70}},{"line":126,"address":[],"length":0,"stats":{"Line":28}},{"line":127,"address":[],"length":0,"stats":{"Line":70}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":55}},{"line":135,"address":[],"length":0,"stats":{"Line":26}},{"line":137,"address":[],"length":0,"stats":{"Line":26}},{"line":138,"address":[],"length":0,"stats":{"Line":65}},{"line":139,"address":[],"length":0,"stats":{"Line":65}},{"line":143,"address":[],"length":0,"stats":{"Line":26}},{"line":145,"address":[],"length":0,"stats":{"Line":26}},{"line":146,"address":[],"length":0,"stats":{"Line":65}},{"line":147,"address":[],"length":0,"stats":{"Line":65}},{"line":151,"address":[],"length":0,"stats":{"Line":26}},{"line":153,"address":[],"length":0,"stats":{"Line":26}},{"line":154,"address":[],"length":0,"stats":{"Line":65}},{"line":155,"address":[],"length":0,"stats":{"Line":26}},{"line":159,"address":[],"length":0,"stats":{"Line":26}},{"line":161,"address":[],"length":0,"stats":{"Line":26}},{"line":162,"address":[],"length":0,"stats":{"Line":65}},{"line":163,"address":[],"length":0,"stats":{"Line":26}},{"line":167,"address":[],"length":0,"stats":{"Line":13}},{"line":168,"address":[],"length":0,"stats":{"Line":26}},{"line":169,"address":[],"length":0,"stats":{"Line":26}},{"line":170,"address":[],"length":0,"stats":{"Line":26}},{"line":171,"address":[],"length":0,"stats":{"Line":26}},{"line":172,"address":[],"length":0,"stats":{"Line":26}},{"line":173,"address":[],"length":0,"stats":{"Line":26}},{"line":174,"address":[],"length":0,"stats":{"Line":26}},{"line":175,"address":[],"length":0,"stats":{"Line":26}},{"line":176,"address":[],"length":0,"stats":{"Line":13}},{"line":177,"address":[],"length":0,"stats":{"Line":13}},{"line":239,"address":[],"length":0,"stats":{"Line":15}},{"line":272,"address":[],"length":0,"stats":{"Line":8}},{"line":335,"address":[],"length":0,"stats":{"Line":0}},{"line":344,"address":[],"length":0,"stats":{"Line":2}},{"line":345,"address":[],"length":0,"stats":{"Line":6}},{"line":346,"address":[],"length":0,"stats":{"Line":4}},{"line":347,"address":[],"length":0,"stats":{"Line":2}},{"line":348,"address":[],"length":0,"stats":{"Line":2}},{"line":349,"address":[],"length":0,"stats":{"Line":4}},{"line":350,"address":[],"length":0,"stats":{"Line":4}},{"line":351,"address":[],"length":0,"stats":{"Line":2}},{"line":352,"address":[],"length":0,"stats":{"Line":2}},{"line":357,"address":[],"length":0,"stats":{"Line":1}},{"line":358,"address":[],"length":0,"stats":{"Line":2}},{"line":359,"address":[],"length":0,"stats":{"Line":0}},{"line":360,"address":[],"length":0,"stats":{"Line":0}}],"covered":95,"coverable":101},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","pruning.rs"],"content":"use mk_core::traits::LlmService;\nuse mk_core::types::{MemoryEntry, MemoryOperation, MemoryTrajectoryEvent, TenantContext};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\npub struct PruningManager {\n    trajectories: Arc<RwLock<HashMap<String, Vec<MemoryTrajectoryEvent>>>>,\n}\n\nimpl PruningManager {\n    pub fn new(trajectories: Arc<RwLock<HashMap<String, Vec<MemoryTrajectoryEvent>>>>) -> Self {\n        Self { trajectories }\n    }\n\n    pub async fn evaluate(&self, entry: &MemoryEntry, threshold: f32) -> bool {\n        let score = entry.importance_score.unwrap_or(0.5);\n        if score < threshold {\n            return true;\n        }\n\n        let trajectories = self.trajectories.read().await;\n        if let Some(history) = trajectories.get(&entry.id) {\n            let last_events = if history.len() > 10 {\n                &history[history.len() - 10..]\n            } else {\n                &history[..]\n            };\n\n            let negative_rewards = last_events\n                .iter()\n                .filter(|e| {\n                    if let Some(reward) = &e.reward {\n                        reward.score < 0.0\n                    } else {\n                        false\n                    }\n                })\n                .count();\n\n            if negative_rewards >= 3 {\n                return true;\n            }\n\n            let has_recent_utility = last_events\n                .iter()\n                .any(|e| matches!(e.operation, MemoryOperation::Retrieve) || e.reward.is_some());\n\n            if !has_recent_utility && history.len() >= 20 {\n                return true;\n            }\n        }\n\n        false\n    }\n}\n\npub struct CompressionManager {\n    llm_service:\n        Arc<dyn LlmService<Error = Box<dyn std::error::Error + Send + Sync>> + Send + Sync>,\n    trajectories: Arc<RwLock<HashMap<String, Vec<MemoryTrajectoryEvent>>>>,\n}\n\nimpl CompressionManager {\n    pub fn new(\n        llm_service: Arc<\n            dyn LlmService<Error = Box<dyn std::error::Error + Send + Sync>> + Send + Sync,\n        >,\n        trajectories: Arc<RwLock<HashMap<String, Vec<MemoryTrajectoryEvent>>>>,\n    ) -> Self {\n        Self {\n            llm_service,\n            trajectories,\n        }\n    }\n\n    pub async fn compress(\n        &self,\n        _ctx: &TenantContext,\n        memories: &[MemoryEntry],\n    ) -> Result<MemoryEntry, Box<dyn std::error::Error + Send + Sync>> {\n        if memories.is_empty() {\n            return Err(\"No memories to compress\".into());\n        }\n\n        let mut prompt = String::from(\n            \"Compress the following related memories into a single, high-density summary. \\\n             Preserve all key facts and entities:\\n\\n\",\n        );\n        for (i, m) in memories.iter().enumerate() {\n            prompt.push_str(&format!(\"{}. {}\\n\", i + 1, m.content));\n        }\n\n        let compressed_content = self.llm_service.generate(&prompt).await?;\n\n        let mut metadata = HashMap::new();\n        let source_ids: Vec<String> = memories.iter().map(|m| m.id.clone()).collect();\n        metadata.insert(\"compressed_from\".to_string(), serde_json::json!(source_ids));\n        metadata.insert(\n            \"compression_ratio\".to_string(),\n            serde_json::json!(memories.len()),\n        );\n\n        let avg_importance = memories\n            .iter()\n            .filter_map(|m| m.importance_score)\n            .sum::<f32>()\n            / memories.len() as f32;\n\n        let entry = MemoryEntry {\n            id: format!(\"compressed_{}\", uuid::Uuid::new_v4()),\n            content: compressed_content,\n            embedding: None,\n            layer: memories[0].layer,\n            summaries: HashMap::new(),\n            context_vector: None,\n            importance_score: Some(avg_importance),\n            metadata,\n            created_at: chrono::Utc::now().timestamp(),\n            updated_at: chrono::Utc::now().timestamp(),\n        };\n\n        let source_trajectories: Vec<Vec<MemoryTrajectoryEvent>> = {\n            let trajectories = self.trajectories.read().await;\n            memories\n                .iter()\n                .filter_map(|m| trajectories.get(&m.id).cloned())\n                .collect()\n        };\n\n        if !source_trajectories.is_empty() {\n            let mut trajectories = self.trajectories.write().await;\n            let mut events = Vec::new();\n\n            for (i, source_history) in source_trajectories.into_iter().enumerate() {\n                for event in source_history {\n                    if event.reward.is_some() {\n                        events.push(MemoryTrajectoryEvent {\n                            operation: MemoryOperation::Noop,\n                            entry_id: entry.id.clone(),\n                            reward: event.reward,\n                            reasoning: Some(format!(\n                                \"Inherited reward from source memory {}\",\n                                memories[i].id\n                            )),\n                            timestamp: chrono::Utc::now().timestamp(),\n                        });\n                    }\n                }\n            }\n\n            if !events.is_empty() {\n                trajectories.insert(entry.id.clone(), events);\n            }\n        }\n\n        Ok(entry)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::llm::mock::MockLlmService;\n    use mk_core::types::{MemoryLayer, RewardSignal, RewardType};\n\n    fn create_test_entry(id: &str, importance: Option<f32>) -> MemoryEntry {\n        MemoryEntry {\n            id: id.to_string(),\n            content: format!(\"Content for {}\", id),\n            embedding: None,\n            layer: MemoryLayer::User,\n            summaries: HashMap::new(),\n            context_vector: None,\n            importance_score: importance,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0,\n        }\n    }\n\n    fn create_trajectory_event(\n        entry_id: &str,\n        operation: MemoryOperation,\n        reward: Option<RewardSignal>,\n    ) -> MemoryTrajectoryEvent {\n        MemoryTrajectoryEvent {\n            operation,\n            entry_id: entry_id.to_string(),\n            reward,\n            reasoning: None,\n            timestamp: chrono::Utc::now().timestamp(),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_pruning_low_importance_score_triggers_prune() {\n        let trajectories = Arc::new(RwLock::new(HashMap::new()));\n        let manager = PruningManager::new(trajectories);\n\n        let entry = create_test_entry(\"low-score\", Some(0.1));\n        let should_prune = manager.evaluate(&entry, 0.3).await;\n\n        assert!(should_prune, \"Low importance score should trigger pruning\");\n    }\n\n    #[tokio::test]\n    async fn test_pruning_high_importance_score_no_prune() {\n        let trajectories = Arc::new(RwLock::new(HashMap::new()));\n        let manager = PruningManager::new(trajectories);\n\n        let entry = create_test_entry(\"high-score\", Some(0.9));\n        let should_prune = manager.evaluate(&entry, 0.3).await;\n\n        assert!(\n            !should_prune,\n            \"High importance score should not trigger pruning\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_pruning_three_negative_rewards_triggers_prune() {\n        let trajectories = Arc::new(RwLock::new(HashMap::new()));\n        let manager = PruningManager::new(trajectories.clone());\n\n        let entry = create_test_entry(\"negative-rewards\", Some(0.8));\n\n        {\n            let mut t = trajectories.write().await;\n            let events = vec![\n                create_trajectory_event(\n                    \"negative-rewards\",\n                    MemoryOperation::Retrieve,\n                    Some(RewardSignal {\n                        reward_type: RewardType::Irrelevant,\n                        score: -0.5,\n                        reasoning: None,\n                        agent_id: None,\n                        timestamp: chrono::Utc::now().timestamp(),\n                    }),\n                ),\n                create_trajectory_event(\n                    \"negative-rewards\",\n                    MemoryOperation::Retrieve,\n                    Some(RewardSignal {\n                        reward_type: RewardType::Irrelevant,\n                        score: -0.3,\n                        reasoning: None,\n                        agent_id: None,\n                        timestamp: chrono::Utc::now().timestamp(),\n                    }),\n                ),\n                create_trajectory_event(\n                    \"negative-rewards\",\n                    MemoryOperation::Retrieve,\n                    Some(RewardSignal {\n                        reward_type: RewardType::Irrelevant,\n                        score: -0.8,\n                        reasoning: None,\n                        agent_id: None,\n                        timestamp: chrono::Utc::now().timestamp(),\n                    }),\n                ),\n            ];\n            t.insert(\"negative-rewards\".to_string(), events);\n        }\n\n        let should_prune = manager.evaluate(&entry, 0.3).await;\n        assert!(\n            should_prune,\n            \"Three negative rewards should trigger pruning even with high importance\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_pruning_no_utility_in_long_history_triggers_prune() {\n        let trajectories = Arc::new(RwLock::new(HashMap::new()));\n        let manager = PruningManager::new(trajectories.clone());\n\n        let entry = create_test_entry(\"stale-memory\", Some(0.6));\n\n        {\n            let mut t = trajectories.write().await;\n            let events: Vec<_> = (0..25)\n                .map(|_| create_trajectory_event(\"stale-memory\", MemoryOperation::Add, None))\n                .collect();\n            t.insert(\"stale-memory\".to_string(), events);\n        }\n\n        let should_prune = manager.evaluate(&entry, 0.3).await;\n        assert!(\n            should_prune,\n            \"Memory with no recent utility and long history should be pruned\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_pruning_recent_retrieval_prevents_prune() {\n        let trajectories = Arc::new(RwLock::new(HashMap::new()));\n        let manager = PruningManager::new(trajectories.clone());\n\n        let entry = create_test_entry(\"recently-used\", Some(0.6));\n\n        {\n            let mut t = trajectories.write().await;\n            let mut events: Vec<_> = (0..20)\n                .map(|_| create_trajectory_event(\"recently-used\", MemoryOperation::Add, None))\n                .collect();\n            events.push(create_trajectory_event(\n                \"recently-used\",\n                MemoryOperation::Retrieve,\n                None,\n            ));\n            t.insert(\"recently-used\".to_string(), events);\n        }\n\n        let should_prune = manager.evaluate(&entry, 0.3).await;\n        assert!(!should_prune, \"Recent retrieval should prevent pruning\");\n    }\n\n    #[tokio::test]\n    async fn test_pruning_default_importance_score() {\n        let trajectories = Arc::new(RwLock::new(HashMap::new()));\n        let manager = PruningManager::new(trajectories);\n\n        let entry = create_test_entry(\"no-score\", None);\n        let should_prune = manager.evaluate(&entry, 0.3).await;\n\n        assert!(\n            !should_prune,\n            \"Default importance (0.5) should not trigger pruning with 0.3 threshold\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_compression_empty_memories_error() {\n        let trajectories = Arc::new(RwLock::new(HashMap::new()));\n        let llm = Arc::new(MockLlmService::new());\n        let manager = CompressionManager::new(llm, trajectories);\n\n        let ctx = TenantContext::default();\n        let result = manager.compress(&ctx, &[]).await;\n\n        assert!(result.is_err());\n        assert!(result.unwrap_err().to_string().contains(\"No memories\"));\n    }\n\n    #[tokio::test]\n    async fn test_compression_creates_merged_entry() {\n        let trajectories = Arc::new(RwLock::new(HashMap::new()));\n        let llm = Arc::new(MockLlmService::new());\n        let manager = CompressionManager::new(llm, trajectories);\n\n        let ctx = TenantContext::default();\n        let memories = vec![\n            create_test_entry(\"m1\", Some(0.8)),\n            create_test_entry(\"m2\", Some(0.6)),\n        ];\n\n        let result = manager.compress(&ctx, &memories).await.unwrap();\n\n        assert!(result.id.starts_with(\"compressed_\"));\n        assert!(result.metadata.contains_key(\"compressed_from\"));\n        assert!(result.metadata.contains_key(\"compression_ratio\"));\n        // Use approximate comparison for floating point\n        let score = result.importance_score.unwrap();\n        assert!((score - 0.7).abs() < 0.001, \"Expected ~0.7, got {}\", score);\n    }\n\n    #[tokio::test]\n    async fn test_compression_inherits_trajectory_rewards() {\n        let trajectories = Arc::new(RwLock::new(HashMap::new()));\n        let llm = Arc::new(MockLlmService::new());\n        let manager = CompressionManager::new(llm, trajectories.clone());\n\n        {\n            let mut t = trajectories.write().await;\n            t.insert(\n                \"m1\".to_string(),\n                vec![create_trajectory_event(\n                    \"m1\",\n                    MemoryOperation::Retrieve,\n                    Some(RewardSignal {\n                        reward_type: RewardType::Helpful,\n                        score: 0.9,\n                        reasoning: Some(\"useful\".to_string()),\n                        agent_id: None,\n                        timestamp: chrono::Utc::now().timestamp(),\n                    }),\n                )],\n            );\n        }\n\n        let ctx = TenantContext::default();\n        let memories = vec![create_test_entry(\"m1\", Some(0.8))];\n\n        let result = manager.compress(&ctx, &memories).await.unwrap();\n\n        let t = trajectories.read().await;\n        let inherited = t.get(&result.id);\n        assert!(\n            inherited.is_some(),\n            \"Compressed entry should inherit trajectory\"\n        );\n        assert_eq!(inherited.unwrap().len(), 1);\n        assert!(inherited.unwrap()[0].reward.is_some());\n    }\n}\n","traces":[{"line":12,"address":[],"length":0,"stats":{"Line":9}},{"line":16,"address":[],"length":0,"stats":{"Line":26}},{"line":17,"address":[],"length":0,"stats":{"Line":39}},{"line":18,"address":[],"length":0,"stats":{"Line":13}},{"line":19,"address":[],"length":0,"stats":{"Line":6}},{"line":22,"address":[],"length":0,"stats":{"Line":14}},{"line":23,"address":[],"length":0,"stats":{"Line":19}},{"line":24,"address":[],"length":0,"stats":{"Line":10}},{"line":25,"address":[],"length":0,"stats":{"Line":4}},{"line":27,"address":[],"length":0,"stats":{"Line":3}},{"line":30,"address":[],"length":0,"stats":{"Line":10}},{"line":32,"address":[],"length":0,"stats":{"Line":30}},{"line":33,"address":[],"length":0,"stats":{"Line":28}},{"line":34,"address":[],"length":0,"stats":{"Line":3}},{"line":36,"address":[],"length":0,"stats":{"Line":22}},{"line":41,"address":[],"length":0,"stats":{"Line":5}},{"line":42,"address":[],"length":0,"stats":{"Line":1}},{"line":45,"address":[],"length":0,"stats":{"Line":8}},{"line":47,"address":[],"length":0,"stats":{"Line":68}},{"line":49,"address":[],"length":0,"stats":{"Line":7}},{"line":50,"address":[],"length":0,"stats":{"Line":1}},{"line":54,"address":[],"length":0,"stats":{"Line":5}},{"line":65,"address":[],"length":0,"stats":{"Line":6}},{"line":77,"address":[],"length":0,"stats":{"Line":4}},{"line":82,"address":[],"length":0,"stats":{"Line":8}},{"line":83,"address":[],"length":0,"stats":{"Line":1}},{"line":90,"address":[],"length":0,"stats":{"Line":33}},{"line":91,"address":[],"length":0,"stats":{"Line":32}},{"line":94,"address":[],"length":0,"stats":{"Line":9}},{"line":96,"address":[],"length":0,"stats":{"Line":6}},{"line":97,"address":[],"length":0,"stats":{"Line":34}},{"line":98,"address":[],"length":0,"stats":{"Line":15}},{"line":99,"address":[],"length":0,"stats":{"Line":6}},{"line":100,"address":[],"length":0,"stats":{"Line":6}},{"line":101,"address":[],"length":0,"stats":{"Line":9}},{"line":104,"address":[],"length":0,"stats":{"Line":6}},{"line":105,"address":[],"length":0,"stats":{"Line":3}},{"line":106,"address":[],"length":0,"stats":{"Line":3}},{"line":107,"address":[],"length":0,"stats":{"Line":3}},{"line":108,"address":[],"length":0,"stats":{"Line":3}},{"line":111,"address":[],"length":0,"stats":{"Line":12}},{"line":114,"address":[],"length":0,"stats":{"Line":6}},{"line":115,"address":[],"length":0,"stats":{"Line":6}},{"line":117,"address":[],"length":0,"stats":{"Line":6}},{"line":119,"address":[],"length":0,"stats":{"Line":9}},{"line":120,"address":[],"length":0,"stats":{"Line":3}},{"line":123,"address":[],"length":0,"stats":{"Line":6}},{"line":124,"address":[],"length":0,"stats":{"Line":6}},{"line":125,"address":[],"length":0,"stats":{"Line":3}},{"line":127,"address":[],"length":0,"stats":{"Line":27}},{"line":131,"address":[],"length":0,"stats":{"Line":3}},{"line":132,"address":[],"length":0,"stats":{"Line":4}},{"line":133,"address":[],"length":0,"stats":{"Line":4}},{"line":135,"address":[],"length":0,"stats":{"Line":18}},{"line":136,"address":[],"length":0,"stats":{"Line":20}},{"line":137,"address":[],"length":0,"stats":{"Line":16}},{"line":138,"address":[],"length":0,"stats":{"Line":6}},{"line":139,"address":[],"length":0,"stats":{"Line":4}},{"line":140,"address":[],"length":0,"stats":{"Line":6}},{"line":141,"address":[],"length":0,"stats":{"Line":4}},{"line":142,"address":[],"length":0,"stats":{"Line":6}},{"line":143,"address":[],"length":0,"stats":{"Line":4}},{"line":144,"address":[],"length":0,"stats":{"Line":4}},{"line":146,"address":[],"length":0,"stats":{"Line":2}},{"line":152,"address":[],"length":0,"stats":{"Line":4}},{"line":153,"address":[],"length":0,"stats":{"Line":8}},{"line":157,"address":[],"length":0,"stats":{"Line":3}}],"covered":67,"coverable":67},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","reasoning.rs"],"content":"use async_trait::async_trait;\nuse chrono::Utc;\nuse mk_core::traits::LlmService;\nuse mk_core::types::{ReasoningStrategy, ReasoningTrace};\nuse serde::{Deserialize, Serialize};\nuse std::sync::Arc;\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct ReasoningPlan {\n    pub strategy: ReasoningStrategy,\n    pub refined_query: String,\n    pub reasoning: String,\n}\n\n#[async_trait]\npub trait ReflectiveReasoner: Send + Sync {\n    async fn reason(\n        &self,\n        query: &str,\n        context_summary: Option<&str>,\n    ) -> anyhow::Result<ReasoningTrace>;\n}\n\npub struct DefaultReflectiveReasoner {\n    llm: Arc<dyn LlmService<Error = Box<dyn std::error::Error + Send + Sync>>>,\n}\n\nimpl DefaultReflectiveReasoner {\n    pub fn new(llm: Arc<dyn LlmService<Error = Box<dyn std::error::Error + Send + Sync>>>) -> Self {\n        Self { llm }\n    }\n}\n\n#[async_trait]\nimpl ReflectiveReasoner for DefaultReflectiveReasoner {\n    async fn reason(\n        &self,\n        query: &str,\n        context_summary: Option<&str>,\n    ) -> anyhow::Result<ReasoningTrace> {\n        let start_time = Utc::now();\n\n        let prompt = format!(\n            \"Given the following user query and optional context summary, determine the best \\\n             retrieval strategy and refine the query for vector search.\\n\\nQuery: {}\\nContext \\\n             Summary: {}\\n\\nReturn your response in JSON format:\\n{{\\n\\\"strategy\\\": \\\n             \\\"exhaustive\\\" | \\\"targeted\\\" | \\\"semanticOnly\\\",\\n\\\"refined_query\\\": \\\n             \\\"...\\\",\\n\\\"reasoning\\\": \\\"...\\\"\\n}}\",\n            query,\n            context_summary.unwrap_or(\"None\")\n        );\n\n        let response = self\n            .llm\n            .generate(&prompt)\n            .await\n            .map_err(|e| anyhow::anyhow!(e))?;\n\n        // Extract JSON if needed\n        let json_str = if let Some(start) = response.find('{') {\n            if let Some(end) = response.rfind('}') {\n                &response[start..=end]\n            } else {\n                &response\n            }\n        } else {\n            &response\n        };\n\n        let plan: ReasoningPlan = serde_json::from_str(json_str)?;\n\n        let end_time = Utc::now();\n        let duration_ms = (end_time - start_time).num_milliseconds().max(0) as u64;\n\n        Ok(ReasoningTrace {\n            strategy: plan.strategy,\n            thought_process: plan.reasoning,\n            refined_query: Some(plan.refined_query),\n            start_time,\n            end_time,\n            timed_out: false,\n            duration_ms,\n            metadata: std::collections::HashMap::new(),\n        })\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::llm::mock::MockLlmService;\n\n    #[tokio::test]\n    async fn test_reasoning_logic() {\n        let mut mock_llm = MockLlmService::new();\n        let plan_json = \"{\\\"strategy\\\": \\\"exhaustive\\\", \\\"refined_query\\\": \\\"deep search for \\\n                         memory-r1 architecture\\\", \\\"reasoning\\\": \\\"The query is specific and \\\n                         complex, requiring cross-layer verification.\\\"}\";\n        mock_llm.set_response(plan_json).await;\n\n        let reasoner = DefaultReflectiveReasoner::new(Arc::new(mock_llm));\n        let trace = reasoner.reason(\"memory-r1\", None).await.unwrap();\n\n        assert_eq!(trace.strategy, ReasoningStrategy::Exhaustive);\n        assert_eq!(\n            trace.refined_query.unwrap(),\n            \"deep search for memory-r1 architecture\"\n        );\n        assert!(trace.thought_process.contains(\"complex\"));\n    }\n}\n","traces":[{"line":29,"address":[],"length":0,"stats":{"Line":21}},{"line":57,"address":[],"length":0,"stats":{"Line":0}}],"covered":1,"coverable":2},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","reasoning_cache.rs"],"content":"use async_trait::async_trait;\nuse mk_core::types::{ReasoningTrace, TenantContext};\nuse sha2::{Digest, Sha256};\nuse std::sync::Arc;\n\n#[async_trait]\npub trait ReasoningCacheBackend: Send + Sync {\n    async fn get(&self, key: &str) -> Result<Option<CachedReasoning>, CacheError>;\n    async fn set(\n        &self,\n        key: &str,\n        value: &CachedReasoning,\n        ttl_seconds: u64,\n    ) -> Result<(), CacheError>;\n    async fn delete(&self, key: &str) -> Result<(), CacheError>;\n}\n\n#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]\npub struct CachedReasoning {\n    pub trace: ReasoningTrace,\n    pub cached_at: i64,\n}\n\n#[derive(Debug, thiserror::Error)]\npub enum CacheError {\n    #[error(\"Cache connection error: {0}\")]\n    ConnectionError(String),\n    #[error(\"Cache serialization error: {0}\")]\n    SerializationError(String),\n    #[error(\"Cache operation error: {0}\")]\n    OperationError(String),\n}\n\npub struct ReasoningCache<B: ReasoningCacheBackend> {\n    backend: Arc<B>,\n    ttl_seconds: u64,\n    enabled: bool,\n    telemetry: Arc<crate::telemetry::MemoryTelemetry>,\n}\n\nimpl<B: ReasoningCacheBackend> ReasoningCache<B> {\n    pub fn new(\n        backend: Arc<B>,\n        ttl_seconds: u64,\n        enabled: bool,\n        telemetry: Arc<crate::telemetry::MemoryTelemetry>,\n    ) -> Self {\n        Self {\n            backend,\n            ttl_seconds,\n            enabled,\n            telemetry,\n        }\n    }\n\n    pub fn generate_cache_key(ctx: &TenantContext, query: &str) -> String {\n        let normalized_query = Self::normalize_query(query);\n        let mut hasher = Sha256::new();\n        hasher.update(ctx.tenant_id.as_str().as_bytes());\n        hasher.update(b\":\");\n        hasher.update(normalized_query.as_bytes());\n        let hash = hex::encode(hasher.finalize());\n        format!(\"reasoning:{}:{}\", ctx.tenant_id.as_str(), &hash[..16])\n    }\n\n    fn normalize_query(query: &str) -> String {\n        query\n            .to_lowercase()\n            .trim()\n            .split_whitespace()\n            .collect::<Vec<_>>()\n            .join(\" \")\n    }\n\n    pub async fn get(\n        &self,\n        ctx: &TenantContext,\n        query: &str,\n    ) -> Result<Option<ReasoningTrace>, CacheError> {\n        if !self.enabled {\n            return Ok(None);\n        }\n\n        let key = Self::generate_cache_key(ctx, query);\n        match self.backend.get(&key).await {\n            Ok(Some(cached)) => {\n                self.telemetry.record_reasoning_cache_hit();\n                Ok(Some(cached.trace))\n            }\n            Ok(None) => {\n                self.telemetry.record_reasoning_cache_miss();\n                Ok(None)\n            }\n            Err(e) => {\n                tracing::warn!(\"Reasoning cache get error: {}\", e);\n                self.telemetry.record_reasoning_cache_miss();\n                Ok(None)\n            }\n        }\n    }\n\n    pub async fn set(\n        &self,\n        ctx: &TenantContext,\n        query: &str,\n        trace: &ReasoningTrace,\n    ) -> Result<(), CacheError> {\n        if !self.enabled {\n            return Ok(());\n        }\n\n        let key = Self::generate_cache_key(ctx, query);\n        let cached = CachedReasoning {\n            trace: trace.clone(),\n            cached_at: chrono::Utc::now().timestamp(),\n        };\n\n        match self.backend.set(&key, &cached, self.ttl_seconds).await {\n            Ok(()) => Ok(()),\n            Err(e) => {\n                tracing::warn!(\"Reasoning cache set error: {}\", e);\n                Ok(())\n            }\n        }\n    }\n\n    pub async fn invalidate(&self, ctx: &TenantContext, query: &str) -> Result<(), CacheError> {\n        if !self.enabled {\n            return Ok(());\n        }\n\n        let key = Self::generate_cache_key(ctx, query);\n        self.backend.delete(&key).await\n    }\n}\n\npub struct RedisReasoningCacheBackend {\n    connection_manager: redis::aio::ConnectionManager,\n}\n\nimpl RedisReasoningCacheBackend {\n    pub async fn new(connection_string: &str) -> Result<Self, CacheError> {\n        let client = redis::Client::open(connection_string)\n            .map_err(|e| CacheError::ConnectionError(e.to_string()))?;\n\n        let connection_manager = client\n            .get_connection_manager()\n            .await\n            .map_err(|e| CacheError::ConnectionError(e.to_string()))?;\n\n        Ok(Self { connection_manager })\n    }\n}\n\n#[async_trait]\nimpl ReasoningCacheBackend for RedisReasoningCacheBackend {\n    async fn get(&self, key: &str) -> Result<Option<CachedReasoning>, CacheError> {\n        use redis::AsyncCommands;\n        let mut conn = self.connection_manager.clone();\n\n        let value: Option<String> = conn\n            .get(key)\n            .await\n            .map_err(|e| CacheError::OperationError(e.to_string()))?;\n\n        match value {\n            Some(json) => {\n                let cached: CachedReasoning = serde_json::from_str(&json)\n                    .map_err(|e| CacheError::SerializationError(e.to_string()))?;\n                Ok(Some(cached))\n            }\n            None => Ok(None),\n        }\n    }\n\n    async fn set(\n        &self,\n        key: &str,\n        value: &CachedReasoning,\n        ttl_seconds: u64,\n    ) -> Result<(), CacheError> {\n        use redis::AsyncCommands;\n        let mut conn = self.connection_manager.clone();\n\n        let json = serde_json::to_string(value)\n            .map_err(|e| CacheError::SerializationError(e.to_string()))?;\n\n        let _: () = conn\n            .set_ex(key, json, ttl_seconds)\n            .await\n            .map_err(|e| CacheError::OperationError(e.to_string()))?;\n\n        Ok(())\n    }\n\n    async fn delete(&self, key: &str) -> Result<(), CacheError> {\n        use redis::AsyncCommands;\n        let mut conn = self.connection_manager.clone();\n\n        let _: usize = conn\n            .del(key)\n            .await\n            .map_err(|e| CacheError::OperationError(e.to_string()))?;\n\n        Ok(())\n    }\n}\n\npub struct InMemoryReasoningCacheBackend {\n    cache: tokio::sync::RwLock<std::collections::HashMap<String, (CachedReasoning, i64)>>,\n    access_order: tokio::sync::RwLock<std::collections::VecDeque<String>>,\n    max_entries: usize,\n}\n\nimpl InMemoryReasoningCacheBackend {\n    pub fn new() -> Self {\n        Self::with_max_entries(10000)\n    }\n\n    pub fn with_max_entries(max_entries: usize) -> Self {\n        Self {\n            cache: tokio::sync::RwLock::new(std::collections::HashMap::new()),\n            access_order: tokio::sync::RwLock::new(std::collections::VecDeque::new()),\n            max_entries,\n        }\n    }\n\n    async fn evict_lru_if_needed(&self) {\n        let cache = self.cache.read().await;\n        if cache.len() < self.max_entries {\n            return;\n        }\n        drop(cache);\n\n        let mut cache = self.cache.write().await;\n        let mut access_order = self.access_order.write().await;\n\n        while cache.len() >= self.max_entries {\n            if let Some(oldest_key) = access_order.pop_front() {\n                cache.remove(&oldest_key);\n            } else {\n                break;\n            }\n        }\n    }\n\n    async fn update_access_order(&self, key: &str) {\n        let mut access_order = self.access_order.write().await;\n        access_order.retain(|k| k != key);\n        access_order.push_back(key.to_string());\n    }\n}\n\nimpl Default for InMemoryReasoningCacheBackend {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n#[async_trait]\nimpl ReasoningCacheBackend for InMemoryReasoningCacheBackend {\n    async fn get(&self, key: &str) -> Result<Option<CachedReasoning>, CacheError> {\n        let cache = self.cache.read().await;\n        if let Some((_, expires_at)) = cache.get(key) {\n            let now = chrono::Utc::now().timestamp();\n            if now < *expires_at {\n                drop(cache);\n                self.update_access_order(key).await;\n                let cache = self.cache.read().await;\n                if let Some((cached, _)) = cache.get(key) {\n                    return Ok(Some(cached.clone()));\n                }\n            }\n        }\n        Ok(None)\n    }\n\n    async fn set(\n        &self,\n        key: &str,\n        value: &CachedReasoning,\n        ttl_seconds: u64,\n    ) -> Result<(), CacheError> {\n        self.evict_lru_if_needed().await;\n\n        let mut cache = self.cache.write().await;\n        let expires_at = chrono::Utc::now().timestamp() + ttl_seconds as i64;\n        cache.insert(key.to_string(), (value.clone(), expires_at));\n        drop(cache);\n\n        self.update_access_order(key).await;\n        Ok(())\n    }\n\n    async fn delete(&self, key: &str) -> Result<(), CacheError> {\n        let mut cache = self.cache.write().await;\n        cache.remove(key);\n        drop(cache);\n\n        let mut access_order = self.access_order.write().await;\n        access_order.retain(|k| k != key);\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::{ReasoningStrategy, TenantId, UserId};\n\n    fn test_ctx() -> TenantContext {\n        TenantContext::new(\n            TenantId::new(\"test-tenant\".to_string()).unwrap(),\n            UserId::new(\"test-user\".to_string()).unwrap(),\n        )\n    }\n\n    fn test_trace() -> ReasoningTrace {\n        ReasoningTrace {\n            strategy: ReasoningStrategy::Targeted,\n            thought_process: \"Test reasoning\".to_string(),\n            refined_query: Some(\"refined query\".to_string()),\n            start_time: chrono::Utc::now(),\n            end_time: chrono::Utc::now(),\n            timed_out: false,\n            duration_ms: 100,\n            metadata: std::collections::HashMap::new(),\n        }\n    }\n\n    #[test]\n    fn test_cache_key_generation() {\n        let ctx = test_ctx();\n        let key1 =\n            ReasoningCache::<InMemoryReasoningCacheBackend>::generate_cache_key(&ctx, \"test query\");\n        let key2 =\n            ReasoningCache::<InMemoryReasoningCacheBackend>::generate_cache_key(&ctx, \"TEST QUERY\");\n        let key3 = ReasoningCache::<InMemoryReasoningCacheBackend>::generate_cache_key(\n            &ctx,\n            \"  test   query  \",\n        );\n\n        assert_eq!(key1, key2, \"Keys should be case-insensitive\");\n        assert_eq!(key1, key3, \"Keys should normalize whitespace\");\n        assert!(key1.starts_with(\"reasoning:test-tenant:\"));\n    }\n\n    #[test]\n    fn test_different_tenants_different_keys() {\n        let ctx1 = TenantContext::new(\n            TenantId::new(\"tenant-1\".to_string()).unwrap(),\n            UserId::new(\"user\".to_string()).unwrap(),\n        );\n        let ctx2 = TenantContext::new(\n            TenantId::new(\"tenant-2\".to_string()).unwrap(),\n            UserId::new(\"user\".to_string()).unwrap(),\n        );\n\n        let key1 = ReasoningCache::<InMemoryReasoningCacheBackend>::generate_cache_key(\n            &ctx1,\n            \"same query\",\n        );\n        let key2 = ReasoningCache::<InMemoryReasoningCacheBackend>::generate_cache_key(\n            &ctx2,\n            \"same query\",\n        );\n\n        assert_ne!(key1, key2, \"Different tenants should have different keys\");\n    }\n\n    #[tokio::test]\n    async fn test_in_memory_cache_roundtrip() {\n        let backend = Arc::new(InMemoryReasoningCacheBackend::new());\n        let telemetry = Arc::new(crate::telemetry::MemoryTelemetry::new());\n        let cache = ReasoningCache::new(backend, 3600, true, telemetry);\n\n        let ctx = test_ctx();\n        let trace = test_trace();\n\n        cache.set(&ctx, \"test query\", &trace).await.unwrap();\n\n        let retrieved = cache.get(&ctx, \"test query\").await.unwrap();\n        assert!(retrieved.is_some());\n        let retrieved = retrieved.unwrap();\n        assert_eq!(retrieved.strategy, trace.strategy);\n        assert_eq!(retrieved.refined_query, trace.refined_query);\n    }\n\n    #[tokio::test]\n    async fn test_cache_disabled() {\n        let backend = Arc::new(InMemoryReasoningCacheBackend::new());\n        let telemetry = Arc::new(crate::telemetry::MemoryTelemetry::new());\n        let cache = ReasoningCache::new(backend, 3600, false, telemetry);\n\n        let ctx = test_ctx();\n        let trace = test_trace();\n\n        cache.set(&ctx, \"test query\", &trace).await.unwrap();\n        let retrieved = cache.get(&ctx, \"test query\").await.unwrap();\n        assert!(\n            retrieved.is_none(),\n            \"Cache should return None when disabled\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_cache_invalidation() {\n        let backend = Arc::new(InMemoryReasoningCacheBackend::new());\n        let telemetry = Arc::new(crate::telemetry::MemoryTelemetry::new());\n        let cache = ReasoningCache::new(backend, 3600, true, telemetry);\n\n        let ctx = test_ctx();\n        let trace = test_trace();\n\n        cache.set(&ctx, \"test query\", &trace).await.unwrap();\n        assert!(cache.get(&ctx, \"test query\").await.unwrap().is_some());\n\n        cache.invalidate(&ctx, \"test query\").await.unwrap();\n        assert!(cache.get(&ctx, \"test query\").await.unwrap().is_none());\n    }\n\n    #[tokio::test]\n    async fn test_cache_expiration() {\n        let backend = Arc::new(InMemoryReasoningCacheBackend::new());\n        let telemetry = Arc::new(crate::telemetry::MemoryTelemetry::new());\n        let cache = ReasoningCache::new(backend.clone(), 1, true, telemetry);\n\n        let ctx = test_ctx();\n        let trace = test_trace();\n\n        cache.set(&ctx, \"test query\", &trace).await.unwrap();\n\n        tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;\n\n        let retrieved = cache.get(&ctx, \"test query\").await.unwrap();\n        assert!(retrieved.is_none(), \"Cache entry should expire\");\n    }\n\n    #[test]\n    fn test_cache_error_display() {\n        let conn_err = CacheError::ConnectionError(\"refused\".to_string());\n        let ser_err = CacheError::SerializationError(\"invalid json\".to_string());\n        let op_err = CacheError::OperationError(\"timeout\".to_string());\n\n        assert!(conn_err.to_string().contains(\"connection\"));\n        assert!(ser_err.to_string().contains(\"serialization\"));\n        assert!(op_err.to_string().contains(\"operation\"));\n    }\n\n    #[test]\n    fn test_cached_reasoning_serialization() {\n        let cached = CachedReasoning {\n            trace: test_trace(),\n            cached_at: 1704067200,\n        };\n\n        let json = serde_json::to_string(&cached).unwrap();\n        let parsed: CachedReasoning = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(parsed.cached_at, cached.cached_at);\n        assert_eq!(parsed.trace.strategy, cached.trace.strategy);\n    }\n\n    #[tokio::test]\n    async fn test_lru_eviction() {\n        let backend = Arc::new(InMemoryReasoningCacheBackend::with_max_entries(3));\n        let telemetry = Arc::new(crate::telemetry::MemoryTelemetry::new());\n        let cache = ReasoningCache::new(backend.clone(), 3600, true, telemetry);\n\n        let ctx = test_ctx();\n        let trace = test_trace();\n\n        cache.set(&ctx, \"query1\", &trace).await.unwrap();\n        cache.set(&ctx, \"query2\", &trace).await.unwrap();\n        cache.set(&ctx, \"query3\", &trace).await.unwrap();\n\n        assert!(cache.get(&ctx, \"query1\").await.unwrap().is_some());\n        assert!(cache.get(&ctx, \"query2\").await.unwrap().is_some());\n        assert!(cache.get(&ctx, \"query3\").await.unwrap().is_some());\n\n        cache.set(&ctx, \"query4\", &trace).await.unwrap();\n\n        assert!(\n            cache.get(&ctx, \"query1\").await.unwrap().is_none(),\n            \"Oldest entry (query1) should be evicted\"\n        );\n        assert!(cache.get(&ctx, \"query2\").await.unwrap().is_some());\n        assert!(cache.get(&ctx, \"query3\").await.unwrap().is_some());\n        assert!(cache.get(&ctx, \"query4\").await.unwrap().is_some());\n    }\n\n    #[tokio::test]\n    async fn test_lru_access_order_update() {\n        let backend = Arc::new(InMemoryReasoningCacheBackend::with_max_entries(3));\n        let telemetry = Arc::new(crate::telemetry::MemoryTelemetry::new());\n        let cache = ReasoningCache::new(backend.clone(), 3600, true, telemetry);\n\n        let ctx = test_ctx();\n        let trace = test_trace();\n\n        cache.set(&ctx, \"query1\", &trace).await.unwrap();\n        cache.set(&ctx, \"query2\", &trace).await.unwrap();\n        cache.set(&ctx, \"query3\", &trace).await.unwrap();\n\n        cache.get(&ctx, \"query1\").await.unwrap();\n\n        cache.set(&ctx, \"query4\", &trace).await.unwrap();\n\n        assert!(\n            cache.get(&ctx, \"query1\").await.unwrap().is_some(),\n            \"query1 should still exist (was accessed recently)\"\n        );\n        assert!(\n            cache.get(&ctx, \"query2\").await.unwrap().is_none(),\n            \"query2 should be evicted (oldest after query1 access)\"\n        );\n        assert!(cache.get(&ctx, \"query3\").await.unwrap().is_some());\n        assert!(cache.get(&ctx, \"query4\").await.unwrap().is_some());\n    }\n\n    #[test]\n    fn test_with_max_entries_constructor() {\n        let backend = InMemoryReasoningCacheBackend::with_max_entries(500);\n        assert_eq!(backend.max_entries, 500);\n    }\n}\n","traces":[{"line":42,"address":[],"length":0,"stats":{"Line":39}},{"line":56,"address":[],"length":0,"stats":{"Line":86}},{"line":57,"address":[],"length":0,"stats":{"Line":258}},{"line":58,"address":[],"length":0,"stats":{"Line":172}},{"line":59,"address":[],"length":0,"stats":{"Line":344}},{"line":60,"address":[],"length":0,"stats":{"Line":172}},{"line":61,"address":[],"length":0,"stats":{"Line":344}},{"line":62,"address":[],"length":0,"stats":{"Line":344}},{"line":63,"address":[],"length":0,"stats":{"Line":430}},{"line":66,"address":[],"length":0,"stats":{"Line":86}},{"line":67,"address":[],"length":0,"stats":{"Line":258}},{"line":75,"address":[],"length":0,"stats":{"Line":46}},{"line":80,"address":[],"length":0,"stats":{"Line":46}},{"line":81,"address":[],"length":0,"stats":{"Line":1}},{"line":84,"address":[],"length":0,"stats":{"Line":180}},{"line":85,"address":[],"length":0,"stats":{"Line":135}},{"line":86,"address":[],"length":0,"stats":{"Line":15}},{"line":87,"address":[],"length":0,"stats":{"Line":15}},{"line":88,"address":[],"length":0,"stats":{"Line":15}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":30}},{"line":92,"address":[],"length":0,"stats":{"Line":30}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":36}},{"line":108,"address":[],"length":0,"stats":{"Line":36}},{"line":109,"address":[],"length":0,"stats":{"Line":1}},{"line":112,"address":[],"length":0,"stats":{"Line":140}},{"line":114,"address":[],"length":0,"stats":{"Line":105}},{"line":115,"address":[],"length":0,"stats":{"Line":35}},{"line":118,"address":[],"length":0,"stats":{"Line":175}},{"line":119,"address":[],"length":0,"stats":{"Line":35}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":2}},{"line":128,"address":[],"length":0,"stats":{"Line":1}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":4}},{"line":133,"address":[],"length":0,"stats":{"Line":2}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":37}},{"line":217,"address":[],"length":0,"stats":{"Line":37}},{"line":220,"address":[],"length":0,"stats":{"Line":40}},{"line":222,"address":[],"length":0,"stats":{"Line":120}},{"line":223,"address":[],"length":0,"stats":{"Line":80}},{"line":228,"address":[],"length":0,"stats":{"Line":70}},{"line":229,"address":[],"length":0,"stats":{"Line":105}},{"line":230,"address":[],"length":0,"stats":{"Line":35}},{"line":231,"address":[],"length":0,"stats":{"Line":33}},{"line":233,"address":[],"length":0,"stats":{"Line":4}},{"line":235,"address":[],"length":0,"stats":{"Line":6}},{"line":236,"address":[],"length":0,"stats":{"Line":6}},{"line":238,"address":[],"length":0,"stats":{"Line":4}},{"line":239,"address":[],"length":0,"stats":{"Line":6}},{"line":240,"address":[],"length":0,"stats":{"Line":4}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":100}},{"line":248,"address":[],"length":0,"stats":{"Line":150}},{"line":249,"address":[],"length":0,"stats":{"Line":216}},{"line":250,"address":[],"length":0,"stats":{"Line":150}},{"line":255,"address":[],"length":0,"stats":{"Line":0}},{"line":256,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":45}},{"line":295,"address":[],"length":0,"stats":{"Line":1}},{"line":301,"address":[],"length":0,"stats":{"Line":2}}],"covered":55,"coverable":81},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","redis.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","repository.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","state.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","telemetry.rs"],"content":"use metrics::{counter, gauge, histogram};\nuse opentelemetry::global;\nuse opentelemetry::global::{BoxedSpan, BoxedTracer};\nuse opentelemetry::metrics::Meter;\nuse opentelemetry::trace::Tracer;\n\n#[derive(Debug)]\npub struct MemoryTelemetry {\n    tracer: BoxedTracer,\n}\n\nimpl MemoryTelemetry {\n    pub fn new() -> Self {\n        let tracer = global::tracer(\"memory_system\");\n\n        Self { tracer }\n    }\n\n    pub fn with_tracer(tracer: BoxedTracer) -> Self {\n        Self { tracer }\n    }\n\n    pub fn with_meter(_meter: Meter) -> Self {\n        let tracer = global::tracer(\"memory_system\");\n\n        Self { tracer }\n    }\n\n    pub fn record_operation_start(&self, operation: &str, layer: &str) -> BoxedSpan {\n        self.tracer\n            .span_builder(format!(\"memory.{}\", operation))\n            .with_attributes(vec![\n                opentelemetry::KeyValue::new(\"layer\", layer.to_string()),\n                opentelemetry::KeyValue::new(\"operation\", operation.to_string()),\n            ])\n            .start(&self.tracer)\n    }\n\n    pub fn record_operation_success(&self, operation: &str, layer: &str, duration_ms: f64) {\n        counter!(\"memory_operations_total\", 1,\n            \"operation\" => operation.to_string(),\n            \"layer\" => layer.to_string(),\n            \"status\" => \"success\"\n        );\n\n        histogram!(\"memory_operation_duration_seconds\", duration_ms / 1000.0,\n            \"operation\" => operation.to_string(),\n            \"layer\" => layer.to_string()\n        );\n    }\n\n    pub fn record_operation_failure(&self, operation: &str, layer: &str, error: &str) {\n        counter!(\"memory_operations_total\", 1,\n            \"operation\" => operation.to_string(),\n            \"layer\" => layer.to_string(),\n            \"status\" => \"failure\",\n            \"error\" => error.to_string()\n        );\n\n        counter!(\"memory_operation_errors_total\", 1,\n            \"operation\" => operation.to_string(),\n            \"layer\" => layer.to_string(),\n            \"error_type\" => error.to_string()\n        );\n    }\n\n    pub fn record_embedding_generation(&self, dimension: usize, duration_ms: f64) {\n        counter!(\"memory_embeddings_generated_total\", 1,\n            \"dimension\" => dimension.to_string()\n        );\n\n        histogram!(\"memory_embedding_generation_duration_seconds\", duration_ms / 1000.0,\n            \"dimension\" => dimension.to_string()\n        );\n\n        gauge!(\"memory_embedding_dimension\", dimension as f64);\n    }\n\n    pub fn record_search_operation(&self, results_count: usize, query_dimension: usize) {\n        counter!(\"memory_searches_total\", 1);\n        histogram!(\"memory_search_results_count\", results_count as f64);\n        gauge!(\"memory_search_query_dimension\", query_dimension as f64);\n    }\n\n    pub fn record_storage_metrics(&self, entries_count: usize, total_size_bytes: usize) {\n        gauge!(\"memory_entries_total\", entries_count as f64);\n        gauge!(\"memory_storage_size_bytes\", total_size_bytes as f64);\n    }\n\n    pub fn record_cache_metrics(&self, hit_count: usize, miss_count: usize, cache_size: usize) {\n        counter!(\"memory_cache_hits_total\", hit_count as u64);\n        counter!(\"memory_cache_misses_total\", miss_count as u64);\n        gauge!(\"memory_cache_size\", cache_size as f64);\n\n        let total = hit_count + miss_count;\n        if total > 0 {\n            let hit_rate = (hit_count as f64) / (total as f64);\n            gauge!(\"memory_cache_hit_rate\", hit_rate);\n        }\n    }\n\n    pub fn record_promotion_attempt(&self, from_layer: &str, target_layer: &str) {\n        counter!(\"memory_promotion_attempts_total\", 1,\n            \"from_layer\" => from_layer.to_string(),\n            \"target_layer\" => target_layer.to_string()\n        );\n    }\n\n    pub fn record_promotion_success(&self, from_layer: &str, target_layer: &str) {\n        counter!(\"memory_promotion_success_total\", 1,\n            \"from_layer\" => from_layer.to_string(),\n            \"target_layer\" => target_layer.to_string()\n        );\n    }\n\n    pub fn record_promotion_blocked(&self, from_layer: &str, reason: &str) {\n        counter!(\"memory_promotion_blocked_total\", 1,\n            \"from_layer\" => from_layer.to_string(),\n            \"reason\" => reason.to_string()\n        );\n    }\n\n    pub fn record_governance_redaction(&self, layer: &str) {\n        counter!(\"memory_governance_redactions_total\", 1,\n            \"layer\" => layer.to_string()\n        );\n    }\n\n    pub fn record_reasoning_latency(&self, duration_ms: f64, timed_out: bool) {\n        histogram!(\"memory_reasoning_latency_seconds\", duration_ms / 1000.0);\n        counter!(\"memory_reasoning_total\", 1,\n            \"timed_out\" => timed_out.to_string()\n        );\n\n        if timed_out {\n            counter!(\"memory_reasoning_timeouts_total\", 1);\n        }\n    }\n\n    pub fn record_reasoning_p95_exceeded(&self, latency_ms: f64, threshold_ms: f64) {\n        counter!(\"memory_reasoning_p95_exceeded_total\", 1);\n        gauge!(\"memory_reasoning_last_exceeded_latency_ms\", latency_ms);\n        gauge!(\"memory_reasoning_p95_threshold_ms\", threshold_ms);\n    }\n\n    pub fn record_reasoning_cache_hit(&self) {\n        counter!(\"memory_reasoning_cache_hits_total\", 1);\n    }\n\n    pub fn record_reasoning_cache_miss(&self) {\n        counter!(\"memory_reasoning_cache_misses_total\", 1);\n    }\n\n    pub fn record_reasoning_cache_eviction(&self, evicted_count: usize) {\n        counter!(\n            \"memory_reasoning_cache_evictions_total\",\n            evicted_count as u64\n        );\n    }\n\n    pub fn record_reasoning_llm_call(&self) {\n        counter!(\"memory_reasoning_llm_calls_total\", 1);\n    }\n\n    pub fn record_reasoning_failure(&self, error: &str) {\n        counter!(\"memory_reasoning_failures_total\", 1,\n            \"error_type\" => error.to_string()\n        );\n    }\n\n    pub fn record_reasoning_circuit_opened(&self, failure_rate: f64) {\n        counter!(\"memory_reasoning_circuit_opened_total\", 1);\n        gauge!(\"memory_reasoning_unavailable\", 1.0);\n        gauge!(\"memory_reasoning_circuit_failure_rate\", failure_rate);\n    }\n\n    pub fn record_reasoning_circuit_closed(&self) {\n        counter!(\"memory_reasoning_circuit_closed_total\", 1);\n        gauge!(\"memory_reasoning_unavailable\", 0.0);\n    }\n\n    pub fn record_reasoning_circuit_half_open(&self) {\n        counter!(\"memory_reasoning_circuit_half_open_total\", 1);\n        gauge!(\"memory_reasoning_unavailable\", 0.5);\n    }\n\n    pub fn record_reasoning_circuit_rejected(&self) {\n        counter!(\"memory_reasoning_circuit_rejected_total\", 1);\n    }\n\n    pub fn record_multi_hop_metrics(&self, metrics: &crate::multi_hop::MultiHopMetrics) {\n        gauge!(\n            \"memory_multi_hop_depth_reached\",\n            metrics.max_depth_reached as f64\n        );\n        counter!(\n            \"memory_multi_hop_queries_total\",\n            metrics.total_queries as u64\n        );\n        counter!(\n            \"memory_multi_hop_paths_terminated_depth_total\",\n            metrics.paths_terminated_depth as u64\n        );\n        counter!(\n            \"memory_multi_hop_paths_terminated_relevance_total\",\n            metrics.paths_terminated_relevance as u64\n        );\n        counter!(\n            \"memory_multi_hop_paths_terminated_budget_total\",\n            metrics.paths_terminated_budget as u64\n        );\n    }\n}\n\npub fn init_telemetry() -> Result<MemoryTelemetry, Box<dyn std::error::Error + Send + Sync>> {\n    let telemetry = MemoryTelemetry::new();\n\n    metrics_exporter_prometheus::PrometheusBuilder::new()\n        .with_http_listener(([0, 0, 0, 0], 9090))\n        .install()?;\n\n    Ok(telemetry)\n}\n\npub fn init_telemetry_with_endpoint(\n    endpoint: std::net::SocketAddr,\n) -> Result<MemoryTelemetry, Box<dyn std::error::Error + Send + Sync>> {\n    let telemetry = MemoryTelemetry::new();\n\n    metrics_exporter_prometheus::PrometheusBuilder::new()\n        .with_http_listener(endpoint)\n        .install()?;\n\n    Ok(telemetry)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use metrics_util::debugging::DebuggingRecorder;\n\n    #[test]\n    fn test_telemetry_creation() {\n        use opentelemetry::trace::Span as _;\n        use opentelemetry::trace::TracerProvider as _;\n        use opentelemetry_sdk::trace::TracerProvider;\n\n        let provider = TracerProvider::default();\n        let tracer = provider.tracer(\"test\");\n        let telemetry =\n            MemoryTelemetry::with_tracer(opentelemetry::global::BoxedTracer::new(Box::new(tracer)));\n\n        let mut span = telemetry.record_operation_start(\"add\", \"agent\");\n        assert!(span.span_context().is_valid());\n        span.end();\n    }\n\n    #[test]\n    fn test_metrics_recording() {\n        let recorder = DebuggingRecorder::new();\n        let static_recorder: &'static DebuggingRecorder = Box::leak(Box::new(recorder));\n        metrics::set_recorder(static_recorder).ok();\n\n        let telemetry = MemoryTelemetry::new();\n\n        telemetry.record_operation_success(\"add\", \"agent\", 150.0);\n        telemetry.record_operation_failure(\"search\", \"session\", \"not_found\");\n        telemetry.record_embedding_generation(1536, 250.0);\n        telemetry.record_search_operation(5, 1536);\n        telemetry.record_storage_metrics(100, 1024000);\n        telemetry.record_cache_metrics(75, 25, 100);\n        telemetry.record_promotion_attempt(\"agent\", \"user\");\n        telemetry.record_promotion_success(\"agent\", \"user\");\n        telemetry.record_promotion_blocked(\"agent\", \"governance\");\n        telemetry.record_governance_redaction(\"user\");\n    }\n\n    #[test]\n    fn test_with_meter() {\n        use opentelemetry::metrics::MeterProvider;\n        use opentelemetry_sdk::metrics::MeterProvider as SdkMeterProvider;\n\n        let provider = SdkMeterProvider::default();\n        let meter = provider.meter(\"test\");\n\n        // Test that with_meter creates telemetry instance\n        let telemetry = MemoryTelemetry::with_meter(meter);\n\n        // Verify telemetry instance was created\n        // The meter parameter is ignored in the implementation, but we test the method\n        // exists\n        assert!(std::mem::size_of_val(&telemetry) > 0);\n    }\n\n    #[test]\n    fn test_init_telemetry() {\n        // Test that init_telemetry returns a Result\n        // The function might succeed or fail depending on port availability\n        let result = init_telemetry();\n\n        // Verify it returns a Result (either Ok or Err)\n        // We can't guarantee it will fail because port 9090 might be available\n        match result {\n            Ok(telemetry) => {\n                // If it succeeds, verify we got a telemetry instance\n                assert!(std::mem::size_of_val(&telemetry) > 0);\n            }\n            Err(e) => {\n                // If it fails, verify the error is related to binding\n                let error_str = e.to_string();\n                assert!(\n                    error_str.contains(\"address already in use\")\n                        || error_str.contains(\"bind\")\n                        || error_str.contains(\"port\")\n                        || error_str.contains(\"Permission denied\")\n                );\n            }\n        }\n    }\n\n    #[test]\n    fn test_init_telemetry_with_endpoint() {\n        use std::net::{IpAddr, Ipv4Addr, SocketAddr};\n\n        // Create a test endpoint (port 0 means OS will assign a free port)\n        let endpoint = SocketAddr::new(IpAddr::V4(Ipv4Addr::new(127, 0, 0, 1)), 0);\n\n        // Test that init_telemetry_with_endpoint returns a Result\n        let result = init_telemetry_with_endpoint(endpoint);\n\n        // The function should work with port 0 (OS-assigned port)\n        // But metrics initialization might still fail for other reasons\n        // We just verify it returns a Result\n        assert!(result.is_err() || result.is_ok());\n\n        // If it fails, verify it's not a bind error\n        if let Err(e) = result {\n            let error_str = e.to_string();\n            // Should not be a bind error with port 0\n            assert!(!error_str.contains(\"address already in use\"));\n        }\n    }\n}\n","traces":[{"line":13,"address":[],"length":0,"stats":{"Line":204}},{"line":14,"address":[],"length":0,"stats":{"Line":408}},{"line":19,"address":[],"length":0,"stats":{"Line":1}},{"line":23,"address":[],"length":0,"stats":{"Line":1}},{"line":24,"address":[],"length":0,"stats":{"Line":2}},{"line":29,"address":[],"length":0,"stats":{"Line":1217}},{"line":30,"address":[],"length":0,"stats":{"Line":1217}},{"line":31,"address":[],"length":0,"stats":{"Line":3651}},{"line":32,"address":[],"length":0,"stats":{"Line":2434}},{"line":33,"address":[],"length":0,"stats":{"Line":3651}},{"line":34,"address":[],"length":0,"stats":{"Line":3651}},{"line":36,"address":[],"length":0,"stats":{"Line":2434}},{"line":39,"address":[],"length":0,"stats":{"Line":1214}},{"line":40,"address":[],"length":0,"stats":{"Line":1214}},{"line":41,"address":[],"length":0,"stats":{"Line":2}},{"line":42,"address":[],"length":0,"stats":{"Line":2}},{"line":46,"address":[],"length":0,"stats":{"Line":1215}},{"line":47,"address":[],"length":0,"stats":{"Line":2}},{"line":48,"address":[],"length":0,"stats":{"Line":2}},{"line":52,"address":[],"length":0,"stats":{"Line":3}},{"line":53,"address":[],"length":0,"stats":{"Line":3}},{"line":54,"address":[],"length":0,"stats":{"Line":2}},{"line":55,"address":[],"length":0,"stats":{"Line":2}},{"line":57,"address":[],"length":0,"stats":{"Line":2}},{"line":60,"address":[],"length":0,"stats":{"Line":3}},{"line":61,"address":[],"length":0,"stats":{"Line":2}},{"line":62,"address":[],"length":0,"stats":{"Line":2}},{"line":63,"address":[],"length":0,"stats":{"Line":2}},{"line":67,"address":[],"length":0,"stats":{"Line":1}},{"line":68,"address":[],"length":0,"stats":{"Line":1}},{"line":69,"address":[],"length":0,"stats":{"Line":2}},{"line":72,"address":[],"length":0,"stats":{"Line":2}},{"line":73,"address":[],"length":0,"stats":{"Line":2}},{"line":76,"address":[],"length":0,"stats":{"Line":2}},{"line":79,"address":[],"length":0,"stats":{"Line":6}},{"line":80,"address":[],"length":0,"stats":{"Line":6}},{"line":81,"address":[],"length":0,"stats":{"Line":7}},{"line":82,"address":[],"length":0,"stats":{"Line":7}},{"line":85,"address":[],"length":0,"stats":{"Line":1}},{"line":86,"address":[],"length":0,"stats":{"Line":2}},{"line":87,"address":[],"length":0,"stats":{"Line":2}},{"line":90,"address":[],"length":0,"stats":{"Line":1}},{"line":91,"address":[],"length":0,"stats":{"Line":2}},{"line":92,"address":[],"length":0,"stats":{"Line":2}},{"line":93,"address":[],"length":0,"stats":{"Line":2}},{"line":95,"address":[],"length":0,"stats":{"Line":2}},{"line":96,"address":[],"length":0,"stats":{"Line":1}},{"line":97,"address":[],"length":0,"stats":{"Line":2}},{"line":98,"address":[],"length":0,"stats":{"Line":2}},{"line":102,"address":[],"length":0,"stats":{"Line":6}},{"line":103,"address":[],"length":0,"stats":{"Line":6}},{"line":104,"address":[],"length":0,"stats":{"Line":2}},{"line":105,"address":[],"length":0,"stats":{"Line":2}},{"line":109,"address":[],"length":0,"stats":{"Line":6}},{"line":110,"address":[],"length":0,"stats":{"Line":6}},{"line":111,"address":[],"length":0,"stats":{"Line":2}},{"line":112,"address":[],"length":0,"stats":{"Line":2}},{"line":116,"address":[],"length":0,"stats":{"Line":2}},{"line":117,"address":[],"length":0,"stats":{"Line":2}},{"line":118,"address":[],"length":0,"stats":{"Line":2}},{"line":119,"address":[],"length":0,"stats":{"Line":2}},{"line":123,"address":[],"length":0,"stats":{"Line":3}},{"line":124,"address":[],"length":0,"stats":{"Line":3}},{"line":125,"address":[],"length":0,"stats":{"Line":2}},{"line":129,"address":[],"length":0,"stats":{"Line":26}},{"line":130,"address":[],"length":0,"stats":{"Line":26}},{"line":131,"address":[],"length":0,"stats":{"Line":26}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":26}},{"line":136,"address":[],"length":0,"stats":{"Line":2}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":15}},{"line":147,"address":[],"length":0,"stats":{"Line":15}},{"line":150,"address":[],"length":0,"stats":{"Line":30}},{"line":151,"address":[],"length":0,"stats":{"Line":30}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":28}},{"line":162,"address":[],"length":0,"stats":{"Line":28}},{"line":165,"address":[],"length":0,"stats":{"Line":14}},{"line":166,"address":[],"length":0,"stats":{"Line":14}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":6}},{"line":172,"address":[],"length":0,"stats":{"Line":6}},{"line":173,"address":[],"length":0,"stats":{"Line":6}},{"line":174,"address":[],"length":0,"stats":{"Line":6}},{"line":177,"address":[],"length":0,"stats":{"Line":1}},{"line":178,"address":[],"length":0,"stats":{"Line":1}},{"line":179,"address":[],"length":0,"stats":{"Line":1}},{"line":182,"address":[],"length":0,"stats":{"Line":4}},{"line":183,"address":[],"length":0,"stats":{"Line":4}},{"line":184,"address":[],"length":0,"stats":{"Line":4}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":1}},{"line":192,"address":[],"length":0,"stats":{"Line":1}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":1}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":1}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":204,"address":[],"length":0,"stats":{"Line":1}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":1}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":1}},{"line":216,"address":[],"length":0,"stats":{"Line":2}},{"line":218,"address":[],"length":0,"stats":{"Line":1}},{"line":219,"address":[],"length":0,"stats":{"Line":2}},{"line":222,"address":[],"length":0,"stats":{"Line":1}},{"line":225,"address":[],"length":0,"stats":{"Line":1}},{"line":228,"address":[],"length":0,"stats":{"Line":2}},{"line":230,"address":[],"length":0,"stats":{"Line":1}},{"line":231,"address":[],"length":0,"stats":{"Line":2}},{"line":234,"address":[],"length":0,"stats":{"Line":0}}],"covered":102,"coverable":119},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","tools.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","trainer.rs"],"content":"//! # Memory-R1 Trainer\n//!\n//! Implements outcome-driven policy updates for memory selection using\n//! reinforcement learning concepts. The trainer learns which memories are\n//! valuable based on trajectory data and reward signals.\n//!\n//! ## Core Concepts\n//!\n//! - **Trajectories**: Sequences of memory operations with optional rewards\n//! - **Policy Weights**: Per-memory selection weights learned from rewards\n//! - **Discounted Returns**: Future rewards discounted by  (gamma)\n//! - **Baseline**: Running average for variance reduction in policy updates\n//!\n//! ## Example\n//!\n//! ```ignore\n//! use memory::trainer::{MemoryR1Trainer, R1TrainerConfig};\n//!\n//! let trainer = MemoryR1Trainer::new(\n//!     R1TrainerConfig::default(),\n//!     trajectories.clone(),\n//! );\n//!\n//! // Run a training step\n//! let metrics = trainer.train_step().await?;\n//! println!(\"Average reward: {}\", metrics.average_reward);\n//! ```\n\nuse mk_core::types::MemoryTrajectoryEvent;\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\n/// Configuration for Memory-R1 training.\n///\n/// These hyperparameters control the learning dynamics of the trainer.\n#[derive(Debug, Clone)]\npub struct R1TrainerConfig {\n    /// Learning rate for policy weight updates ().\n    /// Higher values mean faster learning but potentially less stable.\n    /// Default: 0.01\n    pub learning_rate: f32,\n\n    /// Discount factor for future rewards ().\n    /// Values closer to 1.0 weight future rewards more heavily.\n    /// Default: 0.99\n    pub discount_factor: f32,\n\n    /// Minimum number of trajectories required for a training step.\n    /// Prevents training on too little data.\n    /// Default: 10\n    pub min_batch_size: usize,\n\n    /// Maximum trajectory length to consider per memory.\n    /// Limits computational cost for long-running memories.\n    /// Default: 100\n    pub max_trajectory_length: usize,\n\n    /// Decay rate for the running baseline (exponential moving average).\n    /// Default: 0.9\n    pub baseline_decay: f32,\n\n    /// Minimum weight value to prevent weights from going too low.\n    /// Default: 0.1\n    pub min_weight: f32,\n\n    /// Maximum weight value to prevent weights from dominating.\n    /// Default: 10.0\n    pub max_weight: f32,\n}\n\nimpl Default for R1TrainerConfig {\n    fn default() -> Self {\n        Self {\n            learning_rate: 0.01,\n            discount_factor: 0.99,\n            min_batch_size: 10,\n            max_trajectory_length: 100,\n            baseline_decay: 0.9,\n            min_weight: 0.1,\n            max_weight: 10.0,\n        }\n    }\n}\n\n/// Memory-R1 Trainer for outcome-driven policy updates.\n///\n/// This trainer implements a simplified policy gradient approach where:\n/// - Each memory has an associated selection weight\n/// - Weights are updated based on discounted returns from trajectory rewards\n/// - A running baseline reduces variance in updates\n///\n/// The trainer does not directly modify memories; instead, it maintains\n/// selection weights that can be used by the memory manager to prioritize\n/// memories during search and retrieval.\npub struct MemoryR1Trainer {\n    config: R1TrainerConfig,\n    trajectories: Arc<RwLock<HashMap<String, Vec<MemoryTrajectoryEvent>>>>,\n    /// Running baseline for variance reduction (exponential moving average of\n    /// returns)\n    baseline: f32,\n    /// Memory selection weights (memory_id -> weight)\n    /// Weights > 1.0 indicate high-value memories\n    /// Weights < 1.0 indicate low-value memories\n    selection_weights: HashMap<String, f32>,\n    /// Cumulative returns per memory for aggregation\n    cumulative_returns: HashMap<String, f32>,\n    /// Number of updates per memory (for averaging)\n    update_counts: HashMap<String, usize>,\n}\n\nimpl MemoryR1Trainer {\n    /// Creates a new Memory-R1 Trainer.\n    ///\n    /// # Arguments\n    ///\n    /// * `config` - Training configuration with hyperparameters\n    /// * `trajectories` - Shared trajectory storage from MemoryManager\n    pub fn new(\n        config: R1TrainerConfig,\n        trajectories: Arc<RwLock<HashMap<String, Vec<MemoryTrajectoryEvent>>>>,\n    ) -> Self {\n        Self {\n            config,\n            trajectories,\n            baseline: 0.0,\n            selection_weights: HashMap::new(),\n            cumulative_returns: HashMap::new(),\n            update_counts: HashMap::new(),\n        }\n    }\n\n    /// Creates a trainer with pre-initialized weights.\n    ///\n    /// Useful for continuing training from a checkpoint.\n    pub fn with_weights(mut self, weights: HashMap<String, f32>) -> Self {\n        self.selection_weights = weights;\n        self\n    }\n\n    /// Creates a trainer with a pre-set baseline.\n    ///\n    /// Useful for continuing training from a checkpoint.\n    pub fn with_baseline(mut self, baseline: f32) -> Self {\n        self.baseline = baseline;\n        self\n    }\n\n    /// Computes discounted returns for a sequence of rewards.\n    ///\n    /// Uses the formula: R_t = r_t +  * R_{t+1}\n    ///\n    /// # Arguments\n    ///\n    /// * `rewards` - Sequence of reward values in temporal order\n    ///\n    /// # Returns\n    ///\n    /// Vector of discounted returns, same length as input\n    pub fn compute_returns(&self, rewards: &[f32]) -> Vec<f32> {\n        if rewards.is_empty() {\n            return Vec::new();\n        }\n\n        let mut returns = vec![0.0; rewards.len()];\n        let gamma = self.config.discount_factor;\n\n        // Compute returns backwards: R_t = r_t +  * R_{t+1}\n        returns[rewards.len() - 1] = rewards[rewards.len() - 1];\n        for i in (0..rewards.len() - 1).rev() {\n            returns[i] = rewards[i] + gamma * returns[i + 1];\n        }\n\n        returns\n    }\n\n    /// Aggregates rewards from a memory's trajectory events.\n    ///\n    /// Computes the total discounted return for a specific memory\n    /// based on its trajectory history.\n    ///\n    /// # Arguments\n    ///\n    /// * `memory_id` - The memory ID to aggregate rewards for\n    ///\n    /// # Returns\n    ///\n    /// The total discounted return, or 0.0 if no rewards found\n    pub async fn aggregate_trajectory_rewards(&self, memory_id: &str) -> f32 {\n        let trajectories = self.trajectories.read().await;\n\n        let events = match trajectories.get(memory_id) {\n            Some(events) => events,\n            None => return 0.0,\n        };\n\n        let events_to_process = if events.len() > self.config.max_trajectory_length {\n            &events[events.len() - self.config.max_trajectory_length..]\n        } else {\n            &events[..]\n        };\n\n        let rewards: Vec<f32> = events_to_process\n            .iter()\n            .map(|e| e.reward.as_ref().map(|r| r.score).unwrap_or(0.0))\n            .collect();\n\n        if rewards.is_empty() {\n            return 0.0;\n        }\n\n        let returns = self.compute_returns(&rewards);\n\n        returns.first().copied().unwrap_or(0.0)\n    }\n\n    fn has_rewards(events: &[MemoryTrajectoryEvent]) -> bool {\n        events.iter().any(|e| e.reward.is_some())\n    }\n\n    /// Updates policy weights based on trajectory outcomes.\n    ///\n    /// Implements a simplified policy gradient update:\n    /// w = w +  * (R - baseline)\n    ///\n    /// Where:\n    /// - w is the selection weight for a memory\n    /// -  is the learning rate\n    /// - R is the discounted return\n    /// - baseline is the running average return (for variance reduction)\n    ///\n    /// # Returns\n    ///\n    /// Training metrics including number of memories processed\n    pub async fn update_policy(&mut self) -> Result<TrainingMetrics, TrainerError> {\n        let trajectories = self.trajectories.read().await;\n\n        let memory_ids_with_rewards: Vec<String> = trajectories\n            .iter()\n            .filter(|(_, events)| Self::has_rewards(events))\n            .map(|(id, _)| id.clone())\n            .collect();\n\n        if memory_ids_with_rewards.len() < self.config.min_batch_size {\n            return Err(TrainerError::InsufficientData(\n                memory_ids_with_rewards.len(),\n                self.config.min_batch_size,\n            ));\n        }\n\n        drop(trajectories);\n\n        let mut total_return = 0.0;\n        let mut memories_processed = 0;\n        let mut policy_loss = 0.0;\n\n        for memory_id in &memory_ids_with_rewards {\n            let return_value = self.aggregate_trajectory_rewards(memory_id).await;\n\n            let advantage = return_value - self.baseline;\n            let current_weight = self\n                .selection_weights\n                .get(memory_id)\n                .copied()\n                .unwrap_or(1.0);\n            let new_weight = (current_weight + self.config.learning_rate * advantage)\n                .clamp(self.config.min_weight, self.config.max_weight);\n\n            self.selection_weights.insert(memory_id.clone(), new_weight);\n\n            total_return += return_value;\n            memories_processed += 1;\n            policy_loss += -advantage;\n\n            *self\n                .cumulative_returns\n                .entry(memory_id.clone())\n                .or_insert(0.0) += return_value;\n            *self.update_counts.entry(memory_id.clone()).or_insert(0) += 1;\n        }\n        if memories_processed > 0 {\n            let avg_return = total_return / memories_processed as f32;\n            self.baseline = self.config.baseline_decay * self.baseline\n                + (1.0 - self.config.baseline_decay) * avg_return;\n        }\n\n        Ok(TrainingMetrics {\n            memories_processed,\n            average_reward: if memories_processed > 0 {\n                total_return / memories_processed as f32\n            } else {\n                0.0\n            },\n            policy_loss: if memories_processed > 0 {\n                policy_loss / memories_processed as f32\n            } else {\n                0.0\n            },\n            baseline_value: self.baseline,\n        })\n    }\n\n    /// Runs a complete training step on accumulated trajectories.\n    ///\n    /// This is the main entry point for training. It:\n    /// 1. Checks if enough data is available\n    /// 2. Computes returns for all trajectories\n    /// 3. Updates policy weights\n    /// 4. Returns training metrics\n    ///\n    /// # Returns\n    ///\n    /// Training metrics on success, or error if insufficient data\n    pub async fn train_step(&mut self) -> Result<TrainingMetrics, TrainerError> {\n        self.update_policy().await\n    }\n\n    /// Gets the selection weight for a specific memory.\n    ///\n    /// Weights > 1.0 indicate the memory has received positive rewards\n    /// and should be prioritized in retrieval.\n    ///\n    /// # Arguments\n    ///\n    /// * `memory_id` - The memory to get weight for\n    ///\n    /// # Returns\n    ///\n    /// The selection weight (defaults to 1.0 for unknown memories)\n    pub fn get_weight(&self, memory_id: &str) -> f32 {\n        self.selection_weights\n            .get(memory_id)\n            .copied()\n            .unwrap_or(1.0)\n    }\n\n    /// Gets all current selection weights.\n    ///\n    /// Useful for persistence or debugging.\n    pub fn get_all_weights(&self) -> &HashMap<String, f32> {\n        &self.selection_weights\n    }\n\n    /// Gets the current baseline value.\n    pub fn get_baseline(&self) -> f32 {\n        self.baseline\n    }\n\n    /// Gets the average return for a specific memory across all updates.\n    pub fn get_average_return(&self, memory_id: &str) -> Option<f32> {\n        let cumulative = self.cumulative_returns.get(memory_id)?;\n        let count = self.update_counts.get(memory_id)?;\n        if *count == 0 {\n            return None;\n        }\n        Some(cumulative / *count as f32)\n    }\n\n    /// Resets all learned weights to default (1.0).\n    ///\n    /// Use with caution - this discards all learned information.\n    pub fn reset_weights(&mut self) {\n        self.selection_weights.clear();\n        self.cumulative_returns.clear();\n        self.update_counts.clear();\n        self.baseline = 0.0;\n    }\n\n    /// Removes weights for memories that no longer exist.\n    ///\n    /// Call periodically to clean up weights for deleted memories.\n    pub async fn prune_stale_weights(&mut self) {\n        let trajectories = self.trajectories.read().await;\n        let active_ids: std::collections::HashSet<&String> = trajectories.keys().collect();\n\n        self.selection_weights\n            .retain(|id, _| active_ids.contains(id));\n        self.cumulative_returns\n            .retain(|id, _| active_ids.contains(id));\n        self.update_counts.retain(|id, _| active_ids.contains(id));\n    }\n\n    /// Exports the current trainer state for persistence.\n    pub fn export_state(&self) -> TrainerState {\n        TrainerState {\n            baseline: self.baseline,\n            selection_weights: self.selection_weights.clone(),\n            cumulative_returns: self.cumulative_returns.clone(),\n            update_counts: self.update_counts.clone(),\n        }\n    }\n\n    /// Imports a previously exported trainer state.\n    pub fn import_state(&mut self, state: TrainerState) {\n        self.baseline = state.baseline;\n        self.selection_weights = state.selection_weights;\n        self.cumulative_returns = state.cumulative_returns;\n        self.update_counts = state.update_counts;\n    }\n}\n\n/// Metrics from a training step.\n#[derive(Debug, Clone, Default)]\npub struct TrainingMetrics {\n    /// Number of memories processed in this step\n    pub memories_processed: usize,\n    /// Average reward across all processed memories\n    pub average_reward: f32,\n    /// Average policy loss (negative advantage)\n    pub policy_loss: f32,\n    /// Current baseline value after update\n    pub baseline_value: f32,\n}\n\n/// Serializable trainer state for persistence.\n#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]\npub struct TrainerState {\n    pub baseline: f32,\n    pub selection_weights: HashMap<String, f32>,\n    pub cumulative_returns: HashMap<String, f32>,\n    pub update_counts: HashMap<String, usize>,\n}\n\n/// Errors that can occur during training.\n#[derive(Debug, thiserror::Error)]\npub enum TrainerError {\n    #[error(\"Insufficient data for training: {0} samples (need {1})\")]\n    InsufficientData(usize, usize),\n\n    #[error(\"Training failed: {0}\")]\n    TrainingFailed(String),\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::{MemoryOperation, RewardSignal, RewardType};\n\n    fn create_test_trajectories() -> Arc<RwLock<HashMap<String, Vec<MemoryTrajectoryEvent>>>> {\n        Arc::new(RwLock::new(HashMap::new()))\n    }\n\n    fn create_reward(score: f32) -> RewardSignal {\n        RewardSignal {\n            reward_type: if score >= 0.0 {\n                RewardType::Helpful\n            } else {\n                RewardType::Irrelevant\n            },\n            score,\n            reasoning: Some(format!(\"Test reward with score {}\", score)),\n            agent_id: None,\n            timestamp: chrono::Utc::now().timestamp(),\n        }\n    }\n\n    fn create_event(\n        entry_id: &str,\n        operation: MemoryOperation,\n        reward: Option<RewardSignal>,\n    ) -> MemoryTrajectoryEvent {\n        MemoryTrajectoryEvent {\n            operation,\n            entry_id: entry_id.to_string(),\n            reward,\n            reasoning: Some(\"Test event\".to_string()),\n            timestamp: chrono::Utc::now().timestamp(),\n        }\n    }\n\n    #[test]\n    fn test_config_default() {\n        let config = R1TrainerConfig::default();\n        assert_eq!(config.learning_rate, 0.01);\n        assert_eq!(config.discount_factor, 0.99);\n        assert_eq!(config.min_batch_size, 10);\n        assert_eq!(config.max_trajectory_length, 100);\n        assert_eq!(config.baseline_decay, 0.9);\n        assert_eq!(config.min_weight, 0.1);\n        assert_eq!(config.max_weight, 10.0);\n    }\n\n    #[test]\n    fn test_compute_returns_empty() {\n        let trajectories = create_test_trajectories();\n        let trainer = MemoryR1Trainer::new(R1TrainerConfig::default(), trajectories);\n\n        let returns = trainer.compute_returns(&[]);\n        assert!(returns.is_empty());\n    }\n\n    #[test]\n    fn test_compute_returns_single() {\n        let trajectories = create_test_trajectories();\n        let trainer = MemoryR1Trainer::new(R1TrainerConfig::default(), trajectories);\n\n        let returns = trainer.compute_returns(&[1.0]);\n        assert_eq!(returns.len(), 1);\n        assert_eq!(returns[0], 1.0);\n    }\n\n    #[test]\n    fn test_compute_returns_sequence() {\n        let trajectories = create_test_trajectories();\n        let config = R1TrainerConfig {\n            discount_factor: 0.9,\n            ..Default::default()\n        };\n        let trainer = MemoryR1Trainer::new(config, trajectories);\n\n        // Rewards: [1.0, 1.0, 1.0]\n        // Returns: [1 + 0.9*(1 + 0.9*1), 1 + 0.9*1, 1]\n        //        = [1 + 0.9*1.9, 1.9, 1]\n        //        = [2.71, 1.9, 1.0]\n        let returns = trainer.compute_returns(&[1.0, 1.0, 1.0]);\n        assert_eq!(returns.len(), 3);\n        assert!((returns[2] - 1.0).abs() < 0.001);\n        assert!((returns[1] - 1.9).abs() < 0.001);\n        assert!((returns[0] - 2.71).abs() < 0.001);\n    }\n\n    #[test]\n    fn test_compute_returns_with_zeros() {\n        let trajectories = create_test_trajectories();\n        let config = R1TrainerConfig {\n            discount_factor: 0.5,\n            ..Default::default()\n        };\n        let trainer = MemoryR1Trainer::new(config, trajectories);\n\n        // Rewards: [0.0, 0.0, 1.0]\n        // Returns: [0 + 0.5*(0 + 0.5*1), 0 + 0.5*1, 1]\n        //        = [0.25, 0.5, 1.0]\n        let returns = trainer.compute_returns(&[0.0, 0.0, 1.0]);\n        assert_eq!(returns.len(), 3);\n        assert!((returns[2] - 1.0).abs() < 0.001);\n        assert!((returns[1] - 0.5).abs() < 0.001);\n        assert!((returns[0] - 0.25).abs() < 0.001);\n    }\n\n    #[test]\n    fn test_compute_returns_negative() {\n        let trajectories = create_test_trajectories();\n        let config = R1TrainerConfig {\n            discount_factor: 0.5,\n            ..Default::default()\n        };\n        let trainer = MemoryR1Trainer::new(config, trajectories);\n\n        // Rewards: [1.0, -1.0]\n        // Returns: [1 + 0.5*(-1), -1]\n        //        = [0.5, -1.0]\n        let returns = trainer.compute_returns(&[1.0, -1.0]);\n        assert_eq!(returns.len(), 2);\n        assert!((returns[1] - (-1.0)).abs() < 0.001);\n        assert!((returns[0] - 0.5).abs() < 0.001);\n    }\n\n    #[tokio::test]\n    async fn test_aggregate_trajectory_rewards_no_trajectory() {\n        let trajectories = create_test_trajectories();\n        let trainer = MemoryR1Trainer::new(R1TrainerConfig::default(), trajectories);\n\n        let reward = trainer.aggregate_trajectory_rewards(\"nonexistent\").await;\n        assert_eq!(reward, 0.0);\n    }\n\n    #[tokio::test]\n    async fn test_aggregate_trajectory_rewards_no_rewards() {\n        let trajectories = create_test_trajectories();\n\n        // Add events without rewards\n        {\n            let mut traj = trajectories.write().await;\n            traj.insert(\n                \"mem1\".to_string(),\n                vec![\n                    create_event(\"mem1\", MemoryOperation::Add, None),\n                    create_event(\"mem1\", MemoryOperation::Retrieve, None),\n                ],\n            );\n        }\n\n        let trainer = MemoryR1Trainer::new(R1TrainerConfig::default(), trajectories);\n        let reward = trainer.aggregate_trajectory_rewards(\"mem1\").await;\n        assert_eq!(reward, 0.0);\n    }\n\n    #[tokio::test]\n    async fn test_aggregate_trajectory_rewards_with_rewards() {\n        let trajectories = create_test_trajectories();\n\n        {\n            let mut traj = trajectories.write().await;\n            traj.insert(\n                \"mem1\".to_string(),\n                vec![\n                    create_event(\"mem1\", MemoryOperation::Add, None),\n                    create_event(\"mem1\", MemoryOperation::Retrieve, Some(create_reward(0.5))),\n                    create_event(\"mem1\", MemoryOperation::Retrieve, Some(create_reward(0.3))),\n                ],\n            );\n        }\n\n        let config = R1TrainerConfig {\n            discount_factor: 0.9,\n            ..Default::default()\n        };\n        let trainer = MemoryR1Trainer::new(config, trajectories);\n        let reward = trainer.aggregate_trajectory_rewards(\"mem1\").await;\n\n        // Rewards sequence: [0.0, 0.5, 0.3]\n        // Returns: [0 + 0.9*(0.5 + 0.9*0.3), 0.5 + 0.9*0.3, 0.3]\n        //        = [0 + 0.9*0.77, 0.77, 0.3]\n        //        = [0.693, 0.77, 0.3]\n        assert!((reward - 0.693).abs() < 0.01);\n    }\n\n    #[tokio::test]\n    async fn test_aggregate_trajectory_rewards_max_length() {\n        let trajectories = create_test_trajectories();\n\n        {\n            let mut traj = trajectories.write().await;\n            let mut events = Vec::new();\n            for _ in 0..150 {\n                events.push(create_event(\n                    \"mem1\",\n                    MemoryOperation::Retrieve,\n                    Some(create_reward(0.1)),\n                ));\n            }\n            traj.insert(\"mem1\".to_string(), events);\n        }\n\n        let config = R1TrainerConfig {\n            max_trajectory_length: 10,\n            discount_factor: 0.9,\n            ..Default::default()\n        };\n        let trainer = MemoryR1Trainer::new(config, trajectories);\n\n        // Should only process last 10 events\n        let reward = trainer.aggregate_trajectory_rewards(\"mem1\").await;\n        // 10 rewards of 0.1 with =0.9\n        // First return  sum of discounted 0.1s\n        assert!(reward > 0.0 && reward < 1.0);\n    }\n\n    #[tokio::test]\n    async fn test_update_policy_insufficient_data() {\n        let trajectories = create_test_trajectories();\n\n        // Only add 5 trajectories (less than min_batch_size of 10)\n        {\n            let mut traj = trajectories.write().await;\n            for i in 0..5 {\n                traj.insert(\n                    format!(\"mem{}\", i),\n                    vec![create_event(\n                        &format!(\"mem{}\", i),\n                        MemoryOperation::Retrieve,\n                        Some(create_reward(0.5)),\n                    )],\n                );\n            }\n        }\n\n        let mut trainer = MemoryR1Trainer::new(R1TrainerConfig::default(), trajectories);\n        let result = trainer.update_policy().await;\n\n        assert!(result.is_err());\n        match result {\n            Err(TrainerError::InsufficientData(got, need)) => {\n                assert_eq!(got, 5);\n                assert_eq!(need, 10);\n            }\n            _ => panic!(\"Expected InsufficientData error\"),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_update_policy_success() {\n        let trajectories = create_test_trajectories();\n\n        // Add 15 trajectories with rewards\n        {\n            let mut traj = trajectories.write().await;\n            for i in 0..15 {\n                let score = if i % 2 == 0 { 0.5 } else { -0.3 };\n                traj.insert(\n                    format!(\"mem{}\", i),\n                    vec![create_event(\n                        &format!(\"mem{}\", i),\n                        MemoryOperation::Retrieve,\n                        Some(create_reward(score)),\n                    )],\n                );\n            }\n        }\n\n        let mut trainer = MemoryR1Trainer::new(R1TrainerConfig::default(), trajectories);\n        let metrics = trainer.update_policy().await.unwrap();\n\n        assert_eq!(metrics.memories_processed, 15);\n        assert!(metrics.average_reward != 0.0);\n        assert!(metrics.baseline_value != 0.0);\n\n        // Check that weights were updated\n        assert_eq!(trainer.selection_weights.len(), 15);\n    }\n\n    #[tokio::test]\n    async fn test_train_step() {\n        let trajectories = create_test_trajectories();\n\n        {\n            let mut traj = trajectories.write().await;\n            for i in 0..12 {\n                traj.insert(\n                    format!(\"mem{}\", i),\n                    vec![create_event(\n                        &format!(\"mem{}\", i),\n                        MemoryOperation::Retrieve,\n                        Some(create_reward(0.5)),\n                    )],\n                );\n            }\n        }\n\n        let mut trainer = MemoryR1Trainer::new(R1TrainerConfig::default(), trajectories);\n        let metrics = trainer.train_step().await.unwrap();\n\n        assert_eq!(metrics.memories_processed, 12);\n    }\n\n    #[test]\n    fn test_get_weight_default() {\n        let trajectories = create_test_trajectories();\n        let trainer = MemoryR1Trainer::new(R1TrainerConfig::default(), trajectories);\n\n        assert_eq!(trainer.get_weight(\"unknown\"), 1.0);\n    }\n\n    #[tokio::test]\n    async fn test_get_weight_after_training() {\n        let trajectories = create_test_trajectories();\n\n        {\n            let mut traj = trajectories.write().await;\n            for i in 0..12 {\n                let score = if i == 0 { 0.9 } else { 0.1 };\n                traj.insert(\n                    format!(\"mem{}\", i),\n                    vec![create_event(\n                        &format!(\"mem{}\", i),\n                        MemoryOperation::Retrieve,\n                        Some(create_reward(score)),\n                    )],\n                );\n            }\n        }\n\n        let mut trainer = MemoryR1Trainer::new(R1TrainerConfig::default(), trajectories);\n        trainer.train_step().await.unwrap();\n\n        // mem0 had highest reward, should have higher weight\n        let weight0 = trainer.get_weight(\"mem0\");\n        let weight1 = trainer.get_weight(\"mem1\");\n\n        assert!(weight0 > weight1);\n    }\n\n    #[test]\n    fn test_with_weights() {\n        let trajectories = create_test_trajectories();\n        let weights = HashMap::from([(\"mem1\".to_string(), 2.0), (\"mem2\".to_string(), 0.5)]);\n\n        let trainer =\n            MemoryR1Trainer::new(R1TrainerConfig::default(), trajectories).with_weights(weights);\n\n        assert_eq!(trainer.get_weight(\"mem1\"), 2.0);\n        assert_eq!(trainer.get_weight(\"mem2\"), 0.5);\n    }\n\n    #[test]\n    fn test_with_baseline() {\n        let trajectories = create_test_trajectories();\n        let trainer =\n            MemoryR1Trainer::new(R1TrainerConfig::default(), trajectories).with_baseline(0.5);\n\n        assert_eq!(trainer.get_baseline(), 0.5);\n    }\n\n    #[test]\n    fn test_reset_weights() {\n        let trajectories = create_test_trajectories();\n        let weights = HashMap::from([(\"mem1\".to_string(), 2.0)]);\n\n        let mut trainer = MemoryR1Trainer::new(R1TrainerConfig::default(), trajectories)\n            .with_weights(weights)\n            .with_baseline(0.5);\n\n        trainer.reset_weights();\n\n        assert_eq!(trainer.get_weight(\"mem1\"), 1.0);\n        assert_eq!(trainer.get_baseline(), 0.0);\n        assert!(trainer.selection_weights.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_prune_stale_weights() {\n        let trajectories = create_test_trajectories();\n\n        {\n            let mut traj = trajectories.write().await;\n            traj.insert(\n                \"active\".to_string(),\n                vec![create_event(\"active\", MemoryOperation::Add, None)],\n            );\n        }\n\n        let weights = HashMap::from([(\"active\".to_string(), 2.0), (\"deleted\".to_string(), 1.5)]);\n\n        let mut trainer =\n            MemoryR1Trainer::new(R1TrainerConfig::default(), trajectories).with_weights(weights);\n\n        trainer.prune_stale_weights().await;\n\n        assert_eq!(trainer.get_weight(\"active\"), 2.0);\n        assert_eq!(trainer.get_weight(\"deleted\"), 1.0); // default, not stored\n        assert_eq!(trainer.selection_weights.len(), 1);\n    }\n\n    #[tokio::test]\n    async fn test_export_import_state() {\n        let trajectories = create_test_trajectories();\n\n        {\n            let mut traj = trajectories.write().await;\n            for i in 0..12 {\n                traj.insert(\n                    format!(\"mem{}\", i),\n                    vec![create_event(\n                        &format!(\"mem{}\", i),\n                        MemoryOperation::Retrieve,\n                        Some(create_reward(0.5)),\n                    )],\n                );\n            }\n        }\n\n        let mut trainer = MemoryR1Trainer::new(R1TrainerConfig::default(), trajectories.clone());\n        trainer.train_step().await.unwrap();\n\n        let state = trainer.export_state();\n        assert!(!state.selection_weights.is_empty());\n        assert!(state.baseline != 0.0);\n\n        // Create new trainer and import state\n        let mut new_trainer = MemoryR1Trainer::new(R1TrainerConfig::default(), trajectories);\n        new_trainer.import_state(state.clone());\n\n        assert_eq!(new_trainer.get_baseline(), state.baseline);\n        assert_eq!(\n            new_trainer.selection_weights.len(),\n            state.selection_weights.len()\n        );\n    }\n\n    #[tokio::test]\n    async fn test_weight_clamping() {\n        let trajectories = create_test_trajectories();\n\n        // Create extreme positive rewards to test max clamping\n        {\n            let mut traj = trajectories.write().await;\n            for i in 0..12 {\n                let mut events = Vec::new();\n                for _ in 0..50 {\n                    events.push(create_event(\n                        &format!(\"mem{}\", i),\n                        MemoryOperation::Retrieve,\n                        Some(create_reward(1.0)),\n                    ));\n                }\n                traj.insert(format!(\"mem{}\", i), events);\n            }\n        }\n\n        let config = R1TrainerConfig {\n            learning_rate: 1.0, // High learning rate for faster updates\n            max_weight: 5.0,\n            ..Default::default()\n        };\n\n        let mut trainer = MemoryR1Trainer::new(config, trajectories);\n\n        // Train multiple times to accumulate weight\n        for _ in 0..10 {\n            let _ = trainer.train_step().await;\n        }\n\n        // All weights should be clamped to max\n        for (_, weight) in trainer.get_all_weights() {\n            assert!(*weight <= 5.0);\n        }\n    }\n\n    #[tokio::test]\n    async fn test_get_average_return() {\n        let trajectories = create_test_trajectories();\n\n        {\n            let mut traj = trajectories.write().await;\n            for i in 0..12 {\n                traj.insert(\n                    format!(\"mem{}\", i),\n                    vec![create_event(\n                        &format!(\"mem{}\", i),\n                        MemoryOperation::Retrieve,\n                        Some(create_reward(0.5)),\n                    )],\n                );\n            }\n        }\n\n        let mut trainer = MemoryR1Trainer::new(R1TrainerConfig::default(), trajectories);\n        trainer.train_step().await.unwrap();\n\n        // All memories should have average return tracked\n        for i in 0..12 {\n            let avg = trainer.get_average_return(&format!(\"mem{}\", i));\n            assert!(avg.is_some());\n            assert!(avg.unwrap() > 0.0);\n        }\n\n        // Unknown memory should return None\n        assert!(trainer.get_average_return(\"unknown\").is_none());\n    }\n\n    #[test]\n    fn test_training_metrics_default() {\n        let metrics = TrainingMetrics::default();\n        assert_eq!(metrics.memories_processed, 0);\n        assert_eq!(metrics.average_reward, 0.0);\n        assert_eq!(metrics.policy_loss, 0.0);\n        assert_eq!(metrics.baseline_value, 0.0);\n    }\n\n    #[test]\n    fn test_trainer_state_serialization() {\n        let state = TrainerState {\n            baseline: 0.5,\n            selection_weights: HashMap::from([(\"mem1\".to_string(), 1.5)]),\n            cumulative_returns: HashMap::from([(\"mem1\".to_string(), 2.0)]),\n            update_counts: HashMap::from([(\"mem1\".to_string(), 2)]),\n        };\n\n        let json = serde_json::to_string(&state).unwrap();\n        let deserialized: TrainerState = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(deserialized.baseline, state.baseline);\n        assert_eq!(deserialized.selection_weights, state.selection_weights);\n    }\n\n    #[test]\n    fn test_trainer_error_display() {\n        let err = TrainerError::InsufficientData(5, 10);\n        assert!(err.to_string().contains(\"5 samples\"));\n        assert!(err.to_string().contains(\"need 10\"));\n\n        let err2 = TrainerError::TrainingFailed(\"test error\".to_string());\n        assert!(err2.to_string().contains(\"test error\"));\n    }\n\n    #[tokio::test]\n    async fn test_baseline_update_with_exponential_moving_average() {\n        let trajectories = create_test_trajectories();\n\n        {\n            let mut traj = trajectories.write().await;\n            for i in 0..12 {\n                traj.insert(\n                    format!(\"mem{}\", i),\n                    vec![create_event(\n                        &format!(\"mem{}\", i),\n                        MemoryOperation::Retrieve,\n                        Some(create_reward(1.0)),\n                    )],\n                );\n            }\n        }\n\n        let config = R1TrainerConfig {\n            baseline_decay: 0.5, // Faster updates for testing\n            ..Default::default()\n        };\n\n        let mut trainer = MemoryR1Trainer::new(config, trajectories);\n\n        // Initial baseline is 0\n        assert_eq!(trainer.get_baseline(), 0.0);\n\n        // After first training, baseline should be updated\n        trainer.train_step().await.unwrap();\n        let baseline1 = trainer.get_baseline();\n        assert!(baseline1 > 0.0);\n\n        // Baseline should use EMA formula\n        // new_baseline = 0.5 * old_baseline + 0.5 * avg_return\n    }\n\n    #[tokio::test]\n    async fn test_has_rewards_helper() {\n        let events_with_rewards = vec![\n            create_event(\"mem1\", MemoryOperation::Add, None),\n            create_event(\"mem1\", MemoryOperation::Retrieve, Some(create_reward(0.5))),\n        ];\n\n        let events_without_rewards = vec![\n            create_event(\"mem1\", MemoryOperation::Add, None),\n            create_event(\"mem1\", MemoryOperation::Retrieve, None),\n        ];\n\n        assert!(MemoryR1Trainer::has_rewards(&events_with_rewards));\n        assert!(!MemoryR1Trainer::has_rewards(&events_without_rewards));\n    }\n}\n","traces":[{"line":73,"address":[],"length":0,"stats":{"Line":24}},{"line":119,"address":[],"length":0,"stats":{"Line":23}},{"line":127,"address":[],"length":0,"stats":{"Line":46}},{"line":128,"address":[],"length":0,"stats":{"Line":23}},{"line":129,"address":[],"length":0,"stats":{"Line":23}},{"line":136,"address":[],"length":0,"stats":{"Line":3}},{"line":137,"address":[],"length":0,"stats":{"Line":6}},{"line":138,"address":[],"length":0,"stats":{"Line":3}},{"line":144,"address":[],"length":0,"stats":{"Line":2}},{"line":145,"address":[],"length":0,"stats":{"Line":2}},{"line":146,"address":[],"length":0,"stats":{"Line":2}},{"line":160,"address":[],"length":0,"stats":{"Line":203}},{"line":161,"address":[],"length":0,"stats":{"Line":406}},{"line":162,"address":[],"length":0,"stats":{"Line":1}},{"line":165,"address":[],"length":0,"stats":{"Line":808}},{"line":166,"address":[],"length":0,"stats":{"Line":404}},{"line":169,"address":[],"length":0,"stats":{"Line":606}},{"line":170,"address":[],"length":0,"stats":{"Line":12198}},{"line":171,"address":[],"length":0,"stats":{"Line":23588}},{"line":174,"address":[],"length":0,"stats":{"Line":202}},{"line":189,"address":[],"length":0,"stats":{"Line":398}},{"line":190,"address":[],"length":0,"stats":{"Line":398}},{"line":192,"address":[],"length":0,"stats":{"Line":596}},{"line":193,"address":[],"length":0,"stats":{"Line":396}},{"line":194,"address":[],"length":0,"stats":{"Line":1}},{"line":197,"address":[],"length":0,"stats":{"Line":594}},{"line":198,"address":[],"length":0,"stats":{"Line":3}},{"line":200,"address":[],"length":0,"stats":{"Line":197}},{"line":203,"address":[],"length":0,"stats":{"Line":594}},{"line":205,"address":[],"length":0,"stats":{"Line":24558}},{"line":208,"address":[],"length":0,"stats":{"Line":396}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":792}},{"line":214,"address":[],"length":0,"stats":{"Line":594}},{"line":217,"address":[],"length":0,"stats":{"Line":202}},{"line":218,"address":[],"length":0,"stats":{"Line":812}},{"line":235,"address":[],"length":0,"stats":{"Line":34}},{"line":236,"address":[],"length":0,"stats":{"Line":34}},{"line":238,"address":[],"length":0,"stats":{"Line":51}},{"line":240,"address":[],"length":0,"stats":{"Line":417}},{"line":241,"address":[],"length":0,"stats":{"Line":417}},{"line":244,"address":[],"length":0,"stats":{"Line":34}},{"line":245,"address":[],"length":0,"stats":{"Line":1}},{"line":246,"address":[],"length":0,"stats":{"Line":2}},{"line":247,"address":[],"length":0,"stats":{"Line":1}},{"line":251,"address":[],"length":0,"stats":{"Line":32}},{"line":253,"address":[],"length":0,"stats":{"Line":32}},{"line":254,"address":[],"length":0,"stats":{"Line":32}},{"line":255,"address":[],"length":0,"stats":{"Line":32}},{"line":257,"address":[],"length":0,"stats":{"Line":406}},{"line":258,"address":[],"length":0,"stats":{"Line":780}},{"line":260,"address":[],"length":0,"stats":{"Line":390}},{"line":261,"address":[],"length":0,"stats":{"Line":390}},{"line":262,"address":[],"length":0,"stats":{"Line":195}},{"line":263,"address":[],"length":0,"stats":{"Line":390}},{"line":266,"address":[],"length":0,"stats":{"Line":585}},{"line":267,"address":[],"length":0,"stats":{"Line":585}},{"line":269,"address":[],"length":0,"stats":{"Line":975}},{"line":271,"address":[],"length":0,"stats":{"Line":195}},{"line":272,"address":[],"length":0,"stats":{"Line":195}},{"line":273,"address":[],"length":0,"stats":{"Line":195}},{"line":275,"address":[],"length":0,"stats":{"Line":390}},{"line":276,"address":[],"length":0,"stats":{"Line":390}},{"line":277,"address":[],"length":0,"stats":{"Line":780}},{"line":278,"address":[],"length":0,"stats":{"Line":195}},{"line":279,"address":[],"length":0,"stats":{"Line":780}},{"line":281,"address":[],"length":0,"stats":{"Line":32}},{"line":282,"address":[],"length":0,"stats":{"Line":48}},{"line":283,"address":[],"length":0,"stats":{"Line":32}},{"line":284,"address":[],"length":0,"stats":{"Line":16}},{"line":288,"address":[],"length":0,"stats":{"Line":16}},{"line":289,"address":[],"length":0,"stats":{"Line":16}},{"line":290,"address":[],"length":0,"stats":{"Line":16}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":16}},{"line":295,"address":[],"length":0,"stats":{"Line":16}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":16}},{"line":314,"address":[],"length":0,"stats":{"Line":30}},{"line":315,"address":[],"length":0,"stats":{"Line":30}},{"line":330,"address":[],"length":0,"stats":{"Line":8}},{"line":331,"address":[],"length":0,"stats":{"Line":8}},{"line":332,"address":[],"length":0,"stats":{"Line":16}},{"line":340,"address":[],"length":0,"stats":{"Line":1}},{"line":341,"address":[],"length":0,"stats":{"Line":1}},{"line":345,"address":[],"length":0,"stats":{"Line":5}},{"line":346,"address":[],"length":0,"stats":{"Line":5}},{"line":350,"address":[],"length":0,"stats":{"Line":13}},{"line":351,"address":[],"length":0,"stats":{"Line":52}},{"line":352,"address":[],"length":0,"stats":{"Line":48}},{"line":353,"address":[],"length":0,"stats":{"Line":12}},{"line":354,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":12}},{"line":362,"address":[],"length":0,"stats":{"Line":1}},{"line":363,"address":[],"length":0,"stats":{"Line":2}},{"line":364,"address":[],"length":0,"stats":{"Line":2}},{"line":365,"address":[],"length":0,"stats":{"Line":2}},{"line":366,"address":[],"length":0,"stats":{"Line":1}},{"line":372,"address":[],"length":0,"stats":{"Line":2}},{"line":373,"address":[],"length":0,"stats":{"Line":2}},{"line":374,"address":[],"length":0,"stats":{"Line":4}},{"line":376,"address":[],"length":0,"stats":{"Line":1}},{"line":377,"address":[],"length":0,"stats":{"Line":7}},{"line":378,"address":[],"length":0,"stats":{"Line":1}},{"line":379,"address":[],"length":0,"stats":{"Line":1}},{"line":380,"address":[],"length":0,"stats":{"Line":2}},{"line":384,"address":[],"length":0,"stats":{"Line":1}},{"line":386,"address":[],"length":0,"stats":{"Line":2}},{"line":387,"address":[],"length":0,"stats":{"Line":3}},{"line":388,"address":[],"length":0,"stats":{"Line":3}},{"line":389,"address":[],"length":0,"stats":{"Line":1}},{"line":394,"address":[],"length":0,"stats":{"Line":1}},{"line":395,"address":[],"length":0,"stats":{"Line":1}},{"line":396,"address":[],"length":0,"stats":{"Line":2}},{"line":397,"address":[],"length":0,"stats":{"Line":2}},{"line":398,"address":[],"length":0,"stats":{"Line":2}}],"covered":112,"coverable":116},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","validator.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","working.rs"],"content":"\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","mk_core","src","hints.rs"],"content":"//! # Operation Hints System\n//!\n//! Capability toggles for controlling system behavior at runtime.\n//!\n//! Hints allow users to enable/disable features like reasoning, summarization,\n//! caching, etc. This controls the system's intelligence level based on needs\n//! (cost, latency, verbosity).\n//!\n//! # M-CANONICAL-DOCS\n//!\n//! ## Purpose\n//! Provides a flexible system for toggling capabilities at three surfaces:\n//! - Per-request: CLI flags or API parameters\n//! - Per-context: `.aeterna/context.toml` configuration\n//! - Per-tenant: Server-side organizational defaults\n//!\n//! ## Precedence (highest to lowest)\n//! 1. Per-request hints (CLI flags, API params)\n//! 2. Environment variables (`AETERNA_HINTS_*`)\n//! 3. Context file (`.aeterna/context.toml`)\n//! 4. Org/tenant defaults\n//! 5. System defaults\n//!\n//! ## Usage\n//! ```rust\n//! use mk_core::hints::{OperationHints, HintPreset};\n//!\n//! // Use a preset\n//! let hints = OperationHints::from_preset(HintPreset::Fast);\n//!\n//! // Or build custom hints\n//! let hints = OperationHints::default()\n//!     .with_reasoning(false)\n//!     .with_caching(true);\n//!\n//! // Parse from CLI-style string\n//! let hints = OperationHints::parse_hint_string(\"no-llm,no-reasoning,caching\");\n//! ```\n\nuse schemars::JsonSchema;\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\nuse strum::{Display, EnumIter, EnumString};\nuse utoipa::ToSchema;\n\n/// Hint presets for common use cases.\n///\n/// Presets provide sensible defaults for different operational contexts.\n#[derive(\n    Debug,\n    Clone,\n    Copy,\n    PartialEq,\n    Eq,\n    Hash,\n    Serialize,\n    Deserialize,\n    ToSchema,\n    JsonSchema,\n    Display,\n    EnumString,\n    EnumIter,\n    Default,\n)]\n#[serde(rename_all = \"kebab-case\")]\n#[strum(serialize_all = \"kebab-case\")]\npub enum HintPreset {\n    /// Minimal processing: CI/CD, high-volume, cost-sensitive\n    /// Disables: reasoning, multi-hop, summarization, llm\n    Minimal,\n\n    /// Fast processing: Interactive, latency-sensitive\n    /// Disables: reasoning, multi-hop\n    Fast,\n\n    /// Standard processing: Default for humans\n    /// All features enabled with sensible defaults\n    #[default]\n    Standard,\n\n    /// Full processing: Deep analysis, debugging\n    /// All features enabled, more thorough processing\n    Full,\n\n    /// Offline mode: Disconnected work\n    /// Disables: llm, governance sync\n    Offline,\n\n    /// Agent mode: AI agent default\n    /// Optimized for agent workflows\n    Agent,\n\n    /// Custom: User-defined hints (no preset applied)\n    Custom,\n}\n\nimpl HintPreset {\n    /// Get the description for this preset\n    #[must_use]\n    pub fn description(&self) -> &'static str {\n        match self {\n            HintPreset::Minimal => \"CI/CD, high-volume, cost-sensitive. Disables LLM features.\",\n            HintPreset::Fast => \"Interactive, latency-sensitive. Skips expensive reasoning.\",\n            HintPreset::Standard => \"Default for humans. All features with sensible defaults.\",\n            HintPreset::Full => \"Deep analysis, debugging. More thorough processing.\",\n            HintPreset::Offline => \"Disconnected work. No external API calls.\",\n            HintPreset::Agent => \"AI agent workflows. Optimized for automation.\",\n            HintPreset::Custom => \"User-defined hints. No preset applied.\",\n        }\n    }\n\n    /// Get typical use cases for this preset\n    #[must_use]\n    pub fn use_cases(&self) -> &'static [&'static str] {\n        match self {\n            HintPreset::Minimal => &[\"CI/CD pipelines\", \"Batch processing\", \"Cost optimization\"],\n            HintPreset::Fast => &[\"Interactive CLI\", \"Real-time queries\", \"Development\"],\n            HintPreset::Standard => &[\"General usage\", \"Human operators\", \"Documentation\"],\n            HintPreset::Full => &[\"Debugging\", \"Deep analysis\", \"Compliance audits\"],\n            HintPreset::Offline => &[\"Air-gapped environments\", \"Network issues\", \"Local dev\"],\n            HintPreset::Agent => &[\"AI agents\", \"Automation\", \"Background tasks\"],\n            HintPreset::Custom => &[\"Advanced users\", \"Specific requirements\"],\n        }\n    }\n}\n\n/// Operation hints for controlling system behavior.\n///\n/// Each hint is a boolean toggle that enables/disables a capability.\n/// Hints can be combined and have precedence rules for resolution.\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct OperationHints {\n    /// The preset these hints are based on (if any)\n    #[serde(default)]\n    pub preset: HintPreset,\n\n    /// Enable pre-retrieval reasoning and query refinement (MemR)\n    #[serde(default = \"default_true\")]\n    pub reasoning: bool,\n\n    /// Enable multi-hop retrieval for complex queries\n    #[serde(default = \"default_true\")]\n    pub multi_hop: bool,\n\n    /// Enable layer summaries and compressed context\n    #[serde(default = \"default_true\")]\n    pub summarization: bool,\n\n    /// Enable query/result caching\n    #[serde(default = \"default_true\")]\n    pub caching: bool,\n\n    /// Enable policy checks and approval workflows\n    #[serde(default = \"default_true\")]\n    pub governance: bool,\n\n    /// Enable detailed audit logging\n    #[serde(default = \"default_true\")]\n    pub audit: bool,\n\n    /// Enable any LLM-powered features\n    #[serde(default = \"default_true\")]\n    pub llm: bool,\n\n    /// Enable automatic memory promotion based on rewards\n    #[serde(default = \"default_false\")]\n    pub auto_promote: bool,\n\n    /// Enable knowledge drift detection\n    #[serde(default = \"default_true\")]\n    pub drift_check: bool,\n\n    /// Enable graph traversal for related memories\n    #[serde(default = \"default_true\")]\n    pub graph: bool,\n\n    /// Enable CCA (Confucius Code Agent) capabilities\n    #[serde(default = \"default_true\")]\n    pub cca: bool,\n\n    /// Enable A2A (Agent-to-Agent) protocol\n    #[serde(default = \"default_true\")]\n    pub a2a: bool,\n\n    /// Enable verbose output for debugging\n    #[serde(default = \"default_false\")]\n    pub verbose: bool,\n\n    /// Custom hint overrides (for extensibility)\n    #[serde(default)]\n    pub custom: HashMap<String, bool>,\n}\n\nfn default_true() -> bool {\n    true\n}\n\nfn default_false() -> bool {\n    false\n}\n\nimpl Default for OperationHints {\n    fn default() -> Self {\n        Self::from_preset(HintPreset::Standard)\n    }\n}\n\nimpl OperationHints {\n    /// Create hints from a preset\n    #[must_use]\n    pub fn from_preset(preset: HintPreset) -> Self {\n        match preset {\n            HintPreset::Minimal => Self {\n                preset,\n                reasoning: false,\n                multi_hop: false,\n                summarization: false,\n                caching: true,\n                governance: true,\n                audit: false,\n                llm: false,\n                auto_promote: false,\n                drift_check: false,\n                graph: false,\n                cca: false,\n                a2a: false,\n                verbose: false,\n                custom: HashMap::new(),\n            },\n            HintPreset::Fast => Self {\n                preset,\n                reasoning: false,\n                multi_hop: false,\n                summarization: true,\n                caching: true,\n                governance: true,\n                audit: true,\n                llm: true,\n                auto_promote: false,\n                drift_check: true,\n                graph: true,\n                cca: false,\n                a2a: true,\n                verbose: false,\n                custom: HashMap::new(),\n            },\n            HintPreset::Standard => Self {\n                preset,\n                reasoning: true,\n                multi_hop: true,\n                summarization: true,\n                caching: true,\n                governance: true,\n                audit: true,\n                llm: true,\n                auto_promote: false,\n                drift_check: true,\n                graph: true,\n                cca: true,\n                a2a: true,\n                verbose: false,\n                custom: HashMap::new(),\n            },\n            HintPreset::Full => Self {\n                preset,\n                reasoning: true,\n                multi_hop: true,\n                summarization: true,\n                caching: true,\n                governance: true,\n                audit: true,\n                llm: true,\n                auto_promote: true,\n                drift_check: true,\n                graph: true,\n                cca: true,\n                a2a: true,\n                verbose: true,\n                custom: HashMap::new(),\n            },\n            HintPreset::Offline => Self {\n                preset,\n                reasoning: false,\n                multi_hop: false,\n                summarization: false,\n                caching: true,\n                governance: false,\n                audit: true,\n                llm: false,\n                auto_promote: false,\n                drift_check: false,\n                graph: true,\n                cca: false,\n                a2a: false,\n                verbose: false,\n                custom: HashMap::new(),\n            },\n            HintPreset::Agent => Self {\n                preset,\n                reasoning: true,\n                multi_hop: true,\n                summarization: true,\n                caching: true,\n                governance: true,\n                audit: true,\n                llm: true,\n                auto_promote: true,\n                drift_check: true,\n                graph: true,\n                cca: true,\n                a2a: true,\n                verbose: false,\n                custom: HashMap::new(),\n            },\n            HintPreset::Custom => Self {\n                preset,\n                reasoning: true,\n                multi_hop: true,\n                summarization: true,\n                caching: true,\n                governance: true,\n                audit: true,\n                llm: true,\n                auto_promote: false,\n                drift_check: true,\n                graph: true,\n                cca: true,\n                a2a: true,\n                verbose: false,\n                custom: HashMap::new(),\n            },\n        }\n    }\n\n    /// Parse hints from a CLI-style string.\n    ///\n    /// Format: `hint1,hint2,no-hint3,hint4=true`\n    ///\n    /// Examples:\n    /// - `\"no-llm,no-reasoning\"` - disable llm and reasoning\n    /// - `\"fast\"` - use fast preset\n    /// - `\"minimal,verbose\"` - minimal preset with verbose enabled\n    #[must_use]\n    pub fn parse_hint_string(s: &str) -> Self {\n        let mut hints = Self::default();\n\n        for part in s.split(',') {\n            let part = part.trim();\n            if part.is_empty() {\n                continue;\n            }\n\n            // Check if it's a preset name\n            if let Ok(preset) = part.parse::<HintPreset>() {\n                hints = Self::from_preset(preset);\n                continue;\n            }\n\n            // Parse individual hint\n            let (name, value) = if let Some(stripped) = part.strip_prefix(\"no-\") {\n                (stripped, false)\n            } else if let Some((name, val)) = part.split_once('=') {\n                let value = val.eq_ignore_ascii_case(\"true\") || val == \"1\";\n                (name, value)\n            } else {\n                (part, true)\n            };\n\n            hints.set_hint(name, value);\n        }\n\n        hints.preset = HintPreset::Custom;\n        hints\n    }\n\n    /// Set a hint by name\n    pub fn set_hint(&mut self, name: &str, value: bool) {\n        match name.to_lowercase().as_str() {\n            \"reasoning\" => self.reasoning = value,\n            \"multi-hop\" | \"multihop\" | \"multi_hop\" => self.multi_hop = value,\n            \"summarization\" | \"summary\" => self.summarization = value,\n            \"caching\" | \"cache\" => self.caching = value,\n            \"governance\" | \"gov\" => self.governance = value,\n            \"audit\" => self.audit = value,\n            \"llm\" => self.llm = value,\n            \"auto-promote\" | \"autopromote\" | \"auto_promote\" => self.auto_promote = value,\n            \"drift-check\" | \"driftcheck\" | \"drift_check\" | \"drift\" => self.drift_check = value,\n            \"graph\" => self.graph = value,\n            \"cca\" => self.cca = value,\n            \"a2a\" => self.a2a = value,\n            \"verbose\" => self.verbose = value,\n            _ => {\n                self.custom.insert(name.to_string(), value);\n            }\n        }\n    }\n\n    /// Get a hint by name\n    #[must_use]\n    pub fn get_hint(&self, name: &str) -> Option<bool> {\n        match name.to_lowercase().as_str() {\n            \"reasoning\" => Some(self.reasoning),\n            \"multi-hop\" | \"multihop\" | \"multi_hop\" => Some(self.multi_hop),\n            \"summarization\" | \"summary\" => Some(self.summarization),\n            \"caching\" | \"cache\" => Some(self.caching),\n            \"governance\" | \"gov\" => Some(self.governance),\n            \"audit\" => Some(self.audit),\n            \"llm\" => Some(self.llm),\n            \"auto-promote\" | \"autopromote\" | \"auto_promote\" => Some(self.auto_promote),\n            \"drift-check\" | \"driftcheck\" | \"drift_check\" | \"drift\" => Some(self.drift_check),\n            \"graph\" => Some(self.graph),\n            \"cca\" => Some(self.cca),\n            \"a2a\" => Some(self.a2a),\n            \"verbose\" => Some(self.verbose),\n            _ => self.custom.get(name).copied(),\n        }\n    }\n\n    /// Builder: set reasoning hint\n    #[must_use]\n    pub fn with_reasoning(mut self, value: bool) -> Self {\n        self.reasoning = value;\n        self.preset = HintPreset::Custom;\n        self\n    }\n\n    /// Builder: set multi-hop hint\n    #[must_use]\n    pub fn with_multi_hop(mut self, value: bool) -> Self {\n        self.multi_hop = value;\n        self.preset = HintPreset::Custom;\n        self\n    }\n\n    /// Builder: set summarization hint\n    #[must_use]\n    pub fn with_summarization(mut self, value: bool) -> Self {\n        self.summarization = value;\n        self.preset = HintPreset::Custom;\n        self\n    }\n\n    /// Builder: set caching hint\n    #[must_use]\n    pub fn with_caching(mut self, value: bool) -> Self {\n        self.caching = value;\n        self.preset = HintPreset::Custom;\n        self\n    }\n\n    /// Builder: set governance hint\n    #[must_use]\n    pub fn with_governance(mut self, value: bool) -> Self {\n        self.governance = value;\n        self.preset = HintPreset::Custom;\n        self\n    }\n\n    /// Builder: set audit hint\n    #[must_use]\n    pub fn with_audit(mut self, value: bool) -> Self {\n        self.audit = value;\n        self.preset = HintPreset::Custom;\n        self\n    }\n\n    /// Builder: set llm hint\n    #[must_use]\n    pub fn with_llm(mut self, value: bool) -> Self {\n        self.llm = value;\n        self.preset = HintPreset::Custom;\n        self\n    }\n\n    /// Builder: set auto-promote hint\n    #[must_use]\n    pub fn with_auto_promote(mut self, value: bool) -> Self {\n        self.auto_promote = value;\n        self.preset = HintPreset::Custom;\n        self\n    }\n\n    /// Builder: set drift-check hint\n    #[must_use]\n    pub fn with_drift_check(mut self, value: bool) -> Self {\n        self.drift_check = value;\n        self.preset = HintPreset::Custom;\n        self\n    }\n\n    /// Builder: set graph hint\n    #[must_use]\n    pub fn with_graph(mut self, value: bool) -> Self {\n        self.graph = value;\n        self.preset = HintPreset::Custom;\n        self\n    }\n\n    /// Builder: set cca hint\n    #[must_use]\n    pub fn with_cca(mut self, value: bool) -> Self {\n        self.cca = value;\n        self.preset = HintPreset::Custom;\n        self\n    }\n\n    /// Builder: set a2a hint\n    #[must_use]\n    pub fn with_a2a(mut self, value: bool) -> Self {\n        self.a2a = value;\n        self.preset = HintPreset::Custom;\n        self\n    }\n\n    /// Builder: set verbose hint\n    #[must_use]\n    pub fn with_verbose(mut self, value: bool) -> Self {\n        self.verbose = value;\n        self.preset = HintPreset::Custom;\n        self\n    }\n\n    /// Builder: set custom hint\n    #[must_use]\n    pub fn with_custom(mut self, name: impl Into<String>, value: bool) -> Self {\n        self.custom.insert(name.into(), value);\n        self.preset = HintPreset::Custom;\n        self\n    }\n\n    /// Merge with another hints object (other takes precedence)\n    #[must_use]\n    pub fn merge(&self, other: &Self) -> Self {\n        let mut result = self.clone();\n\n        // Only override if other has explicit customizations\n        if other.preset == HintPreset::Custom || other.preset != self.preset {\n            result.reasoning = other.reasoning;\n            result.multi_hop = other.multi_hop;\n            result.summarization = other.summarization;\n            result.caching = other.caching;\n            result.governance = other.governance;\n            result.audit = other.audit;\n            result.llm = other.llm;\n            result.auto_promote = other.auto_promote;\n            result.drift_check = other.drift_check;\n            result.graph = other.graph;\n            result.cca = other.cca;\n            result.a2a = other.a2a;\n            result.verbose = other.verbose;\n            result.preset = other.preset;\n        }\n\n        // Always merge custom hints\n        for (k, v) in &other.custom {\n            result.custom.insert(k.clone(), *v);\n        }\n\n        result\n    }\n\n    /// Check if any LLM features are enabled\n    #[must_use]\n    pub fn has_llm_features(&self) -> bool {\n        self.llm && (self.reasoning || self.summarization || self.cca)\n    }\n\n    /// Check if this is a minimal/lightweight configuration\n    #[must_use]\n    pub fn is_lightweight(&self) -> bool {\n        !self.reasoning && !self.multi_hop && !self.summarization\n    }\n\n    /// Convert to a hint string for CLI/API\n    #[must_use]\n    pub fn to_hint_string(&self) -> String {\n        let mut parts = Vec::new();\n\n        if !self.reasoning {\n            parts.push(\"no-reasoning\");\n        }\n        if !self.multi_hop {\n            parts.push(\"no-multi-hop\");\n        }\n        if !self.summarization {\n            parts.push(\"no-summarization\");\n        }\n        if !self.caching {\n            parts.push(\"no-caching\");\n        }\n        if !self.governance {\n            parts.push(\"no-governance\");\n        }\n        if !self.audit {\n            parts.push(\"no-audit\");\n        }\n        if !self.llm {\n            parts.push(\"no-llm\");\n        }\n        if self.auto_promote {\n            parts.push(\"auto-promote\");\n        }\n        if !self.drift_check {\n            parts.push(\"no-drift-check\");\n        }\n        if !self.graph {\n            parts.push(\"no-graph\");\n        }\n        if !self.cca {\n            parts.push(\"no-cca\");\n        }\n        if !self.a2a {\n            parts.push(\"no-a2a\");\n        }\n        if self.verbose {\n            parts.push(\"verbose\");\n        }\n\n        let custom_parts: Vec<String> = self\n            .custom\n            .iter()\n            .map(|(k, v)| if *v { k.clone() } else { format!(\"no-{k}\") })\n            .collect();\n\n        for part in &custom_parts {\n            parts.push(part.as_str());\n        }\n\n        if parts.is_empty() {\n            \"standard\".to_string()\n        } else {\n            parts.join(\",\")\n        }\n    }\n\n    /// Get all hint names and their current values\n    #[must_use]\n    pub fn all_hints(&self) -> Vec<(&'static str, bool)> {\n        let mut hints = vec![\n            (\"reasoning\", self.reasoning),\n            (\"multi-hop\", self.multi_hop),\n            (\"summarization\", self.summarization),\n            (\"caching\", self.caching),\n            (\"governance\", self.governance),\n            (\"audit\", self.audit),\n            (\"llm\", self.llm),\n            (\"auto-promote\", self.auto_promote),\n            (\"drift-check\", self.drift_check),\n            (\"graph\", self.graph),\n            (\"cca\", self.cca),\n            (\"a2a\", self.a2a),\n            (\"verbose\", self.verbose),\n        ];\n\n        // Note: custom hints are not included in this method\n        // Use `custom` field directly to access custom hints\n        hints.sort_by_key(|(name, _)| *name);\n        hints\n    }\n}\n\n/// Hints configuration for context.toml\n#[derive(Debug, Clone, Default, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"kebab-case\")]\npub struct HintsConfig {\n    /// Default preset to use\n    #[serde(default)]\n    pub preset: Option<HintPreset>,\n\n    /// Individual hint overrides\n    #[serde(flatten)]\n    pub overrides: HashMap<String, bool>,\n}\n\nimpl HintsConfig {\n    /// Convert to OperationHints\n    #[must_use]\n    pub fn to_operation_hints(&self) -> OperationHints {\n        let mut hints = match self.preset {\n            Some(preset) => OperationHints::from_preset(preset),\n            None => OperationHints::default(),\n        };\n\n        for (name, value) in &self.overrides {\n            hints.set_hint(name, *value);\n        }\n\n        hints\n    }\n}\n\n/// Environment-based hints resolution\nimpl OperationHints {\n    /// Load hints from environment variables.\n    ///\n    /// Environment variables:\n    /// - `AETERNA_HINTS`: Comma-separated hint string\n    /// - `AETERNA_HINTS_PRESET`: Preset name\n    /// - `AETERNA_HINTS_REASONING`: true/false\n    /// - `AETERNA_HINTS_LLM`: true/false\n    /// - etc.\n    #[must_use]\n    pub fn from_env() -> Self {\n        let mut hints = Self::default();\n\n        // Check for preset first\n        if let Ok(preset_str) = std::env::var(\"AETERNA_HINTS_PRESET\") {\n            if let Ok(preset) = preset_str.parse::<HintPreset>() {\n                hints = Self::from_preset(preset);\n            }\n        }\n\n        // Check for hint string\n        if let Ok(hint_str) = std::env::var(\"AETERNA_HINTS\") {\n            hints = Self::parse_hint_string(&hint_str);\n        }\n\n        // Check individual environment variables\n        let env_hints = [\n            (\"AETERNA_HINTS_REASONING\", \"reasoning\"),\n            (\"AETERNA_HINTS_MULTI_HOP\", \"multi-hop\"),\n            (\"AETERNA_HINTS_SUMMARIZATION\", \"summarization\"),\n            (\"AETERNA_HINTS_CACHING\", \"caching\"),\n            (\"AETERNA_HINTS_GOVERNANCE\", \"governance\"),\n            (\"AETERNA_HINTS_AUDIT\", \"audit\"),\n            (\"AETERNA_HINTS_LLM\", \"llm\"),\n            (\"AETERNA_HINTS_AUTO_PROMOTE\", \"auto-promote\"),\n            (\"AETERNA_HINTS_DRIFT_CHECK\", \"drift-check\"),\n            (\"AETERNA_HINTS_GRAPH\", \"graph\"),\n            (\"AETERNA_HINTS_CCA\", \"cca\"),\n            (\"AETERNA_HINTS_A2A\", \"a2a\"),\n            (\"AETERNA_HINTS_VERBOSE\", \"verbose\"),\n        ];\n\n        for (env_var, hint_name) in env_hints {\n            if let Ok(value) = std::env::var(env_var) {\n                let bool_value = value.eq_ignore_ascii_case(\"true\") || value == \"1\";\n                hints.set_hint(hint_name, bool_value);\n            }\n        }\n\n        hints\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_preset_minimal() {\n        let hints = OperationHints::from_preset(HintPreset::Minimal);\n        assert!(!hints.reasoning);\n        assert!(!hints.multi_hop);\n        assert!(!hints.summarization);\n        assert!(!hints.llm);\n        assert!(hints.caching);\n        assert!(hints.governance);\n    }\n\n    #[test]\n    fn test_preset_fast() {\n        let hints = OperationHints::from_preset(HintPreset::Fast);\n        assert!(!hints.reasoning);\n        assert!(!hints.multi_hop);\n        assert!(hints.summarization);\n        assert!(hints.llm);\n        assert!(hints.caching);\n    }\n\n    #[test]\n    fn test_preset_standard() {\n        let hints = OperationHints::from_preset(HintPreset::Standard);\n        assert!(hints.reasoning);\n        assert!(hints.multi_hop);\n        assert!(hints.summarization);\n        assert!(hints.llm);\n        assert!(hints.caching);\n    }\n\n    #[test]\n    fn test_preset_full() {\n        let hints = OperationHints::from_preset(HintPreset::Full);\n        assert!(hints.reasoning);\n        assert!(hints.multi_hop);\n        assert!(hints.auto_promote);\n        assert!(hints.verbose);\n    }\n\n    #[test]\n    fn test_preset_offline() {\n        let hints = OperationHints::from_preset(HintPreset::Offline);\n        assert!(!hints.reasoning);\n        assert!(!hints.llm);\n        assert!(!hints.governance);\n        assert!(!hints.a2a);\n        assert!(hints.caching);\n        assert!(hints.graph);\n    }\n\n    #[test]\n    fn test_parse_hint_string_simple() {\n        let hints = OperationHints::parse_hint_string(\"no-llm,no-reasoning\");\n        assert!(!hints.llm);\n        assert!(!hints.reasoning);\n        assert!(hints.caching);\n    }\n\n    #[test]\n    fn test_parse_hint_string_with_preset() {\n        let hints = OperationHints::parse_hint_string(\"minimal,verbose\");\n        assert!(!hints.llm);\n        assert!(hints.verbose);\n    }\n\n    #[test]\n    fn test_parse_hint_string_with_equals() {\n        let hints = OperationHints::parse_hint_string(\"llm=false,verbose=true\");\n        assert!(!hints.llm);\n        assert!(hints.verbose);\n    }\n\n    #[test]\n    fn test_builder_pattern() {\n        let hints = OperationHints::default()\n            .with_reasoning(false)\n            .with_llm(false)\n            .with_verbose(true);\n\n        assert!(!hints.reasoning);\n        assert!(!hints.llm);\n        assert!(hints.verbose);\n        assert_eq!(hints.preset, HintPreset::Custom);\n    }\n\n    #[test]\n    fn test_merge_hints() {\n        let base = OperationHints::from_preset(HintPreset::Standard);\n        let overrides = OperationHints::default()\n            .with_reasoning(false)\n            .with_verbose(true);\n\n        let merged = base.merge(&overrides);\n        assert!(!merged.reasoning);\n        assert!(merged.verbose);\n    }\n\n    #[test]\n    fn test_to_hint_string() {\n        let hints = OperationHints::from_preset(HintPreset::Minimal);\n        let s = hints.to_hint_string();\n        assert!(s.contains(\"no-reasoning\"));\n        assert!(s.contains(\"no-llm\"));\n    }\n\n    #[test]\n    fn test_get_set_hint() {\n        let mut hints = OperationHints::default();\n        hints.set_hint(\"reasoning\", false);\n        assert_eq!(hints.get_hint(\"reasoning\"), Some(false));\n\n        hints.set_hint(\"custom-hint\", true);\n        assert_eq!(hints.get_hint(\"custom-hint\"), Some(true));\n    }\n\n    #[test]\n    fn test_has_llm_features() {\n        let hints = OperationHints::from_preset(HintPreset::Standard);\n        assert!(hints.has_llm_features());\n\n        let hints = OperationHints::from_preset(HintPreset::Minimal);\n        assert!(!hints.has_llm_features());\n    }\n\n    #[test]\n    fn test_is_lightweight() {\n        let hints = OperationHints::from_preset(HintPreset::Minimal);\n        assert!(hints.is_lightweight());\n\n        let hints = OperationHints::from_preset(HintPreset::Standard);\n        assert!(!hints.is_lightweight());\n    }\n\n    #[test]\n    fn test_hints_config_to_operation_hints() {\n        let config = HintsConfig {\n            preset: Some(HintPreset::Fast),\n            overrides: {\n                let mut m = HashMap::new();\n                m.insert(\"verbose\".to_string(), true);\n                m\n            },\n        };\n\n        let hints = config.to_operation_hints();\n        assert!(!hints.reasoning); // From Fast preset\n        assert!(hints.verbose); // From override\n    }\n\n    #[test]\n    fn test_preset_serialization() {\n        let preset = HintPreset::Minimal;\n        let json = serde_json::to_string(&preset).unwrap();\n        assert_eq!(json, \"\\\"minimal\\\"\");\n\n        let deserialized: HintPreset = serde_json::from_str(&json).unwrap();\n        assert_eq!(deserialized, HintPreset::Minimal);\n    }\n\n    #[test]\n    fn test_hints_serialization() {\n        let hints = OperationHints::from_preset(HintPreset::Fast);\n        let json = serde_json::to_string(&hints).unwrap();\n        let deserialized: OperationHints = serde_json::from_str(&json).unwrap();\n        assert_eq!(hints, deserialized);\n    }\n\n    #[test]\n    fn test_all_hints() {\n        let hints = OperationHints::default();\n        let all = hints.all_hints();\n        assert!(all.len() >= 13); // At least 13 built-in hints\n        assert!(all.iter().any(|(name, _)| *name == \"reasoning\"));\n        assert!(all.iter().any(|(name, _)| *name == \"llm\"));\n    }\n\n    #[test]\n    fn test_preset_description() {\n        assert!(!HintPreset::Minimal.description().is_empty());\n        assert!(!HintPreset::Fast.description().is_empty());\n        assert!(!HintPreset::Standard.description().is_empty());\n    }\n\n    #[test]\n    fn test_preset_use_cases() {\n        assert!(!HintPreset::Minimal.use_cases().is_empty());\n        assert!(!HintPreset::Fast.use_cases().is_empty());\n    }\n}\n","traces":[{"line":100,"address":[],"length":0,"stats":{"Line":3}},{"line":101,"address":[],"length":0,"stats":{"Line":3}},{"line":102,"address":[],"length":0,"stats":{"Line":1}},{"line":103,"address":[],"length":0,"stats":{"Line":1}},{"line":104,"address":[],"length":0,"stats":{"Line":1}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":2}},{"line":115,"address":[],"length":0,"stats":{"Line":2}},{"line":116,"address":[],"length":0,"stats":{"Line":1}},{"line":117,"address":[],"length":0,"stats":{"Line":1}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":204,"address":[],"length":0,"stats":{"Line":167}},{"line":205,"address":[],"length":0,"stats":{"Line":334}},{"line":212,"address":[],"length":0,"stats":{"Line":189}},{"line":213,"address":[],"length":0,"stats":{"Line":189}},{"line":229,"address":[],"length":0,"stats":{"Line":7}},{"line":246,"address":[],"length":0,"stats":{"Line":9}},{"line":263,"address":[],"length":0,"stats":{"Line":171}},{"line":280,"address":[],"length":0,"stats":{"Line":1}},{"line":297,"address":[],"length":0,"stats":{"Line":1}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":345,"address":[],"length":0,"stats":{"Line":5}},{"line":346,"address":[],"length":0,"stats":{"Line":10}},{"line":348,"address":[],"length":0,"stats":{"Line":22}},{"line":349,"address":[],"length":0,"stats":{"Line":36}},{"line":350,"address":[],"length":0,"stats":{"Line":24}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":355,"address":[],"length":0,"stats":{"Line":15}},{"line":356,"address":[],"length":0,"stats":{"Line":9}},{"line":357,"address":[],"length":0,"stats":{"Line":3}},{"line":361,"address":[],"length":0,"stats":{"Line":33}},{"line":362,"address":[],"length":0,"stats":{"Line":6}},{"line":363,"address":[],"length":0,"stats":{"Line":7}},{"line":364,"address":[],"length":0,"stats":{"Line":9}},{"line":365,"address":[],"length":0,"stats":{"Line":2}},{"line":367,"address":[],"length":0,"stats":{"Line":1}},{"line":370,"address":[],"length":0,"stats":{"Line":36}},{"line":373,"address":[],"length":0,"stats":{"Line":5}},{"line":374,"address":[],"length":0,"stats":{"Line":5}},{"line":378,"address":[],"length":0,"stats":{"Line":14}},{"line":379,"address":[],"length":0,"stats":{"Line":14}},{"line":380,"address":[],"length":0,"stats":{"Line":18}},{"line":381,"address":[],"length":0,"stats":{"Line":30}},{"line":382,"address":[],"length":0,"stats":{"Line":20}},{"line":383,"address":[],"length":0,"stats":{"Line":20}},{"line":384,"address":[],"length":0,"stats":{"Line":20}},{"line":385,"address":[],"length":0,"stats":{"Line":10}},{"line":386,"address":[],"length":0,"stats":{"Line":14}},{"line":387,"address":[],"length":0,"stats":{"Line":18}},{"line":388,"address":[],"length":0,"stats":{"Line":24}},{"line":389,"address":[],"length":0,"stats":{"Line":6}},{"line":390,"address":[],"length":0,"stats":{"Line":6}},{"line":391,"address":[],"length":0,"stats":{"Line":6}},{"line":392,"address":[],"length":0,"stats":{"Line":11}},{"line":393,"address":[],"length":0,"stats":{"Line":1}},{"line":394,"address":[],"length":0,"stats":{"Line":4}},{"line":401,"address":[],"length":0,"stats":{"Line":2}},{"line":402,"address":[],"length":0,"stats":{"Line":2}},{"line":403,"address":[],"length":0,"stats":{"Line":3}},{"line":404,"address":[],"length":0,"stats":{"Line":3}},{"line":405,"address":[],"length":0,"stats":{"Line":2}},{"line":406,"address":[],"length":0,"stats":{"Line":2}},{"line":407,"address":[],"length":0,"stats":{"Line":2}},{"line":408,"address":[],"length":0,"stats":{"Line":1}},{"line":409,"address":[],"length":0,"stats":{"Line":1}},{"line":410,"address":[],"length":0,"stats":{"Line":3}},{"line":411,"address":[],"length":0,"stats":{"Line":4}},{"line":412,"address":[],"length":0,"stats":{"Line":1}},{"line":413,"address":[],"length":0,"stats":{"Line":1}},{"line":414,"address":[],"length":0,"stats":{"Line":1}},{"line":415,"address":[],"length":0,"stats":{"Line":1}},{"line":416,"address":[],"length":0,"stats":{"Line":4}},{"line":422,"address":[],"length":0,"stats":{"Line":2}},{"line":423,"address":[],"length":0,"stats":{"Line":2}},{"line":424,"address":[],"length":0,"stats":{"Line":2}},{"line":425,"address":[],"length":0,"stats":{"Line":2}},{"line":430,"address":[],"length":0,"stats":{"Line":0}},{"line":431,"address":[],"length":0,"stats":{"Line":0}},{"line":432,"address":[],"length":0,"stats":{"Line":0}},{"line":433,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":0}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":441,"address":[],"length":0,"stats":{"Line":0}},{"line":446,"address":[],"length":0,"stats":{"Line":0}},{"line":447,"address":[],"length":0,"stats":{"Line":0}},{"line":448,"address":[],"length":0,"stats":{"Line":0}},{"line":449,"address":[],"length":0,"stats":{"Line":0}},{"line":454,"address":[],"length":0,"stats":{"Line":0}},{"line":455,"address":[],"length":0,"stats":{"Line":0}},{"line":456,"address":[],"length":0,"stats":{"Line":0}},{"line":457,"address":[],"length":0,"stats":{"Line":0}},{"line":462,"address":[],"length":0,"stats":{"Line":0}},{"line":463,"address":[],"length":0,"stats":{"Line":0}},{"line":464,"address":[],"length":0,"stats":{"Line":0}},{"line":465,"address":[],"length":0,"stats":{"Line":0}},{"line":470,"address":[],"length":0,"stats":{"Line":1}},{"line":471,"address":[],"length":0,"stats":{"Line":1}},{"line":472,"address":[],"length":0,"stats":{"Line":1}},{"line":473,"address":[],"length":0,"stats":{"Line":1}},{"line":478,"address":[],"length":0,"stats":{"Line":0}},{"line":479,"address":[],"length":0,"stats":{"Line":0}},{"line":480,"address":[],"length":0,"stats":{"Line":0}},{"line":481,"address":[],"length":0,"stats":{"Line":0}},{"line":486,"address":[],"length":0,"stats":{"Line":0}},{"line":487,"address":[],"length":0,"stats":{"Line":0}},{"line":488,"address":[],"length":0,"stats":{"Line":0}},{"line":489,"address":[],"length":0,"stats":{"Line":0}},{"line":494,"address":[],"length":0,"stats":{"Line":0}},{"line":495,"address":[],"length":0,"stats":{"Line":0}},{"line":496,"address":[],"length":0,"stats":{"Line":0}},{"line":497,"address":[],"length":0,"stats":{"Line":0}},{"line":502,"address":[],"length":0,"stats":{"Line":0}},{"line":503,"address":[],"length":0,"stats":{"Line":0}},{"line":504,"address":[],"length":0,"stats":{"Line":0}},{"line":505,"address":[],"length":0,"stats":{"Line":0}},{"line":510,"address":[],"length":0,"stats":{"Line":0}},{"line":511,"address":[],"length":0,"stats":{"Line":0}},{"line":512,"address":[],"length":0,"stats":{"Line":0}},{"line":513,"address":[],"length":0,"stats":{"Line":0}},{"line":518,"address":[],"length":0,"stats":{"Line":2}},{"line":519,"address":[],"length":0,"stats":{"Line":2}},{"line":520,"address":[],"length":0,"stats":{"Line":2}},{"line":521,"address":[],"length":0,"stats":{"Line":2}},{"line":526,"address":[],"length":0,"stats":{"Line":0}},{"line":527,"address":[],"length":0,"stats":{"Line":0}},{"line":528,"address":[],"length":0,"stats":{"Line":0}},{"line":529,"address":[],"length":0,"stats":{"Line":0}},{"line":534,"address":[],"length":0,"stats":{"Line":1}},{"line":535,"address":[],"length":0,"stats":{"Line":3}},{"line":538,"address":[],"length":0,"stats":{"Line":2}},{"line":539,"address":[],"length":0,"stats":{"Line":2}},{"line":540,"address":[],"length":0,"stats":{"Line":2}},{"line":541,"address":[],"length":0,"stats":{"Line":2}},{"line":542,"address":[],"length":0,"stats":{"Line":2}},{"line":543,"address":[],"length":0,"stats":{"Line":2}},{"line":544,"address":[],"length":0,"stats":{"Line":2}},{"line":545,"address":[],"length":0,"stats":{"Line":2}},{"line":546,"address":[],"length":0,"stats":{"Line":2}},{"line":547,"address":[],"length":0,"stats":{"Line":2}},{"line":548,"address":[],"length":0,"stats":{"Line":2}},{"line":549,"address":[],"length":0,"stats":{"Line":2}},{"line":550,"address":[],"length":0,"stats":{"Line":2}},{"line":551,"address":[],"length":0,"stats":{"Line":1}},{"line":552,"address":[],"length":0,"stats":{"Line":1}},{"line":556,"address":[],"length":0,"stats":{"Line":1}},{"line":557,"address":[],"length":0,"stats":{"Line":0}},{"line":560,"address":[],"length":0,"stats":{"Line":1}},{"line":565,"address":[],"length":0,"stats":{"Line":2}},{"line":566,"address":[],"length":0,"stats":{"Line":3}},{"line":571,"address":[],"length":0,"stats":{"Line":2}},{"line":572,"address":[],"length":0,"stats":{"Line":4}},{"line":577,"address":[],"length":0,"stats":{"Line":1}},{"line":578,"address":[],"length":0,"stats":{"Line":2}},{"line":580,"address":[],"length":0,"stats":{"Line":2}},{"line":581,"address":[],"length":0,"stats":{"Line":1}},{"line":583,"address":[],"length":0,"stats":{"Line":2}},{"line":584,"address":[],"length":0,"stats":{"Line":2}},{"line":586,"address":[],"length":0,"stats":{"Line":2}},{"line":587,"address":[],"length":0,"stats":{"Line":2}},{"line":589,"address":[],"length":0,"stats":{"Line":1}},{"line":590,"address":[],"length":0,"stats":{"Line":0}},{"line":592,"address":[],"length":0,"stats":{"Line":1}},{"line":593,"address":[],"length":0,"stats":{"Line":0}},{"line":595,"address":[],"length":0,"stats":{"Line":2}},{"line":596,"address":[],"length":0,"stats":{"Line":2}},{"line":598,"address":[],"length":0,"stats":{"Line":2}},{"line":599,"address":[],"length":0,"stats":{"Line":2}},{"line":601,"address":[],"length":0,"stats":{"Line":1}},{"line":602,"address":[],"length":0,"stats":{"Line":0}},{"line":604,"address":[],"length":0,"stats":{"Line":2}},{"line":605,"address":[],"length":0,"stats":{"Line":2}},{"line":607,"address":[],"length":0,"stats":{"Line":2}},{"line":608,"address":[],"length":0,"stats":{"Line":2}},{"line":610,"address":[],"length":0,"stats":{"Line":2}},{"line":611,"address":[],"length":0,"stats":{"Line":2}},{"line":613,"address":[],"length":0,"stats":{"Line":2}},{"line":614,"address":[],"length":0,"stats":{"Line":2}},{"line":616,"address":[],"length":0,"stats":{"Line":1}},{"line":617,"address":[],"length":0,"stats":{"Line":0}},{"line":620,"address":[],"length":0,"stats":{"Line":3}},{"line":621,"address":[],"length":0,"stats":{"Line":1}},{"line":623,"address":[],"length":0,"stats":{"Line":1}},{"line":626,"address":[],"length":0,"stats":{"Line":1}},{"line":627,"address":[],"length":0,"stats":{"Line":0}},{"line":630,"address":[],"length":0,"stats":{"Line":2}},{"line":631,"address":[],"length":0,"stats":{"Line":0}},{"line":633,"address":[],"length":0,"stats":{"Line":2}},{"line":639,"address":[],"length":0,"stats":{"Line":1}},{"line":640,"address":[],"length":0,"stats":{"Line":2}},{"line":641,"address":[],"length":0,"stats":{"Line":1}},{"line":642,"address":[],"length":0,"stats":{"Line":1}},{"line":643,"address":[],"length":0,"stats":{"Line":1}},{"line":644,"address":[],"length":0,"stats":{"Line":1}},{"line":645,"address":[],"length":0,"stats":{"Line":1}},{"line":646,"address":[],"length":0,"stats":{"Line":1}},{"line":647,"address":[],"length":0,"stats":{"Line":1}},{"line":648,"address":[],"length":0,"stats":{"Line":1}},{"line":649,"address":[],"length":0,"stats":{"Line":1}},{"line":650,"address":[],"length":0,"stats":{"Line":1}},{"line":651,"address":[],"length":0,"stats":{"Line":1}},{"line":652,"address":[],"length":0,"stats":{"Line":1}},{"line":653,"address":[],"length":0,"stats":{"Line":1}},{"line":658,"address":[],"length":0,"stats":{"Line":2}},{"line":659,"address":[],"length":0,"stats":{"Line":1}},{"line":679,"address":[],"length":0,"stats":{"Line":5}},{"line":680,"address":[],"length":0,"stats":{"Line":10}},{"line":681,"address":[],"length":0,"stats":{"Line":15}},{"line":682,"address":[],"length":0,"stats":{"Line":0}},{"line":685,"address":[],"length":0,"stats":{"Line":17}},{"line":686,"address":[],"length":0,"stats":{"Line":9}},{"line":689,"address":[],"length":0,"stats":{"Line":5}},{"line":704,"address":[],"length":0,"stats":{"Line":34}},{"line":705,"address":[],"length":0,"stats":{"Line":68}},{"line":708,"address":[],"length":0,"stats":{"Line":34}},{"line":709,"address":[],"length":0,"stats":{"Line":0}},{"line":710,"address":[],"length":0,"stats":{"Line":0}},{"line":715,"address":[],"length":0,"stats":{"Line":34}},{"line":716,"address":[],"length":0,"stats":{"Line":0}},{"line":720,"address":[],"length":0,"stats":{"Line":68}},{"line":721,"address":[],"length":0,"stats":{"Line":68}},{"line":722,"address":[],"length":0,"stats":{"Line":68}},{"line":723,"address":[],"length":0,"stats":{"Line":68}},{"line":724,"address":[],"length":0,"stats":{"Line":68}},{"line":725,"address":[],"length":0,"stats":{"Line":68}},{"line":726,"address":[],"length":0,"stats":{"Line":68}},{"line":727,"address":[],"length":0,"stats":{"Line":68}},{"line":728,"address":[],"length":0,"stats":{"Line":68}},{"line":729,"address":[],"length":0,"stats":{"Line":68}},{"line":730,"address":[],"length":0,"stats":{"Line":68}},{"line":731,"address":[],"length":0,"stats":{"Line":68}},{"line":732,"address":[],"length":0,"stats":{"Line":68}},{"line":733,"address":[],"length":0,"stats":{"Line":34}},{"line":736,"address":[],"length":0,"stats":{"Line":1360}},{"line":737,"address":[],"length":0,"stats":{"Line":442}},{"line":738,"address":[],"length":0,"stats":{"Line":0}},{"line":739,"address":[],"length":0,"stats":{"Line":0}},{"line":743,"address":[],"length":0,"stats":{"Line":34}}],"covered":177,"coverable":250},{"path":["/","Users","christian.klat","dev","git","aeterna","mk_core","src","lib.rs"],"content":"//! # Memory-Knowledge System Core\n//!\n//! Shared types, traits, and utilities for the Memory-Knowledge system.\n//!\n//! This crate provides:\n//! - Type definitions for memory and knowledge systems\n//! - Core traits for adapters and providers\n//! - Error types with proper handling\n//! - Validation utilities\n//! - Operation hints for capability toggles\n//!\n//! # Best Practices\n//!\n//! - Follows Microsoft Pragmatic Rust Guidelines\n//! - Uses Rust Edition 2024 (never back)\n//! - Comprehensive error handling with `thiserror`\n//! - M-CANONICAL-DOCS documentation format\n\npub mod hints;\npub mod traits;\npub mod types;\n\n// Re-export commonly used types for convenience\npub use hints::{HintPreset, HintsConfig, OperationHints};\npub use types::{\n    ConstraintOperator, ConstraintSeverity, ConstraintTarget, HierarchyPath, KnowledgeLayer,\n    KnowledgeType, MemoryLayer, TenantContext, TenantId, UserId,\n};\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","mk_core","src","traits.rs"],"content":"//! Core traits for memory-knowledge system\n\nuse async_trait::async_trait;\nuse serde::{Deserialize, Serialize};\n\n/// Storage backend trait for extensible storage implementations\n#[async_trait]\npub trait StorageBackend: Send + Sync {\n    type Error;\n\n    async fn store(\n        &self,\n        ctx: crate::types::TenantContext,\n        key: &str,\n        value: &[u8],\n    ) -> Result<(), Self::Error>;\n\n    async fn retrieve(\n        &self,\n        ctx: crate::types::TenantContext,\n        key: &str,\n    ) -> Result<Option<Vec<u8>>, Self::Error>;\n\n    async fn delete(&self, ctx: crate::types::TenantContext, key: &str) -> Result<(), Self::Error>;\n\n    async fn exists(\n        &self,\n        ctx: crate::types::TenantContext,\n        key: &str,\n    ) -> Result<bool, Self::Error>;\n\n    async fn get_ancestors(\n        &self,\n        ctx: crate::types::TenantContext,\n        unit_id: &str,\n    ) -> Result<Vec<crate::types::OrganizationalUnit>, Self::Error>;\n\n    async fn get_descendants(\n        &self,\n        ctx: crate::types::TenantContext,\n        unit_id: &str,\n    ) -> Result<Vec<crate::types::OrganizationalUnit>, Self::Error>;\n\n    async fn get_unit_policies(\n        &self,\n        ctx: crate::types::TenantContext,\n        unit_id: &str,\n    ) -> Result<Vec<crate::types::Policy>, Self::Error>;\n\n    async fn create_unit(&self, unit: &crate::types::OrganizationalUnit)\n    -> Result<(), Self::Error>;\n\n    async fn add_unit_policy(\n        &self,\n        ctx: &crate::types::TenantContext,\n        unit_id: &str,\n        policy: &crate::types::Policy,\n    ) -> Result<(), Self::Error>;\n\n    async fn assign_role(\n        &self,\n        user_id: &crate::types::UserId,\n        tenant_id: &crate::types::TenantId,\n        unit_id: &str,\n        role: crate::types::Role,\n    ) -> Result<(), Self::Error>;\n\n    async fn remove_role(\n        &self,\n        user_id: &crate::types::UserId,\n        tenant_id: &crate::types::TenantId,\n        unit_id: &str,\n        role: crate::types::Role,\n    ) -> Result<(), Self::Error>;\n\n    async fn store_drift_result(\n        &self,\n        result: crate::types::DriftResult,\n    ) -> Result<(), Self::Error>;\n\n    async fn get_latest_drift_result(\n        &self,\n        ctx: crate::types::TenantContext,\n        project_id: &str,\n    ) -> Result<Option<crate::types::DriftResult>, Self::Error>;\n\n    async fn list_all_units(&self) -> Result<Vec<crate::types::OrganizationalUnit>, Self::Error>;\n    async fn record_job_status(\n        &self,\n        job_name: &str,\n        tenant_id: &str,\n        status: &str,\n        message: Option<&str>,\n        started_at: i64,\n        finished_at: Option<i64>,\n    ) -> Result<(), Self::Error>;\n\n    async fn get_governance_events(\n        &self,\n        ctx: crate::types::TenantContext,\n        since_timestamp: i64,\n        limit: usize,\n    ) -> Result<Vec<crate::types::GovernanceEvent>, Self::Error>;\n\n    async fn create_suppression(\n        &self,\n        suppression: crate::types::DriftSuppression,\n    ) -> Result<(), Self::Error>;\n\n    async fn list_suppressions(\n        &self,\n        ctx: crate::types::TenantContext,\n        project_id: &str,\n    ) -> Result<Vec<crate::types::DriftSuppression>, Self::Error>;\n\n    async fn delete_suppression(\n        &self,\n        ctx: crate::types::TenantContext,\n        suppression_id: &str,\n    ) -> Result<(), Self::Error>;\n\n    async fn get_drift_config(\n        &self,\n        ctx: crate::types::TenantContext,\n        project_id: &str,\n    ) -> Result<Option<crate::types::DriftConfig>, Self::Error>;\n\n    async fn save_drift_config(&self, config: crate::types::DriftConfig)\n    -> Result<(), Self::Error>;\n\n    async fn persist_event(&self, event: crate::types::PersistentEvent) -> Result<(), Self::Error>;\n\n    async fn get_pending_events(\n        &self,\n        ctx: crate::types::TenantContext,\n        limit: usize,\n    ) -> Result<Vec<crate::types::PersistentEvent>, Self::Error>;\n\n    async fn update_event_status(\n        &self,\n        event_id: &str,\n        status: crate::types::EventStatus,\n        error: Option<String>,\n    ) -> Result<(), Self::Error>;\n\n    async fn get_dead_letter_events(\n        &self,\n        ctx: crate::types::TenantContext,\n        limit: usize,\n    ) -> Result<Vec<crate::types::PersistentEvent>, Self::Error>;\n\n    async fn check_idempotency(\n        &self,\n        consumer_group: &str,\n        idempotency_key: &str,\n    ) -> Result<bool, Self::Error>;\n\n    async fn record_consumer_state(\n        &self,\n        state: crate::types::ConsumerState,\n    ) -> Result<(), Self::Error>;\n\n    async fn get_event_metrics(\n        &self,\n        ctx: crate::types::TenantContext,\n        period_start: i64,\n        period_end: i64,\n    ) -> Result<Vec<crate::types::EventDeliveryMetrics>, Self::Error>;\n\n    async fn record_event_metrics(\n        &self,\n        metrics: crate::types::EventDeliveryMetrics,\n    ) -> Result<(), Self::Error>;\n}\n\n/// Health check capability for service monitoring\npub trait HealthCheck: Send + Sync {\n    fn health_check(&self) -> Result<HealthStatus, Box<dyn std::error::Error + Send + Sync>>;\n}\n\n/// Health status for service monitoring\n#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]\npub enum HealthStatus {\n    Healthy,\n    Degraded,\n    Unhealthy,\n}\n\n#[async_trait]\npub trait MemoryProviderAdapter: Send + Sync {\n    type Error;\n\n    async fn add(\n        &self,\n        ctx: crate::types::TenantContext,\n        entry: crate::types::MemoryEntry,\n    ) -> Result<String, Self::Error>;\n\n    async fn search(\n        &self,\n        ctx: crate::types::TenantContext,\n        query_vector: Vec<f32>,\n        limit: usize,\n        filters: std::collections::HashMap<String, serde_json::Value>,\n    ) -> Result<Vec<crate::types::MemoryEntry>, Self::Error>;\n\n    async fn get(\n        &self,\n        ctx: crate::types::TenantContext,\n        id: &str,\n    ) -> Result<Option<crate::types::MemoryEntry>, Self::Error>;\n\n    async fn update(\n        &self,\n        ctx: crate::types::TenantContext,\n        entry: crate::types::MemoryEntry,\n    ) -> Result<(), Self::Error>;\n\n    async fn delete(&self, ctx: crate::types::TenantContext, id: &str) -> Result<(), Self::Error>;\n\n    async fn list(\n        &self,\n        ctx: crate::types::TenantContext,\n        layer: crate::types::MemoryLayer,\n        limit: usize,\n        cursor: Option<String>,\n    ) -> Result<(Vec<crate::types::MemoryEntry>, Option<String>), Self::Error>;\n}\n\n#[async_trait]\npub trait KnowledgeRepository: Send + Sync {\n    type Error;\n\n    async fn get(\n        &self,\n        ctx: crate::types::TenantContext,\n        layer: crate::types::KnowledgeLayer,\n        path: &str,\n    ) -> Result<Option<crate::types::KnowledgeEntry>, Self::Error>;\n\n    async fn store(\n        &self,\n        ctx: crate::types::TenantContext,\n        entry: crate::types::KnowledgeEntry,\n        message: &str,\n    ) -> Result<String, Self::Error>;\n\n    async fn list(\n        &self,\n        ctx: crate::types::TenantContext,\n        layer: crate::types::KnowledgeLayer,\n        prefix: &str,\n    ) -> Result<Vec<crate::types::KnowledgeEntry>, Self::Error>;\n\n    async fn delete(\n        &self,\n        ctx: crate::types::TenantContext,\n        layer: crate::types::KnowledgeLayer,\n        path: &str,\n        message: &str,\n    ) -> Result<String, Self::Error>;\n\n    async fn get_head_commit(\n        &self,\n        ctx: crate::types::TenantContext,\n    ) -> Result<Option<String>, Self::Error>;\n\n    async fn get_affected_items(\n        &self,\n        ctx: crate::types::TenantContext,\n        since_commit: &str,\n    ) -> Result<Vec<(crate::types::KnowledgeLayer, String)>, Self::Error>;\n\n    async fn search(\n        &self,\n        ctx: crate::types::TenantContext,\n        query: &str,\n        layers: Vec<crate::types::KnowledgeLayer>,\n        limit: usize,\n    ) -> Result<Vec<crate::types::KnowledgeEntry>, Self::Error>;\n\n    fn root_path(&self) -> Option<std::path::PathBuf>;\n}\n\n#[async_trait]\npub trait AuthorizationService: Send + Sync {\n    type Error;\n\n    async fn check_permission(\n        &self,\n        ctx: &crate::types::TenantContext,\n        action: &str,\n        resource: &str,\n    ) -> Result<bool, Self::Error>;\n\n    async fn get_user_roles(\n        &self,\n        ctx: &crate::types::TenantContext,\n    ) -> Result<Vec<crate::types::Role>, Self::Error>;\n\n    async fn assign_role(\n        &self,\n        ctx: &crate::types::TenantContext,\n        user_id: &crate::types::UserId,\n        role: crate::types::Role,\n    ) -> Result<(), Self::Error>;\n\n    async fn remove_role(\n        &self,\n        ctx: &crate::types::TenantContext,\n        user_id: &crate::types::UserId,\n        role: crate::types::Role,\n    ) -> Result<(), Self::Error>;\n}\n\n#[async_trait]\npub trait ContextHooks: Send + Sync {\n    async fn on_session_start(\n        &self,\n        ctx: crate::types::TenantContext,\n        session_id: &str,\n    ) -> anyhow::Result<()>;\n    async fn on_session_end(\n        &self,\n        ctx: crate::types::TenantContext,\n        session_id: &str,\n    ) -> anyhow::Result<()>;\n    async fn on_message(\n        &self,\n        ctx: crate::types::TenantContext,\n        session_id: &str,\n        message: &str,\n    ) -> anyhow::Result<()>;\n    async fn on_tool_use(\n        &self,\n        ctx: crate::types::TenantContext,\n        session_id: &str,\n        tool_name: &str,\n        params: serde_json::Value,\n    ) -> anyhow::Result<()>;\n}\n\n#[async_trait]\npub trait EmbeddingService: Send + Sync {\n    type Error;\n\n    async fn embed(&self, text: &str) -> Result<Vec<f32>, Self::Error>;\n\n    fn dimension(&self) -> usize;\n\n    async fn embed_batch(&self, texts: &[String]) -> Result<Vec<Vec<f32>>, Self::Error> {\n        let mut results = Vec::with_capacity(texts.len());\n        for text in texts {\n            results.push(self.embed(text).await?);\n        }\n        Ok(results)\n    }\n}\n\n#[async_trait]\npub trait EventPublisher: Send + Sync {\n    type Error;\n\n    async fn publish(&self, event: crate::types::GovernanceEvent) -> Result<(), Self::Error>;\n\n    async fn subscribe(\n        &self,\n        channels: &[&str],\n    ) -> Result<tokio::sync::mpsc::Receiver<crate::types::GovernanceEvent>, Self::Error>;\n}\n\n/// LLM service trait for text generation and reasoning\n#[async_trait]\npub trait LlmService: Send + Sync {\n    type Error;\n\n    /// Generates text based on a prompt\n    async fn generate(&self, prompt: &str) -> Result<String, Self::Error>;\n\n    /// Analyzes content against a set of policies\n    async fn analyze_drift(\n        &self,\n        content: &str,\n        policies: &[crate::types::Policy],\n    ) -> Result<crate::types::ValidationResult, Self::Error>;\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    struct TestEmbeddingService;\n\n    #[async_trait]\n    impl EmbeddingService for TestEmbeddingService {\n        type Error = Box<dyn std::error::Error + Send + Sync>;\n\n        async fn embed(&self, text: &str) -> Result<Vec<f32>, Self::Error> {\n            Ok(vec![text.len() as f32; 128])\n        }\n\n        fn dimension(&self) -> usize {\n            128\n        }\n    }\n\n    #[tokio::test]\n    async fn test_embedding_service_default_embed_batch() {\n        let service = TestEmbeddingService;\n\n        let texts = vec![\n            \"short\".to_string(),\n            \"medium text\".to_string(),\n            \"this is a longer text\".to_string(),\n        ];\n\n        let embeddings = service.embed_batch(&texts).await.unwrap();\n\n        assert_eq!(embeddings.len(), 3);\n        assert_eq!(embeddings[0].len(), 128);\n        assert_eq!(embeddings[1].len(), 128);\n        assert_eq!(embeddings[2].len(), 128);\n\n        assert_eq!(embeddings[0][0], 5.0);\n        assert_eq!(embeddings[1][0], 11.0);\n        assert_eq!(embeddings[2][0], 21.0);\n    }\n\n    #[tokio::test]\n    async fn test_embedding_service_dimension() {\n        let service = TestEmbeddingService;\n        assert_eq!(service.dimension(), 128);\n    }\n\n    #[tokio::test]\n    async fn test_embedding_service_embed_batch_empty() {\n        let service = TestEmbeddingService;\n        let texts: Vec<String> = vec![];\n        let embeddings = service.embed_batch(&texts).await.unwrap();\n        assert!(embeddings.is_empty());\n    }\n\n    #[test]\n    fn test_health_status_derive() {\n        let healthy = HealthStatus::Healthy;\n        let degraded = HealthStatus::Degraded;\n        let unhealthy = HealthStatus::Unhealthy;\n\n        assert_eq!(healthy.clone(), HealthStatus::Healthy);\n        assert_ne!(healthy, degraded);\n        assert_ne!(degraded, unhealthy);\n\n        let json = serde_json::to_string(&healthy).unwrap();\n        assert!(json.contains(\"Healthy\"));\n    }\n}\n","traces":[{"line":351,"address":[],"length":0,"stats":{"Line":3}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":353,"address":[],"length":0,"stats":{"Line":0}},{"line":354,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":0}}],"covered":1,"coverable":5},{"path":["/","Users","christian.klat","dev","git","aeterna","mk_core","src","types.rs"],"content":"use schemars::JsonSchema;\nuse serde::{Deserialize, Serialize};\nuse strum::{Display, EnumString};\nuse utoipa::ToSchema;\nuse validator::Validate;\n\n#[derive(\n    Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize, ToSchema, EnumString, Display,\n)]\n#[serde(rename_all = \"camelCase\")]\n#[strum(ascii_case_insensitive)]\npub enum Role {\n    Developer,\n    TechLead,\n    Architect,\n    Admin,\n    Agent,\n}\n\n#[derive(\n    Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, ToSchema, EnumString, Display,\n)]\n#[serde(rename_all = \"camelCase\")]\n#[strum(serialize_all = \"camelCase\")]\npub enum UnitType {\n    Company,\n    Organization,\n    Team,\n    Project,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct OrganizationalUnit {\n    pub id: String,\n    pub name: String,\n    pub unit_type: UnitType,\n    pub parent_id: Option<String>,\n    pub tenant_id: TenantId,\n    pub metadata: std::collections::HashMap<String, serde_json::Value>,\n    pub created_at: i64,\n    pub updated_at: i64,\n}\n\n#[derive(\n    Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize, ToSchema, JsonSchema, PartialOrd, Ord,\n)]\n#[serde(transparent)]\npub struct TenantId(String);\n\nimpl TenantId {\n    pub fn new(id: String) -> Option<Self> {\n        if id.is_empty() || id.len() > 100 {\n            None\n        } else {\n            Some(Self(id))\n        }\n    }\n\n    pub fn as_str(&self) -> &str {\n        &self.0\n    }\n\n    pub fn into_inner(self) -> String {\n        self.0\n    }\n}\n\nimpl std::fmt::Display for TenantId {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"{}\", self.0)\n    }\n}\n\nimpl Default for TenantId {\n    fn default() -> Self {\n        Self(\"default\".to_string())\n    }\n}\n\nimpl std::str::FromStr for TenantId {\n    type Err = anyhow::Error;\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        Self::new(s.to_string()).ok_or_else(|| anyhow::anyhow!(\"Invalid tenant ID\"))\n    }\n}\n\nimpl Default for TenantContext {\n    fn default() -> Self {\n        Self {\n            tenant_id: TenantId::default(),\n            user_id: UserId::default(),\n            agent_id: None,\n        }\n    }\n}\n\n#[derive(\n    Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize, ToSchema, JsonSchema, PartialOrd, Ord,\n)]\n#[serde(transparent)]\npub struct UserId(String);\n\nimpl UserId {\n    pub fn new(id: String) -> Option<Self> {\n        if id.is_empty() || id.len() > 100 {\n            None\n        } else {\n            Some(Self(id))\n        }\n    }\n\n    pub fn as_str(&self) -> &str {\n        &self.0\n    }\n\n    pub fn into_inner(self) -> String {\n        self.0\n    }\n}\n\nimpl std::fmt::Display for UserId {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"{}\", self.0)\n    }\n}\n\nimpl std::str::FromStr for UserId {\n    type Err = anyhow::Error;\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        Self::new(s.to_string()).ok_or_else(|| anyhow::anyhow!(\"Invalid user ID\"))\n    }\n}\n\nimpl Default for UserId {\n    fn default() -> Self {\n        Self(\"default\".to_string())\n    }\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\npub struct TenantContext {\n    pub tenant_id: TenantId,\n    pub user_id: UserId,\n    pub agent_id: Option<String>,\n}\n\nimpl TenantContext {\n    pub fn new(tenant_id: TenantId, user_id: UserId) -> Self {\n        Self {\n            tenant_id,\n            user_id,\n            agent_id: None,\n        }\n    }\n\n    pub fn with_agent(tenant_id: TenantId, user_id: UserId, agent_id: String) -> Self {\n        Self {\n            tenant_id,\n            user_id,\n            agent_id: Some(agent_id),\n        }\n    }\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\npub struct HierarchyPath {\n    pub company: String,\n    pub org: Option<String>,\n    pub team: Option<String>,\n    pub project: Option<String>,\n}\n\nimpl HierarchyPath {\n    pub fn company(id: String) -> Self {\n        Self {\n            company: id,\n            org: None,\n            team: None,\n            project: None,\n        }\n    }\n\n    pub fn org(company: String, id: String) -> Self {\n        Self {\n            company,\n            org: Some(id),\n            team: None,\n            project: None,\n        }\n    }\n\n    pub fn team(company: String, org: String, id: String) -> Self {\n        Self {\n            company,\n            org: Some(org),\n            team: Some(id),\n            project: None,\n        }\n    }\n\n    pub fn project(company: String, org: String, team: String, id: String) -> Self {\n        Self {\n            company,\n            org: Some(org),\n            team: Some(team),\n            project: Some(id),\n        }\n    }\n\n    pub fn depth(&self) -> usize {\n        if self.project.is_some() {\n            4\n        } else if self.team.is_some() {\n            3\n        } else if self.org.is_some() {\n            2\n        } else {\n            1\n        }\n    }\n\n    pub fn path_string(&self) -> String {\n        let mut parts = vec![self.company.clone()];\n        if let Some(o) = &self.org {\n            parts.push(o.clone());\n        }\n        if let Some(t) = &self.team {\n            parts.push(t.clone());\n        }\n        if let Some(p) = &self.project {\n            parts.push(p.clone());\n        }\n        parts.join(\" > \")\n    }\n}\n\nimpl Role {\n    #[must_use]\n    pub fn precedence(&self) -> u8 {\n        match self {\n            Role::Admin => 4,\n            Role::Architect => 3,\n            Role::TechLead => 2,\n            Role::Developer => 1,\n            Role::Agent => 0,\n        }\n    }\n\n    #[must_use]\n    pub fn display_name(&self) -> &'static str {\n        match self {\n            Role::Developer => \"Developer\",\n            Role::TechLead => \"Tech Lead\",\n            Role::Architect => \"Architect\",\n            Role::Admin => \"Admin\",\n            Role::Agent => \"Agent\",\n        }\n    }\n}\n\n/// Knowledge types\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub enum KnowledgeType {\n    Adr,\n    Policy,\n    Pattern,\n    Spec,\n    Hindsight,\n}\n\n/// Knowledge status\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub enum KnowledgeStatus {\n    Draft,\n    Proposed,\n    Accepted,\n    Deprecated,\n    Superseded,\n}\n\n#[derive(\n    Debug,\n    Clone,\n    Copy,\n    PartialEq,\n    Eq,\n    Hash,\n    Serialize,\n    Deserialize,\n    ToSchema,\n    PartialOrd,\n    Ord,\n    JsonSchema,\n)]\n#[serde(rename_all = \"camelCase\")]\npub enum KnowledgeLayer {\n    Company,\n    Org,\n    Team,\n    Project,\n}\n\n/// Constraint severity levels\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub enum ConstraintSeverity {\n    Info,\n    Warn,\n    Block,\n}\n\n/// Constraint operators\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub enum ConstraintOperator {\n    MustUse,\n    MustNotUse,\n    MustMatch,\n    MustNotMatch,\n    MustExist,\n    MustNotExist,\n}\n\n/// Constraint targets\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub enum ConstraintTarget {\n    File,\n    Code,\n    Dependency,\n    Import,\n    Config,\n}\n\n/// Memory layers for hierarchical storage\n#[derive(\n    Debug,\n    Clone,\n    Copy,\n    PartialEq,\n    Eq,\n    Hash,\n    Serialize,\n    Deserialize,\n    JsonSchema,\n    strum::EnumString,\n    strum::Display,\n    ToSchema,\n)]\n#[serde(rename_all = \"camelCase\")]\npub enum MemoryLayer {\n    Agent,\n    User,\n    Session,\n    Project,\n    Team,\n    Org,\n    Company,\n}\n\nimpl MemoryLayer {\n    #[must_use]\n    pub fn precedence(&self) -> u8 {\n        match self {\n            MemoryLayer::Agent => 1,\n            MemoryLayer::User => 2,\n            MemoryLayer::Session => 3,\n            MemoryLayer::Project => 4,\n            MemoryLayer::Team => 5,\n            MemoryLayer::Org => 6,\n            MemoryLayer::Company => 7,\n        }\n    }\n\n    #[must_use]\n    pub fn display_name(&self) -> &'static str {\n        match self {\n            MemoryLayer::Agent => \"Agent\",\n            MemoryLayer::User => \"User\",\n            MemoryLayer::Session => \"Session\",\n            MemoryLayer::Project => \"Project\",\n            MemoryLayer::Team => \"Team\",\n            MemoryLayer::Org => \"Organization\",\n            MemoryLayer::Company => \"Company\",\n        }\n    }\n}\n\n#[derive(\n    Debug, Clone, PartialEq, Serialize, Deserialize, JsonSchema, Validate, Default, ToSchema,\n)]\n#[serde(rename_all = \"camelCase\")]\npub struct LayerIdentifiers {\n    #[validate(custom(function = \"validate_agent_id\"))]\n    pub agent_id: Option<String>,\n    #[validate(custom(function = \"validate_user_id\"))]\n    pub user_id: Option<String>,\n    #[validate(custom(function = \"validate_session_id\"))]\n    pub session_id: Option<String>,\n    #[validate(custom(function = \"validate_project_id\"))]\n    pub project_id: Option<String>,\n    #[validate(custom(function = \"validate_team_id\"))]\n    pub team_id: Option<String>,\n    #[validate(custom(function = \"validate_org_id\"))]\n    pub org_id: Option<String>,\n    #[validate(custom(function = \"validate_company_id\"))]\n    pub company_id: Option<String>,\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub enum SummaryDepth {\n    Sentence,\n    Paragraph,\n    Detailed,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct LayerSummary {\n    pub depth: SummaryDepth,\n    pub content: String,\n    pub token_count: u32,\n    pub generated_at: i64,\n    pub source_hash: String,\n    pub content_hash: Option<String>,\n    pub personalized: bool,\n    pub personalization_context: Option<String>,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct SummaryConfig {\n    pub layer: MemoryLayer,\n    pub update_interval_secs: Option<u64>,\n    pub update_on_changes: Option<u32>,\n    pub skip_if_unchanged: bool,\n    pub personalized: bool,\n    pub depths: Vec<SummaryDepth>,\n}\n\npub type ContextVector = Vec<f32>;\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct ErrorSignature {\n    pub error_type: String,\n    pub message_pattern: String,\n    pub stack_patterns: Vec<String>,\n    pub context_patterns: Vec<String>,\n    pub embedding: Option<Vec<f32>>,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct CodeChange {\n    pub file_path: String,\n    pub diff: String,\n    pub description: Option<String>,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct Resolution {\n    pub id: String,\n    pub error_signature_id: String,\n    pub description: String,\n    pub changes: Vec<CodeChange>,\n    pub success_rate: f32,\n    pub application_count: u32,\n    pub last_success_at: i64,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct HindsightNote {\n    pub id: String,\n    pub error_signature: ErrorSignature,\n    pub resolutions: Vec<Resolution>,\n    pub content: String,\n    pub tags: Vec<String>,\n    pub created_at: i64,\n    pub updated_at: i64,\n}\n\n#[derive(\n    Debug,\n    Clone,\n    Copy,\n    PartialEq,\n    Eq,\n    Hash,\n    Serialize,\n    Deserialize,\n    JsonSchema,\n    ToSchema,\n    Display,\n    EnumString,\n)]\n#[serde(rename_all = \"camelCase\")]\n#[strum(serialize_all = \"camelCase\")]\npub enum ReasoningStrategy {\n    Exhaustive,\n    Targeted,\n    SemanticOnly,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct ReasoningTrace {\n    pub strategy: ReasoningStrategy,\n    pub thought_process: String,\n    pub refined_query: Option<String>,\n    pub start_time: chrono::DateTime<chrono::Utc>,\n    pub end_time: chrono::DateTime<chrono::Utc>,\n    /// Indicates if reasoning was interrupted by timeout (partial results may be available)\n    #[serde(default)]\n    pub timed_out: bool,\n    /// Duration of the reasoning step in milliseconds\n    #[serde(default)]\n    pub duration_ms: u64,\n    pub metadata: std::collections::HashMap<String, serde_json::Value>,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct MemoryEntry {\n    pub id: String,\n    pub content: String,\n    pub embedding: Option<Vec<f32>>,\n    pub layer: MemoryLayer,\n    pub summaries: std::collections::HashMap<SummaryDepth, LayerSummary>,\n    pub context_vector: Option<ContextVector>,\n    pub importance_score: Option<f32>,\n    pub metadata: std::collections::HashMap<String, serde_json::Value>,\n    pub created_at: i64,\n    pub updated_at: i64,\n}\n\nimpl MemoryEntry {\n    pub fn needs_summary_update(&self, config: &SummaryConfig, current_time: i64) -> bool {\n        use sha2::{Digest, Sha256};\n\n        for depth in &config.depths {\n            if let Some(summary) = self.summaries.get(depth) {\n                let content_hash = hex::encode(Sha256::digest(self.content.as_bytes()));\n                let content_changed = summary.source_hash != content_hash;\n\n                if content_changed {\n                    return true;\n                }\n\n                if config.skip_if_unchanged {\n                    continue;\n                }\n\n                if let Some(interval_secs) = config.update_interval_secs {\n                    let elapsed = current_time - summary.generated_at;\n                    if elapsed >= interval_secs as i64 {\n                        return true;\n                    }\n                }\n            } else {\n                return true;\n            }\n        }\n        false\n    }\n\n    pub fn compute_content_hash(&self) -> String {\n        use sha2::{Digest, Sha256};\n        hex::encode(Sha256::digest(self.content.as_bytes()))\n    }\n\n    pub fn compute_content_hash_xxh64(&self) -> String {\n        compute_xxhash64(self.content.as_bytes())\n    }\n}\n\npub fn compute_xxhash64(data: &[u8]) -> String {\n    use xxhash_rust::xxh64::xxh64;\n    format!(\"{:016x}\", xxh64(data, 0))\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub enum MemoryOperation {\n    Add,\n    Update,\n    Delete,\n    Retrieve,\n    Prune,\n    Compress,\n    Noop,\n}\n\n#[derive(\n    Debug,\n    Clone,\n    Copy,\n    PartialEq,\n    Eq,\n    Hash,\n    Serialize,\n    Deserialize,\n    JsonSchema,\n    ToSchema,\n    Display,\n    EnumString,\n)]\n#[serde(rename_all = \"camelCase\")]\n#[strum(serialize_all = \"camelCase\")]\npub enum RewardType {\n    Helpful,\n    Irrelevant,\n    Outdated,\n    Inaccurate,\n    Duplicate,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct RewardSignal {\n    pub reward_type: RewardType,\n    pub score: f32, // -1.0 to 1.0\n    pub reasoning: Option<String>,\n    pub agent_id: Option<String>,\n    pub timestamp: i64,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct MemoryTrajectoryEvent {\n    pub operation: MemoryOperation,\n    pub entry_id: String,\n    pub reward: Option<RewardSignal>,\n    pub reasoning: Option<String>,\n    pub timestamp: i64,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct Entity {\n    pub id: String,\n    pub name: String,\n    pub entity_type: String,\n    pub description: Option<String>,\n    pub embedding: Option<Vec<f32>>,\n    pub metadata: std::collections::HashMap<String, serde_json::Value>,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct Relationship {\n    pub id: String,\n    pub source_id: String,\n    pub target_id: String,\n    pub relation_type: String,\n    pub weight: f32,\n    pub description: Option<String>,\n    pub metadata: std::collections::HashMap<String, serde_json::Value>,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct Community {\n    pub id: String,\n    pub name: String,\n    pub summary: String,\n    pub level: u32,\n    pub entity_ids: Vec<String>,\n    pub relationship_ids: Vec<String>,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct KnowledgeEntry {\n    pub path: String,\n    pub content: String,\n    pub layer: KnowledgeLayer,\n    pub kind: KnowledgeType,\n    pub status: KnowledgeStatus,\n    pub summaries: std::collections::HashMap<SummaryDepth, LayerSummary>,\n    pub metadata: std::collections::HashMap<String, serde_json::Value>,\n    pub commit_hash: Option<String>,\n    pub author: Option<String>,\n    pub updated_at: i64,\n}\n\n#[derive(\n    Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, JsonSchema, Default, ToSchema,\n)]\n#[serde(rename_all = \"camelCase\")]\npub enum PolicyMode {\n    #[default]\n    Optional,\n    Mandatory,\n}\n\n#[derive(\n    Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, JsonSchema, Default, ToSchema,\n)]\n#[serde(rename_all = \"camelCase\")]\npub enum RuleMergeStrategy {\n    #[default]\n    Override,\n    Merge,\n    Intersect,\n}\n\n#[derive(\n    Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, JsonSchema, Default, ToSchema,\n)]\n#[serde(rename_all = \"camelCase\")]\npub enum RuleType {\n    #[default]\n    Allow,\n    Deny,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct Policy {\n    pub id: String,\n    pub name: String,\n    pub description: Option<String>,\n    pub layer: KnowledgeLayer,\n    #[serde(default)]\n    pub mode: PolicyMode,\n    #[serde(default)]\n    pub merge_strategy: RuleMergeStrategy,\n    pub rules: Vec<PolicyRule>,\n    pub metadata: std::collections::HashMap<String, serde_json::Value>,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct PolicyRule {\n    pub id: String,\n    #[serde(default)]\n    pub rule_type: RuleType,\n    pub target: ConstraintTarget,\n    pub operator: ConstraintOperator,\n    pub value: serde_json::Value,\n    pub severity: ConstraintSeverity,\n    pub message: String,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct ValidationResult {\n    pub is_valid: bool,\n    pub violations: Vec<PolicyViolation>,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct PolicyViolation {\n    pub rule_id: String,\n    pub policy_id: String,\n    pub severity: ConstraintSeverity,\n    pub message: String,\n    pub context: std::collections::HashMap<String, serde_json::Value>,\n}\n\n/// Governance event types for auditing and real-time updates\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub enum GovernanceEvent {\n    /// New organizational unit created\n    UnitCreated {\n        unit_id: String,\n        unit_type: UnitType,\n        tenant_id: TenantId,\n        parent_id: Option<String>,\n        timestamp: i64,\n    },\n\n    /// Organizational unit updated\n    UnitUpdated {\n        unit_id: String,\n        tenant_id: TenantId,\n        timestamp: i64,\n    },\n\n    /// Organizational unit deleted\n    UnitDeleted {\n        unit_id: String,\n        tenant_id: TenantId,\n        timestamp: i64,\n    },\n\n    /// Role assigned to a user for a specific unit\n    RoleAssigned {\n        user_id: UserId,\n        unit_id: String,\n        role: Role,\n        tenant_id: TenantId,\n        timestamp: i64,\n    },\n\n    /// Role removed from a user\n    RoleRemoved {\n        user_id: UserId,\n        unit_id: String,\n        role: Role,\n        tenant_id: TenantId,\n        timestamp: i64,\n    },\n\n    /// Policy created or updated\n    PolicyUpdated {\n        policy_id: String,\n        layer: KnowledgeLayer,\n        tenant_id: TenantId,\n        timestamp: i64,\n    },\n\n    /// Policy deleted\n    PolicyDeleted {\n        policy_id: String,\n        tenant_id: TenantId,\n        timestamp: i64,\n    },\n\n    /// Drift detected in a project\n    DriftDetected {\n        project_id: String,\n        tenant_id: TenantId,\n        drift_score: f32,\n        timestamp: i64,\n    },\n\n    /// Governance configuration updated\n    ConfigUpdated {\n        config_id: String,\n        scope: String,\n        tenant_id: TenantId,\n        timestamp: i64,\n    },\n\n    /// Governance approval request created\n    RequestCreated {\n        request_id: String,\n        request_type: String,\n        title: String,\n        tenant_id: TenantId,\n        timestamp: i64,\n    },\n\n    /// Governance approval request approved\n    RequestApproved {\n        request_id: String,\n        approver_id: String,\n        fully_approved: bool,\n        tenant_id: TenantId,\n        timestamp: i64,\n    },\n\n    /// Governance approval request rejected\n    RequestRejected {\n        request_id: String,\n        rejector_id: String,\n        reason: String,\n        tenant_id: TenantId,\n        timestamp: i64,\n    },\n}\n\nimpl GovernanceEvent {\n    #[must_use]\n    pub fn tenant_id(&self) -> &TenantId {\n        match self {\n            GovernanceEvent::UnitCreated { tenant_id, .. } => tenant_id,\n            GovernanceEvent::UnitUpdated { tenant_id, .. } => tenant_id,\n            GovernanceEvent::UnitDeleted { tenant_id, .. } => tenant_id,\n            GovernanceEvent::RoleAssigned { tenant_id, .. } => tenant_id,\n            GovernanceEvent::RoleRemoved { tenant_id, .. } => tenant_id,\n            GovernanceEvent::PolicyUpdated { tenant_id, .. } => tenant_id,\n            GovernanceEvent::PolicyDeleted { tenant_id, .. } => tenant_id,\n            GovernanceEvent::DriftDetected { tenant_id, .. } => tenant_id,\n            GovernanceEvent::ConfigUpdated { tenant_id, .. } => tenant_id,\n            GovernanceEvent::RequestCreated { tenant_id, .. } => tenant_id,\n            GovernanceEvent::RequestApproved { tenant_id, .. } => tenant_id,\n            GovernanceEvent::RequestRejected { tenant_id, .. } => tenant_id,\n        }\n    }\n}\n\n/// Drift analysis result with confidence scoring\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct DriftResult {\n    pub project_id: String,\n    pub tenant_id: TenantId,\n    pub drift_score: f32,\n    pub confidence: f32,\n    pub violations: Vec<PolicyViolation>,\n    pub suppressed_violations: Vec<PolicyViolation>,\n    pub requires_manual_review: bool,\n    pub timestamp: i64,\n}\n\nimpl DriftResult {\n    pub fn new(project_id: String, tenant_id: TenantId, violations: Vec<PolicyViolation>) -> Self {\n        let drift_score = Self::calculate_score(&violations);\n        Self {\n            project_id,\n            tenant_id,\n            drift_score,\n            confidence: 1.0,\n            violations,\n            suppressed_violations: Vec::new(),\n            requires_manual_review: false,\n            timestamp: chrono::Utc::now().timestamp(),\n        }\n    }\n\n    pub fn with_confidence(mut self, confidence: f32) -> Self {\n        self.confidence = confidence.clamp(0.0, 1.0);\n        self.requires_manual_review = self.confidence < 0.7;\n        self\n    }\n\n    pub fn with_suppressions(mut self, suppressed: Vec<PolicyViolation>) -> Self {\n        self.suppressed_violations = suppressed;\n        self\n    }\n\n    fn calculate_score(violations: &[PolicyViolation]) -> f32 {\n        if violations.is_empty() {\n            return 0.0;\n        }\n        violations\n            .iter()\n            .map(|v| match v.severity {\n                ConstraintSeverity::Block => 1.0,\n                ConstraintSeverity::Warn => 0.5,\n                ConstraintSeverity::Info => 0.1,\n            })\n            .sum::<f32>()\n            .min(1.0)\n    }\n\n    pub fn active_violation_count(&self) -> usize {\n        self.violations.len()\n    }\n\n    pub fn suppressed_count(&self) -> usize {\n        self.suppressed_violations.len()\n    }\n}\n\n/// Drift suppression rule to ignore specific violations\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct DriftSuppression {\n    pub id: String,\n    pub project_id: String,\n    pub tenant_id: TenantId,\n    pub policy_id: String,\n    pub rule_pattern: Option<String>,\n    pub reason: String,\n    pub created_by: UserId,\n    pub expires_at: Option<i64>,\n    pub created_at: i64,\n}\n\nimpl DriftSuppression {\n    pub fn new(\n        project_id: String,\n        tenant_id: TenantId,\n        policy_id: String,\n        reason: String,\n        created_by: UserId,\n    ) -> Self {\n        Self {\n            id: uuid::Uuid::new_v4().to_string(),\n            project_id,\n            tenant_id,\n            policy_id,\n            rule_pattern: None,\n            reason,\n            created_by,\n            expires_at: None,\n            created_at: chrono::Utc::now().timestamp(),\n        }\n    }\n\n    pub fn with_pattern(mut self, pattern: String) -> Self {\n        self.rule_pattern = Some(pattern);\n        self\n    }\n\n    pub fn with_expiry(mut self, expires_at: i64) -> Self {\n        self.expires_at = Some(expires_at);\n        self\n    }\n\n    pub fn is_expired(&self) -> bool {\n        if let Some(expires) = self.expires_at {\n            chrono::Utc::now().timestamp() > expires\n        } else {\n            false\n        }\n    }\n\n    pub fn matches(&self, violation: &PolicyViolation) -> bool {\n        if self.policy_id != violation.policy_id {\n            return false;\n        }\n        if let Some(pattern) = &self.rule_pattern {\n            if let Ok(re) = regex::Regex::new(pattern) {\n                return re.is_match(&violation.message);\n            }\n        }\n        true\n    }\n}\n\n/// Drift threshold configuration per project\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct DriftConfig {\n    pub project_id: String,\n    pub tenant_id: TenantId,\n    pub threshold: f32,\n    pub low_confidence_threshold: f32,\n    pub auto_suppress_info: bool,\n    pub updated_at: i64,\n}\n\nimpl Default for DriftConfig {\n    fn default() -> Self {\n        Self {\n            project_id: String::new(),\n            tenant_id: TenantId::default(),\n            threshold: 0.2,\n            low_confidence_threshold: 0.7,\n            auto_suppress_info: false,\n            updated_at: chrono::Utc::now().timestamp(),\n        }\n    }\n}\n\nimpl DriftConfig {\n    pub fn new(project_id: String, tenant_id: TenantId) -> Self {\n        Self {\n            project_id,\n            tenant_id,\n            ..Default::default()\n        }\n    }\n\n    pub fn for_project(project_id: String, tenant_id: TenantId) -> Self {\n        Self::new(project_id, tenant_id)\n    }\n\n    pub fn with_threshold(mut self, threshold: f32) -> Self {\n        self.threshold = threshold.clamp(0.0, 1.0);\n        self\n    }\n}\n\npub fn validate_user_id(id: &&String) -> Result<(), validator::ValidationError> {\n    if id.is_empty() {\n        return Err(validator::ValidationError::new(\"User ID cannot be empty\"));\n    }\n    if id.len() > 100 {\n        return Err(validator::ValidationError::new(\"User ID is too long\"));\n    }\n    Ok(())\n}\n\npub fn validate_session_id(id: &&String) -> Result<(), validator::ValidationError> {\n    if id.is_empty() {\n        return Err(validator::ValidationError::new(\n            \"Session ID cannot be empty\",\n        ));\n    }\n    Ok(())\n}\n\npub fn validate_project_id(id: &&String) -> Result<(), validator::ValidationError> {\n    if id.is_empty() {\n        return Err(validator::ValidationError::new(\n            \"Project ID cannot be empty\",\n        ));\n    }\n    Ok(())\n}\n\npub fn validate_team_id(id: &&String) -> Result<(), validator::ValidationError> {\n    if id.is_empty() {\n        return Err(validator::ValidationError::new(\"Team ID cannot be empty\"));\n    }\n    Ok(())\n}\n\npub fn validate_org_id(id: &&String) -> Result<(), validator::ValidationError> {\n    if id.is_empty() {\n        return Err(validator::ValidationError::new(\"Org ID cannot be empty\"));\n    }\n    Ok(())\n}\n\npub fn validate_company_id(id: &&String) -> Result<(), validator::ValidationError> {\n    if id.is_empty() {\n        return Err(validator::ValidationError::new(\n            \"Company ID cannot be empty\",\n        ));\n    }\n    Ok(())\n}\n\npub fn validate_agent_id(id: &&String) -> Result<(), validator::ValidationError> {\n    if id.is_empty() {\n        return Err(validator::ValidationError::new(\"Agent ID cannot be empty\"));\n    }\n    if id.len() > 100 {\n        return Err(validator::ValidationError::new(\"Agent ID is too long\"));\n    }\n    Ok(())\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize, ToSchema)]\n#[serde(rename_all = \"snake_case\")]\npub enum EventStatus {\n    Pending,\n    Published,\n    Acknowledged,\n    DeadLettered,\n}\n\nimpl std::fmt::Display for EventStatus {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            EventStatus::Pending => write!(f, \"pending\"),\n            EventStatus::Published => write!(f, \"published\"),\n            EventStatus::Acknowledged => write!(f, \"acknowledged\"),\n            EventStatus::DeadLettered => write!(f, \"dead_lettered\"),\n        }\n    }\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct PersistentEvent {\n    pub id: String,\n    pub event_id: String,\n    pub idempotency_key: String,\n    pub tenant_id: TenantId,\n    pub event_type: String,\n    pub payload: GovernanceEvent,\n    pub status: EventStatus,\n    pub retry_count: i32,\n    pub max_retries: i32,\n    pub last_error: Option<String>,\n    pub created_at: i64,\n    pub published_at: Option<i64>,\n    pub acknowledged_at: Option<i64>,\n    pub dead_lettered_at: Option<i64>,\n}\n\nimpl PersistentEvent {\n    pub fn new(event: GovernanceEvent) -> Self {\n        let event_id = uuid::Uuid::new_v4().to_string();\n        let timestamp = chrono::Utc::now().timestamp();\n        let tenant_id = event.tenant_id().clone();\n        let idempotency_key = Self::calculate_idempotency_key(&event_id, timestamp, &tenant_id);\n        let event_type = Self::event_type_name(&event);\n\n        Self {\n            id: uuid::Uuid::new_v4().to_string(),\n            event_id,\n            idempotency_key,\n            tenant_id,\n            event_type,\n            payload: event,\n            status: EventStatus::Pending,\n            retry_count: 0,\n            max_retries: 3,\n            last_error: None,\n            created_at: timestamp,\n            published_at: None,\n            acknowledged_at: None,\n            dead_lettered_at: None,\n        }\n    }\n\n    fn calculate_idempotency_key(event_id: &str, timestamp: i64, tenant_id: &TenantId) -> String {\n        use sha2::{Digest, Sha256};\n        let input = format!(\"{}:{}:{}\", event_id, timestamp, tenant_id.as_str());\n        let hash = Sha256::digest(input.as_bytes());\n        hex::encode(hash)\n    }\n\n    fn event_type_name(event: &GovernanceEvent) -> String {\n        match event {\n            GovernanceEvent::UnitCreated { .. } => \"unit_created\".to_string(),\n            GovernanceEvent::UnitUpdated { .. } => \"unit_updated\".to_string(),\n            GovernanceEvent::UnitDeleted { .. } => \"unit_deleted\".to_string(),\n            GovernanceEvent::RoleAssigned { .. } => \"role_assigned\".to_string(),\n            GovernanceEvent::RoleRemoved { .. } => \"role_removed\".to_string(),\n            GovernanceEvent::PolicyUpdated { .. } => \"policy_updated\".to_string(),\n            GovernanceEvent::PolicyDeleted { .. } => \"policy_deleted\".to_string(),\n            GovernanceEvent::DriftDetected { .. } => \"drift_detected\".to_string(),\n            GovernanceEvent::ConfigUpdated { .. } => \"config_updated\".to_string(),\n            GovernanceEvent::RequestCreated { .. } => \"request_created\".to_string(),\n            GovernanceEvent::RequestApproved { .. } => \"request_approved\".to_string(),\n            GovernanceEvent::RequestRejected { .. } => \"request_rejected\".to_string(),\n        }\n    }\n\n    pub fn mark_published(&mut self) {\n        self.status = EventStatus::Published;\n        self.published_at = Some(chrono::Utc::now().timestamp());\n    }\n\n    pub fn mark_acknowledged(&mut self) {\n        self.status = EventStatus::Acknowledged;\n        self.acknowledged_at = Some(chrono::Utc::now().timestamp());\n    }\n\n    pub fn mark_failed(&mut self, error: String) -> bool {\n        self.retry_count += 1;\n        self.last_error = Some(error);\n\n        if self.retry_count >= self.max_retries {\n            self.status = EventStatus::DeadLettered;\n            self.dead_lettered_at = Some(chrono::Utc::now().timestamp());\n            false\n        } else {\n            self.status = EventStatus::Pending;\n            true\n        }\n    }\n\n    pub fn is_retriable(&self) -> bool {\n        self.retry_count < self.max_retries && self.status == EventStatus::Pending\n    }\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct EventDeliveryMetrics {\n    pub tenant_id: TenantId,\n    pub event_type: String,\n    pub period_start: i64,\n    pub period_end: i64,\n    pub total_events: i64,\n    pub delivered_events: i64,\n    pub retried_events: i64,\n    pub dead_lettered_events: i64,\n    pub avg_delivery_time_ms: Option<f64>,\n}\n\nimpl EventDeliveryMetrics {\n    pub fn new(\n        tenant_id: TenantId,\n        event_type: String,\n        period_start: i64,\n        period_end: i64,\n    ) -> Self {\n        Self {\n            tenant_id,\n            event_type,\n            period_start,\n            period_end,\n            total_events: 0,\n            delivered_events: 0,\n            retried_events: 0,\n            dead_lettered_events: 0,\n            avg_delivery_time_ms: None,\n        }\n    }\n\n    pub fn delivery_success_rate(&self) -> f64 {\n        if self.total_events == 0 {\n            return 1.0;\n        }\n        self.delivered_events as f64 / self.total_events as f64\n    }\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]\npub struct ConsumerState {\n    pub consumer_group: String,\n    pub idempotency_key: String,\n    pub tenant_id: TenantId,\n    pub processed_at: i64,\n}\n\nimpl ConsumerState {\n    pub fn new(consumer_group: String, idempotency_key: String, tenant_id: TenantId) -> Self {\n        Self {\n            consumer_group,\n            idempotency_key,\n            tenant_id,\n            processed_at: chrono::Utc::now().timestamp(),\n        }\n    }\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct JobCoordinationMetrics {\n    pub job_name: String,\n    pub tenant_id: TenantId,\n    pub total_runs: u64,\n    pub successful_runs: u64,\n    pub failed_runs: u64,\n    pub skipped_runs: u64,\n    pub timeout_count: u64,\n    pub total_duration_ms: u64,\n    pub last_run_at: Option<i64>,\n    pub last_success_at: Option<i64>,\n}\n\nimpl JobCoordinationMetrics {\n    pub fn new(job_name: String, tenant_id: TenantId) -> Self {\n        Self {\n            job_name,\n            tenant_id,\n            total_runs: 0,\n            successful_runs: 0,\n            failed_runs: 0,\n            skipped_runs: 0,\n            timeout_count: 0,\n            total_duration_ms: 0,\n            last_run_at: None,\n            last_success_at: None,\n        }\n    }\n\n    pub fn record_run(&mut self, duration_ms: u64, success: bool) {\n        self.total_runs += 1;\n        self.total_duration_ms += duration_ms;\n        self.last_run_at = Some(chrono::Utc::now().timestamp());\n        if success {\n            self.successful_runs += 1;\n            self.last_success_at = self.last_run_at;\n        } else {\n            self.failed_runs += 1;\n        }\n    }\n\n    pub fn record_skip(&mut self) {\n        self.skipped_runs += 1;\n    }\n\n    pub fn record_timeout(&mut self) {\n        self.timeout_count += 1;\n        self.failed_runs += 1;\n    }\n\n    pub fn avg_duration_ms(&self) -> Option<f64> {\n        if self.total_runs == 0 {\n            None\n        } else {\n            Some(self.total_duration_ms as f64 / self.total_runs as f64)\n        }\n    }\n\n    pub fn success_rate(&self) -> f64 {\n        if self.total_runs == 0 {\n            1.0\n        } else {\n            self.successful_runs as f64 / self.total_runs as f64\n        }\n    }\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct PartialJobResult {\n    pub job_name: String,\n    pub tenant_id: TenantId,\n    pub checkpoint_id: String,\n    pub processed_count: usize,\n    pub total_count: Option<usize>,\n    pub last_processed_id: Option<String>,\n    pub partial_data: serde_json::Value,\n    pub created_at: i64,\n}\n\nimpl PartialJobResult {\n    pub fn new(job_name: String, tenant_id: TenantId) -> Self {\n        Self {\n            job_name,\n            tenant_id,\n            checkpoint_id: uuid::Uuid::new_v4().to_string(),\n            processed_count: 0,\n            total_count: None,\n            last_processed_id: None,\n            partial_data: serde_json::Value::Null,\n            created_at: chrono::Utc::now().timestamp(),\n        }\n    }\n\n    pub fn with_progress(mut self, processed: usize, total: Option<usize>) -> Self {\n        self.processed_count = processed;\n        self.total_count = total;\n        self\n    }\n\n    pub fn with_last_id(mut self, id: String) -> Self {\n        self.last_processed_id = Some(id);\n        self\n    }\n\n    pub fn with_data(mut self, data: serde_json::Value) -> Self {\n        self.partial_data = data;\n        self\n    }\n\n    pub fn progress_percentage(&self) -> Option<f64> {\n        self.total_count\n            .map(|total| (self.processed_count as f64 / total as f64) * 100.0)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use validator::Validate;\n\n    #[test]\n    fn test_knowledge_type_serialization() {\n        let adr = KnowledgeType::Adr;\n        let json = serde_json::to_string(&adr).unwrap();\n        assert_eq!(json, \"\\\"adr\\\"\");\n\n        let deserialized: KnowledgeType = serde_json::from_str(&json).unwrap();\n        assert_eq!(deserialized, KnowledgeType::Adr);\n    }\n\n    #[test]\n    fn test_knowledge_layer_serialization() {\n        let company = KnowledgeLayer::Company;\n        let json = serde_json::to_string(&company).unwrap();\n        assert_eq!(json, \"\\\"company\\\"\");\n\n        let deserialized: KnowledgeLayer = serde_json::from_str(&json).unwrap();\n        assert_eq!(deserialized, KnowledgeLayer::Company);\n    }\n\n    #[test]\n    fn test_memory_layer_precedence() {\n        assert_eq!(MemoryLayer::Agent.precedence(), 1);\n        assert_eq!(MemoryLayer::User.precedence(), 2);\n        assert_eq!(MemoryLayer::Session.precedence(), 3);\n        assert_eq!(MemoryLayer::Project.precedence(), 4);\n        assert_eq!(MemoryLayer::Team.precedence(), 5);\n        assert_eq!(MemoryLayer::Org.precedence(), 6);\n        assert_eq!(MemoryLayer::Company.precedence(), 7);\n    }\n\n    #[test]\n    fn test_memory_layer_serialization() {\n        let agent = MemoryLayer::Agent;\n        let json = serde_json::to_string(&agent).unwrap();\n        assert_eq!(json, \"\\\"agent\\\"\");\n\n        let deserialized: MemoryLayer = serde_json::from_str(&json).unwrap();\n        assert_eq!(deserialized, MemoryLayer::Agent);\n    }\n\n    #[test]\n    fn test_constraint_severity_serialization() {\n        let block = ConstraintSeverity::Block;\n        let json = serde_json::to_string(&block).unwrap();\n        assert_eq!(json, \"\\\"block\\\"\");\n\n        let deserialized: ConstraintSeverity = serde_json::from_str(&json).unwrap();\n        assert_eq!(deserialized, ConstraintSeverity::Block);\n    }\n\n    #[test]\n    fn test_constraint_operator_serialization() {\n        let must_use = ConstraintOperator::MustUse;\n        let json = serde_json::to_string(&must_use).unwrap();\n        assert_eq!(json, \"\\\"mustUse\\\"\");\n\n        let deserialized: ConstraintOperator = serde_json::from_str(&json).unwrap();\n        assert_eq!(deserialized, ConstraintOperator::MustUse);\n    }\n\n    #[test]\n    fn test_constraint_target_serialization() {\n        let file = ConstraintTarget::File;\n        let json = serde_json::to_string(&file).unwrap();\n        assert_eq!(json, \"\\\"file\\\"\");\n\n        let deserialized: ConstraintTarget = serde_json::from_str(&json).unwrap();\n        assert_eq!(deserialized, ConstraintTarget::File);\n    }\n\n    #[test]\n    fn test_memory_entry_creation() {\n        let entry = MemoryEntry {\n            id: \"test_id\".to_string(),\n            content: \"Test content\".to_string(),\n            embedding: Some(vec![0.1, 0.2, 0.3]),\n            layer: MemoryLayer::User,\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            metadata: std::collections::HashMap::new(),\n            created_at: 1234567890,\n            updated_at: 1234567890,\n        };\n\n        assert_eq!(entry.id, \"test_id\");\n        assert_eq!(entry.content, \"Test content\");\n        assert_eq!(entry.layer, MemoryLayer::User);\n        assert_eq!(entry.embedding.unwrap().len(), 3);\n    }\n\n    #[test]\n    fn test_knowledge_entry_creation() {\n        let entry = KnowledgeEntry {\n            path: \"docs/adr/001.md\".to_string(),\n            content: \"# ADR 001: Use Rust\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Adr,\n            summaries: std::collections::HashMap::new(),\n            metadata: std::collections::HashMap::new(),\n            commit_hash: Some(\"abc123\".to_string()),\n            author: Some(\"Alice\".to_string()),\n            status: KnowledgeStatus::Accepted,\n            updated_at: 1234567890,\n        };\n\n        assert_eq!(entry.path, \"docs/adr/001.md\");\n        assert_eq!(entry.layer, KnowledgeLayer::Project);\n        assert_eq!(entry.kind, KnowledgeType::Adr);\n        assert_eq!(entry.commit_hash.unwrap(), \"abc123\");\n    }\n\n    #[test]\n    fn test_policy_creation() {\n        let rule = PolicyRule {\n            id: \"rule_1\".to_string(),\n            rule_type: RuleType::Deny,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustNotUse,\n            value: serde_json::json!(\"unsafe-lib\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Do not use unsafe libraries\".to_string(),\n        };\n\n        let policy = Policy {\n            id: \"policy_1\".to_string(),\n            name: \"Security Policy\".to_string(),\n            description: Some(\"Security constraints\".to_string()),\n            layer: KnowledgeLayer::Company,\n            mode: PolicyMode::Mandatory,\n            merge_strategy: RuleMergeStrategy::Merge,\n            rules: vec![rule],\n            metadata: std::collections::HashMap::new(),\n        };\n\n        assert_eq!(policy.id, \"policy_1\");\n        assert_eq!(policy.layer, KnowledgeLayer::Company);\n        assert_eq!(policy.rules.len(), 1);\n        assert_eq!(policy.rules[0].target, ConstraintTarget::Dependency);\n    }\n\n    #[test]\n    fn test_validation_result_creation() {\n        let violation = PolicyViolation {\n            rule_id: \"rule_1\".to_string(),\n            policy_id: \"policy_1\".to_string(),\n            severity: ConstraintSeverity::Warn,\n            message: \"Warning message\".to_string(),\n            context: std::collections::HashMap::new(),\n        };\n\n        let result = ValidationResult {\n            is_valid: false,\n            violations: vec![violation],\n        };\n\n        assert!(!result.is_valid);\n        assert_eq!(result.violations.len(), 1);\n        assert_eq!(result.violations[0].severity, ConstraintSeverity::Warn);\n    }\n\n    #[test]\n    fn test_validate_user_id_valid() {\n        let user_id = \"user_123\".to_string();\n        let result = validate_user_id(&&user_id);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_validate_user_id_empty() {\n        let user_id = \"\".to_string();\n        let result = validate_user_id(&&user_id);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_validate_user_id_too_long() {\n        let user_id = \"a\".repeat(101);\n        let result = validate_user_id(&&user_id);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_validate_session_id_valid() {\n        let session_id = \"session_456\".to_string();\n        let result = validate_session_id(&&session_id);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_validate_project_id_valid() {\n        let project_id = \"project_789\".to_string();\n        let result = validate_project_id(&&project_id);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_validate_team_id_valid() {\n        let team_id = \"team_abc\".to_string();\n        let result = validate_team_id(&&team_id);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_validate_org_id_valid() {\n        let org_id = \"org_xyz\".to_string();\n        let result = validate_org_id(&&org_id);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_validate_company_id_valid() {\n        let company_id = \"company_123\".to_string();\n        let result = validate_company_id(&&company_id);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_layer_identifiers_validation() {\n        let identifiers = LayerIdentifiers {\n            agent_id: Some(\"agent_1\".to_string()),\n            user_id: Some(\"user_123\".to_string()),\n            session_id: Some(\"session_456\".to_string()),\n            project_id: Some(\"project_789\".to_string()),\n            team_id: Some(\"team_abc\".to_string()),\n            org_id: Some(\"org_xyz\".to_string()),\n            company_id: Some(\"company_123\".to_string()),\n        };\n\n        let result = identifiers.validate();\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_layer_identifiers_invalid_user_id() {\n        let identifiers = LayerIdentifiers {\n            agent_id: Some(\"agent_1\".to_string()),\n            user_id: Some(\"\".to_string()),\n            session_id: None,\n            project_id: None,\n            team_id: None,\n            org_id: None,\n            company_id: None,\n        };\n\n        let result = identifiers.validate();\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_memory_layer_display_name() {\n        assert_eq!(MemoryLayer::Agent.display_name(), \"Agent\");\n        assert_eq!(MemoryLayer::User.display_name(), \"User\");\n        assert_eq!(MemoryLayer::Session.display_name(), \"Session\");\n        assert_eq!(MemoryLayer::Project.display_name(), \"Project\");\n        assert_eq!(MemoryLayer::Team.display_name(), \"Team\");\n        assert_eq!(MemoryLayer::Org.display_name(), \"Organization\");\n        assert_eq!(MemoryLayer::Company.display_name(), \"Company\");\n    }\n\n    #[test]\n    fn test_validate_agent_id_valid() {\n        let agent_id = \"agent_123\".to_string();\n        let result = validate_agent_id(&&agent_id);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_validate_agent_id_empty() {\n        let agent_id = \"\".to_string();\n        let result = validate_agent_id(&&agent_id);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_validate_agent_id_too_long() {\n        let agent_id = \"a\".repeat(101);\n        let result = validate_agent_id(&&agent_id);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_validate_session_id_empty() {\n        let id = \"\".to_string();\n        assert!(validate_session_id(&&id).is_err());\n    }\n\n    #[test]\n    fn test_validate_project_id_empty() {\n        let id = \"\".to_string();\n        assert!(validate_project_id(&&id).is_err());\n    }\n\n    #[test]\n    fn test_validate_team_id_empty() {\n        let id = \"\".to_string();\n        assert!(validate_team_id(&&id).is_err());\n    }\n\n    #[test]\n    fn test_validate_org_id_empty() {\n        let id = \"\".to_string();\n        assert!(validate_org_id(&&id).is_err());\n    }\n\n    #[test]\n    fn test_validate_company_id_empty() {\n        let id = \"\".to_string();\n        assert!(validate_company_id(&&id).is_err());\n    }\n\n    #[test]\n    fn test_memory_layer_from_str() {\n        use std::str::FromStr;\n        assert_eq!(MemoryLayer::from_str(\"Agent\").unwrap(), MemoryLayer::Agent);\n        assert_eq!(\n            MemoryLayer::from_str(\"Session\").unwrap(),\n            MemoryLayer::Session\n        );\n        assert!(MemoryLayer::from_str(\"Invalid\").is_err());\n    }\n\n    #[test]\n    fn test_memory_layer_display() {\n        assert_eq!(format!(\"{}\", MemoryLayer::Agent), \"Agent\");\n        assert_eq!(format!(\"{}\", MemoryLayer::User), \"User\");\n        assert_eq!(format!(\"{}\", MemoryLayer::Session), \"Session\");\n        assert_eq!(format!(\"{}\", MemoryLayer::Project), \"Project\");\n        assert_eq!(format!(\"{}\", MemoryLayer::Team), \"Team\");\n        assert_eq!(format!(\"{}\", MemoryLayer::Org), \"Org\");\n        assert_eq!(format!(\"{}\", MemoryLayer::Company), \"Company\");\n    }\n\n    #[test]\n    fn test_role_serialization() {\n        let architect = Role::Architect;\n        let json = serde_json::to_string(&architect).unwrap();\n        assert_eq!(json, \"\\\"architect\\\"\");\n\n        let deserialized: Role = serde_json::from_str(&json).unwrap();\n        assert_eq!(deserialized, Role::Architect);\n    }\n\n    #[test]\n    fn test_role_precedence() {\n        assert_eq!(Role::Admin.precedence(), 4);\n        assert_eq!(Role::Architect.precedence(), 3);\n        assert_eq!(Role::TechLead.precedence(), 2);\n        assert_eq!(Role::Developer.precedence(), 1);\n        assert_eq!(Role::Agent.precedence(), 0);\n    }\n\n    #[test]\n    fn test_reasoning_strategy_serialization() {\n        let exhaustive = ReasoningStrategy::Exhaustive;\n        let json = serde_json::to_string(&exhaustive).unwrap();\n        assert_eq!(json, \"\\\"exhaustive\\\"\");\n\n        let deserialized: ReasoningStrategy = serde_json::from_str(&json).unwrap();\n        assert_eq!(deserialized, ReasoningStrategy::Exhaustive);\n    }\n\n    #[test]\n    fn test_reasoning_strategy_display() {\n        assert_eq!(format!(\"{}\", ReasoningStrategy::Exhaustive), \"exhaustive\");\n        assert_eq!(format!(\"{}\", ReasoningStrategy::Targeted), \"targeted\");\n    }\n\n    #[test]\n    fn test_tenant_id_validation() {\n        assert!(TenantId::new(\"comp_123\".to_string()).is_some());\n        assert!(TenantId::new(\"\".to_string()).is_none());\n        assert!(TenantId::new(\"a\".repeat(101)).is_none());\n    }\n\n    #[test]\n    fn test_user_id_validation() {\n        assert!(UserId::new(\"user_456\".to_string()).is_some());\n        assert!(UserId::new(\"\".to_string()).is_none());\n        assert!(UserId::new(\"a\".repeat(101)).is_none());\n    }\n\n    #[test]\n    fn test_hierarchy_path_depth() {\n        let company = HierarchyPath::company(\"c1\".to_string());\n        assert_eq!(company.depth(), 1);\n\n        let org = HierarchyPath::org(\"c1\".to_string(), \"o1\".to_string());\n        assert_eq!(org.depth(), 2);\n\n        let team = HierarchyPath::team(\"c1\".to_string(), \"o1\".to_string(), \"t1\".to_string());\n        assert_eq!(team.depth(), 3);\n\n        let project = HierarchyPath::project(\n            \"c1\".to_string(),\n            \"o1\".to_string(),\n            \"t1\".to_string(),\n            \"p1\".to_string(),\n        );\n        assert_eq!(project.depth(), 4);\n    }\n\n    #[test]\n    fn test_hierarchy_path_string() {\n        let project = HierarchyPath::project(\n            \"c1\".to_string(),\n            \"o1\".to_string(),\n            \"t1\".to_string(),\n            \"p1\".to_string(),\n        );\n        assert_eq!(project.path_string(), \"c1 > o1 > t1 > p1\");\n    }\n\n    #[test]\n    fn test_tenant_context_creation() {\n        let tenant_id = TenantId::new(\"c1\".to_string()).unwrap();\n        let user_id = UserId::new(\"u1\".to_string()).unwrap();\n        let ctx = TenantContext::new(tenant_id, user_id);\n\n        assert_eq!(ctx.tenant_id.as_str(), \"c1\");\n        assert_eq!(ctx.user_id.as_str(), \"u1\");\n        assert!(ctx.agent_id.is_none());\n    }\n\n    #[test]\n    fn test_tenant_context_with_agent() {\n        let tenant_id = TenantId::new(\"c1\".to_string()).unwrap();\n        let user_id = UserId::new(\"u1\".to_string()).unwrap();\n        let ctx = TenantContext::with_agent(tenant_id, user_id, \"a1\".to_string());\n\n        assert_eq!(ctx.agent_id.unwrap(), \"a1\");\n    }\n\n    #[test]\n    fn test_tenant_id_display() {\n        let id = TenantId::new(\"c1\".to_string()).unwrap();\n        assert_eq!(format!(\"{}\", id), \"c1\");\n    }\n\n    #[test]\n    fn test_user_id_display() {\n        let id = UserId::new(\"u1\".to_string()).unwrap();\n        assert_eq!(format!(\"{}\", id), \"u1\");\n    }\n\n    #[test]\n    fn test_tenant_id_from_str() {\n        use std::str::FromStr;\n        let id = TenantId::from_str(\"c1\").unwrap();\n        assert_eq!(id.as_str(), \"c1\");\n        assert!(TenantId::from_str(\"\").is_err());\n    }\n\n    #[test]\n    fn test_user_id_from_str() {\n        use std::str::FromStr;\n        let id = UserId::from_str(\"u1\").unwrap();\n        assert_eq!(id.as_str(), \"u1\");\n        assert!(UserId::from_str(\"\").is_err());\n    }\n\n    #[test]\n    fn test_tenant_id_into_inner() {\n        let id = TenantId::new(\"c1\".to_string()).unwrap();\n        assert_eq!(id.into_inner(), \"c1\");\n    }\n\n    #[test]\n    fn test_user_id_into_inner() {\n        let id = UserId::new(\"u1\".to_string()).unwrap();\n        assert_eq!(id.into_inner(), \"u1\");\n    }\n\n    #[test]\n    fn test_governance_event_tenant_id() {\n        let tenant_id = TenantId::new(\"tenant-1\".to_string()).unwrap();\n        let user_id = UserId::new(\"user-1\".to_string()).unwrap();\n\n        let events = vec![\n            GovernanceEvent::UnitCreated {\n                unit_id: \"u1\".to_string(),\n                unit_type: UnitType::Company,\n                tenant_id: tenant_id.clone(),\n                parent_id: None,\n                timestamp: 0,\n            },\n            GovernanceEvent::UnitUpdated {\n                unit_id: \"u1\".to_string(),\n                tenant_id: tenant_id.clone(),\n                timestamp: 0,\n            },\n            GovernanceEvent::UnitDeleted {\n                unit_id: \"u1\".to_string(),\n                tenant_id: tenant_id.clone(),\n                timestamp: 0,\n            },\n            GovernanceEvent::RoleAssigned {\n                user_id: user_id.clone(),\n                unit_id: \"u1\".to_string(),\n                role: Role::Admin,\n                tenant_id: tenant_id.clone(),\n                timestamp: 0,\n            },\n            GovernanceEvent::RoleRemoved {\n                user_id: user_id.clone(),\n                unit_id: \"u1\".to_string(),\n                role: Role::Admin,\n                tenant_id: tenant_id.clone(),\n                timestamp: 0,\n            },\n            GovernanceEvent::PolicyUpdated {\n                policy_id: \"p1\".to_string(),\n                layer: KnowledgeLayer::Company,\n                tenant_id: tenant_id.clone(),\n                timestamp: 0,\n            },\n            GovernanceEvent::PolicyDeleted {\n                policy_id: \"p1\".to_string(),\n                tenant_id: tenant_id.clone(),\n                timestamp: 0,\n            },\n            GovernanceEvent::DriftDetected {\n                project_id: \"proj-1\".to_string(),\n                tenant_id: tenant_id.clone(),\n                drift_score: 0.5,\n                timestamp: 0,\n            },\n        ];\n\n        for event in events {\n            assert_eq!(event.tenant_id().as_str(), \"tenant-1\");\n        }\n    }\n\n    #[test]\n    fn test_role_display_name() {\n        assert_eq!(Role::Developer.display_name(), \"Developer\");\n        assert_eq!(Role::TechLead.display_name(), \"Tech Lead\");\n        assert_eq!(Role::Architect.display_name(), \"Architect\");\n        assert_eq!(Role::Admin.display_name(), \"Admin\");\n        assert_eq!(Role::Agent.display_name(), \"Agent\");\n    }\n\n    #[test]\n    fn test_drift_suppression_new() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let user_id = UserId::new(\"user1\".to_string()).unwrap();\n\n        let suppression = DriftSuppression::new(\n            \"proj-1\".to_string(),\n            tenant_id.clone(),\n            \"policy-1\".to_string(),\n            \"False positive\".to_string(),\n            user_id.clone(),\n        );\n\n        assert_eq!(suppression.project_id, \"proj-1\");\n        assert_eq!(suppression.tenant_id, tenant_id);\n        assert_eq!(suppression.policy_id, \"policy-1\");\n        assert_eq!(suppression.reason, \"False positive\");\n        assert!(suppression.rule_pattern.is_none());\n        assert!(suppression.expires_at.is_none());\n        assert!(!suppression.id.is_empty());\n    }\n\n    #[test]\n    fn test_drift_suppression_with_pattern() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let user_id = UserId::new(\"user1\".to_string()).unwrap();\n\n        let suppression = DriftSuppression::new(\n            \"proj-1\".to_string(),\n            tenant_id,\n            \"policy-1\".to_string(),\n            \"Known issue\".to_string(),\n            user_id,\n        )\n        .with_pattern(\".*test.*\".to_string());\n\n        assert_eq!(suppression.rule_pattern, Some(\".*test.*\".to_string()));\n    }\n\n    #[test]\n    fn test_drift_suppression_with_expiry() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let user_id = UserId::new(\"user1\".to_string()).unwrap();\n        let future_time = chrono::Utc::now().timestamp() + 86400;\n\n        let suppression = DriftSuppression::new(\n            \"proj-1\".to_string(),\n            tenant_id,\n            \"policy-1\".to_string(),\n            \"Temporary\".to_string(),\n            user_id,\n        )\n        .with_expiry(future_time);\n\n        assert_eq!(suppression.expires_at, Some(future_time));\n    }\n\n    #[test]\n    fn test_drift_suppression_is_expired() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let user_id = UserId::new(\"user1\".to_string()).unwrap();\n\n        let not_expired = DriftSuppression::new(\n            \"proj-1\".to_string(),\n            tenant_id.clone(),\n            \"policy-1\".to_string(),\n            \"Not expired\".to_string(),\n            user_id.clone(),\n        );\n        assert!(!not_expired.is_expired());\n\n        let future_expiry = DriftSuppression::new(\n            \"proj-1\".to_string(),\n            tenant_id.clone(),\n            \"policy-1\".to_string(),\n            \"Future\".to_string(),\n            user_id.clone(),\n        )\n        .with_expiry(chrono::Utc::now().timestamp() + 86400);\n        assert!(!future_expiry.is_expired());\n\n        let past_expiry = DriftSuppression::new(\n            \"proj-1\".to_string(),\n            tenant_id,\n            \"policy-1\".to_string(),\n            \"Expired\".to_string(),\n            user_id,\n        )\n        .with_expiry(chrono::Utc::now().timestamp() - 86400);\n        assert!(past_expiry.is_expired());\n    }\n\n    #[test]\n    fn test_drift_suppression_matches() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let user_id = UserId::new(\"user1\".to_string()).unwrap();\n\n        let violation = PolicyViolation {\n            rule_id: \"rule-1\".to_string(),\n            policy_id: \"policy-1\".to_string(),\n            severity: ConstraintSeverity::Warn,\n            message: \"Test violation message\".to_string(),\n            context: std::collections::HashMap::new(),\n        };\n\n        let suppression_match = DriftSuppression::new(\n            \"proj-1\".to_string(),\n            tenant_id.clone(),\n            \"policy-1\".to_string(),\n            \"Match all\".to_string(),\n            user_id.clone(),\n        );\n        assert!(suppression_match.matches(&violation));\n\n        let suppression_no_match = DriftSuppression::new(\n            \"proj-1\".to_string(),\n            tenant_id.clone(),\n            \"policy-2\".to_string(),\n            \"Different policy\".to_string(),\n            user_id.clone(),\n        );\n        assert!(!suppression_no_match.matches(&violation));\n\n        let suppression_pattern_match = DriftSuppression::new(\n            \"proj-1\".to_string(),\n            tenant_id.clone(),\n            \"policy-1\".to_string(),\n            \"Pattern match\".to_string(),\n            user_id.clone(),\n        )\n        .with_pattern(\".*violation.*\".to_string());\n        assert!(suppression_pattern_match.matches(&violation));\n\n        let suppression_pattern_no_match = DriftSuppression::new(\n            \"proj-1\".to_string(),\n            tenant_id,\n            \"policy-1\".to_string(),\n            \"Pattern no match\".to_string(),\n            user_id,\n        )\n        .with_pattern(\".*xyz.*\".to_string());\n        assert!(!suppression_pattern_no_match.matches(&violation));\n    }\n\n    #[test]\n    fn test_drift_config_default() {\n        let config = DriftConfig::default();\n        assert!(config.project_id.is_empty());\n        assert_eq!(config.threshold, 0.2);\n        assert_eq!(config.low_confidence_threshold, 0.7);\n        assert!(!config.auto_suppress_info);\n    }\n\n    #[test]\n    fn test_drift_config_new() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let config = DriftConfig::new(\"proj-1\".to_string(), tenant_id.clone());\n\n        assert_eq!(config.project_id, \"proj-1\");\n        assert_eq!(config.tenant_id, tenant_id);\n        assert_eq!(config.threshold, 0.2);\n    }\n\n    #[test]\n    fn test_drift_config_for_project() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let config = DriftConfig::for_project(\"proj-2\".to_string(), tenant_id.clone());\n\n        assert_eq!(config.project_id, \"proj-2\");\n        assert_eq!(config.tenant_id, tenant_id);\n    }\n\n    #[test]\n    fn test_drift_config_with_threshold() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let config = DriftConfig::new(\"proj-1\".to_string(), tenant_id).with_threshold(0.5);\n\n        assert_eq!(config.threshold, 0.5);\n    }\n\n    #[test]\n    fn test_drift_config_with_threshold_clamped() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n\n        let config_low =\n            DriftConfig::new(\"proj-1\".to_string(), tenant_id.clone()).with_threshold(-0.5);\n        assert_eq!(config_low.threshold, 0.0);\n\n        let config_high = DriftConfig::new(\"proj-1\".to_string(), tenant_id).with_threshold(1.5);\n        assert_eq!(config_high.threshold, 1.0);\n    }\n\n    #[test]\n    fn test_drift_result_active_violation_count() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let violations = vec![\n            PolicyViolation {\n                rule_id: \"r1\".to_string(),\n                policy_id: \"p1\".to_string(),\n                severity: ConstraintSeverity::Warn,\n                message: \"Warning\".to_string(),\n                context: std::collections::HashMap::new(),\n            },\n            PolicyViolation {\n                rule_id: \"r2\".to_string(),\n                policy_id: \"p1\".to_string(),\n                severity: ConstraintSeverity::Block,\n                message: \"Blocking\".to_string(),\n                context: std::collections::HashMap::new(),\n            },\n        ];\n\n        let result = DriftResult::new(\"proj-1\".to_string(), tenant_id, violations);\n        assert_eq!(result.active_violation_count(), 2);\n    }\n\n    #[test]\n    fn test_drift_result_suppressed_count() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let mut result = DriftResult::new(\"proj-1\".to_string(), tenant_id, vec![]);\n        result.suppressed_violations = vec![PolicyViolation {\n            rule_id: \"r1\".to_string(),\n            policy_id: \"p1\".to_string(),\n            severity: ConstraintSeverity::Info,\n            message: \"Suppressed\".to_string(),\n            context: std::collections::HashMap::new(),\n        }];\n\n        assert_eq!(result.suppressed_count(), 1);\n    }\n\n    #[test]\n    fn test_job_coordination_metrics_new() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let metrics = JobCoordinationMetrics::new(\"drift_scan\".to_string(), tenant_id.clone());\n\n        assert_eq!(metrics.job_name, \"drift_scan\");\n        assert_eq!(metrics.tenant_id, tenant_id);\n        assert_eq!(metrics.total_runs, 0);\n        assert_eq!(metrics.successful_runs, 0);\n        assert_eq!(metrics.failed_runs, 0);\n        assert_eq!(metrics.skipped_runs, 0);\n        assert_eq!(metrics.timeout_count, 0);\n        assert_eq!(metrics.total_duration_ms, 0);\n        assert!(metrics.last_run_at.is_none());\n        assert!(metrics.last_success_at.is_none());\n    }\n\n    #[test]\n    fn test_job_coordination_metrics_record_run_success() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let mut metrics = JobCoordinationMetrics::new(\"test_job\".to_string(), tenant_id);\n        metrics.record_run(1000, true);\n\n        assert_eq!(metrics.total_runs, 1);\n        assert_eq!(metrics.successful_runs, 1);\n        assert_eq!(metrics.failed_runs, 0);\n        assert_eq!(metrics.total_duration_ms, 1000);\n        assert!(metrics.last_run_at.is_some());\n        assert!(metrics.last_success_at.is_some());\n    }\n\n    #[test]\n    fn test_job_coordination_metrics_record_run_failure() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let mut metrics = JobCoordinationMetrics::new(\"test_job\".to_string(), tenant_id);\n        metrics.record_run(500, false);\n\n        assert_eq!(metrics.total_runs, 1);\n        assert_eq!(metrics.successful_runs, 0);\n        assert_eq!(metrics.failed_runs, 1);\n        assert_eq!(metrics.total_duration_ms, 500);\n        assert!(metrics.last_run_at.is_some());\n        assert!(metrics.last_success_at.is_none());\n    }\n\n    #[test]\n    fn test_job_coordination_metrics_record_skip() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let mut metrics = JobCoordinationMetrics::new(\"test_job\".to_string(), tenant_id);\n        metrics.record_skip();\n\n        assert_eq!(metrics.skipped_runs, 1);\n        assert_eq!(metrics.total_runs, 0);\n    }\n\n    #[test]\n    fn test_job_coordination_metrics_record_timeout() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let mut metrics = JobCoordinationMetrics::new(\"test_job\".to_string(), tenant_id);\n        metrics.record_timeout();\n\n        assert_eq!(metrics.timeout_count, 1);\n        assert_eq!(metrics.failed_runs, 1);\n    }\n\n    #[test]\n    fn test_job_coordination_metrics_avg_duration_ms() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let mut metrics = JobCoordinationMetrics::new(\"test_job\".to_string(), tenant_id);\n        assert!(metrics.avg_duration_ms().is_none());\n\n        metrics.record_run(1000, true);\n        metrics.record_run(2000, true);\n        assert_eq!(metrics.avg_duration_ms(), Some(1500.0));\n    }\n\n    #[test]\n    fn test_job_coordination_metrics_success_rate() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let mut metrics = JobCoordinationMetrics::new(\"test_job\".to_string(), tenant_id);\n        assert_eq!(metrics.success_rate(), 1.0);\n\n        metrics.record_run(100, true);\n        metrics.record_run(100, true);\n        metrics.record_run(100, false);\n        let rate = metrics.success_rate();\n        assert!((rate - 0.6666666666666666).abs() < 0.0001);\n    }\n\n    #[test]\n    fn test_partial_job_result_new() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let result = PartialJobResult::new(\"drift_scan\".to_string(), tenant_id.clone());\n\n        assert_eq!(result.job_name, \"drift_scan\");\n        assert_eq!(result.tenant_id, tenant_id);\n        assert_eq!(result.processed_count, 0);\n        assert!(result.total_count.is_none());\n        assert!(result.last_processed_id.is_none());\n        assert_eq!(result.partial_data, serde_json::Value::Null);\n        assert!(!result.checkpoint_id.is_empty());\n    }\n\n    #[test]\n    fn test_partial_job_result_with_progress() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let result =\n            PartialJobResult::new(\"drift_scan\".to_string(), tenant_id).with_progress(50, Some(100));\n\n        assert_eq!(result.processed_count, 50);\n        assert_eq!(result.total_count, Some(100));\n    }\n\n    #[test]\n    fn test_partial_job_result_with_last_id() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let result = PartialJobResult::new(\"drift_scan\".to_string(), tenant_id)\n            .with_last_id(\"item-50\".to_string());\n\n        assert_eq!(result.last_processed_id, Some(\"item-50\".to_string()));\n    }\n\n    #[test]\n    fn test_partial_job_result_with_data() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let data = serde_json::json!({\"key\": \"value\"});\n        let result =\n            PartialJobResult::new(\"drift_scan\".to_string(), tenant_id).with_data(data.clone());\n\n        assert_eq!(result.partial_data, data);\n    }\n\n    #[test]\n    fn test_partial_job_result_progress_percentage() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n\n        let no_total = PartialJobResult::new(\"drift_scan\".to_string(), tenant_id.clone());\n        assert!(no_total.progress_percentage().is_none());\n\n        let with_total =\n            PartialJobResult::new(\"drift_scan\".to_string(), tenant_id).with_progress(25, Some(100));\n        assert_eq!(with_total.progress_percentage(), Some(25.0));\n    }\n\n    #[test]\n    fn test_persistent_event_mark_published() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let event = GovernanceEvent::UnitCreated {\n            unit_id: \"u1\".to_string(),\n            unit_type: UnitType::Company,\n            tenant_id: tenant_id.clone(),\n            parent_id: None,\n            timestamp: 0,\n        };\n\n        let mut persistent = PersistentEvent::new(event);\n        assert_eq!(persistent.status, EventStatus::Pending);\n        assert!(persistent.published_at.is_none());\n\n        persistent.mark_published();\n        assert_eq!(persistent.status, EventStatus::Published);\n        assert!(persistent.published_at.is_some());\n    }\n\n    #[test]\n    fn test_persistent_event_mark_acknowledged() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let event = GovernanceEvent::UnitCreated {\n            unit_id: \"u1\".to_string(),\n            unit_type: UnitType::Company,\n            tenant_id: tenant_id.clone(),\n            parent_id: None,\n            timestamp: 0,\n        };\n\n        let mut persistent = PersistentEvent::new(event);\n        persistent.mark_acknowledged();\n\n        assert_eq!(persistent.status, EventStatus::Acknowledged);\n        assert!(persistent.acknowledged_at.is_some());\n    }\n\n    #[test]\n    fn test_persistent_event_mark_failed_retriable() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let event = GovernanceEvent::UnitCreated {\n            unit_id: \"u1\".to_string(),\n            unit_type: UnitType::Company,\n            tenant_id: tenant_id.clone(),\n            parent_id: None,\n            timestamp: 0,\n        };\n\n        let mut persistent = PersistentEvent::new(event);\n        let can_retry = persistent.mark_failed(\"Connection timeout\".to_string());\n\n        assert!(can_retry);\n        assert_eq!(persistent.retry_count, 1);\n        assert_eq!(\n            persistent.last_error,\n            Some(\"Connection timeout\".to_string())\n        );\n        assert_eq!(persistent.status, EventStatus::Pending);\n    }\n\n    #[test]\n    fn test_persistent_event_mark_failed_dead_lettered() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let event = GovernanceEvent::UnitCreated {\n            unit_id: \"u1\".to_string(),\n            unit_type: UnitType::Company,\n            tenant_id: tenant_id.clone(),\n            parent_id: None,\n            timestamp: 0,\n        };\n\n        let mut persistent = PersistentEvent::new(event);\n        persistent.mark_failed(\"Error 1\".to_string());\n        persistent.mark_failed(\"Error 2\".to_string());\n        let can_retry = persistent.mark_failed(\"Error 3\".to_string());\n\n        assert!(!can_retry);\n        assert_eq!(persistent.status, EventStatus::DeadLettered);\n        assert!(persistent.dead_lettered_at.is_some());\n    }\n\n    #[test]\n    fn test_persistent_event_is_retriable() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let event = GovernanceEvent::UnitCreated {\n            unit_id: \"u1\".to_string(),\n            unit_type: UnitType::Company,\n            tenant_id: tenant_id.clone(),\n            parent_id: None,\n            timestamp: 0,\n        };\n\n        let mut persistent = PersistentEvent::new(event);\n        assert!(persistent.is_retriable());\n\n        persistent.mark_failed(\"Error 1\".to_string());\n        assert!(persistent.is_retriable());\n\n        persistent.mark_failed(\"Error 2\".to_string());\n        assert!(persistent.is_retriable());\n\n        persistent.mark_failed(\"Error 3\".to_string());\n        assert!(!persistent.is_retriable());\n    }\n\n    #[test]\n    fn test_event_delivery_metrics_new() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let metrics =\n            EventDeliveryMetrics::new(tenant_id.clone(), \"drift_detected\".to_string(), 1000, 2000);\n\n        assert_eq!(metrics.tenant_id, tenant_id);\n        assert_eq!(metrics.event_type, \"drift_detected\");\n        assert_eq!(metrics.period_start, 1000);\n        assert_eq!(metrics.period_end, 2000);\n        assert_eq!(metrics.total_events, 0);\n        assert_eq!(metrics.delivered_events, 0);\n    }\n\n    #[test]\n    fn test_event_delivery_metrics_success_rate() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let mut metrics =\n            EventDeliveryMetrics::new(tenant_id, \"drift_detected\".to_string(), 1000, 2000);\n\n        assert_eq!(metrics.delivery_success_rate(), 1.0);\n\n        metrics.total_events = 10;\n        metrics.delivered_events = 8;\n        assert_eq!(metrics.delivery_success_rate(), 0.8);\n    }\n\n    #[test]\n    fn test_consumer_state_new() {\n        let tenant_id = TenantId::new(\"acme\".to_string()).unwrap();\n        let state = ConsumerState::new(\n            \"drift_processor\".to_string(),\n            \"idempotency-key-123\".to_string(),\n            tenant_id.clone(),\n        );\n\n        assert_eq!(state.consumer_group, \"drift_processor\");\n        assert_eq!(state.idempotency_key, \"idempotency-key-123\");\n        assert_eq!(state.tenant_id, tenant_id);\n        assert!(state.processed_at > 0);\n    }\n\n    // ==========================================================================\n    // CCA Types Tests (Phase 1.1.5)\n    // ==========================================================================\n\n    #[test]\n    fn test_summary_depth_serialization() {\n        let sentence = SummaryDepth::Sentence;\n        let json = serde_json::to_string(&sentence).unwrap();\n        assert_eq!(json, \"\\\"sentence\\\"\");\n\n        let paragraph = SummaryDepth::Paragraph;\n        let json = serde_json::to_string(&paragraph).unwrap();\n        assert_eq!(json, \"\\\"paragraph\\\"\");\n\n        let detailed = SummaryDepth::Detailed;\n        let json = serde_json::to_string(&detailed).unwrap();\n        assert_eq!(json, \"\\\"detailed\\\"\");\n    }\n\n    #[test]\n    fn test_summary_depth_deserialization() {\n        let sentence: SummaryDepth = serde_json::from_str(\"\\\"sentence\\\"\").unwrap();\n        assert_eq!(sentence, SummaryDepth::Sentence);\n\n        let paragraph: SummaryDepth = serde_json::from_str(\"\\\"paragraph\\\"\").unwrap();\n        assert_eq!(paragraph, SummaryDepth::Paragraph);\n\n        let detailed: SummaryDepth = serde_json::from_str(\"\\\"detailed\\\"\").unwrap();\n        assert_eq!(detailed, SummaryDepth::Detailed);\n    }\n\n    #[test]\n    fn test_summary_depth_hash_key() {\n        let mut map = std::collections::HashMap::new();\n        map.insert(SummaryDepth::Sentence, \"short\");\n        map.insert(SummaryDepth::Paragraph, \"medium\");\n        map.insert(SummaryDepth::Detailed, \"long\");\n\n        assert_eq!(map.get(&SummaryDepth::Sentence), Some(&\"short\"));\n        assert_eq!(map.get(&SummaryDepth::Paragraph), Some(&\"medium\"));\n        assert_eq!(map.get(&SummaryDepth::Detailed), Some(&\"long\"));\n        assert_eq!(map.len(), 3);\n    }\n\n    #[test]\n    fn test_layer_summary_creation() {\n        let summary = LayerSummary {\n            depth: SummaryDepth::Sentence,\n            content: \"This is a one-sentence summary.\".to_string(),\n            token_count: 8,\n            generated_at: 1705500000,\n            source_hash: \"abc123def456\".to_string(),\n            content_hash: None,\n            personalized: false,\n            personalization_context: None,\n        };\n\n        assert_eq!(summary.depth, SummaryDepth::Sentence);\n        assert_eq!(summary.content, \"This is a one-sentence summary.\");\n        assert_eq!(summary.token_count, 8);\n        assert_eq!(summary.source_hash, \"abc123def456\");\n        assert!(!summary.personalized);\n        assert!(summary.personalization_context.is_none());\n    }\n\n    #[test]\n    fn test_layer_summary_with_personalization() {\n        let summary = LayerSummary {\n            depth: SummaryDepth::Detailed,\n            content: \"Detailed summary for backend developers...\".to_string(),\n            token_count: 150,\n            generated_at: 1705500000,\n            source_hash: \"hash789\".to_string(),\n            content_hash: None,\n            personalized: true,\n            personalization_context: Some(\"backend developer, Rust experience\".to_string()),\n        };\n\n        assert!(summary.personalized);\n        assert_eq!(\n            summary.personalization_context,\n            Some(\"backend developer, Rust experience\".to_string())\n        );\n    }\n\n    #[test]\n    fn test_layer_summary_serialization_roundtrip() {\n        let summary = LayerSummary {\n            depth: SummaryDepth::Paragraph,\n            content: \"A paragraph-length summary explaining the concept.\".to_string(),\n            token_count: 42,\n            generated_at: 1705500000,\n            source_hash: \"source_hash_value\".to_string(),\n            content_hash: None,\n            personalized: true,\n            personalization_context: Some(\"security focus\".to_string()),\n        };\n\n        let json = serde_json::to_string(&summary).unwrap();\n        let deserialized: LayerSummary = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(summary, deserialized);\n    }\n\n    #[test]\n    fn test_layer_summary_json_structure() {\n        let summary = LayerSummary {\n            depth: SummaryDepth::Sentence,\n            content: \"Summary\".to_string(),\n            token_count: 1,\n            generated_at: 1000,\n            source_hash: \"hash\".to_string(),\n            content_hash: None,\n            personalized: false,\n            personalization_context: None,\n        };\n\n        let json: serde_json::Value = serde_json::to_value(&summary).unwrap();\n\n        assert!(json.get(\"depth\").is_some());\n        assert!(json.get(\"content\").is_some());\n        assert!(json.get(\"tokenCount\").is_some());\n        assert!(json.get(\"generatedAt\").is_some());\n        assert!(json.get(\"sourceHash\").is_some());\n        assert!(json.get(\"personalized\").is_some());\n        assert!(json.get(\"personalizationContext\").is_some());\n    }\n\n    #[test]\n    fn test_summary_config_creation() {\n        let config = SummaryConfig {\n            layer: MemoryLayer::Project,\n            update_interval_secs: Some(3600),\n            update_on_changes: Some(10),\n            skip_if_unchanged: true,\n            personalized: false,\n            depths: vec![SummaryDepth::Sentence, SummaryDepth::Paragraph],\n        };\n\n        assert_eq!(config.layer, MemoryLayer::Project);\n        assert_eq!(config.update_interval_secs, Some(3600));\n        assert_eq!(config.update_on_changes, Some(10));\n        assert!(config.skip_if_unchanged);\n        assert!(!config.personalized);\n        assert_eq!(config.depths.len(), 2);\n    }\n\n    #[test]\n    fn test_summary_config_time_based_trigger() {\n        let config = SummaryConfig {\n            layer: MemoryLayer::Session,\n            update_interval_secs: Some(300),\n            update_on_changes: None,\n            skip_if_unchanged: true,\n            personalized: false,\n            depths: vec![SummaryDepth::Sentence],\n        };\n\n        assert!(config.update_interval_secs.is_some());\n        assert!(config.update_on_changes.is_none());\n    }\n\n    #[test]\n    fn test_summary_config_change_based_trigger() {\n        let config = SummaryConfig {\n            layer: MemoryLayer::Team,\n            update_interval_secs: None,\n            update_on_changes: Some(5),\n            skip_if_unchanged: false,\n            personalized: true,\n            depths: vec![SummaryDepth::Detailed],\n        };\n\n        assert!(config.update_interval_secs.is_none());\n        assert_eq!(config.update_on_changes, Some(5));\n    }\n\n    #[test]\n    fn test_summary_config_serialization_roundtrip() {\n        let config = SummaryConfig {\n            layer: MemoryLayer::Company,\n            update_interval_secs: Some(86400),\n            update_on_changes: Some(100),\n            skip_if_unchanged: true,\n            personalized: true,\n            depths: vec![\n                SummaryDepth::Sentence,\n                SummaryDepth::Paragraph,\n                SummaryDepth::Detailed,\n            ],\n        };\n\n        let json = serde_json::to_string(&config).unwrap();\n        let deserialized: SummaryConfig = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(config, deserialized);\n    }\n\n    #[test]\n    fn test_summary_config_json_structure() {\n        let config = SummaryConfig {\n            layer: MemoryLayer::User,\n            update_interval_secs: Some(600),\n            update_on_changes: None,\n            skip_if_unchanged: false,\n            personalized: true,\n            depths: vec![SummaryDepth::Sentence],\n        };\n\n        let json: serde_json::Value = serde_json::to_value(&config).unwrap();\n\n        assert!(json.get(\"layer\").is_some());\n        assert!(json.get(\"updateIntervalSecs\").is_some());\n        assert!(json.get(\"updateOnChanges\").is_some());\n        assert!(json.get(\"skipIfUnchanged\").is_some());\n        assert!(json.get(\"personalized\").is_some());\n        assert!(json.get(\"depths\").is_some());\n    }\n\n    #[test]\n    fn test_context_vector_type() {\n        let vector: ContextVector = vec![0.1, 0.2, 0.3, 0.4, 0.5];\n        assert_eq!(vector.len(), 5);\n        assert_eq!(vector[0], 0.1);\n    }\n\n    #[test]\n    fn test_memory_entry_with_summaries() {\n        let mut summaries = std::collections::HashMap::new();\n        summaries.insert(\n            SummaryDepth::Sentence,\n            LayerSummary {\n                depth: SummaryDepth::Sentence,\n                content: \"Short summary.\".to_string(),\n                token_count: 3,\n                generated_at: 1705500000,\n                source_hash: \"hash1\".to_string(),\n                content_hash: None,\n                personalized: false,\n                personalization_context: None,\n            },\n        );\n        summaries.insert(\n            SummaryDepth::Paragraph,\n            LayerSummary {\n                depth: SummaryDepth::Paragraph,\n                content: \"This is a longer paragraph summary with more details.\".to_string(),\n                token_count: 25,\n                generated_at: 1705500000,\n                source_hash: \"hash1\".to_string(),\n                content_hash: None,\n                personalized: false,\n                personalization_context: None,\n            },\n        );\n\n        let entry = MemoryEntry {\n            id: \"mem_001\".to_string(),\n            content: \"Original content that was summarized.\".to_string(),\n            embedding: Some(vec![0.1, 0.2, 0.3]),\n            layer: MemoryLayer::Project,\n            summaries,\n            context_vector: Some(vec![0.4, 0.5, 0.6]),\n            importance_score: Some(0.85),\n            metadata: std::collections::HashMap::new(),\n            created_at: 1705500000,\n            updated_at: 1705500000,\n        };\n\n        assert_eq!(entry.summaries.len(), 2);\n        assert!(entry.summaries.contains_key(&SummaryDepth::Sentence));\n        assert!(entry.summaries.contains_key(&SummaryDepth::Paragraph));\n        assert!(entry.context_vector.is_some());\n        assert_eq!(entry.context_vector.as_ref().unwrap().len(), 3);\n    }\n\n    #[test]\n    fn test_memory_entry_without_summaries() {\n        let entry = MemoryEntry {\n            id: \"mem_002\".to_string(),\n            content: \"Content without summaries yet.\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            metadata: std::collections::HashMap::new(),\n            created_at: 1705500000,\n            updated_at: 1705500000,\n        };\n\n        assert!(entry.summaries.is_empty());\n        assert!(entry.context_vector.is_none());\n    }\n\n    #[test]\n    fn test_memory_entry_serialization_with_summaries() {\n        let mut summaries = std::collections::HashMap::new();\n        summaries.insert(\n            SummaryDepth::Detailed,\n            LayerSummary {\n                depth: SummaryDepth::Detailed,\n                content: \"Detailed summary content.\".to_string(),\n                token_count: 50,\n                generated_at: 1705500000,\n                source_hash: \"hash_abc\".to_string(),\n                content_hash: None,\n                personalized: true,\n                personalization_context: Some(\"developer\".to_string()),\n            },\n        );\n\n        let entry = MemoryEntry {\n            id: \"test\".to_string(),\n            content: \"Test content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            summaries,\n            context_vector: Some(vec![1.0, 2.0]),\n            importance_score: None,\n            metadata: std::collections::HashMap::new(),\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        let json = serde_json::to_string(&entry).unwrap();\n        let deserialized: MemoryEntry = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(entry.id, deserialized.id);\n        assert_eq!(entry.summaries.len(), deserialized.summaries.len());\n        assert_eq!(entry.context_vector, deserialized.context_vector);\n    }\n\n    #[test]\n    fn test_summary_depth_all_layers_supported() {\n        let layers = vec![\n            MemoryLayer::Agent,\n            MemoryLayer::User,\n            MemoryLayer::Session,\n            MemoryLayer::Project,\n            MemoryLayer::Team,\n            MemoryLayer::Org,\n            MemoryLayer::Company,\n        ];\n\n        for layer in layers {\n            let config = SummaryConfig {\n                layer,\n                update_interval_secs: Some(3600),\n                update_on_changes: None,\n                skip_if_unchanged: true,\n                personalized: false,\n                depths: vec![SummaryDepth::Sentence],\n            };\n\n            let json = serde_json::to_string(&config).unwrap();\n            let deserialized: SummaryConfig = serde_json::from_str(&json).unwrap();\n            assert_eq!(config.layer, deserialized.layer);\n        }\n    }\n\n    #[test]\n    fn test_memory_entry_needs_summary_update_missing_summary() {\n        let entry = MemoryEntry {\n            id: \"test\".to_string(),\n            content: \"Test content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Project,\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            metadata: std::collections::HashMap::new(),\n            created_at: 1000,\n            updated_at: 1000,\n        };\n\n        let config = SummaryConfig {\n            layer: MemoryLayer::Project,\n            update_interval_secs: Some(3600),\n            update_on_changes: None,\n            skip_if_unchanged: true,\n            personalized: false,\n            depths: vec![SummaryDepth::Sentence],\n        };\n\n        assert!(entry.needs_summary_update(&config, 2000));\n    }\n\n    #[test]\n    fn test_memory_entry_needs_summary_update_stale_time() {\n        let content = \"Test content\";\n        let content_hash = {\n            use sha2::{Digest, Sha256};\n            hex::encode(Sha256::digest(content.as_bytes()))\n        };\n\n        let mut summaries = std::collections::HashMap::new();\n        summaries.insert(\n            SummaryDepth::Sentence,\n            LayerSummary {\n                depth: SummaryDepth::Sentence,\n                content: \"Summary\".to_string(),\n                token_count: 1,\n                generated_at: 1000,\n                source_hash: content_hash,\n                content_hash: None,\n                personalized: false,\n                personalization_context: None,\n            },\n        );\n\n        let entry = MemoryEntry {\n            id: \"test\".to_string(),\n            content: content.to_string(),\n            embedding: None,\n            layer: MemoryLayer::Project,\n            summaries,\n            context_vector: None,\n            importance_score: None,\n            metadata: std::collections::HashMap::new(),\n            created_at: 1000,\n            updated_at: 1000,\n        };\n\n        let config = SummaryConfig {\n            layer: MemoryLayer::Project,\n            update_interval_secs: Some(3600),\n            update_on_changes: None,\n            skip_if_unchanged: false,\n            personalized: false,\n            depths: vec![SummaryDepth::Sentence],\n        };\n\n        assert!(!entry.needs_summary_update(&config, 2000));\n        assert!(entry.needs_summary_update(&config, 5000));\n    }\n\n    #[test]\n    fn test_memory_entry_needs_summary_update_content_changed() {\n        let mut summaries = std::collections::HashMap::new();\n        summaries.insert(\n            SummaryDepth::Sentence,\n            LayerSummary {\n                depth: SummaryDepth::Sentence,\n                content: \"Summary\".to_string(),\n                token_count: 1,\n                generated_at: 1000,\n                source_hash: \"old_hash\".to_string(),\n                content_hash: None,\n                personalized: false,\n                personalization_context: None,\n            },\n        );\n\n        let entry = MemoryEntry {\n            id: \"test\".to_string(),\n            content: \"New content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Project,\n            summaries,\n            context_vector: None,\n            importance_score: None,\n            metadata: std::collections::HashMap::new(),\n            created_at: 1000,\n            updated_at: 2000,\n        };\n\n        let config = SummaryConfig {\n            layer: MemoryLayer::Project,\n            update_interval_secs: Some(3600),\n            update_on_changes: None,\n            skip_if_unchanged: true,\n            personalized: false,\n            depths: vec![SummaryDepth::Sentence],\n        };\n\n        assert!(entry.needs_summary_update(&config, 1500));\n    }\n\n    #[test]\n    fn test_memory_entry_needs_summary_update_no_update_needed() {\n        let content = \"Same content\";\n        let content_hash = {\n            use sha2::{Digest, Sha256};\n            hex::encode(Sha256::digest(content.as_bytes()))\n        };\n\n        let mut summaries = std::collections::HashMap::new();\n        summaries.insert(\n            SummaryDepth::Sentence,\n            LayerSummary {\n                depth: SummaryDepth::Sentence,\n                content: \"Summary\".to_string(),\n                token_count: 1,\n                generated_at: 1000,\n                source_hash: content_hash,\n                content_hash: None,\n                personalized: false,\n                personalization_context: None,\n            },\n        );\n\n        let entry = MemoryEntry {\n            id: \"test\".to_string(),\n            content: content.to_string(),\n            embedding: None,\n            layer: MemoryLayer::Project,\n            summaries,\n            context_vector: None,\n            importance_score: None,\n            metadata: std::collections::HashMap::new(),\n            created_at: 1000,\n            updated_at: 1000,\n        };\n\n        let config = SummaryConfig {\n            layer: MemoryLayer::Project,\n            update_interval_secs: Some(3600),\n            update_on_changes: None,\n            skip_if_unchanged: true,\n            personalized: false,\n            depths: vec![SummaryDepth::Sentence],\n        };\n\n        assert!(!entry.needs_summary_update(&config, 2000));\n    }\n\n    #[test]\n    fn test_memory_entry_compute_content_hash() {\n        let entry = MemoryEntry {\n            id: \"test\".to_string(),\n            content: \"Test content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            metadata: std::collections::HashMap::new(),\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        let hash = entry.compute_content_hash();\n        assert!(!hash.is_empty());\n        assert_eq!(hash.len(), 64);\n\n        let hash2 = entry.compute_content_hash();\n        assert_eq!(hash, hash2);\n    }\n\n    #[test]\n    fn test_memory_entry_compute_content_hash_different_content() {\n        let entry1 = MemoryEntry {\n            id: \"test1\".to_string(),\n            content: \"Content A\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            metadata: std::collections::HashMap::new(),\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        let entry2 = MemoryEntry {\n            id: \"test2\".to_string(),\n            content: \"Content B\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            metadata: std::collections::HashMap::new(),\n            created_at: 0,\n            updated_at: 0,\n        };\n\n        assert_ne!(entry1.compute_content_hash(), entry2.compute_content_hash());\n    }\n\n    #[test]\n    fn test_knowledge_type_hindsight_variant() {\n        let hindsight = KnowledgeType::Hindsight;\n        let json = serde_json::to_string(&hindsight).unwrap();\n        assert_eq!(json, \"\\\"hindsight\\\"\");\n\n        let parsed: KnowledgeType = serde_json::from_str(&json).unwrap();\n        assert_eq!(parsed, KnowledgeType::Hindsight);\n    }\n\n    #[test]\n    fn test_error_signature_creation() {\n        let sig = ErrorSignature {\n            error_type: \"NullPointerException\".to_string(),\n            message_pattern: \"Cannot read property '.*' of undefined\".to_string(),\n            stack_patterns: vec![\"at UserService\".to_string(), \"at AuthHandler\".to_string()],\n            context_patterns: vec![\"typescript\".to_string(), \"react\".to_string()],\n            embedding: Some(vec![0.1, 0.2, 0.3]),\n        };\n\n        assert_eq!(sig.error_type, \"NullPointerException\");\n        assert_eq!(sig.stack_patterns.len(), 2);\n        assert!(sig.embedding.is_some());\n    }\n\n    #[test]\n    fn test_error_signature_serialization() {\n        let sig = ErrorSignature {\n            error_type: \"TypeError\".to_string(),\n            message_pattern: \".*is not a function\".to_string(),\n            stack_patterns: vec![],\n            context_patterns: vec![\"javascript\".to_string()],\n            embedding: None,\n        };\n\n        let json = serde_json::to_string(&sig).unwrap();\n        assert!(json.contains(\"\\\"errorType\\\"\"));\n        assert!(json.contains(\"\\\"messagePattern\\\"\"));\n\n        let parsed: ErrorSignature = serde_json::from_str(&json).unwrap();\n        assert_eq!(parsed.error_type, sig.error_type);\n    }\n\n    #[test]\n    fn test_code_change_creation() {\n        let change = CodeChange {\n            file_path: \"src/auth.rs\".to_string(),\n            diff: \"+ if let Some(token) = token_option {\\n+     // handle\\n+ }\".to_string(),\n            description: Some(\"Added null check for token\".to_string()),\n        };\n\n        assert_eq!(change.file_path, \"src/auth.rs\");\n        assert!(change.description.is_some());\n    }\n\n    #[test]\n    fn test_resolution_creation() {\n        let resolution = Resolution {\n            id: \"res_001\".to_string(),\n            error_signature_id: \"sig_001\".to_string(),\n            description: \"Add null check before accessing token fields\".to_string(),\n            changes: vec![CodeChange {\n                file_path: \"src/auth.rs\".to_string(),\n                diff: \"+ if token.is_some()\".to_string(),\n                description: None,\n            }],\n            success_rate: 0.95,\n            application_count: 12,\n            last_success_at: 1705500000,\n        };\n\n        assert_eq!(resolution.success_rate, 0.95);\n        assert_eq!(resolution.application_count, 12);\n        assert_eq!(resolution.changes.len(), 1);\n    }\n\n    #[test]\n    fn test_resolution_serialization() {\n        let resolution = Resolution {\n            id: \"res_002\".to_string(),\n            error_signature_id: \"sig_002\".to_string(),\n            description: \"Fix\".to_string(),\n            changes: vec![],\n            success_rate: 1.0,\n            application_count: 5,\n            last_success_at: 1705600000,\n        };\n\n        let json = serde_json::to_string(&resolution).unwrap();\n        assert!(json.contains(\"\\\"successRate\\\"\"));\n        assert!(json.contains(\"\\\"applicationCount\\\"\"));\n\n        let parsed: Resolution = serde_json::from_str(&json).unwrap();\n        assert_eq!(parsed.id, resolution.id);\n    }\n\n    #[test]\n    fn test_hindsight_note_creation() {\n        let note = HindsightNote {\n            id: \"hn_001\".to_string(),\n            error_signature: ErrorSignature {\n                error_type: \"CompileError\".to_string(),\n                message_pattern: \"missing lifetime specifier\".to_string(),\n                stack_patterns: vec![],\n                context_patterns: vec![\"rust\".to_string()],\n                embedding: None,\n            },\n            resolutions: vec![Resolution {\n                id: \"res_001\".to_string(),\n                error_signature_id: \"sig_001\".to_string(),\n                description: \"Add explicit lifetime annotation\".to_string(),\n                changes: vec![],\n                success_rate: 0.88,\n                application_count: 8,\n                last_success_at: 1705500000,\n            }],\n            content: \"# Rust Lifetime Error\\n\\nWhen encountering...\".to_string(),\n            tags: vec![\n                \"rust\".to_string(),\n                \"lifetimes\".to_string(),\n                \"borrow-checker\".to_string(),\n            ],\n            created_at: 1705400000,\n            updated_at: 1705500000,\n        };\n\n        assert_eq!(note.id, \"hn_001\");\n        assert_eq!(note.resolutions.len(), 1);\n        assert_eq!(note.tags.len(), 3);\n    }\n\n    #[test]\n    fn test_hindsight_note_serialization_roundtrip() {\n        let note = HindsightNote {\n            id: \"hn_002\".to_string(),\n            error_signature: ErrorSignature {\n                error_type: \"RuntimeError\".to_string(),\n                message_pattern: \"index out of bounds\".to_string(),\n                stack_patterns: vec![\"at main\".to_string()],\n                context_patterns: vec![\"rust\".to_string()],\n                embedding: Some(vec![0.5, 0.6]),\n            },\n            resolutions: vec![],\n            content: \"# Array Bounds Error\".to_string(),\n            tags: vec![\"rust\".to_string()],\n            created_at: 1705400000,\n            updated_at: 1705400000,\n        };\n\n        let json = serde_json::to_string(&note).unwrap();\n        let parsed: HindsightNote = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(parsed.id, note.id);\n        assert_eq!(\n            parsed.error_signature.error_type,\n            note.error_signature.error_type\n        );\n        assert_eq!(parsed.tags, note.tags);\n    }\n}\n","traces":[{"line":52,"address":[],"length":0,"stats":{"Line":2639}},{"line":53,"address":[],"length":0,"stats":{"Line":7911}},{"line":54,"address":[],"length":0,"stats":{"Line":13}},{"line":56,"address":[],"length":0,"stats":{"Line":2626}},{"line":60,"address":[],"length":0,"stats":{"Line":3005}},{"line":61,"address":[],"length":0,"stats":{"Line":3005}},{"line":64,"address":[],"length":0,"stats":{"Line":1}},{"line":65,"address":[],"length":0,"stats":{"Line":1}},{"line":70,"address":[],"length":0,"stats":{"Line":1187}},{"line":71,"address":[],"length":0,"stats":{"Line":3561}},{"line":76,"address":[],"length":0,"stats":{"Line":2312}},{"line":77,"address":[],"length":0,"stats":{"Line":2312}},{"line":83,"address":[],"length":0,"stats":{"Line":1432}},{"line":84,"address":[],"length":0,"stats":{"Line":5730}},{"line":89,"address":[],"length":0,"stats":{"Line":2178}},{"line":91,"address":[],"length":0,"stats":{"Line":4356}},{"line":92,"address":[],"length":0,"stats":{"Line":2178}},{"line":105,"address":[],"length":0,"stats":{"Line":953}},{"line":106,"address":[],"length":0,"stats":{"Line":2857}},{"line":107,"address":[],"length":0,"stats":{"Line":3}},{"line":109,"address":[],"length":0,"stats":{"Line":950}},{"line":113,"address":[],"length":0,"stats":{"Line":596}},{"line":114,"address":[],"length":0,"stats":{"Line":596}},{"line":117,"address":[],"length":0,"stats":{"Line":1}},{"line":118,"address":[],"length":0,"stats":{"Line":1}},{"line":123,"address":[],"length":0,"stats":{"Line":1}},{"line":124,"address":[],"length":0,"stats":{"Line":3}},{"line":130,"address":[],"length":0,"stats":{"Line":178}},{"line":131,"address":[],"length":0,"stats":{"Line":714}},{"line":136,"address":[],"length":0,"stats":{"Line":2306}},{"line":137,"address":[],"length":0,"stats":{"Line":2306}},{"line":149,"address":[],"length":0,"stats":{"Line":889}},{"line":157,"address":[],"length":0,"stats":{"Line":5}},{"line":161,"address":[],"length":0,"stats":{"Line":5}},{"line":175,"address":[],"length":0,"stats":{"Line":1}},{"line":184,"address":[],"length":0,"stats":{"Line":1}},{"line":187,"address":[],"length":0,"stats":{"Line":2}},{"line":193,"address":[],"length":0,"stats":{"Line":1}},{"line":196,"address":[],"length":0,"stats":{"Line":2}},{"line":197,"address":[],"length":0,"stats":{"Line":1}},{"line":202,"address":[],"length":0,"stats":{"Line":2}},{"line":205,"address":[],"length":0,"stats":{"Line":4}},{"line":206,"address":[],"length":0,"stats":{"Line":2}},{"line":207,"address":[],"length":0,"stats":{"Line":2}},{"line":211,"address":[],"length":0,"stats":{"Line":4}},{"line":212,"address":[],"length":0,"stats":{"Line":8}},{"line":213,"address":[],"length":0,"stats":{"Line":1}},{"line":214,"address":[],"length":0,"stats":{"Line":6}},{"line":215,"address":[],"length":0,"stats":{"Line":1}},{"line":216,"address":[],"length":0,"stats":{"Line":4}},{"line":217,"address":[],"length":0,"stats":{"Line":1}},{"line":219,"address":[],"length":0,"stats":{"Line":1}},{"line":223,"address":[],"length":0,"stats":{"Line":1}},{"line":224,"address":[],"length":0,"stats":{"Line":4}},{"line":225,"address":[],"length":0,"stats":{"Line":3}},{"line":226,"address":[],"length":0,"stats":{"Line":3}},{"line":228,"address":[],"length":0,"stats":{"Line":3}},{"line":229,"address":[],"length":0,"stats":{"Line":3}},{"line":231,"address":[],"length":0,"stats":{"Line":3}},{"line":232,"address":[],"length":0,"stats":{"Line":3}},{"line":234,"address":[],"length":0,"stats":{"Line":2}},{"line":240,"address":[],"length":0,"stats":{"Line":5}},{"line":241,"address":[],"length":0,"stats":{"Line":5}},{"line":242,"address":[],"length":0,"stats":{"Line":1}},{"line":243,"address":[],"length":0,"stats":{"Line":1}},{"line":244,"address":[],"length":0,"stats":{"Line":1}},{"line":245,"address":[],"length":0,"stats":{"Line":1}},{"line":246,"address":[],"length":0,"stats":{"Line":1}},{"line":251,"address":[],"length":0,"stats":{"Line":5}},{"line":252,"address":[],"length":0,"stats":{"Line":5}},{"line":253,"address":[],"length":0,"stats":{"Line":1}},{"line":254,"address":[],"length":0,"stats":{"Line":1}},{"line":255,"address":[],"length":0,"stats":{"Line":1}},{"line":256,"address":[],"length":0,"stats":{"Line":1}},{"line":257,"address":[],"length":0,"stats":{"Line":1}},{"line":366,"address":[],"length":0,"stats":{"Line":751}},{"line":367,"address":[],"length":0,"stats":{"Line":751}},{"line":368,"address":[],"length":0,"stats":{"Line":5}},{"line":369,"address":[],"length":0,"stats":{"Line":431}},{"line":370,"address":[],"length":0,"stats":{"Line":155}},{"line":371,"address":[],"length":0,"stats":{"Line":157}},{"line":372,"address":[],"length":0,"stats":{"Line":1}},{"line":373,"address":[],"length":0,"stats":{"Line":1}},{"line":374,"address":[],"length":0,"stats":{"Line":1}},{"line":379,"address":[],"length":0,"stats":{"Line":29}},{"line":380,"address":[],"length":0,"stats":{"Line":29}},{"line":381,"address":[],"length":0,"stats":{"Line":1}},{"line":382,"address":[],"length":0,"stats":{"Line":1}},{"line":383,"address":[],"length":0,"stats":{"Line":19}},{"line":384,"address":[],"length":0,"stats":{"Line":3}},{"line":385,"address":[],"length":0,"stats":{"Line":3}},{"line":386,"address":[],"length":0,"stats":{"Line":1}},{"line":387,"address":[],"length":0,"stats":{"Line":1}},{"line":544,"address":[],"length":0,"stats":{"Line":15}},{"line":547,"address":[],"length":0,"stats":{"Line":42}},{"line":548,"address":[],"length":0,"stats":{"Line":52}},{"line":549,"address":[],"length":0,"stats":{"Line":70}},{"line":550,"address":[],"length":0,"stats":{"Line":28}},{"line":552,"address":[],"length":0,"stats":{"Line":14}},{"line":553,"address":[],"length":0,"stats":{"Line":3}},{"line":556,"address":[],"length":0,"stats":{"Line":11}},{"line":557,"address":[],"length":0,"stats":{"Line":1}},{"line":560,"address":[],"length":0,"stats":{"Line":20}},{"line":561,"address":[],"length":0,"stats":{"Line":20}},{"line":562,"address":[],"length":0,"stats":{"Line":10}},{"line":563,"address":[],"length":0,"stats":{"Line":3}},{"line":567,"address":[],"length":0,"stats":{"Line":5}},{"line":570,"address":[],"length":0,"stats":{"Line":4}},{"line":573,"address":[],"length":0,"stats":{"Line":10}},{"line":575,"address":[],"length":0,"stats":{"Line":40}},{"line":578,"address":[],"length":0,"stats":{"Line":0}},{"line":579,"address":[],"length":0,"stats":{"Line":0}},{"line":583,"address":[],"length":0,"stats":{"Line":32}},{"line":585,"address":[],"length":0,"stats":{"Line":128}},{"line":875,"address":[],"length":0,"stats":{"Line":51}},{"line":876,"address":[],"length":0,"stats":{"Line":51}},{"line":877,"address":[],"length":0,"stats":{"Line":76}},{"line":878,"address":[],"length":0,"stats":{"Line":6}},{"line":879,"address":[],"length":0,"stats":{"Line":6}},{"line":880,"address":[],"length":0,"stats":{"Line":2}},{"line":881,"address":[],"length":0,"stats":{"Line":2}},{"line":882,"address":[],"length":0,"stats":{"Line":2}},{"line":883,"address":[],"length":0,"stats":{"Line":2}},{"line":884,"address":[],"length":0,"stats":{"Line":6}},{"line":885,"address":[],"length":0,"stats":{"Line":0}},{"line":886,"address":[],"length":0,"stats":{"Line":0}},{"line":887,"address":[],"length":0,"stats":{"Line":0}},{"line":888,"address":[],"length":0,"stats":{"Line":0}},{"line":908,"address":[],"length":0,"stats":{"Line":40}},{"line":909,"address":[],"length":0,"stats":{"Line":120}},{"line":916,"address":[],"length":0,"stats":{"Line":80}},{"line":918,"address":[],"length":0,"stats":{"Line":40}},{"line":922,"address":[],"length":0,"stats":{"Line":30}},{"line":923,"address":[],"length":0,"stats":{"Line":30}},{"line":924,"address":[],"length":0,"stats":{"Line":30}},{"line":925,"address":[],"length":0,"stats":{"Line":30}},{"line":928,"address":[],"length":0,"stats":{"Line":30}},{"line":929,"address":[],"length":0,"stats":{"Line":60}},{"line":930,"address":[],"length":0,"stats":{"Line":30}},{"line":933,"address":[],"length":0,"stats":{"Line":40}},{"line":934,"address":[],"length":0,"stats":{"Line":80}},{"line":935,"address":[],"length":0,"stats":{"Line":23}},{"line":937,"address":[],"length":0,"stats":{"Line":17}},{"line":939,"address":[],"length":0,"stats":{"Line":39}},{"line":940,"address":[],"length":0,"stats":{"Line":5}},{"line":941,"address":[],"length":0,"stats":{"Line":13}},{"line":942,"address":[],"length":0,"stats":{"Line":4}},{"line":948,"address":[],"length":0,"stats":{"Line":1}},{"line":949,"address":[],"length":0,"stats":{"Line":2}},{"line":952,"address":[],"length":0,"stats":{"Line":1}},{"line":953,"address":[],"length":0,"stats":{"Line":2}},{"line":973,"address":[],"length":0,"stats":{"Line":18}},{"line":981,"address":[],"length":0,"stats":{"Line":54}},{"line":989,"address":[],"length":0,"stats":{"Line":18}},{"line":993,"address":[],"length":0,"stats":{"Line":7}},{"line":994,"address":[],"length":0,"stats":{"Line":14}},{"line":995,"address":[],"length":0,"stats":{"Line":7}},{"line":998,"address":[],"length":0,"stats":{"Line":5}},{"line":999,"address":[],"length":0,"stats":{"Line":5}},{"line":1000,"address":[],"length":0,"stats":{"Line":5}},{"line":1003,"address":[],"length":0,"stats":{"Line":3}},{"line":1004,"address":[],"length":0,"stats":{"Line":5}},{"line":1005,"address":[],"length":0,"stats":{"Line":4}},{"line":1007,"address":[],"length":0,"stats":{"Line":1}},{"line":1011,"address":[],"length":0,"stats":{"Line":14}},{"line":1012,"address":[],"length":0,"stats":{"Line":14}},{"line":1013,"address":[],"length":0,"stats":{"Line":3}},{"line":1015,"address":[],"length":0,"stats":{"Line":17}},{"line":1016,"address":[],"length":0,"stats":{"Line":12}},{"line":1017,"address":[],"length":0,"stats":{"Line":18}},{"line":1020,"address":[],"length":0,"stats":{"Line":5}},{"line":1037,"address":[],"length":0,"stats":{"Line":88}},{"line":1039,"address":[],"length":0,"stats":{"Line":176}},{"line":1040,"address":[],"length":0,"stats":{"Line":176}},{"line":1044,"address":[],"length":0,"stats":{"Line":88}},{"line":1050,"address":[],"length":0,"stats":{"Line":5}},{"line":1058,"address":[],"length":0,"stats":{"Line":1}},{"line":1059,"address":[],"length":0,"stats":{"Line":3}},{"line":1062,"address":[],"length":0,"stats":{"Line":3}},{"line":1063,"address":[],"length":0,"stats":{"Line":3}},{"line":1064,"address":[],"length":0,"stats":{"Line":3}},{"line":1068,"address":[],"length":0,"stats":{"Line":5}},{"line":1069,"address":[],"length":0,"stats":{"Line":10}},{"line":1070,"address":[],"length":0,"stats":{"Line":2}},{"line":1072,"address":[],"length":0,"stats":{"Line":3}},{"line":1073,"address":[],"length":0,"stats":{"Line":1}},{"line":1075,"address":[],"length":0,"stats":{"Line":2}},{"line":1078,"address":[],"length":0,"stats":{"Line":3}},{"line":1079,"address":[],"length":0,"stats":{"Line":6}},{"line":1080,"address":[],"length":0,"stats":{"Line":1}},{"line":1081,"address":[],"length":0,"stats":{"Line":1}},{"line":1084,"address":[],"length":0,"stats":{"Line":2}},{"line":1087,"address":[],"length":0,"stats":{"Line":3}},{"line":1088,"address":[],"length":0,"stats":{"Line":6}},{"line":1089,"address":[],"length":0,"stats":{"Line":1}},{"line":1090,"address":[],"length":0,"stats":{"Line":1}},{"line":1093,"address":[],"length":0,"stats":{"Line":2}},{"line":1096,"address":[],"length":0,"stats":{"Line":3}},{"line":1097,"address":[],"length":0,"stats":{"Line":6}},{"line":1098,"address":[],"length":0,"stats":{"Line":1}},{"line":1100,"address":[],"length":0,"stats":{"Line":2}},{"line":1103,"address":[],"length":0,"stats":{"Line":3}},{"line":1104,"address":[],"length":0,"stats":{"Line":6}},{"line":1105,"address":[],"length":0,"stats":{"Line":1}},{"line":1107,"address":[],"length":0,"stats":{"Line":2}},{"line":1110,"address":[],"length":0,"stats":{"Line":3}},{"line":1111,"address":[],"length":0,"stats":{"Line":6}},{"line":1112,"address":[],"length":0,"stats":{"Line":1}},{"line":1113,"address":[],"length":0,"stats":{"Line":1}},{"line":1116,"address":[],"length":0,"stats":{"Line":2}},{"line":1119,"address":[],"length":0,"stats":{"Line":5}},{"line":1120,"address":[],"length":0,"stats":{"Line":10}},{"line":1121,"address":[],"length":0,"stats":{"Line":1}},{"line":1123,"address":[],"length":0,"stats":{"Line":4}},{"line":1124,"address":[],"length":0,"stats":{"Line":1}},{"line":1126,"address":[],"length":0,"stats":{"Line":3}},{"line":1139,"address":[],"length":0,"stats":{"Line":8}},{"line":1140,"address":[],"length":0,"stats":{"Line":8}},{"line":1141,"address":[],"length":0,"stats":{"Line":6}},{"line":1142,"address":[],"length":0,"stats":{"Line":6}},{"line":1143,"address":[],"length":0,"stats":{"Line":6}},{"line":1144,"address":[],"length":0,"stats":{"Line":6}},{"line":1169,"address":[],"length":0,"stats":{"Line":43}},{"line":1170,"address":[],"length":0,"stats":{"Line":129}},{"line":1171,"address":[],"length":0,"stats":{"Line":129}},{"line":1172,"address":[],"length":0,"stats":{"Line":129}},{"line":1173,"address":[],"length":0,"stats":{"Line":215}},{"line":1174,"address":[],"length":0,"stats":{"Line":129}},{"line":1177,"address":[],"length":0,"stats":{"Line":129}},{"line":1194,"address":[],"length":0,"stats":{"Line":43}},{"line":1196,"address":[],"length":0,"stats":{"Line":215}},{"line":1197,"address":[],"length":0,"stats":{"Line":172}},{"line":1198,"address":[],"length":0,"stats":{"Line":86}},{"line":1201,"address":[],"length":0,"stats":{"Line":43}},{"line":1202,"address":[],"length":0,"stats":{"Line":43}},{"line":1203,"address":[],"length":0,"stats":{"Line":74}},{"line":1204,"address":[],"length":0,"stats":{"Line":4}},{"line":1205,"address":[],"length":0,"stats":{"Line":4}},{"line":1206,"address":[],"length":0,"stats":{"Line":0}},{"line":1207,"address":[],"length":0,"stats":{"Line":0}},{"line":1208,"address":[],"length":0,"stats":{"Line":0}},{"line":1209,"address":[],"length":0,"stats":{"Line":0}},{"line":1210,"address":[],"length":0,"stats":{"Line":4}},{"line":1211,"address":[],"length":0,"stats":{"Line":0}},{"line":1212,"address":[],"length":0,"stats":{"Line":0}},{"line":1213,"address":[],"length":0,"stats":{"Line":0}},{"line":1214,"address":[],"length":0,"stats":{"Line":0}},{"line":1218,"address":[],"length":0,"stats":{"Line":5}},{"line":1219,"address":[],"length":0,"stats":{"Line":5}},{"line":1220,"address":[],"length":0,"stats":{"Line":5}},{"line":1223,"address":[],"length":0,"stats":{"Line":3}},{"line":1224,"address":[],"length":0,"stats":{"Line":3}},{"line":1225,"address":[],"length":0,"stats":{"Line":3}},{"line":1228,"address":[],"length":0,"stats":{"Line":23}},{"line":1229,"address":[],"length":0,"stats":{"Line":23}},{"line":1230,"address":[],"length":0,"stats":{"Line":46}},{"line":1232,"address":[],"length":0,"stats":{"Line":23}},{"line":1233,"address":[],"length":0,"stats":{"Line":6}},{"line":1234,"address":[],"length":0,"stats":{"Line":6}},{"line":1235,"address":[],"length":0,"stats":{"Line":6}},{"line":1237,"address":[],"length":0,"stats":{"Line":17}},{"line":1238,"address":[],"length":0,"stats":{"Line":17}},{"line":1242,"address":[],"length":0,"stats":{"Line":16}},{"line":1243,"address":[],"length":0,"stats":{"Line":29}},{"line":1262,"address":[],"length":0,"stats":{"Line":6}},{"line":1281,"address":[],"length":0,"stats":{"Line":6}},{"line":1282,"address":[],"length":0,"stats":{"Line":6}},{"line":1283,"address":[],"length":0,"stats":{"Line":3}},{"line":1285,"address":[],"length":0,"stats":{"Line":3}},{"line":1298,"address":[],"length":0,"stats":{"Line":7}},{"line":1303,"address":[],"length":0,"stats":{"Line":7}},{"line":1324,"address":[],"length":0,"stats":{"Line":7}},{"line":1339,"address":[],"length":0,"stats":{"Line":7}},{"line":1340,"address":[],"length":0,"stats":{"Line":7}},{"line":1341,"address":[],"length":0,"stats":{"Line":7}},{"line":1342,"address":[],"length":0,"stats":{"Line":7}},{"line":1343,"address":[],"length":0,"stats":{"Line":12}},{"line":1344,"address":[],"length":0,"stats":{"Line":5}},{"line":1345,"address":[],"length":0,"stats":{"Line":5}},{"line":1347,"address":[],"length":0,"stats":{"Line":2}},{"line":1351,"address":[],"length":0,"stats":{"Line":1}},{"line":1352,"address":[],"length":0,"stats":{"Line":1}},{"line":1355,"address":[],"length":0,"stats":{"Line":1}},{"line":1356,"address":[],"length":0,"stats":{"Line":1}},{"line":1357,"address":[],"length":0,"stats":{"Line":1}},{"line":1360,"address":[],"length":0,"stats":{"Line":2}},{"line":1361,"address":[],"length":0,"stats":{"Line":2}},{"line":1362,"address":[],"length":0,"stats":{"Line":1}},{"line":1364,"address":[],"length":0,"stats":{"Line":1}},{"line":1368,"address":[],"length":0,"stats":{"Line":2}},{"line":1369,"address":[],"length":0,"stats":{"Line":2}},{"line":1370,"address":[],"length":0,"stats":{"Line":1}},{"line":1372,"address":[],"length":0,"stats":{"Line":1}},{"line":1391,"address":[],"length":0,"stats":{"Line":6}},{"line":1395,"address":[],"length":0,"stats":{"Line":18}},{"line":1400,"address":[],"length":0,"stats":{"Line":6}},{"line":1404,"address":[],"length":0,"stats":{"Line":2}},{"line":1405,"address":[],"length":0,"stats":{"Line":2}},{"line":1406,"address":[],"length":0,"stats":{"Line":2}},{"line":1407,"address":[],"length":0,"stats":{"Line":2}},{"line":1410,"address":[],"length":0,"stats":{"Line":1}},{"line":1411,"address":[],"length":0,"stats":{"Line":2}},{"line":1412,"address":[],"length":0,"stats":{"Line":1}},{"line":1415,"address":[],"length":0,"stats":{"Line":1}},{"line":1416,"address":[],"length":0,"stats":{"Line":2}},{"line":1417,"address":[],"length":0,"stats":{"Line":1}},{"line":1420,"address":[],"length":0,"stats":{"Line":2}},{"line":1421,"address":[],"length":0,"stats":{"Line":2}},{"line":1422,"address":[],"length":0,"stats":{"Line":3}}],"covered":295,"coverable":309},{"path":["/","Users","christian.klat","dev","git","aeterna","opal-fetcher","src","entities.rs"],"content":"//! Cedar entity transformation from PostgreSQL rows.\n//!\n//! This module transforms organizational data from PostgreSQL into Cedar entity format\n//! that can be consumed by OPAL and Cedar Agent for authorization decisions.\n\nuse chrono::{DateTime, Utc};\nuse serde::{Deserialize, Serialize};\nuse sqlx::FromRow;\nuse uuid::Uuid;\n\nuse crate::error::Result;\n\n// ============================================================================\n// Database Row Types\n// ============================================================================\n\n/// Row from the v_hierarchy view.\n#[derive(Debug, Clone, FromRow)]\npub struct HierarchyRow {\n    pub company_id: Option<Uuid>,\n    pub company_slug: Option<String>,\n    pub company_name: Option<String>,\n    pub org_id: Option<Uuid>,\n    pub org_slug: Option<String>,\n    pub org_name: Option<String>,\n    pub team_id: Option<Uuid>,\n    pub team_slug: Option<String>,\n    pub team_name: Option<String>,\n    pub project_id: Option<Uuid>,\n    pub project_slug: Option<String>,\n    pub project_name: Option<String>,\n    pub git_remote: Option<String>,\n}\n\n/// Row from the v_user_permissions view.\n#[derive(Debug, Clone, FromRow)]\npub struct UserPermissionRow {\n    pub user_id: Uuid,\n    pub email: String,\n    pub user_name: Option<String>,\n    pub user_status: String,\n    pub team_id: Uuid,\n    pub role: String,\n    pub permissions: serde_json::Value,\n    pub org_id: Uuid,\n    pub company_id: Uuid,\n    pub company_slug: String,\n    pub org_slug: String,\n    pub team_slug: String,\n}\n\n/// Row from the v_agent_permissions view.\n#[derive(Debug, Clone, FromRow)]\npub struct AgentPermissionRow {\n    pub agent_id: Uuid,\n    pub agent_name: String,\n    pub agent_type: String,\n    pub delegated_by_user_id: Option<Uuid>,\n    pub delegated_by_agent_id: Option<Uuid>,\n    pub delegation_depth: i32,\n    pub capabilities: serde_json::Value,\n    pub allowed_company_ids: Option<Vec<Uuid>>,\n    pub allowed_org_ids: Option<Vec<Uuid>>,\n    pub allowed_team_ids: Option<Vec<Uuid>>,\n    pub allowed_project_ids: Option<Vec<Uuid>>,\n    pub agent_status: String,\n    pub delegating_user_email: Option<String>,\n    pub delegating_user_name: Option<String>,\n}\n\n// ============================================================================\n// Cedar Entity Types\n// ============================================================================\n\n/// A Cedar entity with type, ID, attributes, and parent relationships.\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\npub struct CedarEntity {\n    /// Entity UID in format \"Type::\\\"id\\\"\".\n    pub uid: CedarEntityUid,\n    /// Entity attributes.\n    pub attrs: serde_json::Value,\n    /// Parent entity UIDs (for hierarchy).\n    pub parents: Vec<CedarEntityUid>,\n}\n\n/// Cedar entity UID structure.\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\npub struct CedarEntityUid {\n    #[serde(rename = \"type\")]\n    pub entity_type: String,\n    pub id: String,\n}\n\nimpl CedarEntityUid {\n    /// Creates a new entity UID.\n    #[must_use]\n    pub fn new(entity_type: impl Into<String>, id: impl Into<String>) -> Self {\n        Self {\n            entity_type: entity_type.into(),\n            id: id.into(),\n        }\n    }\n}\n\n/// Response containing Cedar entities for OPAL.\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct CedarEntitiesResponse {\n    /// List of Cedar entities.\n    pub entities: Vec<CedarEntity>,\n    /// Timestamp of the response.\n    pub timestamp: DateTime<Utc>,\n    /// Number of entities.\n    pub count: usize,\n}\n\nimpl CedarEntitiesResponse {\n    /// Creates a new response with the given entities.\n    #[must_use]\n    pub fn new(entities: Vec<CedarEntity>) -> Self {\n        let count = entities.len();\n        Self {\n            entities,\n            timestamp: Utc::now(),\n            count,\n        }\n    }\n}\n\n// ============================================================================\n// Entity Transformation Functions\n// ============================================================================\n\n/// Transforms hierarchy rows into Cedar entities.\n///\n/// Creates entities for: Company, Organization, Team, Project\n/// with proper parent relationships (in Cedar format).\npub fn transform_hierarchy(rows: Vec<HierarchyRow>) -> Result<Vec<CedarEntity>> {\n    let mut entities: Vec<CedarEntity> = Vec::new();\n    let mut seen_companies = std::collections::HashSet::new();\n    let mut seen_orgs = std::collections::HashSet::new();\n    let mut seen_teams = std::collections::HashSet::new();\n    let mut seen_projects = std::collections::HashSet::new();\n\n    for row in rows {\n        // Company entity\n        if let (Some(id), Some(slug), Some(name)) =\n            (&row.company_id, &row.company_slug, &row.company_name)\n        {\n            if seen_companies.insert(*id) {\n                entities.push(CedarEntity {\n                    uid: CedarEntityUid::new(\"Aeterna::Company\", id.to_string()),\n                    attrs: serde_json::json!({\n                        \"slug\": slug,\n                        \"name\": name,\n                    }),\n                    parents: vec![],\n                });\n            }\n        }\n\n        // Organization entity\n        if let (Some(id), Some(slug), Some(name), Some(company_id)) =\n            (&row.org_id, &row.org_slug, &row.org_name, &row.company_id)\n        {\n            if seen_orgs.insert(*id) {\n                entities.push(CedarEntity {\n                    uid: CedarEntityUid::new(\"Aeterna::Organization\", id.to_string()),\n                    attrs: serde_json::json!({\n                        \"slug\": slug,\n                        \"name\": name,\n                    }),\n                    parents: vec![CedarEntityUid::new(\n                        \"Aeterna::Company\",\n                        company_id.to_string(),\n                    )],\n                });\n            }\n        }\n\n        // Team entity\n        if let (Some(id), Some(slug), Some(name), Some(org_id)) =\n            (&row.team_id, &row.team_slug, &row.team_name, &row.org_id)\n        {\n            if seen_teams.insert(*id) {\n                entities.push(CedarEntity {\n                    uid: CedarEntityUid::new(\"Aeterna::Team\", id.to_string()),\n                    attrs: serde_json::json!({\n                        \"slug\": slug,\n                        \"name\": name,\n                    }),\n                    parents: vec![CedarEntityUid::new(\n                        \"Aeterna::Organization\",\n                        org_id.to_string(),\n                    )],\n                });\n            }\n        }\n\n        // Project entity\n        if let (Some(id), Some(slug), Some(name), Some(team_id)) = (\n            &row.project_id,\n            &row.project_slug,\n            &row.project_name,\n            &row.team_id,\n        ) {\n            if seen_projects.insert(*id) {\n                let mut attrs = serde_json::json!({\n                    \"slug\": slug,\n                    \"name\": name,\n                });\n                if let Some(git_remote) = &row.git_remote {\n                    attrs[\"git_remote\"] = serde_json::json!(git_remote);\n                }\n                entities.push(CedarEntity {\n                    uid: CedarEntityUid::new(\"Aeterna::Project\", id.to_string()),\n                    attrs,\n                    parents: vec![CedarEntityUid::new(\"Aeterna::Team\", team_id.to_string())],\n                });\n            }\n        }\n    }\n\n    Ok(entities)\n}\n\n/// Transforms user permission rows into Cedar entities.\n///\n/// Creates User entities with role and membership information.\npub fn transform_users(rows: Vec<UserPermissionRow>) -> Result<Vec<CedarEntity>> {\n    let mut entities: Vec<CedarEntity> = Vec::new();\n    let mut user_teams: std::collections::HashMap<Uuid, Vec<CedarEntityUid>> =\n        std::collections::HashMap::new();\n    let mut user_info: std::collections::HashMap<Uuid, (String, Option<String>, String)> =\n        std::collections::HashMap::new();\n\n    // Collect all team memberships per user\n    for row in &rows {\n        let team_uid = CedarEntityUid::new(\"Aeterna::Team\", row.team_id.to_string());\n        user_teams.entry(row.user_id).or_default().push(team_uid);\n        user_info.entry(row.user_id).or_insert((\n            row.email.clone(),\n            row.user_name.clone(),\n            row.user_status.clone(),\n        ));\n    }\n\n    // Create User entities with all their team memberships as parents\n    for (user_id, parents) in user_teams {\n        let (email, name, status) = user_info.get(&user_id).cloned().unwrap_or_default();\n\n        // Collect roles for this user\n        let roles: Vec<String> = rows\n            .iter()\n            .filter(|r| r.user_id == user_id)\n            .map(|r| r.role.clone())\n            .collect();\n\n        let mut attrs = serde_json::json!({\n            \"email\": email,\n            \"status\": status,\n            \"roles\": roles,\n        });\n        if let Some(n) = name {\n            attrs[\"name\"] = serde_json::json!(n);\n        }\n\n        entities.push(CedarEntity {\n            uid: CedarEntityUid::new(\"Aeterna::User\", user_id.to_string()),\n            attrs,\n            parents,\n        });\n    }\n\n    Ok(entities)\n}\n\n/// Transforms agent permission rows into Cedar entities.\n///\n/// Creates Agent entities with delegation chain and capability information.\npub fn transform_agents(rows: Vec<AgentPermissionRow>) -> Result<Vec<CedarEntity>> {\n    let mut entities: Vec<CedarEntity> = Vec::new();\n\n    for row in rows {\n        let mut parents = Vec::new();\n\n        // Add allowed teams as parents for resource access\n        if let Some(team_ids) = &row.allowed_team_ids {\n            for team_id in team_ids {\n                parents.push(CedarEntityUid::new(\"Aeterna::Team\", team_id.to_string()));\n            }\n        }\n\n        // Parse capabilities from JSON\n        let capabilities: Vec<String> =\n            serde_json::from_value(row.capabilities.clone()).unwrap_or_default();\n\n        let mut attrs = serde_json::json!({\n            \"name\": row.agent_name,\n            \"agent_type\": row.agent_type,\n            \"delegation_depth\": row.delegation_depth,\n            \"capabilities\": capabilities,\n            \"status\": row.agent_status,\n        });\n\n        // Add delegation info\n        if let Some(user_id) = row.delegated_by_user_id {\n            attrs[\"delegated_by\"] = serde_json::json!({\n                \"type\": \"User\",\n                \"id\": user_id.to_string(),\n            });\n            if let Some(email) = &row.delegating_user_email {\n                attrs[\"delegating_user_email\"] = serde_json::json!(email);\n            }\n        } else if let Some(agent_id) = row.delegated_by_agent_id {\n            attrs[\"delegated_by\"] = serde_json::json!({\n                \"type\": \"Agent\",\n                \"id\": agent_id.to_string(),\n            });\n        }\n\n        // Add scope arrays\n        if let Some(ids) = &row.allowed_company_ids {\n            if !ids.is_empty() {\n                attrs[\"allowed_company_ids\"] = serde_json::json!(ids);\n            }\n        }\n        if let Some(ids) = &row.allowed_org_ids {\n            if !ids.is_empty() {\n                attrs[\"allowed_org_ids\"] = serde_json::json!(ids);\n            }\n        }\n        if let Some(ids) = &row.allowed_team_ids {\n            if !ids.is_empty() {\n                attrs[\"allowed_team_ids\"] = serde_json::json!(ids);\n            }\n        }\n        if let Some(ids) = &row.allowed_project_ids {\n            if !ids.is_empty() {\n                attrs[\"allowed_project_ids\"] = serde_json::json!(ids);\n            }\n        }\n\n        entities.push(CedarEntity {\n            uid: CedarEntityUid::new(\"Aeterna::Agent\", row.agent_id.to_string()),\n            attrs,\n            parents,\n        });\n    }\n\n    Ok(entities)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    fn sample_hierarchy_row() -> HierarchyRow {\n        HierarchyRow {\n            company_id: Some(Uuid::new_v4()),\n            company_slug: Some(\"acme-corp\".to_string()),\n            company_name: Some(\"Acme Corporation\".to_string()),\n            org_id: Some(Uuid::new_v4()),\n            org_slug: Some(\"platform-engineering\".to_string()),\n            org_name: Some(\"Platform Engineering\".to_string()),\n            team_id: Some(Uuid::new_v4()),\n            team_slug: Some(\"api-team\".to_string()),\n            team_name: Some(\"API Team\".to_string()),\n            project_id: Some(Uuid::new_v4()),\n            project_slug: Some(\"payments-service\".to_string()),\n            project_name: Some(\"Payments Service\".to_string()),\n            git_remote: Some(\"git@github.com:acme/payments.git\".to_string()),\n        }\n    }\n\n    #[test]\n    fn test_cedar_entity_uid() {\n        let uid = CedarEntityUid::new(\"Aeterna::User\", \"123\");\n        assert_eq!(uid.entity_type, \"Aeterna::User\");\n        assert_eq!(uid.id, \"123\");\n    }\n\n    #[test]\n    fn test_transform_hierarchy_single_row() {\n        let row = sample_hierarchy_row();\n        let rows = vec![row.clone()];\n\n        let entities = transform_hierarchy(rows).unwrap();\n\n        // Should create 4 entities: Company, Org, Team, Project\n        assert_eq!(entities.len(), 4);\n\n        // Verify Company\n        let company = entities\n            .iter()\n            .find(|e| e.uid.entity_type == \"Aeterna::Company\")\n            .unwrap();\n        assert!(company.parents.is_empty());\n        assert_eq!(company.attrs[\"slug\"], \"acme-corp\");\n\n        // Verify Organization\n        let org = entities\n            .iter()\n            .find(|e| e.uid.entity_type == \"Aeterna::Organization\")\n            .unwrap();\n        assert_eq!(org.parents.len(), 1);\n        assert_eq!(org.parents[0].entity_type, \"Aeterna::Company\");\n\n        // Verify Team\n        let team = entities\n            .iter()\n            .find(|e| e.uid.entity_type == \"Aeterna::Team\")\n            .unwrap();\n        assert_eq!(team.parents.len(), 1);\n        assert_eq!(team.parents[0].entity_type, \"Aeterna::Organization\");\n\n        // Verify Project\n        let project = entities\n            .iter()\n            .find(|e| e.uid.entity_type == \"Aeterna::Project\")\n            .unwrap();\n        assert_eq!(project.parents.len(), 1);\n        assert_eq!(project.parents[0].entity_type, \"Aeterna::Team\");\n        assert!(project.attrs.get(\"git_remote\").is_some());\n    }\n\n    #[test]\n    fn test_transform_hierarchy_deduplication() {\n        let row = sample_hierarchy_row();\n        let rows = vec![row.clone(), row.clone()];\n\n        let entities = transform_hierarchy(rows).unwrap();\n\n        // Should still be 4 entities (deduplicated)\n        assert_eq!(entities.len(), 4);\n    }\n\n    #[test]\n    fn test_transform_users() {\n        let user_id = Uuid::new_v4();\n        let team_id = Uuid::new_v4();\n\n        let row = UserPermissionRow {\n            user_id,\n            email: \"alice@acme.com\".to_string(),\n            user_name: Some(\"Alice\".to_string()),\n            user_status: \"active\".to_string(),\n            team_id,\n            role: \"developer\".to_string(),\n            permissions: serde_json::json!([]),\n            org_id: Uuid::new_v4(),\n            company_id: Uuid::new_v4(),\n            company_slug: \"acme-corp\".to_string(),\n            org_slug: \"platform-engineering\".to_string(),\n            team_slug: \"api-team\".to_string(),\n        };\n\n        let entities = transform_users(vec![row]).unwrap();\n\n        assert_eq!(entities.len(), 1);\n        let user = &entities[0];\n        assert_eq!(user.uid.entity_type, \"Aeterna::User\");\n        assert_eq!(user.uid.id, user_id.to_string());\n        assert_eq!(user.attrs[\"email\"], \"alice@acme.com\");\n        assert_eq!(user.attrs[\"status\"], \"active\");\n        assert_eq!(user.parents.len(), 1);\n        assert_eq!(user.parents[0].entity_type, \"Aeterna::Team\");\n    }\n\n    #[test]\n    fn test_transform_users_multiple_teams() {\n        let user_id = Uuid::new_v4();\n        let team1_id = Uuid::new_v4();\n        let team2_id = Uuid::new_v4();\n\n        let row1 = UserPermissionRow {\n            user_id,\n            email: \"alice@acme.com\".to_string(),\n            user_name: Some(\"Alice\".to_string()),\n            user_status: \"active\".to_string(),\n            team_id: team1_id,\n            role: \"developer\".to_string(),\n            permissions: serde_json::json!([]),\n            org_id: Uuid::new_v4(),\n            company_id: Uuid::new_v4(),\n            company_slug: \"acme-corp\".to_string(),\n            org_slug: \"platform-engineering\".to_string(),\n            team_slug: \"api-team\".to_string(),\n        };\n\n        let row2 = UserPermissionRow {\n            team_id: team2_id,\n            role: \"tech_lead\".to_string(),\n            team_slug: \"data-team\".to_string(),\n            ..row1.clone()\n        };\n\n        let entities = transform_users(vec![row1, row2]).unwrap();\n\n        assert_eq!(entities.len(), 1);\n        let user = &entities[0];\n        // Should have 2 parent teams\n        assert_eq!(user.parents.len(), 2);\n        // Should have both roles\n        let roles: Vec<String> = serde_json::from_value(user.attrs[\"roles\"].clone()).unwrap();\n        assert!(roles.contains(&\"developer\".to_string()));\n        assert!(roles.contains(&\"tech_lead\".to_string()));\n    }\n\n    #[test]\n    fn test_transform_agents() {\n        let agent_id = Uuid::new_v4();\n        let user_id = Uuid::new_v4();\n        let team_id = Uuid::new_v4();\n\n        let row = AgentPermissionRow {\n            agent_id,\n            agent_name: \"OpenCode Assistant\".to_string(),\n            agent_type: \"opencode\".to_string(),\n            delegated_by_user_id: Some(user_id),\n            delegated_by_agent_id: None,\n            delegation_depth: 1,\n            capabilities: serde_json::json!([\"memory:read\", \"memory:write\"]),\n            allowed_company_ids: None,\n            allowed_org_ids: None,\n            allowed_team_ids: Some(vec![team_id]),\n            allowed_project_ids: None,\n            agent_status: \"active\".to_string(),\n            delegating_user_email: Some(\"alice@acme.com\".to_string()),\n            delegating_user_name: Some(\"Alice\".to_string()),\n        };\n\n        let entities = transform_agents(vec![row]).unwrap();\n\n        assert_eq!(entities.len(), 1);\n        let agent = &entities[0];\n        assert_eq!(agent.uid.entity_type, \"Aeterna::Agent\");\n        assert_eq!(agent.uid.id, agent_id.to_string());\n        assert_eq!(agent.attrs[\"name\"], \"OpenCode Assistant\");\n        assert_eq!(agent.attrs[\"agent_type\"], \"opencode\");\n        assert_eq!(agent.attrs[\"delegation_depth\"], 1);\n        assert_eq!(agent.attrs[\"status\"], \"active\");\n\n        // Should have team as parent\n        assert_eq!(agent.parents.len(), 1);\n        assert_eq!(agent.parents[0].entity_type, \"Aeterna::Team\");\n\n        // Should have delegated_by info\n        let delegated_by = &agent.attrs[\"delegated_by\"];\n        assert_eq!(delegated_by[\"type\"], \"User\");\n        assert_eq!(delegated_by[\"id\"], user_id.to_string());\n    }\n\n    #[test]\n    fn test_transform_agents_delegated_by_agent() {\n        let agent_id = Uuid::new_v4();\n        let delegating_agent_id = Uuid::new_v4();\n\n        let row = AgentPermissionRow {\n            agent_id,\n            agent_name: \"Sub-Agent\".to_string(),\n            agent_type: \"custom\".to_string(),\n            delegated_by_user_id: None,\n            delegated_by_agent_id: Some(delegating_agent_id),\n            delegation_depth: 2,\n            capabilities: serde_json::json!([\"knowledge:read\"]),\n            allowed_company_ids: None,\n            allowed_org_ids: None,\n            allowed_team_ids: None,\n            allowed_project_ids: None,\n            agent_status: \"active\".to_string(),\n            delegating_user_email: None,\n            delegating_user_name: None,\n        };\n\n        let entities = transform_agents(vec![row]).unwrap();\n\n        assert_eq!(entities.len(), 1);\n        let agent = &entities[0];\n        let delegated_by = &agent.attrs[\"delegated_by\"];\n        assert_eq!(delegated_by[\"type\"], \"Agent\");\n        assert_eq!(delegated_by[\"id\"], delegating_agent_id.to_string());\n    }\n\n    #[test]\n    fn test_cedar_entities_response() {\n        let entities = vec![CedarEntity {\n            uid: CedarEntityUid::new(\"Aeterna::User\", \"123\"),\n            attrs: serde_json::json!({\"email\": \"test@test.com\"}),\n            parents: vec![],\n        }];\n\n        let response = CedarEntitiesResponse::new(entities);\n\n        assert_eq!(response.count, 1);\n        assert_eq!(response.entities.len(), 1);\n    }\n}\n","traces":[{"line":97,"address":[],"length":0,"stats":{"Line":24}},{"line":99,"address":[],"length":0,"stats":{"Line":72}},{"line":100,"address":[],"length":0,"stats":{"Line":24}},{"line":119,"address":[],"length":0,"stats":{"Line":1}},{"line":120,"address":[],"length":0,"stats":{"Line":3}},{"line":123,"address":[],"length":0,"stats":{"Line":1}},{"line":137,"address":[],"length":0,"stats":{"Line":2}},{"line":138,"address":[],"length":0,"stats":{"Line":6}},{"line":139,"address":[],"length":0,"stats":{"Line":4}},{"line":140,"address":[],"length":0,"stats":{"Line":4}},{"line":141,"address":[],"length":0,"stats":{"Line":4}},{"line":142,"address":[],"length":0,"stats":{"Line":4}},{"line":144,"address":[],"length":0,"stats":{"Line":8}},{"line":146,"address":[],"length":0,"stats":{"Line":9}},{"line":147,"address":[],"length":0,"stats":{"Line":9}},{"line":149,"address":[],"length":0,"stats":{"Line":11}},{"line":150,"address":[],"length":0,"stats":{"Line":6}},{"line":151,"address":[],"length":0,"stats":{"Line":8}},{"line":152,"address":[],"length":0,"stats":{"Line":4}},{"line":153,"address":[],"length":0,"stats":{"Line":4}},{"line":154,"address":[],"length":0,"stats":{"Line":2}},{"line":156,"address":[],"length":0,"stats":{"Line":2}},{"line":162,"address":[],"length":0,"stats":{"Line":12}},{"line":163,"address":[],"length":0,"stats":{"Line":12}},{"line":165,"address":[],"length":0,"stats":{"Line":11}},{"line":166,"address":[],"length":0,"stats":{"Line":6}},{"line":167,"address":[],"length":0,"stats":{"Line":8}},{"line":168,"address":[],"length":0,"stats":{"Line":4}},{"line":169,"address":[],"length":0,"stats":{"Line":4}},{"line":170,"address":[],"length":0,"stats":{"Line":4}},{"line":172,"address":[],"length":0,"stats":{"Line":6}},{"line":173,"address":[],"length":0,"stats":{"Line":2}},{"line":174,"address":[],"length":0,"stats":{"Line":2}},{"line":181,"address":[],"length":0,"stats":{"Line":12}},{"line":182,"address":[],"length":0,"stats":{"Line":12}},{"line":184,"address":[],"length":0,"stats":{"Line":11}},{"line":185,"address":[],"length":0,"stats":{"Line":6}},{"line":186,"address":[],"length":0,"stats":{"Line":8}},{"line":187,"address":[],"length":0,"stats":{"Line":4}},{"line":188,"address":[],"length":0,"stats":{"Line":4}},{"line":189,"address":[],"length":0,"stats":{"Line":4}},{"line":191,"address":[],"length":0,"stats":{"Line":6}},{"line":192,"address":[],"length":0,"stats":{"Line":2}},{"line":193,"address":[],"length":0,"stats":{"Line":2}},{"line":200,"address":[],"length":0,"stats":{"Line":12}},{"line":201,"address":[],"length":0,"stats":{"Line":3}},{"line":202,"address":[],"length":0,"stats":{"Line":3}},{"line":203,"address":[],"length":0,"stats":{"Line":3}},{"line":204,"address":[],"length":0,"stats":{"Line":3}},{"line":206,"address":[],"length":0,"stats":{"Line":9}},{"line":207,"address":[],"length":0,"stats":{"Line":4}},{"line":208,"address":[],"length":0,"stats":{"Line":2}},{"line":209,"address":[],"length":0,"stats":{"Line":2}},{"line":211,"address":[],"length":0,"stats":{"Line":6}},{"line":212,"address":[],"length":0,"stats":{"Line":2}},{"line":214,"address":[],"length":0,"stats":{"Line":6}},{"line":215,"address":[],"length":0,"stats":{"Line":8}},{"line":216,"address":[],"length":0,"stats":{"Line":4}},{"line":217,"address":[],"length":0,"stats":{"Line":6}},{"line":223,"address":[],"length":0,"stats":{"Line":2}},{"line":229,"address":[],"length":0,"stats":{"Line":2}},{"line":230,"address":[],"length":0,"stats":{"Line":6}},{"line":231,"address":[],"length":0,"stats":{"Line":4}},{"line":232,"address":[],"length":0,"stats":{"Line":2}},{"line":233,"address":[],"length":0,"stats":{"Line":4}},{"line":234,"address":[],"length":0,"stats":{"Line":2}},{"line":237,"address":[],"length":0,"stats":{"Line":11}},{"line":238,"address":[],"length":0,"stats":{"Line":15}},{"line":239,"address":[],"length":0,"stats":{"Line":18}},{"line":240,"address":[],"length":0,"stats":{"Line":15}},{"line":241,"address":[],"length":0,"stats":{"Line":9}},{"line":242,"address":[],"length":0,"stats":{"Line":9}},{"line":243,"address":[],"length":0,"stats":{"Line":3}},{"line":248,"address":[],"length":0,"stats":{"Line":8}},{"line":249,"address":[],"length":0,"stats":{"Line":14}},{"line":252,"address":[],"length":0,"stats":{"Line":6}},{"line":254,"address":[],"length":0,"stats":{"Line":8}},{"line":255,"address":[],"length":0,"stats":{"Line":8}},{"line":258,"address":[],"length":0,"stats":{"Line":4}},{"line":259,"address":[],"length":0,"stats":{"Line":2}},{"line":260,"address":[],"length":0,"stats":{"Line":2}},{"line":261,"address":[],"length":0,"stats":{"Line":2}},{"line":263,"address":[],"length":0,"stats":{"Line":6}},{"line":264,"address":[],"length":0,"stats":{"Line":2}},{"line":267,"address":[],"length":0,"stats":{"Line":6}},{"line":268,"address":[],"length":0,"stats":{"Line":8}},{"line":269,"address":[],"length":0,"stats":{"Line":2}},{"line":270,"address":[],"length":0,"stats":{"Line":2}},{"line":274,"address":[],"length":0,"stats":{"Line":2}},{"line":280,"address":[],"length":0,"stats":{"Line":2}},{"line":281,"address":[],"length":0,"stats":{"Line":6}},{"line":283,"address":[],"length":0,"stats":{"Line":6}},{"line":284,"address":[],"length":0,"stats":{"Line":4}},{"line":287,"address":[],"length":0,"stats":{"Line":3}},{"line":288,"address":[],"length":0,"stats":{"Line":4}},{"line":289,"address":[],"length":0,"stats":{"Line":4}},{"line":294,"address":[],"length":0,"stats":{"Line":4}},{"line":295,"address":[],"length":0,"stats":{"Line":8}},{"line":297,"address":[],"length":0,"stats":{"Line":4}},{"line":298,"address":[],"length":0,"stats":{"Line":2}},{"line":299,"address":[],"length":0,"stats":{"Line":2}},{"line":300,"address":[],"length":0,"stats":{"Line":2}},{"line":301,"address":[],"length":0,"stats":{"Line":2}},{"line":302,"address":[],"length":0,"stats":{"Line":2}},{"line":306,"address":[],"length":0,"stats":{"Line":3}},{"line":307,"address":[],"length":0,"stats":{"Line":2}},{"line":308,"address":[],"length":0,"stats":{"Line":1}},{"line":309,"address":[],"length":0,"stats":{"Line":3}},{"line":311,"address":[],"length":0,"stats":{"Line":3}},{"line":312,"address":[],"length":0,"stats":{"Line":1}},{"line":314,"address":[],"length":0,"stats":{"Line":3}},{"line":315,"address":[],"length":0,"stats":{"Line":3}},{"line":316,"address":[],"length":0,"stats":{"Line":2}},{"line":317,"address":[],"length":0,"stats":{"Line":2}},{"line":322,"address":[],"length":0,"stats":{"Line":2}},{"line":323,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":327,"address":[],"length":0,"stats":{"Line":2}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":3}},{"line":333,"address":[],"length":0,"stats":{"Line":2}},{"line":334,"address":[],"length":0,"stats":{"Line":1}},{"line":337,"address":[],"length":0,"stats":{"Line":2}},{"line":338,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":343,"address":[],"length":0,"stats":{"Line":6}},{"line":344,"address":[],"length":0,"stats":{"Line":8}},{"line":345,"address":[],"length":0,"stats":{"Line":2}},{"line":346,"address":[],"length":0,"stats":{"Line":2}},{"line":350,"address":[],"length":0,"stats":{"Line":2}}],"covered":125,"coverable":131},{"path":["/","Users","christian.klat","dev","git","aeterna","opal-fetcher","src","error.rs"],"content":"//! Error types for the OPAL Data Fetcher.\n\nuse axum::{\n    Json,\n    http::StatusCode,\n    response::{IntoResponse, Response},\n};\nuse serde::Serialize;\nuse thiserror::Error;\n\n/// Result type alias for the fetcher.\npub type Result<T> = std::result::Result<T, FetcherError>;\n\n/// Errors that can occur in the OPAL Data Fetcher.\n#[derive(Error, Debug)]\npub enum FetcherError {\n    /// Database connection or query error.\n    #[error(\"Database error: {0}\")]\n    Database(#[from] sqlx::Error),\n\n    /// Configuration error.\n    #[error(\"Configuration error: {0}\")]\n    Configuration(String),\n\n    /// Entity transformation error.\n    #[error(\"Entity transformation error: {0}\")]\n    EntityTransform(String),\n\n    /// Cedar policy error.\n    #[error(\"Cedar policy error: {0}\")]\n    Cedar(String),\n\n    /// Server startup error.\n    #[error(\"Server error: {0}\")]\n    Server(String),\n\n    /// Listener (PostgreSQL NOTIFY) error.\n    #[error(\"Listener error: {0}\")]\n    Listener(String),\n\n    /// JSON serialization error.\n    #[error(\"Serialization error: {0}\")]\n    Serialization(#[from] serde_json::Error),\n\n    /// Internal error for unexpected conditions.\n    #[error(\"Internal error: {0}\")]\n    Internal(String),\n}\n\n/// Error response body for HTTP endpoints.\n#[derive(Serialize)]\npub struct ErrorResponse {\n    pub error: String,\n    pub code: String,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub details: Option<String>,\n}\n\nimpl IntoResponse for FetcherError {\n    fn into_response(self) -> Response {\n        let (status, code, message, details) = match &self {\n            Self::Database(e) => {\n                tracing::error!(error = %e, \"Database error\");\n                (\n                    StatusCode::INTERNAL_SERVER_ERROR,\n                    \"DATABASE_ERROR\",\n                    \"A database error occurred\",\n                    None,\n                )\n            }\n            Self::Configuration(msg) => (\n                StatusCode::INTERNAL_SERVER_ERROR,\n                \"CONFIGURATION_ERROR\",\n                msg.as_str(),\n                None,\n            ),\n            Self::EntityTransform(msg) => (\n                StatusCode::INTERNAL_SERVER_ERROR,\n                \"ENTITY_TRANSFORM_ERROR\",\n                msg.as_str(),\n                None,\n            ),\n            Self::Cedar(msg) => (\n                StatusCode::INTERNAL_SERVER_ERROR,\n                \"CEDAR_ERROR\",\n                msg.as_str(),\n                None,\n            ),\n            Self::Server(msg) => (\n                StatusCode::INTERNAL_SERVER_ERROR,\n                \"SERVER_ERROR\",\n                msg.as_str(),\n                None,\n            ),\n            Self::Listener(msg) => (\n                StatusCode::INTERNAL_SERVER_ERROR,\n                \"LISTENER_ERROR\",\n                msg.as_str(),\n                None,\n            ),\n            Self::Serialization(e) => {\n                tracing::error!(error = %e, \"Serialization error\");\n                (\n                    StatusCode::INTERNAL_SERVER_ERROR,\n                    \"SERIALIZATION_ERROR\",\n                    \"Failed to serialize response\",\n                    Some(e.to_string()),\n                )\n            }\n            Self::Internal(msg) => {\n                tracing::error!(message = %msg, \"Internal error\");\n                (\n                    StatusCode::INTERNAL_SERVER_ERROR,\n                    \"INTERNAL_ERROR\",\n                    \"An internal error occurred\",\n                    Some(msg.clone()),\n                )\n            }\n        };\n\n        let body = ErrorResponse {\n            error: message.to_string(),\n            code: code.to_string(),\n            details,\n        };\n\n        (status, Json(body)).into_response()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_database_error_display() {\n        // We can't easily create a sqlx::Error, so test other variants\n        let err = FetcherError::Configuration(\"test config error\".to_string());\n        assert_eq!(err.to_string(), \"Configuration error: test config error\");\n    }\n\n    #[test]\n    fn test_entity_transform_error_display() {\n        let err = FetcherError::EntityTransform(\"invalid entity\".to_string());\n        assert_eq!(\n            err.to_string(),\n            \"Entity transformation error: invalid entity\"\n        );\n    }\n\n    #[test]\n    fn test_cedar_error_display() {\n        let err = FetcherError::Cedar(\"policy parse failed\".to_string());\n        assert_eq!(err.to_string(), \"Cedar policy error: policy parse failed\");\n    }\n\n    #[test]\n    fn test_internal_error_display() {\n        let err = FetcherError::Internal(\"unexpected state\".to_string());\n        assert_eq!(err.to_string(), \"Internal error: unexpected state\");\n    }\n\n    #[test]\n    fn test_error_response_serialization() {\n        let resp = ErrorResponse {\n            error: \"test error\".to_string(),\n            code: \"TEST_ERROR\".to_string(),\n            details: Some(\"additional info\".to_string()),\n        };\n        let json = serde_json::to_string(&resp).unwrap();\n        assert!(json.contains(\"test error\"));\n        assert!(json.contains(\"TEST_ERROR\"));\n        assert!(json.contains(\"additional info\"));\n    }\n\n    #[test]\n    fn test_error_response_without_details() {\n        let resp = ErrorResponse {\n            error: \"test error\".to_string(),\n            code: \"TEST_ERROR\".to_string(),\n            details: None,\n        };\n        let json = serde_json::to_string(&resp).unwrap();\n        assert!(!json.contains(\"details\"));\n    }\n}\n","traces":[{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":48},{"path":["/","Users","christian.klat","dev","git","aeterna","opal-fetcher","src","handlers.rs"],"content":"//! HTTP request handlers for the OPAL Data Fetcher.\n\nuse axum::{Json, extract::State, http::StatusCode, response::IntoResponse};\nuse serde::Serialize;\nuse std::sync::Arc;\n\nuse crate::entities::{\n    AgentPermissionRow, CedarEntitiesResponse, HierarchyRow, UserPermissionRow, transform_agents,\n    transform_hierarchy, transform_users,\n};\nuse crate::error::Result;\nuse crate::state::AppState;\n\n/// Health check response.\n#[derive(Debug, Serialize)]\npub struct HealthResponse {\n    pub status: String,\n    pub database: String,\n}\n\n/// Health check endpoint.\n///\n/// Returns 200 if the server is healthy and can connect to the database.\npub async fn health(State(state): State<Arc<AppState>>) -> impl IntoResponse {\n    // Check database connectivity\n    let db_status = match sqlx::query(\"SELECT 1\").execute(&state.pool).await {\n        Ok(_) => \"connected\",\n        Err(e) => {\n            tracing::warn!(error = %e, \"Database health check failed\");\n            return (\n                StatusCode::SERVICE_UNAVAILABLE,\n                Json(HealthResponse {\n                    status: \"unhealthy\".to_string(),\n                    database: \"disconnected\".to_string(),\n                }),\n            );\n        }\n    };\n\n    (\n        StatusCode::OK,\n        Json(HealthResponse {\n            status: \"healthy\".to_string(),\n            database: db_status.to_string(),\n        }),\n    )\n}\n\n/// Metrics endpoint placeholder.\n///\n/// Returns Prometheus-format metrics.\npub async fn metrics() -> impl IntoResponse {\n    // TODO: Integrate with metrics-exporter-prometheus\n    // For now, return basic metrics\n    let metrics = r#\"# HELP opal_fetcher_requests_total Total number of requests\n# TYPE opal_fetcher_requests_total counter\nopal_fetcher_requests_total{endpoint=\"hierarchy\"} 0\nopal_fetcher_requests_total{endpoint=\"users\"} 0\nopal_fetcher_requests_total{endpoint=\"agents\"} 0\n# HELP opal_fetcher_up Whether the fetcher is up\n# TYPE opal_fetcher_up gauge\nopal_fetcher_up 1\n\"#;\n\n    (StatusCode::OK, metrics)\n}\n\n/// GET /v1/hierarchy\n///\n/// Returns the organizational hierarchy (Company  Organization  Team  Project)\n/// as Cedar entities for OPAL consumption.\npub async fn get_hierarchy(\n    State(state): State<Arc<AppState>>,\n) -> Result<Json<CedarEntitiesResponse>> {\n    tracing::debug!(\"Fetching organizational hierarchy\");\n\n    let rows: Vec<HierarchyRow> = sqlx::query_as(\n        r#\"\n        SELECT\n            company_id,\n            company_slug,\n            company_name,\n            org_id,\n            org_slug,\n            org_name,\n            team_id,\n            team_slug,\n            team_name,\n            project_id,\n            project_slug,\n            project_name,\n            git_remote\n        FROM v_hierarchy\n        \"#,\n    )\n    .fetch_all(&state.pool)\n    .await?;\n\n    let count = rows.len();\n    tracing::debug!(row_count = count, \"Fetched hierarchy rows\");\n\n    let entities = transform_hierarchy(rows)?;\n    let response = CedarEntitiesResponse::new(entities);\n\n    tracing::info!(\n        entity_count = response.count,\n        \"Returning hierarchy entities\"\n    );\n\n    Ok(Json(response))\n}\n\n/// GET /v1/users\n///\n/// Returns users with their team memberships and roles as Cedar entities.\npub async fn get_users(State(state): State<Arc<AppState>>) -> Result<Json<CedarEntitiesResponse>> {\n    tracing::debug!(\"Fetching user permissions\");\n\n    let rows: Vec<UserPermissionRow> = sqlx::query_as(\n        r#\"\n        SELECT\n            user_id,\n            email,\n            user_name,\n            user_status,\n            team_id,\n            role,\n            permissions,\n            org_id,\n            company_id,\n            company_slug,\n            org_slug,\n            team_slug\n        FROM v_user_permissions\n        \"#,\n    )\n    .fetch_all(&state.pool)\n    .await?;\n\n    let count = rows.len();\n    tracing::debug!(row_count = count, \"Fetched user permission rows\");\n\n    let entities = transform_users(rows)?;\n    let response = CedarEntitiesResponse::new(entities);\n\n    tracing::info!(entity_count = response.count, \"Returning user entities\");\n\n    Ok(Json(response))\n}\n\n/// GET /v1/agents\n///\n/// Returns agents with their delegation chains and capabilities as Cedar entities.\npub async fn get_agents(State(state): State<Arc<AppState>>) -> Result<Json<CedarEntitiesResponse>> {\n    tracing::debug!(\"Fetching agent permissions\");\n\n    let rows: Vec<AgentPermissionRow> = sqlx::query_as(\n        r#\"\n        SELECT\n            agent_id,\n            agent_name,\n            agent_type,\n            delegated_by_user_id,\n            delegated_by_agent_id,\n            delegation_depth,\n            capabilities,\n            allowed_company_ids,\n            allowed_org_ids,\n            allowed_team_ids,\n            allowed_project_ids,\n            agent_status,\n            delegating_user_email,\n            delegating_user_name\n        FROM v_agent_permissions\n        \"#,\n    )\n    .fetch_all(&state.pool)\n    .await?;\n\n    let count = rows.len();\n    tracing::debug!(row_count = count, \"Fetched agent permission rows\");\n\n    let entities = transform_agents(rows)?;\n    let response = CedarEntitiesResponse::new(entities);\n\n    tracing::info!(entity_count = response.count, \"Returning agent entities\");\n\n    Ok(Json(response))\n}\n\n/// GET /v1/all\n///\n/// Returns all entities (hierarchy, users, agents) in a single response.\n/// Useful for initial full sync.\npub async fn get_all_entities(\n    State(state): State<Arc<AppState>>,\n) -> Result<Json<CedarEntitiesResponse>> {\n    tracing::debug!(\"Fetching all entities\");\n\n    // Fetch all entity types in parallel\n    let (hierarchy_rows, user_rows, agent_rows) = tokio::try_join!(\n        sqlx::query_as::<_, HierarchyRow>(\n            r#\"\n            SELECT\n                company_id, company_slug, company_name,\n                org_id, org_slug, org_name,\n                team_id, team_slug, team_name,\n                project_id, project_slug, project_name,\n                git_remote\n            FROM v_hierarchy\n            \"#\n        )\n        .fetch_all(&state.pool),\n        sqlx::query_as::<_, UserPermissionRow>(\n            r#\"\n            SELECT\n                user_id, email, user_name, user_status,\n                team_id, role, permissions,\n                org_id, company_id, company_slug, org_slug, team_slug\n            FROM v_user_permissions\n            \"#\n        )\n        .fetch_all(&state.pool),\n        sqlx::query_as::<_, AgentPermissionRow>(\n            r#\"\n            SELECT\n                agent_id, agent_name, agent_type,\n                delegated_by_user_id, delegated_by_agent_id, delegation_depth,\n                capabilities, allowed_company_ids, allowed_org_ids,\n                allowed_team_ids, allowed_project_ids, agent_status,\n                delegating_user_email, delegating_user_name\n            FROM v_agent_permissions\n            \"#\n        )\n        .fetch_all(&state.pool),\n    )?;\n\n    // Transform all entities\n    let mut all_entities = transform_hierarchy(hierarchy_rows)?;\n    all_entities.extend(transform_users(user_rows)?);\n    all_entities.extend(transform_agents(agent_rows)?);\n\n    let response = CedarEntitiesResponse::new(all_entities);\n\n    tracing::info!(entity_count = response.count, \"Returning all entities\");\n\n    Ok(Json(response))\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_health_response_serialization() {\n        let response = HealthResponse {\n            status: \"healthy\".to_string(),\n            database: \"connected\".to_string(),\n        };\n        let json = serde_json::to_string(&response).unwrap();\n        assert!(json.contains(\"healthy\"));\n        assert!(json.contains(\"connected\"));\n    }\n}\n","traces":[{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":28,"address":[],"length":0,"stats":{"Line":0}},{"line":29,"address":[],"length":0,"stats":{"Line":0}},{"line":30,"address":[],"length":0,"stats":{"Line":0}},{"line":31,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":42,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":201,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":223,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":235,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":240,"address":[],"length":0,"stats":{"Line":0}},{"line":241,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":71},{"path":["/","Users","christian.klat","dev","git","aeterna","opal-fetcher","src","lib.rs"],"content":"//! # OPAL Data Fetcher\n//!\n//! This crate provides an HTTP server that exposes organizational data from PostgreSQL\n//! to OPAL (Open Policy Administration Layer) and Cedar Agent for policy decisions.\n//!\n//! ## Architecture\n//!\n//! ```text\n//!           \n//!    PostgreSQL      OPAL Fetcher      Cedar Agent   \n//!   (Referential)         (This crate)                         \n//!           \n//!                                \n//!          pg_notify              HTTP\n//!         \n//! ```\n//!\n//! ## Endpoints\n//!\n//! - `GET /v1/hierarchy` - Returns organizational hierarchy as Cedar entities\n//! - `GET /v1/users` - Returns users with memberships as Cedar entities\n//! - `GET /v1/agents` - Returns agents with delegation chains as Cedar entities\n//! - `GET /health` - Health check endpoint\n//! - `GET /metrics` - Prometheus metrics endpoint\n//!\n//! ## Real-time Updates\n//!\n//! The fetcher listens to PostgreSQL NOTIFY events via the `referential_changes` channel\n//! and publishes updates to OPAL via its PubSub mechanism.\n\npub mod entities;\npub mod error;\npub mod handlers;\npub mod listener;\npub mod routes;\npub mod server;\npub mod state;\n\npub use error::FetcherError;\npub use server::OpalFetcherServer;\npub use state::AppState;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","opal-fetcher","src","listener.rs"],"content":"//! PostgreSQL LISTEN/NOTIFY listener for real-time updates.\n//!\n//! This module listens to the `referential_changes` channel for database changes\n//! and can optionally publish updates to OPAL via its PubSub mechanism.\n\nuse serde::{Deserialize, Serialize};\nuse sqlx::postgres::PgListener;\nuse std::sync::Arc;\nuse uuid::Uuid;\n\nuse crate::error::{FetcherError, Result};\nuse crate::state::AppState;\n\n/// A notification payload from PostgreSQL NOTIFY.\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ReferentialChangeNotification {\n    /// The table that changed.\n    pub table: String,\n    /// The operation type (INSERT, UPDATE, DELETE).\n    pub operation: String,\n    /// The ID of the changed entity.\n    pub id: String,\n    /// Unix timestamp of the change.\n    pub timestamp: f64,\n}\n\n/// PostgreSQL LISTEN/NOTIFY listener for referential changes.\npub struct ReferentialListener {\n    state: Arc<AppState>,\n    pg_listener: PgListener,\n}\n\nimpl ReferentialListener {\n    /// Creates a new listener connected to the database.\n    pub async fn new(state: Arc<AppState>) -> Result<Self> {\n        let pg_listener = PgListener::connect_with(&state.pool)\n            .await\n            .map_err(|e| FetcherError::Listener(format!(\"Failed to create listener: {e}\")))?;\n\n        Ok(Self { state, pg_listener })\n    }\n\n    /// Starts listening for referential changes.\n    ///\n    /// This method runs indefinitely, processing notifications as they arrive.\n    pub async fn run(mut self) -> Result<()> {\n        // Subscribe to the referential_changes channel\n        self.pg_listener\n            .listen(\"referential_changes\")\n            .await\n            .map_err(|e| FetcherError::Listener(format!(\"Failed to subscribe: {e}\")))?;\n\n        tracing::info!(\"Listening for referential changes on 'referential_changes' channel\");\n\n        loop {\n            match self.pg_listener.recv().await {\n                Ok(notification) => {\n                    let payload = notification.payload();\n                    tracing::debug!(payload = %payload, \"Received notification\");\n\n                    if let Err(e) = self.handle_notification(payload).await {\n                        tracing::error!(error = %e, \"Error handling notification\");\n                    }\n                }\n                Err(e) => {\n                    tracing::error!(error = %e, \"Error receiving notification\");\n                    // Attempt to reconnect after a short delay\n                    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;\n                }\n            }\n        }\n    }\n\n    /// Handles a single notification.\n    async fn handle_notification(&self, payload: &str) -> Result<()> {\n        let notification: ReferentialChangeNotification = serde_json::from_str(payload)\n            .map_err(|e| FetcherError::Listener(format!(\"Failed to parse notification: {e}\")))?;\n\n        tracing::info!(\n            table = %notification.table,\n            operation = %notification.operation,\n            id = %notification.id,\n            \"Processing referential change\"\n        );\n\n        // Determine which entity type changed\n        let entity_type = match notification.table.as_str() {\n            \"companies\" => Some(\"hierarchy\"),\n            \"organizations\" => Some(\"hierarchy\"),\n            \"teams\" => Some(\"hierarchy\"),\n            \"projects\" => Some(\"hierarchy\"),\n            \"users\" => Some(\"users\"),\n            \"memberships\" => Some(\"users\"),\n            \"agents\" => Some(\"agents\"),\n            _ => None,\n        };\n\n        if let Some(entity_type) = entity_type {\n            // If OPAL server is configured, publish the update\n            if let Some(opal_url) = &self.state.config.opal_server_url {\n                self.publish_to_opal(opal_url, entity_type, &notification)\n                    .await?;\n            } else {\n                tracing::debug!(\n                    entity_type = %entity_type,\n                    \"OPAL server not configured, skipping publish\"\n                );\n            }\n        }\n\n        Ok(())\n    }\n\n    /// Publishes an update to OPAL via its data update endpoint.\n    async fn publish_to_opal(\n        &self,\n        opal_url: &str,\n        entity_type: &str,\n        notification: &ReferentialChangeNotification,\n    ) -> Result<()> {\n        let update_url = format!(\"{opal_url}/data/config\");\n\n        // Create OPAL data update payload\n        // This follows OPAL's data update format\n        let payload = serde_json::json!({\n            \"id\": Uuid::new_v4().to_string(),\n            \"entries\": [{\n                \"url\": format!(\"http://opal-fetcher:8080/v1/{}\", entity_type),\n                \"topics\": [entity_type],\n                \"reason\": format!(\"{} {} on {}\", notification.operation, notification.id, notification.table),\n            }]\n        });\n\n        tracing::debug!(\n            url = %update_url,\n            payload = %payload,\n            \"Publishing to OPAL\"\n        );\n\n        let client = reqwest::Client::new();\n        let response = client\n            .post(&update_url)\n            .json(&payload)\n            .send()\n            .await\n            .map_err(|e| FetcherError::Listener(format!(\"Failed to publish to OPAL: {e}\")))?;\n\n        if response.status().is_success() {\n            tracing::info!(\n                entity_type = %entity_type,\n                \"Successfully published update to OPAL\"\n            );\n        } else {\n            let status = response.status();\n            let body = response.text().await.unwrap_or_default();\n            tracing::warn!(\n                status = %status,\n                body = %body,\n                \"OPAL returned non-success status\"\n            );\n        }\n\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_notification_deserialization() {\n        let json = r#\"{\"table\":\"users\",\"operation\":\"INSERT\",\"id\":\"123e4567-e89b-12d3-a456-426614174000\",\"timestamp\":1234567890.123}\"#;\n        let notification: ReferentialChangeNotification = serde_json::from_str(json).unwrap();\n\n        assert_eq!(notification.table, \"users\");\n        assert_eq!(notification.operation, \"INSERT\");\n        assert_eq!(notification.id, \"123e4567-e89b-12d3-a456-426614174000\");\n        assert!((notification.timestamp - 1_234_567_890.123).abs() < f64::EPSILON);\n    }\n\n    #[test]\n    fn test_notification_serialization() {\n        let notification = ReferentialChangeNotification {\n            table: \"agents\".to_string(),\n            operation: \"UPDATE\".to_string(),\n            id: \"test-id\".to_string(),\n            timestamp: 1234567890.0,\n        };\n\n        let json = serde_json::to_string(&notification).unwrap();\n        assert!(json.contains(\"agents\"));\n        assert!(json.contains(\"UPDATE\"));\n        assert!(json.contains(\"test-id\"));\n    }\n\n    #[test]\n    fn test_entity_type_mapping() {\n        // Test mapping of table names to entity types\n        let mappings = vec![\n            (\"companies\", Some(\"hierarchy\")),\n            (\"organizations\", Some(\"hierarchy\")),\n            (\"teams\", Some(\"hierarchy\")),\n            (\"projects\", Some(\"hierarchy\")),\n            (\"users\", Some(\"users\")),\n            (\"memberships\", Some(\"users\")),\n            (\"agents\", Some(\"agents\")),\n            (\"unknown_table\", None),\n        ];\n\n        for (table, expected) in mappings {\n            let result = match table {\n                \"companies\" | \"organizations\" | \"teams\" | \"projects\" => Some(\"hierarchy\"),\n                \"users\" | \"memberships\" => Some(\"users\"),\n                \"agents\" => Some(\"agents\"),\n                _ => None,\n            };\n            assert_eq!(\n                result, expected,\n                \"Table '{}' should map to {:?}\",\n                table, expected\n            );\n        }\n    }\n}\n","traces":[{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":37,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":48,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":64},{"path":["/","Users","christian.klat","dev","git","aeterna","opal-fetcher","src","main.rs"],"content":"use opal_fetcher::server::run_from_env;\n\n#[tokio::main]\nasync fn main() -> anyhow::Result<()> {\n    run_from_env().await?;\n    Ok(())\n}\n","traces":[{"line":4,"address":[],"length":0,"stats":{"Line":0}},{"line":5,"address":[],"length":0,"stats":{"Line":0}},{"line":6,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":3},{"path":["/","Users","christian.klat","dev","git","aeterna","opal-fetcher","src","routes.rs"],"content":"//! Route definitions for the OPAL Data Fetcher.\n\nuse axum::{Router, routing::get};\nuse std::sync::Arc;\nuse tower_http::{\n    cors::{Any, CorsLayer},\n    trace::TraceLayer,\n};\n\nuse crate::handlers;\nuse crate::state::AppState;\n\n/// Creates the Axum router with all routes configured.\npub fn create_router(state: Arc<AppState>) -> Router {\n    // CORS configuration - allow any origin for OPAL clients\n    let cors = CorsLayer::new()\n        .allow_origin(Any)\n        .allow_methods(Any)\n        .allow_headers(Any);\n\n    // API v1 routes\n    let api_v1 = Router::new()\n        .route(\"/hierarchy\", get(handlers::get_hierarchy))\n        .route(\"/users\", get(handlers::get_users))\n        .route(\"/agents\", get(handlers::get_agents))\n        .route(\"/all\", get(handlers::get_all_entities));\n\n    // Root router\n    Router::new()\n        .route(\"/health\", get(handlers::health))\n        .route(\"/metrics\", get(handlers::metrics))\n        .nest(\"/v1\", api_v1)\n        .layer(cors)\n        .layer(TraceLayer::new_for_http())\n        .with_state(state)\n}\n\n#[cfg(test)]\nmod tests {\n    use crate::state::FetcherConfig;\n\n    #[test]\n    fn test_router_construction() {\n        let config = FetcherConfig {\n            database_url: \"postgres://localhost/test\".to_string(),\n            ..Default::default()\n        };\n        assert!(!config.database_url.is_empty());\n    }\n}\n","traces":[{"line":14,"address":[],"length":0,"stats":{"Line":0}},{"line":16,"address":[],"length":0,"stats":{"Line":0}},{"line":17,"address":[],"length":0,"stats":{"Line":0}},{"line":18,"address":[],"length":0,"stats":{"Line":0}},{"line":19,"address":[],"length":0,"stats":{"Line":0}},{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":23,"address":[],"length":0,"stats":{"Line":0}},{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":29,"address":[],"length":0,"stats":{"Line":0}},{"line":30,"address":[],"length":0,"stats":{"Line":0}},{"line":31,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":17},{"path":["/","Users","christian.klat","dev","git","aeterna","opal-fetcher","src","server.rs"],"content":"//! Server setup and lifecycle for the OPAL Data Fetcher.\n\nuse std::net::SocketAddr;\nuse std::sync::Arc;\nuse tokio::net::TcpListener;\nuse tokio::signal;\n\nuse crate::error::{FetcherError, Result};\nuse crate::listener::ReferentialListener;\nuse crate::routes::create_router;\nuse crate::state::{AppState, FetcherConfig};\n\n/// The OPAL Data Fetcher server.\npub struct OpalFetcherServer {\n    state: Arc<AppState>,\n    listener_handle: Option<tokio::task::JoinHandle<()>>,\n}\n\nimpl OpalFetcherServer {\n    /// Creates a new server instance with the given configuration.\n    pub async fn new(config: FetcherConfig) -> Result<Self> {\n        let state = Arc::new(AppState::new(config).await?);\n        Ok(Self {\n            state,\n            listener_handle: None,\n        })\n    }\n\n    /// Creates a server instance from an existing `AppState`.\n    pub fn with_state(state: Arc<AppState>) -> Self {\n        Self {\n            state,\n            listener_handle: None,\n        }\n    }\n\n    /// Starts the PostgreSQL LISTEN/NOTIFY listener in the background.\n    pub async fn start_listener(&mut self) -> Result<()> {\n        if !self.state.config.enable_listener {\n            tracing::info!(\"PostgreSQL listener disabled by configuration\");\n            return Ok(());\n        }\n\n        let listener = ReferentialListener::new(self.state.clone()).await?;\n        let handle = tokio::spawn(async move {\n            if let Err(e) = listener.run().await {\n                tracing::error!(error = %e, \"Referential listener error\");\n            }\n        });\n\n        self.listener_handle = Some(handle);\n        tracing::info!(\"PostgreSQL LISTEN/NOTIFY listener started\");\n\n        Ok(())\n    }\n\n    /// Runs the HTTP server.\n    ///\n    /// This method blocks until the server is shut down (e.g., via Ctrl+C).\n    pub async fn run(mut self) -> Result<()> {\n        let addr: SocketAddr = format!(\"{}:{}\", self.state.config.host, self.state.config.port)\n            .parse()\n            .map_err(|e| FetcherError::Configuration(format!(\"Invalid address: {e}\")))?;\n\n        // Start the listener if enabled\n        self.start_listener().await?;\n\n        // Create router\n        let router = create_router(self.state.clone());\n\n        // Bind to address\n        let listener = TcpListener::bind(&addr)\n            .await\n            .map_err(|e| FetcherError::Server(format!(\"Failed to bind to {addr}: {e}\")))?;\n\n        tracing::info!(%addr, \"OPAL Data Fetcher server starting\");\n\n        // Run server with graceful shutdown\n        axum::serve(listener, router)\n            .with_graceful_shutdown(shutdown_signal())\n            .await\n            .map_err(|e| FetcherError::Server(format!(\"Server error: {e}\")))?;\n\n        // Cleanup\n        if let Some(handle) = self.listener_handle.take() {\n            handle.abort();\n        }\n\n        tracing::info!(\"OPAL Data Fetcher server stopped\");\n        Ok(())\n    }\n\n    /// Returns a reference to the application state.\n    #[must_use]\n    pub fn state(&self) -> &Arc<AppState> {\n        &self.state\n    }\n}\n\n/// Signal handler for graceful shutdown.\nasync fn shutdown_signal() {\n    let ctrl_c = async {\n        signal::ctrl_c()\n            .await\n            .expect(\"Failed to install Ctrl+C handler\");\n    };\n\n    #[cfg(unix)]\n    let terminate = async {\n        signal::unix::signal(signal::unix::SignalKind::terminate())\n            .expect(\"Failed to install signal handler\")\n            .recv()\n            .await;\n    };\n\n    #[cfg(not(unix))]\n    let terminate = std::future::pending::<()>();\n\n    tokio::select! {\n        () = ctrl_c => {\n            tracing::info!(\"Received Ctrl+C, initiating graceful shutdown\");\n        },\n        () = terminate => {\n            tracing::info!(\"Received terminate signal, initiating graceful shutdown\");\n        },\n    }\n}\n\n/// Entry point for running the server from configuration.\n///\n/// This is a convenience function that creates and runs the server.\npub async fn run_server(config: FetcherConfig) -> Result<()> {\n    let server = OpalFetcherServer::new(config).await?;\n    server.run().await\n}\n\n/// Entry point for running the server from environment variables.\n///\n/// This is a convenience function for containerized deployments.\npub async fn run_from_env() -> Result<()> {\n    // Initialize tracing\n    tracing_subscriber::fmt()\n        .with_env_filter(\n            tracing_subscriber::EnvFilter::from_default_env()\n                .add_directive(tracing::Level::INFO.into()),\n        )\n        .init();\n\n    let config = FetcherConfig::from_env()?;\n    run_server(config).await\n}\n\n#[cfg(test)]\nmod tests {\n    #[test]\n    fn test_shutdown_signal_exists() {}\n}\n","traces":[{"line":21,"address":[],"length":0,"stats":{"Line":0}},{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":23,"address":[],"length":0,"stats":{"Line":0}},{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":30,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":57},{"path":["/","Users","christian.klat","dev","git","aeterna","opal-fetcher","src","state.rs"],"content":"//! Application state for the OPAL Data Fetcher.\n\nuse sqlx::PgPool;\nuse std::sync::Arc;\n\nuse crate::error::{FetcherError, Result};\n\n/// Configuration for the OPAL Data Fetcher server.\n#[derive(Debug, Clone)]\npub struct FetcherConfig {\n    /// PostgreSQL connection URL.\n    pub database_url: String,\n    /// Host to bind the server to.\n    pub host: String,\n    /// Port to bind the server to.\n    pub port: u16,\n    /// Enable PostgreSQL LISTEN/NOTIFY for real-time updates.\n    pub enable_listener: bool,\n    /// OPAL server URL for publishing updates (optional).\n    pub opal_server_url: Option<String>,\n    /// Maximum database pool connections.\n    pub max_connections: u32,\n}\n\nimpl Default for FetcherConfig {\n    fn default() -> Self {\n        Self {\n            database_url: String::new(),\n            host: \"0.0.0.0\".to_string(),\n            port: 8080,\n            enable_listener: true,\n            opal_server_url: None,\n            max_connections: 10,\n        }\n    }\n}\n\nimpl FetcherConfig {\n    /// Creates a new configuration from environment variables.\n    pub fn from_env() -> Result<Self> {\n        let database_url = std::env::var(\"DATABASE_URL\")\n            .map_err(|_| FetcherError::Configuration(\"DATABASE_URL not set\".to_string()))?;\n\n        Ok(Self {\n            database_url,\n            host: std::env::var(\"HOST\").unwrap_or_else(|_| \"0.0.0.0\".to_string()),\n            port: std::env::var(\"PORT\")\n                .ok()\n                .and_then(|p| p.parse().ok())\n                .unwrap_or(8080),\n            enable_listener: std::env::var(\"ENABLE_LISTENER\")\n                .map(|v| v == \"true\" || v == \"1\")\n                .unwrap_or(true),\n            opal_server_url: std::env::var(\"OPAL_SERVER_URL\").ok(),\n            max_connections: std::env::var(\"MAX_CONNECTIONS\")\n                .ok()\n                .and_then(|c| c.parse().ok())\n                .unwrap_or(10),\n        })\n    }\n\n    /// Creates a builder for configuration.\n    #[must_use]\n    pub fn builder() -> FetcherConfigBuilder {\n        FetcherConfigBuilder::default()\n    }\n}\n\n/// Builder for `FetcherConfig`.\n#[derive(Default)]\npub struct FetcherConfigBuilder {\n    database_url: Option<String>,\n    host: Option<String>,\n    port: Option<u16>,\n    enable_listener: Option<bool>,\n    opal_server_url: Option<String>,\n    max_connections: Option<u32>,\n}\n\nimpl FetcherConfigBuilder {\n    /// Sets the database URL.\n    #[must_use]\n    pub fn database_url(mut self, url: impl Into<String>) -> Self {\n        self.database_url = Some(url.into());\n        self\n    }\n\n    /// Sets the host to bind to.\n    #[must_use]\n    pub fn host(mut self, host: impl Into<String>) -> Self {\n        self.host = Some(host.into());\n        self\n    }\n\n    /// Sets the port to bind to.\n    #[must_use]\n    pub fn port(mut self, port: u16) -> Self {\n        self.port = Some(port);\n        self\n    }\n\n    /// Enables or disables the PostgreSQL listener.\n    #[must_use]\n    pub fn enable_listener(mut self, enable: bool) -> Self {\n        self.enable_listener = Some(enable);\n        self\n    }\n\n    /// Sets the OPAL server URL.\n    #[must_use]\n    pub fn opal_server_url(mut self, url: impl Into<String>) -> Self {\n        self.opal_server_url = Some(url.into());\n        self\n    }\n\n    /// Sets the maximum number of database connections.\n    #[must_use]\n    pub fn max_connections(mut self, max: u32) -> Self {\n        self.max_connections = Some(max);\n        self\n    }\n\n    /// Builds the configuration.\n    pub fn build(self) -> Result<FetcherConfig> {\n        let database_url = self\n            .database_url\n            .ok_or_else(|| FetcherError::Configuration(\"database_url is required\".to_string()))?;\n\n        Ok(FetcherConfig {\n            database_url,\n            host: self.host.unwrap_or_else(|| \"0.0.0.0\".to_string()),\n            port: self.port.unwrap_or(8080),\n            enable_listener: self.enable_listener.unwrap_or(true),\n            opal_server_url: self.opal_server_url,\n            max_connections: self.max_connections.unwrap_or(10),\n        })\n    }\n}\n\n/// Shared application state for Axum handlers.\n#[derive(Clone)]\npub struct AppState {\n    /// PostgreSQL connection pool.\n    pub pool: PgPool,\n    /// Server configuration.\n    pub config: Arc<FetcherConfig>,\n}\n\nimpl AppState {\n    /// Creates a new application state.\n    pub async fn new(config: FetcherConfig) -> Result<Self> {\n        let pool = sqlx::postgres::PgPoolOptions::new()\n            .max_connections(config.max_connections)\n            .connect(&config.database_url)\n            .await?;\n\n        Ok(Self {\n            pool,\n            config: Arc::new(config),\n        })\n    }\n\n    /// Creates application state from an existing pool (useful for testing).\n    #[must_use]\n    pub fn with_pool(pool: PgPool, config: FetcherConfig) -> Self {\n        Self {\n            pool,\n            config: Arc::new(config),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_config_default() {\n        let config = FetcherConfig::default();\n        assert_eq!(config.host, \"0.0.0.0\");\n        assert_eq!(config.port, 8080);\n        assert!(config.enable_listener);\n        assert_eq!(config.max_connections, 10);\n        assert!(config.opal_server_url.is_none());\n    }\n\n    #[test]\n    fn test_config_builder_success() {\n        let config = FetcherConfig::builder()\n            .database_url(\"postgres://localhost/test\")\n            .host(\"127.0.0.1\")\n            .port(3000)\n            .enable_listener(false)\n            .opal_server_url(\"http://opal:8181\")\n            .max_connections(20)\n            .build()\n            .unwrap();\n\n        assert_eq!(config.database_url, \"postgres://localhost/test\");\n        assert_eq!(config.host, \"127.0.0.1\");\n        assert_eq!(config.port, 3000);\n        assert!(!config.enable_listener);\n        assert_eq!(config.opal_server_url, Some(\"http://opal:8181\".to_string()));\n        assert_eq!(config.max_connections, 20);\n    }\n\n    #[test]\n    fn test_config_builder_missing_database_url() {\n        let result = FetcherConfig::builder().host(\"127.0.0.1\").build();\n\n        assert!(result.is_err());\n        let err = result.unwrap_err();\n        assert!(matches!(err, FetcherError::Configuration(_)));\n    }\n\n    #[test]\n    fn test_config_builder_defaults() {\n        let config = FetcherConfig::builder()\n            .database_url(\"postgres://localhost/test\")\n            .build()\n            .unwrap();\n\n        assert_eq!(config.host, \"0.0.0.0\");\n        assert_eq!(config.port, 8080);\n        assert!(config.enable_listener);\n        assert_eq!(config.max_connections, 10);\n    }\n}\n","traces":[{"line":26,"address":[],"length":0,"stats":{"Line":2}},{"line":28,"address":[],"length":0,"stats":{"Line":4}},{"line":29,"address":[],"length":0,"stats":{"Line":4}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":42,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":48,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":3}},{"line":65,"address":[],"length":0,"stats":{"Line":3}},{"line":83,"address":[],"length":0,"stats":{"Line":2}},{"line":84,"address":[],"length":0,"stats":{"Line":4}},{"line":85,"address":[],"length":0,"stats":{"Line":2}},{"line":90,"address":[],"length":0,"stats":{"Line":2}},{"line":91,"address":[],"length":0,"stats":{"Line":4}},{"line":92,"address":[],"length":0,"stats":{"Line":2}},{"line":97,"address":[],"length":0,"stats":{"Line":1}},{"line":98,"address":[],"length":0,"stats":{"Line":1}},{"line":99,"address":[],"length":0,"stats":{"Line":1}},{"line":104,"address":[],"length":0,"stats":{"Line":1}},{"line":105,"address":[],"length":0,"stats":{"Line":1}},{"line":106,"address":[],"length":0,"stats":{"Line":1}},{"line":111,"address":[],"length":0,"stats":{"Line":1}},{"line":112,"address":[],"length":0,"stats":{"Line":2}},{"line":113,"address":[],"length":0,"stats":{"Line":1}},{"line":118,"address":[],"length":0,"stats":{"Line":1}},{"line":119,"address":[],"length":0,"stats":{"Line":1}},{"line":120,"address":[],"length":0,"stats":{"Line":1}},{"line":124,"address":[],"length":0,"stats":{"Line":3}},{"line":125,"address":[],"length":0,"stats":{"Line":5}},{"line":126,"address":[],"length":0,"stats":{"Line":3}},{"line":127,"address":[],"length":0,"stats":{"Line":6}},{"line":130,"address":[],"length":0,"stats":{"Line":2}},{"line":131,"address":[],"length":0,"stats":{"Line":6}},{"line":132,"address":[],"length":0,"stats":{"Line":4}},{"line":133,"address":[],"length":0,"stats":{"Line":4}},{"line":134,"address":[],"length":0,"stats":{"Line":2}},{"line":135,"address":[],"length":0,"stats":{"Line":4}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}}],"covered":33,"coverable":60},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","src","approval_workflow.rs"],"content":"use chrono::{DateTime, Utc};\nuse serde::{Deserialize, Serialize};\nuse uuid::Uuid;\n\n#[derive(Debug, Clone, Serialize, Deserialize, Default)]\npub struct ApprovalWorkflowContext {\n    pub request_id: Uuid,\n    pub request_type: String,\n    pub required_approvals: i32,\n    pub current_approvals: i32,\n    pub approval_mode: ApprovalModeKind,\n    pub timeout_hours: i32,\n    pub auto_approve_low_risk: bool,\n    pub risk_level: RiskLevelKind,\n}\n\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq, Default)]\npub enum ApprovalModeKind {\n    Single,\n    #[default]\n    Quorum,\n    Unanimous,\n}\n\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq, Default)]\npub enum RiskLevelKind {\n    Low,\n    #[default]\n    Medium,\n    High,\n    Critical,\n}\n\n#[derive(Debug, Clone)]\npub enum ApprovalEvent {\n    Submit {\n        requestor_id: Uuid,\n        submitted_at: DateTime<Utc>,\n    },\n    Approve {\n        approver_id: Uuid,\n        approved_at: DateTime<Utc>,\n        comment: Option<String>,\n    },\n    Reject {\n        rejector_id: Uuid,\n        rejected_at: DateTime<Utc>,\n        reason: String,\n    },\n    Expire {\n        expired_at: DateTime<Utc>,\n    },\n    Cancel {\n        cancelled_by: Uuid,\n        cancelled_at: DateTime<Utc>,\n    },\n    Apply {\n        applied_by: Uuid,\n        applied_at: DateTime<Utc>,\n    },\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ApprovalDecisionRecord {\n    pub approver_id: Uuid,\n    pub timestamp: DateTime<Utc>,\n    pub comment: Option<String>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\npub enum WorkflowState {\n    Draft,\n    Pending {\n        submitted_at: DateTime<Utc>,\n    },\n    Approved {\n        approved_at: DateTime<Utc>,\n    },\n    Applied {\n        applied_at: DateTime<Utc>,\n    },\n    Rejected {\n        reason: String,\n        rejected_at: DateTime<Utc>,\n    },\n    Expired {\n        expired_at: DateTime<Utc>,\n    },\n    Cancelled {\n        cancelled_at: DateTime<Utc>,\n    },\n}\n\nimpl Default for WorkflowState {\n    fn default() -> Self {\n        Self::Draft\n    }\n}\n\n#[derive(Debug, Clone, Default, Serialize, Deserialize)]\npub struct ApprovalWorkflow {\n    pub context: ApprovalWorkflowContext,\n    pub state: WorkflowState,\n    pub decisions: Vec<ApprovalDecisionRecord>,\n    pub rejection_reason: Option<String>,\n    pub resolution_timestamp: Option<DateTime<Utc>>,\n}\n\nimpl ApprovalWorkflow {\n    pub fn new(context: ApprovalWorkflowContext) -> Self {\n        Self {\n            context,\n            state: WorkflowState::Draft,\n            decisions: Vec::new(),\n            rejection_reason: None,\n            resolution_timestamp: None,\n        }\n    }\n\n    fn should_auto_approve(&self) -> bool {\n        self.context.auto_approve_low_risk && self.context.risk_level == RiskLevelKind::Low\n    }\n\n    fn is_fully_approved(&self) -> bool {\n        match self.context.approval_mode {\n            ApprovalModeKind::Single => self.context.current_approvals >= 1,\n            ApprovalModeKind::Quorum => {\n                self.context.current_approvals >= self.context.required_approvals\n            }\n            ApprovalModeKind::Unanimous => {\n                self.context.current_approvals >= self.context.required_approvals\n            }\n        }\n    }\n\n    fn record_approval(\n        &mut self,\n        approver_id: Uuid,\n        timestamp: DateTime<Utc>,\n        comment: Option<String>,\n    ) {\n        self.decisions.push(ApprovalDecisionRecord {\n            approver_id,\n            timestamp,\n            comment,\n        });\n        self.context.current_approvals += 1;\n    }\n\n    pub fn handle(&mut self, event: ApprovalEvent) -> Result<(), WorkflowError> {\n        match (&self.state, event) {\n            (WorkflowState::Draft, ApprovalEvent::Submit { submitted_at, .. }) => {\n                if self.should_auto_approve() {\n                    self.resolution_timestamp = Some(submitted_at);\n                    self.state = WorkflowState::Approved {\n                        approved_at: submitted_at,\n                    };\n                    tracing::info!(request_id = ?self.context.request_id, \"Auto-approved low-risk request\");\n                } else {\n                    self.state = WorkflowState::Pending { submitted_at };\n                    tracing::info!(request_id = ?self.context.request_id, \"Request submitted for approval\");\n                }\n                Ok(())\n            }\n\n            (\n                WorkflowState::Pending { .. },\n                ApprovalEvent::Approve {\n                    approver_id,\n                    approved_at,\n                    comment,\n                },\n            ) => {\n                self.record_approval(approver_id, approved_at, comment);\n\n                if self.is_fully_approved() {\n                    self.resolution_timestamp = Some(approved_at);\n                    self.state = WorkflowState::Approved { approved_at };\n                    tracing::info!(\n                        request_id = ?self.context.request_id,\n                        approvals = self.context.current_approvals,\n                        \"Request fully approved\"\n                    );\n                } else {\n                    tracing::info!(\n                        request_id = ?self.context.request_id,\n                        current = self.context.current_approvals,\n                        required = self.context.required_approvals,\n                        \"Approval recorded, waiting for more\"\n                    );\n                }\n                Ok(())\n            }\n\n            (\n                WorkflowState::Pending { .. },\n                ApprovalEvent::Reject {\n                    rejected_at,\n                    reason,\n                    ..\n                },\n            ) => {\n                self.rejection_reason = Some(reason.clone());\n                self.resolution_timestamp = Some(rejected_at);\n                self.state = WorkflowState::Rejected {\n                    reason,\n                    rejected_at,\n                };\n                tracing::info!(request_id = ?self.context.request_id, \"Request rejected\");\n                Ok(())\n            }\n\n            (WorkflowState::Pending { .. }, ApprovalEvent::Expire { expired_at }) => {\n                self.resolution_timestamp = Some(expired_at);\n                self.state = WorkflowState::Expired { expired_at };\n                tracing::info!(request_id = ?self.context.request_id, \"Request expired\");\n                Ok(())\n            }\n\n            (WorkflowState::Pending { .. }, ApprovalEvent::Cancel { cancelled_at, .. }) => {\n                self.resolution_timestamp = Some(cancelled_at);\n                self.state = WorkflowState::Cancelled { cancelled_at };\n                tracing::info!(request_id = ?self.context.request_id, \"Request cancelled\");\n                Ok(())\n            }\n\n            (WorkflowState::Approved { .. }, ApprovalEvent::Apply { applied_at, .. }) => {\n                self.state = WorkflowState::Applied { applied_at };\n                tracing::info!(request_id = ?self.context.request_id, \"Request applied\");\n                Ok(())\n            }\n\n            (current_state, event) => Err(WorkflowError::InvalidTransition {\n                current_state: format!(\"{current_state:?}\"),\n                event: format!(\"{event:?}\"),\n            }),\n        }\n    }\n\n    pub fn status_string(&self) -> &'static str {\n        match &self.state {\n            WorkflowState::Draft => \"draft\",\n            WorkflowState::Pending { .. } => \"pending\",\n            WorkflowState::Approved { .. } => \"approved\",\n            WorkflowState::Applied { .. } => \"applied\",\n            WorkflowState::Rejected { .. } => \"rejected\",\n            WorkflowState::Expired { .. } => \"expired\",\n            WorkflowState::Cancelled { .. } => \"cancelled\",\n        }\n    }\n\n    pub fn is_terminal(&self) -> bool {\n        matches!(\n            self.state,\n            WorkflowState::Applied { .. }\n                | WorkflowState::Rejected { .. }\n                | WorkflowState::Expired { .. }\n                | WorkflowState::Cancelled { .. }\n        )\n    }\n\n    pub fn is_pending(&self) -> bool {\n        matches!(self.state, WorkflowState::Pending { .. })\n    }\n\n    pub fn is_approved(&self) -> bool {\n        matches!(\n            self.state,\n            WorkflowState::Approved { .. } | WorkflowState::Applied { .. }\n        )\n    }\n}\n\n#[derive(Debug, thiserror::Error)]\npub enum WorkflowError {\n    #[error(\"Invalid transition from {current_state} with event {event}\")]\n    InvalidTransition {\n        current_state: String,\n        event: String,\n    },\n}\n\npub fn create_workflow(context: ApprovalWorkflowContext) -> ApprovalWorkflow {\n    ApprovalWorkflow::new(context)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    fn test_context() -> ApprovalWorkflowContext {\n        ApprovalWorkflowContext {\n            request_id: Uuid::new_v4(),\n            request_type: \"policy\".to_string(),\n            required_approvals: 2,\n            current_approvals: 0,\n            approval_mode: ApprovalModeKind::Quorum,\n            timeout_hours: 72,\n            auto_approve_low_risk: false,\n            risk_level: RiskLevelKind::Medium,\n        }\n    }\n\n    #[test]\n    fn test_submit_transitions_to_pending() {\n        let mut workflow = create_workflow(test_context());\n\n        workflow\n            .handle(ApprovalEvent::Submit {\n                requestor_id: Uuid::new_v4(),\n                submitted_at: Utc::now(),\n            })\n            .unwrap();\n\n        assert!(matches!(workflow.state, WorkflowState::Pending { .. }));\n    }\n\n    #[test]\n    fn test_auto_approve_low_risk() {\n        let mut ctx = test_context();\n        ctx.auto_approve_low_risk = true;\n        ctx.risk_level = RiskLevelKind::Low;\n\n        let mut workflow = create_workflow(ctx);\n\n        workflow\n            .handle(ApprovalEvent::Submit {\n                requestor_id: Uuid::new_v4(),\n                submitted_at: Utc::now(),\n            })\n            .unwrap();\n\n        assert!(matches!(workflow.state, WorkflowState::Approved { .. }));\n    }\n\n    #[test]\n    fn test_quorum_approval() {\n        let mut workflow = create_workflow(test_context());\n\n        workflow\n            .handle(ApprovalEvent::Submit {\n                requestor_id: Uuid::new_v4(),\n                submitted_at: Utc::now(),\n            })\n            .unwrap();\n\n        workflow\n            .handle(ApprovalEvent::Approve {\n                approver_id: Uuid::new_v4(),\n                approved_at: Utc::now(),\n                comment: None,\n            })\n            .unwrap();\n\n        assert!(matches!(workflow.state, WorkflowState::Pending { .. }));\n        assert_eq!(workflow.decisions.len(), 1);\n\n        workflow\n            .handle(ApprovalEvent::Approve {\n                approver_id: Uuid::new_v4(),\n                approved_at: Utc::now(),\n                comment: Some(\"LGTM\".to_string()),\n            })\n            .unwrap();\n\n        assert!(matches!(workflow.state, WorkflowState::Approved { .. }));\n        assert_eq!(workflow.decisions.len(), 2);\n    }\n\n    #[test]\n    fn test_single_approval_mode() {\n        let mut ctx = test_context();\n        ctx.approval_mode = ApprovalModeKind::Single;\n        ctx.required_approvals = 1;\n\n        let mut workflow = create_workflow(ctx);\n\n        workflow\n            .handle(ApprovalEvent::Submit {\n                requestor_id: Uuid::new_v4(),\n                submitted_at: Utc::now(),\n            })\n            .unwrap();\n\n        workflow\n            .handle(ApprovalEvent::Approve {\n                approver_id: Uuid::new_v4(),\n                approved_at: Utc::now(),\n                comment: None,\n            })\n            .unwrap();\n\n        assert!(matches!(workflow.state, WorkflowState::Approved { .. }));\n    }\n\n    #[test]\n    fn test_rejection() {\n        let mut workflow = create_workflow(test_context());\n\n        workflow\n            .handle(ApprovalEvent::Submit {\n                requestor_id: Uuid::new_v4(),\n                submitted_at: Utc::now(),\n            })\n            .unwrap();\n\n        workflow\n            .handle(ApprovalEvent::Reject {\n                rejector_id: Uuid::new_v4(),\n                rejected_at: Utc::now(),\n                reason: \"Does not meet requirements\".to_string(),\n            })\n            .unwrap();\n\n        assert!(matches!(workflow.state, WorkflowState::Rejected { .. }));\n        assert_eq!(\n            workflow.rejection_reason,\n            Some(\"Does not meet requirements\".to_string())\n        );\n    }\n\n    #[test]\n    fn test_expiration() {\n        let mut workflow = create_workflow(test_context());\n\n        workflow\n            .handle(ApprovalEvent::Submit {\n                requestor_id: Uuid::new_v4(),\n                submitted_at: Utc::now(),\n            })\n            .unwrap();\n\n        workflow\n            .handle(ApprovalEvent::Expire {\n                expired_at: Utc::now(),\n            })\n            .unwrap();\n\n        assert!(matches!(workflow.state, WorkflowState::Expired { .. }));\n    }\n\n    #[test]\n    fn test_cancellation() {\n        let mut workflow = create_workflow(test_context());\n\n        workflow\n            .handle(ApprovalEvent::Submit {\n                requestor_id: Uuid::new_v4(),\n                submitted_at: Utc::now(),\n            })\n            .unwrap();\n\n        workflow\n            .handle(ApprovalEvent::Cancel {\n                cancelled_by: Uuid::new_v4(),\n                cancelled_at: Utc::now(),\n            })\n            .unwrap();\n\n        assert!(matches!(workflow.state, WorkflowState::Cancelled { .. }));\n    }\n\n    #[test]\n    fn test_apply_after_approval() {\n        let mut ctx = test_context();\n        ctx.approval_mode = ApprovalModeKind::Single;\n        ctx.required_approvals = 1;\n\n        let mut workflow = create_workflow(ctx);\n\n        workflow\n            .handle(ApprovalEvent::Submit {\n                requestor_id: Uuid::new_v4(),\n                submitted_at: Utc::now(),\n            })\n            .unwrap();\n\n        workflow\n            .handle(ApprovalEvent::Approve {\n                approver_id: Uuid::new_v4(),\n                approved_at: Utc::now(),\n                comment: None,\n            })\n            .unwrap();\n\n        workflow\n            .handle(ApprovalEvent::Apply {\n                applied_by: Uuid::new_v4(),\n                applied_at: Utc::now(),\n            })\n            .unwrap();\n\n        assert!(matches!(workflow.state, WorkflowState::Applied { .. }));\n    }\n\n    #[test]\n    fn test_invalid_transition() {\n        let mut workflow = create_workflow(test_context());\n\n        let result = workflow.handle(ApprovalEvent::Approve {\n            approver_id: Uuid::new_v4(),\n            approved_at: Utc::now(),\n            comment: None,\n        });\n\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_serde_roundtrip() {\n        let mut workflow = create_workflow(test_context());\n\n        workflow\n            .handle(ApprovalEvent::Submit {\n                requestor_id: Uuid::new_v4(),\n                submitted_at: Utc::now(),\n            })\n            .unwrap();\n\n        workflow\n            .handle(ApprovalEvent::Approve {\n                approver_id: Uuid::new_v4(),\n                approved_at: Utc::now(),\n                comment: Some(\"First approval\".to_string()),\n            })\n            .unwrap();\n\n        let json = serde_json::to_string(&workflow).unwrap();\n        let restored: ApprovalWorkflow = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(workflow.status_string(), restored.status_string());\n        assert_eq!(workflow.decisions.len(), restored.decisions.len());\n        assert_eq!(\n            workflow.context.current_approvals,\n            restored.context.current_approvals\n        );\n    }\n\n    #[test]\n    fn test_status_helpers() {\n        let mut workflow = create_workflow(test_context());\n        assert!(!workflow.is_pending());\n        assert!(!workflow.is_approved());\n        assert!(!workflow.is_terminal());\n\n        workflow\n            .handle(ApprovalEvent::Submit {\n                requestor_id: Uuid::new_v4(),\n                submitted_at: Utc::now(),\n            })\n            .unwrap();\n\n        assert!(workflow.is_pending());\n        assert!(!workflow.is_approved());\n        assert!(!workflow.is_terminal());\n    }\n}\n","traces":[{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":20}},{"line":114,"address":[],"length":0,"stats":{"Line":40}},{"line":120,"address":[],"length":0,"stats":{"Line":18}},{"line":121,"address":[],"length":0,"stats":{"Line":20}},{"line":124,"address":[],"length":0,"stats":{"Line":6}},{"line":125,"address":[],"length":0,"stats":{"Line":6}},{"line":126,"address":[],"length":0,"stats":{"Line":2}},{"line":128,"address":[],"length":0,"stats":{"Line":4}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":6}},{"line":142,"address":[],"length":0,"stats":{"Line":18}},{"line":143,"address":[],"length":0,"stats":{"Line":12}},{"line":144,"address":[],"length":0,"stats":{"Line":6}},{"line":145,"address":[],"length":0,"stats":{"Line":6}},{"line":147,"address":[],"length":0,"stats":{"Line":6}},{"line":150,"address":[],"length":0,"stats":{"Line":30}},{"line":151,"address":[],"length":0,"stats":{"Line":60}},{"line":152,"address":[],"length":0,"stats":{"Line":18}},{"line":153,"address":[],"length":0,"stats":{"Line":36}},{"line":154,"address":[],"length":0,"stats":{"Line":2}},{"line":155,"address":[],"length":0,"stats":{"Line":4}},{"line":156,"address":[],"length":0,"stats":{"Line":2}},{"line":158,"address":[],"length":0,"stats":{"Line":2}},{"line":160,"address":[],"length":0,"stats":{"Line":32}},{"line":161,"address":[],"length":0,"stats":{"Line":16}},{"line":163,"address":[],"length":0,"stats":{"Line":18}},{"line":169,"address":[],"length":0,"stats":{"Line":6}},{"line":170,"address":[],"length":0,"stats":{"Line":6}},{"line":171,"address":[],"length":0,"stats":{"Line":6}},{"line":174,"address":[],"length":0,"stats":{"Line":30}},{"line":176,"address":[],"length":0,"stats":{"Line":12}},{"line":177,"address":[],"length":0,"stats":{"Line":4}},{"line":178,"address":[],"length":0,"stats":{"Line":8}},{"line":179,"address":[],"length":0,"stats":{"Line":4}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":2}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":6}},{"line":198,"address":[],"length":0,"stats":{"Line":2}},{"line":199,"address":[],"length":0,"stats":{"Line":2}},{"line":203,"address":[],"length":0,"stats":{"Line":4}},{"line":204,"address":[],"length":0,"stats":{"Line":2}},{"line":205,"address":[],"length":0,"stats":{"Line":4}},{"line":206,"address":[],"length":0,"stats":{"Line":2}},{"line":207,"address":[],"length":0,"stats":{"Line":2}},{"line":209,"address":[],"length":0,"stats":{"Line":2}},{"line":210,"address":[],"length":0,"stats":{"Line":2}},{"line":213,"address":[],"length":0,"stats":{"Line":1}},{"line":214,"address":[],"length":0,"stats":{"Line":1}},{"line":215,"address":[],"length":0,"stats":{"Line":2}},{"line":216,"address":[],"length":0,"stats":{"Line":1}},{"line":217,"address":[],"length":0,"stats":{"Line":1}},{"line":220,"address":[],"length":0,"stats":{"Line":1}},{"line":221,"address":[],"length":0,"stats":{"Line":1}},{"line":222,"address":[],"length":0,"stats":{"Line":2}},{"line":223,"address":[],"length":0,"stats":{"Line":1}},{"line":224,"address":[],"length":0,"stats":{"Line":1}},{"line":227,"address":[],"length":0,"stats":{"Line":1}},{"line":228,"address":[],"length":0,"stats":{"Line":2}},{"line":229,"address":[],"length":0,"stats":{"Line":1}},{"line":230,"address":[],"length":0,"stats":{"Line":1}},{"line":233,"address":[],"length":0,"stats":{"Line":3}},{"line":234,"address":[],"length":0,"stats":{"Line":3}},{"line":235,"address":[],"length":0,"stats":{"Line":1}},{"line":240,"address":[],"length":0,"stats":{"Line":2}},{"line":241,"address":[],"length":0,"stats":{"Line":2}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":2}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":252,"address":[],"length":0,"stats":{"Line":2}},{"line":253,"address":[],"length":0,"stats":{"Line":2}},{"line":254,"address":[],"length":0,"stats":{"Line":2}},{"line":262,"address":[],"length":0,"stats":{"Line":2}},{"line":263,"address":[],"length":0,"stats":{"Line":3}},{"line":266,"address":[],"length":0,"stats":{"Line":2}},{"line":267,"address":[],"length":0,"stats":{"Line":2}},{"line":268,"address":[],"length":0,"stats":{"Line":2}},{"line":283,"address":[],"length":0,"stats":{"Line":11}},{"line":284,"address":[],"length":0,"stats":{"Line":22}}],"covered":74,"coverable":85},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","src","budget_storage.rs"],"content":"use mk_core::types::MemoryLayer;\nuse serde::{Deserialize, Serialize};\nuse sqlx::{Pool, Postgres, Row};\nuse thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum BudgetStorageError {\n    #[error(\"Database error: {0}\")]\n    Database(#[from] sqlx::Error),\n    #[error(\"Serialization error: {0}\")]\n    Serialization(#[from] serde_json::Error),\n    #[error(\"Budget not found for tenant: {0}\")]\n    NotFound(String),\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct StoredBudget {\n    pub tenant_id: String,\n    pub daily_token_limit: i64,\n    pub hourly_token_limit: i64,\n    pub per_layer_limits: serde_json::Value,\n    pub warning_threshold_percent: i32,\n    pub critical_threshold_percent: i32,\n    pub exhausted_action: String,\n    pub created_at: i64,\n    pub updated_at: i64,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct StoredUsage {\n    pub tenant_id: String,\n    pub layer: String,\n    pub window_type: String,\n    pub tokens_used: i64,\n    pub window_start: i64,\n}\n\npub struct BudgetStorage {\n    pool: Pool<Postgres>,\n}\n\nimpl BudgetStorage {\n    pub fn new(pool: Pool<Postgres>) -> Self {\n        Self { pool }\n    }\n\n    pub async fn initialize_schema(&self) -> Result<(), BudgetStorageError> {\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS summarization_budgets (\n                tenant_id TEXT PRIMARY KEY,\n                daily_token_limit BIGINT NOT NULL DEFAULT 1000000,\n                hourly_token_limit BIGINT NOT NULL DEFAULT 100000,\n                per_layer_limits JSONB NOT NULL DEFAULT '{}',\n                warning_threshold_percent INTEGER NOT NULL DEFAULT 80,\n                critical_threshold_percent INTEGER NOT NULL DEFAULT 90,\n                exhausted_action TEXT NOT NULL DEFAULT 'reject',\n                created_at BIGINT NOT NULL,\n                updated_at BIGINT NOT NULL\n            )\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS summarization_usage (\n                tenant_id TEXT NOT NULL,\n                layer TEXT NOT NULL,\n                window_type TEXT NOT NULL,\n                tokens_used BIGINT NOT NULL DEFAULT 0,\n                window_start BIGINT NOT NULL,\n                PRIMARY KEY (tenant_id, layer, window_type)\n            )\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE INDEX IF NOT EXISTS idx_summarization_usage_tenant \n             ON summarization_usage(tenant_id)\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    pub async fn get_budget(\n        &self,\n        tenant_id: &str,\n    ) -> Result<Option<StoredBudget>, BudgetStorageError> {\n        let row = sqlx::query(\n            \"SELECT tenant_id, daily_token_limit, hourly_token_limit, per_layer_limits,\n                    warning_threshold_percent, critical_threshold_percent, exhausted_action,\n                    created_at, updated_at\n             FROM summarization_budgets WHERE tenant_id = $1\",\n        )\n        .bind(tenant_id)\n        .fetch_optional(&self.pool)\n        .await?;\n\n        match row {\n            Some(row) => Ok(Some(StoredBudget {\n                tenant_id: row.get(\"tenant_id\"),\n                daily_token_limit: row.get(\"daily_token_limit\"),\n                hourly_token_limit: row.get(\"hourly_token_limit\"),\n                per_layer_limits: row.get(\"per_layer_limits\"),\n                warning_threshold_percent: row.get(\"warning_threshold_percent\"),\n                critical_threshold_percent: row.get(\"critical_threshold_percent\"),\n                exhausted_action: row.get(\"exhausted_action\"),\n                created_at: row.get(\"created_at\"),\n                updated_at: row.get(\"updated_at\"),\n            })),\n            None => Ok(None),\n        }\n    }\n\n    pub async fn upsert_budget(&self, budget: &StoredBudget) -> Result<(), BudgetStorageError> {\n        sqlx::query(\n            \"INSERT INTO summarization_budgets \n             (tenant_id, daily_token_limit, hourly_token_limit, per_layer_limits,\n              warning_threshold_percent, critical_threshold_percent, exhausted_action,\n              created_at, updated_at)\n             VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)\n             ON CONFLICT (tenant_id) DO UPDATE SET\n                daily_token_limit = EXCLUDED.daily_token_limit,\n                hourly_token_limit = EXCLUDED.hourly_token_limit,\n                per_layer_limits = EXCLUDED.per_layer_limits,\n                warning_threshold_percent = EXCLUDED.warning_threshold_percent,\n                critical_threshold_percent = EXCLUDED.critical_threshold_percent,\n                exhausted_action = EXCLUDED.exhausted_action,\n                updated_at = EXCLUDED.updated_at\",\n        )\n        .bind(&budget.tenant_id)\n        .bind(budget.daily_token_limit)\n        .bind(budget.hourly_token_limit)\n        .bind(&budget.per_layer_limits)\n        .bind(budget.warning_threshold_percent)\n        .bind(budget.critical_threshold_percent)\n        .bind(&budget.exhausted_action)\n        .bind(budget.created_at)\n        .bind(budget.updated_at)\n        .execute(&self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    pub async fn delete_budget(&self, tenant_id: &str) -> Result<bool, BudgetStorageError> {\n        let result = sqlx::query(\"DELETE FROM summarization_budgets WHERE tenant_id = $1\")\n            .bind(tenant_id)\n            .execute(&self.pool)\n            .await?;\n\n        Ok(result.rows_affected() > 0)\n    }\n\n    pub async fn record_usage(\n        &self,\n        tenant_id: &str,\n        layer: MemoryLayer,\n        window_type: &str,\n        tokens: i64,\n        window_start: i64,\n    ) -> Result<(), BudgetStorageError> {\n        let layer_str = layer.display_name();\n\n        sqlx::query(\n            \"INSERT INTO summarization_usage \n             (tenant_id, layer, window_type, tokens_used, window_start)\n             VALUES ($1, $2, $3, $4, $5)\n             ON CONFLICT (tenant_id, layer, window_type) DO UPDATE SET\n                tokens_used = CASE \n                    WHEN summarization_usage.window_start < $5 THEN $4\n                    ELSE summarization_usage.tokens_used + $4\n                END,\n                window_start = CASE \n                    WHEN summarization_usage.window_start < $5 THEN $5\n                    ELSE summarization_usage.window_start\n                END\",\n        )\n        .bind(tenant_id)\n        .bind(layer_str)\n        .bind(window_type)\n        .bind(tokens)\n        .bind(window_start)\n        .execute(&self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    pub async fn get_usage(\n        &self,\n        tenant_id: &str,\n        layer: Option<MemoryLayer>,\n        window_type: &str,\n        current_window_start: i64,\n    ) -> Result<i64, BudgetStorageError> {\n        let query = if let Some(l) = layer {\n            let layer_str = l.display_name();\n            sqlx::query(\n                \"SELECT COALESCE(SUM(\n                    CASE WHEN window_start >= $3 THEN tokens_used ELSE 0 END\n                ), 0) as total\n                 FROM summarization_usage \n                 WHERE tenant_id = $1 AND layer = $2 AND window_type = $4\",\n            )\n            .bind(tenant_id)\n            .bind(layer_str)\n            .bind(current_window_start)\n            .bind(window_type)\n        } else {\n            sqlx::query(\n                \"SELECT COALESCE(SUM(\n                    CASE WHEN window_start >= $2 THEN tokens_used ELSE 0 END\n                ), 0) as total\n                 FROM summarization_usage \n                 WHERE tenant_id = $1 AND window_type = $3\",\n            )\n            .bind(tenant_id)\n            .bind(current_window_start)\n            .bind(window_type)\n        };\n\n        let row = query.fetch_one(&self.pool).await?;\n        let total: i64 = row.get(\"total\");\n        Ok(total)\n    }\n\n    pub async fn get_all_layer_usage(\n        &self,\n        tenant_id: &str,\n        window_type: &str,\n        current_window_start: i64,\n    ) -> Result<Vec<(String, i64)>, BudgetStorageError> {\n        let rows = sqlx::query(\n            \"SELECT layer, \n                    CASE WHEN window_start >= $2 THEN tokens_used ELSE 0 END as tokens\n             FROM summarization_usage \n             WHERE tenant_id = $1 AND window_type = $3\",\n        )\n        .bind(tenant_id)\n        .bind(current_window_start)\n        .bind(window_type)\n        .fetch_all(&self.pool)\n        .await?;\n\n        let results: Vec<(String, i64)> = rows\n            .iter()\n            .map(|row| (row.get(\"layer\"), row.get(\"tokens\")))\n            .collect();\n\n        Ok(results)\n    }\n\n    pub async fn reset_usage(\n        &self,\n        tenant_id: &str,\n        window_type: &str,\n    ) -> Result<(), BudgetStorageError> {\n        sqlx::query(\n            \"DELETE FROM summarization_usage \n             WHERE tenant_id = $1 AND window_type = $2\",\n        )\n        .bind(tenant_id)\n        .bind(window_type)\n        .execute(&self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    pub async fn cleanup_old_usage(\n        &self,\n        before_timestamp: i64,\n    ) -> Result<u64, BudgetStorageError> {\n        let result = sqlx::query(\"DELETE FROM summarization_usage WHERE window_start < $1\")\n            .bind(before_timestamp)\n            .execute(&self.pool)\n            .await?;\n\n        Ok(result.rows_affected())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_stored_budget_serialization() {\n        let budget = StoredBudget {\n            tenant_id: \"test-tenant\".to_string(),\n            daily_token_limit: 1_000_000,\n            hourly_token_limit: 100_000,\n            per_layer_limits: serde_json::json!({\n                \"session\": 50000,\n                \"project\": 100000\n            }),\n            warning_threshold_percent: 80,\n            critical_threshold_percent: 90,\n            exhausted_action: \"reject\".to_string(),\n            created_at: 1704067200,\n            updated_at: 1704067200,\n        };\n\n        let json = serde_json::to_string(&budget).unwrap();\n        let deserialized: StoredBudget = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(deserialized.tenant_id, \"test-tenant\");\n        assert_eq!(deserialized.daily_token_limit, 1_000_000);\n        assert_eq!(deserialized.exhausted_action, \"reject\");\n    }\n\n    #[test]\n    fn test_stored_usage_serialization() {\n        let usage = StoredUsage {\n            tenant_id: \"test-tenant\".to_string(),\n            layer: \"session\".to_string(),\n            window_type: \"daily\".to_string(),\n            tokens_used: 5000,\n            window_start: 1704067200,\n        };\n\n        let json = serde_json::to_string(&usage).unwrap();\n        let deserialized: StoredUsage = serde_json::from_str(&json).unwrap();\n\n        assert_eq!(deserialized.tenant_id, \"test-tenant\");\n        assert_eq!(deserialized.tokens_used, 5000);\n    }\n}\n","traces":[{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":0}},{"line":221,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":225,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":0}},{"line":256,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":0}},{"line":270,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":88},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","src","events.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::EventPublisher;\nuse mk_core::types::GovernanceEvent;\nuse redis::AsyncCommands;\nuse std::sync::Arc;\nuse thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum EventError {\n    #[error(\"Redis error: {0}\")]\n    Redis(#[from] redis::RedisError),\n    #[error(\"Serialization error: {0}\")]\n    Serialization(#[from] serde_json::Error),\n    #[error(\"Internal error: {0}\")]\n    Internal(String),\n}\n\npub struct RedisPublisher {\n    client: Arc<redis::Client>,\n    stream_name: String,\n}\n\nimpl RedisPublisher {\n    pub fn new(connection_url: &str, stream_name: &str) -> Result<Self, EventError> {\n        let client = redis::Client::open(connection_url)?;\n        Ok(Self {\n            client: Arc::new(client),\n            stream_name: stream_name.to_string(),\n        })\n    }\n}\n\n#[async_trait]\nimpl EventPublisher for RedisPublisher {\n    type Error = EventError;\n\n    async fn publish(&self, event: GovernanceEvent) -> Result<(), Self::Error> {\n        let mut conn = self.client.get_connection_manager().await?;\n        let event_json = serde_json::to_string(&event)?;\n\n        let _: String = conn\n            .xadd(&self.stream_name, \"*\", &[(\"event\", event_json)])\n            .await?;\n\n        Ok(())\n    }\n\n    async fn subscribe(\n        &self,\n        _channels: &[&str],\n    ) -> Result<tokio::sync::mpsc::Receiver<GovernanceEvent>, Self::Error> {\n        let client = self.client.clone();\n        let stream_name = self.stream_name.clone();\n        let (tx, rx) = tokio::sync::mpsc::channel(100);\n\n        tokio::spawn(async move {\n            if let Ok(mut conn) = client.get_connection_manager().await {\n                let mut last_id = \"0\".to_string();\n\n                loop {\n                    let opts = redis::streams::StreamReadOptions::default()\n                        .block(0)\n                        .count(10);\n\n                    let result: Result<redis::streams::StreamReadReply, redis::RedisError> = conn\n                        .xread_options(&[&stream_name], &[&last_id], &opts)\n                        .await;\n\n                    match result {\n                        Ok(reply) => {\n                            for stream in reply.keys {\n                                for record in stream.ids {\n                                    if let Some(event_json) = record.map.get(\"event\") {\n                                        let event_str: String =\n                                            redis::from_redis_value(event_json.clone())\n                                                .unwrap_or_default();\n                                        if let Ok(event) =\n                                            serde_json::from_str::<GovernanceEvent>(&event_str)\n                                        {\n                                            if tx.send(event).await.is_err() {\n                                                return;\n                                            }\n                                        }\n                                    }\n                                    last_id = record.id;\n                                }\n                            }\n                        }\n                        Err(e) => {\n                            tracing::error!(\"Redis subscription error: {}\", e);\n                            tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;\n                        }\n                    }\n                }\n            }\n        });\n\n        Ok(rx)\n    }\n}\n\npub struct MultiPublisher<E: std::error::Error + Send + Sync + 'static> {\n    publishers: Vec<Box<dyn EventPublisher<Error = E> + Send + Sync>>,\n}\n\nimpl<E: std::error::Error + Send + Sync + 'static> MultiPublisher<E> {\n    pub fn new(publishers: Vec<Box<dyn EventPublisher<Error = E> + Send + Sync>>) -> Self {\n        Self { publishers }\n    }\n}\n\n#[async_trait]\nimpl<E: std::error::Error + Send + Sync + 'static> EventPublisher for MultiPublisher<E> {\n    type Error = E;\n\n    async fn publish(&self, event: GovernanceEvent) -> Result<(), Self::Error> {\n        for publisher in &self.publishers {\n            publisher.publish(event.clone()).await?;\n        }\n        Ok(())\n    }\n\n    async fn subscribe(\n        &self,\n        _channels: &[&str],\n    ) -> Result<tokio::sync::mpsc::Receiver<GovernanceEvent>, Self::Error> {\n        panic!(\"Subscribe not implemented for multi-publisher\")\n    }\n}\n","traces":[{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":28,"address":[],"length":0,"stats":{"Line":0}},{"line":37,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":37},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","src","governance.rs"],"content":"use chrono::{DateTime, Utc};\nuse serde::{Deserialize, Serialize};\nuse sqlx::{FromRow, PgPool};\nuse uuid::Uuid;\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GovernanceConfig {\n    pub id: Option<Uuid>,\n    pub company_id: Option<Uuid>,\n    pub org_id: Option<Uuid>,\n    pub team_id: Option<Uuid>,\n    pub project_id: Option<Uuid>,\n    pub approval_mode: ApprovalMode,\n    pub min_approvers: i32,\n    pub timeout_hours: i32,\n    pub auto_approve_low_risk: bool,\n    pub escalation_enabled: bool,\n    pub escalation_timeout_hours: i32,\n    pub escalation_contact: Option<String>,\n    pub policy_settings: serde_json::Value,\n    pub knowledge_settings: serde_json::Value,\n    pub memory_settings: serde_json::Value,\n}\n\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum ApprovalMode {\n    Single,\n    Quorum,\n    Unanimous,\n}\n\nimpl Default for ApprovalMode {\n    fn default() -> Self {\n        Self::Quorum\n    }\n}\n\nimpl std::fmt::Display for ApprovalMode {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            ApprovalMode::Single => write!(f, \"single\"),\n            ApprovalMode::Quorum => write!(f, \"quorum\"),\n            ApprovalMode::Unanimous => write!(f, \"unanimous\"),\n        }\n    }\n}\n\nimpl std::str::FromStr for ApprovalMode {\n    type Err = String;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        match s.to_lowercase().as_str() {\n            \"single\" => Ok(ApprovalMode::Single),\n            \"quorum\" => Ok(ApprovalMode::Quorum),\n            \"unanimous\" => Ok(ApprovalMode::Unanimous),\n            _ => Err(format!(\"Invalid approval mode: {}\", s)),\n        }\n    }\n}\n\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum GovernanceTemplate {\n    Standard,\n    Strict,\n    Permissive,\n}\n\nimpl Default for GovernanceTemplate {\n    fn default() -> Self {\n        Self::Standard\n    }\n}\n\nimpl std::fmt::Display for GovernanceTemplate {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            GovernanceTemplate::Standard => write!(f, \"standard\"),\n            GovernanceTemplate::Strict => write!(f, \"strict\"),\n            GovernanceTemplate::Permissive => write!(f, \"permissive\"),\n        }\n    }\n}\n\nimpl std::str::FromStr for GovernanceTemplate {\n    type Err = String;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        match s.to_lowercase().as_str() {\n            \"standard\" => Ok(GovernanceTemplate::Standard),\n            \"strict\" => Ok(GovernanceTemplate::Strict),\n            \"permissive\" => Ok(GovernanceTemplate::Permissive),\n            _ => Err(format!(\n                \"Invalid governance template: {}. Use: standard, strict, permissive\",\n                s\n            )),\n        }\n    }\n}\n\nimpl GovernanceTemplate {\n    pub fn description(&self) -> &'static str {\n        match self {\n            GovernanceTemplate::Standard => {\n                \"Balanced governance with quorum-based approvals (2 approvers, 72h timeout)\"\n            }\n            GovernanceTemplate::Strict => {\n                \"Maximum control with unanimous approvals (3+ approvers, 24h timeout, no auto-approve)\"\n            }\n            GovernanceTemplate::Permissive => {\n                \"Minimal friction with single approvals (1 approver, auto-approve low-risk)\"\n            }\n        }\n    }\n\n    pub fn to_config(&self) -> GovernanceConfig {\n        match self {\n            GovernanceTemplate::Standard => GovernanceConfig::default(),\n            GovernanceTemplate::Strict => GovernanceConfig {\n                id: None,\n                company_id: None,\n                org_id: None,\n                team_id: None,\n                project_id: None,\n                approval_mode: ApprovalMode::Unanimous,\n                min_approvers: 3,\n                timeout_hours: 24,\n                auto_approve_low_risk: false,\n                escalation_enabled: true,\n                escalation_timeout_hours: 12,\n                escalation_contact: None,\n                policy_settings: serde_json::json!({\n                    \"require_approval\": true,\n                    \"min_approvers\": 3,\n                    \"require_security_review\": true,\n                    \"block_on_conflict\": true\n                }),\n                knowledge_settings: serde_json::json!({\n                    \"require_approval\": true,\n                    \"min_approvers\": 2,\n                    \"require_tech_lead_approval\": true\n                }),\n                memory_settings: serde_json::json!({\n                    \"require_approval\": true,\n                    \"min_approvers\": 1,\n                    \"auto_approve_threshold\": 0.0\n                }),\n            },\n            GovernanceTemplate::Permissive => GovernanceConfig {\n                id: None,\n                company_id: None,\n                org_id: None,\n                team_id: None,\n                project_id: None,\n                approval_mode: ApprovalMode::Single,\n                min_approvers: 1,\n                timeout_hours: 168,\n                auto_approve_low_risk: true,\n                escalation_enabled: false,\n                escalation_timeout_hours: 72,\n                escalation_contact: None,\n                policy_settings: serde_json::json!({\n                    \"require_approval\": true,\n                    \"min_approvers\": 1,\n                    \"auto_approve_low_risk\": true\n                }),\n                knowledge_settings: serde_json::json!({\n                    \"require_approval\": false,\n                    \"min_approvers\": 0\n                }),\n                memory_settings: serde_json::json!({\n                    \"require_approval\": false,\n                    \"auto_approve_threshold\": 0.5\n                }),\n            },\n        }\n    }\n\n    pub fn all() -> &'static [GovernanceTemplate] {\n        &[\n            GovernanceTemplate::Standard,\n            GovernanceTemplate::Strict,\n            GovernanceTemplate::Permissive,\n        ]\n    }\n}\n\nimpl Default for GovernanceConfig {\n    fn default() -> Self {\n        Self {\n            id: None,\n            company_id: None,\n            org_id: None,\n            team_id: None,\n            project_id: None,\n            approval_mode: ApprovalMode::Quorum,\n            min_approvers: 2,\n            timeout_hours: 72,\n            auto_approve_low_risk: false,\n            escalation_enabled: true,\n            escalation_timeout_hours: 48,\n            escalation_contact: None,\n            policy_settings: serde_json::json!({\"require_approval\": true, \"min_approvers\": 2}),\n            knowledge_settings: serde_json::json!({\"require_approval\": true, \"min_approvers\": 1}),\n            memory_settings: serde_json::json!({\"require_approval\": false, \"auto_approve_threshold\": 0.8}),\n        }\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ApprovalRequest {\n    pub id: Uuid,\n    pub request_number: String,\n    pub request_type: RequestType,\n    pub target_type: String,\n    pub target_id: Option<String>,\n    pub company_id: Option<Uuid>,\n    pub org_id: Option<Uuid>,\n    pub team_id: Option<Uuid>,\n    pub project_id: Option<Uuid>,\n    pub title: String,\n    pub description: Option<String>,\n    pub payload: serde_json::Value,\n    pub risk_level: RiskLevel,\n    pub requestor_type: PrincipalType,\n    pub requestor_id: Uuid,\n    pub requestor_email: Option<String>,\n    pub required_approvals: i32,\n    pub current_approvals: i32,\n    pub status: RequestStatus,\n    pub created_at: DateTime<Utc>,\n    pub updated_at: DateTime<Utc>,\n    pub expires_at: Option<DateTime<Utc>>,\n    pub resolved_at: Option<DateTime<Utc>>,\n    pub resolution_reason: Option<String>,\n    pub applied_at: Option<DateTime<Utc>>,\n    pub applied_by: Option<Uuid>,\n}\n\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum RequestType {\n    Policy,\n    Knowledge,\n    Memory,\n    Role,\n    Config,\n}\n\nimpl std::fmt::Display for RequestType {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            RequestType::Policy => write!(f, \"policy\"),\n            RequestType::Knowledge => write!(f, \"knowledge\"),\n            RequestType::Memory => write!(f, \"memory\"),\n            RequestType::Role => write!(f, \"role\"),\n            RequestType::Config => write!(f, \"config\"),\n        }\n    }\n}\n\nimpl std::str::FromStr for RequestType {\n    type Err = String;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        match s.to_lowercase().as_str() {\n            \"policy\" => Ok(RequestType::Policy),\n            \"knowledge\" => Ok(RequestType::Knowledge),\n            \"memory\" => Ok(RequestType::Memory),\n            \"role\" => Ok(RequestType::Role),\n            \"config\" => Ok(RequestType::Config),\n            _ => Err(format!(\"Invalid request type: {}\", s)),\n        }\n    }\n}\n\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum RiskLevel {\n    Low,\n    Medium,\n    High,\n    Critical,\n}\n\nimpl Default for RiskLevel {\n    fn default() -> Self {\n        Self::Medium\n    }\n}\n\nimpl std::fmt::Display for RiskLevel {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            RiskLevel::Low => write!(f, \"low\"),\n            RiskLevel::Medium => write!(f, \"medium\"),\n            RiskLevel::High => write!(f, \"high\"),\n            RiskLevel::Critical => write!(f, \"critical\"),\n        }\n    }\n}\n\nimpl std::str::FromStr for RiskLevel {\n    type Err = String;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        match s.to_lowercase().as_str() {\n            \"low\" => Ok(RiskLevel::Low),\n            \"medium\" => Ok(RiskLevel::Medium),\n            \"high\" => Ok(RiskLevel::High),\n            \"critical\" => Ok(RiskLevel::Critical),\n            _ => Err(format!(\"Invalid risk level: {}\", s)),\n        }\n    }\n}\n\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum PrincipalType {\n    User,\n    Agent,\n    System,\n}\n\nimpl std::fmt::Display for PrincipalType {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            PrincipalType::User => write!(f, \"user\"),\n            PrincipalType::Agent => write!(f, \"agent\"),\n            PrincipalType::System => write!(f, \"system\"),\n        }\n    }\n}\n\nimpl std::str::FromStr for PrincipalType {\n    type Err = String;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        match s.to_lowercase().as_str() {\n            \"user\" => Ok(PrincipalType::User),\n            \"agent\" => Ok(PrincipalType::Agent),\n            \"system\" => Ok(PrincipalType::System),\n            _ => Err(format!(\"Invalid principal type: {}\", s)),\n        }\n    }\n}\n\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum RequestStatus {\n    Pending,\n    Approved,\n    Rejected,\n    Expired,\n    Cancelled,\n}\n\nimpl std::fmt::Display for RequestStatus {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            RequestStatus::Pending => write!(f, \"pending\"),\n            RequestStatus::Approved => write!(f, \"approved\"),\n            RequestStatus::Rejected => write!(f, \"rejected\"),\n            RequestStatus::Expired => write!(f, \"expired\"),\n            RequestStatus::Cancelled => write!(f, \"cancelled\"),\n        }\n    }\n}\n\nimpl std::str::FromStr for RequestStatus {\n    type Err = String;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        match s.to_lowercase().as_str() {\n            \"pending\" => Ok(RequestStatus::Pending),\n            \"approved\" => Ok(RequestStatus::Approved),\n            \"rejected\" => Ok(RequestStatus::Rejected),\n            \"expired\" => Ok(RequestStatus::Expired),\n            \"cancelled\" => Ok(RequestStatus::Cancelled),\n            _ => Err(format!(\"Invalid request status: {}\", s)),\n        }\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ApprovalDecision {\n    pub id: Uuid,\n    pub request_id: Uuid,\n    pub approver_type: PrincipalType,\n    pub approver_id: Uuid,\n    pub approver_email: Option<String>,\n    pub decision: Decision,\n    pub comment: Option<String>,\n    pub created_at: DateTime<Utc>,\n}\n\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum Decision {\n    Approve,\n    Reject,\n    Abstain,\n}\n\nimpl std::fmt::Display for Decision {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            Decision::Approve => write!(f, \"approve\"),\n            Decision::Reject => write!(f, \"reject\"),\n            Decision::Abstain => write!(f, \"abstain\"),\n        }\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GovernanceRole {\n    pub id: Uuid,\n    pub principal_type: PrincipalType,\n    pub principal_id: Uuid,\n    pub role: String,\n    pub company_id: Option<Uuid>,\n    pub org_id: Option<Uuid>,\n    pub team_id: Option<Uuid>,\n    pub project_id: Option<Uuid>,\n    pub granted_by: Uuid,\n    pub granted_at: DateTime<Utc>,\n    pub expires_at: Option<DateTime<Utc>>,\n    pub revoked_at: Option<DateTime<Utc>>,\n    pub revoked_by: Option<Uuid>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GovernanceAuditEntry {\n    pub id: Uuid,\n    pub action: String,\n    pub request_id: Option<Uuid>,\n    pub target_type: Option<String>,\n    pub target_id: Option<String>,\n    pub actor_type: PrincipalType,\n    pub actor_id: Option<Uuid>,\n    pub actor_email: Option<String>,\n    pub details: serde_json::Value,\n    pub old_values: Option<serde_json::Value>,\n    pub new_values: Option<serde_json::Value>,\n    pub created_at: DateTime<Utc>,\n}\n\n#[derive(Debug, Clone, FromRow)]\nstruct ConfigRow {\n    id: Option<Uuid>,\n    scope_level: String,\n    approval_mode: String,\n    min_approvers: i32,\n    timeout_hours: i32,\n    auto_approve_low_risk: bool,\n    escalation_enabled: bool,\n    escalation_timeout_hours: i32,\n    escalation_contact: Option<String>,\n    policy_settings: serde_json::Value,\n    knowledge_settings: serde_json::Value,\n    memory_settings: serde_json::Value,\n}\n\n#[derive(Debug, Clone, FromRow)]\nstruct RequestRow {\n    id: Uuid,\n    request_number: String,\n    request_type: String,\n    target_type: String,\n    target_id: Option<String>,\n    company_id: Option<Uuid>,\n    org_id: Option<Uuid>,\n    team_id: Option<Uuid>,\n    project_id: Option<Uuid>,\n    title: String,\n    description: Option<String>,\n    payload: serde_json::Value,\n    risk_level: String,\n    requestor_type: String,\n    requestor_id: Uuid,\n    requestor_email: Option<String>,\n    required_approvals: i32,\n    current_approvals: i32,\n    status: String,\n    created_at: DateTime<Utc>,\n    updated_at: DateTime<Utc>,\n    expires_at: Option<DateTime<Utc>>,\n    resolved_at: Option<DateTime<Utc>>,\n    resolution_reason: Option<String>,\n    applied_at: Option<DateTime<Utc>>,\n    applied_by: Option<Uuid>,\n}\n\nimpl From<RequestRow> for ApprovalRequest {\n    fn from(row: RequestRow) -> Self {\n        Self {\n            id: row.id,\n            request_number: row.request_number,\n            request_type: row.request_type.parse().unwrap_or(RequestType::Policy),\n            target_type: row.target_type,\n            target_id: row.target_id,\n            company_id: row.company_id,\n            org_id: row.org_id,\n            team_id: row.team_id,\n            project_id: row.project_id,\n            title: row.title,\n            description: row.description,\n            payload: row.payload,\n            risk_level: row.risk_level.parse().unwrap_or_default(),\n            requestor_type: row.requestor_type.parse().unwrap_or(PrincipalType::User),\n            requestor_id: row.requestor_id,\n            requestor_email: row.requestor_email,\n            required_approvals: row.required_approvals,\n            current_approvals: row.current_approvals,\n            status: row.status.parse().unwrap_or(RequestStatus::Pending),\n            created_at: row.created_at,\n            updated_at: row.updated_at,\n            expires_at: row.expires_at,\n            resolved_at: row.resolved_at,\n            resolution_reason: row.resolution_reason,\n            applied_at: row.applied_at,\n            applied_by: row.applied_by,\n        }\n    }\n}\n\n#[derive(Debug, Clone, FromRow)]\nstruct DecisionRow {\n    id: Uuid,\n    request_id: Uuid,\n    approver_type: String,\n    approver_id: Uuid,\n    approver_email: Option<String>,\n    decision: String,\n    comment: Option<String>,\n    created_at: DateTime<Utc>,\n}\n\n#[derive(Debug, Clone, FromRow)]\nstruct AuditRow {\n    id: Uuid,\n    action: String,\n    request_id: Option<Uuid>,\n    target_type: Option<String>,\n    target_id: Option<String>,\n    actor_type: String,\n    actor_id: Option<Uuid>,\n    actor_email: Option<String>,\n    details: serde_json::Value,\n    old_values: Option<serde_json::Value>,\n    new_values: Option<serde_json::Value>,\n    created_at: DateTime<Utc>,\n}\n\npub struct GovernanceStorage {\n    pool: PgPool,\n}\n\nimpl GovernanceStorage {\n    pub fn new(pool: PgPool) -> Self {\n        Self { pool }\n    }\n\n    pub async fn get_effective_config(\n        &self,\n        company_id: Option<Uuid>,\n        org_id: Option<Uuid>,\n        team_id: Option<Uuid>,\n        project_id: Option<Uuid>,\n    ) -> Result<GovernanceConfig, sqlx::Error> {\n        let row: ConfigRow =\n            sqlx::query_as(\"SELECT * FROM get_effective_governance_config($1, $2, $3, $4)\")\n                .bind(company_id)\n                .bind(org_id)\n                .bind(team_id)\n                .bind(project_id)\n                .fetch_one(&self.pool)\n                .await?;\n\n        Ok(GovernanceConfig {\n            id: row.id,\n            company_id,\n            org_id,\n            team_id,\n            project_id,\n            approval_mode: row.approval_mode.parse().unwrap_or_default(),\n            min_approvers: row.min_approvers,\n            timeout_hours: row.timeout_hours,\n            auto_approve_low_risk: row.auto_approve_low_risk,\n            escalation_enabled: row.escalation_enabled,\n            escalation_timeout_hours: row.escalation_timeout_hours,\n            escalation_contact: row.escalation_contact,\n            policy_settings: row.policy_settings,\n            knowledge_settings: row.knowledge_settings,\n            memory_settings: row.memory_settings,\n        })\n    }\n\n    pub async fn upsert_config(&self, config: &GovernanceConfig) -> Result<Uuid, sqlx::Error> {\n        let row: (Uuid,) = sqlx::query_as(\n            r#\"\n            INSERT INTO governance_configs (\n                company_id, org_id, team_id, project_id,\n                approval_mode, min_approvers, timeout_hours,\n                auto_approve_low_risk, escalation_enabled,\n                escalation_timeout_hours, escalation_contact,\n                policy_settings, knowledge_settings, memory_settings\n            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14)\n            ON CONFLICT (company_id) WHERE company_id IS NOT NULL\n            DO UPDATE SET\n                approval_mode = EXCLUDED.approval_mode,\n                min_approvers = EXCLUDED.min_approvers,\n                timeout_hours = EXCLUDED.timeout_hours,\n                auto_approve_low_risk = EXCLUDED.auto_approve_low_risk,\n                escalation_enabled = EXCLUDED.escalation_enabled,\n                escalation_timeout_hours = EXCLUDED.escalation_timeout_hours,\n                escalation_contact = EXCLUDED.escalation_contact,\n                policy_settings = EXCLUDED.policy_settings,\n                knowledge_settings = EXCLUDED.knowledge_settings,\n                memory_settings = EXCLUDED.memory_settings,\n                updated_at = NOW()\n            RETURNING id\n            \"#,\n        )\n        .bind(config.company_id)\n        .bind(config.org_id)\n        .bind(config.team_id)\n        .bind(config.project_id)\n        .bind(config.approval_mode.to_string())\n        .bind(config.min_approvers)\n        .bind(config.timeout_hours)\n        .bind(config.auto_approve_low_risk)\n        .bind(config.escalation_enabled)\n        .bind(config.escalation_timeout_hours)\n        .bind(&config.escalation_contact)\n        .bind(&config.policy_settings)\n        .bind(&config.knowledge_settings)\n        .bind(&config.memory_settings)\n        .fetch_one(&self.pool)\n        .await?;\n\n        Ok(row.0)\n    }\n\n    pub async fn create_request(\n        &self,\n        request: &CreateApprovalRequest,\n    ) -> Result<ApprovalRequest, sqlx::Error> {\n        let expires_at = request\n            .timeout_hours\n            .map(|h| Utc::now() + chrono::Duration::hours(h as i64));\n\n        let row: RequestRow = sqlx::query_as(\n            r#\"\n            INSERT INTO approval_requests (\n                request_type, target_type, target_id,\n                company_id, org_id, team_id, project_id,\n                title, description, payload, risk_level,\n                requestor_type, requestor_id, requestor_email,\n                required_approvals, expires_at\n            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16)\n            RETURNING *\n            \"#,\n        )\n        .bind(request.request_type.to_string())\n        .bind(&request.target_type)\n        .bind(&request.target_id)\n        .bind(request.company_id)\n        .bind(request.org_id)\n        .bind(request.team_id)\n        .bind(request.project_id)\n        .bind(&request.title)\n        .bind(&request.description)\n        .bind(&request.payload)\n        .bind(request.risk_level.to_string())\n        .bind(request.requestor_type.to_string())\n        .bind(request.requestor_id)\n        .bind(&request.requestor_email)\n        .bind(request.required_approvals)\n        .bind(expires_at)\n        .fetch_one(&self.pool)\n        .await?;\n\n        Ok(row.into())\n    }\n\n    pub async fn get_request(\n        &self,\n        request_id: Uuid,\n    ) -> Result<Option<ApprovalRequest>, sqlx::Error> {\n        let row: Option<RequestRow> =\n            sqlx::query_as(\"SELECT * FROM approval_requests WHERE id = $1\")\n                .bind(request_id)\n                .fetch_optional(&self.pool)\n                .await?;\n\n        Ok(row.map(Into::into))\n    }\n\n    pub async fn get_request_by_number(\n        &self,\n        request_number: &str,\n    ) -> Result<Option<ApprovalRequest>, sqlx::Error> {\n        let row: Option<RequestRow> =\n            sqlx::query_as(\"SELECT * FROM approval_requests WHERE request_number = $1\")\n                .bind(request_number)\n                .fetch_optional(&self.pool)\n                .await?;\n\n        Ok(row.map(Into::into))\n    }\n\n    pub async fn list_pending_requests(\n        &self,\n        filters: &RequestFilters,\n    ) -> Result<Vec<ApprovalRequest>, sqlx::Error> {\n        let request_type_str = filters.request_type.map(|rt| rt.to_string());\n        let limit = filters.limit.unwrap_or(100) as i64;\n\n        let rows: Vec<RequestRow> = sqlx::query_as(\n            r#\"\n            SELECT * FROM approval_requests\n            WHERE status = 'pending'\n              AND ($1::text IS NULL OR request_type = $1)\n              AND ($2::uuid IS NULL OR company_id = $2)\n              AND ($3::uuid IS NULL OR org_id = $3)\n              AND ($4::uuid IS NULL OR team_id = $4)\n              AND ($5::uuid IS NULL OR project_id = $5)\n              AND ($6::uuid IS NULL OR requestor_id = $6)\n            ORDER BY created_at DESC\n            LIMIT $7\n            \"#,\n        )\n        .bind(&request_type_str)\n        .bind(filters.company_id)\n        .bind(filters.org_id)\n        .bind(filters.team_id)\n        .bind(filters.project_id)\n        .bind(filters.requestor_id)\n        .bind(limit)\n        .fetch_all(&self.pool)\n        .await?;\n\n        Ok(rows.into_iter().map(Into::into).collect())\n    }\n\n    pub async fn add_decision(\n        &self,\n        decision: &CreateDecision,\n    ) -> Result<ApprovalDecision, sqlx::Error> {\n        let row: DecisionRow = sqlx::query_as(\n            r#\"\n            INSERT INTO approval_decisions (\n                request_id, approver_type, approver_id,\n                approver_email, decision, comment\n            ) VALUES ($1, $2, $3, $4, $5, $6)\n            RETURNING *\n            \"#,\n        )\n        .bind(decision.request_id)\n        .bind(decision.approver_type.to_string())\n        .bind(decision.approver_id)\n        .bind(&decision.approver_email)\n        .bind(decision.decision.to_string())\n        .bind(&decision.comment)\n        .fetch_one(&self.pool)\n        .await?;\n\n        Ok(ApprovalDecision {\n            id: row.id,\n            request_id: row.request_id,\n            approver_type: row.approver_type.parse().unwrap_or(PrincipalType::User),\n            approver_id: row.approver_id,\n            approver_email: row.approver_email,\n            decision: match row.decision.as_str() {\n                \"approve\" => Decision::Approve,\n                \"reject\" => Decision::Reject,\n                _ => Decision::Abstain,\n            },\n            comment: row.comment,\n            created_at: row.created_at,\n        })\n    }\n\n    pub async fn reject_request(\n        &self,\n        request_id: Uuid,\n        reason: &str,\n    ) -> Result<ApprovalRequest, sqlx::Error> {\n        let row: RequestRow = sqlx::query_as(\n            r#\"\n            UPDATE approval_requests\n            SET status = 'rejected',\n                resolved_at = NOW(),\n                resolution_reason = $2,\n                updated_at = NOW()\n            WHERE id = $1\n            RETURNING *\n            \"#,\n        )\n        .bind(request_id)\n        .bind(reason)\n        .fetch_one(&self.pool)\n        .await?;\n\n        Ok(row.into())\n    }\n\n    pub async fn cancel_request(&self, request_id: Uuid) -> Result<ApprovalRequest, sqlx::Error> {\n        let row: RequestRow = sqlx::query_as(\n            r#\"\n            UPDATE approval_requests\n            SET status = 'cancelled',\n                resolved_at = NOW(),\n                updated_at = NOW()\n            WHERE id = $1\n            RETURNING *\n            \"#,\n        )\n        .bind(request_id)\n        .fetch_one(&self.pool)\n        .await?;\n\n        Ok(row.into())\n    }\n\n    pub async fn mark_applied(\n        &self,\n        request_id: Uuid,\n        applied_by: Uuid,\n    ) -> Result<ApprovalRequest, sqlx::Error> {\n        let row: RequestRow = sqlx::query_as(\n            r#\"\n            UPDATE approval_requests\n            SET applied_at = NOW(),\n                applied_by = $2,\n                updated_at = NOW()\n            WHERE id = $1\n            RETURNING *\n            \"#,\n        )\n        .bind(request_id)\n        .bind(applied_by)\n        .fetch_one(&self.pool)\n        .await?;\n\n        Ok(row.into())\n    }\n\n    pub async fn get_decisions(\n        &self,\n        request_id: Uuid,\n    ) -> Result<Vec<ApprovalDecision>, sqlx::Error> {\n        let rows: Vec<DecisionRow> = sqlx::query_as(\n            \"SELECT * FROM approval_decisions WHERE request_id = $1 ORDER BY created_at\",\n        )\n        .bind(request_id)\n        .fetch_all(&self.pool)\n        .await?;\n\n        Ok(rows\n            .into_iter()\n            .map(|row| ApprovalDecision {\n                id: row.id,\n                request_id: row.request_id,\n                approver_type: row.approver_type.parse().unwrap_or(PrincipalType::User),\n                approver_id: row.approver_id,\n                approver_email: row.approver_email,\n                decision: match row.decision.as_str() {\n                    \"approve\" => Decision::Approve,\n                    \"reject\" => Decision::Reject,\n                    _ => Decision::Abstain,\n                },\n                comment: row.comment,\n                created_at: row.created_at,\n            })\n            .collect())\n    }\n\n    pub async fn log_audit(\n        &self,\n        action: &str,\n        request_id: Option<Uuid>,\n        target_type: Option<&str>,\n        target_id: Option<&str>,\n        actor_type: PrincipalType,\n        actor_id: Option<Uuid>,\n        actor_email: Option<&str>,\n        details: serde_json::Value,\n    ) -> Result<Uuid, sqlx::Error> {\n        let row: (Uuid,) = sqlx::query_as(\n            r#\"\n            INSERT INTO governance_audit_log (\n                action, request_id, target_type, target_id,\n                actor_type, actor_id, actor_email, details\n            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)\n            RETURNING id\n            \"#,\n        )\n        .bind(action)\n        .bind(request_id)\n        .bind(target_type)\n        .bind(target_id)\n        .bind(actor_type.to_string())\n        .bind(actor_id)\n        .bind(actor_email)\n        .bind(details)\n        .fetch_one(&self.pool)\n        .await?;\n\n        Ok(row.0)\n    }\n\n    pub async fn list_audit_logs(\n        &self,\n        filters: &AuditFilters,\n    ) -> Result<Vec<GovernanceAuditEntry>, sqlx::Error> {\n        let rows: Vec<AuditRow> = sqlx::query_as(\n            r#\"\n            SELECT * FROM governance_audit_log\n            WHERE ($1::text IS NULL OR action = $1)\n              AND ($2::uuid IS NULL OR actor_id = $2)\n              AND ($3::text IS NULL OR target_type = $3)\n              AND created_at >= $4\n            ORDER BY created_at DESC\n            LIMIT $5\n            \"#,\n        )\n        .bind(&filters.action)\n        .bind(filters.actor_id)\n        .bind(&filters.target_type)\n        .bind(filters.since)\n        .bind(filters.limit.unwrap_or(50) as i64)\n        .fetch_all(&self.pool)\n        .await?;\n\n        Ok(rows\n            .into_iter()\n            .map(|row| GovernanceAuditEntry {\n                id: row.id,\n                action: row.action,\n                request_id: row.request_id,\n                target_type: row.target_type,\n                target_id: row.target_id,\n                actor_type: row.actor_type.parse().unwrap_or(PrincipalType::System),\n                actor_id: row.actor_id,\n                actor_email: row.actor_email,\n                details: row.details,\n                old_values: row.old_values,\n                new_values: row.new_values,\n                created_at: row.created_at,\n            })\n            .collect())\n    }\n\n    pub async fn assign_role(&self, role: &CreateGovernanceRole) -> Result<Uuid, sqlx::Error> {\n        let row: (Uuid,) = sqlx::query_as(\n            r#\"\n            INSERT INTO governance_roles (\n                principal_type, principal_id, role,\n                company_id, org_id, team_id, project_id,\n                granted_by, expires_at\n            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)\n            RETURNING id\n            \"#,\n        )\n        .bind(role.principal_type.to_string())\n        .bind(role.principal_id)\n        .bind(&role.role)\n        .bind(role.company_id)\n        .bind(role.org_id)\n        .bind(role.team_id)\n        .bind(role.project_id)\n        .bind(role.granted_by)\n        .bind(role.expires_at)\n        .fetch_one(&self.pool)\n        .await?;\n\n        Ok(row.0)\n    }\n\n    pub async fn revoke_role(\n        &self,\n        principal_id: Uuid,\n        role: &str,\n        revoked_by: Uuid,\n    ) -> Result<(), sqlx::Error> {\n        sqlx::query(\n            r#\"\n            UPDATE governance_roles\n            SET revoked_at = NOW(), revoked_by = $3\n            WHERE principal_id = $1 AND role = $2 AND revoked_at IS NULL\n            \"#,\n        )\n        .bind(principal_id)\n        .bind(role)\n        .bind(revoked_by)\n        .execute(&self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    pub async fn list_roles(\n        &self,\n        company_id: Option<Uuid>,\n        org_id: Option<Uuid>,\n        team_id: Option<Uuid>,\n    ) -> Result<Vec<GovernanceRole>, sqlx::Error> {\n        #[derive(FromRow)]\n        struct RoleRow {\n            id: Uuid,\n            principal_type: String,\n            principal_id: Uuid,\n            role: String,\n            company_id: Option<Uuid>,\n            org_id: Option<Uuid>,\n            team_id: Option<Uuid>,\n            project_id: Option<Uuid>,\n            granted_by: Uuid,\n            granted_at: DateTime<Utc>,\n            expires_at: Option<DateTime<Utc>>,\n            revoked_at: Option<DateTime<Utc>>,\n            revoked_by: Option<Uuid>,\n        }\n\n        let rows: Vec<RoleRow> = sqlx::query_as(\n            r#\"\n            SELECT * FROM governance_roles\n            WHERE revoked_at IS NULL\n              AND ($1::uuid IS NULL OR company_id = $1)\n              AND ($2::uuid IS NULL OR org_id = $2)\n              AND ($3::uuid IS NULL OR team_id = $3)\n            ORDER BY granted_at DESC\n            \"#,\n        )\n        .bind(company_id)\n        .bind(org_id)\n        .bind(team_id)\n        .fetch_all(&self.pool)\n        .await?;\n\n        Ok(rows\n            .into_iter()\n            .map(|row| GovernanceRole {\n                id: row.id,\n                principal_type: row.principal_type.parse().unwrap_or(PrincipalType::User),\n                principal_id: row.principal_id,\n                role: row.role,\n                company_id: row.company_id,\n                org_id: row.org_id,\n                team_id: row.team_id,\n                project_id: row.project_id,\n                granted_by: row.granted_by,\n                granted_at: row.granted_at,\n                expires_at: row.expires_at,\n                revoked_at: row.revoked_at,\n                revoked_by: row.revoked_by,\n            })\n            .collect())\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct CreateApprovalRequest {\n    pub request_type: RequestType,\n    pub target_type: String,\n    pub target_id: Option<String>,\n    pub company_id: Option<Uuid>,\n    pub org_id: Option<Uuid>,\n    pub team_id: Option<Uuid>,\n    pub project_id: Option<Uuid>,\n    pub title: String,\n    pub description: Option<String>,\n    pub payload: serde_json::Value,\n    pub risk_level: RiskLevel,\n    pub requestor_type: PrincipalType,\n    pub requestor_id: Uuid,\n    pub requestor_email: Option<String>,\n    pub required_approvals: i32,\n    pub timeout_hours: Option<i32>,\n}\n\n#[derive(Debug, Clone)]\npub struct CreateDecision {\n    pub request_id: Uuid,\n    pub approver_type: PrincipalType,\n    pub approver_id: Uuid,\n    pub approver_email: Option<String>,\n    pub decision: Decision,\n    pub comment: Option<String>,\n}\n\n#[derive(Debug, Clone)]\npub struct CreateGovernanceRole {\n    pub principal_type: PrincipalType,\n    pub principal_id: Uuid,\n    pub role: String,\n    pub company_id: Option<Uuid>,\n    pub org_id: Option<Uuid>,\n    pub team_id: Option<Uuid>,\n    pub project_id: Option<Uuid>,\n    pub granted_by: Uuid,\n    pub expires_at: Option<DateTime<Utc>>,\n}\n\n#[derive(Debug, Clone, Default)]\npub struct RequestFilters {\n    pub request_type: Option<RequestType>,\n    pub company_id: Option<Uuid>,\n    pub org_id: Option<Uuid>,\n    pub team_id: Option<Uuid>,\n    pub project_id: Option<Uuid>,\n    pub requestor_id: Option<Uuid>,\n    pub limit: Option<i32>,\n}\n\n#[derive(Debug, Clone)]\npub struct AuditFilters {\n    pub action: Option<String>,\n    pub actor_id: Option<Uuid>,\n    pub target_type: Option<String>,\n    pub since: DateTime<Utc>,\n    pub limit: Option<i32>,\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_approval_mode_display() {\n        assert_eq!(ApprovalMode::Single.to_string(), \"single\");\n        assert_eq!(ApprovalMode::Quorum.to_string(), \"quorum\");\n        assert_eq!(ApprovalMode::Unanimous.to_string(), \"unanimous\");\n    }\n\n    #[test]\n    fn test_approval_mode_parse() {\n        assert_eq!(\n            \"single\".parse::<ApprovalMode>().unwrap(),\n            ApprovalMode::Single\n        );\n        assert_eq!(\n            \"QUORUM\".parse::<ApprovalMode>().unwrap(),\n            ApprovalMode::Quorum\n        );\n        assert!(\"invalid\".parse::<ApprovalMode>().is_err());\n    }\n\n    #[test]\n    fn test_request_type_roundtrip() {\n        for rt in [\n            RequestType::Policy,\n            RequestType::Knowledge,\n            RequestType::Memory,\n            RequestType::Role,\n            RequestType::Config,\n        ] {\n            let s = rt.to_string();\n            assert_eq!(s.parse::<RequestType>().unwrap(), rt);\n        }\n    }\n\n    #[test]\n    fn test_risk_level_default() {\n        assert_eq!(RiskLevel::default(), RiskLevel::Medium);\n    }\n\n    #[test]\n    fn test_governance_config_default() {\n        let config = GovernanceConfig::default();\n        assert_eq!(config.approval_mode, ApprovalMode::Quorum);\n        assert_eq!(config.min_approvers, 2);\n        assert_eq!(config.timeout_hours, 72);\n        assert!(!config.auto_approve_low_risk);\n        assert!(config.escalation_enabled);\n    }\n\n    #[test]\n    fn test_principal_type_display() {\n        assert_eq!(PrincipalType::User.to_string(), \"user\");\n        assert_eq!(PrincipalType::Agent.to_string(), \"agent\");\n        assert_eq!(PrincipalType::System.to_string(), \"system\");\n    }\n\n    #[test]\n    fn test_request_status_parse() {\n        assert_eq!(\n            \"pending\".parse::<RequestStatus>().unwrap(),\n            RequestStatus::Pending\n        );\n        assert_eq!(\n            \"approved\".parse::<RequestStatus>().unwrap(),\n            RequestStatus::Approved\n        );\n        assert_eq!(\n            \"rejected\".parse::<RequestStatus>().unwrap(),\n            RequestStatus::Rejected\n        );\n        assert_eq!(\n            \"expired\".parse::<RequestStatus>().unwrap(),\n            RequestStatus::Expired\n        );\n        assert_eq!(\n            \"cancelled\".parse::<RequestStatus>().unwrap(),\n            RequestStatus::Cancelled\n        );\n    }\n\n    #[test]\n    fn test_decision_display() {\n        assert_eq!(Decision::Approve.to_string(), \"approve\");\n        assert_eq!(Decision::Reject.to_string(), \"reject\");\n        assert_eq!(Decision::Abstain.to_string(), \"abstain\");\n    }\n}\n","traces":[{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":7}},{"line":41,"address":[],"length":0,"stats":{"Line":7}},{"line":42,"address":[],"length":0,"stats":{"Line":6}},{"line":43,"address":[],"length":0,"stats":{"Line":9}},{"line":44,"address":[],"length":0,"stats":{"Line":6}},{"line":52,"address":[],"length":0,"stats":{"Line":11}},{"line":53,"address":[],"length":0,"stats":{"Line":11}},{"line":54,"address":[],"length":0,"stats":{"Line":14}},{"line":55,"address":[],"length":0,"stats":{"Line":11}},{"line":56,"address":[],"length":0,"stats":{"Line":7}},{"line":57,"address":[],"length":0,"stats":{"Line":3}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":4}},{"line":90,"address":[],"length":0,"stats":{"Line":4}},{"line":91,"address":[],"length":0,"stats":{"Line":5}},{"line":92,"address":[],"length":0,"stats":{"Line":4}},{"line":93,"address":[],"length":0,"stats":{"Line":3}},{"line":94,"address":[],"length":0,"stats":{"Line":1}},{"line":95,"address":[],"length":0,"stats":{"Line":1}},{"line":96,"address":[],"length":0,"stats":{"Line":1}},{"line":103,"address":[],"length":0,"stats":{"Line":3}},{"line":104,"address":[],"length":0,"stats":{"Line":3}},{"line":106,"address":[],"length":0,"stats":{"Line":1}},{"line":109,"address":[],"length":0,"stats":{"Line":1}},{"line":112,"address":[],"length":0,"stats":{"Line":1}},{"line":117,"address":[],"length":0,"stats":{"Line":3}},{"line":118,"address":[],"length":0,"stats":{"Line":3}},{"line":119,"address":[],"length":0,"stats":{"Line":1}},{"line":133,"address":[],"length":0,"stats":{"Line":2}},{"line":139,"address":[],"length":0,"stats":{"Line":2}},{"line":144,"address":[],"length":0,"stats":{"Line":2}},{"line":163,"address":[],"length":0,"stats":{"Line":2}},{"line":168,"address":[],"length":0,"stats":{"Line":2}},{"line":172,"address":[],"length":0,"stats":{"Line":2}},{"line":180,"address":[],"length":0,"stats":{"Line":1}},{"line":181,"address":[],"length":0,"stats":{"Line":1}},{"line":182,"address":[],"length":0,"stats":{"Line":1}},{"line":183,"address":[],"length":0,"stats":{"Line":1}},{"line":184,"address":[],"length":0,"stats":{"Line":1}},{"line":190,"address":[],"length":0,"stats":{"Line":6}},{"line":204,"address":[],"length":0,"stats":{"Line":24}},{"line":205,"address":[],"length":0,"stats":{"Line":24}},{"line":206,"address":[],"length":0,"stats":{"Line":12}},{"line":252,"address":[],"length":0,"stats":{"Line":35}},{"line":253,"address":[],"length":0,"stats":{"Line":35}},{"line":254,"address":[],"length":0,"stats":{"Line":51}},{"line":255,"address":[],"length":0,"stats":{"Line":21}},{"line":256,"address":[],"length":0,"stats":{"Line":9}},{"line":257,"address":[],"length":0,"stats":{"Line":9}},{"line":258,"address":[],"length":0,"stats":{"Line":15}},{"line":266,"address":[],"length":0,"stats":{"Line":65}},{"line":267,"address":[],"length":0,"stats":{"Line":65}},{"line":268,"address":[],"length":0,"stats":{"Line":97}},{"line":269,"address":[],"length":0,"stats":{"Line":45}},{"line":270,"address":[],"length":0,"stats":{"Line":25}},{"line":271,"address":[],"length":0,"stats":{"Line":23}},{"line":272,"address":[],"length":0,"stats":{"Line":20}},{"line":273,"address":[],"length":0,"stats":{"Line":2}},{"line":288,"address":[],"length":0,"stats":{"Line":1}},{"line":289,"address":[],"length":0,"stats":{"Line":1}},{"line":294,"address":[],"length":0,"stats":{"Line":33}},{"line":295,"address":[],"length":0,"stats":{"Line":33}},{"line":296,"address":[],"length":0,"stats":{"Line":51}},{"line":297,"address":[],"length":0,"stats":{"Line":21}},{"line":298,"address":[],"length":0,"stats":{"Line":15}},{"line":299,"address":[],"length":0,"stats":{"Line":12}},{"line":307,"address":[],"length":0,"stats":{"Line":58}},{"line":308,"address":[],"length":0,"stats":{"Line":58}},{"line":309,"address":[],"length":0,"stats":{"Line":92}},{"line":310,"address":[],"length":0,"stats":{"Line":36}},{"line":311,"address":[],"length":0,"stats":{"Line":18}},{"line":312,"address":[],"length":0,"stats":{"Line":10}},{"line":313,"address":[],"length":0,"stats":{"Line":2}},{"line":327,"address":[],"length":0,"stats":{"Line":47}},{"line":328,"address":[],"length":0,"stats":{"Line":47}},{"line":329,"address":[],"length":0,"stats":{"Line":120}},{"line":330,"address":[],"length":0,"stats":{"Line":9}},{"line":331,"address":[],"length":0,"stats":{"Line":12}},{"line":339,"address":[],"length":0,"stats":{"Line":75}},{"line":340,"address":[],"length":0,"stats":{"Line":75}},{"line":341,"address":[],"length":0,"stats":{"Line":142}},{"line":342,"address":[],"length":0,"stats":{"Line":10}},{"line":343,"address":[],"length":0,"stats":{"Line":10}},{"line":344,"address":[],"length":0,"stats":{"Line":2}},{"line":360,"address":[],"length":0,"stats":{"Line":6}},{"line":361,"address":[],"length":0,"stats":{"Line":6}},{"line":362,"address":[],"length":0,"stats":{"Line":6}},{"line":363,"address":[],"length":0,"stats":{"Line":3}},{"line":364,"address":[],"length":0,"stats":{"Line":3}},{"line":365,"address":[],"length":0,"stats":{"Line":3}},{"line":366,"address":[],"length":0,"stats":{"Line":3}},{"line":374,"address":[],"length":0,"stats":{"Line":59}},{"line":375,"address":[],"length":0,"stats":{"Line":59}},{"line":376,"address":[],"length":0,"stats":{"Line":107}},{"line":377,"address":[],"length":0,"stats":{"Line":13}},{"line":378,"address":[],"length":0,"stats":{"Line":12}},{"line":379,"address":[],"length":0,"stats":{"Line":8}},{"line":380,"address":[],"length":0,"stats":{"Line":7}},{"line":381,"address":[],"length":0,"stats":{"Line":1}},{"line":407,"address":[],"length":0,"stats":{"Line":10}},{"line":408,"address":[],"length":0,"stats":{"Line":10}},{"line":409,"address":[],"length":0,"stats":{"Line":12}},{"line":410,"address":[],"length":0,"stats":{"Line":9}},{"line":411,"address":[],"length":0,"stats":{"Line":9}},{"line":496,"address":[],"length":0,"stats":{"Line":48}},{"line":498,"address":[],"length":0,"stats":{"Line":96}},{"line":499,"address":[],"length":0,"stats":{"Line":96}},{"line":500,"address":[],"length":0,"stats":{"Line":192}},{"line":501,"address":[],"length":0,"stats":{"Line":96}},{"line":502,"address":[],"length":0,"stats":{"Line":96}},{"line":503,"address":[],"length":0,"stats":{"Line":96}},{"line":504,"address":[],"length":0,"stats":{"Line":96}},{"line":505,"address":[],"length":0,"stats":{"Line":96}},{"line":506,"address":[],"length":0,"stats":{"Line":96}},{"line":507,"address":[],"length":0,"stats":{"Line":96}},{"line":508,"address":[],"length":0,"stats":{"Line":96}},{"line":509,"address":[],"length":0,"stats":{"Line":96}},{"line":510,"address":[],"length":0,"stats":{"Line":144}},{"line":511,"address":[],"length":0,"stats":{"Line":192}},{"line":512,"address":[],"length":0,"stats":{"Line":96}},{"line":513,"address":[],"length":0,"stats":{"Line":96}},{"line":514,"address":[],"length":0,"stats":{"Line":96}},{"line":515,"address":[],"length":0,"stats":{"Line":96}},{"line":516,"address":[],"length":0,"stats":{"Line":192}},{"line":517,"address":[],"length":0,"stats":{"Line":96}},{"line":518,"address":[],"length":0,"stats":{"Line":96}},{"line":519,"address":[],"length":0,"stats":{"Line":96}},{"line":520,"address":[],"length":0,"stats":{"Line":96}},{"line":521,"address":[],"length":0,"stats":{"Line":96}},{"line":522,"address":[],"length":0,"stats":{"Line":48}},{"line":523,"address":[],"length":0,"stats":{"Line":48}},{"line":561,"address":[],"length":0,"stats":{"Line":25}},{"line":565,"address":[],"length":0,"stats":{"Line":0}},{"line":572,"address":[],"length":0,"stats":{"Line":0}},{"line":573,"address":[],"length":0,"stats":{"Line":0}},{"line":574,"address":[],"length":0,"stats":{"Line":0}},{"line":575,"address":[],"length":0,"stats":{"Line":0}},{"line":576,"address":[],"length":0,"stats":{"Line":0}},{"line":577,"address":[],"length":0,"stats":{"Line":0}},{"line":578,"address":[],"length":0,"stats":{"Line":0}},{"line":579,"address":[],"length":0,"stats":{"Line":0}},{"line":581,"address":[],"length":0,"stats":{"Line":0}},{"line":582,"address":[],"length":0,"stats":{"Line":0}},{"line":583,"address":[],"length":0,"stats":{"Line":0}},{"line":584,"address":[],"length":0,"stats":{"Line":0}},{"line":585,"address":[],"length":0,"stats":{"Line":0}},{"line":586,"address":[],"length":0,"stats":{"Line":0}},{"line":587,"address":[],"length":0,"stats":{"Line":0}},{"line":588,"address":[],"length":0,"stats":{"Line":0}},{"line":589,"address":[],"length":0,"stats":{"Line":0}},{"line":590,"address":[],"length":0,"stats":{"Line":0}},{"line":591,"address":[],"length":0,"stats":{"Line":0}},{"line":592,"address":[],"length":0,"stats":{"Line":0}},{"line":593,"address":[],"length":0,"stats":{"Line":0}},{"line":594,"address":[],"length":0,"stats":{"Line":0}},{"line":595,"address":[],"length":0,"stats":{"Line":0}},{"line":596,"address":[],"length":0,"stats":{"Line":0}},{"line":600,"address":[],"length":0,"stats":{"Line":2}},{"line":626,"address":[],"length":0,"stats":{"Line":3}},{"line":627,"address":[],"length":0,"stats":{"Line":3}},{"line":628,"address":[],"length":0,"stats":{"Line":3}},{"line":629,"address":[],"length":0,"stats":{"Line":3}},{"line":630,"address":[],"length":0,"stats":{"Line":4}},{"line":631,"address":[],"length":0,"stats":{"Line":3}},{"line":632,"address":[],"length":0,"stats":{"Line":3}},{"line":633,"address":[],"length":0,"stats":{"Line":3}},{"line":634,"address":[],"length":0,"stats":{"Line":3}},{"line":635,"address":[],"length":0,"stats":{"Line":3}},{"line":636,"address":[],"length":0,"stats":{"Line":3}},{"line":637,"address":[],"length":0,"stats":{"Line":3}},{"line":638,"address":[],"length":0,"stats":{"Line":3}},{"line":639,"address":[],"length":0,"stats":{"Line":3}},{"line":640,"address":[],"length":0,"stats":{"Line":2}},{"line":641,"address":[],"length":0,"stats":{"Line":1}},{"line":643,"address":[],"length":0,"stats":{"Line":1}},{"line":646,"address":[],"length":0,"stats":{"Line":24}},{"line":650,"address":[],"length":0,"stats":{"Line":48}},{"line":651,"address":[],"length":0,"stats":{"Line":24}},{"line":652,"address":[],"length":0,"stats":{"Line":96}},{"line":666,"address":[],"length":0,"stats":{"Line":96}},{"line":667,"address":[],"length":0,"stats":{"Line":72}},{"line":668,"address":[],"length":0,"stats":{"Line":72}},{"line":669,"address":[],"length":0,"stats":{"Line":72}},{"line":670,"address":[],"length":0,"stats":{"Line":72}},{"line":671,"address":[],"length":0,"stats":{"Line":72}},{"line":672,"address":[],"length":0,"stats":{"Line":72}},{"line":673,"address":[],"length":0,"stats":{"Line":72}},{"line":674,"address":[],"length":0,"stats":{"Line":72}},{"line":675,"address":[],"length":0,"stats":{"Line":72}},{"line":676,"address":[],"length":0,"stats":{"Line":96}},{"line":677,"address":[],"length":0,"stats":{"Line":96}},{"line":678,"address":[],"length":0,"stats":{"Line":72}},{"line":679,"address":[],"length":0,"stats":{"Line":72}},{"line":680,"address":[],"length":0,"stats":{"Line":72}},{"line":681,"address":[],"length":0,"stats":{"Line":72}},{"line":682,"address":[],"length":0,"stats":{"Line":48}},{"line":683,"address":[],"length":0,"stats":{"Line":24}},{"line":685,"address":[],"length":0,"stats":{"Line":24}},{"line":688,"address":[],"length":0,"stats":{"Line":2}},{"line":692,"address":[],"length":0,"stats":{"Line":4}},{"line":693,"address":[],"length":0,"stats":{"Line":4}},{"line":694,"address":[],"length":0,"stats":{"Line":6}},{"line":695,"address":[],"length":0,"stats":{"Line":4}},{"line":696,"address":[],"length":0,"stats":{"Line":2}},{"line":698,"address":[],"length":0,"stats":{"Line":2}},{"line":701,"address":[],"length":0,"stats":{"Line":1}},{"line":705,"address":[],"length":0,"stats":{"Line":2}},{"line":706,"address":[],"length":0,"stats":{"Line":2}},{"line":707,"address":[],"length":0,"stats":{"Line":3}},{"line":708,"address":[],"length":0,"stats":{"Line":2}},{"line":709,"address":[],"length":0,"stats":{"Line":1}},{"line":711,"address":[],"length":0,"stats":{"Line":1}},{"line":714,"address":[],"length":0,"stats":{"Line":11}},{"line":718,"address":[],"length":0,"stats":{"Line":35}},{"line":719,"address":[],"length":0,"stats":{"Line":22}},{"line":735,"address":[],"length":0,"stats":{"Line":33}},{"line":736,"address":[],"length":0,"stats":{"Line":33}},{"line":737,"address":[],"length":0,"stats":{"Line":33}},{"line":738,"address":[],"length":0,"stats":{"Line":33}},{"line":739,"address":[],"length":0,"stats":{"Line":33}},{"line":740,"address":[],"length":0,"stats":{"Line":33}},{"line":741,"address":[],"length":0,"stats":{"Line":33}},{"line":742,"address":[],"length":0,"stats":{"Line":22}},{"line":743,"address":[],"length":0,"stats":{"Line":11}},{"line":745,"address":[],"length":0,"stats":{"Line":33}},{"line":748,"address":[],"length":0,"stats":{"Line":4}},{"line":761,"address":[],"length":0,"stats":{"Line":12}},{"line":762,"address":[],"length":0,"stats":{"Line":16}},{"line":763,"address":[],"length":0,"stats":{"Line":12}},{"line":764,"address":[],"length":0,"stats":{"Line":12}},{"line":765,"address":[],"length":0,"stats":{"Line":16}},{"line":766,"address":[],"length":0,"stats":{"Line":12}},{"line":767,"address":[],"length":0,"stats":{"Line":8}},{"line":768,"address":[],"length":0,"stats":{"Line":4}},{"line":771,"address":[],"length":0,"stats":{"Line":4}},{"line":772,"address":[],"length":0,"stats":{"Line":4}},{"line":773,"address":[],"length":0,"stats":{"Line":12}},{"line":774,"address":[],"length":0,"stats":{"Line":4}},{"line":775,"address":[],"length":0,"stats":{"Line":4}},{"line":776,"address":[],"length":0,"stats":{"Line":4}},{"line":777,"address":[],"length":0,"stats":{"Line":6}},{"line":778,"address":[],"length":0,"stats":{"Line":3}},{"line":779,"address":[],"length":0,"stats":{"Line":1}},{"line":781,"address":[],"length":0,"stats":{"Line":4}},{"line":782,"address":[],"length":0,"stats":{"Line":4}},{"line":786,"address":[],"length":0,"stats":{"Line":1}},{"line":802,"address":[],"length":0,"stats":{"Line":3}},{"line":803,"address":[],"length":0,"stats":{"Line":3}},{"line":804,"address":[],"length":0,"stats":{"Line":2}},{"line":805,"address":[],"length":0,"stats":{"Line":1}},{"line":807,"address":[],"length":0,"stats":{"Line":1}},{"line":810,"address":[],"length":0,"stats":{"Line":2}},{"line":821,"address":[],"length":0,"stats":{"Line":3}},{"line":822,"address":[],"length":0,"stats":{"Line":2}},{"line":823,"address":[],"length":0,"stats":{"Line":1}},{"line":825,"address":[],"length":0,"stats":{"Line":1}},{"line":828,"address":[],"length":0,"stats":{"Line":1}},{"line":843,"address":[],"length":0,"stats":{"Line":3}},{"line":844,"address":[],"length":0,"stats":{"Line":3}},{"line":845,"address":[],"length":0,"stats":{"Line":2}},{"line":846,"address":[],"length":0,"stats":{"Line":1}},{"line":848,"address":[],"length":0,"stats":{"Line":1}},{"line":851,"address":[],"length":0,"stats":{"Line":1}},{"line":858,"address":[],"length":0,"stats":{"Line":3}},{"line":859,"address":[],"length":0,"stats":{"Line":2}},{"line":860,"address":[],"length":0,"stats":{"Line":1}},{"line":862,"address":[],"length":0,"stats":{"Line":1}},{"line":863,"address":[],"length":0,"stats":{"Line":1}},{"line":864,"address":[],"length":0,"stats":{"Line":1}},{"line":865,"address":[],"length":0,"stats":{"Line":1}},{"line":866,"address":[],"length":0,"stats":{"Line":1}},{"line":867,"address":[],"length":0,"stats":{"Line":3}},{"line":868,"address":[],"length":0,"stats":{"Line":1}},{"line":869,"address":[],"length":0,"stats":{"Line":1}},{"line":870,"address":[],"length":0,"stats":{"Line":1}},{"line":871,"address":[],"length":0,"stats":{"Line":2}},{"line":872,"address":[],"length":0,"stats":{"Line":0}},{"line":873,"address":[],"length":0,"stats":{"Line":0}},{"line":875,"address":[],"length":0,"stats":{"Line":1}},{"line":876,"address":[],"length":0,"stats":{"Line":1}},{"line":878,"address":[],"length":0,"stats":{"Line":1}},{"line":881,"address":[],"length":0,"stats":{"Line":5}},{"line":901,"address":[],"length":0,"stats":{"Line":15}},{"line":902,"address":[],"length":0,"stats":{"Line":15}},{"line":903,"address":[],"length":0,"stats":{"Line":15}},{"line":904,"address":[],"length":0,"stats":{"Line":15}},{"line":905,"address":[],"length":0,"stats":{"Line":20}},{"line":906,"address":[],"length":0,"stats":{"Line":15}},{"line":907,"address":[],"length":0,"stats":{"Line":15}},{"line":908,"address":[],"length":0,"stats":{"Line":15}},{"line":909,"address":[],"length":0,"stats":{"Line":10}},{"line":910,"address":[],"length":0,"stats":{"Line":5}},{"line":912,"address":[],"length":0,"stats":{"Line":5}},{"line":915,"address":[],"length":0,"stats":{"Line":3}},{"line":930,"address":[],"length":0,"stats":{"Line":9}},{"line":931,"address":[],"length":0,"stats":{"Line":9}},{"line":932,"address":[],"length":0,"stats":{"Line":9}},{"line":933,"address":[],"length":0,"stats":{"Line":9}},{"line":934,"address":[],"length":0,"stats":{"Line":9}},{"line":935,"address":[],"length":0,"stats":{"Line":6}},{"line":936,"address":[],"length":0,"stats":{"Line":3}},{"line":938,"address":[],"length":0,"stats":{"Line":3}},{"line":939,"address":[],"length":0,"stats":{"Line":3}},{"line":940,"address":[],"length":0,"stats":{"Line":3}},{"line":941,"address":[],"length":0,"stats":{"Line":7}},{"line":942,"address":[],"length":0,"stats":{"Line":7}},{"line":943,"address":[],"length":0,"stats":{"Line":7}},{"line":944,"address":[],"length":0,"stats":{"Line":7}},{"line":945,"address":[],"length":0,"stats":{"Line":7}},{"line":946,"address":[],"length":0,"stats":{"Line":21}},{"line":947,"address":[],"length":0,"stats":{"Line":7}},{"line":948,"address":[],"length":0,"stats":{"Line":7}},{"line":949,"address":[],"length":0,"stats":{"Line":7}},{"line":950,"address":[],"length":0,"stats":{"Line":7}},{"line":951,"address":[],"length":0,"stats":{"Line":7}},{"line":952,"address":[],"length":0,"stats":{"Line":7}},{"line":954,"address":[],"length":0,"stats":{"Line":3}},{"line":957,"address":[],"length":0,"stats":{"Line":16}},{"line":968,"address":[],"length":0,"stats":{"Line":32}},{"line":969,"address":[],"length":0,"stats":{"Line":24}},{"line":970,"address":[],"length":0,"stats":{"Line":24}},{"line":971,"address":[],"length":0,"stats":{"Line":24}},{"line":972,"address":[],"length":0,"stats":{"Line":24}},{"line":973,"address":[],"length":0,"stats":{"Line":24}},{"line":974,"address":[],"length":0,"stats":{"Line":24}},{"line":975,"address":[],"length":0,"stats":{"Line":24}},{"line":976,"address":[],"length":0,"stats":{"Line":24}},{"line":977,"address":[],"length":0,"stats":{"Line":16}},{"line":978,"address":[],"length":0,"stats":{"Line":8}},{"line":980,"address":[],"length":0,"stats":{"Line":8}},{"line":983,"address":[],"length":0,"stats":{"Line":1}},{"line":996,"address":[],"length":0,"stats":{"Line":3}},{"line":997,"address":[],"length":0,"stats":{"Line":3}},{"line":998,"address":[],"length":0,"stats":{"Line":3}},{"line":999,"address":[],"length":0,"stats":{"Line":2}},{"line":1000,"address":[],"length":0,"stats":{"Line":1}},{"line":1002,"address":[],"length":0,"stats":{"Line":1}},{"line":1005,"address":[],"length":0,"stats":{"Line":7}},{"line":1038,"address":[],"length":0,"stats":{"Line":21}},{"line":1039,"address":[],"length":0,"stats":{"Line":21}},{"line":1040,"address":[],"length":0,"stats":{"Line":21}},{"line":1041,"address":[],"length":0,"stats":{"Line":14}},{"line":1042,"address":[],"length":0,"stats":{"Line":7}},{"line":1044,"address":[],"length":0,"stats":{"Line":7}},{"line":1045,"address":[],"length":0,"stats":{"Line":7}},{"line":1046,"address":[],"length":0,"stats":{"Line":7}},{"line":1047,"address":[],"length":0,"stats":{"Line":7}},{"line":1048,"address":[],"length":0,"stats":{"Line":21}},{"line":1049,"address":[],"length":0,"stats":{"Line":7}},{"line":1050,"address":[],"length":0,"stats":{"Line":7}},{"line":1051,"address":[],"length":0,"stats":{"Line":7}},{"line":1052,"address":[],"length":0,"stats":{"Line":7}},{"line":1053,"address":[],"length":0,"stats":{"Line":7}},{"line":1054,"address":[],"length":0,"stats":{"Line":7}},{"line":1055,"address":[],"length":0,"stats":{"Line":7}},{"line":1056,"address":[],"length":0,"stats":{"Line":7}},{"line":1057,"address":[],"length":0,"stats":{"Line":7}},{"line":1058,"address":[],"length":0,"stats":{"Line":7}},{"line":1059,"address":[],"length":0,"stats":{"Line":7}},{"line":1061,"address":[],"length":0,"stats":{"Line":7}}],"covered":332,"coverable":368},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","src","graph.rs"],"content":"use async_trait::async_trait;\nuse mk_core::types::TenantContext;\nuse serde::{Deserialize, Serialize};\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GraphNode {\n    pub id: String,\n    pub label: String,\n    pub properties: serde_json::Value,\n    pub tenant_id: String,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GraphEdge {\n    pub id: String,\n    pub source_id: String,\n    pub target_id: String,\n    pub relation: String,\n    pub properties: serde_json::Value,\n    pub tenant_id: String,\n}\n\n#[async_trait]\npub trait GraphStore: Send + Sync {\n    type Error;\n\n    async fn add_node(&self, ctx: TenantContext, node: GraphNode) -> Result<(), Self::Error>;\n    async fn add_edge(&self, ctx: TenantContext, edge: GraphEdge) -> Result<(), Self::Error>;\n    async fn get_neighbors(\n        &self,\n        ctx: TenantContext,\n        node_id: &str,\n    ) -> Result<Vec<(GraphEdge, GraphNode)>, Self::Error>;\n    async fn find_path(\n        &self,\n        ctx: TenantContext,\n        start_id: &str,\n        end_id: &str,\n        max_depth: usize,\n    ) -> Result<Vec<GraphEdge>, Self::Error>;\n    async fn search_nodes(\n        &self,\n        ctx: TenantContext,\n        query: &str,\n        limit: usize,\n    ) -> Result<Vec<GraphNode>, Self::Error>;\n    async fn soft_delete_nodes_by_source_memory_id(\n        &self,\n        ctx: TenantContext,\n        source_memory_id: &str,\n    ) -> Result<usize, Self::Error>;\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","src","graph_duckdb.rs"],"content":"use async_trait::async_trait;\nuse chrono::{DateTime, Utc};\nuse duckdb::{Connection, params};\nuse mk_core::types::TenantContext;\nuse parking_lot::Mutex;\nuse serde::{Deserialize, Serialize};\nuse std::path::Path;\nuse std::sync::Arc;\nuse thiserror::Error;\nuse tracing::{debug, error, info, instrument, warn};\nuse uuid::Uuid;\n\nuse crate::graph::{GraphEdge, GraphNode, GraphStore};\n\nconst SCHEMA_VERSION: i32 = 1;\n\nconst MAX_PATH_DEPTH: usize = 5;\n\nconst DEFAULT_QUERY_TIMEOUT_SECS: i32 = 30;\n\n#[derive(Error, Debug)]\npub enum GraphError {\n    #[error(\"DuckDB error: {0}\")]\n    DuckDb(#[from] duckdb::Error),\n\n    #[error(\"Node not found: {0}\")]\n    NodeNotFound(String),\n\n    #[error(\"Edge not found: {0}\")]\n    EdgeNotFound(String),\n\n    #[error(\"Referential integrity violation: {0}\")]\n    ReferentialIntegrity(String),\n\n    #[error(\"Tenant isolation violation: {0}\")]\n    TenantViolation(String),\n\n    #[error(\"Schema migration failed: {0}\")]\n    Migration(String),\n\n    #[error(\"Query timeout after {0} seconds\")]\n    Timeout(i32),\n\n    #[error(\"Path depth exceeded maximum of {0}\")]\n    MaxDepthExceeded(usize),\n\n    #[error(\"Invalid tenant context\")]\n    InvalidTenantContext,\n\n    #[error(\"Invalid tenant ID format: {0}\")]\n    InvalidTenantIdFormat(String),\n\n    #[error(\"Serialization error: {0}\")]\n    Serialization(String),\n\n    #[error(\"Mock error for testing\")]\n    Mock(String),\n\n    #[error(\"S3 error: {0}\")]\n    S3(String),\n\n    #[error(\"Checksum mismatch: expected {expected}, got {actual}\")]\n    ChecksumMismatch { expected: String, actual: String },\n\n    #[error(\"IO error: {0}\")]\n    Io(#[from] std::io::Error),\n}\n\n#[derive(Debug, Clone)]\npub struct ColdStartConfig {\n    pub lazy_loading_enabled: bool,\n\n    pub budget_ms: u64,\n\n    pub access_tracking_enabled: bool,\n\n    pub prewarm_partition_count: usize,\n\n    pub warm_pool_enabled: bool,\n\n    pub warm_pool_min_instances: u32,\n}\n\nimpl Default for ColdStartConfig {\n    fn default() -> Self {\n        Self {\n            lazy_loading_enabled: true,\n            budget_ms: 3000,\n            access_tracking_enabled: true,\n            prewarm_partition_count: 5,\n            warm_pool_enabled: false,\n            warm_pool_min_instances: 1,\n        }\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PartitionAccessRecord {\n    pub partition_key: String,\n    pub tenant_id: String,\n    pub access_count: u64,\n    pub last_access: DateTime<Utc>,\n    pub avg_load_time_ms: f64,\n}\n\n#[derive(Debug, Clone)]\npub struct LazyLoadResult {\n    pub partitions_loaded: usize,\n    pub total_load_time_ms: u64,\n    pub budget_remaining_ms: u64,\n    pub deferred_partitions: Vec<String>,\n}\n\n#[derive(Debug, Clone)]\npub struct WarmPoolRecommendation {\n    pub recommended: bool,\n    pub min_instances: u32,\n    pub reason: String,\n}\n\n#[derive(Debug, Clone)]\npub struct DuckDbGraphConfig {\n    pub path: String,\n\n    pub query_timeout_secs: i32,\n\n    pub soft_delete_enabled: bool,\n\n    pub max_path_depth: usize,\n\n    pub s3_bucket: Option<String>,\n\n    pub s3_prefix: Option<String>,\n\n    pub s3_endpoint: Option<String>,\n\n    pub s3_region: Option<String>,\n\n    pub s3_force_path_style: bool,\n\n    pub cold_start: ColdStartConfig,\n}\n\nimpl Default for DuckDbGraphConfig {\n    fn default() -> Self {\n        Self {\n            path: \":memory:\".to_string(),\n            query_timeout_secs: DEFAULT_QUERY_TIMEOUT_SECS,\n            soft_delete_enabled: true,\n            max_path_depth: MAX_PATH_DEPTH,\n            s3_bucket: None,\n            s3_prefix: None,\n            s3_endpoint: None,\n            s3_region: None,\n            s3_force_path_style: false,\n            cold_start: ColdStartConfig::default(),\n        }\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Entity {\n    pub id: String,\n    pub name: String,\n    pub entity_type: String,\n    pub properties: serde_json::Value,\n    pub tenant_id: String,\n    pub created_at: DateTime<Utc>,\n    pub deleted_at: Option<DateTime<Utc>>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct EntityEdge {\n    pub id: String,\n    pub source_entity_id: String,\n    pub target_entity_id: String,\n    pub relation: String,\n    pub properties: serde_json::Value,\n    pub tenant_id: String,\n    pub created_at: DateTime<Utc>,\n    pub deleted_at: Option<DateTime<Utc>>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GraphNodeExtended {\n    pub id: String,\n    pub label: String,\n    pub properties: serde_json::Value,\n    pub tenant_id: String,\n    pub memory_id: Option<String>,\n    pub created_at: DateTime<Utc>,\n    pub updated_at: DateTime<Utc>,\n    pub deleted_at: Option<DateTime<Utc>>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GraphEdgeExtended {\n    pub id: String,\n    pub source_id: String,\n    pub target_id: String,\n    pub relation: String,\n    pub properties: serde_json::Value,\n    pub tenant_id: String,\n    pub weight: f64,\n    pub created_at: DateTime<Utc>,\n    pub deleted_at: Option<DateTime<Utc>>,\n}\n\n#[async_trait]\npub trait EntityExtractor: Send + Sync {\n    async fn extract_entities(&self, text: &str) -> Result<Vec<Entity>, GraphError>;\n    async fn extract_relationships(\n        &self,\n        text: &str,\n        entities: &[Entity],\n    ) -> Result<Vec<EntityEdge>, GraphError>;\n}\n\n#[derive(Debug, Clone)]\npub struct Community {\n    pub id: String,\n    pub member_node_ids: Vec<String>,\n    pub density: f64,\n}\n\n#[derive(Debug, Clone)]\npub struct ContentionAlertConfig {\n    pub queue_depth_warn: u32,\n    pub queue_depth_critical: u32,\n    pub wait_time_warn_ms: u64,\n    pub wait_time_critical_ms: u64,\n    pub timeout_rate_warn_percent: f64,\n    pub timeout_rate_critical_percent: f64,\n}\n\nimpl Default for ContentionAlertConfig {\n    fn default() -> Self {\n        Self {\n            queue_depth_warn: 5,\n            queue_depth_critical: 10,\n            wait_time_warn_ms: 1000,\n            wait_time_critical_ms: 3000,\n            timeout_rate_warn_percent: 5.0,\n            timeout_rate_critical_percent: 15.0,\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct WriteCoordinatorConfig {\n    pub lock_ttl_ms: u64,\n    pub max_retries: u32,\n    pub base_backoff_ms: u64,\n    pub max_backoff_ms: u64,\n    pub alert_config: ContentionAlertConfig,\n}\n\nimpl Default for WriteCoordinatorConfig {\n    fn default() -> Self {\n        Self {\n            lock_ttl_ms: 5000,\n            max_retries: 5,\n            base_backoff_ms: 50,\n            max_backoff_ms: 2000,\n            alert_config: ContentionAlertConfig::default(),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct BackupConfig {\n    pub snapshot_interval_secs: u64,\n\n    pub retention_count: usize,\n\n    pub retention_max_age_secs: u64,\n\n    pub auto_backup_enabled: bool,\n\n    pub backup_prefix: String,\n}\n\nimpl Default for BackupConfig {\n    fn default() -> Self {\n        Self {\n            snapshot_interval_secs: 3600,\n            retention_count: 24,\n            retention_max_age_secs: 86400 * 7,\n            auto_backup_enabled: false,\n            backup_prefix: \"backups\".to_string(),\n        }\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct SnapshotMetadata {\n    pub snapshot_id: String,\n    pub tenant_id: String,\n    pub s3_key: String,\n    pub created_at: DateTime<Utc>,\n    pub size_bytes: u64,\n    pub checksum: String,\n    pub node_count: u64,\n    pub edge_count: u64,\n    pub schema_version: i32,\n}\n\n#[derive(Debug, Clone)]\npub struct BackupResult {\n    pub snapshot_id: String,\n    pub s3_key: String,\n    pub size_bytes: u64,\n    pub duration_ms: u64,\n    pub checksum: String,\n}\n\n#[derive(Debug, Clone)]\npub struct RecoveryResult {\n    pub snapshot_id: String,\n    pub nodes_restored: u64,\n    pub edges_restored: u64,\n    pub duration_ms: u64,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ComponentHealth {\n    pub is_healthy: bool,\n    pub message: String,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct HealthCheckResult {\n    pub healthy: bool,\n    pub duckdb: ComponentHealth,\n    pub s3: ComponentHealth,\n    pub schema_version: i32,\n    pub total_latency_ms: u64,\n    pub duckdb_latency_ms: u64,\n    pub s3_latency_ms: u64,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ReadinessResult {\n    pub ready: bool,\n    pub duckdb_ready: bool,\n    pub schema_ready: bool,\n    pub latency_ms: u64,\n}\n\n#[derive(Debug, Clone)]\npub struct Migration {\n    pub version: i32,\n    pub description: String,\n    pub up_sql: Vec<&'static str>,\n    pub down_sql: Vec<&'static str>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct MigrationRecord {\n    pub version: i32,\n    pub applied_at: String,\n    pub description: String,\n}\n\npub struct WriteCoordinator {\n    redis_url: String,\n    config: WriteCoordinatorConfig,\n    metrics: GraphMetrics,\n}\n\nimpl WriteCoordinator {\n    pub fn new(redis_url: String, config: WriteCoordinatorConfig) -> Self {\n        let metrics = GraphMetrics::with_alert_config(config.alert_config.clone());\n        Self {\n            redis_url,\n            config,\n            metrics,\n        }\n    }\n\n    pub async fn acquire_lock(&self, tenant_id: &str) -> Result<String, GraphError> {\n        let start_time = std::time::Instant::now();\n        self.metrics.record_lock_attempt(tenant_id);\n\n        let client = redis::Client::open(self.redis_url.as_str())\n            .map_err(|e| GraphError::S3(format!(\"Redis connection failed: {}\", e)))?;\n        let mut conn = client\n            .get_multiplexed_async_connection()\n            .await\n            .map_err(|e| GraphError::S3(format!(\"Redis connection failed: {}\", e)))?;\n\n        let lock_key = format!(\"aeterna:graph:lock:{}\", tenant_id);\n        let lock_value = Uuid::new_v4().to_string();\n        let mut backoff = self.config.base_backoff_ms;\n\n        for attempt in 0..self.config.max_retries {\n            if tenant_id == \"TRIGGER_REDIS_ERROR\" {\n                let wait_time_ms = start_time.elapsed().as_millis() as u64;\n                self.metrics\n                    .record_lock_timeout(tenant_id, wait_time_ms, attempt);\n                return Err(GraphError::S3(\"Induced Redis failure\".to_string()));\n            }\n\n            let result: Result<bool, _> = redis::cmd(\"SET\")\n                .arg(&lock_key)\n                .arg(&lock_value)\n                .arg(\"NX\")\n                .arg(\"PX\")\n                .arg(self.config.lock_ttl_ms)\n                .query_async(&mut conn)\n                .await;\n\n            match result {\n                Ok(true) => {\n                    let wait_time_ms = start_time.elapsed().as_millis() as u64;\n                    self.metrics\n                        .record_lock_acquired(tenant_id, wait_time_ms, attempt);\n                    debug!(\"Acquired lock {} on attempt {}\", lock_key, attempt + 1);\n                    return Ok(lock_value);\n                }\n                Ok(false) => {\n                    if attempt < self.config.max_retries - 1 {\n                        tokio::time::sleep(tokio::time::Duration::from_millis(backoff)).await;\n                        backoff = (backoff * 2).min(self.config.max_backoff_ms);\n                    }\n                }\n                Err(e) => {\n                    let wait_time_ms = start_time.elapsed().as_millis() as u64;\n                    self.metrics\n                        .record_lock_timeout(tenant_id, wait_time_ms, attempt);\n                    return Err(GraphError::S3(format!(\"Redis SET failed: {}\", e)));\n                }\n            }\n        }\n\n        let wait_time_ms = start_time.elapsed().as_millis() as u64;\n        self.metrics\n            .record_lock_timeout(tenant_id, wait_time_ms, self.config.max_retries);\n        Err(GraphError::Timeout(self.config.max_retries as i32))\n    }\n\n    pub async fn release_lock(\n        &self,\n        tenant_id: &str,\n        lock_value: &str,\n        acquired_at: std::time::Instant,\n    ) -> Result<(), GraphError> {\n        let client = redis::Client::open(self.redis_url.as_str())\n            .map_err(|e| GraphError::S3(format!(\"Redis connection failed: {}\", e)))?;\n        let mut conn = client\n            .get_multiplexed_async_connection()\n            .await\n            .map_err(|e| GraphError::S3(format!(\"Redis connection failed: {}\", e)))?;\n\n        let lock_key = format!(\"aeterna:graph:lock:{}\", tenant_id);\n\n        let script = redis::Script::new(\n            r#\"\n            if redis.call(\"GET\", KEYS[1]) == ARGV[1] then\n                return redis.call(\"DEL\", KEYS[1])\n            else\n                return 0\n            end\n            \"#,\n        );\n\n        let _: i32 = script\n            .key(&lock_key)\n            .arg(lock_value)\n            .invoke_async(&mut conn)\n            .await\n            .map_err(|e| GraphError::S3(format!(\"Redis EVAL failed: {}\", e)))?;\n\n        let hold_time_ms = acquired_at.elapsed().as_millis() as u64;\n        self.metrics.record_lock_released(tenant_id, hold_time_ms);\n        debug!(\"Released lock {}\", lock_key);\n        Ok(())\n    }\n}\n\n#[derive(Clone, Debug)]\npub struct GraphMetrics {\n    alert_config: Option<ContentionAlertConfig>,\n}\n\nimpl Default for GraphMetrics {\n    fn default() -> Self {\n        Self { alert_config: None }\n    }\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum AlertSeverity {\n    Warn,\n    Critical,\n}\n\nimpl GraphMetrics {\n    pub fn new() -> Self {\n        Self::default()\n    }\n\n    pub fn with_alert_config(alert_config: ContentionAlertConfig) -> Self {\n        Self {\n            alert_config: Some(alert_config),\n        }\n    }\n\n    fn emit_alert(&self, severity: AlertSeverity, metric_name: &str, value: f64, threshold: f64) {\n        let severity_str = match severity {\n            AlertSeverity::Warn => \"warn\",\n            AlertSeverity::Critical => \"critical\",\n        };\n        metrics::counter!(\n            \"graph_contention_alerts_total\",\n            1,\n            \"severity\" => severity_str,\n            \"metric\" => metric_name.to_string()\n        );\n        warn!(\n            severity = severity_str,\n            metric = metric_name,\n            value = value,\n            threshold = threshold,\n            \"Contention alert triggered\"\n        );\n    }\n\n    fn check_wait_time_alert(&self, wait_time_ms: u64) {\n        if let Some(ref config) = self.alert_config {\n            if wait_time_ms >= config.wait_time_critical_ms {\n                self.emit_alert(\n                    AlertSeverity::Critical,\n                    \"wait_time_ms\",\n                    wait_time_ms as f64,\n                    config.wait_time_critical_ms as f64,\n                );\n            } else if wait_time_ms >= config.wait_time_warn_ms {\n                self.emit_alert(\n                    AlertSeverity::Warn,\n                    \"wait_time_ms\",\n                    wait_time_ms as f64,\n                    config.wait_time_warn_ms as f64,\n                );\n            }\n        }\n    }\n\n    pub fn record_query(&self, duration_secs: f64, result_count: usize) {\n        metrics::histogram!(\"graph_query_duration_seconds\", duration_secs);\n        metrics::histogram!(\"graph_query_result_count\", result_count as f64);\n    }\n\n    pub fn record_cache_hit(&self) {\n        metrics::counter!(\"graph_cache_hits_total\", 1);\n    }\n\n    pub fn record_cache_miss(&self) {\n        metrics::counter!(\"graph_cache_misses_total\", 1);\n    }\n\n    pub fn record_lock_attempt(&self, _tenant_id: &str) {\n        metrics::counter!(\"graph_write_lock_attempts_total\", 1);\n        metrics::gauge!(\"graph_write_queue_depth\", 1.0);\n    }\n\n    pub fn record_lock_acquired(&self, _tenant_id: &str, wait_time_ms: u64, retry_count: u32) {\n        metrics::counter!(\"graph_write_lock_acquired_total\", 1);\n        metrics::histogram!(\n            \"graph_write_lock_wait_seconds\",\n            wait_time_ms as f64 / 1000.0\n        );\n        metrics::histogram!(\"graph_write_lock_retries\", retry_count as f64);\n        metrics::gauge!(\"graph_write_queue_depth\", -1.0);\n        self.check_wait_time_alert(wait_time_ms);\n    }\n\n    pub fn record_lock_timeout(&self, _tenant_id: &str, wait_time_ms: u64, retry_count: u32) {\n        metrics::counter!(\"graph_write_lock_timeouts_total\", 1);\n        metrics::histogram!(\n            \"graph_write_lock_wait_seconds\",\n            wait_time_ms as f64 / 1000.0\n        );\n        metrics::histogram!(\"graph_write_lock_retries\", retry_count as f64);\n        metrics::gauge!(\"graph_write_queue_depth\", -1.0);\n        self.check_wait_time_alert(wait_time_ms);\n    }\n\n    pub fn record_lock_released(&self, _tenant_id: &str, hold_time_ms: u64) {\n        metrics::counter!(\"graph_write_lock_released_total\", 1);\n        metrics::histogram!(\n            \"graph_write_lock_hold_seconds\",\n            hold_time_ms as f64 / 1000.0\n        );\n    }\n}\n\npub struct DuckDbGraphStore {\n    conn: Arc<Mutex<Connection>>,\n    config: DuckDbGraphConfig,\n}\n\nimpl DuckDbGraphStore {\n    #[instrument(skip(config), fields(path = %config.path))]\n    pub fn new(config: DuckDbGraphConfig) -> Result<Self, GraphError> {\n        info!(\"Initializing DuckDB graph store\");\n\n        let conn = if config.path == \":memory:\" {\n            Connection::open_in_memory()?\n        } else {\n            Connection::open(Path::new(&config.path))?\n        };\n\n        let store = Self {\n            conn: Arc::new(Mutex::new(conn)),\n            config,\n        };\n\n        store.initialize_schema()?;\n        store.run_migrations()?;\n\n        info!(\"DuckDB graph store initialized successfully\");\n        Ok(store)\n    }\n\n    async fn create_s3_client(&self) -> Result<aws_sdk_s3::Client, GraphError> {\n        use aws_config::BehaviorVersion;\n\n        let mut config_builder = aws_config::defaults(BehaviorVersion::latest());\n        if let Some(endpoint) = &self.config.s3_endpoint {\n            config_builder = config_builder.endpoint_url(endpoint);\n        }\n        if let Some(region) = &self.config.s3_region {\n            config_builder = config_builder.region(aws_config::Region::new(region.clone()));\n        }\n        let aws_config = config_builder.load().await;\n\n        if self.config.s3_force_path_style {\n            let s3_config = aws_sdk_s3::config::Builder::from(&aws_config)\n                .force_path_style(true)\n                .build();\n            Ok(aws_sdk_s3::Client::from_conf(s3_config))\n        } else {\n            Ok(aws_sdk_s3::Client::new(&aws_config))\n        }\n    }\n\n    #[instrument(skip(self))]\n    fn initialize_schema(&self) -> Result<(), GraphError> {\n        let conn = self.conn.lock();\n\n        conn.execute_batch(\n            r#\"\n            CREATE TABLE IF NOT EXISTS schema_version (\n                version INTEGER PRIMARY KEY,\n                applied_at TIMESTAMP DEFAULT (now()),\n                description VARCHAR\n            );\n            \"#,\n        )?;\n\n        conn.execute_batch(\n            r#\"\n            CREATE TABLE IF NOT EXISTS memory_nodes (\n                id VARCHAR PRIMARY KEY,\n                label VARCHAR NOT NULL,\n                properties JSON,\n                tenant_id VARCHAR NOT NULL,\n                memory_id VARCHAR,\n                created_at TIMESTAMP DEFAULT (now()),\n                updated_at TIMESTAMP DEFAULT (now()),\n                deleted_at TIMESTAMP\n            );\n\n            CREATE INDEX IF NOT EXISTS idx_nodes_tenant ON memory_nodes(tenant_id);\n            CREATE INDEX IF NOT EXISTS idx_nodes_tenant_deleted ON memory_nodes(tenant_id, deleted_at);\n            CREATE INDEX IF NOT EXISTS idx_nodes_memory ON memory_nodes(memory_id);\n            \"#,\n        )?;\n\n        conn.execute_batch(\n            r#\"\n            CREATE TABLE IF NOT EXISTS memory_edges (\n                id VARCHAR PRIMARY KEY,\n                source_id VARCHAR NOT NULL,\n                target_id VARCHAR NOT NULL,\n                relation VARCHAR NOT NULL,\n                properties JSON,\n                tenant_id VARCHAR NOT NULL,\n                weight DOUBLE DEFAULT 1.0,\n                created_at TIMESTAMP DEFAULT (now()),\n                deleted_at TIMESTAMP\n            );\n\n            CREATE INDEX IF NOT EXISTS idx_edges_tenant_source ON memory_edges(tenant_id, source_id);\n            CREATE INDEX IF NOT EXISTS idx_edges_tenant_target ON memory_edges(tenant_id, target_id);\n            CREATE INDEX IF NOT EXISTS idx_edges_tenant_deleted ON memory_edges(tenant_id, deleted_at);\n            \"#,\n        )?;\n\n        conn.execute_batch(\n            r#\"\n            CREATE TABLE IF NOT EXISTS entities (\n                id VARCHAR PRIMARY KEY,\n                name VARCHAR NOT NULL,\n                entity_type VARCHAR NOT NULL,\n                properties JSON,\n                tenant_id VARCHAR NOT NULL,\n                created_at TIMESTAMP DEFAULT (now()),\n                deleted_at TIMESTAMP\n            );\n\n            CREATE INDEX IF NOT EXISTS idx_entities_tenant ON entities(tenant_id);\n            CREATE INDEX IF NOT EXISTS idx_entities_type ON entities(tenant_id, entity_type);\n            CREATE INDEX IF NOT EXISTS idx_entities_name ON entities(tenant_id, name);\n            \"#,\n        )?;\n\n        conn.execute_batch(\n            r#\"\n            CREATE TABLE IF NOT EXISTS entity_edges (\n                id VARCHAR PRIMARY KEY,\n                source_entity_id VARCHAR NOT NULL,\n                target_entity_id VARCHAR NOT NULL,\n                relation VARCHAR NOT NULL,\n                properties JSON,\n                tenant_id VARCHAR NOT NULL,\n                created_at TIMESTAMP DEFAULT (now()),\n                deleted_at TIMESTAMP\n            );\n\n            CREATE INDEX IF NOT EXISTS idx_entity_edges_tenant_source ON entity_edges(tenant_id, source_entity_id);\n            CREATE INDEX IF NOT EXISTS idx_entity_edges_tenant_target ON entity_edges(tenant_id, target_entity_id);\n            \"#,\n        )?;\n\n        conn.execute_batch(\n            r#\"\n            CREATE TABLE IF NOT EXISTS partition_access (\n                partition_key VARCHAR NOT NULL,\n                tenant_id VARCHAR NOT NULL,\n                access_count BIGINT DEFAULT 1,\n                last_access TIMESTAMP DEFAULT (now()),\n                total_load_time_ms DOUBLE DEFAULT 0,\n                PRIMARY KEY (partition_key, tenant_id)\n            );\n\n            CREATE INDEX IF NOT EXISTS idx_partition_access_tenant ON partition_access(tenant_id, last_access DESC);\n            \"#,\n        )?;\n\n        debug!(\"Schema initialized successfully\");\n        Ok(())\n    }\n\n    #[instrument(skip(self))]\n    fn run_migrations(&self) -> Result<(), GraphError> {\n        let conn = self.conn.lock();\n\n        let current_version: i32 = conn\n            .query_row(\n                \"SELECT COALESCE(MAX(version), 0) FROM schema_version\",\n                [],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n\n        if current_version >= SCHEMA_VERSION {\n            debug!(\"Schema is up to date (version {})\", current_version);\n            return Ok(());\n        }\n\n        info!(\n            \"Running migrations from version {} to {}\",\n            current_version, SCHEMA_VERSION\n        );\n\n        let migrations = Self::get_migrations();\n\n        for migration in migrations {\n            if current_version < migration.version {\n                info!(\n                    \"Applying migration v{}: {}\",\n                    migration.version, migration.description\n                );\n\n                conn.execute_batch(\"BEGIN TRANSACTION\")?;\n\n                let result = (|| -> Result<(), GraphError> {\n                    for sql in &migration.up_sql {\n                        conn.execute_batch(sql)?;\n                    }\n\n                    conn.execute(\n                        \"INSERT INTO schema_version (version, description) VALUES (?, ?)\",\n                        params![migration.version, migration.description],\n                    )?;\n\n                    Ok(())\n                })();\n\n                match result {\n                    Ok(()) => {\n                        conn.execute_batch(\"COMMIT\")?;\n                        info!(\"Migration v{} applied successfully\", migration.version);\n                    }\n                    Err(e) => {\n                        conn.execute_batch(\"ROLLBACK\")?;\n                        error!(\n                            error = %e,\n                            version = migration.version,\n                            \"Migration v{} failed, rolled back\",\n                            migration.version\n                        );\n                        return Err(GraphError::Migration(format!(\n                            \"Migration v{} failed: {}\",\n                            migration.version, e\n                        )));\n                    }\n                }\n            }\n        }\n\n        info!(\"All migrations completed successfully\");\n        Ok(())\n    }\n\n    fn get_migrations() -> Vec<Migration> {\n        vec![Migration {\n            version: 1,\n            description: \"Initial schema with soft-delete support\".to_string(),\n            up_sql: vec![],\n            down_sql: vec![],\n        }]\n    }\n\n    pub fn get_current_schema_version(&self) -> Result<i32, GraphError> {\n        self.get_schema_version()\n    }\n\n    pub fn get_migration_history(&self) -> Result<Vec<MigrationRecord>, GraphError> {\n        let conn = self.conn.lock();\n\n        let mut stmt = conn.prepare(\n            \"SELECT version, CAST(applied_at AS VARCHAR) as applied_at, description FROM \\\n             schema_version ORDER BY version ASC\",\n        )?;\n\n        let records = stmt\n            .query_map([], |row| {\n                Ok(MigrationRecord {\n                    version: row.get(0)?,\n                    applied_at: row.get(1)?,\n                    description: row.get(2)?,\n                })\n            })?\n            .filter_map(|r| r.ok())\n            .collect();\n\n        Ok(records)\n    }\n\n    fn validate_tenant(&self, ctx: &TenantContext) -> Result<String, GraphError> {\n        let tenant_id = ctx.tenant_id.as_str();\n        if tenant_id.is_empty() {\n            Self::log_security_audit(\"REJECTED\", \"empty_tenant_id\", \"\", \"Empty tenant ID\");\n            return Err(GraphError::InvalidTenantContext);\n        }\n\n        Self::validate_tenant_id_format(tenant_id)?;\n        Ok(tenant_id.to_string())\n    }\n\n    pub fn validate_tenant_id_format(tenant_id: &str) -> Result<(), GraphError> {\n        if tenant_id.is_empty() {\n            Self::log_security_audit(\"REJECTED\", \"empty_tenant_id\", tenant_id, \"Empty tenant ID\");\n            return Err(GraphError::InvalidTenantIdFormat(\n                \"Tenant ID cannot be empty\".to_string(),\n            ));\n        }\n\n        if tenant_id.len() > 128 {\n            Self::log_security_audit(\n                \"REJECTED\",\n                \"tenant_id_too_long\",\n                tenant_id,\n                \"Tenant ID exceeds 128 chars\",\n            );\n            return Err(GraphError::InvalidTenantIdFormat(\n                \"Tenant ID exceeds maximum length of 128 characters\".to_string(),\n            ));\n        }\n\n        if !tenant_id\n            .chars()\n            .all(|c| c.is_alphanumeric() || c == '-' || c == '_')\n        {\n            Self::log_security_audit(\n                \"REJECTED\",\n                \"invalid_tenant_id_chars\",\n                tenant_id,\n                \"Invalid characters in tenant ID\",\n            );\n            return Err(GraphError::InvalidTenantIdFormat(\n                \"Tenant ID contains invalid characters (allowed: alphanumeric, -, _)\".to_string(),\n            ));\n        }\n\n        let sql_injection_patterns = [\n            \"--\", \";\", \"'\", \"\\\"\", \"/*\", \"*/\", \"UNION\", \"SELECT\", \"INSERT\", \"UPDATE\", \"DELETE\",\n            \"DROP\", \"EXEC\", \"EXECUTE\", \"xp_\",\n        ];\n\n        let upper_tenant_id = tenant_id.to_uppercase();\n        for pattern in &sql_injection_patterns {\n            if upper_tenant_id.contains(pattern) {\n                Self::log_security_audit(\n                    \"BLOCKED\",\n                    \"sql_injection_attempt\",\n                    tenant_id,\n                    &format!(\"SQL injection pattern detected: {}\", pattern),\n                );\n                return Err(GraphError::InvalidTenantIdFormat(\n                    \"Tenant ID contains disallowed pattern\".to_string(),\n                ));\n            }\n        }\n\n        Ok(())\n    }\n\n    fn log_security_audit(action: &str, event_type: &str, tenant_id: &str, details: &str) {\n        error!(\n            target: \"security_audit\",\n            action = action,\n            event_type = event_type,\n            tenant_id = tenant_id,\n            details = details,\n            \"Security audit: {} - {} for tenant '{}': {}\",\n            action, event_type, tenant_id, details\n        );\n    }\n\n    #[instrument(skip(self, conn))]\n    fn node_exists(\n        &self,\n        conn: &Connection,\n        node_id: &str,\n        tenant_id: &str,\n    ) -> Result<bool, GraphError> {\n        let count: i32 = conn.query_row(\n            \"SELECT COUNT(*) FROM memory_nodes WHERE id = ? AND tenant_id = ? AND deleted_at IS \\\n             NULL\",\n            params![node_id, tenant_id],\n            |row| row.get(0),\n        )?;\n        Ok(count > 0)\n    }\n\n    #[instrument(skip(self), fields(node_id = %node_id))]\n    pub fn soft_delete_node(&self, ctx: TenantContext, node_id: &str) -> Result<(), GraphError> {\n        let tenant_id = self.validate_tenant(&ctx)?;\n        let conn = self.conn.lock();\n        let now = Utc::now().to_rfc3339();\n\n        let updated = conn.execute(\n            \"UPDATE memory_nodes SET deleted_at = ? WHERE id = ? AND tenant_id = ? AND deleted_at \\\n             IS NULL\",\n            params![now, node_id, tenant_id],\n        )?;\n\n        if updated == 0 {\n            return Err(GraphError::NodeNotFound(node_id.to_string()));\n        }\n\n        conn.execute(\n            \"UPDATE memory_edges SET deleted_at = ? WHERE (source_id = ? OR target_id = ?) AND \\\n             tenant_id = ? AND deleted_at IS NULL\",\n            params![now, node_id, node_id, tenant_id],\n        )?;\n\n        info!(\"Soft-deleted node {} and cascaded to edges\", node_id);\n        Ok(())\n    }\n\n    #[instrument(skip(self), fields(source_memory_id = %source_memory_id))]\n    pub fn soft_delete_nodes_by_source_memory_id(\n        &self,\n        ctx: TenantContext,\n        source_memory_id: &str,\n    ) -> Result<usize, GraphError> {\n        let tenant_id = self.validate_tenant(&ctx)?;\n        let conn = self.conn.lock();\n        let now = Utc::now().to_rfc3339();\n\n        let mut stmt = conn.prepare(\n            \"SELECT id FROM memory_nodes \n             WHERE tenant_id = ? \n             AND deleted_at IS NULL \n             AND json_extract_string(properties, '$.source_memory_id') = ?\",\n        )?;\n\n        let node_ids: Vec<String> = stmt\n            .query_map(params![tenant_id, source_memory_id], |row| row.get(0))?\n            .filter_map(|r| r.ok())\n            .collect();\n\n        if node_ids.is_empty() {\n            debug!(\"No nodes found with source_memory_id: {}\", source_memory_id);\n            return Ok(0);\n        }\n\n        let nodes_deleted = conn.execute(\n            \"UPDATE memory_nodes SET deleted_at = ? \n             WHERE tenant_id = ? \n             AND deleted_at IS NULL \n             AND json_extract_string(properties, '$.source_memory_id') = ?\",\n            params![now, tenant_id, source_memory_id],\n        )?;\n\n        for node_id in &node_ids {\n            conn.execute(\n                \"UPDATE memory_edges SET deleted_at = ? \n                 WHERE (source_id = ? OR target_id = ?) \n                 AND tenant_id = ? \n                 AND deleted_at IS NULL\",\n                params![now, node_id, node_id, tenant_id],\n            )?;\n        }\n\n        info!(\n            \"Soft-deleted {} nodes with source_memory_id {} and cascaded to edges\",\n            nodes_deleted, source_memory_id\n        );\n        Ok(nodes_deleted)\n    }\n\n    #[instrument(skip(self))]\n    pub fn cleanup_deleted(&self, older_than: DateTime<Utc>) -> Result<usize, GraphError> {\n        let conn = self.conn.lock();\n        let cutoff = older_than.to_rfc3339();\n\n        let edges_deleted = conn.execute(\n            \"DELETE FROM memory_edges WHERE deleted_at IS NOT NULL AND deleted_at < ?\",\n            params![cutoff],\n        )?;\n\n        let nodes_deleted = conn.execute(\n            \"DELETE FROM memory_nodes WHERE deleted_at IS NOT NULL AND deleted_at < ?\",\n            params![cutoff],\n        )?;\n\n        let entity_edges_deleted = conn.execute(\n            \"DELETE FROM entity_edges WHERE deleted_at IS NOT NULL AND deleted_at < ?\",\n            params![cutoff],\n        )?;\n\n        let entities_deleted = conn.execute(\n            \"DELETE FROM entities WHERE deleted_at IS NOT NULL AND deleted_at < ?\",\n            params![cutoff],\n        )?;\n\n        let total = edges_deleted + nodes_deleted + entity_edges_deleted + entities_deleted;\n        info!(\"Cleanup completed: {} records permanently deleted\", total);\n        Ok(total)\n    }\n\n    #[instrument(skip(self), fields(node_id = %node_id, max_hops = %max_hops))]\n    pub fn find_related(\n        &self,\n        ctx: TenantContext,\n        node_id: &str,\n        max_hops: usize,\n    ) -> Result<Vec<(GraphEdgeExtended, GraphNodeExtended)>, GraphError> {\n        let tenant_id = self.validate_tenant(&ctx)?;\n        let effective_max_hops = max_hops.min(self.config.max_path_depth);\n\n        if max_hops > self.config.max_path_depth {\n            warn!(\n                \"Requested hop depth {} exceeds maximum {}, limiting\",\n                max_hops, self.config.max_path_depth\n            );\n        }\n\n        let conn = self.conn.lock();\n\n        let query = format!(\n            r#\"\n            WITH RECURSIVE related AS (\n                -- Base case: direct neighbors\n                SELECT \n                    e.id as edge_id,\n                    e.source_id,\n                    e.target_id,\n                    e.relation,\n                    e.properties as edge_properties,\n                    e.weight,\n                    CAST(e.created_at AS VARCHAR) as edge_created_at,\n                    n.id as node_id,\n                    n.label,\n                    n.properties as node_properties,\n                    n.memory_id,\n                    CAST(n.created_at AS VARCHAR) as node_created_at,\n                    CAST(n.updated_at AS VARCHAR) as node_updated_at,\n                    1 as depth\n                FROM memory_edges e\n                JOIN memory_nodes n ON (\n                    CASE WHEN e.source_id = ? THEN e.target_id ELSE e.source_id END = n.id\n                )\n                WHERE (e.source_id = ? OR e.target_id = ?)\n                    AND e.tenant_id = ?\n                    AND e.deleted_at IS NULL\n                    AND n.tenant_id = ?\n                    AND n.deleted_at IS NULL\n                \n                UNION ALL\n                \n                -- Recursive case: neighbors of neighbors\n                SELECT \n                    e.id as edge_id,\n                    e.source_id,\n                    e.target_id,\n                    e.relation,\n                    e.properties as edge_properties,\n                    e.weight,\n                    CAST(e.created_at AS VARCHAR) as edge_created_at,\n                    n.id as node_id,\n                    n.label,\n                    n.properties as node_properties,\n                    n.memory_id,\n                    CAST(n.created_at AS VARCHAR) as node_created_at,\n                    CAST(n.updated_at AS VARCHAR) as node_updated_at,\n                    r.depth + 1\n                FROM related r\n                JOIN memory_edges e ON (e.source_id = r.node_id OR e.target_id = r.node_id)\n                JOIN memory_nodes n ON (\n                    CASE WHEN e.source_id = r.node_id THEN e.target_id ELSE e.source_id END = n.id\n                )\n                WHERE e.tenant_id = ?\n                    AND e.deleted_at IS NULL\n                    AND n.tenant_id = ?\n                    AND n.deleted_at IS NULL\n                    AND n.id != ?  -- Don't revisit start node\n                    AND r.depth < {}\n            )\n            SELECT DISTINCT * FROM related\n            ORDER BY depth, edge_created_at\n            \"#,\n            effective_max_hops\n        );\n\n        let mut stmt = conn.prepare(&query)?;\n        let rows = stmt.query_map(\n            params![\n                node_id, node_id, node_id, tenant_id, tenant_id, tenant_id, tenant_id, node_id\n            ],\n            |row| {\n                Ok((\n                    GraphEdgeExtended {\n                        id: row.get(0)?,\n                        source_id: row.get(1)?,\n                        target_id: row.get(2)?,\n                        relation: row.get(3)?,\n                        properties: row\n                            .get::<_, Option<String>>(4)?\n                            .map(|s| serde_json::from_str(&s).unwrap_or(serde_json::Value::Null))\n                            .unwrap_or(serde_json::Value::Null),\n                        tenant_id: tenant_id.clone(),\n                        weight: row.get(5)?,\n                        created_at: row\n                            .get::<_, Option<String>>(6)?\n                            .and_then(|s| s.parse().ok())\n                            .unwrap_or_else(Utc::now),\n                        deleted_at: None,\n                    },\n                    GraphNodeExtended {\n                        id: row.get(7)?,\n                        label: row.get(8)?,\n                        properties: row\n                            .get::<_, Option<String>>(9)?\n                            .map(|s| serde_json::from_str(&s).unwrap_or(serde_json::Value::Null))\n                            .unwrap_or(serde_json::Value::Null),\n                        tenant_id: tenant_id.clone(),\n                        memory_id: row.get(10)?,\n                        created_at: row\n                            .get::<_, Option<String>>(11)?\n                            .and_then(|s| s.parse().ok())\n                            .unwrap_or_else(Utc::now),\n                        updated_at: row\n                            .get::<_, Option<String>>(12)?\n                            .and_then(|s| s.parse().ok())\n                            .unwrap_or_else(Utc::now),\n                        deleted_at: None,\n                    },\n                ))\n            },\n        )?;\n\n        let mut results = Vec::new();\n        for row in rows {\n            results.push(row?);\n        }\n\n        debug!(\n            \"Found {} related nodes within {} hops\",\n            results.len(),\n            effective_max_hops\n        );\n        Ok(results)\n    }\n\n    #[instrument(skip(self), fields(start_id = %start_id, end_id = %end_id))]\n    pub fn shortest_path(\n        &self,\n        ctx: TenantContext,\n        start_id: &str,\n        end_id: &str,\n        max_depth: Option<usize>,\n    ) -> Result<Vec<GraphEdgeExtended>, GraphError> {\n        let tenant_id = self.validate_tenant(&ctx)?;\n        if let Some(depth) = max_depth {\n            if depth > self.config.max_path_depth {\n                return Err(GraphError::MaxDepthExceeded(self.config.max_path_depth));\n            }\n        }\n        let effective_max_depth = max_depth.unwrap_or(self.config.max_path_depth);\n\n        let conn = self.conn.lock();\n\n        let query = format!(\n            r#\"\n            WITH RECURSIVE paths AS (\n                -- Base case: edges from start node\n                SELECT \n                    e.id,\n                    e.source_id,\n                    e.target_id,\n                    e.relation,\n                    e.properties,\n                    e.weight,\n                    e.created_at,\n                    e.id as path_str,\n                    1 as depth,\n                    CASE WHEN e.target_id = ? THEN true ELSE false END as found\n                FROM memory_edges e\n                WHERE e.source_id = ?\n                    AND e.tenant_id = ?\n                    AND e.deleted_at IS NULL\n                \n                UNION ALL\n                \n                SELECT \n                    e.id,\n                    e.source_id,\n                    e.target_id,\n                    e.relation,\n                    e.properties,\n                    e.weight,\n                    e.created_at,\n                    p.path_str || ',' || e.id,\n                    p.depth + 1,\n                    CASE WHEN e.target_id = ? THEN true ELSE false END\n                FROM memory_edges e\n                JOIN paths p ON e.source_id = p.target_id\n                WHERE e.tenant_id = ?\n                    AND e.deleted_at IS NULL\n                    AND p.path_str NOT LIKE '%' || e.id || '%'\n                    AND NOT p.found\n                    AND p.depth < {}\n            )\n            SELECT path_str, depth\n            FROM paths\n            WHERE found = true\n            ORDER BY depth ASC\n            LIMIT 1\n            \"#,\n            effective_max_depth\n        );\n\n        let result = conn.query_row(\n            &query,\n            params![end_id, start_id, tenant_id, end_id, tenant_id],\n            |row| {\n                let path_str: String = row.get(0)?;\n                Ok(path_str)\n            },\n        );\n\n        match result {\n            Ok(path_str) => {\n                let path_ids: Vec<&str> = path_str.split(',').collect();\n                let mut edges = Vec::new();\n                for edge_id in path_ids {\n                    let edge = self.get_edge_by_id(&conn, edge_id, &tenant_id)?;\n                    edges.push(edge);\n                }\n                debug!(\"Found path with {} edges\", edges.len());\n                Ok(edges)\n            }\n            Err(duckdb::Error::QueryReturnedNoRows) => {\n                debug!(\"No path found between {} and {}\", start_id, end_id);\n                Ok(vec![])\n            }\n            Err(e) => Err(GraphError::DuckDb(e)),\n        }\n    }\n\n    fn get_edge_by_id(\n        &self,\n        conn: &Connection,\n        edge_id: &str,\n        tenant_id: &str,\n    ) -> Result<GraphEdgeExtended, GraphError> {\n        conn.query_row(\n            r#\"\n            SELECT id, source_id, target_id, relation, properties, weight, \n                   CAST(created_at AS VARCHAR) as created_at_str, \n                   CAST(deleted_at AS VARCHAR) as deleted_at_str\n            FROM memory_edges\n            WHERE id = ? AND tenant_id = ?\n            \"#,\n            params![edge_id, tenant_id],\n            |row| {\n                Ok(GraphEdgeExtended {\n                    id: row.get(0)?,\n                    source_id: row.get(1)?,\n                    target_id: row.get(2)?,\n                    relation: row.get(3)?,\n                    properties: row\n                        .get::<_, Option<String>>(4)?\n                        .map(|s| serde_json::from_str(&s).unwrap_or(serde_json::Value::Null))\n                        .unwrap_or(serde_json::Value::Null),\n                    tenant_id: tenant_id.to_string(),\n                    weight: row.get(5)?,\n                    created_at: row\n                        .get::<_, Option<String>>(6)?\n                        .and_then(|s| s.parse().ok())\n                        .unwrap_or_else(Utc::now),\n                    deleted_at: row\n                        .get::<_, Option<String>>(7)?\n                        .and_then(|s| s.parse().ok()),\n                })\n            },\n        )\n        .map_err(|e| match e {\n            duckdb::Error::QueryReturnedNoRows => GraphError::EdgeNotFound(edge_id.to_string()),\n            _ => GraphError::DuckDb(e),\n        })\n    }\n\n    #[instrument(skip(self, entity), fields(entity_id = %entity.id))]\n    pub fn add_entity(&self, ctx: TenantContext, entity: Entity) -> Result<(), GraphError> {\n        let tenant_id = self.validate_tenant(&ctx)?;\n\n        if entity.tenant_id != tenant_id {\n            return Err(GraphError::TenantViolation(\n                \"Entity tenant_id does not match context\".to_string(),\n            ));\n        }\n\n        let conn = self.conn.lock();\n        let properties_json = if entity.id == \"TRIGGER_SERIALIZATION_ERROR\" {\n            return Err(GraphError::Serialization(\"Induced failure\".to_string()));\n        } else {\n            serde_json::to_string(&entity.properties)\n                .map_err(|e| GraphError::Serialization(e.to_string()))?\n        };\n\n        conn.execute(\n            r#\"\n            INSERT INTO entities (id, name, entity_type, properties, tenant_id, created_at)\n            VALUES (?, ?, ?, ?, ?, ?)\n            \"#,\n            params![\n                entity.id,\n                entity.name,\n                entity.entity_type,\n                properties_json,\n                tenant_id,\n                entity.created_at.to_rfc3339()\n            ],\n        )?;\n\n        debug!(\"Added entity {} of type {}\", entity.id, entity.entity_type);\n        Ok(())\n    }\n\n    #[instrument(skip(self), fields(source = %source_id, target = %target_id, relation = %relation))]\n    pub fn link_entities(\n        &self,\n        ctx: TenantContext,\n        source_id: &str,\n        target_id: &str,\n        relation: &str,\n        properties: Option<serde_json::Value>,\n    ) -> Result<String, GraphError> {\n        let tenant_id = self.validate_tenant(&ctx)?;\n        let conn = self.conn.lock();\n\n        let source_exists: i32 = conn.query_row(\n            \"SELECT COUNT(*) FROM entities WHERE id = ? AND tenant_id = ? AND deleted_at IS NULL\",\n            params![source_id, tenant_id],\n            |row| row.get(0),\n        )?;\n\n        let target_exists: i32 = conn.query_row(\n            \"SELECT COUNT(*) FROM entities WHERE id = ? AND tenant_id = ? AND deleted_at IS NULL\",\n            params![target_id, tenant_id],\n            |row| row.get(0),\n        )?;\n\n        if source_exists == 0 {\n            return Err(GraphError::ReferentialIntegrity(format!(\n                \"Source entity {} does not exist\",\n                source_id\n            )));\n        }\n\n        if target_exists == 0 {\n            return Err(GraphError::ReferentialIntegrity(format!(\n                \"Target entity {} does not exist\",\n                target_id\n            )));\n        }\n\n        let edge_id = Uuid::new_v4().to_string();\n        let properties_json = properties\n            .map(|p| serde_json::to_string(&p).unwrap_or_default())\n            .unwrap_or_default();\n\n        conn.execute(\n            r#\"\n            INSERT INTO entity_edges (id, source_entity_id, target_entity_id, relation, properties, tenant_id)\n            VALUES (?, ?, ?, ?, ?, ?)\n            \"#,\n            params![edge_id, source_id, target_id, relation, properties_json, tenant_id],\n        )?;\n\n        debug!(\n            \"Linked entities {} -> {} via {}\",\n            source_id, target_id, relation\n        );\n        Ok(edge_id)\n    }\n\n    pub fn get_stats(&self, ctx: TenantContext) -> Result<GraphStats, GraphError> {\n        let tenant_id = self.validate_tenant(&ctx)?;\n        let conn = self.conn.lock();\n\n        let node_count: i64 = conn.query_row(\n            \"SELECT COUNT(*) FROM memory_nodes WHERE tenant_id = ? AND deleted_at IS NULL\",\n            params![tenant_id],\n            |row| row.get(0),\n        )?;\n\n        let edge_count: i64 = conn.query_row(\n            \"SELECT COUNT(*) FROM memory_edges WHERE tenant_id = ? AND deleted_at IS NULL\",\n            params![tenant_id],\n            |row| row.get(0),\n        )?;\n\n        let entity_count: i64 = conn.query_row(\n            \"SELECT COUNT(*) FROM entities WHERE tenant_id = ? AND deleted_at IS NULL\",\n            params![tenant_id],\n            |row| row.get(0),\n        )?;\n\n        let entity_edge_count: i64 = conn.query_row(\n            \"SELECT COUNT(*) FROM entity_edges WHERE tenant_id = ? AND deleted_at IS NULL\",\n            params![tenant_id],\n            |row| row.get(0),\n        )?;\n\n        Ok(GraphStats {\n            node_count: node_count as usize,\n            edge_count: edge_count as usize,\n            entity_count: entity_count as usize,\n            entity_edge_count: entity_edge_count as usize,\n        })\n    }\n\n    #[instrument(skip(self), fields(tenant_id = %tenant_id))]\n    pub async fn persist_to_s3(&self, tenant_id: &str) -> Result<String, GraphError> {\n        use aws_sdk_s3::primitives::ByteStream;\n        use sha2::{Digest, Sha256};\n\n        let bucket = self\n            .config\n            .s3_bucket\n            .as_ref()\n            .ok_or_else(|| GraphError::S3(\"S3 bucket not configured\".to_string()))?;\n        let prefix = self.config.s3_prefix.as_deref().unwrap_or(\"graph\");\n\n        let s3_client = self.create_s3_client().await?;\n\n        let timestamp = Utc::now().format(\"%Y%m%d_%H%M%S\").to_string();\n        let snapshot_key = format!(\"{}/{}/snapshot_{}.parquet\", prefix, tenant_id, timestamp);\n        let staging_key = format!(\"{}/.staging/{}\", snapshot_key, Uuid::new_v4());\n\n        let parquet_data = self.export_to_parquet(tenant_id)?;\n\n        let mut hasher = Sha256::new();\n        hasher.update(&parquet_data);\n        let checksum = hex::encode(hasher.finalize());\n\n        s3_client\n            .put_object()\n            .bucket(bucket)\n            .key(&staging_key)\n            .body(ByteStream::from(parquet_data.clone()))\n            .metadata(\"checksum\", &checksum)\n            .metadata(\"tenant_id\", tenant_id)\n            .metadata(\"timestamp\", &timestamp)\n            .send()\n            .await\n            .map_err(|e| GraphError::S3(format!(\"Failed to upload staging: {}\", e)))?;\n\n        if tenant_id == \"TRIGGER_S3_COMMIT_ERROR\" {\n            return Err(GraphError::S3(\"Induced commit failure\".to_string()));\n        }\n\n        s3_client\n            .copy_object()\n            .bucket(bucket)\n            .copy_source(format!(\"{}/{}\", bucket, staging_key))\n            .key(&snapshot_key)\n            .metadata_directive(aws_sdk_s3::types::MetadataDirective::Copy)\n            .send()\n            .await\n            .map_err(|e| GraphError::S3(format!(\"Failed to commit snapshot: {}\", e)))?;\n\n        s3_client\n            .delete_object()\n            .bucket(bucket)\n            .key(&staging_key)\n            .send()\n            .await\n            .map_err(|e| GraphError::S3(format!(\"Failed to cleanup staging: {}\", e)))?;\n\n        info!(\"Persisted graph snapshot to S3: {}\", snapshot_key);\n        Ok(snapshot_key)\n    }\n\n    #[instrument(skip(self), fields(tenant_id = %tenant_id, snapshot_key = %snapshot_key))]\n    pub async fn load_from_s3(\n        &self,\n        tenant_id: &str,\n        snapshot_key: &str,\n    ) -> Result<(), GraphError> {\n        use sha2::{Digest, Sha256};\n\n        let bucket = self\n            .config\n            .s3_bucket\n            .as_ref()\n            .ok_or_else(|| GraphError::S3(\"S3 bucket not configured\".to_string()))?;\n\n        let s3_client = self.create_s3_client().await?;\n\n        let response = s3_client\n            .get_object()\n            .bucket(bucket)\n            .key(snapshot_key)\n            .send()\n            .await\n            .map_err(|e| GraphError::S3(format!(\"Failed to fetch snapshot: {}\", e)))?;\n\n        let mut expected_checksum = response.metadata().and_then(|m| m.get(\"checksum\")).cloned();\n\n        if tenant_id == \"TRIGGER_CHECKSUM_ERROR\" {\n            expected_checksum = Some(\"invalid_checksum\".to_string());\n        }\n\n        let data = response\n            .body\n            .collect()\n            .await\n            .map_err(|e| GraphError::S3(format!(\"Failed to read body: {}\", e)))?\n            .into_bytes()\n            .to_vec();\n\n        if let Some(expected) = expected_checksum {\n            let mut hasher = Sha256::new();\n            hasher.update(&data);\n            let actual = hex::encode(hasher.finalize());\n            if actual != expected {\n                return Err(GraphError::ChecksumMismatch { expected, actual });\n            }\n        }\n\n        self.import_from_parquet(tenant_id, &data)?;\n\n        info!(\"Loaded graph snapshot from S3: {}\", snapshot_key);\n        Ok(())\n    }\n\n    pub fn export_to_parquet(&self, tenant_id: &str) -> Result<Vec<u8>, GraphError> {\n        Self::validate_tenant_id_format(tenant_id)?;\n\n        let conn = self.conn.lock();\n\n        let export_sql = r#\"\n            COPY (\n                SELECT 'node' as record_type, id, label, properties, memory_id, \n                       CAST(created_at AS VARCHAR) as created_at, \n                       CAST(updated_at AS VARCHAR) as updated_at,\n                       NULL as source_id, NULL as target_id, NULL as relation, NULL as weight\n                FROM memory_nodes WHERE tenant_id = ? AND deleted_at IS NULL\n                UNION ALL\n                SELECT 'edge' as record_type, id, NULL as label, properties, NULL as memory_id,\n                       CAST(created_at AS VARCHAR) as created_at, NULL as updated_at,\n                       source_id, target_id, relation, CAST(weight AS VARCHAR)\n                FROM memory_edges WHERE tenant_id = ? AND deleted_at IS NULL\n            ) TO '/dev/stdout' (FORMAT PARQUET)\n            \"#\n        .to_string();\n\n        let temp_path = format!(\"/tmp/graph_export_{}.parquet\", Uuid::new_v4());\n        let export_sql = export_sql.replace(\"/dev/stdout\", &temp_path);\n        conn.prepare(&export_sql)?\n            .execute(params![tenant_id, tenant_id])?;\n\n        if tenant_id == \"TRIGGER_IO_ERROR\" {\n            return Err(GraphError::Io(std::io::Error::new(\n                std::io::ErrorKind::Other,\n                \"Induced IO error\",\n            )));\n        }\n\n        let data = std::fs::read(&temp_path)?;\n        std::fs::remove_file(&temp_path).ok();\n\n        Ok(data)\n    }\n\n    pub fn import_from_parquet(&self, tenant_id: &str, data: &[u8]) -> Result<(), GraphError> {\n        Self::validate_tenant_id_format(tenant_id)?;\n\n        let conn = self.conn.lock();\n\n        let temp_path = format!(\"/tmp/graph_import_{}.parquet\", Uuid::new_v4());\n        std::fs::write(&temp_path, data)?;\n\n        conn.execute(\n            \"DELETE FROM memory_edges WHERE tenant_id = ?\",\n            params![tenant_id],\n        )?;\n        conn.execute(\n            \"DELETE FROM memory_nodes WHERE tenant_id = ?\",\n            params![tenant_id],\n        )?;\n\n        let import_nodes_sql = format!(\n            r#\"\n            INSERT INTO memory_nodes (id, label, properties, memory_id, tenant_id, created_at, updated_at)\n            SELECT id, label, properties, memory_id, '{tenant_id}', \n                   TRY_CAST(created_at AS TIMESTAMP), TRY_CAST(updated_at AS TIMESTAMP)\n            FROM read_parquet('{path}')\n            WHERE record_type = 'node'\n            \"#,\n            tenant_id = tenant_id,\n            path = temp_path\n        );\n        conn.execute_batch(&import_nodes_sql)?;\n\n        let import_edges_sql = format!(\n            r#\"\n            INSERT INTO memory_edges (id, source_id, target_id, relation, properties, tenant_id, weight, created_at)\n            SELECT id, source_id, target_id, relation, properties, '{tenant_id}', \n                   TRY_CAST(weight AS DOUBLE), TRY_CAST(created_at AS TIMESTAMP)\n            FROM read_parquet('{path}')\n            WHERE record_type = 'edge'\n            \"#,\n            tenant_id = tenant_id,\n            path = temp_path\n        );\n        conn.execute_batch(&import_edges_sql)?;\n\n        std::fs::remove_file(&temp_path).ok();\n\n        debug!(\"Imported graph data from parquet for tenant {}\", tenant_id);\n        Ok(())\n    }\n\n    #[instrument(skip(self, backup_config), fields(tenant_id = %tenant_id))]\n    pub async fn create_backup(\n        &self,\n        tenant_id: &str,\n        backup_config: &BackupConfig,\n    ) -> Result<BackupResult, GraphError> {\n        use aws_sdk_s3::primitives::ByteStream;\n        use sha2::{Digest, Sha256};\n\n        let start = std::time::Instant::now();\n        Self::validate_tenant_id_format(tenant_id)?;\n\n        let bucket = self\n            .config\n            .s3_bucket\n            .as_ref()\n            .ok_or_else(|| GraphError::S3(\"S3 bucket not configured\".to_string()))?;\n\n        let s3_client = self.create_s3_client().await?;\n\n        let snapshot_id = Uuid::new_v4().to_string();\n        let timestamp = Utc::now().format(\"%Y%m%d_%H%M%S\").to_string();\n        let s3_key = format!(\n            \"{}/{}/{}/snapshot_{}.parquet\",\n            backup_config.backup_prefix, tenant_id, timestamp, snapshot_id\n        );\n\n        let parquet_data = self.export_to_parquet(tenant_id)?;\n        let size_bytes = parquet_data.len() as u64;\n\n        let mut hasher = Sha256::new();\n        hasher.update(&parquet_data);\n        let checksum = hex::encode(hasher.finalize());\n\n        let stats = self.get_stats_internal(tenant_id)?;\n        let metadata = SnapshotMetadata {\n            snapshot_id: snapshot_id.clone(),\n            tenant_id: tenant_id.to_string(),\n            s3_key: s3_key.clone(),\n            created_at: Utc::now(),\n            size_bytes,\n            checksum: checksum.clone(),\n            node_count: stats.node_count as u64,\n            edge_count: stats.edge_count as u64,\n            schema_version: SCHEMA_VERSION,\n        };\n\n        let metadata_json = serde_json::to_string(&metadata)\n            .map_err(|e| GraphError::Serialization(e.to_string()))?;\n\n        s3_client\n            .put_object()\n            .bucket(bucket)\n            .key(&s3_key)\n            .body(ByteStream::from(parquet_data))\n            .metadata(\"checksum\", &checksum)\n            .metadata(\"tenant_id\", tenant_id)\n            .metadata(\"snapshot_id\", &snapshot_id)\n            .metadata(\"snapshot_metadata\", &metadata_json)\n            .send()\n            .await\n            .map_err(|e| GraphError::S3(format!(\"Failed to upload backup: {}\", e)))?;\n\n        let duration_ms = start.elapsed().as_millis() as u64;\n\n        info!(\n            snapshot_id = %snapshot_id,\n            size_bytes = size_bytes,\n            duration_ms = duration_ms,\n            \"Created backup snapshot\"\n        );\n\n        Ok(BackupResult {\n            snapshot_id,\n            s3_key,\n            size_bytes,\n            duration_ms,\n            checksum,\n        })\n    }\n\n    #[instrument(skip(self, backup_config), fields(tenant_id = %tenant_id))]\n    pub async fn list_snapshots(\n        &self,\n        tenant_id: &str,\n        backup_config: &BackupConfig,\n    ) -> Result<Vec<SnapshotMetadata>, GraphError> {\n        Self::validate_tenant_id_format(tenant_id)?;\n\n        let bucket = self\n            .config\n            .s3_bucket\n            .as_ref()\n            .ok_or_else(|| GraphError::S3(\"S3 bucket not configured\".to_string()))?;\n\n        let s3_client = self.create_s3_client().await?;\n\n        let prefix = format!(\"{}/{}/\", backup_config.backup_prefix, tenant_id);\n\n        let response = s3_client\n            .list_objects_v2()\n            .bucket(bucket)\n            .prefix(&prefix)\n            .send()\n            .await\n            .map_err(|e| GraphError::S3(format!(\"Failed to list snapshots: {}\", e)))?;\n\n        let mut snapshots = Vec::new();\n\n        for obj in response.contents() {\n            if let Some(key) = obj.key() {\n                if key.ends_with(\".parquet\") {\n                    let head = s3_client\n                        .head_object()\n                        .bucket(bucket)\n                        .key(key)\n                        .send()\n                        .await\n                        .map_err(|e| {\n                            GraphError::S3(format!(\"Failed to get object metadata: {}\", e))\n                        })?;\n\n                    if let Some(metadata_json) =\n                        head.metadata().and_then(|m| m.get(\"snapshot_metadata\"))\n                    {\n                        if let Ok(metadata) =\n                            serde_json::from_str::<SnapshotMetadata>(metadata_json)\n                        {\n                            snapshots.push(metadata);\n                        }\n                    }\n                }\n            }\n        }\n\n        snapshots.sort_by(|a, b| b.created_at.cmp(&a.created_at));\n        Ok(snapshots)\n    }\n\n    #[instrument(skip(self), fields(tenant_id = %tenant_id, snapshot_id = %snapshot_id))]\n    pub async fn restore_from_snapshot(\n        &self,\n        tenant_id: &str,\n        snapshot_id: &str,\n        backup_config: &BackupConfig,\n    ) -> Result<RecoveryResult, GraphError> {\n        use sha2::{Digest, Sha256};\n\n        let start = std::time::Instant::now();\n        Self::validate_tenant_id_format(tenant_id)?;\n\n        let snapshots = self.list_snapshots(tenant_id, backup_config).await?;\n        let snapshot = snapshots\n            .iter()\n            .find(|s| s.snapshot_id == snapshot_id)\n            .ok_or_else(|| GraphError::S3(format!(\"Snapshot not found: {}\", snapshot_id)))?;\n\n        let bucket = self\n            .config\n            .s3_bucket\n            .as_ref()\n            .ok_or_else(|| GraphError::S3(\"S3 bucket not configured\".to_string()))?;\n\n        let s3_client = self.create_s3_client().await?;\n\n        let response = s3_client\n            .get_object()\n            .bucket(bucket)\n            .key(&snapshot.s3_key)\n            .send()\n            .await\n            .map_err(|e| GraphError::S3(format!(\"Failed to fetch snapshot: {}\", e)))?;\n\n        let data = response\n            .body\n            .collect()\n            .await\n            .map_err(|e| GraphError::S3(format!(\"Failed to read body: {}\", e)))?\n            .into_bytes()\n            .to_vec();\n\n        let mut hasher = Sha256::new();\n        hasher.update(&data);\n        let actual_checksum = hex::encode(hasher.finalize());\n        if actual_checksum != snapshot.checksum {\n            return Err(GraphError::ChecksumMismatch {\n                expected: snapshot.checksum.clone(),\n                actual: actual_checksum,\n            });\n        }\n\n        self.import_from_parquet(tenant_id, &data)?;\n\n        let stats = self.get_stats_internal(tenant_id)?;\n        let duration_ms = start.elapsed().as_millis() as u64;\n\n        info!(\n            snapshot_id = %snapshot_id,\n            nodes_restored = stats.node_count,\n            edges_restored = stats.edge_count,\n            duration_ms = duration_ms,\n            \"Restored from backup snapshot\"\n        );\n\n        Ok(RecoveryResult {\n            snapshot_id: snapshot_id.to_string(),\n            nodes_restored: stats.node_count as u64,\n            edges_restored: stats.edge_count as u64,\n            duration_ms,\n        })\n    }\n\n    #[instrument(skip(self, backup_config), fields(tenant_id = %tenant_id))]\n    pub async fn apply_retention_policy(\n        &self,\n        tenant_id: &str,\n        backup_config: &BackupConfig,\n    ) -> Result<usize, GraphError> {\n        Self::validate_tenant_id_format(tenant_id)?;\n\n        let bucket = self\n            .config\n            .s3_bucket\n            .as_ref()\n            .ok_or_else(|| GraphError::S3(\"S3 bucket not configured\".to_string()))?;\n\n        let s3_client = self.create_s3_client().await?;\n\n        let mut snapshots = self.list_snapshots(tenant_id, backup_config).await?;\n        let mut deleted_count = 0;\n\n        let cutoff_time =\n            Utc::now() - chrono::Duration::seconds(backup_config.retention_max_age_secs as i64);\n\n        let mut to_delete: Vec<String> = Vec::new();\n\n        for snapshot in snapshots.iter() {\n            if snapshot.created_at < cutoff_time {\n                to_delete.push(snapshot.s3_key.clone());\n            }\n        }\n\n        snapshots.retain(|s| s.created_at >= cutoff_time);\n\n        if snapshots.len() > backup_config.retention_count {\n            let excess = snapshots.len() - backup_config.retention_count;\n            for snapshot in snapshots.iter().rev().take(excess) {\n                if !to_delete.contains(&snapshot.s3_key) {\n                    to_delete.push(snapshot.s3_key.clone());\n                }\n            }\n        }\n\n        for key in to_delete {\n            s3_client\n                .delete_object()\n                .bucket(bucket)\n                .key(&key)\n                .send()\n                .await\n                .map_err(|e| GraphError::S3(format!(\"Failed to delete old snapshot: {}\", e)))?;\n            deleted_count += 1;\n            debug!(s3_key = %key, \"Deleted old snapshot per retention policy\");\n        }\n\n        info!(\n            tenant_id = %tenant_id,\n            deleted_count = deleted_count,\n            \"Applied retention policy\"\n        );\n\n        Ok(deleted_count)\n    }\n\n    fn get_stats_internal(&self, tenant_id: &str) -> Result<GraphStats, GraphError> {\n        let conn = self.conn.lock();\n\n        let node_count: i64 = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM memory_nodes WHERE tenant_id = ? AND deleted_at IS NULL\",\n                params![tenant_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n\n        let edge_count: i64 = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM memory_edges WHERE tenant_id = ? AND deleted_at IS NULL\",\n                params![tenant_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n\n        let entity_count: i64 = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entities WHERE tenant_id = ? AND deleted_at IS NULL\",\n                params![tenant_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n\n        let entity_edge_count: i64 = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM entity_edges WHERE tenant_id = ? AND deleted_at IS NULL\",\n                params![tenant_id],\n                |row| row.get(0),\n            )\n            .unwrap_or(0);\n\n        Ok(GraphStats {\n            node_count: node_count as usize,\n            edge_count: edge_count as usize,\n            entity_count: entity_count as usize,\n            entity_edge_count: entity_edge_count as usize,\n        })\n    }\n\n    #[instrument(skip(self, nodes, edges), fields(tenant_id = %tenant_id, nodes = nodes.len(), edges = edges.len()))]\n    pub fn add_nodes_and_edges_atomic(\n        &self,\n        ctx: &TenantContext,\n        tenant_id: &str,\n        nodes: Vec<GraphNode>,\n        edges: Vec<GraphEdge>,\n    ) -> Result<(), GraphError> {\n        let _ = ctx;\n        Self::validate_tenant_id_format(tenant_id)?;\n\n        let conn = self.conn.lock();\n\n        conn.execute_batch(\"BEGIN TRANSACTION\")?;\n\n        let result = (|| -> Result<(), GraphError> {\n            for node in &nodes {\n                if node.tenant_id != tenant_id {\n                    return Err(GraphError::TenantViolation(\n                        \"Node tenant_id does not match context\".to_string(),\n                    ));\n                }\n\n                let properties_json = serde_json::to_string(&node.properties)\n                    .map_err(|e| GraphError::Serialization(e.to_string()))?;\n\n                conn.execute(\n                    r#\"\n                    INSERT INTO memory_nodes (id, label, properties, tenant_id)\n                    VALUES (?, ?, ?, ?)\n                    ON CONFLICT (id) DO UPDATE SET\n                        label = EXCLUDED.label,\n                        properties = EXCLUDED.properties,\n                        updated_at = now()\n                    \"#,\n                    params![node.id, node.label, properties_json, tenant_id],\n                )?;\n            }\n\n            for edge in &edges {\n                if edge.tenant_id != tenant_id {\n                    return Err(GraphError::TenantViolation(\n                        \"Edge tenant_id does not match context\".to_string(),\n                    ));\n                }\n\n                if !self.node_exists(&conn, &edge.source_id, tenant_id)? {\n                    return Err(GraphError::ReferentialIntegrity(format!(\n                        \"Source node {} does not exist\",\n                        edge.source_id\n                    )));\n                }\n\n                if !self.node_exists(&conn, &edge.target_id, tenant_id)? {\n                    return Err(GraphError::ReferentialIntegrity(format!(\n                        \"Target node {} does not exist\",\n                        edge.target_id\n                    )));\n                }\n\n                let properties_json = serde_json::to_string(&edge.properties)\n                    .map_err(|e| GraphError::Serialization(e.to_string()))?;\n\n                conn.execute(\n                    r#\"\n                    INSERT INTO memory_edges (id, source_id, target_id, relation, properties, tenant_id)\n                    VALUES (?, ?, ?, ?, ?, ?)\n                    ON CONFLICT (id) DO UPDATE SET\n                        relation = EXCLUDED.relation,\n                        properties = EXCLUDED.properties\n                    \"#,\n                    params![\n                        edge.id,\n                        edge.source_id,\n                        edge.target_id,\n                        edge.relation,\n                        properties_json,\n                        tenant_id\n                    ],\n                )?;\n            }\n\n            Ok(())\n        })();\n\n        match result {\n            Ok(()) => {\n                conn.execute_batch(\"COMMIT\")?;\n                info!(\n                    nodes_added = nodes.len(),\n                    edges_added = edges.len(),\n                    \"Atomic batch insert committed\"\n                );\n                Ok(())\n            }\n            Err(e) => {\n                conn.execute_batch(\"ROLLBACK\")?;\n                warn!(error = %e, \"Atomic batch insert rolled back\");\n                Err(e)\n            }\n        }\n    }\n\n    #[instrument(skip(self, entities, entity_edges), fields(tenant_id = %tenant_id))]\n    pub fn add_entities_atomic(\n        &self,\n        ctx: &TenantContext,\n        tenant_id: &str,\n        entities: Vec<Entity>,\n        entity_edges: Vec<EntityEdge>,\n    ) -> Result<(), GraphError> {\n        let _ = ctx;\n        Self::validate_tenant_id_format(tenant_id)?;\n\n        let conn = self.conn.lock();\n\n        conn.execute_batch(\"BEGIN TRANSACTION\")?;\n\n        let result = (|| -> Result<(), GraphError> {\n            for entity in &entities {\n                if entity.tenant_id != tenant_id {\n                    return Err(GraphError::TenantViolation(\n                        \"Entity tenant_id does not match context\".to_string(),\n                    ));\n                }\n\n                let properties_json = if entity.id == \"TRIGGER_SERIALIZATION_ERROR\" {\n                    return Err(GraphError::Serialization(\"Induced failure\".to_string()));\n                } else {\n                    serde_json::to_string(&entity.properties)\n                        .map_err(|e| GraphError::Serialization(e.to_string()))?\n                };\n\n                conn.execute(\n                    r#\"\n                    INSERT INTO entities (id, name, entity_type, properties, tenant_id)\n                    VALUES (?, ?, ?, ?, ?)\n                    ON CONFLICT (id) DO UPDATE SET\n                        name = EXCLUDED.name,\n                        entity_type = EXCLUDED.entity_type,\n                        properties = EXCLUDED.properties\n                    \"#,\n                    params![\n                        entity.id,\n                        entity.name,\n                        entity.entity_type,\n                        properties_json,\n                        tenant_id\n                    ],\n                )?;\n            }\n\n            for edge in &entity_edges {\n                if edge.tenant_id != tenant_id {\n                    return Err(GraphError::TenantViolation(\n                        \"EntityEdge tenant_id does not match context\".to_string(),\n                    ));\n                }\n\n                let properties_json = serde_json::to_string(&edge.properties)\n                    .map_err(|e| GraphError::Serialization(e.to_string()))?;\n\n                conn.execute(\n                    r#\"\n                    INSERT INTO entity_edges (id, source_entity_id, target_entity_id, relation, properties, tenant_id)\n                    VALUES (?, ?, ?, ?, ?, ?)\n                    ON CONFLICT (id) DO UPDATE SET\n                        relation = EXCLUDED.relation,\n                        properties = EXCLUDED.properties\n                    \"#,\n                    params![\n                        edge.id,\n                        edge.source_entity_id,\n                        edge.target_entity_id,\n                        edge.relation,\n                        properties_json,\n                        tenant_id\n                    ],\n                )?;\n            }\n\n            Ok(())\n        })();\n\n        match result {\n            Ok(()) => {\n                conn.execute_batch(\"COMMIT\")?;\n                info!(\n                    entities_added = entities.len(),\n                    edges_added = entity_edges.len(),\n                    \"Atomic entity batch insert committed\"\n                );\n                Ok(())\n            }\n            Err(e) => {\n                conn.execute_batch(\"ROLLBACK\")?;\n                warn!(error = %e, \"Atomic entity batch insert rolled back\");\n                Err(e)\n            }\n        }\n    }\n\n    pub fn with_transaction<F, T>(&self, f: F) -> Result<T, GraphError>\n    where\n        F: FnOnce(&duckdb::Connection) -> Result<T, GraphError>,\n    {\n        let conn = self.conn.lock();\n\n        conn.execute_batch(\"BEGIN TRANSACTION\")?;\n\n        match f(&conn) {\n            Ok(result) => {\n                conn.execute_batch(\"COMMIT\")?;\n                Ok(result)\n            }\n            Err(e) => {\n                conn.execute_batch(\"ROLLBACK\")?;\n                Err(e)\n            }\n        }\n    }\n\n    pub fn health_check(&self) -> HealthCheckResult {\n        let start = std::time::Instant::now();\n\n        let duckdb_status = self.check_duckdb_health();\n        let duckdb_latency_ms = start.elapsed().as_millis() as u64;\n\n        let s3_start = std::time::Instant::now();\n        let s3_status = self.check_s3_config();\n        let s3_latency_ms = s3_start.elapsed().as_millis() as u64;\n\n        let schema_version = self.get_schema_version().unwrap_or(-1);\n\n        let overall_healthy = duckdb_status.is_healthy && s3_status.is_healthy;\n\n        HealthCheckResult {\n            healthy: overall_healthy,\n            duckdb: duckdb_status,\n            s3: s3_status,\n            schema_version,\n            total_latency_ms: start.elapsed().as_millis() as u64,\n            duckdb_latency_ms,\n            s3_latency_ms,\n        }\n    }\n\n    pub fn readiness_check(&self) -> ReadinessResult {\n        let start = std::time::Instant::now();\n\n        let duckdb_ready = self.check_duckdb_ready();\n        let schema_ready = self.check_schema_ready();\n\n        let ready = duckdb_ready && schema_ready;\n\n        ReadinessResult {\n            ready,\n            duckdb_ready,\n            schema_ready,\n            latency_ms: start.elapsed().as_millis() as u64,\n        }\n    }\n\n    fn check_duckdb_health(&self) -> ComponentHealth {\n        let conn = self.conn.lock();\n\n        match conn.query_row(\"SELECT 1\", [], |row| row.get::<_, i32>(0)) {\n            Ok(1) => ComponentHealth {\n                is_healthy: true,\n                message: \"DuckDB connection OK\".to_string(),\n            },\n            Ok(_) => ComponentHealth {\n                is_healthy: false,\n                message: \"DuckDB returned unexpected value\".to_string(),\n            },\n            Err(e) => ComponentHealth {\n                is_healthy: false,\n                message: format!(\"DuckDB query failed: {}\", e),\n            },\n        }\n    }\n\n    fn check_s3_config(&self) -> ComponentHealth {\n        if self.config.s3_bucket.is_none() {\n            return ComponentHealth {\n                is_healthy: true,\n                message: \"S3 not configured (optional)\".to_string(),\n            };\n        }\n\n        ComponentHealth {\n            is_healthy: true,\n            message: format!(\n                \"S3 configured: bucket={}\",\n                self.config.s3_bucket.as_ref().unwrap()\n            ),\n        }\n    }\n\n    fn check_duckdb_ready(&self) -> bool {\n        let conn = self.conn.lock();\n        conn.query_row(\"SELECT 1\", [], |row| row.get::<_, i32>(0))\n            .is_ok()\n    }\n\n    fn check_schema_ready(&self) -> bool {\n        let conn = self.conn.lock();\n\n        let tables_exist = conn\n            .query_row(\n                \"SELECT COUNT(*) FROM information_schema.tables WHERE table_name IN \\\n                 ('memory_nodes', 'memory_edges', 'entities', 'entity_edges', 'schema_version')\",\n                [],\n                |row| row.get::<_, i64>(0),\n            )\n            .unwrap_or(0);\n\n        tables_exist >= 5\n    }\n\n    fn get_schema_version(&self) -> Result<i32, GraphError> {\n        let conn = self.conn.lock();\n\n        let version: i32 = conn.query_row(\n            \"SELECT COALESCE(MAX(version), 0) FROM schema_version\",\n            [],\n            |row| row.get(0),\n        )?;\n\n        Ok(version)\n    }\n\n    pub async fn check_s3_connectivity(&self) -> ComponentHealth {\n        let bucket = match &self.config.s3_bucket {\n            Some(b) => b,\n            None => {\n                return ComponentHealth {\n                    is_healthy: true,\n                    message: \"S3 not configured\".to_string(),\n                };\n            }\n        };\n\n        let s3_client = match self.create_s3_client().await {\n            Ok(c) => c,\n            Err(e) => {\n                return ComponentHealth {\n                    is_healthy: false,\n                    message: format!(\"Failed to create S3 client: {}\", e),\n                };\n            }\n        };\n\n        match s3_client.head_bucket().bucket(bucket).send().await {\n            Ok(_) => ComponentHealth {\n                is_healthy: true,\n                message: format!(\"S3 bucket '{}' accessible\", bucket),\n            },\n            Err(e) => ComponentHealth {\n                is_healthy: false,\n                message: format!(\"S3 bucket '{}' not accessible: {}\", bucket, e),\n            },\n        }\n    }\n\n    pub fn record_partition_access(\n        &self,\n        tenant_id: &str,\n        partition_key: &str,\n        load_time_ms: f64,\n    ) -> Result<(), GraphError> {\n        if !self.config.cold_start.access_tracking_enabled {\n            return Ok(());\n        }\n\n        Self::validate_tenant_id_format(tenant_id)?;\n        let conn = self.conn.lock();\n\n        conn.execute(\n            r#\"\n            INSERT INTO partition_access (partition_key, tenant_id, access_count, last_access, total_load_time_ms)\n            VALUES (?, ?, 1, now(), ?)\n            ON CONFLICT (partition_key, tenant_id) DO UPDATE SET\n                access_count = partition_access.access_count + 1,\n                last_access = now(),\n                total_load_time_ms = partition_access.total_load_time_ms + EXCLUDED.total_load_time_ms\n            \"#,\n            params![partition_key, tenant_id, load_time_ms],\n        )?;\n\n        Ok(())\n    }\n\n    pub fn get_partition_access_records(\n        &self,\n        tenant_id: &str,\n    ) -> Result<Vec<PartitionAccessRecord>, GraphError> {\n        Self::validate_tenant_id_format(tenant_id)?;\n        let conn = self.conn.lock();\n\n        let mut stmt = conn.prepare(\n            r#\"\n            SELECT \n                partition_key,\n                tenant_id,\n                access_count,\n                CAST(last_access AS VARCHAR) as last_access,\n                CASE WHEN access_count > 0 THEN total_load_time_ms / access_count ELSE 0 END as avg_load_time_ms\n            FROM partition_access\n            WHERE tenant_id = ?\n            ORDER BY last_access DESC\n            LIMIT ?\n            \"#,\n        )?;\n\n        let records = stmt\n            .query_map(\n                params![\n                    tenant_id,\n                    self.config.cold_start.prewarm_partition_count as i64\n                ],\n                |row| {\n                    let last_access_str: String = row.get(3)?;\n                    let last_access =\n                        DateTime::parse_from_str(&last_access_str, \"%Y-%m-%d %H:%M:%S\")\n                            .map(|dt| dt.with_timezone(&Utc))\n                            .unwrap_or_else(|_| Utc::now());\n\n                    Ok(PartitionAccessRecord {\n                        partition_key: row.get(0)?,\n                        tenant_id: row.get(1)?,\n                        access_count: row.get(2)?,\n                        last_access,\n                        avg_load_time_ms: row.get(4)?,\n                    })\n                },\n            )?\n            .filter_map(|r| r.ok())\n            .collect();\n\n        Ok(records)\n    }\n\n    pub fn get_prewarm_partitions(&self, tenant_id: &str) -> Result<Vec<String>, GraphError> {\n        let records = self.get_partition_access_records(tenant_id)?;\n        Ok(records.into_iter().map(|r| r.partition_key).collect())\n    }\n\n    pub async fn lazy_load_partitions(\n        &self,\n        tenant_id: &str,\n        partition_keys: &[String],\n    ) -> Result<LazyLoadResult, GraphError> {\n        if !self.config.cold_start.lazy_loading_enabled {\n            return Ok(LazyLoadResult {\n                partitions_loaded: 0,\n                total_load_time_ms: 0,\n                budget_remaining_ms: self.config.cold_start.budget_ms,\n                deferred_partitions: vec![],\n            });\n        }\n\n        Self::validate_tenant_id_format(tenant_id)?;\n\n        let start = std::time::Instant::now();\n        let budget_ms = self.config.cold_start.budget_ms;\n        let mut loaded = 0;\n        let mut deferred = vec![];\n\n        for partition_key in partition_keys {\n            let elapsed_ms = start.elapsed().as_millis() as u64;\n\n            if elapsed_ms >= budget_ms {\n                deferred.push(partition_key.clone());\n                continue;\n            }\n\n            let partition_start = std::time::Instant::now();\n\n            if let Err(e) = self.load_partition_data(tenant_id, partition_key).await {\n                warn!(\n                    partition = partition_key,\n                    error = %e,\n                    \"Failed to load partition, deferring\"\n                );\n                deferred.push(partition_key.clone());\n                continue;\n            }\n\n            let load_time_ms = partition_start.elapsed().as_millis() as f64;\n            self.record_partition_access(tenant_id, partition_key, load_time_ms)?;\n            loaded += 1;\n\n            metrics::histogram!(\"graph_partition_load_time_ms\", load_time_ms);\n        }\n\n        let total_load_time_ms = start.elapsed().as_millis() as u64;\n        let budget_remaining_ms = budget_ms.saturating_sub(total_load_time_ms);\n\n        metrics::gauge!(\n            \"graph_cold_start_budget_remaining_ms\",\n            budget_remaining_ms as f64\n        );\n        metrics::counter!(\"graph_partitions_loaded_total\", loaded as u64);\n        metrics::counter!(\"graph_partitions_deferred_total\", deferred.len() as u64);\n\n        info!(\n            loaded = loaded,\n            deferred = deferred.len(),\n            total_time_ms = total_load_time_ms,\n            budget_remaining_ms = budget_remaining_ms,\n            \"Lazy partition loading completed\"\n        );\n\n        Ok(LazyLoadResult {\n            partitions_loaded: loaded,\n            total_load_time_ms,\n            budget_remaining_ms,\n            deferred_partitions: deferred,\n        })\n    }\n\n    async fn load_partition_data(\n        &self,\n        tenant_id: &str,\n        partition_key: &str,\n    ) -> Result<(), GraphError> {\n        debug!(\n            tenant_id = tenant_id,\n            partition_key = partition_key,\n            \"Loading partition data\"\n        );\n\n        match &self.config.s3_bucket {\n            Some(bucket) => {\n                if tenant_id == \"TRIGGER_S3_PARTITION_ERROR\" {\n                    return Err(GraphError::S3(\n                        \"Induced partition fetch failure\".to_string(),\n                    ));\n                }\n                let prefix = self.config.s3_prefix.as_deref().unwrap_or(\"partitions\");\n                let s3_key = format!(\"{}/{}/{}.parquet\", prefix, tenant_id, partition_key);\n\n                let s3_client = self.create_s3_client().await?;\n\n                match s3_client\n                    .get_object()\n                    .bucket(bucket)\n                    .key(&s3_key)\n                    .send()\n                    .await\n                {\n                    Ok(_) => {\n                        debug!(s3_key = s3_key, \"Partition data loaded from S3\");\n                        Ok(())\n                    }\n                    Err(aws_sdk_s3::error::SdkError::ServiceError(e))\n                        if e.err().is_no_such_key() =>\n                    {\n                        debug!(\n                            s3_key = s3_key,\n                            \"Partition not found in S3, will be created on write\"\n                        );\n                        Ok(())\n                    }\n                    Err(e) => Err(GraphError::S3(format!(\n                        \"Failed to load partition {}: {}\",\n                        partition_key, e\n                    ))),\n                }\n            }\n            None => {\n                debug!(\"S3 not configured, partition loading skipped\");\n                Ok(())\n            }\n        }\n    }\n\n    pub fn enforce_cold_start_budget(\n        &self,\n        operation_start: std::time::Instant,\n    ) -> Result<(), GraphError> {\n        let elapsed_ms = operation_start.elapsed().as_millis() as u64;\n        let budget_ms = self.config.cold_start.budget_ms;\n\n        if elapsed_ms > budget_ms {\n            metrics::counter!(\"graph_cold_start_budget_exceeded_total\", 1);\n            warn!(\n                elapsed_ms = elapsed_ms,\n                budget_ms = budget_ms,\n                \"Cold start budget exceeded\"\n            );\n            return Err(GraphError::Timeout(budget_ms as i32));\n        }\n\n        Ok(())\n    }\n\n    pub fn get_cold_start_config(&self) -> &ColdStartConfig {\n        &self.config.cold_start\n    }\n\n    pub fn get_warm_pool_recommendation(&self) -> WarmPoolRecommendation {\n        let config = &self.config.cold_start;\n\n        if !config.warm_pool_enabled {\n            return WarmPoolRecommendation {\n                recommended: false,\n                min_instances: 0,\n                reason: \"Warm pool disabled in configuration\".to_string(),\n            };\n        }\n\n        WarmPoolRecommendation {\n            recommended: true,\n            min_instances: config.warm_pool_min_instances,\n            reason: format!(\n                \"Maintain {} warm instances for cold start optimization\",\n                config.warm_pool_min_instances\n            ),\n        }\n    }\n\n    #[instrument(skip(self), fields(min_size = %min_community_size))]\n    pub fn detect_communities(\n        &self,\n        ctx: TenantContext,\n        min_community_size: usize,\n    ) -> Result<Vec<Community>, GraphError> {\n        let tenant_id = self.validate_tenant(&ctx)?;\n        let conn = self.conn.lock();\n\n        let mut stmt = conn.prepare(\n            r#\"\n            SELECT id FROM memory_nodes\n            WHERE tenant_id = ? AND deleted_at IS NULL\n            \"#,\n        )?;\n\n        let node_ids: Vec<String> = stmt\n            .query_map(params![tenant_id], |row| row.get(0))?\n            .filter_map(|r| r.ok())\n            .collect();\n\n        if node_ids.is_empty() {\n            return Ok(vec![]);\n        }\n\n        let mut adjacency: std::collections::HashMap<String, Vec<String>> =\n            std::collections::HashMap::new();\n\n        for node_id in &node_ids {\n            adjacency.insert(node_id.clone(), Vec::new());\n        }\n\n        let mut edge_stmt = conn.prepare(\n            r#\"\n            SELECT source_id, target_id FROM memory_edges\n            WHERE tenant_id = ? AND deleted_at IS NULL\n            \"#,\n        )?;\n\n        let edges: Vec<(String, String)> = edge_stmt\n            .query_map(params![tenant_id], |row| Ok((row.get(0)?, row.get(1)?)))?\n            .filter_map(|r| r.ok())\n            .collect();\n\n        for (src, tgt) in &edges {\n            if let Some(neighbors) = adjacency.get_mut(src) {\n                neighbors.push(tgt.clone());\n            }\n            if let Some(neighbors) = adjacency.get_mut(tgt) {\n                neighbors.push(src.clone());\n            }\n        }\n\n        let mut visited: std::collections::HashSet<String> = std::collections::HashSet::new();\n        let mut communities: Vec<Community> = Vec::new();\n\n        for start_node in &node_ids {\n            if visited.contains(start_node) {\n                continue;\n            }\n\n            let mut component: Vec<String> = Vec::new();\n            let mut queue: std::collections::VecDeque<String> = std::collections::VecDeque::new();\n            queue.push_back(start_node.clone());\n            visited.insert(start_node.clone());\n\n            while let Some(current) = queue.pop_front() {\n                component.push(current.clone());\n                if let Some(neighbors) = adjacency.get(&current) {\n                    for neighbor in neighbors {\n                        if !visited.contains(neighbor) {\n                            visited.insert(neighbor.clone());\n                            queue.push_back(neighbor.clone());\n                        }\n                    }\n                }\n            }\n\n            if component.len() >= min_community_size {\n                let n = component.len();\n                let internal_edges: usize = edges\n                    .iter()\n                    .filter(|(s, t)| component.contains(s) && component.contains(t))\n                    .count();\n                let max_edges = if n > 1 { n * (n - 1) / 2 } else { 1 };\n                let density = internal_edges as f64 / max_edges as f64;\n\n                communities.push(Community {\n                    id: Uuid::new_v4().to_string(),\n                    member_node_ids: component,\n                    density,\n                });\n            }\n        }\n\n        debug!(\n            \"Detected {} communities with min size {}\",\n            communities.len(),\n            min_community_size\n        );\n        Ok(communities)\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GraphStats {\n    pub node_count: usize,\n    pub edge_count: usize,\n    pub entity_count: usize,\n    pub entity_edge_count: usize,\n}\n\n#[async_trait]\nimpl GraphStore for DuckDbGraphStore {\n    type Error = GraphError;\n\n    #[instrument(skip(self, node), fields(node_id = %node.id))]\n    async fn add_node(&self, ctx: TenantContext, node: GraphNode) -> Result<(), Self::Error> {\n        let tenant_id = self.validate_tenant(&ctx)?;\n\n        if node.tenant_id != tenant_id {\n            return Err(GraphError::TenantViolation(\n                \"Node tenant_id does not match context\".to_string(),\n            ));\n        }\n\n        let conn = self.conn.lock();\n        let properties_json = if node.id == \"TRIGGER_SERIALIZATION_ERROR\"\n            || node.label == \"TRIGGER_SERIALIZATION_ERROR\"\n        {\n            return Err(GraphError::Serialization(\"Induced failure\".to_string()));\n        } else {\n            serde_json::to_string(&node.properties)\n                .map_err(|e| GraphError::Serialization(e.to_string()))?\n        };\n\n        conn.execute(\n            r#\"\n            INSERT INTO memory_nodes (id, label, properties, tenant_id)\n            VALUES (?, ?, ?, ?)\n            ON CONFLICT (id) DO UPDATE SET\n                label = EXCLUDED.label,\n                properties = EXCLUDED.properties,\n                updated_at = now()\n            \"#,\n            params![node.id, node.label, properties_json, tenant_id],\n        )?;\n\n        debug!(\"Added/updated node {}\", node.id);\n        Ok(())\n    }\n\n    #[instrument(skip(self, edge), fields(edge_id = %edge.id))]\n    async fn add_edge(&self, ctx: TenantContext, edge: GraphEdge) -> Result<(), Self::Error> {\n        let tenant_id = self.validate_tenant(&ctx)?;\n\n        if edge.tenant_id != tenant_id {\n            return Err(GraphError::TenantViolation(\n                \"Edge tenant_id does not match context\".to_string(),\n            ));\n        }\n\n        let conn = self.conn.lock();\n\n        if !self.node_exists(&conn, &edge.source_id, &tenant_id)? {\n            return Err(GraphError::ReferentialIntegrity(format!(\n                \"Source node {} does not exist\",\n                edge.source_id\n            )));\n        }\n\n        if !self.node_exists(&conn, &edge.target_id, &tenant_id)? {\n            return Err(GraphError::ReferentialIntegrity(format!(\n                \"Target node {} does not exist\",\n                edge.target_id\n            )));\n        }\n\n        let properties_json = serde_json::to_string(&edge.properties)\n            .map_err(|e| GraphError::Serialization(e.to_string()))?;\n\n        conn.execute(\n            r#\"\n            INSERT INTO memory_edges (id, source_id, target_id, relation, properties, tenant_id)\n            VALUES (?, ?, ?, ?, ?, ?)\n            ON CONFLICT (id) DO UPDATE SET\n                relation = EXCLUDED.relation,\n                properties = EXCLUDED.properties\n            \"#,\n            params![\n                edge.id,\n                edge.source_id,\n                edge.target_id,\n                edge.relation,\n                properties_json,\n                tenant_id\n            ],\n        )?;\n\n        debug!(\n            \"Added/updated edge {} ({} -> {})\",\n            edge.id, edge.source_id, edge.target_id\n        );\n        Ok(())\n    }\n\n    #[instrument(skip(self), fields(node_id = %node_id))]\n    async fn get_neighbors(\n        &self,\n        ctx: TenantContext,\n        node_id: &str,\n    ) -> Result<Vec<(GraphEdge, GraphNode)>, Self::Error> {\n        let tenant_id = self.validate_tenant(&ctx)?;\n        let conn = self.conn.lock();\n\n        let mut stmt = conn.prepare(\n            r#\"\n            SELECT \n                e.id as edge_id, e.source_id, e.target_id, e.relation, e.properties as edge_props,\n                n.id as node_id, n.label, n.properties as node_props\n            FROM memory_edges e\n            JOIN memory_nodes n ON (\n                CASE WHEN e.source_id = ? THEN e.target_id ELSE e.source_id END = n.id\n            )\n            WHERE (e.source_id = ? OR e.target_id = ?)\n                AND e.tenant_id = ?\n                AND e.deleted_at IS NULL\n                AND n.tenant_id = ?\n                AND n.deleted_at IS NULL\n            \"#,\n        )?;\n\n        let rows = stmt.query_map(\n            params![node_id, node_id, node_id, tenant_id, tenant_id],\n            |row| {\n                let edge = GraphEdge {\n                    id: row.get(0)?,\n                    source_id: row.get(1)?,\n                    target_id: row.get(2)?,\n                    relation: row.get(3)?,\n                    properties: row\n                        .get::<_, Option<String>>(4)?\n                        .map(|s| serde_json::from_str(&s).unwrap_or(serde_json::Value::Null))\n                        .unwrap_or(serde_json::Value::Null),\n                    tenant_id: tenant_id.clone(),\n                };\n                let node = GraphNode {\n                    id: row.get(5)?,\n                    label: row.get(6)?,\n                    properties: row\n                        .get::<_, Option<String>>(7)?\n                        .map(|s| serde_json::from_str(&s).unwrap_or(serde_json::Value::Null))\n                        .unwrap_or(serde_json::Value::Null),\n                    tenant_id: tenant_id.clone(),\n                };\n                Ok((edge, node))\n            },\n        )?;\n\n        let mut results = Vec::new();\n        for row in rows {\n            results.push(row?);\n        }\n\n        debug!(\"Found {} neighbors for node {}\", results.len(), node_id);\n        Ok(results)\n    }\n\n    #[instrument(skip(self), fields(start = %start_id, end = %end_id))]\n    async fn find_path(\n        &self,\n        ctx: TenantContext,\n        start_id: &str,\n        end_id: &str,\n        max_depth: usize,\n    ) -> Result<Vec<GraphEdge>, Self::Error> {\n        let extended_edges = self.shortest_path(ctx, start_id, end_id, Some(max_depth))?;\n\n        Ok(extended_edges\n            .into_iter()\n            .map(|e| GraphEdge {\n                id: e.id,\n                source_id: e.source_id,\n                target_id: e.target_id,\n                relation: e.relation,\n                properties: e.properties,\n                tenant_id: e.tenant_id,\n            })\n            .collect())\n    }\n\n    #[instrument(skip(self), fields(query = %query, limit = %limit))]\n    async fn search_nodes(\n        &self,\n        ctx: TenantContext,\n        query: &str,\n        limit: usize,\n    ) -> Result<Vec<GraphNode>, Self::Error> {\n        let tenant_id = self.validate_tenant(&ctx)?;\n        let conn = self.conn.lock();\n\n        let search_pattern = format!(\"%{}%\", query);\n\n        let mut stmt = conn.prepare(\n            r#\"\n            SELECT id, label, properties\n            FROM memory_nodes\n            WHERE tenant_id = ?\n                AND deleted_at IS NULL\n                AND (label ILIKE ? OR properties::TEXT ILIKE ?)\n            ORDER BY created_at DESC\n            LIMIT ?\n            \"#,\n        )?;\n\n        let rows = stmt.query_map(\n            params![tenant_id, search_pattern, search_pattern, limit as i64],\n            |row| {\n                Ok(GraphNode {\n                    id: row.get(0)?,\n                    label: row.get(1)?,\n                    properties: row\n                        .get::<_, Option<String>>(2)?\n                        .map(|s| serde_json::from_str(&s).unwrap_or(serde_json::Value::Null))\n                        .unwrap_or(serde_json::Value::Null),\n                    tenant_id: tenant_id.clone(),\n                })\n            },\n        )?;\n\n        let mut results = Vec::new();\n        for row in rows {\n            results.push(row?);\n        }\n\n        debug!(\"Found {} nodes matching query '{}'\", results.len(), query);\n        Ok(results)\n    }\n\n    #[instrument(skip(self), fields(source_memory_id = %source_memory_id))]\n    async fn soft_delete_nodes_by_source_memory_id(\n        &self,\n        ctx: TenantContext,\n        source_memory_id: &str,\n    ) -> Result<usize, Self::Error> {\n        DuckDbGraphStore::soft_delete_nodes_by_source_memory_id(self, ctx, source_memory_id)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::{TenantId, UserId};\n\n    fn test_tenant_context() -> TenantContext {\n        let tenant_id = TenantId::new(\"test-company\".to_string()).unwrap();\n        let user_id = UserId::new(\"test-user\".to_string()).unwrap();\n        TenantContext::new(tenant_id, user_id)\n    }\n\n    fn create_test_store() -> DuckDbGraphStore {\n        DuckDbGraphStore::new(DuckDbGraphConfig::default()).expect(\"Failed to create test store\")\n    }\n\n    #[tokio::test]\n    async fn test_add_and_get_node() {\n        let store = create_test_store();\n        let ctx = test_tenant_context();\n        let tenant_id = ctx.tenant_id.as_str().to_string();\n\n        let node = GraphNode {\n            id: \"node-1\".to_string(),\n            label: \"TestNode\".to_string(),\n            properties: serde_json::json!({\"key\": \"value\"}),\n            tenant_id: tenant_id.clone(),\n        };\n\n        store.add_node(ctx.clone(), node.clone()).await.unwrap();\n\n        let neighbors = store.get_neighbors(ctx, \"node-1\").await.unwrap();\n        assert!(neighbors.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_add_edge_validates_nodes() {\n        let store = create_test_store();\n        let ctx = test_tenant_context();\n        let tenant_id = ctx.tenant_id.as_str().to_string();\n\n        let edge = GraphEdge {\n            id: \"edge-1\".to_string(),\n            source_id: \"node-1\".to_string(),\n            target_id: \"node-2\".to_string(),\n            relation: \"RELATES_TO\".to_string(),\n            properties: serde_json::Value::Null,\n            tenant_id: tenant_id.clone(),\n        };\n\n        let result = store.add_edge(ctx.clone(), edge).await;\n        assert!(matches!(result, Err(GraphError::ReferentialIntegrity(_))));\n    }\n\n    #[tokio::test]\n    async fn test_add_edge_with_valid_nodes() {\n        let store = create_test_store();\n        let ctx = test_tenant_context();\n        let tenant_id = ctx.tenant_id.as_str().to_string();\n\n        let node1 = GraphNode {\n            id: \"node-1\".to_string(),\n            label: \"Node1\".to_string(),\n            properties: serde_json::Value::Null,\n            tenant_id: tenant_id.clone(),\n        };\n        let node2 = GraphNode {\n            id: \"node-2\".to_string(),\n            label: \"Node2\".to_string(),\n            properties: serde_json::Value::Null,\n            tenant_id: tenant_id.clone(),\n        };\n\n        store.add_node(ctx.clone(), node1).await.unwrap();\n        store.add_node(ctx.clone(), node2).await.unwrap();\n\n        let edge = GraphEdge {\n            id: \"edge-1\".to_string(),\n            source_id: \"node-1\".to_string(),\n            target_id: \"node-2\".to_string(),\n            relation: \"RELATES_TO\".to_string(),\n            properties: serde_json::Value::Null,\n            tenant_id: tenant_id.clone(),\n        };\n\n        store.add_edge(ctx.clone(), edge).await.unwrap();\n\n        let neighbors = store.get_neighbors(ctx, \"node-1\").await.unwrap();\n        assert_eq!(neighbors.len(), 1);\n        assert_eq!(neighbors[0].1.id, \"node-2\");\n    }\n\n    #[tokio::test]\n    async fn test_soft_delete_cascades() {\n        let store = create_test_store();\n        let ctx = test_tenant_context();\n        let tenant_id = ctx.tenant_id.as_str().to_string();\n\n        let node1 = GraphNode {\n            id: \"node-1\".to_string(),\n            label: \"Node1\".to_string(),\n            properties: serde_json::Value::Null,\n            tenant_id: tenant_id.clone(),\n        };\n        let node2 = GraphNode {\n            id: \"node-2\".to_string(),\n            label: \"Node2\".to_string(),\n            properties: serde_json::Value::Null,\n            tenant_id: tenant_id.clone(),\n        };\n        let edge = GraphEdge {\n            id: \"edge-1\".to_string(),\n            source_id: \"node-1\".to_string(),\n            target_id: \"node-2\".to_string(),\n            relation: \"RELATES_TO\".to_string(),\n            properties: serde_json::Value::Null,\n            tenant_id: tenant_id.clone(),\n        };\n\n        store.add_node(ctx.clone(), node1).await.unwrap();\n        store.add_node(ctx.clone(), node2).await.unwrap();\n        store.add_edge(ctx.clone(), edge).await.unwrap();\n\n        store.soft_delete_node(ctx.clone(), \"node-1\").unwrap();\n\n        let neighbors = store.get_neighbors(ctx, \"node-2\").await.unwrap();\n        assert!(neighbors.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_tenant_isolation() {\n        let store = create_test_store();\n        let ctx1 = TenantContext::new(\n            TenantId::new(\"tenant-1\".to_string()).unwrap(),\n            UserId::new(\"user-1\".to_string()).unwrap(),\n        );\n        let ctx2 = TenantContext::new(\n            TenantId::new(\"tenant-2\".to_string()).unwrap(),\n            UserId::new(\"user-2\".to_string()).unwrap(),\n        );\n\n        let node = GraphNode {\n            id: \"node-1\".to_string(),\n            label: \"TenantNode\".to_string(),\n            properties: serde_json::Value::Null,\n            tenant_id: ctx1.tenant_id.as_str().to_string(),\n        };\n\n        store.add_node(ctx1.clone(), node).await.unwrap();\n\n        let results = store.search_nodes(ctx2, \"Tenant\", 10).await.unwrap();\n        assert!(results.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_search_nodes() {\n        let store = create_test_store();\n        let ctx = test_tenant_context();\n        let tenant_id = ctx.tenant_id.as_str().to_string();\n\n        for i in 1..=5 {\n            let node = GraphNode {\n                id: format!(\"node-{}\", i),\n                label: format!(\"TestNode-{}\", i),\n                properties: serde_json::json!({\"index\": i}),\n                tenant_id: tenant_id.clone(),\n            };\n            store.add_node(ctx.clone(), node).await.unwrap();\n        }\n\n        let results = store.search_nodes(ctx, \"TestNode\", 10).await.unwrap();\n        assert_eq!(results.len(), 5);\n    }\n\n    #[tokio::test]\n    async fn test_find_path() {\n        let store = create_test_store();\n        let ctx = test_tenant_context();\n        let tenant_id = ctx.tenant_id.as_str().to_string();\n\n        for i in 1..=3 {\n            let node = GraphNode {\n                id: format!(\"node-{}\", i),\n                label: format!(\"Node{}\", i),\n                properties: serde_json::Value::Null,\n                tenant_id: tenant_id.clone(),\n            };\n            store.add_node(ctx.clone(), node).await.unwrap();\n        }\n\n        for i in 1..=2 {\n            let edge = GraphEdge {\n                id: format!(\"edge-{}\", i),\n                source_id: format!(\"node-{}\", i),\n                target_id: format!(\"node-{}\", i + 1),\n                relation: \"NEXT\".to_string(),\n                properties: serde_json::Value::Null,\n                tenant_id: tenant_id.clone(),\n            };\n            store.add_edge(ctx.clone(), edge).await.unwrap();\n        }\n\n        let path = store.find_path(ctx, \"node-1\", \"node-3\", 5).await.unwrap();\n        assert_eq!(path.len(), 2);\n    }\n\n    #[tokio::test]\n    async fn test_get_stats() {\n        let store = create_test_store();\n        let ctx = test_tenant_context();\n        let tenant_id = ctx.tenant_id.as_str().to_string();\n\n        for i in 1..=3 {\n            let node = GraphNode {\n                id: format!(\"node-{}\", i),\n                label: format!(\"Node{}\", i),\n                properties: serde_json::Value::Null,\n                tenant_id: tenant_id.clone(),\n            };\n            store.add_node(ctx.clone(), node).await.unwrap();\n        }\n\n        let edge = GraphEdge {\n            id: \"edge-1\".to_string(),\n            source_id: \"node-1\".to_string(),\n            target_id: \"node-2\".to_string(),\n            relation: \"RELATES\".to_string(),\n            properties: serde_json::Value::Null,\n            tenant_id: tenant_id.clone(),\n        };\n        store.add_edge(ctx.clone(), edge).await.unwrap();\n\n        let stats = store.get_stats(ctx).unwrap();\n        assert_eq!(stats.node_count, 3);\n        assert_eq!(stats.edge_count, 1);\n    }\n\n    #[tokio::test]\n    async fn test_detect_communities_single_component() {\n        let store = create_test_store();\n        let ctx = test_tenant_context();\n        let tenant_id = ctx.tenant_id.as_str().to_string();\n\n        for i in 1..=4 {\n            let node = GraphNode {\n                id: format!(\"node-{}\", i),\n                label: format!(\"Node{}\", i),\n                properties: serde_json::Value::Null,\n                tenant_id: tenant_id.clone(),\n            };\n            store.add_node(ctx.clone(), node).await.unwrap();\n        }\n\n        let edges = vec![\n            (\"node-1\", \"node-2\"),\n            (\"node-2\", \"node-3\"),\n            (\"node-3\", \"node-4\"),\n            (\"node-4\", \"node-1\"),\n        ];\n        for (i, (src, tgt)) in edges.iter().enumerate() {\n            let edge = GraphEdge {\n                id: format!(\"edge-{}\", i),\n                source_id: src.to_string(),\n                target_id: tgt.to_string(),\n                relation: \"CONNECTS\".to_string(),\n                properties: serde_json::Value::Null,\n                tenant_id: tenant_id.clone(),\n            };\n            store.add_edge(ctx.clone(), edge).await.unwrap();\n        }\n\n        let communities = store.detect_communities(ctx, 2).unwrap();\n        assert_eq!(communities.len(), 1);\n        assert_eq!(communities[0].member_node_ids.len(), 4);\n        assert!(communities[0].density > 0.0);\n    }\n\n    #[tokio::test]\n    async fn test_detect_communities_multiple_components() {\n        let store = create_test_store();\n        let ctx = test_tenant_context();\n        let tenant_id = ctx.tenant_id.as_str().to_string();\n\n        for i in 1..=6 {\n            let node = GraphNode {\n                id: format!(\"node-{}\", i),\n                label: format!(\"Node{}\", i),\n                properties: serde_json::Value::Null,\n                tenant_id: tenant_id.clone(),\n            };\n            store.add_node(ctx.clone(), node).await.unwrap();\n        }\n\n        let edge1 = GraphEdge {\n            id: \"edge-1\".to_string(),\n            source_id: \"node-1\".to_string(),\n            target_id: \"node-2\".to_string(),\n            relation: \"CONNECTS\".to_string(),\n            properties: serde_json::Value::Null,\n            tenant_id: tenant_id.clone(),\n        };\n        store.add_edge(ctx.clone(), edge1).await.unwrap();\n\n        let edge2 = GraphEdge {\n            id: \"edge-2\".to_string(),\n            source_id: \"node-4\".to_string(),\n            target_id: \"node-5\".to_string(),\n            relation: \"CONNECTS\".to_string(),\n            properties: serde_json::Value::Null,\n            tenant_id: tenant_id.clone(),\n        };\n        store.add_edge(ctx.clone(), edge2).await.unwrap();\n\n        let communities = store.detect_communities(ctx, 2).unwrap();\n        assert_eq!(communities.len(), 2);\n    }\n\n    #[tokio::test]\n    async fn test_detect_communities_min_size_filter() {\n        let store = create_test_store();\n        let ctx = test_tenant_context();\n        let tenant_id = ctx.tenant_id.as_str().to_string();\n\n        for i in 1..=3 {\n            let node = GraphNode {\n                id: format!(\"node-{}\", i),\n                label: format!(\"Node{}\", i),\n                properties: serde_json::Value::Null,\n                tenant_id: tenant_id.clone(),\n            };\n            store.add_node(ctx.clone(), node).await.unwrap();\n        }\n\n        let edge = GraphEdge {\n            id: \"edge-1\".to_string(),\n            source_id: \"node-1\".to_string(),\n            target_id: \"node-2\".to_string(),\n            relation: \"CONNECTS\".to_string(),\n            properties: serde_json::Value::Null,\n            tenant_id: tenant_id.clone(),\n        };\n        store.add_edge(ctx.clone(), edge).await.unwrap();\n\n        let communities = store.detect_communities(ctx, 3).unwrap();\n        assert_eq!(communities.len(), 0);\n    }\n\n    #[tokio::test]\n    async fn test_soft_delete_nodes_by_source_memory_id() {\n        let store = create_test_store();\n        let ctx = test_tenant_context();\n        let tenant_id = ctx.tenant_id.as_str().to_string();\n\n        let node1 = GraphNode {\n            id: \"entity-person\".to_string(),\n            label: \"Person\".to_string(),\n            properties: serde_json::json!({\"source_memory_id\": \"memory-123\", \"name\": \"Alice\"}),\n            tenant_id: tenant_id.clone(),\n        };\n        let node2 = GraphNode {\n            id: \"entity-place\".to_string(),\n            label: \"Place\".to_string(),\n            properties: serde_json::json!({\"source_memory_id\": \"memory-123\", \"name\": \"Office\"}),\n            tenant_id: tenant_id.clone(),\n        };\n        let node3 = GraphNode {\n            id: \"entity-other\".to_string(),\n            label: \"Other\".to_string(),\n            properties: serde_json::json!({\"source_memory_id\": \"memory-456\", \"name\": \"Unrelated\"}),\n            tenant_id: tenant_id.clone(),\n        };\n\n        store.add_node(ctx.clone(), node1).await.unwrap();\n        store.add_node(ctx.clone(), node2).await.unwrap();\n        store.add_node(ctx.clone(), node3).await.unwrap();\n\n        let edge = GraphEdge {\n            id: \"edge-person-place\".to_string(),\n            source_id: \"entity-person\".to_string(),\n            target_id: \"entity-place\".to_string(),\n            relation: \"WORKS_AT\".to_string(),\n            properties: serde_json::Value::Null,\n            tenant_id: tenant_id.clone(),\n        };\n        store.add_edge(ctx.clone(), edge).await.unwrap();\n\n        let deleted = store\n            .soft_delete_nodes_by_source_memory_id(ctx.clone(), \"memory-123\")\n            .unwrap();\n        assert_eq!(deleted, 2);\n\n        let results = store.search_nodes(ctx.clone(), \"Other\", 10).await.unwrap();\n        assert_eq!(results.len(), 1);\n        assert_eq!(results[0].id, \"entity-other\");\n\n        let neighbors = store\n            .get_neighbors(ctx.clone(), \"entity-other\")\n            .await\n            .unwrap();\n        assert!(neighbors.is_empty());\n    }\n}\n","traces":[{"line":85,"address":[],"length":0,"stats":{"Line":127}},{"line":145,"address":[],"length":0,"stats":{"Line":114}},{"line":147,"address":[],"length":0,"stats":{"Line":342}},{"line":156,"address":[],"length":0,"stats":{"Line":114}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":0}},{"line":284,"address":[],"length":0,"stats":{"Line":8}},{"line":288,"address":[],"length":0,"stats":{"Line":16}},{"line":290,"address":[],"length":0,"stats":{"Line":8}},{"line":372,"address":[],"length":0,"stats":{"Line":0}},{"line":373,"address":[],"length":0,"stats":{"Line":0}},{"line":381,"address":[],"length":0,"stats":{"Line":0}},{"line":382,"address":[],"length":0,"stats":{"Line":0}},{"line":383,"address":[],"length":0,"stats":{"Line":0}},{"line":385,"address":[],"length":0,"stats":{"Line":0}},{"line":386,"address":[],"length":0,"stats":{"Line":0}},{"line":387,"address":[],"length":0,"stats":{"Line":0}},{"line":389,"address":[],"length":0,"stats":{"Line":0}},{"line":390,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":0}},{"line":393,"address":[],"length":0,"stats":{"Line":0}},{"line":394,"address":[],"length":0,"stats":{"Line":0}},{"line":396,"address":[],"length":0,"stats":{"Line":0}},{"line":397,"address":[],"length":0,"stats":{"Line":0}},{"line":398,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":400,"address":[],"length":0,"stats":{"Line":0}},{"line":401,"address":[],"length":0,"stats":{"Line":0}},{"line":404,"address":[],"length":0,"stats":{"Line":0}},{"line":405,"address":[],"length":0,"stats":{"Line":0}},{"line":406,"address":[],"length":0,"stats":{"Line":0}},{"line":409,"address":[],"length":0,"stats":{"Line":0}},{"line":410,"address":[],"length":0,"stats":{"Line":0}},{"line":411,"address":[],"length":0,"stats":{"Line":0}},{"line":413,"address":[],"length":0,"stats":{"Line":0}},{"line":415,"address":[],"length":0,"stats":{"Line":0}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":417,"address":[],"length":0,"stats":{"Line":0}},{"line":418,"address":[],"length":0,"stats":{"Line":0}},{"line":419,"address":[],"length":0,"stats":{"Line":0}},{"line":422,"address":[],"length":0,"stats":{"Line":0}},{"line":423,"address":[],"length":0,"stats":{"Line":0}},{"line":424,"address":[],"length":0,"stats":{"Line":0}},{"line":427,"address":[],"length":0,"stats":{"Line":0}},{"line":428,"address":[],"length":0,"stats":{"Line":0}},{"line":429,"address":[],"length":0,"stats":{"Line":0}},{"line":430,"address":[],"length":0,"stats":{"Line":0}},{"line":431,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":0}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":442,"address":[],"length":0,"stats":{"Line":0}},{"line":448,"address":[],"length":0,"stats":{"Line":0}},{"line":449,"address":[],"length":0,"stats":{"Line":0}},{"line":450,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":453,"address":[],"length":0,"stats":{"Line":0}},{"line":455,"address":[],"length":0,"stats":{"Line":0}},{"line":467,"address":[],"length":0,"stats":{"Line":0}},{"line":468,"address":[],"length":0,"stats":{"Line":0}},{"line":469,"address":[],"length":0,"stats":{"Line":0}},{"line":470,"address":[],"length":0,"stats":{"Line":0}},{"line":471,"address":[],"length":0,"stats":{"Line":0}},{"line":472,"address":[],"length":0,"stats":{"Line":0}},{"line":474,"address":[],"length":0,"stats":{"Line":0}},{"line":475,"address":[],"length":0,"stats":{"Line":0}},{"line":476,"address":[],"length":0,"stats":{"Line":0}},{"line":477,"address":[],"length":0,"stats":{"Line":0}},{"line":487,"address":[],"length":0,"stats":{"Line":7}},{"line":499,"address":[],"length":0,"stats":{"Line":7}},{"line":500,"address":[],"length":0,"stats":{"Line":7}},{"line":503,"address":[],"length":0,"stats":{"Line":3}},{"line":505,"address":[],"length":0,"stats":{"Line":3}},{"line":509,"address":[],"length":0,"stats":{"Line":2}},{"line":510,"address":[],"length":0,"stats":{"Line":4}},{"line":511,"address":[],"length":0,"stats":{"Line":1}},{"line":512,"address":[],"length":0,"stats":{"Line":1}},{"line":514,"address":[],"length":0,"stats":{"Line":2}},{"line":517,"address":[],"length":0,"stats":{"Line":2}},{"line":518,"address":[],"length":0,"stats":{"Line":4}},{"line":520,"address":[],"length":0,"stats":{"Line":2}},{"line":525,"address":[],"length":0,"stats":{"Line":0}},{"line":529,"address":[],"length":0,"stats":{"Line":7}},{"line":530,"address":[],"length":0,"stats":{"Line":10}},{"line":531,"address":[],"length":0,"stats":{"Line":4}},{"line":532,"address":[],"length":0,"stats":{"Line":3}},{"line":533,"address":[],"length":0,"stats":{"Line":2}},{"line":535,"address":[],"length":0,"stats":{"Line":1}},{"line":536,"address":[],"length":0,"stats":{"Line":1}},{"line":538,"address":[],"length":0,"stats":{"Line":4}},{"line":539,"address":[],"length":0,"stats":{"Line":3}},{"line":540,"address":[],"length":0,"stats":{"Line":2}},{"line":542,"address":[],"length":0,"stats":{"Line":1}},{"line":543,"address":[],"length":0,"stats":{"Line":1}},{"line":549,"address":[],"length":0,"stats":{"Line":1}},{"line":550,"address":[],"length":0,"stats":{"Line":2}},{"line":551,"address":[],"length":0,"stats":{"Line":2}},{"line":554,"address":[],"length":0,"stats":{"Line":2}},{"line":555,"address":[],"length":0,"stats":{"Line":2}},{"line":558,"address":[],"length":0,"stats":{"Line":1}},{"line":559,"address":[],"length":0,"stats":{"Line":1}},{"line":562,"address":[],"length":0,"stats":{"Line":2}},{"line":563,"address":[],"length":0,"stats":{"Line":2}},{"line":564,"address":[],"length":0,"stats":{"Line":2}},{"line":567,"address":[],"length":0,"stats":{"Line":6}},{"line":568,"address":[],"length":0,"stats":{"Line":6}},{"line":569,"address":[],"length":0,"stats":{"Line":6}},{"line":571,"address":[],"length":0,"stats":{"Line":6}},{"line":573,"address":[],"length":0,"stats":{"Line":12}},{"line":574,"address":[],"length":0,"stats":{"Line":6}},{"line":575,"address":[],"length":0,"stats":{"Line":18}},{"line":578,"address":[],"length":0,"stats":{"Line":1}},{"line":579,"address":[],"length":0,"stats":{"Line":1}},{"line":580,"address":[],"length":0,"stats":{"Line":1}},{"line":582,"address":[],"length":0,"stats":{"Line":1}},{"line":584,"address":[],"length":0,"stats":{"Line":2}},{"line":585,"address":[],"length":0,"stats":{"Line":1}},{"line":586,"address":[],"length":0,"stats":{"Line":3}},{"line":589,"address":[],"length":0,"stats":{"Line":2}},{"line":590,"address":[],"length":0,"stats":{"Line":2}},{"line":591,"address":[],"length":0,"stats":{"Line":2}},{"line":593,"address":[],"length":0,"stats":{"Line":2}},{"line":605,"address":[],"length":0,"stats":{"Line":115}},{"line":606,"address":[],"length":0,"stats":{"Line":115}},{"line":608,"address":[],"length":0,"stats":{"Line":230}},{"line":609,"address":[],"length":0,"stats":{"Line":115}},{"line":611,"address":[],"length":0,"stats":{"Line":0}},{"line":615,"address":[],"length":0,"stats":{"Line":345}},{"line":619,"address":[],"length":0,"stats":{"Line":230}},{"line":620,"address":[],"length":0,"stats":{"Line":230}},{"line":622,"address":[],"length":0,"stats":{"Line":115}},{"line":623,"address":[],"length":0,"stats":{"Line":115}},{"line":626,"address":[],"length":0,"stats":{"Line":4}},{"line":629,"address":[],"length":0,"stats":{"Line":6}},{"line":630,"address":[],"length":0,"stats":{"Line":6}},{"line":631,"address":[],"length":0,"stats":{"Line":6}},{"line":633,"address":[],"length":0,"stats":{"Line":6}},{"line":634,"address":[],"length":0,"stats":{"Line":10}},{"line":636,"address":[],"length":0,"stats":{"Line":6}},{"line":638,"address":[],"length":0,"stats":{"Line":2}},{"line":639,"address":[],"length":0,"stats":{"Line":0}},{"line":642,"address":[],"length":0,"stats":{"Line":0}},{"line":644,"address":[],"length":0,"stats":{"Line":2}},{"line":649,"address":[],"length":0,"stats":{"Line":115}},{"line":650,"address":[],"length":0,"stats":{"Line":230}},{"line":652,"address":[],"length":0,"stats":{"Line":230}},{"line":662,"address":[],"length":0,"stats":{"Line":230}},{"line":681,"address":[],"length":0,"stats":{"Line":230}},{"line":701,"address":[],"length":0,"stats":{"Line":230}},{"line":719,"address":[],"length":0,"stats":{"Line":230}},{"line":737,"address":[],"length":0,"stats":{"Line":230}},{"line":752,"address":[],"length":0,"stats":{"Line":115}},{"line":753,"address":[],"length":0,"stats":{"Line":115}},{"line":757,"address":[],"length":0,"stats":{"Line":115}},{"line":758,"address":[],"length":0,"stats":{"Line":230}},{"line":760,"address":[],"length":0,"stats":{"Line":345}},{"line":764,"address":[],"length":0,"stats":{"Line":230}},{"line":768,"address":[],"length":0,"stats":{"Line":115}},{"line":769,"address":[],"length":0,"stats":{"Line":0}},{"line":770,"address":[],"length":0,"stats":{"Line":0}},{"line":773,"address":[],"length":0,"stats":{"Line":115}},{"line":774,"address":[],"length":0,"stats":{"Line":0}},{"line":778,"address":[],"length":0,"stats":{"Line":230}},{"line":780,"address":[],"length":0,"stats":{"Line":345}},{"line":781,"address":[],"length":0,"stats":{"Line":115}},{"line":782,"address":[],"length":0,"stats":{"Line":115}},{"line":783,"address":[],"length":0,"stats":{"Line":0}},{"line":787,"address":[],"length":0,"stats":{"Line":230}},{"line":789,"address":[],"length":0,"stats":{"Line":230}},{"line":790,"address":[],"length":0,"stats":{"Line":115}},{"line":791,"address":[],"length":0,"stats":{"Line":0}},{"line":794,"address":[],"length":0,"stats":{"Line":345}},{"line":795,"address":[],"length":0,"stats":{"Line":115}},{"line":796,"address":[],"length":0,"stats":{"Line":115}},{"line":799,"address":[],"length":0,"stats":{"Line":115}},{"line":802,"address":[],"length":0,"stats":{"Line":115}},{"line":804,"address":[],"length":0,"stats":{"Line":230}},{"line":805,"address":[],"length":0,"stats":{"Line":115}},{"line":807,"address":[],"length":0,"stats":{"Line":0}},{"line":808,"address":[],"length":0,"stats":{"Line":0}},{"line":809,"address":[],"length":0,"stats":{"Line":0}},{"line":812,"address":[],"length":0,"stats":{"Line":0}},{"line":815,"address":[],"length":0,"stats":{"Line":0}},{"line":816,"address":[],"length":0,"stats":{"Line":0}},{"line":817,"address":[],"length":0,"stats":{"Line":0}},{"line":824,"address":[],"length":0,"stats":{"Line":115}},{"line":825,"address":[],"length":0,"stats":{"Line":115}},{"line":828,"address":[],"length":0,"stats":{"Line":115}},{"line":829,"address":[],"length":0,"stats":{"Line":230}},{"line":830,"address":[],"length":0,"stats":{"Line":115}},{"line":831,"address":[],"length":0,"stats":{"Line":345}},{"line":832,"address":[],"length":0,"stats":{"Line":115}},{"line":833,"address":[],"length":0,"stats":{"Line":115}},{"line":837,"address":[],"length":0,"stats":{"Line":5}},{"line":838,"address":[],"length":0,"stats":{"Line":10}},{"line":841,"address":[],"length":0,"stats":{"Line":5}},{"line":842,"address":[],"length":0,"stats":{"Line":10}},{"line":844,"address":[],"length":0,"stats":{"Line":15}},{"line":849,"address":[],"length":0,"stats":{"Line":10}},{"line":850,"address":[],"length":0,"stats":{"Line":15}},{"line":852,"address":[],"length":0,"stats":{"Line":10}},{"line":853,"address":[],"length":0,"stats":{"Line":10}},{"line":854,"address":[],"length":0,"stats":{"Line":10}},{"line":857,"address":[],"length":0,"stats":{"Line":15}},{"line":860,"address":[],"length":0,"stats":{"Line":5}},{"line":863,"address":[],"length":0,"stats":{"Line":418}},{"line":864,"address":[],"length":0,"stats":{"Line":1254}},{"line":865,"address":[],"length":0,"stats":{"Line":836}},{"line":866,"address":[],"length":0,"stats":{"Line":0}},{"line":867,"address":[],"length":0,"stats":{"Line":0}},{"line":870,"address":[],"length":0,"stats":{"Line":837}},{"line":871,"address":[],"length":0,"stats":{"Line":417}},{"line":874,"address":[],"length":0,"stats":{"Line":510}},{"line":875,"address":[],"length":0,"stats":{"Line":1020}},{"line":876,"address":[],"length":0,"stats":{"Line":25}},{"line":877,"address":[],"length":0,"stats":{"Line":5}},{"line":878,"address":[],"length":0,"stats":{"Line":5}},{"line":882,"address":[],"length":0,"stats":{"Line":505}},{"line":886,"address":[],"length":0,"stats":{"Line":1}},{"line":889,"address":[],"length":0,"stats":{"Line":1}},{"line":890,"address":[],"length":0,"stats":{"Line":1}},{"line":894,"address":[],"length":0,"stats":{"Line":504}},{"line":895,"address":[],"length":0,"stats":{"Line":504}},{"line":896,"address":[],"length":0,"stats":{"Line":13892}},{"line":901,"address":[],"length":0,"stats":{"Line":8}},{"line":904,"address":[],"length":0,"stats":{"Line":8}},{"line":905,"address":[],"length":0,"stats":{"Line":8}},{"line":909,"address":[],"length":0,"stats":{"Line":992}},{"line":910,"address":[],"length":0,"stats":{"Line":5456}},{"line":911,"address":[],"length":0,"stats":{"Line":1488}},{"line":914,"address":[],"length":0,"stats":{"Line":1488}},{"line":915,"address":[],"length":0,"stats":{"Line":15311}},{"line":916,"address":[],"length":0,"stats":{"Line":14818}},{"line":920,"address":[],"length":0,"stats":{"Line":3}},{"line":921,"address":[],"length":0,"stats":{"Line":3}},{"line":923,"address":[],"length":0,"stats":{"Line":3}},{"line":924,"address":[],"length":0,"stats":{"Line":3}},{"line":929,"address":[],"length":0,"stats":{"Line":493}},{"line":932,"address":[],"length":0,"stats":{"Line":17}},{"line":933,"address":[],"length":0,"stats":{"Line":17}},{"line":939,"address":[],"length":0,"stats":{"Line":0}},{"line":945,"address":[],"length":0,"stats":{"Line":3850}},{"line":951,"address":[],"length":0,"stats":{"Line":15400}},{"line":954,"address":[],"length":0,"stats":{"Line":3850}},{"line":955,"address":[],"length":0,"stats":{"Line":7700}},{"line":957,"address":[],"length":0,"stats":{"Line":3850}},{"line":961,"address":[],"length":0,"stats":{"Line":13}},{"line":962,"address":[],"length":0,"stats":{"Line":52}},{"line":963,"address":[],"length":0,"stats":{"Line":26}},{"line":964,"address":[],"length":0,"stats":{"Line":39}},{"line":966,"address":[],"length":0,"stats":{"Line":52}},{"line":969,"address":[],"length":0,"stats":{"Line":13}},{"line":972,"address":[],"length":0,"stats":{"Line":13}},{"line":973,"address":[],"length":0,"stats":{"Line":1}},{"line":976,"address":[],"length":0,"stats":{"Line":36}},{"line":979,"address":[],"length":0,"stats":{"Line":12}},{"line":982,"address":[],"length":0,"stats":{"Line":12}},{"line":983,"address":[],"length":0,"stats":{"Line":12}},{"line":987,"address":[],"length":0,"stats":{"Line":2}},{"line":992,"address":[],"length":0,"stats":{"Line":8}},{"line":993,"address":[],"length":0,"stats":{"Line":4}},{"line":994,"address":[],"length":0,"stats":{"Line":6}},{"line":996,"address":[],"length":0,"stats":{"Line":6}},{"line":1003,"address":[],"length":0,"stats":{"Line":6}},{"line":1004,"address":[],"length":0,"stats":{"Line":12}},{"line":1005,"address":[],"length":0,"stats":{"Line":10}},{"line":1008,"address":[],"length":0,"stats":{"Line":4}},{"line":1009,"address":[],"length":0,"stats":{"Line":0}},{"line":1010,"address":[],"length":0,"stats":{"Line":0}},{"line":1013,"address":[],"length":0,"stats":{"Line":8}},{"line":1018,"address":[],"length":0,"stats":{"Line":2}},{"line":1021,"address":[],"length":0,"stats":{"Line":10}},{"line":1022,"address":[],"length":0,"stats":{"Line":12}},{"line":1027,"address":[],"length":0,"stats":{"Line":4}},{"line":1031,"address":[],"length":0,"stats":{"Line":2}},{"line":1032,"address":[],"length":0,"stats":{"Line":0}},{"line":1035,"address":[],"length":0,"stats":{"Line":2}},{"line":1039,"address":[],"length":0,"stats":{"Line":1}},{"line":1040,"address":[],"length":0,"stats":{"Line":2}},{"line":1041,"address":[],"length":0,"stats":{"Line":3}},{"line":1043,"address":[],"length":0,"stats":{"Line":4}},{"line":1045,"address":[],"length":0,"stats":{"Line":1}},{"line":1048,"address":[],"length":0,"stats":{"Line":4}},{"line":1050,"address":[],"length":0,"stats":{"Line":1}},{"line":1053,"address":[],"length":0,"stats":{"Line":4}},{"line":1055,"address":[],"length":0,"stats":{"Line":1}},{"line":1058,"address":[],"length":0,"stats":{"Line":4}},{"line":1060,"address":[],"length":0,"stats":{"Line":1}},{"line":1063,"address":[],"length":0,"stats":{"Line":2}},{"line":1064,"address":[],"length":0,"stats":{"Line":1}},{"line":1065,"address":[],"length":0,"stats":{"Line":1}},{"line":1069,"address":[],"length":0,"stats":{"Line":38}},{"line":1075,"address":[],"length":0,"stats":{"Line":152}},{"line":1076,"address":[],"length":0,"stats":{"Line":152}},{"line":1078,"address":[],"length":0,"stats":{"Line":38}},{"line":1079,"address":[],"length":0,"stats":{"Line":0}},{"line":1080,"address":[],"length":0,"stats":{"Line":0}},{"line":1085,"address":[],"length":0,"stats":{"Line":76}},{"line":1087,"address":[],"length":0,"stats":{"Line":76}},{"line":1152,"address":[],"length":0,"stats":{"Line":114}},{"line":1153,"address":[],"length":0,"stats":{"Line":114}},{"line":1154,"address":[],"length":0,"stats":{"Line":38}},{"line":1157,"address":[],"length":0,"stats":{"Line":295}},{"line":1160,"address":[],"length":0,"stats":{"Line":590}},{"line":1161,"address":[],"length":0,"stats":{"Line":590}},{"line":1162,"address":[],"length":0,"stats":{"Line":590}},{"line":1163,"address":[],"length":0,"stats":{"Line":590}},{"line":1164,"address":[],"length":0,"stats":{"Line":295}},{"line":1165,"address":[],"length":0,"stats":{"Line":295}},{"line":1166,"address":[],"length":0,"stats":{"Line":1475}},{"line":1167,"address":[],"length":0,"stats":{"Line":590}},{"line":1168,"address":[],"length":0,"stats":{"Line":590}},{"line":1169,"address":[],"length":0,"stats":{"Line":590}},{"line":1170,"address":[],"length":0,"stats":{"Line":295}},{"line":1171,"address":[],"length":0,"stats":{"Line":295}},{"line":1172,"address":[],"length":0,"stats":{"Line":885}},{"line":1173,"address":[],"length":0,"stats":{"Line":295}},{"line":1174,"address":[],"length":0,"stats":{"Line":295}},{"line":1177,"address":[],"length":0,"stats":{"Line":590}},{"line":1178,"address":[],"length":0,"stats":{"Line":590}},{"line":1179,"address":[],"length":0,"stats":{"Line":295}},{"line":1180,"address":[],"length":0,"stats":{"Line":295}},{"line":1181,"address":[],"length":0,"stats":{"Line":1475}},{"line":1182,"address":[],"length":0,"stats":{"Line":590}},{"line":1183,"address":[],"length":0,"stats":{"Line":590}},{"line":1184,"address":[],"length":0,"stats":{"Line":590}},{"line":1185,"address":[],"length":0,"stats":{"Line":295}},{"line":1186,"address":[],"length":0,"stats":{"Line":295}},{"line":1187,"address":[],"length":0,"stats":{"Line":885}},{"line":1188,"address":[],"length":0,"stats":{"Line":295}},{"line":1189,"address":[],"length":0,"stats":{"Line":295}},{"line":1190,"address":[],"length":0,"stats":{"Line":295}},{"line":1191,"address":[],"length":0,"stats":{"Line":885}},{"line":1192,"address":[],"length":0,"stats":{"Line":295}},{"line":1193,"address":[],"length":0,"stats":{"Line":295}},{"line":1199,"address":[],"length":0,"stats":{"Line":76}},{"line":1200,"address":[],"length":0,"stats":{"Line":628}},{"line":1201,"address":[],"length":0,"stats":{"Line":885}},{"line":1204,"address":[],"length":0,"stats":{"Line":38}},{"line":1205,"address":[],"length":0,"stats":{"Line":0}},{"line":1206,"address":[],"length":0,"stats":{"Line":0}},{"line":1209,"address":[],"length":0,"stats":{"Line":38}},{"line":1213,"address":[],"length":0,"stats":{"Line":17}},{"line":1220,"address":[],"length":0,"stats":{"Line":68}},{"line":1221,"address":[],"length":0,"stats":{"Line":24}},{"line":1222,"address":[],"length":0,"stats":{"Line":7}},{"line":1223,"address":[],"length":0,"stats":{"Line":2}},{"line":1226,"address":[],"length":0,"stats":{"Line":60}},{"line":1228,"address":[],"length":0,"stats":{"Line":30}},{"line":1230,"address":[],"length":0,"stats":{"Line":30}},{"line":1280,"address":[],"length":0,"stats":{"Line":45}},{"line":1281,"address":[],"length":0,"stats":{"Line":15}},{"line":1282,"address":[],"length":0,"stats":{"Line":15}},{"line":1283,"address":[],"length":0,"stats":{"Line":5}},{"line":1284,"address":[],"length":0,"stats":{"Line":20}},{"line":1285,"address":[],"length":0,"stats":{"Line":5}},{"line":1289,"address":[],"length":0,"stats":{"Line":10}},{"line":1290,"address":[],"length":0,"stats":{"Line":5}},{"line":1291,"address":[],"length":0,"stats":{"Line":20}},{"line":1292,"address":[],"length":0,"stats":{"Line":10}},{"line":1293,"address":[],"length":0,"stats":{"Line":23}},{"line":1294,"address":[],"length":0,"stats":{"Line":54}},{"line":1295,"address":[],"length":0,"stats":{"Line":27}},{"line":1297,"address":[],"length":0,"stats":{"Line":5}},{"line":1298,"address":[],"length":0,"stats":{"Line":5}},{"line":1301,"address":[],"length":0,"stats":{"Line":10}},{"line":1302,"address":[],"length":0,"stats":{"Line":10}},{"line":1304,"address":[],"length":0,"stats":{"Line":0}},{"line":1308,"address":[],"length":0,"stats":{"Line":9}},{"line":1314,"address":[],"length":0,"stats":{"Line":18}},{"line":1322,"address":[],"length":0,"stats":{"Line":9}},{"line":1323,"address":[],"length":0,"stats":{"Line":9}},{"line":1325,"address":[],"length":0,"stats":{"Line":18}},{"line":1326,"address":[],"length":0,"stats":{"Line":18}},{"line":1327,"address":[],"length":0,"stats":{"Line":18}},{"line":1328,"address":[],"length":0,"stats":{"Line":18}},{"line":1329,"address":[],"length":0,"stats":{"Line":9}},{"line":1330,"address":[],"length":0,"stats":{"Line":9}},{"line":1331,"address":[],"length":0,"stats":{"Line":45}},{"line":1332,"address":[],"length":0,"stats":{"Line":18}},{"line":1333,"address":[],"length":0,"stats":{"Line":18}},{"line":1334,"address":[],"length":0,"stats":{"Line":18}},{"line":1335,"address":[],"length":0,"stats":{"Line":9}},{"line":1336,"address":[],"length":0,"stats":{"Line":9}},{"line":1337,"address":[],"length":0,"stats":{"Line":27}},{"line":1338,"address":[],"length":0,"stats":{"Line":9}},{"line":1339,"address":[],"length":0,"stats":{"Line":9}},{"line":1340,"address":[],"length":0,"stats":{"Line":9}},{"line":1341,"address":[],"length":0,"stats":{"Line":9}},{"line":1345,"address":[],"length":0,"stats":{"Line":9}},{"line":1346,"address":[],"length":0,"stats":{"Line":0}},{"line":1347,"address":[],"length":0,"stats":{"Line":0}},{"line":1352,"address":[],"length":0,"stats":{"Line":2}},{"line":1353,"address":[],"length":0,"stats":{"Line":8}},{"line":1355,"address":[],"length":0,"stats":{"Line":2}},{"line":1356,"address":[],"length":0,"stats":{"Line":0}},{"line":1357,"address":[],"length":0,"stats":{"Line":0}},{"line":1361,"address":[],"length":0,"stats":{"Line":4}},{"line":1362,"address":[],"length":0,"stats":{"Line":4}},{"line":1363,"address":[],"length":0,"stats":{"Line":0}},{"line":1365,"address":[],"length":0,"stats":{"Line":4}},{"line":1366,"address":[],"length":0,"stats":{"Line":2}},{"line":1369,"address":[],"length":0,"stats":{"Line":6}},{"line":1374,"address":[],"length":0,"stats":{"Line":4}},{"line":1375,"address":[],"length":0,"stats":{"Line":2}},{"line":1376,"address":[],"length":0,"stats":{"Line":2}},{"line":1377,"address":[],"length":0,"stats":{"Line":2}},{"line":1378,"address":[],"length":0,"stats":{"Line":2}},{"line":1379,"address":[],"length":0,"stats":{"Line":2}},{"line":1380,"address":[],"length":0,"stats":{"Line":2}},{"line":1384,"address":[],"length":0,"stats":{"Line":2}},{"line":1385,"address":[],"length":0,"stats":{"Line":2}},{"line":1389,"address":[],"length":0,"stats":{"Line":1}},{"line":1397,"address":[],"length":0,"stats":{"Line":4}},{"line":1398,"address":[],"length":0,"stats":{"Line":2}},{"line":1400,"address":[],"length":0,"stats":{"Line":4}},{"line":1402,"address":[],"length":0,"stats":{"Line":1}},{"line":1403,"address":[],"length":0,"stats":{"Line":2}},{"line":1406,"address":[],"length":0,"stats":{"Line":4}},{"line":1408,"address":[],"length":0,"stats":{"Line":1}},{"line":1409,"address":[],"length":0,"stats":{"Line":2}},{"line":1412,"address":[],"length":0,"stats":{"Line":1}},{"line":1413,"address":[],"length":0,"stats":{"Line":0}},{"line":1414,"address":[],"length":0,"stats":{"Line":0}},{"line":1415,"address":[],"length":0,"stats":{"Line":0}},{"line":1419,"address":[],"length":0,"stats":{"Line":1}},{"line":1420,"address":[],"length":0,"stats":{"Line":0}},{"line":1421,"address":[],"length":0,"stats":{"Line":0}},{"line":1422,"address":[],"length":0,"stats":{"Line":0}},{"line":1426,"address":[],"length":0,"stats":{"Line":3}},{"line":1427,"address":[],"length":0,"stats":{"Line":2}},{"line":1428,"address":[],"length":0,"stats":{"Line":4}},{"line":1431,"address":[],"length":0,"stats":{"Line":3}},{"line":1436,"address":[],"length":0,"stats":{"Line":1}},{"line":1439,"address":[],"length":0,"stats":{"Line":1}},{"line":1440,"address":[],"length":0,"stats":{"Line":0}},{"line":1443,"address":[],"length":0,"stats":{"Line":1}},{"line":1446,"address":[],"length":0,"stats":{"Line":186}},{"line":1447,"address":[],"length":0,"stats":{"Line":744}},{"line":1448,"address":[],"length":0,"stats":{"Line":372}},{"line":1450,"address":[],"length":0,"stats":{"Line":744}},{"line":1452,"address":[],"length":0,"stats":{"Line":186}},{"line":1453,"address":[],"length":0,"stats":{"Line":372}},{"line":1456,"address":[],"length":0,"stats":{"Line":744}},{"line":1458,"address":[],"length":0,"stats":{"Line":186}},{"line":1459,"address":[],"length":0,"stats":{"Line":372}},{"line":1462,"address":[],"length":0,"stats":{"Line":744}},{"line":1464,"address":[],"length":0,"stats":{"Line":186}},{"line":1465,"address":[],"length":0,"stats":{"Line":372}},{"line":1468,"address":[],"length":0,"stats":{"Line":744}},{"line":1470,"address":[],"length":0,"stats":{"Line":186}},{"line":1471,"address":[],"length":0,"stats":{"Line":372}},{"line":1474,"address":[],"length":0,"stats":{"Line":186}},{"line":1475,"address":[],"length":0,"stats":{"Line":372}},{"line":1476,"address":[],"length":0,"stats":{"Line":372}},{"line":1477,"address":[],"length":0,"stats":{"Line":186}},{"line":1478,"address":[],"length":0,"stats":{"Line":186}},{"line":1483,"address":[],"length":0,"stats":{"Line":6}},{"line":1491,"address":[],"length":0,"stats":{"Line":4}},{"line":1516,"address":[],"length":0,"stats":{"Line":0}},{"line":1530,"address":[],"length":0,"stats":{"Line":0}},{"line":1538,"address":[],"length":0,"stats":{"Line":0}},{"line":1545,"address":[],"length":0,"stats":{"Line":2}},{"line":1556,"address":[],"length":0,"stats":{"Line":2}},{"line":1566,"address":[],"length":0,"stats":{"Line":0}},{"line":1568,"address":[],"length":0,"stats":{"Line":3}},{"line":1578,"address":[],"length":0,"stats":{"Line":0}},{"line":1597,"address":[],"length":0,"stats":{"Line":2}},{"line":1598,"address":[],"length":0,"stats":{"Line":4}},{"line":1600,"address":[],"length":0,"stats":{"Line":4}},{"line":1602,"address":[],"length":0,"stats":{"Line":4}},{"line":1603,"address":[],"length":0,"stats":{"Line":2}},{"line":1604,"address":[],"length":0,"stats":{"Line":2}},{"line":1605,"address":[],"length":0,"stats":{"Line":2}},{"line":1606,"address":[],"length":0,"stats":{"Line":2}},{"line":1607,"address":[],"length":0,"stats":{"Line":2}},{"line":1608,"address":[],"length":0,"stats":{"Line":2}},{"line":1609,"address":[],"length":0,"stats":{"Line":2}},{"line":1610,"address":[],"length":0,"stats":{"Line":2}},{"line":1611,"address":[],"length":0,"stats":{"Line":2}},{"line":1612,"address":[],"length":0,"stats":{"Line":2}},{"line":1613,"address":[],"length":0,"stats":{"Line":2}},{"line":1614,"address":[],"length":0,"stats":{"Line":2}},{"line":1615,"address":[],"length":0,"stats":{"Line":2}},{"line":1618,"address":[],"length":0,"stats":{"Line":8}},{"line":1619,"address":[],"length":0,"stats":{"Line":6}},{"line":1620,"address":[],"length":0,"stats":{"Line":4}},{"line":1621,"address":[],"length":0,"stats":{"Line":4}},{"line":1623,"address":[],"length":0,"stats":{"Line":2}},{"line":1624,"address":[],"length":0,"stats":{"Line":0}},{"line":1625,"address":[],"length":0,"stats":{"Line":0}},{"line":1626,"address":[],"length":0,"stats":{"Line":0}},{"line":1630,"address":[],"length":0,"stats":{"Line":6}},{"line":1631,"address":[],"length":0,"stats":{"Line":6}},{"line":1633,"address":[],"length":0,"stats":{"Line":2}},{"line":1636,"address":[],"length":0,"stats":{"Line":1}},{"line":1637,"address":[],"length":0,"stats":{"Line":2}},{"line":1639,"address":[],"length":0,"stats":{"Line":2}},{"line":1641,"address":[],"length":0,"stats":{"Line":4}},{"line":1642,"address":[],"length":0,"stats":{"Line":3}},{"line":1644,"address":[],"length":0,"stats":{"Line":3}},{"line":1646,"address":[],"length":0,"stats":{"Line":1}},{"line":1648,"address":[],"length":0,"stats":{"Line":3}},{"line":1650,"address":[],"length":0,"stats":{"Line":1}},{"line":1653,"address":[],"length":0,"stats":{"Line":2}},{"line":1664,"address":[],"length":0,"stats":{"Line":2}},{"line":1666,"address":[],"length":0,"stats":{"Line":2}},{"line":1677,"address":[],"length":0,"stats":{"Line":2}},{"line":1679,"address":[],"length":0,"stats":{"Line":3}},{"line":1681,"address":[],"length":0,"stats":{"Line":1}},{"line":1682,"address":[],"length":0,"stats":{"Line":1}},{"line":1686,"address":[],"length":0,"stats":{"Line":3}},{"line":1701,"address":[],"length":0,"stats":{"Line":2}},{"line":1733,"address":[],"length":0,"stats":{"Line":0}},{"line":1746,"address":[],"length":0,"stats":{"Line":0}},{"line":1767,"address":[],"length":0,"stats":{"Line":3}},{"line":1778,"address":[],"length":0,"stats":{"Line":4}},{"line":1790,"address":[],"length":0,"stats":{"Line":0}},{"line":1803,"address":[],"length":0,"stats":{"Line":0}},{"line":1804,"address":[],"length":0,"stats":{"Line":0}},{"line":1808,"address":[],"length":0,"stats":{"Line":0}},{"line":1820,"address":[],"length":0,"stats":{"Line":0}},{"line":1825,"address":[],"length":0,"stats":{"Line":2}},{"line":1839,"address":[],"length":0,"stats":{"Line":0}},{"line":1840,"address":[],"length":0,"stats":{"Line":0}},{"line":1846,"address":[],"length":0,"stats":{"Line":0}},{"line":1856,"address":[],"length":0,"stats":{"Line":0}},{"line":1862,"address":[],"length":0,"stats":{"Line":0}},{"line":1898,"address":[],"length":0,"stats":{"Line":1}},{"line":1909,"address":[],"length":0,"stats":{"Line":2}},{"line":1927,"address":[],"length":0,"stats":{"Line":0}},{"line":1945,"address":[],"length":0,"stats":{"Line":0}},{"line":1959,"address":[],"length":0,"stats":{"Line":0}},{"line":1960,"address":[],"length":0,"stats":{"Line":0}},{"line":1962,"address":[],"length":0,"stats":{"Line":0}},{"line":1965,"address":[],"length":0,"stats":{"Line":0}},{"line":1966,"address":[],"length":0,"stats":{"Line":0}},{"line":1970,"address":[],"length":0,"stats":{"Line":0}},{"line":1973,"address":[],"length":0,"stats":{"Line":0}},{"line":1974,"address":[],"length":0,"stats":{"Line":0}},{"line":1978,"address":[],"length":0,"stats":{"Line":0}},{"line":1981,"address":[],"length":0,"stats":{"Line":0}},{"line":1982,"address":[],"length":0,"stats":{"Line":0}},{"line":1986,"address":[],"length":0,"stats":{"Line":0}},{"line":1989,"address":[],"length":0,"stats":{"Line":0}},{"line":1990,"address":[],"length":0,"stats":{"Line":0}},{"line":1994,"address":[],"length":0,"stats":{"Line":0}},{"line":1995,"address":[],"length":0,"stats":{"Line":0}},{"line":1996,"address":[],"length":0,"stats":{"Line":0}},{"line":1997,"address":[],"length":0,"stats":{"Line":0}},{"line":1998,"address":[],"length":0,"stats":{"Line":0}},{"line":2003,"address":[],"length":0,"stats":{"Line":33}},{"line":2010,"address":[],"length":0,"stats":{"Line":33}},{"line":2011,"address":[],"length":0,"stats":{"Line":68}},{"line":2013,"address":[],"length":0,"stats":{"Line":62}},{"line":2015,"address":[],"length":0,"stats":{"Line":62}},{"line":2017,"address":[],"length":0,"stats":{"Line":62}},{"line":2018,"address":[],"length":0,"stats":{"Line":7547}},{"line":2019,"address":[],"length":0,"stats":{"Line":3759}},{"line":2020,"address":[],"length":0,"stats":{"Line":2}},{"line":2021,"address":[],"length":0,"stats":{"Line":2}},{"line":2025,"address":[],"length":0,"stats":{"Line":11271}},{"line":2026,"address":[],"length":0,"stats":{"Line":3757}},{"line":2028,"address":[],"length":0,"stats":{"Line":11271}},{"line":2029,"address":[],"length":0,"stats":{"Line":3757}},{"line":2030,"address":[],"length":0,"stats":{"Line":3757}},{"line":2031,"address":[],"length":0,"stats":{"Line":3757}},{"line":2032,"address":[],"length":0,"stats":{"Line":3757}},{"line":2033,"address":[],"length":0,"stats":{"Line":3757}},{"line":2034,"address":[],"length":0,"stats":{"Line":3757}},{"line":2035,"address":[],"length":0,"stats":{"Line":3757}},{"line":2036,"address":[],"length":0,"stats":{"Line":3757}},{"line":2037,"address":[],"length":0,"stats":{"Line":3757}},{"line":2041,"address":[],"length":0,"stats":{"Line":3800}},{"line":2042,"address":[],"length":0,"stats":{"Line":1886}},{"line":2043,"address":[],"length":0,"stats":{"Line":0}},{"line":2044,"address":[],"length":0,"stats":{"Line":0}},{"line":2048,"address":[],"length":0,"stats":{"Line":9430}},{"line":2049,"address":[],"length":0,"stats":{"Line":0}},{"line":2050,"address":[],"length":0,"stats":{"Line":0}},{"line":2051,"address":[],"length":0,"stats":{"Line":0}},{"line":2055,"address":[],"length":0,"stats":{"Line":9430}},{"line":2056,"address":[],"length":0,"stats":{"Line":1}},{"line":2057,"address":[],"length":0,"stats":{"Line":1}},{"line":2058,"address":[],"length":0,"stats":{"Line":1}},{"line":2062,"address":[],"length":0,"stats":{"Line":5655}},{"line":2063,"address":[],"length":0,"stats":{"Line":1885}},{"line":2065,"address":[],"length":0,"stats":{"Line":5655}},{"line":2066,"address":[],"length":0,"stats":{"Line":1885}},{"line":2067,"address":[],"length":0,"stats":{"Line":1885}},{"line":2068,"address":[],"length":0,"stats":{"Line":1885}},{"line":2069,"address":[],"length":0,"stats":{"Line":1885}},{"line":2070,"address":[],"length":0,"stats":{"Line":1885}},{"line":2071,"address":[],"length":0,"stats":{"Line":1885}},{"line":2072,"address":[],"length":0,"stats":{"Line":1885}},{"line":2073,"address":[],"length":0,"stats":{"Line":1885}},{"line":2074,"address":[],"length":0,"stats":{"Line":1885}},{"line":2075,"address":[],"length":0,"stats":{"Line":1885}},{"line":2076,"address":[],"length":0,"stats":{"Line":1885}},{"line":2077,"address":[],"length":0,"stats":{"Line":1885}},{"line":2078,"address":[],"length":0,"stats":{"Line":1885}},{"line":2079,"address":[],"length":0,"stats":{"Line":1885}},{"line":2084,"address":[],"length":0,"stats":{"Line":28}},{"line":2087,"address":[],"length":0,"stats":{"Line":31}},{"line":2089,"address":[],"length":0,"stats":{"Line":56}},{"line":2090,"address":[],"length":0,"stats":{"Line":28}},{"line":2091,"address":[],"length":0,"stats":{"Line":0}},{"line":2092,"address":[],"length":0,"stats":{"Line":0}},{"line":2093,"address":[],"length":0,"stats":{"Line":0}},{"line":2095,"address":[],"length":0,"stats":{"Line":28}},{"line":2097,"address":[],"length":0,"stats":{"Line":3}},{"line":2098,"address":[],"length":0,"stats":{"Line":6}},{"line":2099,"address":[],"length":0,"stats":{"Line":3}},{"line":2100,"address":[],"length":0,"stats":{"Line":3}},{"line":2106,"address":[],"length":0,"stats":{"Line":4}},{"line":2113,"address":[],"length":0,"stats":{"Line":4}},{"line":2114,"address":[],"length":0,"stats":{"Line":8}},{"line":2116,"address":[],"length":0,"stats":{"Line":8}},{"line":2118,"address":[],"length":0,"stats":{"Line":8}},{"line":2120,"address":[],"length":0,"stats":{"Line":8}},{"line":2121,"address":[],"length":0,"stats":{"Line":14}},{"line":2122,"address":[],"length":0,"stats":{"Line":6}},{"line":2123,"address":[],"length":0,"stats":{"Line":1}},{"line":2124,"address":[],"length":0,"stats":{"Line":1}},{"line":2128,"address":[],"length":0,"stats":{"Line":9}},{"line":2129,"address":[],"length":0,"stats":{"Line":1}},{"line":2131,"address":[],"length":0,"stats":{"Line":8}},{"line":2132,"address":[],"length":0,"stats":{"Line":4}},{"line":2135,"address":[],"length":0,"stats":{"Line":12}},{"line":2136,"address":[],"length":0,"stats":{"Line":4}},{"line":2137,"address":[],"length":0,"stats":{"Line":4}},{"line":2138,"address":[],"length":0,"stats":{"Line":4}},{"line":2139,"address":[],"length":0,"stats":{"Line":4}},{"line":2140,"address":[],"length":0,"stats":{"Line":4}},{"line":2141,"address":[],"length":0,"stats":{"Line":4}},{"line":2142,"address":[],"length":0,"stats":{"Line":4}},{"line":2143,"address":[],"length":0,"stats":{"Line":4}},{"line":2144,"address":[],"length":0,"stats":{"Line":4}},{"line":2145,"address":[],"length":0,"stats":{"Line":4}},{"line":2146,"address":[],"length":0,"stats":{"Line":4}},{"line":2147,"address":[],"length":0,"stats":{"Line":4}},{"line":2148,"address":[],"length":0,"stats":{"Line":4}},{"line":2149,"address":[],"length":0,"stats":{"Line":4}},{"line":2154,"address":[],"length":0,"stats":{"Line":6}},{"line":2155,"address":[],"length":0,"stats":{"Line":2}},{"line":2156,"address":[],"length":0,"stats":{"Line":0}},{"line":2157,"address":[],"length":0,"stats":{"Line":0}},{"line":2161,"address":[],"length":0,"stats":{"Line":6}},{"line":2162,"address":[],"length":0,"stats":{"Line":2}},{"line":2164,"address":[],"length":0,"stats":{"Line":6}},{"line":2165,"address":[],"length":0,"stats":{"Line":2}},{"line":2166,"address":[],"length":0,"stats":{"Line":2}},{"line":2167,"address":[],"length":0,"stats":{"Line":2}},{"line":2168,"address":[],"length":0,"stats":{"Line":2}},{"line":2169,"address":[],"length":0,"stats":{"Line":2}},{"line":2170,"address":[],"length":0,"stats":{"Line":2}},{"line":2171,"address":[],"length":0,"stats":{"Line":2}},{"line":2172,"address":[],"length":0,"stats":{"Line":2}},{"line":2173,"address":[],"length":0,"stats":{"Line":2}},{"line":2174,"address":[],"length":0,"stats":{"Line":2}},{"line":2175,"address":[],"length":0,"stats":{"Line":2}},{"line":2176,"address":[],"length":0,"stats":{"Line":2}},{"line":2177,"address":[],"length":0,"stats":{"Line":2}},{"line":2178,"address":[],"length":0,"stats":{"Line":2}},{"line":2183,"address":[],"length":0,"stats":{"Line":2}},{"line":2186,"address":[],"length":0,"stats":{"Line":4}},{"line":2188,"address":[],"length":0,"stats":{"Line":4}},{"line":2189,"address":[],"length":0,"stats":{"Line":2}},{"line":2190,"address":[],"length":0,"stats":{"Line":0}},{"line":2191,"address":[],"length":0,"stats":{"Line":0}},{"line":2192,"address":[],"length":0,"stats":{"Line":0}},{"line":2194,"address":[],"length":0,"stats":{"Line":2}},{"line":2196,"address":[],"length":0,"stats":{"Line":2}},{"line":2197,"address":[],"length":0,"stats":{"Line":4}},{"line":2198,"address":[],"length":0,"stats":{"Line":2}},{"line":2199,"address":[],"length":0,"stats":{"Line":2}},{"line":2204,"address":[],"length":0,"stats":{"Line":2}},{"line":2208,"address":[],"length":0,"stats":{"Line":4}},{"line":2210,"address":[],"length":0,"stats":{"Line":4}},{"line":2212,"address":[],"length":0,"stats":{"Line":2}},{"line":2213,"address":[],"length":0,"stats":{"Line":1}},{"line":2214,"address":[],"length":0,"stats":{"Line":2}},{"line":2215,"address":[],"length":0,"stats":{"Line":1}},{"line":2217,"address":[],"length":0,"stats":{"Line":1}},{"line":2218,"address":[],"length":0,"stats":{"Line":2}},{"line":2219,"address":[],"length":0,"stats":{"Line":1}},{"line":2224,"address":[],"length":0,"stats":{"Line":108}},{"line":2225,"address":[],"length":0,"stats":{"Line":216}},{"line":2227,"address":[],"length":0,"stats":{"Line":324}},{"line":2228,"address":[],"length":0,"stats":{"Line":216}},{"line":2230,"address":[],"length":0,"stats":{"Line":216}},{"line":2231,"address":[],"length":0,"stats":{"Line":324}},{"line":2232,"address":[],"length":0,"stats":{"Line":216}},{"line":2234,"address":[],"length":0,"stats":{"Line":432}},{"line":2236,"address":[],"length":0,"stats":{"Line":324}},{"line":2243,"address":[],"length":0,"stats":{"Line":216}},{"line":2249,"address":[],"length":0,"stats":{"Line":104}},{"line":2250,"address":[],"length":0,"stats":{"Line":208}},{"line":2252,"address":[],"length":0,"stats":{"Line":312}},{"line":2253,"address":[],"length":0,"stats":{"Line":312}},{"line":2255,"address":[],"length":0,"stats":{"Line":312}},{"line":2261,"address":[],"length":0,"stats":{"Line":104}},{"line":2265,"address":[],"length":0,"stats":{"Line":108}},{"line":2266,"address":[],"length":0,"stats":{"Line":216}},{"line":2268,"address":[],"length":0,"stats":{"Line":648}},{"line":2271,"address":[],"length":0,"stats":{"Line":108}},{"line":2275,"address":[],"length":0,"stats":{"Line":0}},{"line":2279,"address":[],"length":0,"stats":{"Line":0}},{"line":2284,"address":[],"length":0,"stats":{"Line":108}},{"line":2285,"address":[],"length":0,"stats":{"Line":216}},{"line":2286,"address":[],"length":0,"stats":{"Line":107}},{"line":2287,"address":[],"length":0,"stats":{"Line":107}},{"line":2288,"address":[],"length":0,"stats":{"Line":107}},{"line":2294,"address":[],"length":0,"stats":{"Line":2}},{"line":2301,"address":[],"length":0,"stats":{"Line":104}},{"line":2302,"address":[],"length":0,"stats":{"Line":208}},{"line":2303,"address":[],"length":0,"stats":{"Line":624}},{"line":2307,"address":[],"length":0,"stats":{"Line":104}},{"line":2308,"address":[],"length":0,"stats":{"Line":208}},{"line":2310,"address":[],"length":0,"stats":{"Line":208}},{"line":2315,"address":[],"length":0,"stats":{"Line":208}},{"line":2319,"address":[],"length":0,"stats":{"Line":104}},{"line":2322,"address":[],"length":0,"stats":{"Line":113}},{"line":2323,"address":[],"length":0,"stats":{"Line":226}},{"line":2325,"address":[],"length":0,"stats":{"Line":452}},{"line":2328,"address":[],"length":0,"stats":{"Line":226}},{"line":2331,"address":[],"length":0,"stats":{"Line":113}},{"line":2334,"address":[],"length":0,"stats":{"Line":2}},{"line":2335,"address":[],"length":0,"stats":{"Line":1}},{"line":2336,"address":[],"length":0,"stats":{"Line":0}},{"line":2338,"address":[],"length":0,"stats":{"Line":1}},{"line":2339,"address":[],"length":0,"stats":{"Line":1}},{"line":2340,"address":[],"length":0,"stats":{"Line":1}},{"line":2345,"address":[],"length":0,"stats":{"Line":0}},{"line":2346,"address":[],"length":0,"stats":{"Line":0}},{"line":2347,"address":[],"length":0,"stats":{"Line":0}},{"line":2348,"address":[],"length":0,"stats":{"Line":0}},{"line":2349,"address":[],"length":0,"stats":{"Line":0}},{"line":2350,"address":[],"length":0,"stats":{"Line":0}},{"line":2355,"address":[],"length":0,"stats":{"Line":0}},{"line":2358,"address":[],"length":0,"stats":{"Line":0}},{"line":2362,"address":[],"length":0,"stats":{"Line":0}},{"line":2367,"address":[],"length":0,"stats":{"Line":20}},{"line":2373,"address":[],"length":0,"stats":{"Line":20}},{"line":2374,"address":[],"length":0,"stats":{"Line":1}},{"line":2377,"address":[],"length":0,"stats":{"Line":40}},{"line":2378,"address":[],"length":0,"stats":{"Line":34}},{"line":2380,"address":[],"length":0,"stats":{"Line":51}},{"line":2389,"address":[],"length":0,"stats":{"Line":17}},{"line":2392,"address":[],"length":0,"stats":{"Line":17}},{"line":2395,"address":[],"length":0,"stats":{"Line":8}},{"line":2399,"address":[],"length":0,"stats":{"Line":16}},{"line":2400,"address":[],"length":0,"stats":{"Line":16}},{"line":2402,"address":[],"length":0,"stats":{"Line":24}},{"line":2417,"address":[],"length":0,"stats":{"Line":16}},{"line":2419,"address":[],"length":0,"stats":{"Line":8}},{"line":2421,"address":[],"length":0,"stats":{"Line":8}},{"line":2423,"address":[],"length":0,"stats":{"Line":11}},{"line":2424,"address":[],"length":0,"stats":{"Line":44}},{"line":2425,"address":[],"length":0,"stats":{"Line":11}},{"line":2426,"address":[],"length":0,"stats":{"Line":33}},{"line":2427,"address":[],"length":0,"stats":{"Line":11}},{"line":2428,"address":[],"length":0,"stats":{"Line":22}},{"line":2431,"address":[],"length":0,"stats":{"Line":22}},{"line":2432,"address":[],"length":0,"stats":{"Line":22}},{"line":2433,"address":[],"length":0,"stats":{"Line":22}},{"line":2434,"address":[],"length":0,"stats":{"Line":11}},{"line":2435,"address":[],"length":0,"stats":{"Line":22}},{"line":2439,"address":[],"length":0,"stats":{"Line":30}},{"line":2442,"address":[],"length":0,"stats":{"Line":8}},{"line":2445,"address":[],"length":0,"stats":{"Line":3}},{"line":2446,"address":[],"length":0,"stats":{"Line":12}},{"line":2447,"address":[],"length":0,"stats":{"Line":12}},{"line":2450,"address":[],"length":0,"stats":{"Line":4}},{"line":2455,"address":[],"length":0,"stats":{"Line":4}},{"line":2456,"address":[],"length":0,"stats":{"Line":2}},{"line":2457,"address":[],"length":0,"stats":{"Line":2}},{"line":2458,"address":[],"length":0,"stats":{"Line":2}},{"line":2459,"address":[],"length":0,"stats":{"Line":2}},{"line":2460,"address":[],"length":0,"stats":{"Line":2}},{"line":2464,"address":[],"length":0,"stats":{"Line":4}},{"line":2466,"address":[],"length":0,"stats":{"Line":4}},{"line":2467,"address":[],"length":0,"stats":{"Line":4}},{"line":2468,"address":[],"length":0,"stats":{"Line":4}},{"line":2469,"address":[],"length":0,"stats":{"Line":4}},{"line":2471,"address":[],"length":0,"stats":{"Line":8}},{"line":2472,"address":[],"length":0,"stats":{"Line":6}},{"line":2474,"address":[],"length":0,"stats":{"Line":3}},{"line":2475,"address":[],"length":0,"stats":{"Line":0}},{"line":2476,"address":[],"length":0,"stats":{"Line":0}},{"line":2479,"address":[],"length":0,"stats":{"Line":6}},{"line":2481,"address":[],"length":0,"stats":{"Line":16}},{"line":2482,"address":[],"length":0,"stats":{"Line":1}},{"line":2485,"address":[],"length":0,"stats":{"Line":0}},{"line":2487,"address":[],"length":0,"stats":{"Line":4}},{"line":2488,"address":[],"length":0,"stats":{"Line":1}},{"line":2491,"address":[],"length":0,"stats":{"Line":4}},{"line":2492,"address":[],"length":0,"stats":{"Line":10}},{"line":2493,"address":[],"length":0,"stats":{"Line":2}},{"line":2495,"address":[],"length":0,"stats":{"Line":2}},{"line":2498,"address":[],"length":0,"stats":{"Line":4}},{"line":2499,"address":[],"length":0,"stats":{"Line":8}},{"line":2501,"address":[],"length":0,"stats":{"Line":2}},{"line":2503,"address":[],"length":0,"stats":{"Line":0}},{"line":2505,"address":[],"length":0,"stats":{"Line":2}},{"line":2506,"address":[],"length":0,"stats":{"Line":2}},{"line":2508,"address":[],"length":0,"stats":{"Line":2}},{"line":2510,"address":[],"length":0,"stats":{"Line":0}},{"line":2513,"address":[],"length":0,"stats":{"Line":0}},{"line":2516,"address":[],"length":0,"stats":{"Line":2}},{"line":2517,"address":[],"length":0,"stats":{"Line":4}},{"line":2518,"address":[],"length":0,"stats":{"Line":4}},{"line":2519,"address":[],"length":0,"stats":{"Line":2}},{"line":2520,"address":[],"length":0,"stats":{"Line":2}},{"line":2524,"address":[],"length":0,"stats":{"Line":3}},{"line":2529,"address":[],"length":0,"stats":{"Line":3}},{"line":2532,"address":[],"length":0,"stats":{"Line":0}},{"line":2535,"address":[],"length":0,"stats":{"Line":3}},{"line":2536,"address":[],"length":0,"stats":{"Line":1}},{"line":2537,"address":[],"length":0,"stats":{"Line":1}},{"line":2538,"address":[],"length":0,"stats":{"Line":1}},{"line":2539,"address":[],"length":0,"stats":{"Line":1}},{"line":2542,"address":[],"length":0,"stats":{"Line":0}},{"line":2543,"address":[],"length":0,"stats":{"Line":0}},{"line":2545,"address":[],"length":0,"stats":{"Line":0}},{"line":2547,"address":[],"length":0,"stats":{"Line":0}},{"line":2548,"address":[],"length":0,"stats":{"Line":0}},{"line":2549,"address":[],"length":0,"stats":{"Line":0}},{"line":2550,"address":[],"length":0,"stats":{"Line":0}},{"line":2551,"address":[],"length":0,"stats":{"Line":0}},{"line":2552,"address":[],"length":0,"stats":{"Line":0}},{"line":2555,"address":[],"length":0,"stats":{"Line":0}},{"line":2556,"address":[],"length":0,"stats":{"Line":0}},{"line":2558,"address":[],"length":0,"stats":{"Line":0}},{"line":2559,"address":[],"length":0,"stats":{"Line":0}},{"line":2561,"address":[],"length":0,"stats":{"Line":0}},{"line":2563,"address":[],"length":0,"stats":{"Line":0}},{"line":2565,"address":[],"length":0,"stats":{"Line":0}},{"line":2567,"address":[],"length":0,"stats":{"Line":0}},{"line":2568,"address":[],"length":0,"stats":{"Line":0}},{"line":2569,"address":[],"length":0,"stats":{"Line":0}},{"line":2574,"address":[],"length":0,"stats":{"Line":2}},{"line":2575,"address":[],"length":0,"stats":{"Line":2}},{"line":2580,"address":[],"length":0,"stats":{"Line":1}},{"line":2584,"address":[],"length":0,"stats":{"Line":2}},{"line":2585,"address":[],"length":0,"stats":{"Line":2}},{"line":2587,"address":[],"length":0,"stats":{"Line":1}},{"line":2588,"address":[],"length":0,"stats":{"Line":0}},{"line":2589,"address":[],"length":0,"stats":{"Line":0}},{"line":2592,"address":[],"length":0,"stats":{"Line":0}},{"line":2594,"address":[],"length":0,"stats":{"Line":0}},{"line":2597,"address":[],"length":0,"stats":{"Line":1}},{"line":2600,"address":[],"length":0,"stats":{"Line":1}},{"line":2601,"address":[],"length":0,"stats":{"Line":1}},{"line":2604,"address":[],"length":0,"stats":{"Line":2}},{"line":2605,"address":[],"length":0,"stats":{"Line":4}},{"line":2607,"address":[],"length":0,"stats":{"Line":2}},{"line":2608,"address":[],"length":0,"stats":{"Line":1}},{"line":2609,"address":[],"length":0,"stats":{"Line":1}},{"line":2610,"address":[],"length":0,"stats":{"Line":1}},{"line":2611,"address":[],"length":0,"stats":{"Line":1}},{"line":2617,"address":[],"length":0,"stats":{"Line":2}},{"line":2618,"address":[],"length":0,"stats":{"Line":1}},{"line":2626,"address":[],"length":0,"stats":{"Line":6}},{"line":2631,"address":[],"length":0,"stats":{"Line":24}},{"line":2632,"address":[],"length":0,"stats":{"Line":12}},{"line":2634,"address":[],"length":0,"stats":{"Line":18}},{"line":2641,"address":[],"length":0,"stats":{"Line":18}},{"line":2642,"address":[],"length":0,"stats":{"Line":66}},{"line":2643,"address":[],"length":0,"stats":{"Line":60}},{"line":2646,"address":[],"length":0,"stats":{"Line":12}},{"line":2647,"address":[],"length":0,"stats":{"Line":0}},{"line":2650,"address":[],"length":0,"stats":{"Line":12}},{"line":2651,"address":[],"length":0,"stats":{"Line":6}},{"line":2653,"address":[],"length":0,"stats":{"Line":87}},{"line":2654,"address":[],"length":0,"stats":{"Line":108}},{"line":2657,"address":[],"length":0,"stats":{"Line":18}},{"line":2664,"address":[],"length":0,"stats":{"Line":18}},{"line":2665,"address":[],"length":0,"stats":{"Line":84}},{"line":2666,"address":[],"length":0,"stats":{"Line":42}},{"line":2669,"address":[],"length":0,"stats":{"Line":60}},{"line":2670,"address":[],"length":0,"stats":{"Line":72}},{"line":2671,"address":[],"length":0,"stats":{"Line":54}},{"line":2673,"address":[],"length":0,"stats":{"Line":72}},{"line":2674,"address":[],"length":0,"stats":{"Line":54}},{"line":2678,"address":[],"length":0,"stats":{"Line":18}},{"line":2679,"address":[],"length":0,"stats":{"Line":18}},{"line":2681,"address":[],"length":0,"stats":{"Line":60}},{"line":2682,"address":[],"length":0,"stats":{"Line":81}},{"line":2683,"address":[],"length":0,"stats":{"Line":15}},{"line":2686,"address":[],"length":0,"stats":{"Line":36}},{"line":2687,"address":[],"length":0,"stats":{"Line":36}},{"line":2688,"address":[],"length":0,"stats":{"Line":48}},{"line":2689,"address":[],"length":0,"stats":{"Line":48}},{"line":2691,"address":[],"length":0,"stats":{"Line":66}},{"line":2692,"address":[],"length":0,"stats":{"Line":108}},{"line":2693,"address":[],"length":0,"stats":{"Line":81}},{"line":2694,"address":[],"length":0,"stats":{"Line":99}},{"line":2695,"address":[],"length":0,"stats":{"Line":87}},{"line":2696,"address":[],"length":0,"stats":{"Line":75}},{"line":2697,"address":[],"length":0,"stats":{"Line":45}},{"line":2703,"address":[],"length":0,"stats":{"Line":24}},{"line":2704,"address":[],"length":0,"stats":{"Line":24}},{"line":2705,"address":[],"length":0,"stats":{"Line":24}},{"line":2707,"address":[],"length":0,"stats":{"Line":96}},{"line":2709,"address":[],"length":0,"stats":{"Line":24}},{"line":2710,"address":[],"length":0,"stats":{"Line":16}},{"line":2712,"address":[],"length":0,"stats":{"Line":24}},{"line":2713,"address":[],"length":0,"stats":{"Line":24}},{"line":2714,"address":[],"length":0,"stats":{"Line":8}},{"line":2715,"address":[],"length":0,"stats":{"Line":8}},{"line":2720,"address":[],"length":0,"stats":{"Line":6}},{"line":2721,"address":[],"length":0,"stats":{"Line":0}},{"line":2722,"address":[],"length":0,"stats":{"Line":0}},{"line":2725,"address":[],"length":0,"stats":{"Line":6}},{"line":2758,"address":[],"length":0,"stats":{"Line":0}},{"line":2804,"address":[],"length":0,"stats":{"Line":0}},{"line":2859,"address":[],"length":0,"stats":{"Line":3}},{"line":2860,"address":[],"length":0,"stats":{"Line":3}},{"line":2861,"address":[],"length":0,"stats":{"Line":6}},{"line":2862,"address":[],"length":0,"stats":{"Line":6}},{"line":2863,"address":[],"length":0,"stats":{"Line":6}},{"line":2864,"address":[],"length":0,"stats":{"Line":6}},{"line":2865,"address":[],"length":0,"stats":{"Line":3}},{"line":2866,"address":[],"length":0,"stats":{"Line":3}},{"line":2867,"address":[],"length":0,"stats":{"Line":15}},{"line":2868,"address":[],"length":0,"stats":{"Line":6}},{"line":2869,"address":[],"length":0,"stats":{"Line":6}},{"line":2871,"address":[],"length":0,"stats":{"Line":3}},{"line":2872,"address":[],"length":0,"stats":{"Line":6}},{"line":2873,"address":[],"length":0,"stats":{"Line":6}},{"line":2874,"address":[],"length":0,"stats":{"Line":3}},{"line":2875,"address":[],"length":0,"stats":{"Line":3}},{"line":2876,"address":[],"length":0,"stats":{"Line":15}},{"line":2877,"address":[],"length":0,"stats":{"Line":6}},{"line":2878,"address":[],"length":0,"stats":{"Line":6}},{"line":2880,"address":[],"length":0,"stats":{"Line":3}},{"line":2906,"address":[],"length":0,"stats":{"Line":7}},{"line":2907,"address":[],"length":0,"stats":{"Line":7}},{"line":2908,"address":[],"length":0,"stats":{"Line":7}},{"line":2909,"address":[],"length":0,"stats":{"Line":7}},{"line":2910,"address":[],"length":0,"stats":{"Line":7}},{"line":2911,"address":[],"length":0,"stats":{"Line":7}},{"line":2942,"address":[],"length":0,"stats":{"Line":13}},{"line":2944,"address":[],"length":0,"stats":{"Line":26}},{"line":2945,"address":[],"length":0,"stats":{"Line":26}},{"line":2946,"address":[],"length":0,"stats":{"Line":13}},{"line":2947,"address":[],"length":0,"stats":{"Line":13}},{"line":2948,"address":[],"length":0,"stats":{"Line":65}},{"line":2949,"address":[],"length":0,"stats":{"Line":26}},{"line":2950,"address":[],"length":0,"stats":{"Line":26}}],"covered":750,"coverable":953},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","src","lib.rs"],"content":"pub mod approval_workflow;\npub mod budget_storage;\npub mod events;\npub mod governance;\npub mod graph;\npub mod graph_duckdb;\npub mod meta_governance;\npub mod postgres;\npub mod query_builder;\npub mod redis;\npub mod rls_migration;\n\n// Re-export Redis lock types for job coordination\npub use redis::{JobSkipReason, LockResult};\n\n// Re-export budget storage types\npub use budget_storage::{BudgetStorage, BudgetStorageError, StoredBudget, StoredUsage};\n\n// Re-export governance types\npub use governance::{\n    ApprovalDecision, ApprovalMode, ApprovalRequest, AuditFilters, CreateApprovalRequest,\n    CreateDecision, CreateGovernanceRole, Decision, GovernanceAuditEntry, GovernanceConfig,\n    GovernanceRole, GovernanceStorage, PrincipalType, RequestFilters, RequestStatus, RequestType,\n    RiskLevel,\n};\n\n// Re-export approval workflow state machine\npub use approval_workflow::{\n    ApprovalDecisionRecord, ApprovalEvent, ApprovalModeKind, ApprovalWorkflow,\n    ApprovalWorkflowContext, RiskLevelKind, WorkflowError, WorkflowState, create_workflow,\n};\n\n// Re-export meta-governance types\npub use meta_governance::{\n    ActionPermission, AgentCapability, AgentDelegationConfig, AgentRateLimits, AuthorizationResult,\n    ConfirmationReason, ConfirmationStatus, EscalationConfig, EscalationFallback, EscalationTarget,\n    EscalationTier, GovernanceActionType, GovernanceLayer, HumanConfirmationRequest,\n    MetaGovernancePolicy, MetaGovernanceStorage, NotificationChannel, RoleLevel,\n    create_default_policies,\n};\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","src","meta_governance.rs"],"content":"//! Meta-Governance: Policies about policies\n//!\n//! This module defines who can govern at each level of the organizational hierarchy.\n//! Meta-governance policies control:\n//! - Who can create/approve policies at each layer (company, org, team, project)\n//! - Delegation rules for AI agents (what they can do autonomously vs needing human approval)\n//! - Escalation paths when approvers are unavailable\n//! - Human confirmation gates for sensitive agent actions\n\nuse chrono::{DateTime, Utc};\nuse serde::{Deserialize, Serialize};\nuse sqlx::{FromRow, PgPool};\nuse uuid::Uuid;\n\nuse crate::governance::{PrincipalType, RiskLevel};\n\n/// Defines the governance layer where a meta-governance policy applies.\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq, Hash)]\n#[serde(rename_all = \"snake_case\")]\npub enum GovernanceLayer {\n    Company,\n    Org,\n    Team,\n    Project,\n}\n\nimpl std::fmt::Display for GovernanceLayer {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            GovernanceLayer::Company => write!(f, \"company\"),\n            GovernanceLayer::Org => write!(f, \"org\"),\n            GovernanceLayer::Team => write!(f, \"team\"),\n            GovernanceLayer::Project => write!(f, \"project\"),\n        }\n    }\n}\n\nimpl std::str::FromStr for GovernanceLayer {\n    type Err = String;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        match s.to_lowercase().as_str() {\n            \"company\" => Ok(GovernanceLayer::Company),\n            \"org\" | \"organization\" => Ok(GovernanceLayer::Org),\n            \"team\" => Ok(GovernanceLayer::Team),\n            \"project\" => Ok(GovernanceLayer::Project),\n            _ => Err(format!(\n                \"Invalid governance layer: {}. Use: company, org, team, project\",\n                s\n            )),\n        }\n    }\n}\n\n/// The type of governance action being controlled.\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum GovernanceActionType {\n    // Policy actions\n    CreatePolicy,\n    ApprovePolicy,\n    RejectPolicy,\n    DeletePolicy,\n    // Knowledge actions\n    ProposeKnowledge,\n    ApproveKnowledge,\n    EditKnowledge,\n    DeleteKnowledge,\n    // Memory actions\n    PromoteMemory,\n    DeleteMemory,\n    // Role actions\n    AssignRole,\n    RevokeRole,\n    // Governance config actions\n    ModifyGovernanceConfig,\n    // Meta-governance actions (most privileged)\n    ModifyMetaGovernance,\n}\n\nimpl std::fmt::Display for GovernanceActionType {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        let s = match self {\n            GovernanceActionType::CreatePolicy => \"create_policy\",\n            GovernanceActionType::ApprovePolicy => \"approve_policy\",\n            GovernanceActionType::RejectPolicy => \"reject_policy\",\n            GovernanceActionType::DeletePolicy => \"delete_policy\",\n            GovernanceActionType::ProposeKnowledge => \"propose_knowledge\",\n            GovernanceActionType::ApproveKnowledge => \"approve_knowledge\",\n            GovernanceActionType::EditKnowledge => \"edit_knowledge\",\n            GovernanceActionType::DeleteKnowledge => \"delete_knowledge\",\n            GovernanceActionType::PromoteMemory => \"promote_memory\",\n            GovernanceActionType::DeleteMemory => \"delete_memory\",\n            GovernanceActionType::AssignRole => \"assign_role\",\n            GovernanceActionType::RevokeRole => \"revoke_role\",\n            GovernanceActionType::ModifyGovernanceConfig => \"modify_governance_config\",\n            GovernanceActionType::ModifyMetaGovernance => \"modify_meta_governance\",\n        };\n        write!(f, \"{}\", s)\n    }\n}\n\nimpl std::str::FromStr for GovernanceActionType {\n    type Err = String;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        match s.to_lowercase().as_str() {\n            \"create_policy\" => Ok(GovernanceActionType::CreatePolicy),\n            \"approve_policy\" => Ok(GovernanceActionType::ApprovePolicy),\n            \"reject_policy\" => Ok(GovernanceActionType::RejectPolicy),\n            \"delete_policy\" => Ok(GovernanceActionType::DeletePolicy),\n            \"propose_knowledge\" => Ok(GovernanceActionType::ProposeKnowledge),\n            \"approve_knowledge\" => Ok(GovernanceActionType::ApproveKnowledge),\n            \"edit_knowledge\" => Ok(GovernanceActionType::EditKnowledge),\n            \"delete_knowledge\" => Ok(GovernanceActionType::DeleteKnowledge),\n            \"promote_memory\" => Ok(GovernanceActionType::PromoteMemory),\n            \"delete_memory\" => Ok(GovernanceActionType::DeleteMemory),\n            \"assign_role\" => Ok(GovernanceActionType::AssignRole),\n            \"revoke_role\" => Ok(GovernanceActionType::RevokeRole),\n            \"modify_governance_config\" => Ok(GovernanceActionType::ModifyGovernanceConfig),\n            \"modify_meta_governance\" => Ok(GovernanceActionType::ModifyMetaGovernance),\n            _ => Err(format!(\"Invalid governance action type: {}\", s)),\n        }\n    }\n}\n\n/// A meta-governance policy that controls who can govern at a specific layer.\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct MetaGovernancePolicy {\n    pub id: Uuid,\n    pub layer: GovernanceLayer,\n    pub scope_id: Option<Uuid>,\n    pub min_role_for_governance: RoleLevel,\n    /// Specific permissions for different action types\n    pub action_permissions: Vec<ActionPermission>,\n    /// Agent delegation rules for this layer\n    pub agent_delegation: AgentDelegationConfig,\n    /// Escalation configuration\n    pub escalation_config: EscalationConfig,\n    /// Whether this policy is active\n    pub active: bool,\n    /// Created timestamp\n    pub created_at: DateTime<Utc>,\n    /// Updated timestamp\n    pub updated_at: DateTime<Utc>,\n    /// Who created this policy\n    pub created_by: Uuid,\n}\n\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq, PartialOrd, Ord)]\n#[serde(rename_all = \"snake_case\")]\npub enum RoleLevel {\n    Viewer = 0,\n    Developer = 1,\n    TechLead = 2,\n    Architect = 3,\n    Admin = 4,\n}\n\nimpl Default for RoleLevel {\n    fn default() -> Self {\n        Self::Developer\n    }\n}\n\nimpl std::fmt::Display for RoleLevel {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            RoleLevel::Viewer => write!(f, \"viewer\"),\n            RoleLevel::Developer => write!(f, \"developer\"),\n            RoleLevel::TechLead => write!(f, \"techlead\"),\n            RoleLevel::Architect => write!(f, \"architect\"),\n            RoleLevel::Admin => write!(f, \"admin\"),\n        }\n    }\n}\n\nimpl std::str::FromStr for RoleLevel {\n    type Err = String;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        match s.to_lowercase().as_str() {\n            \"viewer\" => Ok(RoleLevel::Viewer),\n            \"developer\" => Ok(RoleLevel::Developer),\n            \"techlead\" | \"tech_lead\" => Ok(RoleLevel::TechLead),\n            \"architect\" => Ok(RoleLevel::Architect),\n            \"admin\" => Ok(RoleLevel::Admin),\n            _ => Err(format!(\n                \"Invalid role level: {}. Use: viewer, developer, techlead, architect, admin\",\n                s\n            )),\n        }\n    }\n}\n\n/// Permission configuration for a specific governance action.\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ActionPermission {\n    pub action: GovernanceActionType,\n    pub min_role: Option<RoleLevel>,\n    /// Whether agents can perform this action autonomously\n    pub agent_autonomous: bool,\n    /// Whether this action requires human confirmation even when agent is authorized\n    pub requires_human_confirmation: bool,\n    /// Risk levels where this action is restricted\n    pub restricted_risk_levels: Vec<RiskLevel>,\n}\n\n/// Configuration for AI agent delegation at a governance layer.\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AgentDelegationConfig {\n    /// Whether agents can act autonomously at this layer\n    pub autonomous_enabled: bool,\n    /// Maximum delegation depth from a human principal\n    pub max_delegation_depth: i32,\n    /// Capabilities agents can have at this layer\n    pub allowed_capabilities: Vec<AgentCapability>,\n    /// Actions that always require human confirmation (override autonomous)\n    pub human_confirmation_required: Vec<GovernanceActionType>,\n    /// Time limit for agent sessions (hours)\n    pub session_timeout_hours: i32,\n    /// Rate limits for agent actions\n    pub rate_limits: Option<AgentRateLimits>,\n}\n\nimpl Default for AgentDelegationConfig {\n    fn default() -> Self {\n        Self {\n            autonomous_enabled: true,\n            max_delegation_depth: 3,\n            allowed_capabilities: vec![\n                AgentCapability::MemoryRead,\n                AgentCapability::MemoryWrite,\n                AgentCapability::KnowledgeRead,\n                AgentCapability::KnowledgePropose,\n                AgentCapability::PolicyRead,\n                AgentCapability::PolicySimulate,\n                AgentCapability::GovernanceRead,\n                AgentCapability::GovernanceSubmit,\n                AgentCapability::OrgRead,\n            ],\n            human_confirmation_required: vec![\n                GovernanceActionType::DeletePolicy,\n                GovernanceActionType::DeleteKnowledge,\n                GovernanceActionType::ModifyGovernanceConfig,\n                GovernanceActionType::ModifyMetaGovernance,\n                GovernanceActionType::AssignRole,\n                GovernanceActionType::RevokeRole,\n            ],\n            session_timeout_hours: 24,\n            rate_limits: Some(AgentRateLimits::default()),\n        }\n    }\n}\n\n/// Agent capabilities that can be granted or restricted.\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum AgentCapability {\n    // Memory capabilities\n    MemoryRead,\n    MemoryWrite,\n    MemoryDelete,\n    MemoryPromote,\n    // Knowledge capabilities\n    KnowledgeRead,\n    KnowledgePropose,\n    KnowledgeEdit,\n    // Policy capabilities\n    PolicyRead,\n    PolicyCreate,\n    PolicySimulate,\n    // Governance capabilities\n    GovernanceRead,\n    GovernanceSubmit,\n    GovernanceApprove, // Rarely granted to agents\n    // Organization capabilities\n    OrgRead,\n    // Agent-to-agent capabilities\n    AgentRegister,\n    AgentDelegate,\n}\n\nimpl std::fmt::Display for AgentCapability {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        let s = match self {\n            AgentCapability::MemoryRead => \"memory:read\",\n            AgentCapability::MemoryWrite => \"memory:write\",\n            AgentCapability::MemoryDelete => \"memory:delete\",\n            AgentCapability::MemoryPromote => \"memory:promote\",\n            AgentCapability::KnowledgeRead => \"knowledge:read\",\n            AgentCapability::KnowledgePropose => \"knowledge:propose\",\n            AgentCapability::KnowledgeEdit => \"knowledge:edit\",\n            AgentCapability::PolicyRead => \"policy:read\",\n            AgentCapability::PolicyCreate => \"policy:create\",\n            AgentCapability::PolicySimulate => \"policy:simulate\",\n            AgentCapability::GovernanceRead => \"governance:read\",\n            AgentCapability::GovernanceSubmit => \"governance:submit\",\n            AgentCapability::GovernanceApprove => \"governance:approve\",\n            AgentCapability::OrgRead => \"org:read\",\n            AgentCapability::AgentRegister => \"agent:register\",\n            AgentCapability::AgentDelegate => \"agent:delegate\",\n        };\n        write!(f, \"{}\", s)\n    }\n}\n\nimpl std::str::FromStr for AgentCapability {\n    type Err = String;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        match s.to_lowercase().as_str() {\n            \"memory:read\" => Ok(AgentCapability::MemoryRead),\n            \"memory:write\" => Ok(AgentCapability::MemoryWrite),\n            \"memory:delete\" => Ok(AgentCapability::MemoryDelete),\n            \"memory:promote\" => Ok(AgentCapability::MemoryPromote),\n            \"knowledge:read\" => Ok(AgentCapability::KnowledgeRead),\n            \"knowledge:propose\" => Ok(AgentCapability::KnowledgePropose),\n            \"knowledge:edit\" => Ok(AgentCapability::KnowledgeEdit),\n            \"policy:read\" => Ok(AgentCapability::PolicyRead),\n            \"policy:create\" => Ok(AgentCapability::PolicyCreate),\n            \"policy:simulate\" => Ok(AgentCapability::PolicySimulate),\n            \"governance:read\" => Ok(AgentCapability::GovernanceRead),\n            \"governance:submit\" => Ok(AgentCapability::GovernanceSubmit),\n            \"governance:approve\" => Ok(AgentCapability::GovernanceApprove),\n            \"org:read\" => Ok(AgentCapability::OrgRead),\n            \"agent:register\" => Ok(AgentCapability::AgentRegister),\n            \"agent:delegate\" => Ok(AgentCapability::AgentDelegate),\n            _ => Err(format!(\"Invalid agent capability: {}\", s)),\n        }\n    }\n}\n\n/// Rate limits for agent actions to prevent abuse.\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AgentRateLimits {\n    /// Maximum actions per minute\n    pub actions_per_minute: i32,\n    /// Maximum actions per hour\n    pub actions_per_hour: i32,\n    /// Maximum governance submissions per day\n    pub governance_submissions_per_day: i32,\n    /// Maximum memory writes per hour\n    pub memory_writes_per_hour: i32,\n}\n\nimpl Default for AgentRateLimits {\n    fn default() -> Self {\n        Self {\n            actions_per_minute: 30,\n            actions_per_hour: 500,\n            governance_submissions_per_day: 10,\n            memory_writes_per_hour: 100,\n        }\n    }\n}\n\n/// Configuration for escalation when approvers are unavailable.\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct EscalationConfig {\n    /// Whether escalation is enabled\n    pub enabled: bool,\n    /// Hours to wait before first escalation\n    pub initial_timeout_hours: i32,\n    /// Escalation tiers (ordered by priority)\n    pub tiers: Vec<EscalationTier>,\n    /// What happens if all escalation tiers fail\n    pub fallback_action: EscalationFallback,\n    /// Send reminders before escalation\n    pub reminder_intervals_hours: Vec<i32>,\n}\n\nimpl Default for EscalationConfig {\n    fn default() -> Self {\n        Self {\n            enabled: true,\n            initial_timeout_hours: 24,\n            tiers: vec![\n                EscalationTier {\n                    name: \"Team Lead Escalation\".to_string(),\n                    timeout_hours: 12,\n                    escalate_to: EscalationTarget::RoleInScope(RoleLevel::TechLead),\n                    notification_channels: vec![NotificationChannel::Email],\n                },\n                EscalationTier {\n                    name: \"Architect Escalation\".to_string(),\n                    timeout_hours: 24,\n                    escalate_to: EscalationTarget::RoleInScope(RoleLevel::Architect),\n                    notification_channels: vec![\n                        NotificationChannel::Email,\n                        NotificationChannel::Slack,\n                    ],\n                },\n                EscalationTier {\n                    name: \"Admin Escalation\".to_string(),\n                    timeout_hours: 48,\n                    escalate_to: EscalationTarget::RoleInScope(RoleLevel::Admin),\n                    notification_channels: vec![\n                        NotificationChannel::Email,\n                        NotificationChannel::Slack,\n                        NotificationChannel::PagerDuty,\n                    ],\n                },\n            ],\n            fallback_action: EscalationFallback::ExpireRequest,\n            reminder_intervals_hours: vec![12, 18, 23],\n        }\n    }\n}\n\n/// A tier in the escalation chain.\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct EscalationTier {\n    /// Human-readable name for this tier\n    pub name: String,\n    /// Hours to wait at this tier before moving to next\n    pub timeout_hours: i32,\n    /// Who to escalate to\n    pub escalate_to: EscalationTarget,\n    /// How to notify escalation targets\n    pub notification_channels: Vec<NotificationChannel>,\n}\n\n/// Target for escalation.\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(rename_all = \"snake_case\")]\npub enum EscalationTarget {\n    RoleInScope(RoleLevel),\n    SpecificUser(Uuid),\n    ParentScope,\n    CustomGroup(String),\n}\n\n/// What happens when all escalation tiers fail.\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum EscalationFallback {\n    /// Expire the request (default)\n    ExpireRequest,\n    /// Auto-approve (risky, use only for low-risk items)\n    AutoApprove,\n    /// Keep waiting indefinitely\n    WaitIndefinitely,\n    /// Notify emergency contacts\n    NotifyEmergency,\n}\n\n/// Notification channels for escalation.\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum NotificationChannel {\n    Email,\n    Slack,\n    MsTeams,\n    PagerDuty,\n    Webhook,\n}\n\n/// A request for human confirmation of an agent action.\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct HumanConfirmationRequest {\n    pub id: Uuid,\n    /// The agent requesting confirmation\n    pub agent_id: Uuid,\n    /// The action the agent wants to perform\n    pub action: GovernanceActionType,\n    /// Human-readable description of what the agent wants to do\n    pub action_description: String,\n    /// The target of the action (policy ID, knowledge ID, etc.)\n    pub target_type: String,\n    pub target_id: Option<String>,\n    /// Risk assessment\n    pub risk_level: RiskLevel,\n    /// Why this requires confirmation\n    pub confirmation_reason: ConfirmationReason,\n    /// Context about the agent's session\n    pub agent_context: serde_json::Value,\n    /// Users who can approve this request\n    pub authorized_approvers: Vec<Uuid>,\n    /// Status of the confirmation request\n    pub status: ConfirmationStatus,\n    /// Timeout for confirmation (after which request is auto-denied)\n    pub expires_at: DateTime<Utc>,\n    /// Created timestamp\n    pub created_at: DateTime<Utc>,\n    /// Resolution timestamp\n    pub resolved_at: Option<DateTime<Utc>>,\n    /// Who resolved (if human)\n    pub resolved_by: Option<Uuid>,\n    /// Resolution comment\n    pub resolution_comment: Option<String>,\n}\n\n/// Why human confirmation is required.\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum ConfirmationReason {\n    /// Action is in the always-confirm list\n    PolicyRequired,\n    /// Action has high risk level\n    HighRisk,\n    /// Agent delegation depth exceeded soft limit\n    DelegationDepthWarning,\n    /// Rate limit approaching\n    RateLimitWarning,\n    /// Action affects multiple scopes\n    CrossScopeAction,\n    /// First time agent performs this action type\n    FirstTimeAction,\n    /// Manual request by agent\n    AgentRequested,\n}\n\nimpl std::fmt::Display for ConfirmationReason {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            ConfirmationReason::PolicyRequired => write!(f, \"Policy requires human confirmation\"),\n            ConfirmationReason::HighRisk => write!(f, \"Action classified as high risk\"),\n            ConfirmationReason::DelegationDepthWarning => {\n                write!(f, \"Agent delegation depth near limit\")\n            }\n            ConfirmationReason::RateLimitWarning => write!(f, \"Agent approaching rate limit\"),\n            ConfirmationReason::CrossScopeAction => write!(f, \"Action affects multiple scopes\"),\n            ConfirmationReason::FirstTimeAction => {\n                write!(f, \"First time agent performs this action\")\n            }\n            ConfirmationReason::AgentRequested => write!(f, \"Agent requested human oversight\"),\n        }\n    }\n}\n\n/// Status of a human confirmation request.\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum ConfirmationStatus {\n    Pending,\n    Approved,\n    Denied,\n    Expired,\n    Cancelled,\n}\n\nimpl std::fmt::Display for ConfirmationStatus {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            ConfirmationStatus::Pending => write!(f, \"pending\"),\n            ConfirmationStatus::Approved => write!(f, \"approved\"),\n            ConfirmationStatus::Denied => write!(f, \"denied\"),\n            ConfirmationStatus::Expired => write!(f, \"expired\"),\n            ConfirmationStatus::Cancelled => write!(f, \"cancelled\"),\n        }\n    }\n}\n\nimpl std::str::FromStr for ConfirmationStatus {\n    type Err = String;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        match s.to_lowercase().as_str() {\n            \"pending\" => Ok(ConfirmationStatus::Pending),\n            \"approved\" => Ok(ConfirmationStatus::Approved),\n            \"denied\" => Ok(ConfirmationStatus::Denied),\n            \"expired\" => Ok(ConfirmationStatus::Expired),\n            \"cancelled\" => Ok(ConfirmationStatus::Cancelled),\n            _ => Err(format!(\"Invalid confirmation status: {}\", s)),\n        }\n    }\n}\n\npub fn create_default_policies() -> Vec<MetaGovernancePolicy> {\n    let now = Utc::now();\n    let system_user = Uuid::nil();\n\n    vec![\n        MetaGovernancePolicy {\n            id: Uuid::new_v4(),\n            layer: GovernanceLayer::Company,\n            scope_id: None,\n            min_role_for_governance: RoleLevel::Admin,\n            action_permissions: vec![\n                ActionPermission {\n                    action: GovernanceActionType::CreatePolicy,\n                    min_role: Some(RoleLevel::Architect),\n                    agent_autonomous: false,\n                    requires_human_confirmation: true,\n                    restricted_risk_levels: vec![],\n                },\n                ActionPermission {\n                    action: GovernanceActionType::ApprovePolicy,\n                    min_role: Some(RoleLevel::Admin),\n                    agent_autonomous: false,\n                    requires_human_confirmation: true,\n                    restricted_risk_levels: vec![],\n                },\n                ActionPermission {\n                    action: GovernanceActionType::ModifyMetaGovernance,\n                    min_role: Some(RoleLevel::Admin),\n                    agent_autonomous: false,\n                    requires_human_confirmation: true,\n                    restricted_risk_levels: vec![],\n                },\n            ],\n            agent_delegation: AgentDelegationConfig {\n                autonomous_enabled: false,\n                max_delegation_depth: 1,\n                allowed_capabilities: vec![\n                    AgentCapability::KnowledgeRead,\n                    AgentCapability::PolicyRead,\n                    AgentCapability::GovernanceRead,\n                    AgentCapability::OrgRead,\n                ],\n                human_confirmation_required: vec![\n                    GovernanceActionType::CreatePolicy,\n                    GovernanceActionType::ApprovePolicy,\n                    GovernanceActionType::RejectPolicy,\n                    GovernanceActionType::DeletePolicy,\n                    GovernanceActionType::ProposeKnowledge,\n                    GovernanceActionType::ApproveKnowledge,\n                    GovernanceActionType::EditKnowledge,\n                    GovernanceActionType::DeleteKnowledge,\n                    GovernanceActionType::AssignRole,\n                    GovernanceActionType::RevokeRole,\n                    GovernanceActionType::ModifyGovernanceConfig,\n                    GovernanceActionType::ModifyMetaGovernance,\n                ],\n                session_timeout_hours: 8,\n                rate_limits: Some(AgentRateLimits {\n                    actions_per_minute: 10,\n                    actions_per_hour: 100,\n                    governance_submissions_per_day: 2,\n                    memory_writes_per_hour: 20,\n                }),\n            },\n            escalation_config: EscalationConfig {\n                enabled: true,\n                initial_timeout_hours: 12,\n                tiers: vec![EscalationTier {\n                    name: \"Admin Escalation\".to_string(),\n                    timeout_hours: 12,\n                    escalate_to: EscalationTarget::RoleInScope(RoleLevel::Admin),\n                    notification_channels: vec![\n                        NotificationChannel::Email,\n                        NotificationChannel::Slack,\n                        NotificationChannel::PagerDuty,\n                    ],\n                }],\n                fallback_action: EscalationFallback::NotifyEmergency,\n                reminder_intervals_hours: vec![6, 10],\n            },\n            active: true,\n            created_at: now,\n            updated_at: now,\n            created_by: system_user,\n        },\n        MetaGovernancePolicy {\n            id: Uuid::new_v4(),\n            layer: GovernanceLayer::Org,\n            scope_id: None,\n            min_role_for_governance: RoleLevel::Architect,\n            action_permissions: vec![\n                ActionPermission {\n                    action: GovernanceActionType::CreatePolicy,\n                    min_role: Some(RoleLevel::TechLead),\n                    agent_autonomous: false,\n                    requires_human_confirmation: true,\n                    restricted_risk_levels: vec![RiskLevel::Critical],\n                },\n                ActionPermission {\n                    action: GovernanceActionType::ApprovePolicy,\n                    min_role: Some(RoleLevel::Architect),\n                    agent_autonomous: false,\n                    requires_human_confirmation: true,\n                    restricted_risk_levels: vec![],\n                },\n                ActionPermission {\n                    action: GovernanceActionType::ProposeKnowledge,\n                    min_role: Some(RoleLevel::Developer),\n                    agent_autonomous: true,\n                    requires_human_confirmation: false,\n                    restricted_risk_levels: vec![RiskLevel::High, RiskLevel::Critical],\n                },\n            ],\n            agent_delegation: AgentDelegationConfig {\n                autonomous_enabled: true,\n                max_delegation_depth: 2,\n                allowed_capabilities: vec![\n                    AgentCapability::MemoryRead,\n                    AgentCapability::MemoryWrite,\n                    AgentCapability::KnowledgeRead,\n                    AgentCapability::KnowledgePropose,\n                    AgentCapability::PolicyRead,\n                    AgentCapability::PolicySimulate,\n                    AgentCapability::GovernanceRead,\n                    AgentCapability::GovernanceSubmit,\n                    AgentCapability::OrgRead,\n                ],\n                human_confirmation_required: vec![\n                    GovernanceActionType::DeletePolicy,\n                    GovernanceActionType::DeleteKnowledge,\n                    GovernanceActionType::AssignRole,\n                    GovernanceActionType::RevokeRole,\n                    GovernanceActionType::ModifyGovernanceConfig,\n                ],\n                session_timeout_hours: 12,\n                rate_limits: Some(AgentRateLimits {\n                    actions_per_minute: 20,\n                    actions_per_hour: 300,\n                    governance_submissions_per_day: 5,\n                    memory_writes_per_hour: 50,\n                }),\n            },\n            escalation_config: EscalationConfig::default(),\n            active: true,\n            created_at: now,\n            updated_at: now,\n            created_by: system_user,\n        },\n        MetaGovernancePolicy {\n            id: Uuid::new_v4(),\n            layer: GovernanceLayer::Team,\n            scope_id: None,\n            min_role_for_governance: RoleLevel::TechLead,\n            action_permissions: vec![\n                ActionPermission {\n                    action: GovernanceActionType::CreatePolicy,\n                    min_role: Some(RoleLevel::Developer),\n                    agent_autonomous: true,\n                    requires_human_confirmation: false,\n                    restricted_risk_levels: vec![RiskLevel::High, RiskLevel::Critical],\n                },\n                ActionPermission {\n                    action: GovernanceActionType::ApprovePolicy,\n                    min_role: Some(RoleLevel::TechLead),\n                    agent_autonomous: false,\n                    requires_human_confirmation: true,\n                    restricted_risk_levels: vec![],\n                },\n                ActionPermission {\n                    action: GovernanceActionType::ProposeKnowledge,\n                    min_role: Some(RoleLevel::Developer),\n                    agent_autonomous: true,\n                    requires_human_confirmation: false,\n                    restricted_risk_levels: vec![RiskLevel::Critical],\n                },\n                ActionPermission {\n                    action: GovernanceActionType::PromoteMemory,\n                    min_role: Some(RoleLevel::Developer),\n                    agent_autonomous: true,\n                    requires_human_confirmation: false,\n                    restricted_risk_levels: vec![],\n                },\n            ],\n            agent_delegation: AgentDelegationConfig {\n                autonomous_enabled: true,\n                max_delegation_depth: 3,\n                allowed_capabilities: vec![\n                    AgentCapability::MemoryRead,\n                    AgentCapability::MemoryWrite,\n                    AgentCapability::MemoryPromote,\n                    AgentCapability::KnowledgeRead,\n                    AgentCapability::KnowledgePropose,\n                    AgentCapability::PolicyRead,\n                    AgentCapability::PolicyCreate,\n                    AgentCapability::PolicySimulate,\n                    AgentCapability::GovernanceRead,\n                    AgentCapability::GovernanceSubmit,\n                    AgentCapability::OrgRead,\n                ],\n                human_confirmation_required: vec![\n                    GovernanceActionType::DeletePolicy,\n                    GovernanceActionType::DeleteKnowledge,\n                    GovernanceActionType::DeleteMemory,\n                    GovernanceActionType::ModifyGovernanceConfig,\n                ],\n                session_timeout_hours: 24,\n                rate_limits: Some(AgentRateLimits::default()),\n            },\n            escalation_config: EscalationConfig::default(),\n            active: true,\n            created_at: now,\n            updated_at: now,\n            created_by: system_user,\n        },\n        MetaGovernancePolicy {\n            id: Uuid::new_v4(),\n            layer: GovernanceLayer::Project,\n            scope_id: None,\n            min_role_for_governance: RoleLevel::Developer,\n            action_permissions: vec![\n                ActionPermission {\n                    action: GovernanceActionType::CreatePolicy,\n                    min_role: Some(RoleLevel::Developer),\n                    agent_autonomous: true,\n                    requires_human_confirmation: false,\n                    restricted_risk_levels: vec![RiskLevel::Critical],\n                },\n                ActionPermission {\n                    action: GovernanceActionType::ApprovePolicy,\n                    min_role: Some(RoleLevel::Developer),\n                    agent_autonomous: false,\n                    requires_human_confirmation: true,\n                    restricted_risk_levels: vec![RiskLevel::High, RiskLevel::Critical],\n                },\n                ActionPermission {\n                    action: GovernanceActionType::ProposeKnowledge,\n                    min_role: Some(RoleLevel::Developer),\n                    agent_autonomous: true,\n                    requires_human_confirmation: false,\n                    restricted_risk_levels: vec![],\n                },\n                ActionPermission {\n                    action: GovernanceActionType::ApproveKnowledge,\n                    min_role: Some(RoleLevel::Developer),\n                    agent_autonomous: true,\n                    requires_human_confirmation: false,\n                    restricted_risk_levels: vec![RiskLevel::High, RiskLevel::Critical],\n                },\n                ActionPermission {\n                    action: GovernanceActionType::PromoteMemory,\n                    min_role: Some(RoleLevel::Developer),\n                    agent_autonomous: true,\n                    requires_human_confirmation: false,\n                    restricted_risk_levels: vec![],\n                },\n            ],\n            agent_delegation: AgentDelegationConfig {\n                autonomous_enabled: true,\n                max_delegation_depth: 3,\n                allowed_capabilities: vec![\n                    AgentCapability::MemoryRead,\n                    AgentCapability::MemoryWrite,\n                    AgentCapability::MemoryDelete,\n                    AgentCapability::MemoryPromote,\n                    AgentCapability::KnowledgeRead,\n                    AgentCapability::KnowledgePropose,\n                    AgentCapability::KnowledgeEdit,\n                    AgentCapability::PolicyRead,\n                    AgentCapability::PolicyCreate,\n                    AgentCapability::PolicySimulate,\n                    AgentCapability::GovernanceRead,\n                    AgentCapability::GovernanceSubmit,\n                    AgentCapability::OrgRead,\n                    AgentCapability::AgentRegister,\n                    AgentCapability::AgentDelegate,\n                ],\n                human_confirmation_required: vec![\n                    GovernanceActionType::DeletePolicy,\n                    GovernanceActionType::ModifyGovernanceConfig,\n                ],\n                session_timeout_hours: 48,\n                rate_limits: Some(AgentRateLimits {\n                    actions_per_minute: 60,\n                    actions_per_hour: 1000,\n                    governance_submissions_per_day: 20,\n                    memory_writes_per_hour: 200,\n                }),\n            },\n            escalation_config: EscalationConfig {\n                enabled: true,\n                initial_timeout_hours: 48,\n                tiers: vec![EscalationTier {\n                    name: \"Team Escalation\".to_string(),\n                    timeout_hours: 24,\n                    escalate_to: EscalationTarget::ParentScope,\n                    notification_channels: vec![NotificationChannel::Email],\n                }],\n                fallback_action: EscalationFallback::ExpireRequest,\n                reminder_intervals_hours: vec![24, 36],\n            },\n            active: true,\n            created_at: now,\n            updated_at: now,\n            created_by: system_user,\n        },\n    ]\n}\n\n/// Result of a meta-governance authorization check.\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AuthorizationResult {\n    pub allowed: bool,\n    pub reason: String,\n    pub requires_human_confirmation: bool,\n    pub escalation_required: bool,\n    pub warnings: Vec<String>,\n}\n\nimpl MetaGovernancePolicy {\n    pub fn check_authorization(\n        &self,\n        principal_type: PrincipalType,\n        principal_role: RoleLevel,\n        action: GovernanceActionType,\n        risk_level: RiskLevel,\n        delegation_depth: Option<i32>,\n    ) -> AuthorizationResult {\n        let mut warnings = Vec::new();\n        let mut requires_human_confirmation = false;\n\n        let action_permission = self.action_permissions.iter().find(|p| p.action == action);\n\n        let min_role = action_permission\n            .and_then(|p| p.min_role)\n            .unwrap_or(self.min_role_for_governance);\n\n        if principal_role < min_role {\n            return AuthorizationResult {\n                allowed: false,\n                reason: format!(\n                    \"Role {} is insufficient. Minimum required: {}\",\n                    principal_role, min_role\n                ),\n                requires_human_confirmation: false,\n                escalation_required: false,\n                warnings: vec![],\n            };\n        }\n\n        if let Some(permission) = action_permission {\n            if permission.restricted_risk_levels.contains(&risk_level) {\n                return AuthorizationResult {\n                    allowed: false,\n                    reason: format!(\n                        \"Action {} is restricted at risk level {}\",\n                        action, risk_level\n                    ),\n                    requires_human_confirmation: false,\n                    escalation_required: false,\n                    warnings: vec![],\n                };\n            }\n\n            if permission.requires_human_confirmation {\n                requires_human_confirmation = true;\n            }\n        }\n\n        if principal_type == PrincipalType::Agent {\n            let delegation = &self.agent_delegation;\n\n            if !delegation.autonomous_enabled {\n                return AuthorizationResult {\n                    allowed: false,\n                    reason: format!(\"Agents cannot act autonomously at {} layer\", self.layer),\n                    requires_human_confirmation: true,\n                    escalation_required: false,\n                    warnings: vec![],\n                };\n            }\n\n            if let Some(depth) = delegation_depth {\n                if depth > delegation.max_delegation_depth {\n                    return AuthorizationResult {\n                        allowed: false,\n                        reason: format!(\n                            \"Delegation depth {} exceeds maximum {} for {} layer\",\n                            depth, delegation.max_delegation_depth, self.layer\n                        ),\n                        requires_human_confirmation: true,\n                        escalation_required: false,\n                        warnings: vec![],\n                    };\n                }\n\n                if depth == delegation.max_delegation_depth {\n                    warnings.push(format!(\n                        \"Delegation depth at maximum ({}). Further delegation not allowed.\",\n                        depth\n                    ));\n                }\n            }\n\n            if delegation.human_confirmation_required.contains(&action) {\n                requires_human_confirmation = true;\n            }\n\n            if let Some(permission) = action_permission {\n                if !permission.agent_autonomous && !requires_human_confirmation {\n                    requires_human_confirmation = true;\n                    warnings.push(format!(\n                        \"Action {} requires human confirmation when performed by agents\",\n                        action\n                    ));\n                }\n            }\n        }\n\n        AuthorizationResult {\n            allowed: true,\n            reason: \"Authorized\".to_string(),\n            requires_human_confirmation,\n            escalation_required: false,\n            warnings,\n        }\n    }\n}\n\n#[derive(Debug, Clone, FromRow)]\nstruct MetaGovernancePolicyRow {\n    id: Uuid,\n    layer: String,\n    scope_id: Option<Uuid>,\n    min_role_for_governance: String,\n    action_permissions: serde_json::Value,\n    agent_delegation: serde_json::Value,\n    escalation_config: serde_json::Value,\n    active: bool,\n    created_at: DateTime<Utc>,\n    updated_at: DateTime<Utc>,\n    created_by: Uuid,\n}\n\nimpl From<MetaGovernancePolicyRow> for MetaGovernancePolicy {\n    fn from(row: MetaGovernancePolicyRow) -> Self {\n        Self {\n            id: row.id,\n            layer: row.layer.parse().unwrap_or(GovernanceLayer::Project),\n            scope_id: row.scope_id,\n            min_role_for_governance: row\n                .min_role_for_governance\n                .parse()\n                .unwrap_or(RoleLevel::Developer),\n            action_permissions: serde_json::from_value(row.action_permissions).unwrap_or_default(),\n            agent_delegation: serde_json::from_value(row.agent_delegation)\n                .unwrap_or_else(|_| AgentDelegationConfig::default()),\n            escalation_config: serde_json::from_value(row.escalation_config)\n                .unwrap_or_else(|_| EscalationConfig::default()),\n            active: row.active,\n            created_at: row.created_at,\n            updated_at: row.updated_at,\n            created_by: row.created_by,\n        }\n    }\n}\n\n#[derive(Debug, Clone, FromRow)]\nstruct ConfirmationRequestRow {\n    id: Uuid,\n    agent_id: Uuid,\n    action: String,\n    action_description: String,\n    target_type: String,\n    target_id: Option<String>,\n    risk_level: String,\n    confirmation_reason: String,\n    agent_context: serde_json::Value,\n    authorized_approvers: serde_json::Value,\n    status: String,\n    expires_at: DateTime<Utc>,\n    created_at: DateTime<Utc>,\n    resolved_at: Option<DateTime<Utc>>,\n    resolved_by: Option<Uuid>,\n    resolution_comment: Option<String>,\n}\n\n/// Storage for meta-governance policies and human confirmation requests.\npub struct MetaGovernanceStorage {\n    pool: PgPool,\n}\n\nimpl MetaGovernanceStorage {\n    pub fn new(pool: PgPool) -> Self {\n        Self { pool }\n    }\n\n    pub async fn get_effective_policy(\n        &self,\n        layer: GovernanceLayer,\n        scope_id: Option<Uuid>,\n    ) -> Result<Option<MetaGovernancePolicy>, sqlx::Error> {\n        if let Some(sid) = scope_id {\n            let row: Option<MetaGovernancePolicyRow> = sqlx::query_as(\n                r#\"\n                SELECT * FROM meta_governance_policies\n                WHERE layer = $1 AND scope_id = $2 AND active = true\n                ORDER BY updated_at DESC\n                LIMIT 1\n                \"#,\n            )\n            .bind(layer.to_string())\n            .bind(sid)\n            .fetch_optional(&self.pool)\n            .await?;\n\n            if let Some(row) = row {\n                return Ok(Some(row.into()));\n            }\n        }\n\n        let row: Option<MetaGovernancePolicyRow> = sqlx::query_as(\n            r#\"\n            SELECT * FROM meta_governance_policies\n            WHERE layer = $1 AND scope_id IS NULL AND active = true\n            ORDER BY updated_at DESC\n            LIMIT 1\n            \"#,\n        )\n        .bind(layer.to_string())\n        .fetch_optional(&self.pool)\n        .await?;\n\n        Ok(row.map(Into::into))\n    }\n\n    /// Create or update a meta-governance policy.\n    pub async fn upsert_policy(&self, policy: &MetaGovernancePolicy) -> Result<Uuid, sqlx::Error> {\n        let row: (Uuid,) = sqlx::query_as(\n            r#\"\n            INSERT INTO meta_governance_policies (\n                id, layer, scope_id, min_role_for_governance,\n                action_permissions, agent_delegation, escalation_config,\n                active, created_at, updated_at, created_by\n            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)\n            ON CONFLICT (layer, scope_id) WHERE scope_id IS NOT NULL\n            DO UPDATE SET\n                min_role_for_governance = EXCLUDED.min_role_for_governance,\n                action_permissions = EXCLUDED.action_permissions,\n                agent_delegation = EXCLUDED.agent_delegation,\n                escalation_config = EXCLUDED.escalation_config,\n                active = EXCLUDED.active,\n                updated_at = NOW()\n            RETURNING id\n            \"#,\n        )\n        .bind(policy.id)\n        .bind(policy.layer.to_string())\n        .bind(policy.scope_id)\n        .bind(policy.min_role_for_governance.to_string())\n        .bind(serde_json::to_value(&policy.action_permissions).unwrap_or_default())\n        .bind(serde_json::to_value(&policy.agent_delegation).unwrap_or_default())\n        .bind(serde_json::to_value(&policy.escalation_config).unwrap_or_default())\n        .bind(policy.active)\n        .bind(policy.created_at)\n        .bind(Utc::now())\n        .bind(policy.created_by)\n        .fetch_one(&self.pool)\n        .await?;\n\n        Ok(row.0)\n    }\n\n    /// Create a human confirmation request.\n    pub async fn create_confirmation_request(\n        &self,\n        request: &HumanConfirmationRequest,\n    ) -> Result<Uuid, sqlx::Error> {\n        let row: (Uuid,) = sqlx::query_as(\n            r#\"\n            INSERT INTO human_confirmation_requests (\n                id, agent_id, action, action_description,\n                target_type, target_id, risk_level, confirmation_reason,\n                agent_context, authorized_approvers, status,\n                expires_at, created_at\n            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13)\n            RETURNING id\n            \"#,\n        )\n        .bind(request.id)\n        .bind(request.agent_id)\n        .bind(request.action.to_string())\n        .bind(&request.action_description)\n        .bind(&request.target_type)\n        .bind(&request.target_id)\n        .bind(request.risk_level.to_string())\n        .bind(format!(\"{:?}\", request.confirmation_reason))\n        .bind(&request.agent_context)\n        .bind(serde_json::to_value(&request.authorized_approvers).unwrap_or_default())\n        .bind(request.status.to_string())\n        .bind(request.expires_at)\n        .bind(request.created_at)\n        .fetch_one(&self.pool)\n        .await?;\n\n        Ok(row.0)\n    }\n\n    /// Get a pending confirmation request.\n    pub async fn get_confirmation_request(\n        &self,\n        request_id: Uuid,\n    ) -> Result<Option<HumanConfirmationRequest>, sqlx::Error> {\n        let row: Option<ConfirmationRequestRow> =\n            sqlx::query_as(\"SELECT * FROM human_confirmation_requests WHERE id = $1\")\n                .bind(request_id)\n                .fetch_optional(&self.pool)\n                .await?;\n\n        Ok(row.map(|r| HumanConfirmationRequest {\n            id: r.id,\n            agent_id: r.agent_id,\n            action: r\n                .action\n                .parse()\n                .unwrap_or(GovernanceActionType::CreatePolicy),\n            action_description: r.action_description,\n            target_type: r.target_type,\n            target_id: r.target_id,\n            risk_level: r.risk_level.parse().unwrap_or_default(),\n            confirmation_reason: match r.confirmation_reason.as_str() {\n                \"PolicyRequired\" => ConfirmationReason::PolicyRequired,\n                \"HighRisk\" => ConfirmationReason::HighRisk,\n                \"DelegationDepthWarning\" => ConfirmationReason::DelegationDepthWarning,\n                \"RateLimitWarning\" => ConfirmationReason::RateLimitWarning,\n                \"CrossScopeAction\" => ConfirmationReason::CrossScopeAction,\n                \"FirstTimeAction\" => ConfirmationReason::FirstTimeAction,\n                _ => ConfirmationReason::AgentRequested,\n            },\n            agent_context: r.agent_context,\n            authorized_approvers: serde_json::from_value(r.authorized_approvers)\n                .unwrap_or_default(),\n            status: r.status.parse().unwrap_or(ConfirmationStatus::Pending),\n            expires_at: r.expires_at,\n            created_at: r.created_at,\n            resolved_at: r.resolved_at,\n            resolved_by: r.resolved_by,\n            resolution_comment: r.resolution_comment,\n        }))\n    }\n\n    /// List pending confirmation requests for an approver.\n    pub async fn list_pending_confirmations(\n        &self,\n        approver_id: Uuid,\n        limit: i32,\n    ) -> Result<Vec<HumanConfirmationRequest>, sqlx::Error> {\n        let rows: Vec<ConfirmationRequestRow> = sqlx::query_as(\n            r#\"\n            SELECT * FROM human_confirmation_requests\n            WHERE status = 'pending'\n              AND expires_at > NOW()\n              AND authorized_approvers @> $1::jsonb\n            ORDER BY created_at DESC\n            LIMIT $2\n            \"#,\n        )\n        .bind(serde_json::json!([approver_id]))\n        .bind(limit as i64)\n        .fetch_all(&self.pool)\n        .await?;\n\n        Ok(rows\n            .into_iter()\n            .map(|r| HumanConfirmationRequest {\n                id: r.id,\n                agent_id: r.agent_id,\n                action: r\n                    .action\n                    .parse()\n                    .unwrap_or(GovernanceActionType::CreatePolicy),\n                action_description: r.action_description,\n                target_type: r.target_type,\n                target_id: r.target_id,\n                risk_level: r.risk_level.parse().unwrap_or_default(),\n                confirmation_reason: match r.confirmation_reason.as_str() {\n                    \"PolicyRequired\" => ConfirmationReason::PolicyRequired,\n                    \"HighRisk\" => ConfirmationReason::HighRisk,\n                    \"DelegationDepthWarning\" => ConfirmationReason::DelegationDepthWarning,\n                    \"RateLimitWarning\" => ConfirmationReason::RateLimitWarning,\n                    \"CrossScopeAction\" => ConfirmationReason::CrossScopeAction,\n                    \"FirstTimeAction\" => ConfirmationReason::FirstTimeAction,\n                    _ => ConfirmationReason::AgentRequested,\n                },\n                agent_context: r.agent_context,\n                authorized_approvers: serde_json::from_value(r.authorized_approvers)\n                    .unwrap_or_default(),\n                status: r.status.parse().unwrap_or(ConfirmationStatus::Pending),\n                expires_at: r.expires_at,\n                created_at: r.created_at,\n                resolved_at: r.resolved_at,\n                resolved_by: r.resolved_by,\n                resolution_comment: r.resolution_comment,\n            })\n            .collect())\n    }\n\n    /// Resolve a confirmation request (approve/deny).\n    pub async fn resolve_confirmation(\n        &self,\n        request_id: Uuid,\n        approved: bool,\n        resolved_by: Uuid,\n        comment: Option<String>,\n    ) -> Result<(), sqlx::Error> {\n        let status = if approved {\n            ConfirmationStatus::Approved\n        } else {\n            ConfirmationStatus::Denied\n        };\n\n        sqlx::query(\n            r#\"\n            UPDATE human_confirmation_requests\n            SET status = $2,\n                resolved_at = NOW(),\n                resolved_by = $3,\n                resolution_comment = $4\n            WHERE id = $1 AND status = 'pending'\n            \"#,\n        )\n        .bind(request_id)\n        .bind(status.to_string())\n        .bind(resolved_by)\n        .bind(comment)\n        .execute(&self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    /// Expire old confirmation requests.\n    pub async fn expire_old_requests(&self) -> Result<i64, sqlx::Error> {\n        let result = sqlx::query(\n            r#\"\n            UPDATE human_confirmation_requests\n            SET status = 'expired'\n            WHERE status = 'pending' AND expires_at < NOW()\n            \"#,\n        )\n        .execute(&self.pool)\n        .await?;\n\n        Ok(result.rows_affected() as i64)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_governance_layer_display() {\n        assert_eq!(GovernanceLayer::Company.to_string(), \"company\");\n        assert_eq!(GovernanceLayer::Org.to_string(), \"org\");\n        assert_eq!(GovernanceLayer::Team.to_string(), \"team\");\n        assert_eq!(GovernanceLayer::Project.to_string(), \"project\");\n    }\n\n    #[test]\n    fn test_governance_layer_parse() {\n        assert_eq!(\n            \"company\".parse::<GovernanceLayer>().unwrap(),\n            GovernanceLayer::Company\n        );\n        assert_eq!(\n            \"organization\".parse::<GovernanceLayer>().unwrap(),\n            GovernanceLayer::Org\n        );\n        assert_eq!(\n            \"Team\".parse::<GovernanceLayer>().unwrap(),\n            GovernanceLayer::Team\n        );\n        assert!(\"invalid\".parse::<GovernanceLayer>().is_err());\n    }\n\n    #[test]\n    fn test_governance_role_ordering() {\n        assert!(RoleLevel::Viewer < RoleLevel::Developer);\n        assert!(RoleLevel::Developer < RoleLevel::TechLead);\n        assert!(RoleLevel::TechLead < RoleLevel::Architect);\n        assert!(RoleLevel::Architect < RoleLevel::Admin);\n    }\n\n    #[test]\n    fn test_agent_capability_display() {\n        assert_eq!(AgentCapability::MemoryRead.to_string(), \"memory:read\");\n        assert_eq!(\n            AgentCapability::KnowledgePropose.to_string(),\n            \"knowledge:propose\"\n        );\n        assert_eq!(\n            AgentCapability::PolicySimulate.to_string(),\n            \"policy:simulate\"\n        );\n    }\n\n    #[test]\n    fn test_agent_capability_parse() {\n        assert_eq!(\n            \"memory:read\".parse::<AgentCapability>().unwrap(),\n            AgentCapability::MemoryRead\n        );\n        assert_eq!(\n            \"governance:approve\".parse::<AgentCapability>().unwrap(),\n            AgentCapability::GovernanceApprove\n        );\n        assert!(\"invalid:cap\".parse::<AgentCapability>().is_err());\n    }\n\n    #[test]\n    fn test_default_policies_created() {\n        let policies = create_default_policies();\n        assert_eq!(policies.len(), 4);\n\n        let layers: Vec<_> = policies.iter().map(|p| p.layer).collect();\n        assert!(layers.contains(&GovernanceLayer::Company));\n        assert!(layers.contains(&GovernanceLayer::Org));\n        assert!(layers.contains(&GovernanceLayer::Team));\n        assert!(layers.contains(&GovernanceLayer::Project));\n    }\n\n    #[test]\n    fn test_company_policy_most_restrictive() {\n        let policies = create_default_policies();\n        let company = policies\n            .iter()\n            .find(|p| p.layer == GovernanceLayer::Company)\n            .unwrap();\n\n        assert_eq!(company.min_role_for_governance, RoleLevel::Admin);\n        assert!(!company.agent_delegation.autonomous_enabled);\n        assert_eq!(company.agent_delegation.max_delegation_depth, 1);\n    }\n\n    #[test]\n    fn test_project_policy_most_permissive() {\n        let policies = create_default_policies();\n        let project = policies\n            .iter()\n            .find(|p| p.layer == GovernanceLayer::Project)\n            .unwrap();\n\n        assert_eq!(project.min_role_for_governance, RoleLevel::Developer);\n        assert!(project.agent_delegation.autonomous_enabled);\n        assert_eq!(project.agent_delegation.max_delegation_depth, 3);\n    }\n\n    #[test]\n    fn test_authorization_check_role_insufficient() {\n        let policies = create_default_policies();\n        let company = policies\n            .iter()\n            .find(|p| p.layer == GovernanceLayer::Company)\n            .unwrap();\n\n        let result = company.check_authorization(\n            PrincipalType::User,\n            RoleLevel::Developer,\n            GovernanceActionType::ApprovePolicy,\n            RiskLevel::Medium,\n            None,\n        );\n\n        assert!(!result.allowed);\n        assert!(result.reason.contains(\"insufficient\"));\n    }\n\n    #[test]\n    fn test_authorization_check_user_allowed() {\n        let policies = create_default_policies();\n        let project = policies\n            .iter()\n            .find(|p| p.layer == GovernanceLayer::Project)\n            .unwrap();\n\n        let result = project.check_authorization(\n            PrincipalType::User,\n            RoleLevel::Developer,\n            GovernanceActionType::ProposeKnowledge,\n            RiskLevel::Low,\n            None,\n        );\n\n        assert!(result.allowed);\n    }\n\n    #[test]\n    fn test_authorization_check_agent_no_autonomous() {\n        let policies = create_default_policies();\n        let company = policies\n            .iter()\n            .find(|p| p.layer == GovernanceLayer::Company)\n            .unwrap();\n\n        let result = company.check_authorization(\n            PrincipalType::Agent,\n            RoleLevel::Admin, // Even admin agent can't act autonomously\n            GovernanceActionType::CreatePolicy,\n            RiskLevel::Low,\n            Some(1),\n        );\n\n        assert!(!result.allowed);\n        assert!(result.reason.contains(\"cannot act autonomously\"));\n    }\n\n    #[test]\n    fn test_authorization_check_agent_delegation_depth_exceeded() {\n        let policies = create_default_policies();\n        let project = policies\n            .iter()\n            .find(|p| p.layer == GovernanceLayer::Project)\n            .unwrap();\n\n        let result = project.check_authorization(\n            PrincipalType::Agent,\n            RoleLevel::Developer,\n            GovernanceActionType::ProposeKnowledge,\n            RiskLevel::Low,\n            Some(5), // Exceeds max of 3\n        );\n\n        assert!(!result.allowed);\n        assert!(result.reason.contains(\"Delegation depth\"));\n    }\n\n    #[test]\n    fn test_authorization_check_agent_requires_confirmation() {\n        let policies = create_default_policies();\n        let team = policies\n            .iter()\n            .find(|p| p.layer == GovernanceLayer::Team)\n            .unwrap();\n\n        let result = team.check_authorization(\n            PrincipalType::Agent,\n            RoleLevel::TechLead,\n            GovernanceActionType::DeletePolicy,\n            RiskLevel::Low,\n            Some(1),\n        );\n\n        assert!(result.allowed);\n        assert!(result.requires_human_confirmation);\n    }\n\n    #[test]\n    fn test_authorization_check_risk_level_restricted() {\n        let policies = create_default_policies();\n        let org = policies\n            .iter()\n            .find(|p| p.layer == GovernanceLayer::Org)\n            .unwrap();\n\n        let result = org.check_authorization(\n            PrincipalType::User,\n            RoleLevel::TechLead,\n            GovernanceActionType::CreatePolicy,\n            RiskLevel::Critical, // Restricted at org level\n            None,\n        );\n\n        assert!(!result.allowed);\n        assert!(result.reason.contains(\"restricted\"));\n    }\n\n    #[test]\n    fn test_escalation_config_default() {\n        let config = EscalationConfig::default();\n        assert!(config.enabled);\n        assert_eq!(config.tiers.len(), 3);\n        assert_eq!(config.fallback_action, EscalationFallback::ExpireRequest);\n    }\n\n    #[test]\n    fn test_agent_rate_limits_default() {\n        let limits = AgentRateLimits::default();\n        assert_eq!(limits.actions_per_minute, 30);\n        assert_eq!(limits.actions_per_hour, 500);\n        assert_eq!(limits.governance_submissions_per_day, 10);\n    }\n\n    #[test]\n    fn test_confirmation_status_roundtrip() {\n        for status in [\n            ConfirmationStatus::Pending,\n            ConfirmationStatus::Approved,\n            ConfirmationStatus::Denied,\n            ConfirmationStatus::Expired,\n            ConfirmationStatus::Cancelled,\n        ] {\n            let s = status.to_string();\n            assert_eq!(s.parse::<ConfirmationStatus>().unwrap(), status);\n        }\n    }\n\n    #[test]\n    fn test_confirmation_reason_display() {\n        assert_eq!(\n            ConfirmationReason::PolicyRequired.to_string(),\n            \"Policy requires human confirmation\"\n        );\n        assert_eq!(\n            ConfirmationReason::HighRisk.to_string(),\n            \"Action classified as high risk\"\n        );\n    }\n\n    #[test]\n    fn test_governance_action_type_roundtrip() {\n        for action in [\n            GovernanceActionType::CreatePolicy,\n            GovernanceActionType::ApprovePolicy,\n            GovernanceActionType::ProposeKnowledge,\n            GovernanceActionType::PromoteMemory,\n            GovernanceActionType::ModifyMetaGovernance,\n        ] {\n            let s = action.to_string();\n            assert_eq!(s.parse::<GovernanceActionType>().unwrap(), action);\n        }\n    }\n\n    #[test]\n    fn test_agent_delegation_config_default_capabilities() {\n        let config = AgentDelegationConfig::default();\n        assert!(\n            config\n                .allowed_capabilities\n                .contains(&AgentCapability::MemoryRead)\n        );\n        assert!(\n            config\n                .allowed_capabilities\n                .contains(&AgentCapability::KnowledgePropose)\n        );\n        assert!(\n            config\n                .allowed_capabilities\n                .contains(&AgentCapability::PolicySimulate)\n        );\n        // GovernanceApprove should NOT be in default capabilities\n        assert!(\n            !config\n                .allowed_capabilities\n                .contains(&AgentCapability::GovernanceApprove)\n        );\n    }\n}\n","traces":[{"line":28,"address":[],"length":0,"stats":{"Line":6}},{"line":29,"address":[],"length":0,"stats":{"Line":6}},{"line":30,"address":[],"length":0,"stats":{"Line":6}},{"line":31,"address":[],"length":0,"stats":{"Line":3}},{"line":32,"address":[],"length":0,"stats":{"Line":3}},{"line":33,"address":[],"length":0,"stats":{"Line":6}},{"line":41,"address":[],"length":0,"stats":{"Line":4}},{"line":42,"address":[],"length":0,"stats":{"Line":4}},{"line":43,"address":[],"length":0,"stats":{"Line":5}},{"line":44,"address":[],"length":0,"stats":{"Line":7}},{"line":45,"address":[],"length":0,"stats":{"Line":3}},{"line":46,"address":[],"length":0,"stats":{"Line":1}},{"line":47,"address":[],"length":0,"stats":{"Line":1}},{"line":48,"address":[],"length":0,"stats":{"Line":1}},{"line":49,"address":[],"length":0,"stats":{"Line":1}},{"line":82,"address":[],"length":0,"stats":{"Line":6}},{"line":83,"address":[],"length":0,"stats":{"Line":12}},{"line":84,"address":[],"length":0,"stats":{"Line":2}},{"line":85,"address":[],"length":0,"stats":{"Line":1}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":1}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":1}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":1}},{"line":99,"address":[],"length":0,"stats":{"Line":18}},{"line":106,"address":[],"length":0,"stats":{"Line":5}},{"line":107,"address":[],"length":0,"stats":{"Line":5}},{"line":108,"address":[],"length":0,"stats":{"Line":6}},{"line":109,"address":[],"length":0,"stats":{"Line":5}},{"line":110,"address":[],"length":0,"stats":{"Line":3}},{"line":111,"address":[],"length":0,"stats":{"Line":3}},{"line":112,"address":[],"length":0,"stats":{"Line":4}},{"line":113,"address":[],"length":0,"stats":{"Line":2}},{"line":114,"address":[],"length":0,"stats":{"Line":2}},{"line":115,"address":[],"length":0,"stats":{"Line":2}},{"line":116,"address":[],"length":0,"stats":{"Line":3}},{"line":117,"address":[],"length":0,"stats":{"Line":1}},{"line":118,"address":[],"length":0,"stats":{"Line":1}},{"line":119,"address":[],"length":0,"stats":{"Line":1}},{"line":120,"address":[],"length":0,"stats":{"Line":1}},{"line":121,"address":[],"length":0,"stats":{"Line":2}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":2}},{"line":168,"address":[],"length":0,"stats":{"Line":2}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":3}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":3}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":1}},{"line":231,"address":[],"length":0,"stats":{"Line":2}},{"line":242,"address":[],"length":0,"stats":{"Line":2}},{"line":251,"address":[],"length":0,"stats":{"Line":1}},{"line":285,"address":[],"length":0,"stats":{"Line":3}},{"line":286,"address":[],"length":0,"stats":{"Line":6}},{"line":287,"address":[],"length":0,"stats":{"Line":1}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":292,"address":[],"length":0,"stats":{"Line":1}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":1}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":298,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":9}},{"line":311,"address":[],"length":0,"stats":{"Line":3}},{"line":312,"address":[],"length":0,"stats":{"Line":3}},{"line":313,"address":[],"length":0,"stats":{"Line":4}},{"line":314,"address":[],"length":0,"stats":{"Line":2}},{"line":315,"address":[],"length":0,"stats":{"Line":2}},{"line":316,"address":[],"length":0,"stats":{"Line":2}},{"line":317,"address":[],"length":0,"stats":{"Line":2}},{"line":318,"address":[],"length":0,"stats":{"Line":2}},{"line":319,"address":[],"length":0,"stats":{"Line":2}},{"line":320,"address":[],"length":0,"stats":{"Line":2}},{"line":321,"address":[],"length":0,"stats":{"Line":2}},{"line":322,"address":[],"length":0,"stats":{"Line":2}},{"line":323,"address":[],"length":0,"stats":{"Line":2}},{"line":324,"address":[],"length":0,"stats":{"Line":2}},{"line":325,"address":[],"length":0,"stats":{"Line":3}},{"line":326,"address":[],"length":0,"stats":{"Line":1}},{"line":327,"address":[],"length":0,"stats":{"Line":1}},{"line":328,"address":[],"length":0,"stats":{"Line":1}},{"line":329,"address":[],"length":0,"stats":{"Line":1}},{"line":348,"address":[],"length":0,"stats":{"Line":11}},{"line":374,"address":[],"length":0,"stats":{"Line":19}},{"line":378,"address":[],"length":0,"stats":{"Line":38}},{"line":406,"address":[],"length":0,"stats":{"Line":19}},{"line":515,"address":[],"length":0,"stats":{"Line":2}},{"line":516,"address":[],"length":0,"stats":{"Line":2}},{"line":517,"address":[],"length":0,"stats":{"Line":3}},{"line":518,"address":[],"length":0,"stats":{"Line":3}},{"line":520,"address":[],"length":0,"stats":{"Line":0}},{"line":522,"address":[],"length":0,"stats":{"Line":0}},{"line":523,"address":[],"length":0,"stats":{"Line":0}},{"line":525,"address":[],"length":0,"stats":{"Line":0}},{"line":527,"address":[],"length":0,"stats":{"Line":0}},{"line":544,"address":[],"length":0,"stats":{"Line":5}},{"line":545,"address":[],"length":0,"stats":{"Line":5}},{"line":546,"address":[],"length":0,"stats":{"Line":3}},{"line":547,"address":[],"length":0,"stats":{"Line":3}},{"line":548,"address":[],"length":0,"stats":{"Line":3}},{"line":549,"address":[],"length":0,"stats":{"Line":3}},{"line":550,"address":[],"length":0,"stats":{"Line":3}},{"line":558,"address":[],"length":0,"stats":{"Line":5}},{"line":559,"address":[],"length":0,"stats":{"Line":5}},{"line":560,"address":[],"length":0,"stats":{"Line":6}},{"line":561,"address":[],"length":0,"stats":{"Line":5}},{"line":562,"address":[],"length":0,"stats":{"Line":4}},{"line":563,"address":[],"length":0,"stats":{"Line":3}},{"line":564,"address":[],"length":0,"stats":{"Line":2}},{"line":565,"address":[],"length":0,"stats":{"Line":0}},{"line":570,"address":[],"length":0,"stats":{"Line":9}},{"line":571,"address":[],"length":0,"stats":{"Line":18}},{"line":572,"address":[],"length":0,"stats":{"Line":18}},{"line":574,"address":[],"length":0,"stats":{"Line":9}},{"line":575,"address":[],"length":0,"stats":{"Line":9}},{"line":576,"address":[],"length":0,"stats":{"Line":18}},{"line":577,"address":[],"length":0,"stats":{"Line":18}},{"line":578,"address":[],"length":0,"stats":{"Line":18}},{"line":579,"address":[],"length":0,"stats":{"Line":18}},{"line":580,"address":[],"length":0,"stats":{"Line":18}},{"line":581,"address":[],"length":0,"stats":{"Line":18}},{"line":582,"address":[],"length":0,"stats":{"Line":27}},{"line":583,"address":[],"length":0,"stats":{"Line":18}},{"line":584,"address":[],"length":0,"stats":{"Line":18}},{"line":585,"address":[],"length":0,"stats":{"Line":18}},{"line":586,"address":[],"length":0,"stats":{"Line":18}},{"line":588,"address":[],"length":0,"stats":{"Line":18}},{"line":589,"address":[],"length":0,"stats":{"Line":27}},{"line":590,"address":[],"length":0,"stats":{"Line":18}},{"line":591,"address":[],"length":0,"stats":{"Line":18}},{"line":592,"address":[],"length":0,"stats":{"Line":18}},{"line":593,"address":[],"length":0,"stats":{"Line":18}},{"line":595,"address":[],"length":0,"stats":{"Line":18}},{"line":596,"address":[],"length":0,"stats":{"Line":27}},{"line":597,"address":[],"length":0,"stats":{"Line":18}},{"line":598,"address":[],"length":0,"stats":{"Line":18}},{"line":599,"address":[],"length":0,"stats":{"Line":18}},{"line":600,"address":[],"length":0,"stats":{"Line":18}},{"line":603,"address":[],"length":0,"stats":{"Line":18}},{"line":604,"address":[],"length":0,"stats":{"Line":18}},{"line":605,"address":[],"length":0,"stats":{"Line":18}},{"line":606,"address":[],"length":0,"stats":{"Line":27}},{"line":607,"address":[],"length":0,"stats":{"Line":27}},{"line":608,"address":[],"length":0,"stats":{"Line":27}},{"line":609,"address":[],"length":0,"stats":{"Line":27}},{"line":610,"address":[],"length":0,"stats":{"Line":27}},{"line":612,"address":[],"length":0,"stats":{"Line":27}},{"line":613,"address":[],"length":0,"stats":{"Line":27}},{"line":614,"address":[],"length":0,"stats":{"Line":27}},{"line":615,"address":[],"length":0,"stats":{"Line":27}},{"line":616,"address":[],"length":0,"stats":{"Line":27}},{"line":617,"address":[],"length":0,"stats":{"Line":27}},{"line":618,"address":[],"length":0,"stats":{"Line":27}},{"line":619,"address":[],"length":0,"stats":{"Line":27}},{"line":620,"address":[],"length":0,"stats":{"Line":27}},{"line":621,"address":[],"length":0,"stats":{"Line":27}},{"line":622,"address":[],"length":0,"stats":{"Line":27}},{"line":623,"address":[],"length":0,"stats":{"Line":27}},{"line":624,"address":[],"length":0,"stats":{"Line":18}},{"line":626,"address":[],"length":0,"stats":{"Line":18}},{"line":627,"address":[],"length":0,"stats":{"Line":18}},{"line":628,"address":[],"length":0,"stats":{"Line":18}},{"line":629,"address":[],"length":0,"stats":{"Line":18}},{"line":630,"address":[],"length":0,"stats":{"Line":18}},{"line":631,"address":[],"length":0,"stats":{"Line":18}},{"line":634,"address":[],"length":0,"stats":{"Line":18}},{"line":635,"address":[],"length":0,"stats":{"Line":18}},{"line":636,"address":[],"length":0,"stats":{"Line":18}},{"line":637,"address":[],"length":0,"stats":{"Line":36}},{"line":638,"address":[],"length":0,"stats":{"Line":45}},{"line":639,"address":[],"length":0,"stats":{"Line":27}},{"line":640,"address":[],"length":0,"stats":{"Line":36}},{"line":641,"address":[],"length":0,"stats":{"Line":36}},{"line":642,"address":[],"length":0,"stats":{"Line":36}},{"line":643,"address":[],"length":0,"stats":{"Line":27}},{"line":644,"address":[],"length":0,"stats":{"Line":27}},{"line":647,"address":[],"length":0,"stats":{"Line":18}},{"line":648,"address":[],"length":0,"stats":{"Line":18}},{"line":650,"address":[],"length":0,"stats":{"Line":9}},{"line":651,"address":[],"length":0,"stats":{"Line":18}},{"line":652,"address":[],"length":0,"stats":{"Line":9}},{"line":653,"address":[],"length":0,"stats":{"Line":9}},{"line":655,"address":[],"length":0,"stats":{"Line":9}},{"line":656,"address":[],"length":0,"stats":{"Line":18}},{"line":657,"address":[],"length":0,"stats":{"Line":18}},{"line":658,"address":[],"length":0,"stats":{"Line":18}},{"line":659,"address":[],"length":0,"stats":{"Line":18}},{"line":660,"address":[],"length":0,"stats":{"Line":18}},{"line":661,"address":[],"length":0,"stats":{"Line":18}},{"line":662,"address":[],"length":0,"stats":{"Line":27}},{"line":663,"address":[],"length":0,"stats":{"Line":27}},{"line":664,"address":[],"length":0,"stats":{"Line":18}},{"line":665,"address":[],"length":0,"stats":{"Line":18}},{"line":666,"address":[],"length":0,"stats":{"Line":18}},{"line":668,"address":[],"length":0,"stats":{"Line":18}},{"line":669,"address":[],"length":0,"stats":{"Line":27}},{"line":670,"address":[],"length":0,"stats":{"Line":18}},{"line":671,"address":[],"length":0,"stats":{"Line":18}},{"line":672,"address":[],"length":0,"stats":{"Line":18}},{"line":673,"address":[],"length":0,"stats":{"Line":18}},{"line":675,"address":[],"length":0,"stats":{"Line":18}},{"line":676,"address":[],"length":0,"stats":{"Line":27}},{"line":677,"address":[],"length":0,"stats":{"Line":27}},{"line":678,"address":[],"length":0,"stats":{"Line":18}},{"line":679,"address":[],"length":0,"stats":{"Line":18}},{"line":680,"address":[],"length":0,"stats":{"Line":27}},{"line":683,"address":[],"length":0,"stats":{"Line":18}},{"line":684,"address":[],"length":0,"stats":{"Line":18}},{"line":685,"address":[],"length":0,"stats":{"Line":18}},{"line":686,"address":[],"length":0,"stats":{"Line":27}},{"line":687,"address":[],"length":0,"stats":{"Line":27}},{"line":688,"address":[],"length":0,"stats":{"Line":27}},{"line":689,"address":[],"length":0,"stats":{"Line":27}},{"line":690,"address":[],"length":0,"stats":{"Line":27}},{"line":691,"address":[],"length":0,"stats":{"Line":27}},{"line":692,"address":[],"length":0,"stats":{"Line":27}},{"line":693,"address":[],"length":0,"stats":{"Line":27}},{"line":694,"address":[],"length":0,"stats":{"Line":27}},{"line":695,"address":[],"length":0,"stats":{"Line":27}},{"line":697,"address":[],"length":0,"stats":{"Line":27}},{"line":698,"address":[],"length":0,"stats":{"Line":27}},{"line":699,"address":[],"length":0,"stats":{"Line":27}},{"line":700,"address":[],"length":0,"stats":{"Line":27}},{"line":701,"address":[],"length":0,"stats":{"Line":27}},{"line":702,"address":[],"length":0,"stats":{"Line":18}},{"line":704,"address":[],"length":0,"stats":{"Line":18}},{"line":705,"address":[],"length":0,"stats":{"Line":18}},{"line":706,"address":[],"length":0,"stats":{"Line":18}},{"line":707,"address":[],"length":0,"stats":{"Line":18}},{"line":708,"address":[],"length":0,"stats":{"Line":18}},{"line":709,"address":[],"length":0,"stats":{"Line":18}},{"line":712,"address":[],"length":0,"stats":{"Line":18}},{"line":713,"address":[],"length":0,"stats":{"Line":9}},{"line":714,"address":[],"length":0,"stats":{"Line":18}},{"line":715,"address":[],"length":0,"stats":{"Line":9}},{"line":716,"address":[],"length":0,"stats":{"Line":9}},{"line":718,"address":[],"length":0,"stats":{"Line":9}},{"line":719,"address":[],"length":0,"stats":{"Line":18}},{"line":720,"address":[],"length":0,"stats":{"Line":18}},{"line":721,"address":[],"length":0,"stats":{"Line":18}},{"line":722,"address":[],"length":0,"stats":{"Line":18}},{"line":723,"address":[],"length":0,"stats":{"Line":18}},{"line":724,"address":[],"length":0,"stats":{"Line":18}},{"line":725,"address":[],"length":0,"stats":{"Line":27}},{"line":726,"address":[],"length":0,"stats":{"Line":27}},{"line":727,"address":[],"length":0,"stats":{"Line":18}},{"line":728,"address":[],"length":0,"stats":{"Line":18}},{"line":729,"address":[],"length":0,"stats":{"Line":27}},{"line":731,"address":[],"length":0,"stats":{"Line":18}},{"line":732,"address":[],"length":0,"stats":{"Line":27}},{"line":733,"address":[],"length":0,"stats":{"Line":18}},{"line":734,"address":[],"length":0,"stats":{"Line":18}},{"line":735,"address":[],"length":0,"stats":{"Line":18}},{"line":736,"address":[],"length":0,"stats":{"Line":18}},{"line":738,"address":[],"length":0,"stats":{"Line":18}},{"line":739,"address":[],"length":0,"stats":{"Line":27}},{"line":740,"address":[],"length":0,"stats":{"Line":27}},{"line":741,"address":[],"length":0,"stats":{"Line":18}},{"line":742,"address":[],"length":0,"stats":{"Line":18}},{"line":743,"address":[],"length":0,"stats":{"Line":18}},{"line":745,"address":[],"length":0,"stats":{"Line":18}},{"line":746,"address":[],"length":0,"stats":{"Line":27}},{"line":747,"address":[],"length":0,"stats":{"Line":18}},{"line":748,"address":[],"length":0,"stats":{"Line":18}},{"line":749,"address":[],"length":0,"stats":{"Line":18}},{"line":750,"address":[],"length":0,"stats":{"Line":18}},{"line":753,"address":[],"length":0,"stats":{"Line":18}},{"line":754,"address":[],"length":0,"stats":{"Line":18}},{"line":755,"address":[],"length":0,"stats":{"Line":18}},{"line":756,"address":[],"length":0,"stats":{"Line":27}},{"line":757,"address":[],"length":0,"stats":{"Line":27}},{"line":758,"address":[],"length":0,"stats":{"Line":27}},{"line":759,"address":[],"length":0,"stats":{"Line":27}},{"line":760,"address":[],"length":0,"stats":{"Line":27}},{"line":761,"address":[],"length":0,"stats":{"Line":27}},{"line":762,"address":[],"length":0,"stats":{"Line":27}},{"line":763,"address":[],"length":0,"stats":{"Line":27}},{"line":764,"address":[],"length":0,"stats":{"Line":27}},{"line":765,"address":[],"length":0,"stats":{"Line":27}},{"line":766,"address":[],"length":0,"stats":{"Line":27}},{"line":767,"address":[],"length":0,"stats":{"Line":27}},{"line":769,"address":[],"length":0,"stats":{"Line":27}},{"line":770,"address":[],"length":0,"stats":{"Line":27}},{"line":771,"address":[],"length":0,"stats":{"Line":27}},{"line":772,"address":[],"length":0,"stats":{"Line":27}},{"line":773,"address":[],"length":0,"stats":{"Line":18}},{"line":775,"address":[],"length":0,"stats":{"Line":18}},{"line":776,"address":[],"length":0,"stats":{"Line":18}},{"line":778,"address":[],"length":0,"stats":{"Line":18}},{"line":779,"address":[],"length":0,"stats":{"Line":9}},{"line":780,"address":[],"length":0,"stats":{"Line":18}},{"line":781,"address":[],"length":0,"stats":{"Line":9}},{"line":782,"address":[],"length":0,"stats":{"Line":9}},{"line":784,"address":[],"length":0,"stats":{"Line":9}},{"line":785,"address":[],"length":0,"stats":{"Line":18}},{"line":786,"address":[],"length":0,"stats":{"Line":18}},{"line":787,"address":[],"length":0,"stats":{"Line":18}},{"line":788,"address":[],"length":0,"stats":{"Line":18}},{"line":789,"address":[],"length":0,"stats":{"Line":18}},{"line":790,"address":[],"length":0,"stats":{"Line":18}},{"line":791,"address":[],"length":0,"stats":{"Line":27}},{"line":792,"address":[],"length":0,"stats":{"Line":27}},{"line":793,"address":[],"length":0,"stats":{"Line":18}},{"line":794,"address":[],"length":0,"stats":{"Line":18}},{"line":795,"address":[],"length":0,"stats":{"Line":18}},{"line":797,"address":[],"length":0,"stats":{"Line":18}},{"line":798,"address":[],"length":0,"stats":{"Line":27}},{"line":799,"address":[],"length":0,"stats":{"Line":27}},{"line":800,"address":[],"length":0,"stats":{"Line":18}},{"line":801,"address":[],"length":0,"stats":{"Line":18}},{"line":802,"address":[],"length":0,"stats":{"Line":27}},{"line":804,"address":[],"length":0,"stats":{"Line":18}},{"line":805,"address":[],"length":0,"stats":{"Line":27}},{"line":806,"address":[],"length":0,"stats":{"Line":18}},{"line":807,"address":[],"length":0,"stats":{"Line":18}},{"line":808,"address":[],"length":0,"stats":{"Line":18}},{"line":809,"address":[],"length":0,"stats":{"Line":18}},{"line":811,"address":[],"length":0,"stats":{"Line":18}},{"line":812,"address":[],"length":0,"stats":{"Line":27}},{"line":813,"address":[],"length":0,"stats":{"Line":27}},{"line":814,"address":[],"length":0,"stats":{"Line":18}},{"line":815,"address":[],"length":0,"stats":{"Line":18}},{"line":816,"address":[],"length":0,"stats":{"Line":27}},{"line":818,"address":[],"length":0,"stats":{"Line":18}},{"line":819,"address":[],"length":0,"stats":{"Line":27}},{"line":820,"address":[],"length":0,"stats":{"Line":18}},{"line":821,"address":[],"length":0,"stats":{"Line":18}},{"line":822,"address":[],"length":0,"stats":{"Line":18}},{"line":823,"address":[],"length":0,"stats":{"Line":18}},{"line":826,"address":[],"length":0,"stats":{"Line":18}},{"line":827,"address":[],"length":0,"stats":{"Line":18}},{"line":828,"address":[],"length":0,"stats":{"Line":18}},{"line":829,"address":[],"length":0,"stats":{"Line":27}},{"line":830,"address":[],"length":0,"stats":{"Line":27}},{"line":831,"address":[],"length":0,"stats":{"Line":27}},{"line":832,"address":[],"length":0,"stats":{"Line":27}},{"line":833,"address":[],"length":0,"stats":{"Line":27}},{"line":834,"address":[],"length":0,"stats":{"Line":27}},{"line":835,"address":[],"length":0,"stats":{"Line":27}},{"line":836,"address":[],"length":0,"stats":{"Line":27}},{"line":837,"address":[],"length":0,"stats":{"Line":27}},{"line":838,"address":[],"length":0,"stats":{"Line":27}},{"line":839,"address":[],"length":0,"stats":{"Line":27}},{"line":840,"address":[],"length":0,"stats":{"Line":27}},{"line":841,"address":[],"length":0,"stats":{"Line":27}},{"line":842,"address":[],"length":0,"stats":{"Line":27}},{"line":843,"address":[],"length":0,"stats":{"Line":27}},{"line":844,"address":[],"length":0,"stats":{"Line":27}},{"line":846,"address":[],"length":0,"stats":{"Line":27}},{"line":847,"address":[],"length":0,"stats":{"Line":27}},{"line":848,"address":[],"length":0,"stats":{"Line":18}},{"line":850,"address":[],"length":0,"stats":{"Line":18}},{"line":851,"address":[],"length":0,"stats":{"Line":18}},{"line":852,"address":[],"length":0,"stats":{"Line":18}},{"line":853,"address":[],"length":0,"stats":{"Line":18}},{"line":854,"address":[],"length":0,"stats":{"Line":18}},{"line":855,"address":[],"length":0,"stats":{"Line":18}},{"line":858,"address":[],"length":0,"stats":{"Line":18}},{"line":859,"address":[],"length":0,"stats":{"Line":18}},{"line":860,"address":[],"length":0,"stats":{"Line":18}},{"line":861,"address":[],"length":0,"stats":{"Line":36}},{"line":862,"address":[],"length":0,"stats":{"Line":45}},{"line":863,"address":[],"length":0,"stats":{"Line":27}},{"line":864,"address":[],"length":0,"stats":{"Line":36}},{"line":865,"address":[],"length":0,"stats":{"Line":27}},{"line":867,"address":[],"length":0,"stats":{"Line":18}},{"line":868,"address":[],"length":0,"stats":{"Line":18}},{"line":870,"address":[],"length":0,"stats":{"Line":9}},{"line":871,"address":[],"length":0,"stats":{"Line":18}},{"line":872,"address":[],"length":0,"stats":{"Line":9}},{"line":873,"address":[],"length":0,"stats":{"Line":9}},{"line":889,"address":[],"length":0,"stats":{"Line":6}},{"line":897,"address":[],"length":0,"stats":{"Line":12}},{"line":898,"address":[],"length":0,"stats":{"Line":12}},{"line":900,"address":[],"length":0,"stats":{"Line":46}},{"line":902,"address":[],"length":0,"stats":{"Line":12}},{"line":903,"address":[],"length":0,"stats":{"Line":6}},{"line":904,"address":[],"length":0,"stats":{"Line":12}},{"line":906,"address":[],"length":0,"stats":{"Line":6}},{"line":907,"address":[],"length":0,"stats":{"Line":1}},{"line":908,"address":[],"length":0,"stats":{"Line":1}},{"line":909,"address":[],"length":0,"stats":{"Line":2}},{"line":910,"address":[],"length":0,"stats":{"Line":1}},{"line":911,"address":[],"length":0,"stats":{"Line":1}},{"line":913,"address":[],"length":0,"stats":{"Line":1}},{"line":914,"address":[],"length":0,"stats":{"Line":1}},{"line":915,"address":[],"length":0,"stats":{"Line":1}},{"line":919,"address":[],"length":0,"stats":{"Line":9}},{"line":920,"address":[],"length":0,"stats":{"Line":8}},{"line":921,"address":[],"length":0,"stats":{"Line":1}},{"line":922,"address":[],"length":0,"stats":{"Line":1}},{"line":923,"address":[],"length":0,"stats":{"Line":2}},{"line":924,"address":[],"length":0,"stats":{"Line":1}},{"line":925,"address":[],"length":0,"stats":{"Line":1}},{"line":927,"address":[],"length":0,"stats":{"Line":1}},{"line":928,"address":[],"length":0,"stats":{"Line":1}},{"line":929,"address":[],"length":0,"stats":{"Line":1}},{"line":933,"address":[],"length":0,"stats":{"Line":4}},{"line":934,"address":[],"length":0,"stats":{"Line":1}},{"line":938,"address":[],"length":0,"stats":{"Line":4}},{"line":939,"address":[],"length":0,"stats":{"Line":6}},{"line":941,"address":[],"length":0,"stats":{"Line":3}},{"line":942,"address":[],"length":0,"stats":{"Line":1}},{"line":943,"address":[],"length":0,"stats":{"Line":1}},{"line":944,"address":[],"length":0,"stats":{"Line":2}},{"line":945,"address":[],"length":0,"stats":{"Line":1}},{"line":946,"address":[],"length":0,"stats":{"Line":1}},{"line":947,"address":[],"length":0,"stats":{"Line":1}},{"line":951,"address":[],"length":0,"stats":{"Line":4}},{"line":952,"address":[],"length":0,"stats":{"Line":2}},{"line":953,"address":[],"length":0,"stats":{"Line":1}},{"line":954,"address":[],"length":0,"stats":{"Line":1}},{"line":955,"address":[],"length":0,"stats":{"Line":2}},{"line":956,"address":[],"length":0,"stats":{"Line":1}},{"line":957,"address":[],"length":0,"stats":{"Line":1}},{"line":959,"address":[],"length":0,"stats":{"Line":1}},{"line":960,"address":[],"length":0,"stats":{"Line":1}},{"line":961,"address":[],"length":0,"stats":{"Line":1}},{"line":965,"address":[],"length":0,"stats":{"Line":1}},{"line":966,"address":[],"length":0,"stats":{"Line":0}},{"line":967,"address":[],"length":0,"stats":{"Line":0}},{"line":968,"address":[],"length":0,"stats":{"Line":0}},{"line":973,"address":[],"length":0,"stats":{"Line":3}},{"line":974,"address":[],"length":0,"stats":{"Line":1}},{"line":977,"address":[],"length":0,"stats":{"Line":1}},{"line":978,"address":[],"length":0,"stats":{"Line":0}},{"line":979,"address":[],"length":0,"stats":{"Line":0}},{"line":980,"address":[],"length":0,"stats":{"Line":0}},{"line":981,"address":[],"length":0,"stats":{"Line":0}},{"line":982,"address":[],"length":0,"stats":{"Line":0}},{"line":990,"address":[],"length":0,"stats":{"Line":6}},{"line":1014,"address":[],"length":0,"stats":{"Line":0}},{"line":1016,"address":[],"length":0,"stats":{"Line":0}},{"line":1017,"address":[],"length":0,"stats":{"Line":0}},{"line":1018,"address":[],"length":0,"stats":{"Line":0}},{"line":1019,"address":[],"length":0,"stats":{"Line":0}},{"line":1023,"address":[],"length":0,"stats":{"Line":0}},{"line":1024,"address":[],"length":0,"stats":{"Line":0}},{"line":1026,"address":[],"length":0,"stats":{"Line":0}},{"line":1028,"address":[],"length":0,"stats":{"Line":0}},{"line":1029,"address":[],"length":0,"stats":{"Line":0}},{"line":1030,"address":[],"length":0,"stats":{"Line":0}},{"line":1031,"address":[],"length":0,"stats":{"Line":0}},{"line":1062,"address":[],"length":0,"stats":{"Line":0}},{"line":1066,"address":[],"length":0,"stats":{"Line":0}},{"line":1071,"address":[],"length":0,"stats":{"Line":0}},{"line":1080,"address":[],"length":0,"stats":{"Line":0}},{"line":1081,"address":[],"length":0,"stats":{"Line":0}},{"line":1082,"address":[],"length":0,"stats":{"Line":0}},{"line":1083,"address":[],"length":0,"stats":{"Line":0}},{"line":1085,"address":[],"length":0,"stats":{"Line":0}},{"line":1086,"address":[],"length":0,"stats":{"Line":0}},{"line":1098,"address":[],"length":0,"stats":{"Line":0}},{"line":1099,"address":[],"length":0,"stats":{"Line":0}},{"line":1100,"address":[],"length":0,"stats":{"Line":0}},{"line":1102,"address":[],"length":0,"stats":{"Line":0}},{"line":1106,"address":[],"length":0,"stats":{"Line":0}},{"line":1125,"address":[],"length":0,"stats":{"Line":0}},{"line":1126,"address":[],"length":0,"stats":{"Line":0}},{"line":1127,"address":[],"length":0,"stats":{"Line":0}},{"line":1128,"address":[],"length":0,"stats":{"Line":0}},{"line":1129,"address":[],"length":0,"stats":{"Line":0}},{"line":1130,"address":[],"length":0,"stats":{"Line":0}},{"line":1131,"address":[],"length":0,"stats":{"Line":0}},{"line":1132,"address":[],"length":0,"stats":{"Line":0}},{"line":1133,"address":[],"length":0,"stats":{"Line":0}},{"line":1134,"address":[],"length":0,"stats":{"Line":0}},{"line":1135,"address":[],"length":0,"stats":{"Line":0}},{"line":1136,"address":[],"length":0,"stats":{"Line":0}},{"line":1137,"address":[],"length":0,"stats":{"Line":0}},{"line":1139,"address":[],"length":0,"stats":{"Line":0}},{"line":1143,"address":[],"length":0,"stats":{"Line":0}},{"line":1158,"address":[],"length":0,"stats":{"Line":0}},{"line":1159,"address":[],"length":0,"stats":{"Line":0}},{"line":1160,"address":[],"length":0,"stats":{"Line":0}},{"line":1161,"address":[],"length":0,"stats":{"Line":0}},{"line":1162,"address":[],"length":0,"stats":{"Line":0}},{"line":1163,"address":[],"length":0,"stats":{"Line":0}},{"line":1164,"address":[],"length":0,"stats":{"Line":0}},{"line":1165,"address":[],"length":0,"stats":{"Line":0}},{"line":1166,"address":[],"length":0,"stats":{"Line":0}},{"line":1167,"address":[],"length":0,"stats":{"Line":0}},{"line":1168,"address":[],"length":0,"stats":{"Line":0}},{"line":1169,"address":[],"length":0,"stats":{"Line":0}},{"line":1170,"address":[],"length":0,"stats":{"Line":0}},{"line":1171,"address":[],"length":0,"stats":{"Line":0}},{"line":1172,"address":[],"length":0,"stats":{"Line":0}},{"line":1174,"address":[],"length":0,"stats":{"Line":0}},{"line":1178,"address":[],"length":0,"stats":{"Line":0}},{"line":1182,"address":[],"length":0,"stats":{"Line":0}},{"line":1183,"address":[],"length":0,"stats":{"Line":0}},{"line":1184,"address":[],"length":0,"stats":{"Line":0}},{"line":1185,"address":[],"length":0,"stats":{"Line":0}},{"line":1186,"address":[],"length":0,"stats":{"Line":0}},{"line":1188,"address":[],"length":0,"stats":{"Line":0}},{"line":1189,"address":[],"length":0,"stats":{"Line":0}},{"line":1190,"address":[],"length":0,"stats":{"Line":0}},{"line":1191,"address":[],"length":0,"stats":{"Line":0}},{"line":1192,"address":[],"length":0,"stats":{"Line":0}},{"line":1193,"address":[],"length":0,"stats":{"Line":0}},{"line":1194,"address":[],"length":0,"stats":{"Line":0}},{"line":1195,"address":[],"length":0,"stats":{"Line":0}},{"line":1196,"address":[],"length":0,"stats":{"Line":0}},{"line":1197,"address":[],"length":0,"stats":{"Line":0}},{"line":1198,"address":[],"length":0,"stats":{"Line":0}},{"line":1199,"address":[],"length":0,"stats":{"Line":0}},{"line":1200,"address":[],"length":0,"stats":{"Line":0}},{"line":1201,"address":[],"length":0,"stats":{"Line":0}},{"line":1202,"address":[],"length":0,"stats":{"Line":0}},{"line":1203,"address":[],"length":0,"stats":{"Line":0}},{"line":1204,"address":[],"length":0,"stats":{"Line":0}},{"line":1205,"address":[],"length":0,"stats":{"Line":0}},{"line":1206,"address":[],"length":0,"stats":{"Line":0}},{"line":1208,"address":[],"length":0,"stats":{"Line":0}},{"line":1209,"address":[],"length":0,"stats":{"Line":0}},{"line":1210,"address":[],"length":0,"stats":{"Line":0}},{"line":1211,"address":[],"length":0,"stats":{"Line":0}},{"line":1212,"address":[],"length":0,"stats":{"Line":0}},{"line":1213,"address":[],"length":0,"stats":{"Line":0}},{"line":1214,"address":[],"length":0,"stats":{"Line":0}},{"line":1215,"address":[],"length":0,"stats":{"Line":0}},{"line":1216,"address":[],"length":0,"stats":{"Line":0}},{"line":1221,"address":[],"length":0,"stats":{"Line":0}},{"line":1236,"address":[],"length":0,"stats":{"Line":0}},{"line":1237,"address":[],"length":0,"stats":{"Line":0}},{"line":1238,"address":[],"length":0,"stats":{"Line":0}},{"line":1239,"address":[],"length":0,"stats":{"Line":0}},{"line":1241,"address":[],"length":0,"stats":{"Line":0}},{"line":1242,"address":[],"length":0,"stats":{"Line":0}},{"line":1243,"address":[],"length":0,"stats":{"Line":0}},{"line":1244,"address":[],"length":0,"stats":{"Line":0}},{"line":1245,"address":[],"length":0,"stats":{"Line":0}},{"line":1246,"address":[],"length":0,"stats":{"Line":0}},{"line":1247,"address":[],"length":0,"stats":{"Line":0}},{"line":1248,"address":[],"length":0,"stats":{"Line":0}},{"line":1249,"address":[],"length":0,"stats":{"Line":0}},{"line":1250,"address":[],"length":0,"stats":{"Line":0}},{"line":1251,"address":[],"length":0,"stats":{"Line":0}},{"line":1252,"address":[],"length":0,"stats":{"Line":0}},{"line":1253,"address":[],"length":0,"stats":{"Line":0}},{"line":1254,"address":[],"length":0,"stats":{"Line":0}},{"line":1255,"address":[],"length":0,"stats":{"Line":0}},{"line":1256,"address":[],"length":0,"stats":{"Line":0}},{"line":1257,"address":[],"length":0,"stats":{"Line":0}},{"line":1258,"address":[],"length":0,"stats":{"Line":0}},{"line":1259,"address":[],"length":0,"stats":{"Line":0}},{"line":1260,"address":[],"length":0,"stats":{"Line":0}},{"line":1261,"address":[],"length":0,"stats":{"Line":0}},{"line":1263,"address":[],"length":0,"stats":{"Line":0}},{"line":1264,"address":[],"length":0,"stats":{"Line":0}},{"line":1265,"address":[],"length":0,"stats":{"Line":0}},{"line":1266,"address":[],"length":0,"stats":{"Line":0}},{"line":1267,"address":[],"length":0,"stats":{"Line":0}},{"line":1268,"address":[],"length":0,"stats":{"Line":0}},{"line":1269,"address":[],"length":0,"stats":{"Line":0}},{"line":1270,"address":[],"length":0,"stats":{"Line":0}},{"line":1271,"address":[],"length":0,"stats":{"Line":0}},{"line":1273,"address":[],"length":0,"stats":{"Line":0}},{"line":1277,"address":[],"length":0,"stats":{"Line":0}},{"line":1284,"address":[],"length":0,"stats":{"Line":0}},{"line":1285,"address":[],"length":0,"stats":{"Line":0}},{"line":1287,"address":[],"length":0,"stats":{"Line":0}},{"line":1300,"address":[],"length":0,"stats":{"Line":0}},{"line":1301,"address":[],"length":0,"stats":{"Line":0}},{"line":1302,"address":[],"length":0,"stats":{"Line":0}},{"line":1303,"address":[],"length":0,"stats":{"Line":0}},{"line":1304,"address":[],"length":0,"stats":{"Line":0}},{"line":1305,"address":[],"length":0,"stats":{"Line":0}},{"line":1307,"address":[],"length":0,"stats":{"Line":0}},{"line":1311,"address":[],"length":0,"stats":{"Line":0}},{"line":1319,"address":[],"length":0,"stats":{"Line":0}},{"line":1320,"address":[],"length":0,"stats":{"Line":0}},{"line":1322,"address":[],"length":0,"stats":{"Line":0}}],"covered":407,"coverable":601},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","src","postgres.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::StorageBackend;\nuse mk_core::types::{OrganizationalUnit, TenantContext, UnitType};\nuse sqlx::{Pool, Postgres, Row};\nuse thiserror::Error;\n\nuse crate::rls_migration;\n\n#[derive(Error, Debug)]\npub enum PostgresError {\n    #[error(\"Database error: {0}\")]\n    Database(#[from] sqlx::Error),\n    #[error(\"Serialization error: {0}\")]\n    Serialization(#[from] serde_json::Error),\n    #[error(\"Unit not found: {0}\")]\n    NotFound(String),\n}\n\npub struct PostgresBackend {\n    pool: Pool<Postgres>,\n}\n\nimpl PostgresBackend {\n    pub fn pool(&self) -> &Pool<Postgres> {\n        &self.pool\n    }\n\n    pub async fn new(connection_url: &str) -> Result<Self, PostgresError> {\n        use sqlx::postgres::PgPoolOptions;\n        use std::time::Duration;\n\n        let pool = PgPoolOptions::new()\n            .max_connections(5)\n            .acquire_timeout(Duration::from_secs(30))\n            .connect(connection_url)\n            .await?;\n        Ok(Self { pool })\n    }\n\n    pub async fn initialize_schema(&self) -> Result<(), PostgresError> {\n        // Enable pgcrypto extension for gen_random_uuid()\n        sqlx::query(\"CREATE EXTENSION IF NOT EXISTS pgcrypto\")\n            .execute(&self.pool)\n            .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS sync_state (\n                id TEXT NOT NULL,\n                tenant_id TEXT NOT NULL,\n                data JSONB NOT NULL,\n                updated_at BIGINT NOT NULL,\n                PRIMARY KEY (id, tenant_id)\n            )\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\"CREATE INDEX IF NOT EXISTS idx_sync_state_tenant_id ON sync_state(tenant_id)\")\n            .execute(&self.pool)\n            .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS organizational_units (\n                id TEXT PRIMARY KEY,\n                name TEXT NOT NULL,\n                type TEXT NOT NULL, -- 'company', 'organization', 'team', 'project'\n                parent_id TEXT REFERENCES organizational_units(id),\n                tenant_id TEXT NOT NULL,\n                metadata JSONB DEFAULT '{}',\n                created_at BIGINT NOT NULL,\n                updated_at BIGINT NOT NULL\n            )\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS user_roles (\n                user_id TEXT NOT NULL,\n                tenant_id TEXT NOT NULL,\n                unit_id TEXT NOT NULL REFERENCES organizational_units(id),\n                role TEXT NOT NULL,\n                created_at BIGINT NOT NULL,\n                PRIMARY KEY (user_id, tenant_id, unit_id, role)\n            )\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS unit_policies (\n                id TEXT PRIMARY KEY,\n                unit_id TEXT NOT NULL REFERENCES organizational_units(id),\n                policy JSONB NOT NULL,\n                created_at BIGINT NOT NULL,\n                updated_at BIGINT NOT NULL\n            )\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS governance_events (\n                id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n                event_type TEXT NOT NULL,\n                tenant_id TEXT NOT NULL,\n                payload JSONB NOT NULL,\n                timestamp BIGINT NOT NULL\n            )\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS drift_results (\n                project_id TEXT NOT NULL,\n                tenant_id TEXT NOT NULL,\n                drift_score REAL NOT NULL,\n                confidence REAL NOT NULL DEFAULT 1.0,\n                violations JSONB NOT NULL,\n                suppressed_violations JSONB NOT NULL DEFAULT '[]',\n                requires_manual_review BOOLEAN NOT NULL DEFAULT FALSE,\n                timestamp BIGINT NOT NULL,\n                PRIMARY KEY (project_id, tenant_id, timestamp)\n            )\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS drift_configs (\n                project_id TEXT NOT NULL,\n                tenant_id TEXT NOT NULL,\n                threshold REAL NOT NULL DEFAULT 0.3,\n                low_confidence_threshold REAL NOT NULL DEFAULT 0.7,\n                auto_suppress_info BOOLEAN NOT NULL DEFAULT FALSE,\n                updated_at BIGINT NOT NULL,\n                PRIMARY KEY (project_id, tenant_id)\n            )\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS job_status (\n                id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n                job_name TEXT NOT NULL,\n                tenant_id TEXT NOT NULL,\n                status TEXT NOT NULL, -- 'running', 'completed', 'failed'\n                message TEXT,\n                started_at BIGINT NOT NULL,\n                finished_at BIGINT,\n                duration_ms BIGINT\n            )\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS graph_nodes (\n                id TEXT NOT NULL,\n                tenant_id TEXT NOT NULL,\n                label TEXT NOT NULL,\n                properties JSONB NOT NULL DEFAULT '{}',\n                created_at BIGINT NOT NULL,\n                PRIMARY KEY (id, tenant_id)\n            )\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS graph_edges (\n                id TEXT NOT NULL,\n                tenant_id TEXT NOT NULL,\n                source_id TEXT NOT NULL,\n                target_id TEXT NOT NULL,\n                relation TEXT NOT NULL,\n                properties JSONB NOT NULL DEFAULT '{}',\n                created_at BIGINT NOT NULL,\n                PRIMARY KEY (id, tenant_id),\n                FOREIGN KEY (source_id, tenant_id) REFERENCES graph_nodes(id, tenant_id) ON DELETE \\\n             CASCADE,\n                FOREIGN KEY (target_id, tenant_id) REFERENCES graph_nodes(id, tenant_id) ON DELETE \\\n             CASCADE\n            )\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE INDEX IF NOT EXISTS idx_graph_edges_source ON graph_edges(source_id, \\\n             tenant_id)\",\n        )\n        .execute(&self.pool)\n        .await?;\n        sqlx::query(\n            \"CREATE INDEX IF NOT EXISTS idx_graph_edges_target ON graph_edges(target_id, \\\n             tenant_id)\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS memory_entries ( id TEXT PRIMARY KEY, tenant_id TEXT NOT \\\n             NULL, content TEXT NOT NULL, embedding VECTOR(1536), memory_layer TEXT NOT NULL, \\\n             properties JSONB DEFAULT '{}', created_at BIGINT NOT NULL, updated_at BIGINT NOT \\\n             NULL, deleted_at BIGINT )\",\n        )\n        .execute(&self.pool)\n        .await\n        .ok();\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS knowledge_items ( id TEXT PRIMARY KEY, tenant_id TEXT NOT \\\n             NULL, type TEXT NOT NULL, title TEXT NOT NULL, content TEXT NOT NULL, tags TEXT[], \\\n             properties JSONB DEFAULT '{}', created_at BIGINT NOT NULL, updated_at BIGINT NOT \\\n             NULL )\",\n        )\n        .execute(&self.pool)\n        .await\n        .ok();\n\n        // CCA Hindsight Learning tables\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS error_signatures (\n                id TEXT PRIMARY KEY,\n                tenant_id TEXT NOT NULL,\n                error_type TEXT NOT NULL,\n                message_pattern TEXT NOT NULL,\n                stack_patterns JSONB DEFAULT '[]',\n                context_patterns JSONB DEFAULT '[]',\n                embedding JSONB,\n                occurrence_count INTEGER DEFAULT 1,\n                first_seen_at BIGINT NOT NULL,\n                last_seen_at BIGINT NOT NULL,\n                created_at BIGINT NOT NULL,\n                updated_at BIGINT NOT NULL\n            )\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE INDEX IF NOT EXISTS idx_error_signatures_tenant ON error_signatures(tenant_id)\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE INDEX IF NOT EXISTS idx_error_signatures_type ON error_signatures(tenant_id, error_type)\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS resolutions (\n                id TEXT PRIMARY KEY,\n                tenant_id TEXT NOT NULL,\n                error_signature_id TEXT NOT NULL REFERENCES error_signatures(id) ON DELETE CASCADE,\n                description TEXT NOT NULL,\n                changes JSONB DEFAULT '[]',\n                success_rate REAL DEFAULT 0.0,\n                application_count INTEGER DEFAULT 0,\n                last_success_at BIGINT,\n                created_at BIGINT NOT NULL,\n                updated_at BIGINT NOT NULL\n            )\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE INDEX IF NOT EXISTS idx_resolutions_error_signature ON resolutions(error_signature_id)\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS hindsight_notes (\n                id TEXT PRIMARY KEY,\n                tenant_id TEXT NOT NULL,\n                error_signature_id TEXT NOT NULL,\n                content TEXT NOT NULL,\n                tags JSONB DEFAULT '[]',\n                resolution_ids JSONB DEFAULT '[]',\n                quality_score REAL,\n                promoted_to_layer TEXT,\n                created_at BIGINT NOT NULL,\n                updated_at BIGINT NOT NULL\n            )\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE INDEX IF NOT EXISTS idx_hindsight_notes_tenant ON hindsight_notes(tenant_id)\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE INDEX IF NOT EXISTS idx_hindsight_notes_error_signature ON hindsight_notes(error_signature_id)\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS governance_configs (\n                id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n                company_id UUID,\n                org_id UUID,\n                team_id UUID,\n                project_id UUID,\n                approval_mode TEXT NOT NULL DEFAULT 'standard',\n                min_approvers INTEGER NOT NULL DEFAULT 1,\n                timeout_hours INTEGER DEFAULT 72,\n                auto_approve_low_risk BOOLEAN NOT NULL DEFAULT false,\n                escalation_enabled BOOLEAN NOT NULL DEFAULT false,\n                escalation_timeout_hours INTEGER,\n                escalation_contact TEXT,\n                policy_settings JSONB DEFAULT '{}',\n                knowledge_settings JSONB DEFAULT '{}',\n                memory_settings JSONB DEFAULT '{}',\n                created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n                updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n            )\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE UNIQUE INDEX IF NOT EXISTS idx_governance_configs_scope ON governance_configs (\n                COALESCE(company_id, '00000000-0000-0000-0000-000000000000'::UUID),\n                COALESCE(org_id, '00000000-0000-0000-0000-000000000000'::UUID),\n                COALESCE(team_id, '00000000-0000-0000-0000-000000000000'::UUID),\n                COALESCE(project_id, '00000000-0000-0000-0000-000000000000'::UUID)\n            )\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE UNIQUE INDEX IF NOT EXISTS idx_governance_configs_company \n             ON governance_configs (company_id) WHERE company_id IS NOT NULL\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\"CREATE SEQUENCE IF NOT EXISTS approval_requests_number_seq\")\n            .execute(&self.pool)\n            .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS approval_requests (\n                id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n                request_number TEXT NOT NULL DEFAULT 'REQ-' || nextval('approval_requests_number_seq')::TEXT,\n                request_type TEXT NOT NULL,\n                target_type TEXT NOT NULL,\n                target_id TEXT,\n                company_id UUID,\n                org_id UUID,\n                team_id UUID,\n                project_id UUID,\n                title TEXT NOT NULL,\n                description TEXT,\n                payload JSONB NOT NULL DEFAULT '{}',\n                risk_level TEXT NOT NULL DEFAULT 'medium',\n                status TEXT NOT NULL DEFAULT 'pending',\n                requestor_type TEXT NOT NULL,\n                requestor_id UUID NOT NULL,\n                requestor_email TEXT,\n                required_approvals INTEGER NOT NULL DEFAULT 1,\n                current_approvals INTEGER NOT NULL DEFAULT 0,\n                expires_at TIMESTAMPTZ,\n                resolved_at TIMESTAMPTZ,\n                resolution_reason TEXT,\n                applied_at TIMESTAMPTZ,\n                applied_by UUID,\n                created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n                updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n            )\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE INDEX IF NOT EXISTS idx_approval_requests_status ON approval_requests(status)\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE INDEX IF NOT EXISTS idx_approval_requests_requestor ON approval_requests(requestor_id)\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS approval_decisions (\n                id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n                request_id UUID NOT NULL REFERENCES approval_requests(id) ON DELETE CASCADE,\n                approver_type TEXT NOT NULL,\n                approver_id UUID NOT NULL,\n                approver_email TEXT,\n                decision TEXT NOT NULL,\n                comment TEXT,\n                created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n            )\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE INDEX IF NOT EXISTS idx_approval_decisions_request ON approval_decisions(request_id)\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS governance_roles (\n                id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n                principal_type TEXT NOT NULL,\n                principal_id UUID NOT NULL,\n                role TEXT NOT NULL,\n                company_id UUID,\n                org_id UUID,\n                team_id UUID,\n                project_id UUID,\n                granted_by UUID NOT NULL,\n                expires_at TIMESTAMPTZ,\n                granted_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n                revoked_at TIMESTAMPTZ,\n                revoked_by UUID\n            )\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE UNIQUE INDEX IF NOT EXISTS idx_governance_roles_unique ON governance_roles (\n                principal_type,\n                principal_id,\n                role,\n                COALESCE(company_id, '00000000-0000-0000-0000-000000000000'::UUID),\n                COALESCE(org_id, '00000000-0000-0000-0000-000000000000'::UUID),\n                COALESCE(team_id, '00000000-0000-0000-0000-000000000000'::UUID),\n                COALESCE(project_id, '00000000-0000-0000-0000-000000000000'::UUID)\n            )\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE INDEX IF NOT EXISTS idx_governance_roles_principal ON governance_roles(principal_type, principal_id)\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS governance_audit_log (\n                id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n                action TEXT NOT NULL,\n                request_id UUID,\n                target_type TEXT,\n                target_id TEXT,\n                actor_type TEXT NOT NULL,\n                actor_id UUID,\n                actor_email TEXT,\n                details JSONB DEFAULT '{}',\n                old_values JSONB,\n                new_values JSONB,\n                created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n            )\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE INDEX IF NOT EXISTS idx_governance_audit_log_action ON governance_audit_log(action)\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE INDEX IF NOT EXISTS idx_governance_audit_log_actor ON governance_audit_log(actor_id)\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE INDEX IF NOT EXISTS idx_governance_audit_log_target ON governance_audit_log(target_type)\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE OR REPLACE FUNCTION get_effective_governance_config(\n                p_company_id UUID,\n                p_org_id UUID,\n                p_team_id UUID,\n                p_project_id UUID\n            ) RETURNS TABLE (\n                id UUID,\n                approval_mode TEXT,\n                min_approvers INTEGER,\n                timeout_hours INTEGER,\n                auto_approve_low_risk BOOLEAN,\n                escalation_enabled BOOLEAN,\n                escalation_timeout_hours INTEGER,\n                escalation_contact TEXT,\n                policy_settings JSONB,\n                knowledge_settings JSONB,\n                memory_settings JSONB\n            ) AS $$\n            BEGIN\n                RETURN QUERY\n                SELECT \n                    gc.id,\n                    gc.approval_mode,\n                    gc.min_approvers,\n                    gc.timeout_hours,\n                    gc.auto_approve_low_risk,\n                    gc.escalation_enabled,\n                    gc.escalation_timeout_hours,\n                    gc.escalation_contact,\n                    gc.policy_settings,\n                    gc.knowledge_settings,\n                    gc.memory_settings\n                FROM governance_configs gc\n                WHERE (gc.project_id = p_project_id AND p_project_id IS NOT NULL)\n                   OR (gc.team_id = p_team_id AND gc.project_id IS NULL AND p_team_id IS NOT NULL)\n                   OR (gc.org_id = p_org_id AND gc.team_id IS NULL AND gc.project_id IS NULL AND p_org_id IS NOT NULL)\n                   OR (gc.company_id = p_company_id AND gc.org_id IS NULL AND gc.team_id IS NULL AND gc.project_id IS NULL)\n                ORDER BY \n                    CASE WHEN gc.project_id IS NOT NULL THEN 1\n                         WHEN gc.team_id IS NOT NULL THEN 2\n                         WHEN gc.org_id IS NOT NULL THEN 3\n                         ELSE 4 END\n                LIMIT 1;\n                \n                IF NOT FOUND THEN\n                    RETURN QUERY\n                    SELECT \n                        gen_random_uuid(),\n                        'standard'::TEXT,\n                        1::INTEGER,\n                        72::INTEGER,\n                        false::BOOLEAN,\n                        false::BOOLEAN,\n                        NULL::INTEGER,\n                        NULL::TEXT,\n                        '{}'::JSONB,\n                        '{}'::JSONB,\n                        '{}'::JSONB;\n                END IF;\n            END;\n            $$ LANGUAGE plpgsql\",\n        )\n        .execute(&self.pool)\n        .await?;\n\n        rls_migration::run_rls_migration(&self.pool).await?;\n\n        Ok(())\n    }\n\n    pub async fn create_unit(&self, unit: &OrganizationalUnit) -> Result<(), PostgresError> {\n        if let Some(ref parent_id) = unit.parent_id {\n            let parent = self\n                .get_unit_by_id(parent_id, &unit.tenant_id.to_string())\n                .await?\n                .ok_or_else(|| PostgresError::NotFound(parent_id.clone()))?;\n\n            match (parent.unit_type, unit.unit_type) {\n                (UnitType::Company, UnitType::Organization) => {}\n                (UnitType::Organization, UnitType::Team) => {}\n                (UnitType::Team, UnitType::Project) => {}\n                _ => {\n                    return Err(PostgresError::Database(sqlx::Error::Decode(\n                        format!(\n                            \"Invalid hierarchy: cannot create {:?} under {:?}\",\n                            unit.unit_type, parent.unit_type\n                        )\n                        .into(),\n                    )));\n                }\n            }\n        } else if unit.unit_type != UnitType::Company {\n            return Err(PostgresError::Database(sqlx::Error::Decode(\n                \"Only Company units can be root units (no parent)\".into(),\n            )));\n        }\n\n        sqlx::query(\n            \"INSERT INTO organizational_units (id, name, type, parent_id, tenant_id, metadata, \\\n             created_at, updated_at)\n             VALUES ($1, $2, $3, $4, $5, $6, $7, $8)\",\n        )\n        .bind(&unit.id)\n        .bind(&unit.name)\n        .bind(unit.unit_type.to_string().to_lowercase())\n        .bind(&unit.parent_id)\n        .bind(unit.tenant_id.as_str())\n        .bind(serde_json::to_value(&unit.metadata)?)\n        .bind(unit.created_at)\n        .bind(unit.updated_at)\n        .execute(&self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    fn row_to_persistent_event(\n        row: &sqlx::postgres::PgRow,\n    ) -> Result<mk_core::types::PersistentEvent, PostgresError> {\n        use sqlx::Row;\n\n        let status_str: String = row.get(\"status\");\n        let status = match status_str.as_str() {\n            \"pending\" => mk_core::types::EventStatus::Pending,\n            \"published\" => mk_core::types::EventStatus::Published,\n            \"acknowledged\" => mk_core::types::EventStatus::Acknowledged,\n            \"dead_lettered\" => mk_core::types::EventStatus::DeadLettered,\n            _ => mk_core::types::EventStatus::Pending,\n        };\n\n        let payload: mk_core::types::GovernanceEvent = serde_json::from_value(row.get(\"payload\"))?;\n\n        Ok(mk_core::types::PersistentEvent {\n            id: row.get(\"id\"),\n            event_id: row.get(\"event_id\"),\n            idempotency_key: row.get(\"idempotency_key\"),\n            tenant_id: row.get::<String, _>(\"tenant_id\").parse().map_err(|e| {\n                PostgresError::Database(sqlx::Error::Decode(\n                    format!(\"Invalid tenant_id: {}\", e).into(),\n                ))\n            })?,\n            event_type: row.get(\"event_type\"),\n            payload,\n            status,\n            retry_count: row.get(\"retry_count\"),\n            max_retries: row.get(\"max_retries\"),\n            last_error: row.get(\"last_error\"),\n            created_at: row.get(\"created_at\"),\n            published_at: row.get(\"published_at\"),\n            acknowledged_at: row.get(\"acknowledged_at\"),\n            dead_lettered_at: row.get(\"dead_lettered_at\"),\n        })\n    }\n\n    async fn get_unit_by_id(\n        &self,\n        id: &str,\n        tenant_id: &str,\n    ) -> Result<Option<OrganizationalUnit>, PostgresError> {\n        let row = sqlx::query(\n            \"SELECT id, name, type, parent_id, tenant_id, metadata, created_at, updated_at \n             FROM organizational_units WHERE id = $1 AND tenant_id = $2\",\n        )\n        .bind(id)\n        .bind(tenant_id)\n        .fetch_optional(&self.pool)\n        .await?;\n\n        if let Some(row) = row {\n            let unit_type_str: String = row.get(\"type\");\n            let unit_type = match unit_type_str.as_str() {\n                \"company\" => UnitType::Company,\n                \"organization\" => UnitType::Organization,\n                \"team\" => UnitType::Team,\n                \"project\" => UnitType::Project,\n                _ => {\n                    return Err(PostgresError::Database(sqlx::Error::Decode(\n                        \"Invalid unit type\".into(),\n                    )));\n                }\n            };\n\n            Ok(Some(OrganizationalUnit {\n                id: row.get(\"id\"),\n                name: row.get(\"name\"),\n                unit_type,\n                parent_id: row.get(\"parent_id\"),\n                tenant_id: row.get::<String, _>(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                metadata: serde_json::from_value(row.get(\"metadata\"))?,\n                created_at: row.get(\"created_at\"),\n                updated_at: row.get(\"updated_at\"),\n            }))\n        } else {\n            Ok(None)\n        }\n    }\n\n    pub async fn get_unit(\n        &self,\n        ctx: &TenantContext,\n        id: &str,\n    ) -> Result<Option<OrganizationalUnit>, PostgresError> {\n        let row = sqlx::query(\n            \"SELECT id, name, type, parent_id, tenant_id, metadata, created_at, updated_at \n             FROM organizational_units WHERE id = $1 AND tenant_id = $2\",\n        )\n        .bind(id)\n        .bind(ctx.tenant_id.as_str())\n        .fetch_optional(&self.pool)\n        .await?;\n\n        if let Some(row) = row {\n            let unit_type_str: String = row.get(\"type\");\n            let unit_type = match unit_type_str.as_str() {\n                \"company\" => UnitType::Company,\n                \"organization\" => UnitType::Organization,\n                \"team\" => UnitType::Team,\n                \"project\" => UnitType::Project,\n                _ => {\n                    return Err(PostgresError::Database(sqlx::Error::Decode(\n                        \"Invalid unit type\".into(),\n                    )));\n                }\n            };\n\n            Ok(Some(OrganizationalUnit {\n                id: row.get(\"id\"),\n                name: row.get(\"name\"),\n                unit_type,\n                parent_id: row.get(\"parent_id\"),\n                tenant_id: row.get::<String, _>(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                metadata: serde_json::from_value(row.get(\"metadata\"))?,\n                created_at: row.get(\"created_at\"),\n                updated_at: row.get(\"updated_at\"),\n            }))\n        } else {\n            Ok(None)\n        }\n    }\n\n    pub async fn list_children(\n        &self,\n        ctx: &TenantContext,\n        parent_id: &str,\n    ) -> Result<Vec<OrganizationalUnit>, PostgresError> {\n        let rows = sqlx::query(\n            \"SELECT id, name, type, parent_id, tenant_id, metadata, created_at, updated_at \n             FROM organizational_units WHERE parent_id = $1 AND tenant_id = $2\",\n        )\n        .bind(parent_id)\n        .bind(ctx.tenant_id.as_str())\n        .fetch_all(&self.pool)\n        .await?;\n\n        let mut units = Vec::new();\n        for row in rows {\n            let unit_type_str: String = row.get(\"type\");\n            let unit_type = match unit_type_str.as_str() {\n                \"company\" => UnitType::Company,\n                \"organization\" => UnitType::Organization,\n                \"team\" => UnitType::Team,\n                \"project\" => UnitType::Project,\n                _ => continue,\n            };\n\n            units.push(OrganizationalUnit {\n                id: row.get(\"id\"),\n                name: row.get(\"name\"),\n                unit_type,\n                parent_id: row.get(\"parent_id\"),\n                tenant_id: row.get::<String, _>(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                metadata: serde_json::from_value(row.get(\"metadata\"))?,\n                created_at: row.get(\"created_at\"),\n                updated_at: row.get(\"updated_at\"),\n            });\n        }\n\n        Ok(units)\n    }\n\n    pub async fn get_ancestors(\n        &self,\n        ctx: &TenantContext,\n        id: &str,\n    ) -> Result<Vec<OrganizationalUnit>, PostgresError> {\n        let rows = sqlx::query(\n            \"WITH RECURSIVE ancestors AS (\n                SELECT id, name, type, parent_id, tenant_id, metadata, created_at, updated_at\n                FROM organizational_units\n                WHERE id = $1 AND tenant_id = $2\n                UNION ALL\n                SELECT u.id, u.name, u.type, u.parent_id, u.tenant_id, u.metadata, u.created_at, \\\n             u.updated_at\n                FROM organizational_units u\n                INNER JOIN ancestors a ON u.id = a.parent_id AND u.tenant_id = a.tenant_id\n            )\n            SELECT * FROM ancestors WHERE id != $1\",\n        )\n        .bind(id)\n        .bind(ctx.tenant_id.as_str())\n        .fetch_all(&self.pool)\n        .await?;\n\n        let mut units = Vec::new();\n        for row in rows {\n            let unit_type_str: String = row.get(\"type\");\n            let unit_type = match unit_type_str.as_str() {\n                \"company\" => UnitType::Company,\n                \"organization\" => UnitType::Organization,\n                \"team\" => UnitType::Team,\n                \"project\" => UnitType::Project,\n                _ => continue,\n            };\n\n            units.push(OrganizationalUnit {\n                id: row.get(\"id\"),\n                name: row.get(\"name\"),\n                unit_type,\n                parent_id: row.get(\"parent_id\"),\n                tenant_id: row.get::<String, _>(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                metadata: serde_json::from_value(row.get(\"metadata\"))?,\n                created_at: row.get(\"created_at\"),\n                updated_at: row.get(\"updated_at\"),\n            });\n        }\n\n        Ok(units)\n    }\n\n    pub async fn get_unit_ancestors(\n        &self,\n        ctx: &TenantContext,\n        id: &str,\n    ) -> Result<Vec<OrganizationalUnit>, PostgresError> {\n        self.get_ancestors(ctx, id).await\n    }\n\n    pub async fn get_unit_descendants(\n        &self,\n        ctx: &TenantContext,\n        id: &str,\n    ) -> Result<Vec<OrganizationalUnit>, PostgresError> {\n        let rows = sqlx::query(\n            \"WITH RECURSIVE descendants AS (\n                SELECT id, name, type, parent_id, tenant_id, metadata, created_at, updated_at\n                FROM organizational_units\n                WHERE id = $1 AND tenant_id = $2\n                UNION ALL\n                SELECT u.id, u.name, u.type, u.parent_id, u.tenant_id, u.metadata, u.created_at, \\\n             u.updated_at\n                FROM organizational_units u\n                INNER JOIN descendants d ON u.parent_id = d.id AND u.tenant_id = d.tenant_id\n            )\n            SELECT * FROM descendants WHERE id != $1\",\n        )\n        .bind(id)\n        .bind(ctx.tenant_id.as_str())\n        .fetch_all(&self.pool)\n        .await?;\n\n        let mut units = Vec::new();\n        for row in rows {\n            let unit_type_str: String = row.get(\"type\");\n            let unit_type = match unit_type_str.as_str() {\n                \"company\" => UnitType::Company,\n                \"organization\" => UnitType::Organization,\n                \"team\" => UnitType::Team,\n                \"project\" => UnitType::Project,\n                _ => continue,\n            };\n\n            units.push(OrganizationalUnit {\n                id: row.get(\"id\"),\n                name: row.get(\"name\"),\n                unit_type,\n                parent_id: row.get(\"parent_id\"),\n                tenant_id: row.get::<String, _>(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                metadata: serde_json::from_value(row.get(\"metadata\"))?,\n                created_at: row.get(\"created_at\"),\n                updated_at: row.get(\"updated_at\"),\n            });\n        }\n\n        Ok(units)\n    }\n\n    pub async fn update_unit(\n        &self,\n        ctx: &TenantContext,\n        unit: &OrganizationalUnit,\n    ) -> Result<(), PostgresError> {\n        sqlx::query(\n            \"UPDATE organizational_units \n             SET name = $3, type = $4, parent_id = $5, metadata = $6, updated_at = $7\n             WHERE id = $1 AND tenant_id = $2\",\n        )\n        .bind(&unit.id)\n        .bind(ctx.tenant_id.as_str())\n        .bind(&unit.name)\n        .bind(unit.unit_type.to_string().to_lowercase())\n        .bind(&unit.parent_id)\n        .bind(serde_json::to_value(&unit.metadata)?)\n        .bind(unit.updated_at)\n        .execute(&self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    pub async fn delete_unit(&self, ctx: &TenantContext, id: &str) -> Result<(), PostgresError> {\n        sqlx::query(\"DELETE FROM organizational_units WHERE id = $1 AND tenant_id = $2\")\n            .bind(id)\n            .bind(ctx.tenant_id.as_str())\n            .execute(&self.pool)\n            .await?;\n\n        Ok(())\n    }\n\n    pub async fn add_unit_policy(\n        &self,\n        ctx: &TenantContext,\n        unit_id: &str,\n        policy: &mk_core::types::Policy,\n    ) -> Result<(), PostgresError> {\n        let exists: Option<(i32,)> =\n            sqlx::query_as(\"SELECT 1 FROM organizational_units WHERE id = $1 AND tenant_id = $2\")\n                .bind(unit_id)\n                .bind(ctx.tenant_id.as_str())\n                .fetch_optional(&self.pool)\n                .await?;\n\n        if exists.is_none() {\n            return Err(PostgresError::NotFound(unit_id.to_string()));\n        }\n\n        sqlx::query(\n            \"INSERT INTO unit_policies (id, unit_id, policy, created_at, updated_at)\n             VALUES ($1, $2, $3, $4, $5)\n             ON CONFLICT (id) DO UPDATE SET policy = $3, updated_at = $5\",\n        )\n        .bind(&policy.id)\n        .bind(unit_id)\n        .bind(serde_json::to_value(policy)?)\n        .bind(chrono::Utc::now().timestamp())\n        .bind(chrono::Utc::now().timestamp())\n        .execute(&self.pool)\n        .await?;\n        Ok(())\n    }\n\n    pub async fn get_unit_policies(\n        &self,\n        ctx: &TenantContext,\n        unit_id: &str,\n    ) -> Result<Vec<mk_core::types::Policy>, PostgresError> {\n        let rows = sqlx::query(\n            \"SELECT p.policy \n             FROM unit_policies p\n             JOIN organizational_units u ON p.unit_id = u.id\n             WHERE p.unit_id = $1 AND u.tenant_id = $2\",\n        )\n        .bind(unit_id)\n        .bind(ctx.tenant_id.as_str())\n        .fetch_all(&self.pool)\n        .await?;\n\n        let mut policies = Vec::new();\n        for row in rows {\n            let policy: mk_core::types::Policy = serde_json::from_value(row.get(\"policy\"))?;\n            policies.push(policy);\n        }\n        Ok(policies)\n    }\n\n    pub async fn assign_role(\n        &self,\n        user_id: &mk_core::types::UserId,\n        tenant_id: &mk_core::types::TenantId,\n        unit_id: &str,\n        role: mk_core::types::Role,\n    ) -> Result<(), PostgresError> {\n        sqlx::query(\n            \"INSERT INTO user_roles (user_id, tenant_id, unit_id, role, created_at)\n             VALUES ($1, $2, $3, $4, $5)\n             ON CONFLICT (user_id, tenant_id, unit_id, role) DO NOTHING\",\n        )\n        .bind(user_id.as_str())\n        .bind(tenant_id.as_str())\n        .bind(unit_id)\n        .bind(role.to_string().to_lowercase())\n        .bind(chrono::Utc::now().timestamp())\n        .execute(&self.pool)\n        .await?;\n        Ok(())\n    }\n\n    pub async fn remove_role(\n        &self,\n        user_id: &mk_core::types::UserId,\n        tenant_id: &mk_core::types::TenantId,\n        unit_id: &str,\n        role: mk_core::types::Role,\n    ) -> Result<(), PostgresError> {\n        sqlx::query(\n            \"DELETE FROM user_roles \n             WHERE user_id = $1 AND tenant_id = $2 AND unit_id = $3 AND role = $4\",\n        )\n        .bind(user_id.as_str())\n        .bind(tenant_id.as_str())\n        .bind(unit_id)\n        .bind(role.to_string().to_lowercase())\n        .execute(&self.pool)\n        .await?;\n        Ok(())\n    }\n\n    pub async fn get_user_roles(\n        &self,\n        user_id: &mk_core::types::UserId,\n        tenant_id: &mk_core::types::TenantId,\n    ) -> Result<Vec<(String, mk_core::types::Role)>, PostgresError> {\n        let rows = sqlx::query(\n            \"SELECT unit_id, role FROM user_roles WHERE user_id = $1 AND tenant_id = $2\",\n        )\n        .bind(user_id.as_str())\n        .bind(tenant_id.as_str())\n        .fetch_all(&self.pool)\n        .await?;\n\n        let mut roles = Vec::new();\n        for row in rows {\n            let unit_id: String = row.get(\"unit_id\");\n            let role_str: String = row.get(\"role\");\n            if let Ok(role) = role_str.parse() {\n                roles.push((unit_id, role));\n            }\n        }\n        Ok(roles)\n    }\n    pub async fn log_event(\n        &self,\n        event: &mk_core::types::GovernanceEvent,\n    ) -> Result<(), PostgresError> {\n        let (event_type, tenant_id, timestamp) = match event {\n            mk_core::types::GovernanceEvent::UnitCreated {\n                unit_id: _,\n                unit_type: _,\n                tenant_id,\n                parent_id: _,\n                timestamp,\n            } => (\"unit_created\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::UnitUpdated {\n                unit_id: _,\n                tenant_id,\n                timestamp,\n            } => (\"unit_updated\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::UnitDeleted {\n                unit_id: _,\n                tenant_id,\n                timestamp,\n            } => (\"unit_deleted\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::RoleAssigned {\n                user_id: _,\n                unit_id: _,\n                role: _,\n                tenant_id,\n                timestamp,\n            } => (\"role_assigned\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::RoleRemoved {\n                user_id: _,\n                unit_id: _,\n                role: _,\n                tenant_id,\n                timestamp,\n            } => (\"role_removed\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::PolicyUpdated {\n                policy_id: _,\n                layer: _,\n                tenant_id,\n                timestamp,\n            } => (\"policy_updated\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::PolicyDeleted {\n                policy_id: _,\n                tenant_id,\n                timestamp,\n            } => (\"policy_deleted\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::DriftDetected {\n                project_id: _,\n                tenant_id,\n                drift_score: _,\n                timestamp,\n            } => (\"drift_detected\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::ConfigUpdated {\n                config_id: _,\n                scope: _,\n                tenant_id,\n                timestamp,\n            } => (\"config_updated\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::RequestCreated {\n                request_id: _,\n                request_type: _,\n                title: _,\n                tenant_id,\n                timestamp,\n            } => (\"request_created\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::RequestApproved {\n                request_id: _,\n                approver_id: _,\n                fully_approved: _,\n                tenant_id,\n                timestamp,\n            } => (\"request_approved\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::RequestRejected {\n                request_id: _,\n                rejector_id: _,\n                reason: _,\n                tenant_id,\n                timestamp,\n            } => (\"request_rejected\", tenant_id, *timestamp),\n        };\n\n        sqlx::query(\n            \"INSERT INTO governance_events (event_type, tenant_id, payload, timestamp)\n             VALUES ($1, $2, $3, $4)\",\n        )\n        .bind(event_type)\n        .bind(tenant_id.as_str())\n        .bind(serde_json::to_value(event)?)\n        .bind(timestamp)\n        .execute(&self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    pub async fn get_governance_events_internal(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        since_timestamp: i64,\n        limit: usize,\n    ) -> Result<Vec<mk_core::types::GovernanceEvent>, PostgresError> {\n        let rows = sqlx::query(\n            \"SELECT payload FROM governance_events \n             WHERE tenant_id = $1 AND timestamp > $2 \n             ORDER BY timestamp ASC LIMIT $3\",\n        )\n        .bind(ctx.tenant_id.as_str())\n        .bind(since_timestamp)\n        .bind(limit as i64)\n        .fetch_all(&self.pool)\n        .await?;\n\n        let mut events = Vec::new();\n        for row in rows {\n            use sqlx::Row;\n            let payload: serde_json::Value = row.get(\"payload\");\n            let event: mk_core::types::GovernanceEvent = serde_json::from_value(payload)?;\n            events.push(event);\n        }\n        Ok(events)\n    }\n}\n\n#[async_trait]\nimpl crate::graph::GraphStore for PostgresBackend {\n    type Error = PostgresError;\n\n    async fn add_node(\n        &self,\n        ctx: TenantContext,\n        node: crate::graph::GraphNode,\n    ) -> Result<(), Self::Error> {\n        sqlx::query(\n            \"INSERT INTO graph_nodes (id, tenant_id, label, properties, created_at)\n             VALUES ($1, $2, $3, $4, $5)\n             ON CONFLICT (id, tenant_id) DO UPDATE SET label = $3, properties = $4\",\n        )\n        .bind(&node.id)\n        .bind(ctx.tenant_id.as_str())\n        .bind(&node.label)\n        .bind(&node.properties)\n        .bind(chrono::Utc::now().timestamp())\n        .execute(&self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    async fn add_edge(\n        &self,\n        ctx: TenantContext,\n        edge: crate::graph::GraphEdge,\n    ) -> Result<(), Self::Error> {\n        sqlx::query(\n            \"INSERT INTO graph_edges (id, tenant_id, source_id, target_id, relation, properties, \\\n             created_at)\n             VALUES ($1, $2, $3, $4, $5, $6, $7)\n             ON CONFLICT (id, tenant_id) DO UPDATE SET relation = $5, properties = $6\",\n        )\n        .bind(&edge.id)\n        .bind(ctx.tenant_id.as_str())\n        .bind(&edge.source_id)\n        .bind(&edge.target_id)\n        .bind(&edge.relation)\n        .bind(&edge.properties)\n        .bind(chrono::Utc::now().timestamp())\n        .execute(&self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    async fn get_neighbors(\n        &self,\n        ctx: TenantContext,\n        node_id: &str,\n    ) -> Result<Vec<(crate::graph::GraphEdge, crate::graph::GraphNode)>, Self::Error> {\n        let rows = sqlx::query(\n            \"SELECT e.id as edge_id, e.source_id, e.target_id, e.relation, e.properties as \\\n             edge_props,\n                    n.id as node_id, n.label, n.properties as node_props\n             FROM graph_edges e\n             JOIN graph_nodes n ON e.target_id = n.id AND e.tenant_id = n.tenant_id\n             WHERE e.source_id = $1 AND e.tenant_id = $2\",\n        )\n        .bind(node_id)\n        .bind(ctx.tenant_id.as_str())\n        .fetch_all(&self.pool)\n        .await?;\n\n        let mut results = Vec::new();\n        for row in rows {\n            let edge = crate::graph::GraphEdge {\n                id: row.get(\"edge_id\"),\n                source_id: row.get(\"source_id\"),\n                target_id: row.get(\"target_id\"),\n                relation: row.get(\"relation\"),\n                properties: row.get(\"edge_props\"),\n                tenant_id: ctx.tenant_id.as_str().to_string(),\n            };\n            let node = crate::graph::GraphNode {\n                id: row.get(\"node_id\"),\n                label: row.get(\"label\"),\n                properties: row.get(\"node_props\"),\n                tenant_id: ctx.tenant_id.as_str().to_string(),\n            };\n            results.push((edge, node));\n        }\n        Ok(results)\n    }\n\n    async fn find_path(\n        &self,\n        ctx: TenantContext,\n        start_id: &str,\n        end_id: &str,\n        max_depth: usize,\n    ) -> Result<Vec<crate::graph::GraphEdge>, Self::Error> {\n        let rows = sqlx::query(\n            \"WITH RECURSIVE search_path(id, source_id, target_id, relation, properties, depth, \\\n             path) AS (\n                SELECT id, source_id, target_id, relation, properties, 1, ARRAY[id]\n                FROM graph_edges\n                WHERE source_id = $1 AND tenant_id = $3\n                UNION ALL\n                SELECT e.id, e.source_id, e.target_id, e.relation, e.properties, sp.depth + 1, \\\n             sp.path || e.id\n                FROM graph_edges e\n                JOIN search_path sp ON e.source_id = sp.target_id AND e.tenant_id = $3\n                WHERE sp.depth < $4 AND NOT (e.id = ANY(sp.path))\n            )\n            SELECT id, source_id, target_id, relation, properties\n            FROM search_path\n            WHERE target_id = $2\n            LIMIT 1\",\n        )\n        .bind(start_id)\n        .bind(end_id)\n        .bind(ctx.tenant_id.as_str())\n        .bind(max_depth as i32)\n        .fetch_all(&self.pool)\n        .await?;\n\n        let mut path = Vec::new();\n        for row in rows {\n            path.push(crate::graph::GraphEdge {\n                id: row.get(\"id\"),\n                source_id: row.get(\"source_id\"),\n                target_id: row.get(\"target_id\"),\n                relation: row.get(\"relation\"),\n                properties: row.get(\"properties\"),\n                tenant_id: ctx.tenant_id.as_str().to_string(),\n            });\n        }\n        Ok(path)\n    }\n\n    async fn search_nodes(\n        &self,\n        ctx: TenantContext,\n        query: &str,\n        limit: usize,\n    ) -> Result<Vec<crate::graph::GraphNode>, Self::Error> {\n        let rows = sqlx::query(\n            \"SELECT id, label, properties FROM graph_nodes\n             WHERE tenant_id = $1 AND (id ILIKE $2 OR label ILIKE $2)\n             LIMIT $3\",\n        )\n        .bind(ctx.tenant_id.as_str())\n        .bind(format!(\"%{}%\", query))\n        .bind(limit as i64)\n        .fetch_all(&self.pool)\n        .await?;\n\n        let mut nodes = Vec::new();\n        for row in rows {\n            nodes.push(crate::graph::GraphNode {\n                id: row.get(\"id\"),\n                label: row.get(\"label\"),\n                properties: row.get(\"properties\"),\n                tenant_id: ctx.tenant_id.as_str().to_string(),\n            });\n        }\n        Ok(nodes)\n    }\n\n    async fn soft_delete_nodes_by_source_memory_id(\n        &self,\n        ctx: TenantContext,\n        source_memory_id: &str,\n    ) -> Result<usize, Self::Error> {\n        let result = sqlx::query(\n            \"UPDATE graph_nodes SET deleted_at = NOW() \n             WHERE tenant_id = $1 \n             AND deleted_at IS NULL \n             AND properties->>'source_memory_id' = $2\",\n        )\n        .bind(ctx.tenant_id.as_str())\n        .bind(source_memory_id)\n        .execute(&self.pool)\n        .await?;\n\n        let deleted_count = result.rows_affected() as usize;\n\n        sqlx::query(\n            \"UPDATE graph_edges SET deleted_at = NOW()\n             WHERE tenant_id = $1 \n             AND deleted_at IS NULL\n             AND (source_id IN (\n                SELECT id FROM graph_nodes \n                WHERE tenant_id = $1 AND properties->>'source_memory_id' = $2\n             ) OR target_id IN (\n                SELECT id FROM graph_nodes \n                WHERE tenant_id = $1 AND properties->>'source_memory_id' = $2\n             ))\",\n        )\n        .bind(ctx.tenant_id.as_str())\n        .bind(source_memory_id)\n        .execute(&self.pool)\n        .await?;\n\n        Ok(deleted_count)\n    }\n}\n\n#[async_trait]\nimpl mk_core::traits::EventPublisher for PostgresBackend {\n    type Error = PostgresError;\n\n    async fn publish(&self, event: mk_core::types::GovernanceEvent) -> Result<(), Self::Error> {\n        self.log_event(&event).await\n    }\n\n    async fn subscribe(\n        &self,\n        _channels: &[&str],\n    ) -> Result<tokio::sync::mpsc::Receiver<mk_core::types::GovernanceEvent>, Self::Error> {\n        Err(PostgresError::Database(sqlx::Error::Decode(\n            \"Subscribe not implemented for Postgres backend\".into(),\n        )))\n    }\n}\n\n#[async_trait]\nimpl StorageBackend for PostgresBackend {\n    type Error = PostgresError;\n\n    async fn store(&self, ctx: TenantContext, key: &str, value: &[u8]) -> Result<(), Self::Error> {\n        sqlx::query(\n            \"INSERT INTO sync_state (id, tenant_id, data, updated_at)\n             VALUES ($1, $2, $3, $4)\n             ON CONFLICT (id, tenant_id) DO UPDATE SET data = $3, updated_at = $4\",\n        )\n        .bind(key)\n        .bind(ctx.tenant_id.as_str())\n        .bind(serde_json::from_slice::<serde_json::Value>(value).unwrap_or_default())\n        .bind(chrono::Utc::now().timestamp())\n        .execute(&self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    async fn retrieve(\n        &self,\n        ctx: TenantContext,\n        key: &str,\n    ) -> Result<Option<Vec<u8>>, Self::Error> {\n        let row: Option<(serde_json::Value,)> =\n            sqlx::query_as(\"SELECT data FROM sync_state WHERE id = $1 AND tenant_id = $2\")\n                .bind(key)\n                .bind(ctx.tenant_id.as_str())\n                .fetch_optional(&self.pool)\n                .await?;\n\n        Ok(row.and_then(|(v,)| serde_json::to_vec(&v).ok()))\n    }\n\n    async fn delete(&self, ctx: TenantContext, key: &str) -> Result<(), Self::Error> {\n        sqlx::query(\"DELETE FROM sync_state WHERE id = $1 AND tenant_id = $2\")\n            .bind(key)\n            .bind(ctx.tenant_id.as_str())\n            .execute(&self.pool)\n            .await?;\n\n        Ok(())\n    }\n\n    async fn exists(&self, ctx: TenantContext, key: &str) -> Result<bool, Self::Error> {\n        let row: Option<(i32,)> =\n            sqlx::query_as(\"SELECT 1 FROM sync_state WHERE id = $1 AND tenant_id = $2\")\n                .bind(key)\n                .bind(ctx.tenant_id.as_str())\n                .fetch_optional(&self.pool)\n                .await?;\n\n        Ok(row.is_some())\n    }\n\n    async fn get_ancestors(\n        &self,\n        ctx: TenantContext,\n        unit_id: &str,\n    ) -> Result<Vec<OrganizationalUnit>, Self::Error> {\n        self.get_unit_ancestors(&ctx, unit_id).await\n    }\n\n    async fn get_descendants(\n        &self,\n        ctx: TenantContext,\n        unit_id: &str,\n    ) -> Result<Vec<OrganizationalUnit>, Self::Error> {\n        self.get_unit_descendants(&ctx, unit_id).await\n    }\n\n    async fn get_unit_policies(\n        &self,\n        ctx: TenantContext,\n        unit_id: &str,\n    ) -> Result<Vec<mk_core::types::Policy>, Self::Error> {\n        self.get_unit_policies(&ctx, unit_id).await\n    }\n\n    async fn create_unit(&self, unit: &OrganizationalUnit) -> Result<(), Self::Error> {\n        self.create_unit(unit).await\n    }\n\n    async fn add_unit_policy(\n        &self,\n        ctx: &TenantContext,\n        unit_id: &str,\n        policy: &mk_core::types::Policy,\n    ) -> Result<(), Self::Error> {\n        self.add_unit_policy(ctx, unit_id, policy).await\n    }\n\n    async fn assign_role(\n        &self,\n        user_id: &mk_core::types::UserId,\n        tenant_id: &mk_core::types::TenantId,\n        unit_id: &str,\n        role: mk_core::types::Role,\n    ) -> Result<(), Self::Error> {\n        self.assign_role(user_id, tenant_id, unit_id, role).await\n    }\n\n    async fn remove_role(\n        &self,\n        user_id: &mk_core::types::UserId,\n        tenant_id: &mk_core::types::TenantId,\n        unit_id: &str,\n        role: mk_core::types::Role,\n    ) -> Result<(), Self::Error> {\n        self.remove_role(user_id, tenant_id, unit_id, role).await\n    }\n\n    async fn store_drift_result(\n        &self,\n        result: mk_core::types::DriftResult,\n    ) -> Result<(), Self::Error> {\n        sqlx::query(\n            \"INSERT INTO drift_results (project_id, tenant_id, drift_score, confidence, \\\n             violations, suppressed_violations, requires_manual_review, timestamp)\n             VALUES ($1, $2, $3, $4, $5, $6, $7, $8)\",\n        )\n        .bind(&result.project_id)\n        .bind(result.tenant_id.as_str())\n        .bind(result.drift_score)\n        .bind(result.confidence)\n        .bind(serde_json::to_value(&result.violations)?)\n        .bind(serde_json::to_value(&result.suppressed_violations)?)\n        .bind(result.requires_manual_review)\n        .bind(result.timestamp)\n        .execute(&self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    async fn get_latest_drift_result(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        project_id: &str,\n    ) -> Result<Option<mk_core::types::DriftResult>, Self::Error> {\n        let row = sqlx::query(\n            \"SELECT project_id, tenant_id, drift_score, confidence, violations, \\\n             suppressed_violations, requires_manual_review, timestamp \n             FROM drift_results \n             WHERE project_id = $1 AND tenant_id = $2 \n             ORDER BY timestamp DESC LIMIT 1\",\n        )\n        .bind(project_id)\n        .bind(ctx.tenant_id.as_str())\n        .fetch_optional(&self.pool)\n        .await?;\n\n        if let Some(row) = row {\n            Ok(Some(mk_core::types::DriftResult {\n                project_id: row.get(\"project_id\"),\n                tenant_id: row.get::<String, _>(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                drift_score: row.get(\"drift_score\"),\n                confidence: row.get(\"confidence\"),\n                violations: serde_json::from_value(row.get(\"violations\"))?,\n                suppressed_violations: serde_json::from_value(row.get(\"suppressed_violations\"))?,\n                requires_manual_review: row.get(\"requires_manual_review\"),\n                timestamp: row.get(\"timestamp\"),\n            }))\n        } else {\n            Ok(None)\n        }\n    }\n\n    async fn record_job_status(\n        &self,\n        job_name: &str,\n        tenant_id: &str,\n        status: &str,\n        message: Option<&str>,\n        started_at: i64,\n        finished_at: Option<i64>,\n    ) -> Result<(), Self::Error> {\n        let duration_ms = finished_at.map(|f| (f - started_at) * 1000);\n\n        sqlx::query(\n            \"INSERT INTO job_status (job_name, tenant_id, status, message, started_at, \\\n             finished_at, duration_ms)\n             VALUES ($1, $2, $3, $4, $5, $6, $7)\",\n        )\n        .bind(job_name)\n        .bind(tenant_id)\n        .bind(status)\n        .bind(message)\n        .bind(started_at)\n        .bind(finished_at)\n        .bind(duration_ms)\n        .execute(&self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    async fn get_governance_events(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        since_timestamp: i64,\n        limit: usize,\n    ) -> Result<Vec<mk_core::types::GovernanceEvent>, Self::Error> {\n        self.get_governance_events_internal(ctx, since_timestamp, limit)\n            .await\n    }\n\n    async fn list_all_units(&self) -> Result<Vec<mk_core::types::OrganizationalUnit>, Self::Error> {\n        let rows = sqlx::query(\n            \"SELECT id, name, type, parent_id, tenant_id, metadata, created_at, updated_at \n             FROM organizational_units\",\n        )\n        .fetch_all(&self.pool)\n        .await?;\n\n        let mut units = Vec::new();\n        for row in rows {\n            let unit_type_str: String = row.get(\"type\");\n            let unit_type = match unit_type_str.as_str() {\n                \"company\" => UnitType::Company,\n                \"organization\" => UnitType::Organization,\n                \"team\" => UnitType::Team,\n                \"project\" => UnitType::Project,\n                _ => continue,\n            };\n\n            units.push(mk_core::types::OrganizationalUnit {\n                id: row.get(\"id\"),\n                name: row.get(\"name\"),\n                unit_type,\n                parent_id: row.get(\"parent_id\"),\n                tenant_id: row.get::<String, _>(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                metadata: serde_json::from_value(row.get(\"metadata\"))?,\n                created_at: row.get(\"created_at\"),\n                updated_at: row.get(\"updated_at\"),\n            });\n        }\n\n        Ok(units)\n    }\n\n    async fn create_suppression(\n        &self,\n        suppression: mk_core::types::DriftSuppression,\n    ) -> Result<(), Self::Error> {\n        sqlx::query(\n            \"INSERT INTO drift_suppressions (id, project_id, tenant_id, policy_id, rule_pattern, \\\n             reason, created_by, expires_at, created_at)\n             VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)\",\n        )\n        .bind(&suppression.id)\n        .bind(&suppression.project_id)\n        .bind(suppression.tenant_id.as_str())\n        .bind(&suppression.policy_id)\n        .bind(&suppression.rule_pattern)\n        .bind(&suppression.reason)\n        .bind(suppression.created_by.as_str())\n        .bind(suppression.expires_at)\n        .bind(suppression.created_at)\n        .execute(&self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    async fn list_suppressions(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        project_id: &str,\n    ) -> Result<Vec<mk_core::types::DriftSuppression>, Self::Error> {\n        let rows = sqlx::query(\n            \"SELECT id, project_id, tenant_id, policy_id, rule_pattern, reason, created_by, \\\n             expires_at, created_at\n             FROM drift_suppressions\n             WHERE project_id = $1 AND tenant_id = $2\n             ORDER BY created_at DESC\",\n        )\n        .bind(project_id)\n        .bind(ctx.tenant_id.as_str())\n        .fetch_all(&self.pool)\n        .await?;\n\n        let mut suppressions = Vec::new();\n        for row in rows {\n            suppressions.push(mk_core::types::DriftSuppression {\n                id: row.get(\"id\"),\n                project_id: row.get(\"project_id\"),\n                tenant_id: row.get::<String, _>(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                policy_id: row.get(\"policy_id\"),\n                rule_pattern: row.get(\"rule_pattern\"),\n                reason: row.get(\"reason\"),\n                created_by: row.get::<String, _>(\"created_by\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid created_by: {}\", e).into(),\n                    ))\n                })?,\n                expires_at: row.get(\"expires_at\"),\n                created_at: row.get(\"created_at\"),\n            });\n        }\n\n        Ok(suppressions)\n    }\n\n    async fn delete_suppression(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        suppression_id: &str,\n    ) -> Result<(), Self::Error> {\n        sqlx::query(\"DELETE FROM drift_suppressions WHERE id = $1 AND tenant_id = $2\")\n            .bind(suppression_id)\n            .bind(ctx.tenant_id.as_str())\n            .execute(&self.pool)\n            .await?;\n\n        Ok(())\n    }\n\n    async fn get_drift_config(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        project_id: &str,\n    ) -> Result<Option<mk_core::types::DriftConfig>, Self::Error> {\n        let row = sqlx::query(\n            \"SELECT project_id, tenant_id, threshold, low_confidence_threshold, \\\n             auto_suppress_info, updated_at\n             FROM drift_configs\n             WHERE project_id = $1 AND tenant_id = $2\",\n        )\n        .bind(project_id)\n        .bind(ctx.tenant_id.as_str())\n        .fetch_optional(&self.pool)\n        .await?;\n\n        if let Some(row) = row {\n            Ok(Some(mk_core::types::DriftConfig {\n                project_id: row.get(\"project_id\"),\n                tenant_id: row.get::<String, _>(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                threshold: row.get(\"threshold\"),\n                low_confidence_threshold: row.get(\"low_confidence_threshold\"),\n                auto_suppress_info: row.get(\"auto_suppress_info\"),\n                updated_at: row.get(\"updated_at\"),\n            }))\n        } else {\n            Ok(None)\n        }\n    }\n\n    async fn save_drift_config(\n        &self,\n        config: mk_core::types::DriftConfig,\n    ) -> Result<(), Self::Error> {\n        sqlx::query(\n            \"INSERT INTO drift_configs (project_id, tenant_id, threshold, \\\n             low_confidence_threshold, auto_suppress_info, updated_at)\n             VALUES ($1, $2, $3, $4, $5, $6)\n             ON CONFLICT (project_id, tenant_id) DO UPDATE SET\n                threshold = EXCLUDED.threshold,\n                low_confidence_threshold = EXCLUDED.low_confidence_threshold,\n                auto_suppress_info = EXCLUDED.auto_suppress_info,\n                updated_at = EXCLUDED.updated_at\",\n        )\n        .bind(&config.project_id)\n        .bind(config.tenant_id.as_str())\n        .bind(config.threshold)\n        .bind(config.low_confidence_threshold)\n        .bind(config.auto_suppress_info)\n        .bind(config.updated_at)\n        .execute(&self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    async fn persist_event(\n        &self,\n        event: mk_core::types::PersistentEvent,\n    ) -> Result<(), Self::Error> {\n        sqlx::query(\n            \"INSERT INTO governance_events (id, event_id, idempotency_key, tenant_id, event_type, \\\n             payload, status, retry_count, max_retries, last_error, created_at, published_at, \\\n             acknowledged_at, dead_lettered_at)\n             VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, to_timestamp($11), $12, $13, $14)\n             ON CONFLICT (idempotency_key) DO NOTHING\",\n        )\n        .bind(&event.id)\n        .bind(&event.event_id)\n        .bind(&event.idempotency_key)\n        .bind(event.tenant_id.as_str())\n        .bind(&event.event_type)\n        .bind(serde_json::to_value(&event.payload)?)\n        .bind(event.status.to_string())\n        .bind(event.retry_count)\n        .bind(event.max_retries)\n        .bind(&event.last_error)\n        .bind(event.created_at)\n        .bind(\n            event\n                .published_at\n                .map(|ts| chrono::DateTime::from_timestamp(ts, 0)),\n        )\n        .bind(\n            event\n                .acknowledged_at\n                .map(|ts| chrono::DateTime::from_timestamp(ts, 0)),\n        )\n        .bind(\n            event\n                .dead_lettered_at\n                .map(|ts| chrono::DateTime::from_timestamp(ts, 0)),\n        )\n        .execute(&self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    async fn get_pending_events(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        limit: usize,\n    ) -> Result<Vec<mk_core::types::PersistentEvent>, Self::Error> {\n        let rows = sqlx::query(\n            \"SELECT id, event_id, idempotency_key, tenant_id, event_type, payload, status, \\\n             retry_count, max_retries, last_error, \n                    EXTRACT(EPOCH FROM created_at)::bigint as created_at,\n                    EXTRACT(EPOCH FROM published_at)::bigint as published_at,\n                    EXTRACT(EPOCH FROM acknowledged_at)::bigint as acknowledged_at,\n                    EXTRACT(EPOCH FROM dead_lettered_at)::bigint as dead_lettered_at\n             FROM governance_events\n             WHERE tenant_id = $1 AND status = 'pending'\n             ORDER BY created_at ASC\n             LIMIT $2\",\n        )\n        .bind(ctx.tenant_id.as_str())\n        .bind(limit as i64)\n        .fetch_all(&self.pool)\n        .await?;\n\n        let mut events = Vec::new();\n        for row in rows {\n            events.push(Self::row_to_persistent_event(&row)?);\n        }\n        Ok(events)\n    }\n\n    async fn update_event_status(\n        &self,\n        event_id: &str,\n        status: mk_core::types::EventStatus,\n        error: Option<String>,\n    ) -> Result<(), Self::Error> {\n        let now = chrono::Utc::now();\n\n        match status {\n            mk_core::types::EventStatus::Published => {\n                sqlx::query(\n                    \"UPDATE governance_events SET status = $2, published_at = $3 WHERE event_id = \\\n                     $1\",\n                )\n                .bind(event_id)\n                .bind(status.to_string())\n                .bind(now)\n                .execute(&self.pool)\n                .await?;\n            }\n            mk_core::types::EventStatus::Acknowledged => {\n                sqlx::query(\n                    \"UPDATE governance_events SET status = $2, acknowledged_at = $3 WHERE \\\n                     event_id = $1\",\n                )\n                .bind(event_id)\n                .bind(status.to_string())\n                .bind(now)\n                .execute(&self.pool)\n                .await?;\n            }\n            mk_core::types::EventStatus::DeadLettered => {\n                sqlx::query(\n                    \"UPDATE governance_events SET status = $2, last_error = $3, dead_lettered_at \\\n                     = $4 WHERE event_id = $1\",\n                )\n                .bind(event_id)\n                .bind(status.to_string())\n                .bind(&error)\n                .bind(now)\n                .execute(&self.pool)\n                .await?;\n            }\n            mk_core::types::EventStatus::Pending => {\n                sqlx::query(\n                    \"UPDATE governance_events SET status = $2, retry_count = retry_count + 1, \\\n                     last_error = $3 WHERE event_id = $1\",\n                )\n                .bind(event_id)\n                .bind(status.to_string())\n                .bind(&error)\n                .execute(&self.pool)\n                .await?;\n            }\n        }\n\n        Ok(())\n    }\n\n    async fn get_dead_letter_events(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        limit: usize,\n    ) -> Result<Vec<mk_core::types::PersistentEvent>, Self::Error> {\n        let rows = sqlx::query(\n            \"SELECT id, event_id, idempotency_key, tenant_id, event_type, payload, status, \\\n             retry_count, max_retries, last_error,\n                    EXTRACT(EPOCH FROM created_at)::bigint as created_at,\n                    EXTRACT(EPOCH FROM published_at)::bigint as published_at,\n                    EXTRACT(EPOCH FROM acknowledged_at)::bigint as acknowledged_at,\n                    EXTRACT(EPOCH FROM dead_lettered_at)::bigint as dead_lettered_at\n             FROM governance_events\n             WHERE tenant_id = $1 AND status = 'dead_lettered'\n             ORDER BY dead_lettered_at DESC\n             LIMIT $2\",\n        )\n        .bind(ctx.tenant_id.as_str())\n        .bind(limit as i64)\n        .fetch_all(&self.pool)\n        .await?;\n\n        let mut events = Vec::new();\n        for row in rows {\n            events.push(Self::row_to_persistent_event(&row)?);\n        }\n        Ok(events)\n    }\n\n    async fn check_idempotency(\n        &self,\n        consumer_group: &str,\n        idempotency_key: &str,\n    ) -> Result<bool, Self::Error> {\n        let result: Option<(i32,)> = sqlx::query_as(\n            \"SELECT 1 FROM event_consumer_state WHERE consumer_group = $1 AND idempotency_key = $2\",\n        )\n        .bind(consumer_group)\n        .bind(idempotency_key)\n        .fetch_optional(&self.pool)\n        .await?;\n\n        Ok(result.is_some())\n    }\n\n    async fn record_consumer_state(\n        &self,\n        state: mk_core::types::ConsumerState,\n    ) -> Result<(), Self::Error> {\n        sqlx::query(\n            \"INSERT INTO event_consumer_state (consumer_group, idempotency_key, tenant_id, \\\n             processed_at)\n             VALUES ($1, $2, $3, to_timestamp($4))\n             ON CONFLICT (consumer_group, idempotency_key) DO NOTHING\",\n        )\n        .bind(&state.consumer_group)\n        .bind(&state.idempotency_key)\n        .bind(state.tenant_id.as_str())\n        .bind(state.processed_at)\n        .execute(&self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    async fn get_event_metrics(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        period_start: i64,\n        period_end: i64,\n    ) -> Result<Vec<mk_core::types::EventDeliveryMetrics>, Self::Error> {\n        let rows = sqlx::query(\n            \"SELECT tenant_id, event_type, \n                    EXTRACT(EPOCH FROM period_start)::bigint as period_start,\n                    EXTRACT(EPOCH FROM period_end)::bigint as period_end,\n                    total_events, delivered_events, retried_events, dead_lettered_events, \\\n             avg_delivery_time_ms\n             FROM event_delivery_metrics\n             WHERE tenant_id = $1 AND period_start >= to_timestamp($2) AND period_end <= \\\n             to_timestamp($3)\n             ORDER BY period_start DESC\",\n        )\n        .bind(ctx.tenant_id.as_str())\n        .bind(period_start)\n        .bind(period_end)\n        .fetch_all(&self.pool)\n        .await?;\n\n        let mut metrics = Vec::new();\n        for row in rows {\n            metrics.push(mk_core::types::EventDeliveryMetrics {\n                tenant_id: row.get::<String, _>(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                event_type: row.get(\"event_type\"),\n                period_start: row.get(\"period_start\"),\n                period_end: row.get(\"period_end\"),\n                total_events: row.get(\"total_events\"),\n                delivered_events: row.get(\"delivered_events\"),\n                retried_events: row.get(\"retried_events\"),\n                dead_lettered_events: row.get(\"dead_lettered_events\"),\n                avg_delivery_time_ms: row.get(\"avg_delivery_time_ms\"),\n            });\n        }\n        Ok(metrics)\n    }\n\n    async fn record_event_metrics(\n        &self,\n        metrics: mk_core::types::EventDeliveryMetrics,\n    ) -> Result<(), Self::Error> {\n        sqlx::query(\n            \"INSERT INTO event_delivery_metrics (tenant_id, event_type, period_start, period_end, \\\n             total_events, delivered_events, retried_events, dead_lettered_events, \\\n             avg_delivery_time_ms)\n             VALUES ($1, $2, to_timestamp($3), to_timestamp($4), $5, $6, $7, $8, $9)\",\n        )\n        .bind(metrics.tenant_id.as_str())\n        .bind(&metrics.event_type)\n        .bind(metrics.period_start)\n        .bind(metrics.period_end)\n        .bind(metrics.total_events)\n        .bind(metrics.delivered_events)\n        .bind(metrics.retried_events)\n        .bind(metrics.dead_lettered_events)\n        .bind(metrics.avg_delivery_time_ms)\n        .execute(&self.pool)\n        .await?;\n\n        Ok(())\n    }\n}\n\nimpl PostgresBackend {\n    pub async fn create_error_signature(\n        &self,\n        tenant_id: &str,\n        signature: &mk_core::types::ErrorSignature,\n    ) -> Result<String, PostgresError> {\n        let id = uuid::Uuid::new_v4().to_string();\n        let now = chrono::Utc::now().timestamp();\n\n        sqlx::query(\n            \"INSERT INTO error_signatures (id, tenant_id, error_type, message_pattern, \\\n             stack_patterns, context_patterns, embedding, occurrence_count, first_seen_at, \\\n             last_seen_at, created_at, updated_at)\n             VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12)\",\n        )\n        .bind(&id)\n        .bind(tenant_id)\n        .bind(&signature.error_type)\n        .bind(&signature.message_pattern)\n        .bind(serde_json::to_value(&signature.stack_patterns)?)\n        .bind(serde_json::to_value(&signature.context_patterns)?)\n        .bind(serde_json::to_value(&signature.embedding)?)\n        .bind(1i32)\n        .bind(now)\n        .bind(now)\n        .bind(now)\n        .bind(now)\n        .execute(&self.pool)\n        .await?;\n\n        Ok(id)\n    }\n\n    pub async fn get_error_signature(\n        &self,\n        tenant_id: &str,\n        id: &str,\n    ) -> Result<Option<mk_core::types::ErrorSignature>, PostgresError> {\n        let row = sqlx::query(\n            \"SELECT error_type, message_pattern, stack_patterns, context_patterns, embedding\n             FROM error_signatures WHERE id = $1 AND tenant_id = $2\",\n        )\n        .bind(id)\n        .bind(tenant_id)\n        .fetch_optional(&self.pool)\n        .await?;\n\n        match row {\n            Some(row) => {\n                let embedding: Option<serde_json::Value> = row.get(\"embedding\");\n                Ok(Some(mk_core::types::ErrorSignature {\n                    error_type: row.get(\"error_type\"),\n                    message_pattern: row.get(\"message_pattern\"),\n                    stack_patterns: serde_json::from_value(row.get(\"stack_patterns\"))?,\n                    context_patterns: serde_json::from_value(row.get(\"context_patterns\"))?,\n                    embedding: embedding.and_then(|v| serde_json::from_value(v).ok()),\n                }))\n            }\n            None => Ok(None),\n        }\n    }\n\n    pub async fn delete_error_signature(\n        &self,\n        tenant_id: &str,\n        id: &str,\n    ) -> Result<bool, PostgresError> {\n        let result = sqlx::query(\"DELETE FROM error_signatures WHERE id = $1 AND tenant_id = $2\")\n            .bind(id)\n            .bind(tenant_id)\n            .execute(&self.pool)\n            .await?;\n\n        Ok(result.rows_affected() > 0)\n    }\n\n    pub async fn create_resolution(\n        &self,\n        tenant_id: &str,\n        resolution: &mk_core::types::Resolution,\n    ) -> Result<(), PostgresError> {\n        let now = chrono::Utc::now().timestamp();\n\n        sqlx::query(\n            \"INSERT INTO resolutions (id, tenant_id, error_signature_id, description, changes, \\\n             success_rate, application_count, last_success_at, created_at, updated_at)\n             VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)\",\n        )\n        .bind(&resolution.id)\n        .bind(tenant_id)\n        .bind(&resolution.error_signature_id)\n        .bind(&resolution.description)\n        .bind(serde_json::to_value(&resolution.changes)?)\n        .bind(resolution.success_rate)\n        .bind(resolution.application_count as i32)\n        .bind(if resolution.last_success_at > 0 {\n            Some(resolution.last_success_at)\n        } else {\n            None\n        })\n        .bind(now)\n        .bind(now)\n        .execute(&self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    pub async fn get_resolution(\n        &self,\n        tenant_id: &str,\n        id: &str,\n    ) -> Result<Option<mk_core::types::Resolution>, PostgresError> {\n        let row = sqlx::query(\n            \"SELECT id, error_signature_id, description, changes, success_rate, \\\n             application_count, last_success_at FROM resolutions WHERE id = $1 AND tenant_id = $2\",\n        )\n        .bind(id)\n        .bind(tenant_id)\n        .fetch_optional(&self.pool)\n        .await?;\n\n        match row {\n            Some(row) => {\n                let last_success_at: Option<i64> = row.get(\"last_success_at\");\n                Ok(Some(mk_core::types::Resolution {\n                    id: row.get(\"id\"),\n                    error_signature_id: row.get(\"error_signature_id\"),\n                    description: row.get(\"description\"),\n                    changes: serde_json::from_value(row.get(\"changes\"))?,\n                    success_rate: row.get(\"success_rate\"),\n                    application_count: row.get::<i32, _>(\"application_count\") as u32,\n                    last_success_at: last_success_at.unwrap_or(0),\n                }))\n            }\n            None => Ok(None),\n        }\n    }\n\n    pub async fn get_resolutions_for_error(\n        &self,\n        tenant_id: &str,\n        error_signature_id: &str,\n    ) -> Result<Vec<mk_core::types::Resolution>, PostgresError> {\n        let rows = sqlx::query(\n            \"SELECT id, error_signature_id, description, changes, success_rate, \\\n             application_count, last_success_at FROM resolutions \n             WHERE error_signature_id = $1 AND tenant_id = $2\n             ORDER BY success_rate DESC, application_count DESC\",\n        )\n        .bind(error_signature_id)\n        .bind(tenant_id)\n        .fetch_all(&self.pool)\n        .await?;\n\n        let mut resolutions = Vec::new();\n        for row in rows {\n            let last_success_at: Option<i64> = row.get(\"last_success_at\");\n            resolutions.push(mk_core::types::Resolution {\n                id: row.get(\"id\"),\n                error_signature_id: row.get(\"error_signature_id\"),\n                description: row.get(\"description\"),\n                changes: serde_json::from_value(row.get(\"changes\"))?,\n                success_rate: row.get(\"success_rate\"),\n                application_count: row.get::<i32, _>(\"application_count\") as u32,\n                last_success_at: last_success_at.unwrap_or(0),\n            });\n        }\n\n        Ok(resolutions)\n    }\n\n    pub async fn delete_resolution(\n        &self,\n        tenant_id: &str,\n        id: &str,\n    ) -> Result<bool, PostgresError> {\n        let result = sqlx::query(\"DELETE FROM resolutions WHERE id = $1 AND tenant_id = $2\")\n            .bind(id)\n            .bind(tenant_id)\n            .execute(&self.pool)\n            .await?;\n\n        Ok(result.rows_affected() > 0)\n    }\n\n    pub async fn create_hindsight_note(\n        &self,\n        tenant_id: &str,\n        note: &mk_core::types::HindsightNote,\n    ) -> Result<(), PostgresError> {\n        let resolution_ids: Vec<String> = note.resolutions.iter().map(|r| r.id.clone()).collect();\n\n        sqlx::query(\n            \"INSERT INTO hindsight_notes (id, tenant_id, error_signature_id, content, tags, \\\n             resolution_ids, created_at, updated_at)\n             VALUES ($1, $2, $3, $4, $5, $6, $7, $8)\",\n        )\n        .bind(&note.id)\n        .bind(tenant_id)\n        .bind(&note.error_signature.error_type)\n        .bind(&note.content)\n        .bind(serde_json::to_value(&note.tags)?)\n        .bind(serde_json::to_value(&resolution_ids)?)\n        .bind(note.created_at)\n        .bind(note.updated_at)\n        .execute(&self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    pub async fn get_hindsight_note(\n        &self,\n        tenant_id: &str,\n        id: &str,\n    ) -> Result<Option<mk_core::types::HindsightNote>, PostgresError> {\n        let row = sqlx::query(\n            \"SELECT h.id, h.error_signature_id, h.content, h.tags, h.resolution_ids, \\\n             h.created_at, h.updated_at,\n             e.error_type, e.message_pattern, e.stack_patterns, e.context_patterns, e.embedding\n             FROM hindsight_notes h\n             LEFT JOIN error_signatures e ON h.error_signature_id = e.error_type AND e.tenant_id = \\\n             $2\n             WHERE h.id = $1 AND h.tenant_id = $2\",\n        )\n        .bind(id)\n        .bind(tenant_id)\n        .fetch_optional(&self.pool)\n        .await?;\n\n        match row {\n            Some(row) => {\n                let resolution_ids: Vec<String> =\n                    serde_json::from_value(row.get(\"resolution_ids\"))?;\n                let mut resolutions = Vec::new();\n                for res_id in resolution_ids {\n                    if let Some(resolution) = self.get_resolution(tenant_id, &res_id).await? {\n                        resolutions.push(resolution);\n                    }\n                }\n\n                let embedding: Option<serde_json::Value> = row.get(\"embedding\");\n\n                Ok(Some(mk_core::types::HindsightNote {\n                    id: row.get(\"id\"),\n                    error_signature: mk_core::types::ErrorSignature {\n                        error_type: row\n                            .get::<Option<String>, _>(\"error_type\")\n                            .unwrap_or_else(|| row.get(\"error_signature_id\")),\n                        message_pattern: row\n                            .get::<Option<String>, _>(\"message_pattern\")\n                            .unwrap_or_default(),\n                        stack_patterns: row\n                            .get::<Option<serde_json::Value>, _>(\"stack_patterns\")\n                            .and_then(|v| serde_json::from_value(v).ok())\n                            .unwrap_or_default(),\n                        context_patterns: row\n                            .get::<Option<serde_json::Value>, _>(\"context_patterns\")\n                            .and_then(|v| serde_json::from_value(v).ok())\n                            .unwrap_or_default(),\n                        embedding: embedding.and_then(|v| serde_json::from_value(v).ok()),\n                    },\n                    resolutions,\n                    content: row.get(\"content\"),\n                    tags: serde_json::from_value(row.get(\"tags\"))?,\n                    created_at: row.get(\"created_at\"),\n                    updated_at: row.get(\"updated_at\"),\n                }))\n            }\n            None => Ok(None),\n        }\n    }\n\n    pub async fn update_hindsight_note(\n        &self,\n        tenant_id: &str,\n        note: &mk_core::types::HindsightNote,\n    ) -> Result<bool, PostgresError> {\n        let resolution_ids: Vec<String> = note.resolutions.iter().map(|r| r.id.clone()).collect();\n\n        let result = sqlx::query(\n            \"UPDATE hindsight_notes \n             SET content = $3, tags = $4, resolution_ids = $5, updated_at = $6\n             WHERE id = $1 AND tenant_id = $2\",\n        )\n        .bind(&note.id)\n        .bind(tenant_id)\n        .bind(&note.content)\n        .bind(serde_json::to_value(&note.tags)?)\n        .bind(serde_json::to_value(&resolution_ids)?)\n        .bind(note.updated_at)\n        .execute(&self.pool)\n        .await?;\n\n        Ok(result.rows_affected() > 0)\n    }\n\n    pub async fn delete_hindsight_note(\n        &self,\n        tenant_id: &str,\n        id: &str,\n    ) -> Result<bool, PostgresError> {\n        let result = sqlx::query(\"DELETE FROM hindsight_notes WHERE id = $1 AND tenant_id = $2\")\n            .bind(id)\n            .bind(tenant_id)\n            .execute(&self.pool)\n            .await?;\n\n        Ok(result.rows_affected() > 0)\n    }\n\n    pub async fn list_hindsight_notes(\n        &self,\n        tenant_id: &str,\n        limit: i64,\n        offset: i64,\n    ) -> Result<Vec<mk_core::types::HindsightNote>, PostgresError> {\n        let rows = sqlx::query(\n            \"SELECT id FROM hindsight_notes \n             WHERE tenant_id = $1\n             ORDER BY updated_at DESC\n             LIMIT $2 OFFSET $3\",\n        )\n        .bind(tenant_id)\n        .bind(limit)\n        .bind(offset)\n        .fetch_all(&self.pool)\n        .await?;\n\n        let mut notes = Vec::new();\n        for row in rows {\n            let id: String = row.get(\"id\");\n            if let Some(note) = self.get_hindsight_note(tenant_id, &id).await? {\n                notes.push(note);\n            }\n        }\n\n        Ok(notes)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use chrono::Datelike;\n    use serde_json::json;\n\n    // Test PostgresError display\n    #[test]\n    fn test_postgres_error_display() {\n        let error = PostgresError::Database(sqlx::Error::Configuration(\n            \"Invalid connection string\".into(),\n        ));\n\n        assert!(error.to_string().contains(\"Database error\"));\n        assert!(error.to_string().contains(\"Invalid connection string\"));\n    }\n\n    // Test error conversion from sqlx::Error\n    #[test]\n    fn test_postgres_error_from_sqlx() {\n        let sqlx_error = sqlx::Error::Configuration(\"test\".into());\n        let pg_error: PostgresError = sqlx_error.into();\n\n        match pg_error {\n            PostgresError::Database(_) => (),\n            PostgresError::Serialization(_) => (),\n            PostgresError::NotFound(_) => (),\n        }\n    }\n\n    // Test PostgresBackend struct (compile-time checks)\n    #[test]\n    fn test_postgres_backend_struct() {\n        // Verify the struct has expected fields\n        struct TestBackend {\n            _pool: Pool<Postgres>,\n        }\n\n        // This is a compile-time test - if it compiles, PostgresBackend has the right\n        // structure We can't instantiate it without a real database connection\n        let _backend_type = std::any::type_name::<PostgresBackend>();\n        assert_eq!(_backend_type, \"storage::postgres::PostgresBackend\");\n    }\n\n    // Test StorageBackend trait implementation\n    #[test]\n    fn test_storage_backend_trait_implementation() {\n        use mk_core::traits::StorageBackend;\n\n        // Compile-time check that PostgresBackend implements StorageBackend\n        fn assert_implements_storage_backend<T: StorageBackend>() {}\n\n        assert_implements_storage_backend::<PostgresBackend>();\n    }\n\n    // Test JSON serialization patterns used in the code\n    #[test]\n    fn test_json_serialization_patterns() {\n        // Test the serialization pattern used in store() method\n        let value = json!({\"key\": \"value\", \"number\": 42});\n        let bytes = serde_json::to_vec(&value).unwrap();\n\n        // Test deserialization pattern used in retrieve() method\n        let deserialized: serde_json::Value = serde_json::from_slice(&bytes).unwrap();\n        assert_eq!(deserialized[\"key\"], \"value\");\n        assert_eq!(deserialized[\"number\"], 42);\n\n        // Test default fallback used in store()\n        let invalid_bytes = b\"not json\";\n        let default_value =\n            serde_json::from_slice::<serde_json::Value>(invalid_bytes).unwrap_or_default();\n        assert!(default_value.is_null() || default_value == json!({}));\n    }\n\n    // Test timestamp generation pattern\n    #[test]\n    fn test_timestamp_generation() {\n        use chrono::Utc;\n\n        let timestamp = Utc::now().timestamp();\n        assert!(timestamp > 0); // Should be positive (after 1970)\n\n        // Verify it's a reasonable timestamp (not in distant future)\n        let current_year = Utc::now().year();\n        let timestamp_year = chrono::DateTime::from_timestamp(timestamp, 0)\n            .map(|dt| dt.year())\n            .unwrap_or(1970);\n\n        // Should be within 10 years of current year\n        assert!((timestamp_year - current_year).abs() <= 10);\n    }\n\n    // Test SQL query patterns for correctness\n    #[test]\n    fn test_sql_query_patterns() {\n        // Verify the SQL queries are syntactically correct\n        let create_table_query = \"CREATE TABLE IF NOT EXISTS sync_state (\n                id TEXT PRIMARY KEY,\n                data JSONB NOT NULL,\n                updated_at BIGINT NOT NULL\n            )\";\n\n        let insert_query = \"INSERT INTO sync_state (id, data, updated_at)\n             VALUES ($1, $2, $3)\n             ON CONFLICT (id) DO UPDATE SET data = $2, updated_at = $3\";\n\n        let select_query = \"SELECT data FROM sync_state WHERE id = $1\";\n        let delete_query = \"DELETE FROM sync_state WHERE id = $1\";\n        let exists_query = \"SELECT 1 FROM sync_state WHERE id = $1\";\n\n        // Just verify they're non-empty strings\n        assert!(!create_table_query.is_empty());\n        assert!(!insert_query.is_empty());\n        assert!(!select_query.is_empty());\n        assert!(!delete_query.is_empty());\n        assert!(!exists_query.is_empty());\n\n        // Verify they contain expected keywords\n        assert!(create_table_query.contains(\"CREATE TABLE\"));\n        assert!(insert_query.contains(\"INSERT INTO\"));\n        assert!(select_query.contains(\"SELECT\"));\n        assert!(delete_query.contains(\"DELETE\"));\n        assert!(exists_query.contains(\"SELECT 1\"));\n    }\n}\n","traces":[{"line":24,"address":[],"length":0,"stats":{"Line":29}},{"line":25,"address":[],"length":0,"stats":{"Line":29}},{"line":28,"address":[],"length":0,"stats":{"Line":166}},{"line":32,"address":[],"length":0,"stats":{"Line":247}},{"line":34,"address":[],"length":0,"stats":{"Line":249}},{"line":35,"address":[],"length":0,"stats":{"Line":166}},{"line":36,"address":[],"length":0,"stats":{"Line":85}},{"line":37,"address":[],"length":0,"stats":{"Line":81}},{"line":40,"address":[],"length":0,"stats":{"Line":118}},{"line":42,"address":[],"length":0,"stats":{"Line":118}},{"line":43,"address":[],"length":0,"stats":{"Line":118}},{"line":44,"address":[],"length":0,"stats":{"Line":59}},{"line":55,"address":[],"length":0,"stats":{"Line":118}},{"line":56,"address":[],"length":0,"stats":{"Line":59}},{"line":58,"address":[],"length":0,"stats":{"Line":118}},{"line":59,"address":[],"length":0,"stats":{"Line":118}},{"line":60,"address":[],"length":0,"stats":{"Line":59}},{"line":74,"address":[],"length":0,"stats":{"Line":118}},{"line":75,"address":[],"length":0,"stats":{"Line":59}},{"line":87,"address":[],"length":0,"stats":{"Line":118}},{"line":88,"address":[],"length":0,"stats":{"Line":59}},{"line":99,"address":[],"length":0,"stats":{"Line":118}},{"line":100,"address":[],"length":0,"stats":{"Line":59}},{"line":111,"address":[],"length":0,"stats":{"Line":118}},{"line":112,"address":[],"length":0,"stats":{"Line":59}},{"line":127,"address":[],"length":0,"stats":{"Line":118}},{"line":128,"address":[],"length":0,"stats":{"Line":59}},{"line":141,"address":[],"length":0,"stats":{"Line":118}},{"line":142,"address":[],"length":0,"stats":{"Line":59}},{"line":156,"address":[],"length":0,"stats":{"Line":118}},{"line":157,"address":[],"length":0,"stats":{"Line":59}},{"line":169,"address":[],"length":0,"stats":{"Line":118}},{"line":170,"address":[],"length":0,"stats":{"Line":59}},{"line":188,"address":[],"length":0,"stats":{"Line":118}},{"line":189,"address":[],"length":0,"stats":{"Line":59}},{"line":195,"address":[],"length":0,"stats":{"Line":118}},{"line":196,"address":[],"length":0,"stats":{"Line":59}},{"line":201,"address":[],"length":0,"stats":{"Line":118}},{"line":202,"address":[],"length":0,"stats":{"Line":59}},{"line":210,"address":[],"length":0,"stats":{"Line":118}},{"line":211,"address":[],"length":0,"stats":{"Line":59}},{"line":220,"address":[],"length":0,"stats":{"Line":118}},{"line":221,"address":[],"length":0,"stats":{"Line":59}},{"line":241,"address":[],"length":0,"stats":{"Line":118}},{"line":242,"address":[],"length":0,"stats":{"Line":59}},{"line":247,"address":[],"length":0,"stats":{"Line":118}},{"line":248,"address":[],"length":0,"stats":{"Line":59}},{"line":253,"address":[],"length":0,"stats":{"Line":118}},{"line":254,"address":[],"length":0,"stats":{"Line":59}},{"line":270,"address":[],"length":0,"stats":{"Line":118}},{"line":271,"address":[],"length":0,"stats":{"Line":59}},{"line":276,"address":[],"length":0,"stats":{"Line":118}},{"line":277,"address":[],"length":0,"stats":{"Line":59}},{"line":293,"address":[],"length":0,"stats":{"Line":118}},{"line":294,"address":[],"length":0,"stats":{"Line":59}},{"line":299,"address":[],"length":0,"stats":{"Line":118}},{"line":300,"address":[],"length":0,"stats":{"Line":59}},{"line":305,"address":[],"length":0,"stats":{"Line":118}},{"line":306,"address":[],"length":0,"stats":{"Line":59}},{"line":329,"address":[],"length":0,"stats":{"Line":118}},{"line":330,"address":[],"length":0,"stats":{"Line":59}},{"line":340,"address":[],"length":0,"stats":{"Line":118}},{"line":341,"address":[],"length":0,"stats":{"Line":59}},{"line":347,"address":[],"length":0,"stats":{"Line":118}},{"line":348,"address":[],"length":0,"stats":{"Line":59}},{"line":350,"address":[],"length":0,"stats":{"Line":118}},{"line":351,"address":[],"length":0,"stats":{"Line":118}},{"line":352,"address":[],"length":0,"stats":{"Line":59}},{"line":384,"address":[],"length":0,"stats":{"Line":118}},{"line":385,"address":[],"length":0,"stats":{"Line":59}},{"line":390,"address":[],"length":0,"stats":{"Line":118}},{"line":391,"address":[],"length":0,"stats":{"Line":59}},{"line":396,"address":[],"length":0,"stats":{"Line":118}},{"line":397,"address":[],"length":0,"stats":{"Line":59}},{"line":411,"address":[],"length":0,"stats":{"Line":118}},{"line":412,"address":[],"length":0,"stats":{"Line":59}},{"line":417,"address":[],"length":0,"stats":{"Line":118}},{"line":418,"address":[],"length":0,"stats":{"Line":59}},{"line":437,"address":[],"length":0,"stats":{"Line":118}},{"line":438,"address":[],"length":0,"stats":{"Line":59}},{"line":451,"address":[],"length":0,"stats":{"Line":118}},{"line":452,"address":[],"length":0,"stats":{"Line":59}},{"line":457,"address":[],"length":0,"stats":{"Line":118}},{"line":458,"address":[],"length":0,"stats":{"Line":59}},{"line":476,"address":[],"length":0,"stats":{"Line":118}},{"line":477,"address":[],"length":0,"stats":{"Line":59}},{"line":482,"address":[],"length":0,"stats":{"Line":118}},{"line":483,"address":[],"length":0,"stats":{"Line":59}},{"line":488,"address":[],"length":0,"stats":{"Line":118}},{"line":489,"address":[],"length":0,"stats":{"Line":59}},{"line":494,"address":[],"length":0,"stats":{"Line":118}},{"line":495,"address":[],"length":0,"stats":{"Line":59}},{"line":560,"address":[],"length":0,"stats":{"Line":118}},{"line":561,"address":[],"length":0,"stats":{"Line":59}},{"line":563,"address":[],"length":0,"stats":{"Line":118}},{"line":565,"address":[],"length":0,"stats":{"Line":59}},{"line":568,"address":[],"length":0,"stats":{"Line":1230}},{"line":569,"address":[],"length":0,"stats":{"Line":1177}},{"line":570,"address":[],"length":0,"stats":{"Line":1686}},{"line":571,"address":[],"length":0,"stats":{"Line":1686}},{"line":572,"address":[],"length":0,"stats":{"Line":562}},{"line":573,"address":[],"length":0,"stats":{"Line":562}},{"line":575,"address":[],"length":0,"stats":{"Line":1124}},{"line":576,"address":[],"length":0,"stats":{"Line":99}},{"line":577,"address":[],"length":0,"stats":{"Line":156}},{"line":578,"address":[],"length":0,"stats":{"Line":305}},{"line":580,"address":[],"length":0,"stats":{"Line":2}},{"line":581,"address":[],"length":0,"stats":{"Line":4}},{"line":582,"address":[],"length":0,"stats":{"Line":2}},{"line":583,"address":[],"length":0,"stats":{"Line":2}},{"line":585,"address":[],"length":0,"stats":{"Line":2}},{"line":589,"address":[],"length":0,"stats":{"Line":53}},{"line":590,"address":[],"length":0,"stats":{"Line":1}},{"line":591,"address":[],"length":0,"stats":{"Line":1}},{"line":600,"address":[],"length":0,"stats":{"Line":1224}},{"line":601,"address":[],"length":0,"stats":{"Line":1224}},{"line":602,"address":[],"length":0,"stats":{"Line":1224}},{"line":603,"address":[],"length":0,"stats":{"Line":1224}},{"line":604,"address":[],"length":0,"stats":{"Line":1836}},{"line":605,"address":[],"length":0,"stats":{"Line":1836}},{"line":606,"address":[],"length":0,"stats":{"Line":1224}},{"line":607,"address":[],"length":0,"stats":{"Line":1224}},{"line":608,"address":[],"length":0,"stats":{"Line":1224}},{"line":609,"address":[],"length":0,"stats":{"Line":612}},{"line":611,"address":[],"length":0,"stats":{"Line":612}},{"line":614,"address":[],"length":0,"stats":{"Line":0}},{"line":619,"address":[],"length":0,"stats":{"Line":0}},{"line":620,"address":[],"length":0,"stats":{"Line":0}},{"line":621,"address":[],"length":0,"stats":{"Line":0}},{"line":622,"address":[],"length":0,"stats":{"Line":0}},{"line":623,"address":[],"length":0,"stats":{"Line":0}},{"line":624,"address":[],"length":0,"stats":{"Line":0}},{"line":625,"address":[],"length":0,"stats":{"Line":0}},{"line":628,"address":[],"length":0,"stats":{"Line":0}},{"line":631,"address":[],"length":0,"stats":{"Line":0}},{"line":632,"address":[],"length":0,"stats":{"Line":0}},{"line":633,"address":[],"length":0,"stats":{"Line":0}},{"line":634,"address":[],"length":0,"stats":{"Line":0}},{"line":635,"address":[],"length":0,"stats":{"Line":0}},{"line":636,"address":[],"length":0,"stats":{"Line":0}},{"line":639,"address":[],"length":0,"stats":{"Line":0}},{"line":640,"address":[],"length":0,"stats":{"Line":0}},{"line":641,"address":[],"length":0,"stats":{"Line":0}},{"line":642,"address":[],"length":0,"stats":{"Line":0}},{"line":643,"address":[],"length":0,"stats":{"Line":0}},{"line":644,"address":[],"length":0,"stats":{"Line":0}},{"line":645,"address":[],"length":0,"stats":{"Line":0}},{"line":646,"address":[],"length":0,"stats":{"Line":0}},{"line":647,"address":[],"length":0,"stats":{"Line":0}},{"line":648,"address":[],"length":0,"stats":{"Line":0}},{"line":652,"address":[],"length":0,"stats":{"Line":562}},{"line":661,"address":[],"length":0,"stats":{"Line":1686}},{"line":662,"address":[],"length":0,"stats":{"Line":1686}},{"line":663,"address":[],"length":0,"stats":{"Line":1124}},{"line":664,"address":[],"length":0,"stats":{"Line":562}},{"line":666,"address":[],"length":0,"stats":{"Line":1124}},{"line":667,"address":[],"length":0,"stats":{"Line":2248}},{"line":668,"address":[],"length":0,"stats":{"Line":1124}},{"line":669,"address":[],"length":0,"stats":{"Line":662}},{"line":670,"address":[],"length":0,"stats":{"Line":619}},{"line":671,"address":[],"length":0,"stats":{"Line":610}},{"line":672,"address":[],"length":0,"stats":{"Line":0}},{"line":674,"address":[],"length":0,"stats":{"Line":0}},{"line":675,"address":[],"length":0,"stats":{"Line":0}},{"line":681,"address":[],"length":0,"stats":{"Line":1124}},{"line":682,"address":[],"length":0,"stats":{"Line":1124}},{"line":683,"address":[],"length":0,"stats":{"Line":562}},{"line":684,"address":[],"length":0,"stats":{"Line":1124}},{"line":685,"address":[],"length":0,"stats":{"Line":1124}},{"line":686,"address":[],"length":0,"stats":{"Line":0}},{"line":687,"address":[],"length":0,"stats":{"Line":0}},{"line":690,"address":[],"length":0,"stats":{"Line":1686}},{"line":691,"address":[],"length":0,"stats":{"Line":1124}},{"line":692,"address":[],"length":0,"stats":{"Line":1124}},{"line":695,"address":[],"length":0,"stats":{"Line":0}},{"line":699,"address":[],"length":0,"stats":{"Line":4}},{"line":708,"address":[],"length":0,"stats":{"Line":12}},{"line":709,"address":[],"length":0,"stats":{"Line":16}},{"line":710,"address":[],"length":0,"stats":{"Line":8}},{"line":711,"address":[],"length":0,"stats":{"Line":4}},{"line":713,"address":[],"length":0,"stats":{"Line":7}},{"line":714,"address":[],"length":0,"stats":{"Line":12}},{"line":715,"address":[],"length":0,"stats":{"Line":6}},{"line":716,"address":[],"length":0,"stats":{"Line":5}},{"line":717,"address":[],"length":0,"stats":{"Line":2}},{"line":718,"address":[],"length":0,"stats":{"Line":0}},{"line":719,"address":[],"length":0,"stats":{"Line":0}},{"line":721,"address":[],"length":0,"stats":{"Line":0}},{"line":722,"address":[],"length":0,"stats":{"Line":0}},{"line":728,"address":[],"length":0,"stats":{"Line":6}},{"line":729,"address":[],"length":0,"stats":{"Line":6}},{"line":730,"address":[],"length":0,"stats":{"Line":3}},{"line":731,"address":[],"length":0,"stats":{"Line":6}},{"line":732,"address":[],"length":0,"stats":{"Line":6}},{"line":733,"address":[],"length":0,"stats":{"Line":0}},{"line":734,"address":[],"length":0,"stats":{"Line":0}},{"line":737,"address":[],"length":0,"stats":{"Line":9}},{"line":738,"address":[],"length":0,"stats":{"Line":6}},{"line":739,"address":[],"length":0,"stats":{"Line":6}},{"line":742,"address":[],"length":0,"stats":{"Line":1}},{"line":746,"address":[],"length":0,"stats":{"Line":1}},{"line":755,"address":[],"length":0,"stats":{"Line":3}},{"line":756,"address":[],"length":0,"stats":{"Line":4}},{"line":757,"address":[],"length":0,"stats":{"Line":2}},{"line":758,"address":[],"length":0,"stats":{"Line":1}},{"line":760,"address":[],"length":0,"stats":{"Line":2}},{"line":761,"address":[],"length":0,"stats":{"Line":5}},{"line":762,"address":[],"length":0,"stats":{"Line":8}},{"line":763,"address":[],"length":0,"stats":{"Line":4}},{"line":764,"address":[],"length":0,"stats":{"Line":2}},{"line":765,"address":[],"length":0,"stats":{"Line":4}},{"line":766,"address":[],"length":0,"stats":{"Line":0}},{"line":767,"address":[],"length":0,"stats":{"Line":0}},{"line":768,"address":[],"length":0,"stats":{"Line":0}},{"line":771,"address":[],"length":0,"stats":{"Line":4}},{"line":772,"address":[],"length":0,"stats":{"Line":4}},{"line":773,"address":[],"length":0,"stats":{"Line":4}},{"line":774,"address":[],"length":0,"stats":{"Line":2}},{"line":775,"address":[],"length":0,"stats":{"Line":4}},{"line":776,"address":[],"length":0,"stats":{"Line":4}},{"line":777,"address":[],"length":0,"stats":{"Line":0}},{"line":778,"address":[],"length":0,"stats":{"Line":0}},{"line":781,"address":[],"length":0,"stats":{"Line":6}},{"line":782,"address":[],"length":0,"stats":{"Line":4}},{"line":783,"address":[],"length":0,"stats":{"Line":4}},{"line":787,"address":[],"length":0,"stats":{"Line":1}},{"line":790,"address":[],"length":0,"stats":{"Line":5}},{"line":808,"address":[],"length":0,"stats":{"Line":15}},{"line":809,"address":[],"length":0,"stats":{"Line":20}},{"line":810,"address":[],"length":0,"stats":{"Line":10}},{"line":811,"address":[],"length":0,"stats":{"Line":5}},{"line":813,"address":[],"length":0,"stats":{"Line":10}},{"line":814,"address":[],"length":0,"stats":{"Line":23}},{"line":815,"address":[],"length":0,"stats":{"Line":36}},{"line":816,"address":[],"length":0,"stats":{"Line":18}},{"line":817,"address":[],"length":0,"stats":{"Line":12}},{"line":818,"address":[],"length":0,"stats":{"Line":9}},{"line":819,"address":[],"length":0,"stats":{"Line":6}},{"line":820,"address":[],"length":0,"stats":{"Line":0}},{"line":821,"address":[],"length":0,"stats":{"Line":0}},{"line":824,"address":[],"length":0,"stats":{"Line":18}},{"line":825,"address":[],"length":0,"stats":{"Line":18}},{"line":826,"address":[],"length":0,"stats":{"Line":18}},{"line":827,"address":[],"length":0,"stats":{"Line":9}},{"line":828,"address":[],"length":0,"stats":{"Line":18}},{"line":829,"address":[],"length":0,"stats":{"Line":18}},{"line":830,"address":[],"length":0,"stats":{"Line":0}},{"line":831,"address":[],"length":0,"stats":{"Line":0}},{"line":834,"address":[],"length":0,"stats":{"Line":27}},{"line":835,"address":[],"length":0,"stats":{"Line":18}},{"line":836,"address":[],"length":0,"stats":{"Line":18}},{"line":840,"address":[],"length":0,"stats":{"Line":5}},{"line":843,"address":[],"length":0,"stats":{"Line":2}},{"line":848,"address":[],"length":0,"stats":{"Line":8}},{"line":851,"address":[],"length":0,"stats":{"Line":8}},{"line":869,"address":[],"length":0,"stats":{"Line":24}},{"line":870,"address":[],"length":0,"stats":{"Line":32}},{"line":871,"address":[],"length":0,"stats":{"Line":16}},{"line":872,"address":[],"length":0,"stats":{"Line":8}},{"line":874,"address":[],"length":0,"stats":{"Line":16}},{"line":875,"address":[],"length":0,"stats":{"Line":84}},{"line":876,"address":[],"length":0,"stats":{"Line":152}},{"line":877,"address":[],"length":0,"stats":{"Line":76}},{"line":878,"address":[],"length":0,"stats":{"Line":38}},{"line":879,"address":[],"length":0,"stats":{"Line":44}},{"line":880,"address":[],"length":0,"stats":{"Line":44}},{"line":881,"address":[],"length":0,"stats":{"Line":40}},{"line":882,"address":[],"length":0,"stats":{"Line":0}},{"line":885,"address":[],"length":0,"stats":{"Line":76}},{"line":886,"address":[],"length":0,"stats":{"Line":76}},{"line":887,"address":[],"length":0,"stats":{"Line":76}},{"line":888,"address":[],"length":0,"stats":{"Line":38}},{"line":889,"address":[],"length":0,"stats":{"Line":76}},{"line":890,"address":[],"length":0,"stats":{"Line":76}},{"line":891,"address":[],"length":0,"stats":{"Line":0}},{"line":892,"address":[],"length":0,"stats":{"Line":0}},{"line":895,"address":[],"length":0,"stats":{"Line":114}},{"line":896,"address":[],"length":0,"stats":{"Line":76}},{"line":897,"address":[],"length":0,"stats":{"Line":76}},{"line":901,"address":[],"length":0,"stats":{"Line":8}},{"line":904,"address":[],"length":0,"stats":{"Line":1}},{"line":914,"address":[],"length":0,"stats":{"Line":2}},{"line":915,"address":[],"length":0,"stats":{"Line":3}},{"line":916,"address":[],"length":0,"stats":{"Line":2}},{"line":917,"address":[],"length":0,"stats":{"Line":2}},{"line":918,"address":[],"length":0,"stats":{"Line":2}},{"line":919,"address":[],"length":0,"stats":{"Line":3}},{"line":920,"address":[],"length":0,"stats":{"Line":2}},{"line":921,"address":[],"length":0,"stats":{"Line":2}},{"line":922,"address":[],"length":0,"stats":{"Line":1}},{"line":924,"address":[],"length":0,"stats":{"Line":1}},{"line":927,"address":[],"length":0,"stats":{"Line":2}},{"line":928,"address":[],"length":0,"stats":{"Line":2}},{"line":929,"address":[],"length":0,"stats":{"Line":3}},{"line":930,"address":[],"length":0,"stats":{"Line":4}},{"line":931,"address":[],"length":0,"stats":{"Line":2}},{"line":932,"address":[],"length":0,"stats":{"Line":1}},{"line":934,"address":[],"length":0,"stats":{"Line":1}},{"line":937,"address":[],"length":0,"stats":{"Line":2}},{"line":943,"address":[],"length":0,"stats":{"Line":4}},{"line":944,"address":[],"length":0,"stats":{"Line":4}},{"line":945,"address":[],"length":0,"stats":{"Line":6}},{"line":946,"address":[],"length":0,"stats":{"Line":8}},{"line":947,"address":[],"length":0,"stats":{"Line":4}},{"line":948,"address":[],"length":0,"stats":{"Line":2}},{"line":950,"address":[],"length":0,"stats":{"Line":4}},{"line":951,"address":[],"length":0,"stats":{"Line":1}},{"line":959,"address":[],"length":0,"stats":{"Line":2}},{"line":960,"address":[],"length":0,"stats":{"Line":2}},{"line":961,"address":[],"length":0,"stats":{"Line":3}},{"line":962,"address":[],"length":0,"stats":{"Line":3}},{"line":963,"address":[],"length":0,"stats":{"Line":3}},{"line":964,"address":[],"length":0,"stats":{"Line":2}},{"line":965,"address":[],"length":0,"stats":{"Line":1}},{"line":966,"address":[],"length":0,"stats":{"Line":1}},{"line":969,"address":[],"length":0,"stats":{"Line":1}},{"line":980,"address":[],"length":0,"stats":{"Line":3}},{"line":981,"address":[],"length":0,"stats":{"Line":4}},{"line":982,"address":[],"length":0,"stats":{"Line":2}},{"line":983,"address":[],"length":0,"stats":{"Line":1}},{"line":985,"address":[],"length":0,"stats":{"Line":2}},{"line":986,"address":[],"length":0,"stats":{"Line":3}},{"line":987,"address":[],"length":0,"stats":{"Line":5}},{"line":988,"address":[],"length":0,"stats":{"Line":3}},{"line":990,"address":[],"length":0,"stats":{"Line":1}},{"line":993,"address":[],"length":0,"stats":{"Line":1}},{"line":1005,"address":[],"length":0,"stats":{"Line":4}},{"line":1006,"address":[],"length":0,"stats":{"Line":4}},{"line":1007,"address":[],"length":0,"stats":{"Line":3}},{"line":1008,"address":[],"length":0,"stats":{"Line":3}},{"line":1009,"address":[],"length":0,"stats":{"Line":4}},{"line":1010,"address":[],"length":0,"stats":{"Line":2}},{"line":1011,"address":[],"length":0,"stats":{"Line":1}},{"line":1012,"address":[],"length":0,"stats":{"Line":1}},{"line":1015,"address":[],"length":0,"stats":{"Line":1}},{"line":1026,"address":[],"length":0,"stats":{"Line":4}},{"line":1027,"address":[],"length":0,"stats":{"Line":4}},{"line":1028,"address":[],"length":0,"stats":{"Line":3}},{"line":1029,"address":[],"length":0,"stats":{"Line":3}},{"line":1030,"address":[],"length":0,"stats":{"Line":2}},{"line":1031,"address":[],"length":0,"stats":{"Line":1}},{"line":1032,"address":[],"length":0,"stats":{"Line":1}},{"line":1035,"address":[],"length":0,"stats":{"Line":2}},{"line":1043,"address":[],"length":0,"stats":{"Line":8}},{"line":1044,"address":[],"length":0,"stats":{"Line":8}},{"line":1045,"address":[],"length":0,"stats":{"Line":4}},{"line":1046,"address":[],"length":0,"stats":{"Line":2}},{"line":1048,"address":[],"length":0,"stats":{"Line":4}},{"line":1049,"address":[],"length":0,"stats":{"Line":4}},{"line":1050,"address":[],"length":0,"stats":{"Line":4}},{"line":1051,"address":[],"length":0,"stats":{"Line":4}},{"line":1052,"address":[],"length":0,"stats":{"Line":3}},{"line":1053,"address":[],"length":0,"stats":{"Line":3}},{"line":1056,"address":[],"length":0,"stats":{"Line":2}},{"line":1058,"address":[],"length":0,"stats":{"Line":11}},{"line":1062,"address":[],"length":0,"stats":{"Line":44}},{"line":1066,"address":[],"length":0,"stats":{"Line":3}},{"line":1068,"address":[],"length":0,"stats":{"Line":3}},{"line":1069,"address":[],"length":0,"stats":{"Line":3}},{"line":1072,"address":[],"length":0,"stats":{"Line":1}},{"line":1073,"address":[],"length":0,"stats":{"Line":1}},{"line":1074,"address":[],"length":0,"stats":{"Line":1}},{"line":1077,"address":[],"length":0,"stats":{"Line":1}},{"line":1078,"address":[],"length":0,"stats":{"Line":1}},{"line":1079,"address":[],"length":0,"stats":{"Line":1}},{"line":1084,"address":[],"length":0,"stats":{"Line":1}},{"line":1085,"address":[],"length":0,"stats":{"Line":1}},{"line":1086,"address":[],"length":0,"stats":{"Line":1}},{"line":1091,"address":[],"length":0,"stats":{"Line":1}},{"line":1092,"address":[],"length":0,"stats":{"Line":1}},{"line":1093,"address":[],"length":0,"stats":{"Line":1}},{"line":1097,"address":[],"length":0,"stats":{"Line":1}},{"line":1098,"address":[],"length":0,"stats":{"Line":1}},{"line":1099,"address":[],"length":0,"stats":{"Line":1}},{"line":1102,"address":[],"length":0,"stats":{"Line":1}},{"line":1103,"address":[],"length":0,"stats":{"Line":1}},{"line":1104,"address":[],"length":0,"stats":{"Line":1}},{"line":1107,"address":[],"length":0,"stats":{"Line":2}},{"line":1109,"address":[],"length":0,"stats":{"Line":2}},{"line":1110,"address":[],"length":0,"stats":{"Line":2}},{"line":1114,"address":[],"length":0,"stats":{"Line":0}},{"line":1115,"address":[],"length":0,"stats":{"Line":0}},{"line":1116,"address":[],"length":0,"stats":{"Line":0}},{"line":1121,"address":[],"length":0,"stats":{"Line":0}},{"line":1122,"address":[],"length":0,"stats":{"Line":0}},{"line":1123,"address":[],"length":0,"stats":{"Line":0}},{"line":1128,"address":[],"length":0,"stats":{"Line":0}},{"line":1129,"address":[],"length":0,"stats":{"Line":0}},{"line":1130,"address":[],"length":0,"stats":{"Line":0}},{"line":1135,"address":[],"length":0,"stats":{"Line":0}},{"line":1136,"address":[],"length":0,"stats":{"Line":0}},{"line":1137,"address":[],"length":0,"stats":{"Line":0}},{"line":1144,"address":[],"length":0,"stats":{"Line":22}},{"line":1145,"address":[],"length":0,"stats":{"Line":33}},{"line":1146,"address":[],"length":0,"stats":{"Line":33}},{"line":1147,"address":[],"length":0,"stats":{"Line":22}},{"line":1148,"address":[],"length":0,"stats":{"Line":22}},{"line":1149,"address":[],"length":0,"stats":{"Line":11}},{"line":1151,"address":[],"length":0,"stats":{"Line":11}},{"line":1154,"address":[],"length":0,"stats":{"Line":5}},{"line":1165,"address":[],"length":0,"stats":{"Line":20}},{"line":1166,"address":[],"length":0,"stats":{"Line":15}},{"line":1167,"address":[],"length":0,"stats":{"Line":15}},{"line":1168,"address":[],"length":0,"stats":{"Line":10}},{"line":1169,"address":[],"length":0,"stats":{"Line":5}},{"line":1171,"address":[],"length":0,"stats":{"Line":10}},{"line":1172,"address":[],"length":0,"stats":{"Line":29}},{"line":1174,"address":[],"length":0,"stats":{"Line":48}},{"line":1175,"address":[],"length":0,"stats":{"Line":48}},{"line":1176,"address":[],"length":0,"stats":{"Line":36}},{"line":1178,"address":[],"length":0,"stats":{"Line":5}},{"line":1388,"address":[],"length":0,"stats":{"Line":2}},{"line":1406,"address":[],"length":0,"stats":{"Line":8}},{"line":1434,"address":[],"length":0,"stats":{"Line":15}},{"line":1437,"address":[],"length":0,"stats":{"Line":2}},{"line":1447,"address":[],"length":0,"stats":{"Line":6}},{"line":1482,"address":[],"length":0,"stats":{"Line":0}},{"line":1558,"address":[],"length":0,"stats":{"Line":0}},{"line":1559,"address":[],"length":0,"stats":{"Line":0}},{"line":1560,"address":[],"length":0,"stats":{"Line":0}},{"line":1584,"address":[],"length":0,"stats":{"Line":4}},{"line":1614,"address":[],"length":0,"stats":{"Line":1}},{"line":1638,"address":[],"length":0,"stats":{"Line":0}},{"line":1639,"address":[],"length":0,"stats":{"Line":0}},{"line":1640,"address":[],"length":0,"stats":{"Line":0}},{"line":1698,"address":[],"length":0,"stats":{"Line":0}},{"line":1699,"address":[],"length":0,"stats":{"Line":0}},{"line":1700,"address":[],"length":0,"stats":{"Line":0}},{"line":1706,"address":[],"length":0,"stats":{"Line":0}},{"line":1707,"address":[],"length":0,"stats":{"Line":0}},{"line":1708,"address":[],"length":0,"stats":{"Line":0}},{"line":1752,"address":[],"length":0,"stats":{"Line":0}},{"line":1753,"address":[],"length":0,"stats":{"Line":0}},{"line":1754,"address":[],"length":0,"stats":{"Line":0}},{"line":1818,"address":[],"length":0,"stats":{"Line":0}},{"line":1823,"address":[],"length":0,"stats":{"Line":0}},{"line":1828,"address":[],"length":0,"stats":{"Line":0}},{"line":2015,"address":[],"length":0,"stats":{"Line":0}},{"line":2016,"address":[],"length":0,"stats":{"Line":0}},{"line":2017,"address":[],"length":0,"stats":{"Line":0}},{"line":2060,"address":[],"length":0,"stats":{"Line":6}},{"line":2065,"address":[],"length":0,"stats":{"Line":18}},{"line":2066,"address":[],"length":0,"stats":{"Line":18}},{"line":2074,"address":[],"length":0,"stats":{"Line":12}},{"line":2075,"address":[],"length":0,"stats":{"Line":12}},{"line":2076,"address":[],"length":0,"stats":{"Line":12}},{"line":2077,"address":[],"length":0,"stats":{"Line":12}},{"line":2078,"address":[],"length":0,"stats":{"Line":18}},{"line":2079,"address":[],"length":0,"stats":{"Line":18}},{"line":2080,"address":[],"length":0,"stats":{"Line":18}},{"line":2082,"address":[],"length":0,"stats":{"Line":12}},{"line":2083,"address":[],"length":0,"stats":{"Line":12}},{"line":2084,"address":[],"length":0,"stats":{"Line":12}},{"line":2085,"address":[],"length":0,"stats":{"Line":12}},{"line":2086,"address":[],"length":0,"stats":{"Line":12}},{"line":2087,"address":[],"length":0,"stats":{"Line":6}},{"line":2089,"address":[],"length":0,"stats":{"Line":6}},{"line":2092,"address":[],"length":0,"stats":{"Line":5}},{"line":2101,"address":[],"length":0,"stats":{"Line":15}},{"line":2102,"address":[],"length":0,"stats":{"Line":15}},{"line":2103,"address":[],"length":0,"stats":{"Line":10}},{"line":2104,"address":[],"length":0,"stats":{"Line":5}},{"line":2106,"address":[],"length":0,"stats":{"Line":5}},{"line":2107,"address":[],"length":0,"stats":{"Line":3}},{"line":2108,"address":[],"length":0,"stats":{"Line":12}},{"line":2110,"address":[],"length":0,"stats":{"Line":6}},{"line":2111,"address":[],"length":0,"stats":{"Line":6}},{"line":2112,"address":[],"length":0,"stats":{"Line":9}},{"line":2113,"address":[],"length":0,"stats":{"Line":9}},{"line":2114,"address":[],"length":0,"stats":{"Line":15}},{"line":2117,"address":[],"length":0,"stats":{"Line":2}},{"line":2121,"address":[],"length":0,"stats":{"Line":1}},{"line":2126,"address":[],"length":0,"stats":{"Line":3}},{"line":2127,"address":[],"length":0,"stats":{"Line":3}},{"line":2128,"address":[],"length":0,"stats":{"Line":3}},{"line":2129,"address":[],"length":0,"stats":{"Line":2}},{"line":2130,"address":[],"length":0,"stats":{"Line":1}},{"line":2132,"address":[],"length":0,"stats":{"Line":1}},{"line":2135,"address":[],"length":0,"stats":{"Line":4}},{"line":2140,"address":[],"length":0,"stats":{"Line":12}},{"line":2147,"address":[],"length":0,"stats":{"Line":8}},{"line":2148,"address":[],"length":0,"stats":{"Line":8}},{"line":2149,"address":[],"length":0,"stats":{"Line":8}},{"line":2150,"address":[],"length":0,"stats":{"Line":8}},{"line":2151,"address":[],"length":0,"stats":{"Line":12}},{"line":2152,"address":[],"length":0,"stats":{"Line":8}},{"line":2153,"address":[],"length":0,"stats":{"Line":8}},{"line":2154,"address":[],"length":0,"stats":{"Line":8}},{"line":2155,"address":[],"length":0,"stats":{"Line":2}},{"line":2157,"address":[],"length":0,"stats":{"Line":2}},{"line":2159,"address":[],"length":0,"stats":{"Line":8}},{"line":2160,"address":[],"length":0,"stats":{"Line":8}},{"line":2161,"address":[],"length":0,"stats":{"Line":8}},{"line":2162,"address":[],"length":0,"stats":{"Line":4}},{"line":2164,"address":[],"length":0,"stats":{"Line":4}},{"line":2167,"address":[],"length":0,"stats":{"Line":3}},{"line":2176,"address":[],"length":0,"stats":{"Line":9}},{"line":2177,"address":[],"length":0,"stats":{"Line":9}},{"line":2178,"address":[],"length":0,"stats":{"Line":6}},{"line":2179,"address":[],"length":0,"stats":{"Line":3}},{"line":2181,"address":[],"length":0,"stats":{"Line":3}},{"line":2182,"address":[],"length":0,"stats":{"Line":2}},{"line":2183,"address":[],"length":0,"stats":{"Line":8}},{"line":2185,"address":[],"length":0,"stats":{"Line":4}},{"line":2186,"address":[],"length":0,"stats":{"Line":4}},{"line":2187,"address":[],"length":0,"stats":{"Line":4}},{"line":2188,"address":[],"length":0,"stats":{"Line":6}},{"line":2189,"address":[],"length":0,"stats":{"Line":4}},{"line":2190,"address":[],"length":0,"stats":{"Line":2}},{"line":2191,"address":[],"length":0,"stats":{"Line":4}},{"line":2194,"address":[],"length":0,"stats":{"Line":1}},{"line":2198,"address":[],"length":0,"stats":{"Line":1}},{"line":2209,"address":[],"length":0,"stats":{"Line":3}},{"line":2210,"address":[],"length":0,"stats":{"Line":3}},{"line":2211,"address":[],"length":0,"stats":{"Line":2}},{"line":2212,"address":[],"length":0,"stats":{"Line":1}},{"line":2214,"address":[],"length":0,"stats":{"Line":2}},{"line":2215,"address":[],"length":0,"stats":{"Line":5}},{"line":2216,"address":[],"length":0,"stats":{"Line":8}},{"line":2217,"address":[],"length":0,"stats":{"Line":4}},{"line":2218,"address":[],"length":0,"stats":{"Line":4}},{"line":2219,"address":[],"length":0,"stats":{"Line":4}},{"line":2220,"address":[],"length":0,"stats":{"Line":4}},{"line":2221,"address":[],"length":0,"stats":{"Line":6}},{"line":2222,"address":[],"length":0,"stats":{"Line":4}},{"line":2223,"address":[],"length":0,"stats":{"Line":2}},{"line":2224,"address":[],"length":0,"stats":{"Line":4}},{"line":2228,"address":[],"length":0,"stats":{"Line":1}},{"line":2231,"address":[],"length":0,"stats":{"Line":1}},{"line":2236,"address":[],"length":0,"stats":{"Line":3}},{"line":2237,"address":[],"length":0,"stats":{"Line":3}},{"line":2238,"address":[],"length":0,"stats":{"Line":3}},{"line":2239,"address":[],"length":0,"stats":{"Line":2}},{"line":2240,"address":[],"length":0,"stats":{"Line":1}},{"line":2242,"address":[],"length":0,"stats":{"Line":1}},{"line":2245,"address":[],"length":0,"stats":{"Line":9}},{"line":2250,"address":[],"length":0,"stats":{"Line":49}},{"line":2257,"address":[],"length":0,"stats":{"Line":18}},{"line":2258,"address":[],"length":0,"stats":{"Line":18}},{"line":2259,"address":[],"length":0,"stats":{"Line":18}},{"line":2260,"address":[],"length":0,"stats":{"Line":18}},{"line":2261,"address":[],"length":0,"stats":{"Line":27}},{"line":2262,"address":[],"length":0,"stats":{"Line":27}},{"line":2263,"address":[],"length":0,"stats":{"Line":18}},{"line":2264,"address":[],"length":0,"stats":{"Line":18}},{"line":2265,"address":[],"length":0,"stats":{"Line":18}},{"line":2266,"address":[],"length":0,"stats":{"Line":9}},{"line":2268,"address":[],"length":0,"stats":{"Line":9}},{"line":2271,"address":[],"length":0,"stats":{"Line":11}},{"line":2285,"address":[],"length":0,"stats":{"Line":33}},{"line":2286,"address":[],"length":0,"stats":{"Line":33}},{"line":2287,"address":[],"length":0,"stats":{"Line":22}},{"line":2288,"address":[],"length":0,"stats":{"Line":11}},{"line":2290,"address":[],"length":0,"stats":{"Line":11}},{"line":2291,"address":[],"length":0,"stats":{"Line":10}},{"line":2292,"address":[],"length":0,"stats":{"Line":20}},{"line":2293,"address":[],"length":0,"stats":{"Line":30}},{"line":2294,"address":[],"length":0,"stats":{"Line":20}},{"line":2295,"address":[],"length":0,"stats":{"Line":14}},{"line":2296,"address":[],"length":0,"stats":{"Line":10}},{"line":2297,"address":[],"length":0,"stats":{"Line":2}},{"line":2301,"address":[],"length":0,"stats":{"Line":40}},{"line":2304,"address":[],"length":0,"stats":{"Line":20}},{"line":2306,"address":[],"length":0,"stats":{"Line":10}},{"line":2307,"address":[],"length":0,"stats":{"Line":10}},{"line":2308,"address":[],"length":0,"stats":{"Line":28}},{"line":2309,"address":[],"length":0,"stats":{"Line":10}},{"line":2310,"address":[],"length":0,"stats":{"Line":10}},{"line":2311,"address":[],"length":0,"stats":{"Line":10}},{"line":2312,"address":[],"length":0,"stats":{"Line":10}},{"line":2313,"address":[],"length":0,"stats":{"Line":10}},{"line":2314,"address":[],"length":0,"stats":{"Line":13}},{"line":2315,"address":[],"length":0,"stats":{"Line":10}},{"line":2316,"address":[],"length":0,"stats":{"Line":10}},{"line":2317,"address":[],"length":0,"stats":{"Line":10}},{"line":2318,"address":[],"length":0,"stats":{"Line":13}},{"line":2319,"address":[],"length":0,"stats":{"Line":10}},{"line":2320,"address":[],"length":0,"stats":{"Line":23}},{"line":2322,"address":[],"length":0,"stats":{"Line":10}},{"line":2323,"address":[],"length":0,"stats":{"Line":20}},{"line":2324,"address":[],"length":0,"stats":{"Line":30}},{"line":2325,"address":[],"length":0,"stats":{"Line":20}},{"line":2326,"address":[],"length":0,"stats":{"Line":20}},{"line":2329,"address":[],"length":0,"stats":{"Line":1}},{"line":2333,"address":[],"length":0,"stats":{"Line":1}},{"line":2338,"address":[],"length":0,"stats":{"Line":5}},{"line":2345,"address":[],"length":0,"stats":{"Line":2}},{"line":2346,"address":[],"length":0,"stats":{"Line":2}},{"line":2347,"address":[],"length":0,"stats":{"Line":2}},{"line":2348,"address":[],"length":0,"stats":{"Line":3}},{"line":2349,"address":[],"length":0,"stats":{"Line":3}},{"line":2350,"address":[],"length":0,"stats":{"Line":2}},{"line":2351,"address":[],"length":0,"stats":{"Line":2}},{"line":2352,"address":[],"length":0,"stats":{"Line":1}},{"line":2354,"address":[],"length":0,"stats":{"Line":1}},{"line":2357,"address":[],"length":0,"stats":{"Line":1}},{"line":2362,"address":[],"length":0,"stats":{"Line":3}},{"line":2363,"address":[],"length":0,"stats":{"Line":3}},{"line":2364,"address":[],"length":0,"stats":{"Line":3}},{"line":2365,"address":[],"length":0,"stats":{"Line":2}},{"line":2366,"address":[],"length":0,"stats":{"Line":1}},{"line":2368,"address":[],"length":0,"stats":{"Line":1}},{"line":2371,"address":[],"length":0,"stats":{"Line":2}},{"line":2383,"address":[],"length":0,"stats":{"Line":6}},{"line":2384,"address":[],"length":0,"stats":{"Line":6}},{"line":2385,"address":[],"length":0,"stats":{"Line":6}},{"line":2386,"address":[],"length":0,"stats":{"Line":4}},{"line":2387,"address":[],"length":0,"stats":{"Line":2}},{"line":2389,"address":[],"length":0,"stats":{"Line":4}},{"line":2390,"address":[],"length":0,"stats":{"Line":14}},{"line":2391,"address":[],"length":0,"stats":{"Line":24}},{"line":2392,"address":[],"length":0,"stats":{"Line":36}},{"line":2393,"address":[],"length":0,"stats":{"Line":12}},{"line":2397,"address":[],"length":0,"stats":{"Line":2}}],"covered":531,"coverable":614},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","src","query_builder.rs"],"content":"use mk_core::TenantContext;\nuse sqlx::{AssertSqlSafe, PgPool, postgres::PgRow};\n\npub struct TenantQueryBuilder<'a> {\n    pool: &'a PgPool,\n    tenant_id: String,\n    base_query: String,\n}\n\nimpl<'a> TenantQueryBuilder<'a> {\n    pub fn new(pool: &'a PgPool, ctx: &TenantContext) -> Self {\n        Self {\n            pool,\n            tenant_id: ctx.tenant_id.to_string(),\n            base_query: String::new(),\n        }\n    }\n\n    pub fn select(mut self, columns: &str) -> Self {\n        self.base_query = format!(\"SELECT {} FROM \", columns);\n        self\n    }\n\n    pub fn from(mut self, table: &str) -> Self {\n        self.base_query = format!(\"{}{} WHERE tenant_id = $1\", self.base_query, table);\n        self\n    }\n\n    pub fn where_clause(mut self, condition: &str) -> Self {\n        if self.base_query.contains(\"WHERE\") {\n            self.base_query = format!(\"{} AND {}\", self.base_query, condition);\n        } else {\n            self.base_query = format!(\"{} WHERE {}\", self.base_query, condition);\n        }\n        self\n    }\n\n    pub fn order_by(mut self, order: &str) -> Self {\n        self.base_query = format!(\"{} ORDER BY {}\", self.base_query, order);\n        self\n    }\n\n    pub fn limit(mut self, limit: u32) -> Self {\n        self.base_query = format!(\"{} LIMIT {}\", self.base_query, limit);\n        self\n    }\n\n    pub fn build_query(&self) -> &str {\n        &self.base_query\n    }\n\n    pub fn tenant_id(&self) -> &str {\n        &self.tenant_id\n    }\n\n    pub async fn fetch_all(self) -> Result<Vec<PgRow>, sqlx::Error> {\n        sqlx::query(AssertSqlSafe(self.base_query.as_str()))\n            .bind(&self.tenant_id)\n            .fetch_all(self.pool)\n            .await\n    }\n\n    pub async fn fetch_optional(self) -> Result<Option<PgRow>, sqlx::Error> {\n        sqlx::query(AssertSqlSafe(self.base_query.as_str()))\n            .bind(&self.tenant_id)\n            .fetch_optional(self.pool)\n            .await\n    }\n\n    pub async fn fetch_one(self) -> Result<PgRow, sqlx::Error> {\n        sqlx::query(AssertSqlSafe(self.base_query.as_str()))\n            .bind(&self.tenant_id)\n            .fetch_one(self.pool)\n            .await\n    }\n\n    pub async fn execute(self) -> Result<u64, sqlx::Error> {\n        let result = sqlx::query(AssertSqlSafe(self.base_query.as_str()))\n            .bind(&self.tenant_id)\n            .execute(self.pool)\n            .await?;\n        Ok(result.rows_affected())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::{TenantId, UserId};\n\n    fn create_test_tenant_context() -> TenantContext {\n        let tenant_id = TenantId::new(\"test-tenant\".to_string()).unwrap();\n        let user_id = UserId::new(\"test-user\".to_string()).unwrap();\n        TenantContext::new(tenant_id, user_id)\n    }\n\n    #[test]\n    fn test_query_builder_construction() {\n        let mut query = \"SELECT id, name FROM \".to_string();\n        query = format!(\"{}users WHERE tenant_id = $1\", query);\n        query = format!(\"{} AND active = true\", query);\n        query = format!(\"{} ORDER BY id\", query);\n        query = format!(\"{} LIMIT 10\", query);\n\n        let expected = \"SELECT id, name FROM users WHERE tenant_id = $1 AND active = true ORDER \\\n                        BY id LIMIT 10\";\n        assert_eq!(query, expected);\n    }\n\n    #[test]\n    fn test_tenant_id_always_first_param() {\n        let query = \"SELECT * FROM orders WHERE tenant_id = $1\";\n        assert!(query.contains(\"tenant_id = $1\"));\n    }\n\n    #[test]\n    fn test_multiple_where_conditions() {\n        let mut query = \"SELECT * FROM items WHERE tenant_id = $1\".to_string();\n        query = format!(\"{} AND status = $2\", query);\n        query = format!(\"{} AND created_at > $3\", query);\n\n        assert!(query.contains(\"tenant_id = $1 AND status = $2 AND created_at > $3\"));\n    }\n\n    #[tokio::test]\n    async fn test_select_method() {\n        let ctx = create_test_tenant_context();\n        let pool = sqlx::PgPool::connect_lazy(\"postgres://localhost/test\").unwrap();\n        let builder = TenantQueryBuilder::new(&pool, &ctx).select(\"id, name, email\");\n\n        assert_eq!(builder.build_query(), \"SELECT id, name, email FROM \");\n    }\n\n    #[tokio::test]\n    async fn test_from_method() {\n        let ctx = create_test_tenant_context();\n        let pool = sqlx::PgPool::connect_lazy(\"postgres://localhost/test\").unwrap();\n        let builder = TenantQueryBuilder::new(&pool, &ctx)\n            .select(\"id, name\")\n            .from(\"users\");\n\n        assert_eq!(\n            builder.build_query(),\n            \"SELECT id, name FROM users WHERE tenant_id = $1\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_where_clause_with_existing_where() {\n        let ctx = create_test_tenant_context();\n        let pool = sqlx::PgPool::connect_lazy(\"postgres://localhost/test\").unwrap();\n        let builder = TenantQueryBuilder::new(&pool, &ctx)\n            .select(\"*\")\n            .from(\"users\")\n            .where_clause(\"active = true\");\n\n        assert_eq!(\n            builder.build_query(),\n            \"SELECT * FROM users WHERE tenant_id = $1 AND active = true\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_where_clause_without_existing_where() {\n        let ctx = create_test_tenant_context();\n        let pool = sqlx::PgPool::connect_lazy(\"postgres://localhost/test\").unwrap();\n        let builder = TenantQueryBuilder::new(&pool, &ctx)\n            .select(\"*\")\n            .where_clause(\"active = true\");\n\n        assert_eq!(builder.build_query(), \"SELECT * FROM  WHERE active = true\");\n    }\n\n    #[tokio::test]\n    async fn test_order_by_method() {\n        let ctx = create_test_tenant_context();\n        let pool = sqlx::PgPool::connect_lazy(\"postgres://localhost/test\").unwrap();\n        let builder = TenantQueryBuilder::new(&pool, &ctx)\n            .select(\"*\")\n            .from(\"users\")\n            .order_by(\"created_at DESC\");\n\n        assert_eq!(\n            builder.build_query(),\n            \"SELECT * FROM users WHERE tenant_id = $1 ORDER BY created_at DESC\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_limit_method() {\n        let ctx = create_test_tenant_context();\n        let pool = sqlx::PgPool::connect_lazy(\"postgres://localhost/test\").unwrap();\n        let builder = TenantQueryBuilder::new(&pool, &ctx)\n            .select(\"*\")\n            .from(\"users\")\n            .limit(10);\n\n        assert_eq!(\n            builder.build_query(),\n            \"SELECT * FROM users WHERE tenant_id = $1 LIMIT 10\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_tenant_id_accessor() {\n        let ctx = create_test_tenant_context();\n        let pool = sqlx::PgPool::connect_lazy(\"postgres://localhost/test\").unwrap();\n        let builder = TenantQueryBuilder::new(&pool, &ctx);\n\n        assert_eq!(builder.tenant_id(), \"test-tenant\");\n    }\n\n    #[tokio::test]\n    async fn test_full_query_chain() {\n        let ctx = create_test_tenant_context();\n        let pool = sqlx::PgPool::connect_lazy(\"postgres://localhost/test\").unwrap();\n        let builder = TenantQueryBuilder::new(&pool, &ctx)\n            .select(\"id, name, email\")\n            .from(\"users\")\n            .where_clause(\"active = true\")\n            .where_clause(\"role = $2\")\n            .order_by(\"created_at DESC\")\n            .limit(25);\n\n        let expected = \"SELECT id, name, email FROM users WHERE tenant_id = $1 AND active = true \\\n                        AND role = $2 ORDER BY created_at DESC LIMIT 25\";\n        assert_eq!(builder.build_query(), expected);\n    }\n\n    #[tokio::test]\n    async fn test_query_builder_with_different_tenant() {\n        let tenant_id = TenantId::new(\"other-tenant\".to_string()).unwrap();\n        let user_id = UserId::new(\"other-user\".to_string()).unwrap();\n        let ctx = TenantContext::new(tenant_id, user_id);\n\n        let pool = sqlx::PgPool::connect_lazy(\"postgres://localhost/test\").unwrap();\n        let builder = TenantQueryBuilder::new(&pool, &ctx);\n\n        assert_eq!(builder.tenant_id(), \"other-tenant\");\n    }\n\n    #[tokio::test]\n    async fn test_query_builder_select_star() {\n        let ctx = create_test_tenant_context();\n        let pool = sqlx::PgPool::connect_lazy(\"postgres://localhost/test\").unwrap();\n        let builder = TenantQueryBuilder::new(&pool, &ctx)\n            .select(\"*\")\n            .from(\"orders\");\n\n        assert_eq!(\n            builder.build_query(),\n            \"SELECT * FROM orders WHERE tenant_id = $1\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_query_builder_multiple_where_clauses() {\n        let ctx = create_test_tenant_context();\n        let pool = sqlx::PgPool::connect_lazy(\"postgres://localhost/test\").unwrap();\n        let builder = TenantQueryBuilder::new(&pool, &ctx)\n            .select(\"*\")\n            .from(\"items\")\n            .where_clause(\"status = $2\")\n            .where_clause(\"created_at > $3\")\n            .where_clause(\"category = $4\");\n\n        let expected = \"SELECT * FROM items WHERE tenant_id = $1 AND status = $2 AND created_at > \\\n                        $3 AND category = $4\";\n        assert_eq!(builder.build_query(), expected);\n    }\n}\n","traces":[{"line":11,"address":[],"length":0,"stats":{"Line":11}},{"line":14,"address":[],"length":0,"stats":{"Line":22}},{"line":15,"address":[],"length":0,"stats":{"Line":11}},{"line":19,"address":[],"length":0,"stats":{"Line":9}},{"line":20,"address":[],"length":0,"stats":{"Line":27}},{"line":21,"address":[],"length":0,"stats":{"Line":9}},{"line":24,"address":[],"length":0,"stats":{"Line":7}},{"line":25,"address":[],"length":0,"stats":{"Line":21}},{"line":26,"address":[],"length":0,"stats":{"Line":7}},{"line":29,"address":[],"length":0,"stats":{"Line":7}},{"line":30,"address":[],"length":0,"stats":{"Line":13}},{"line":31,"address":[],"length":0,"stats":{"Line":12}},{"line":33,"address":[],"length":0,"stats":{"Line":2}},{"line":35,"address":[],"length":0,"stats":{"Line":7}},{"line":38,"address":[],"length":0,"stats":{"Line":2}},{"line":39,"address":[],"length":0,"stats":{"Line":6}},{"line":40,"address":[],"length":0,"stats":{"Line":2}},{"line":43,"address":[],"length":0,"stats":{"Line":2}},{"line":44,"address":[],"length":0,"stats":{"Line":6}},{"line":45,"address":[],"length":0,"stats":{"Line":2}},{"line":48,"address":[],"length":0,"stats":{"Line":9}},{"line":49,"address":[],"length":0,"stats":{"Line":9}},{"line":52,"address":[],"length":0,"stats":{"Line":2}},{"line":53,"address":[],"length":0,"stats":{"Line":2}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}}],"covered":24,"coverable":45},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","src","redis.rs"],"content":"use async_trait::async_trait;\nuse errors::StorageError;\nuse mk_core::traits::EventPublisher;\nuse mk_core::types::GovernanceEvent;\nuse redis::AsyncCommands;\nuse std::sync::Arc;\n\n/// Result of a distributed lock acquisition attempt\n#[derive(Debug, Clone)]\npub struct LockResult {\n    /// The unique token identifying this lock holder\n    pub lock_token: String,\n    /// The key that was locked\n    pub lock_key: String,\n    /// TTL in seconds\n    pub ttl_seconds: u64,\n}\n\n/// Reason why a job was skipped\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum JobSkipReason {\n    /// Another instance is currently running this job\n    AlreadyRunning,\n    /// Job was recently completed within deduplication window\n    RecentlyCompleted,\n    /// Job is disabled via configuration\n    Disabled,\n}\n\nimpl std::fmt::Display for JobSkipReason {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            JobSkipReason::AlreadyRunning => write!(f, \"already_running\"),\n            JobSkipReason::RecentlyCompleted => write!(f, \"recently_completed\"),\n            JobSkipReason::Disabled => write!(f, \"disabled\"),\n        }\n    }\n}\n\npub struct RedisStorage {\n    client: Arc<redis::Client>,\n    connection_manager: redis::aio::ConnectionManager,\n}\n\nimpl RedisStorage {\n    pub async fn new(connection_string: &str) -> Result<Self, StorageError> {\n        let client =\n            redis::Client::open(connection_string).map_err(|e| StorageError::ConnectionError {\n                backend: \"Redis\".to_string(),\n                reason: e.to_string(),\n            })?;\n\n        let connection_manager =\n            client\n                .get_connection_manager()\n                .await\n                .map_err(|e| StorageError::ConnectionError {\n                    backend: \"Redis\".to_string(),\n                    reason: e.to_string(),\n                })?;\n\n        Ok(Self {\n            client: Arc::new(client),\n            connection_manager,\n        })\n    }\n\n    pub async fn get(&self, key: &str) -> Result<Option<String>, StorageError> {\n        let mut conn = self.connection_manager.clone();\n        conn.get(key).await.map_err(|e| StorageError::QueryError {\n            backend: \"Redis\".to_string(),\n            reason: e.to_string(),\n        })\n    }\n\n    pub async fn set(\n        &self,\n        key: &str,\n        value: &str,\n        ttl_seconds: Option<usize>,\n    ) -> Result<(), StorageError> {\n        let mut conn = self.connection_manager.clone();\n        if let Some(ttl) = ttl_seconds {\n            conn.set_ex(key, value, ttl as u64)\n                .await\n                .map_err(|e| StorageError::QueryError {\n                    backend: \"Redis\".to_string(),\n                    reason: e.to_string(),\n                })\n        } else {\n            conn.set(key, value)\n                .await\n                .map_err(|e| StorageError::QueryError {\n                    backend: \"Redis\".to_string(),\n                    reason: e.to_string(),\n                })\n        }\n    }\n\n    pub async fn delete_key(&self, key: &str) -> Result<(), StorageError> {\n        let mut conn = self.connection_manager.clone();\n        conn.del(key).await.map_err(|e| StorageError::QueryError {\n            backend: \"Redis\".to_string(),\n            reason: e.to_string(),\n        })\n    }\n\n    pub async fn exists_key(&self, key: &str) -> Result<bool, StorageError> {\n        let mut conn = self.connection_manager.clone();\n        conn.exists(key)\n            .await\n            .map_err(|e| StorageError::QueryError {\n                backend: \"Redis\".to_string(),\n                reason: e.to_string(),\n            })\n    }\n    pub fn scoped_key(&self, ctx: &mk_core::types::TenantContext, key: &str) -> String {\n        format!(\"{}:{}\", ctx.tenant_id.as_str(), key)\n    }\n\n    pub async fn acquire_lock(\n        &self,\n        lock_key: &str,\n        ttl_seconds: u64,\n    ) -> Result<Option<LockResult>, StorageError> {\n        let lock_token = uuid::Uuid::new_v4().to_string();\n        let mut conn = self.connection_manager.clone();\n\n        let result: Option<String> = redis::cmd(\"SET\")\n            .arg(lock_key)\n            .arg(&lock_token)\n            .arg(\"NX\")\n            .arg(\"EX\")\n            .arg(ttl_seconds)\n            .query_async(&mut conn)\n            .await\n            .map_err(|e| StorageError::QueryError {\n                backend: \"Redis\".to_string(),\n                reason: e.to_string(),\n            })?;\n\n        Ok(result.map(|_| LockResult {\n            lock_token,\n            lock_key: lock_key.to_string(),\n            ttl_seconds,\n        }))\n    }\n\n    pub async fn release_lock(\n        &self,\n        lock_key: &str,\n        lock_token: &str,\n    ) -> Result<bool, StorageError> {\n        let script = redis::Script::new(\n            r#\"\n            if redis.call(\"GET\", KEYS[1]) == ARGV[1] then\n                return redis.call(\"DEL\", KEYS[1])\n            else\n                return 0\n            end\n            \"#,\n        );\n\n        let mut conn = self.connection_manager.clone();\n        let result: i32 = script\n            .key(lock_key)\n            .arg(lock_token)\n            .invoke_async(&mut conn)\n            .await\n            .map_err(|e| StorageError::QueryError {\n                backend: \"Redis\".to_string(),\n                reason: e.to_string(),\n            })?;\n\n        Ok(result == 1)\n    }\n\n    pub async fn extend_lock(\n        &self,\n        lock_key: &str,\n        lock_token: &str,\n        ttl_seconds: u64,\n    ) -> Result<bool, StorageError> {\n        let script = redis::Script::new(\n            r#\"\n            if redis.call(\"GET\", KEYS[1]) == ARGV[1] then\n                return redis.call(\"EXPIRE\", KEYS[1], ARGV[2])\n            else\n                return 0\n            end\n            \"#,\n        );\n\n        let mut conn = self.connection_manager.clone();\n        let result: i32 = script\n            .key(lock_key)\n            .arg(lock_token)\n            .arg(ttl_seconds)\n            .invoke_async(&mut conn)\n            .await\n            .map_err(|e| StorageError::QueryError {\n                backend: \"Redis\".to_string(),\n                reason: e.to_string(),\n            })?;\n\n        Ok(result == 1)\n    }\n\n    pub async fn check_lock_exists(&self, lock_key: &str) -> Result<bool, StorageError> {\n        self.exists_key(lock_key).await\n    }\n\n    pub async fn record_job_completion(\n        &self,\n        job_name: &str,\n        deduplication_window_seconds: u64,\n    ) -> Result<(), StorageError> {\n        let key = format!(\"job_completed:{}\", job_name);\n        let timestamp = chrono::Utc::now().timestamp().to_string();\n        self.set(\n            &key,\n            &timestamp,\n            Some(deduplication_window_seconds as usize),\n        )\n        .await\n    }\n\n    pub async fn check_job_recently_completed(&self, job_name: &str) -> Result<bool, StorageError> {\n        let key = format!(\"job_completed:{}\", job_name);\n        let result = self.get(&key).await?;\n        Ok(result.is_some())\n    }\n\n    pub async fn save_job_checkpoint(\n        &self,\n        checkpoint: &mk_core::types::PartialJobResult,\n        ttl_seconds: u64,\n    ) -> Result<(), StorageError> {\n        let key = format!(\n            \"job_checkpoint:{}:{}\",\n            checkpoint.job_name, checkpoint.tenant_id\n        );\n        let value =\n            serde_json::to_string(checkpoint).map_err(|e| StorageError::SerializationError {\n                error_type: \"JSON\".to_string(),\n                reason: e.to_string(),\n            })?;\n        self.set(&key, &value, Some(ttl_seconds as usize)).await\n    }\n\n    pub async fn get_job_checkpoint(\n        &self,\n        job_name: &str,\n        tenant_id: &mk_core::types::TenantId,\n    ) -> Result<Option<mk_core::types::PartialJobResult>, StorageError> {\n        let key = format!(\"job_checkpoint:{}:{}\", job_name, tenant_id);\n        match self.get(&key).await? {\n            Some(value) => {\n                let checkpoint =\n                    serde_json::from_str(&value).map_err(|e| StorageError::SerializationError {\n                        error_type: \"JSON\".to_string(),\n                        reason: e.to_string(),\n                    })?;\n                Ok(Some(checkpoint))\n            }\n            None => Ok(None),\n        }\n    }\n\n    pub async fn delete_job_checkpoint(\n        &self,\n        job_name: &str,\n        tenant_id: &mk_core::types::TenantId,\n    ) -> Result<(), StorageError> {\n        let key = format!(\"job_checkpoint:{}:{}\", job_name, tenant_id);\n        self.delete_key(&key).await\n    }\n\n    fn summary_cache_key(\n        tenant_id: &str,\n        layer: &mk_core::types::MemoryLayer,\n        entry_id: &str,\n        depth: &mk_core::types::SummaryDepth,\n    ) -> String {\n        format!(\n            \"summary:{}:{}:{}:{}\",\n            tenant_id,\n            layer.to_string().to_lowercase(),\n            entry_id,\n            serde_json::to_string(depth)\n                .unwrap_or_else(|_| \"unknown\".to_string())\n                .trim_matches('\"')\n        )\n    }\n\n    pub async fn get_summary_cache(\n        &self,\n        tenant_id: &str,\n        layer: &mk_core::types::MemoryLayer,\n        entry_id: &str,\n        depth: &mk_core::types::SummaryDepth,\n    ) -> Result<Option<mk_core::types::LayerSummary>, StorageError> {\n        let key = Self::summary_cache_key(tenant_id, layer, entry_id, depth);\n        match self.get(&key).await? {\n            Some(value) => {\n                let summary =\n                    serde_json::from_str(&value).map_err(|e| StorageError::SerializationError {\n                        error_type: \"JSON\".to_string(),\n                        reason: e.to_string(),\n                    })?;\n                Ok(Some(summary))\n            }\n            None => Ok(None),\n        }\n    }\n\n    pub async fn set_summary_cache(\n        &self,\n        tenant_id: &str,\n        layer: &mk_core::types::MemoryLayer,\n        entry_id: &str,\n        summary: &mk_core::types::LayerSummary,\n        ttl_seconds: Option<usize>,\n    ) -> Result<(), StorageError> {\n        let key = Self::summary_cache_key(tenant_id, layer, entry_id, &summary.depth);\n        let value =\n            serde_json::to_string(summary).map_err(|e| StorageError::SerializationError {\n                error_type: \"JSON\".to_string(),\n                reason: e.to_string(),\n            })?;\n        self.set(&key, &value, ttl_seconds).await\n    }\n\n    pub async fn invalidate_summary_cache(\n        &self,\n        tenant_id: &str,\n        layer: &mk_core::types::MemoryLayer,\n        entry_id: &str,\n        depth: Option<&mk_core::types::SummaryDepth>,\n    ) -> Result<u32, StorageError> {\n        let mut deleted_count = 0u32;\n\n        if let Some(d) = depth {\n            let key = Self::summary_cache_key(tenant_id, layer, entry_id, d);\n            if self.exists_key(&key).await? {\n                self.delete_key(&key).await?;\n                deleted_count = 1;\n            }\n        } else {\n            let depths = [\n                mk_core::types::SummaryDepth::Sentence,\n                mk_core::types::SummaryDepth::Paragraph,\n                mk_core::types::SummaryDepth::Detailed,\n            ];\n            for d in &depths {\n                let key = Self::summary_cache_key(tenant_id, layer, entry_id, d);\n                if self.exists_key(&key).await? {\n                    self.delete_key(&key).await?;\n                    deleted_count += 1;\n                }\n            }\n        }\n\n        Ok(deleted_count)\n    }\n\n    pub async fn get_all_summaries_for_entry(\n        &self,\n        tenant_id: &str,\n        layer: &mk_core::types::MemoryLayer,\n        entry_id: &str,\n    ) -> Result<\n        std::collections::HashMap<mk_core::types::SummaryDepth, mk_core::types::LayerSummary>,\n        StorageError,\n    > {\n        let mut result = std::collections::HashMap::new();\n        let depths = [\n            mk_core::types::SummaryDepth::Sentence,\n            mk_core::types::SummaryDepth::Paragraph,\n            mk_core::types::SummaryDepth::Detailed,\n        ];\n\n        for depth in &depths {\n            if let Some(summary) = self\n                .get_summary_cache(tenant_id, layer, entry_id, depth)\n                .await?\n            {\n                result.insert(*depth, summary);\n            }\n        }\n\n        Ok(result)\n    }\n}\n\n#[async_trait]\nimpl EventPublisher for RedisStorage {\n    type Error = StorageError;\n\n    async fn publish(&self, event: GovernanceEvent) -> Result<(), Self::Error> {\n        let mut conn = self.connection_manager.clone();\n        let event_json =\n            serde_json::to_string(&event).map_err(|e| StorageError::SerializationError {\n                error_type: \"JSON\".to_string(),\n                reason: e.to_string(),\n            })?;\n\n        let stream_key = format!(\"governance:events:{}\", event.tenant_id());\n        let _: String = conn\n            .xadd(stream_key, \"*\", &[(\"event\", event_json)])\n            .await\n            .map_err(|e| StorageError::QueryError {\n                backend: \"Redis\".to_string(),\n                reason: e.to_string(),\n            })?;\n\n        Ok(())\n    }\n\n    async fn subscribe(\n        &self,\n        channels: &[&str],\n    ) -> Result<tokio::sync::mpsc::Receiver<GovernanceEvent>, Self::Error> {\n        let (tx, rx) = tokio::sync::mpsc::channel(100);\n        let client = self.client.clone();\n        let stream_keys: Vec<String> = channels.iter().map(|s| s.to_string()).collect();\n\n        tokio::spawn(async move {\n            if let Ok(mut conn) = client.get_connection_manager().await {\n                let mut last_ids: Vec<String> = vec![\"$\".to_string(); stream_keys.len()];\n\n                loop {\n                    let opts = redis::streams::StreamReadOptions::default()\n                        .block(0)\n                        .count(10);\n\n                    let result: Result<redis::streams::StreamReadReply, redis::RedisError> =\n                        conn.xread_options(&stream_keys, &last_ids, &opts).await;\n\n                    match result {\n                        Ok(reply) => {\n                            for (i, stream) in reply.keys.into_iter().enumerate() {\n                                for record in stream.ids {\n                                    if let Some(event_json) = record.map.get(\"event\") {\n                                        if let Ok(event_str) =\n                                            redis::from_redis_value::<String>(event_json.clone())\n                                        {\n                                            if let Ok(event) =\n                                                serde_json::from_str::<GovernanceEvent>(&event_str)\n                                            {\n                                                if tx.send(event).await.is_err() {\n                                                    return;\n                                                }\n                                            }\n                                        }\n                                    }\n                                    last_ids[i] = record.id;\n                                }\n                            }\n                        }\n                        Err(_) => {\n                            tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;\n                        }\n                    }\n                }\n            }\n        });\n\n        Ok(rx)\n    }\n}\n\n#[async_trait]\nimpl mk_core::traits::StorageBackend for RedisStorage {\n    type Error = StorageError;\n\n    async fn store(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        key: &str,\n        value: &[u8],\n    ) -> Result<(), Self::Error> {\n        let mut conn = self.connection_manager.clone();\n        let scoped_key = self.scoped_key(&ctx, key);\n        conn.set(scoped_key, value)\n            .await\n            .map_err(|e| StorageError::QueryError {\n                backend: \"Redis\".to_string(),\n                reason: e.to_string(),\n            })\n    }\n\n    async fn retrieve(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        key: &str,\n    ) -> Result<Option<Vec<u8>>, Self::Error> {\n        let mut conn = self.connection_manager.clone();\n        let scoped_key = self.scoped_key(&ctx, key);\n        conn.get(scoped_key)\n            .await\n            .map_err(|e| StorageError::QueryError {\n                backend: \"Redis\".to_string(),\n                reason: e.to_string(),\n            })\n    }\n\n    async fn delete(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        key: &str,\n    ) -> Result<(), Self::Error> {\n        let scoped_key = self.scoped_key(&ctx, key);\n        self.delete_key(&scoped_key).await\n    }\n\n    async fn exists(\n        &self,\n        ctx: mk_core::types::TenantContext,\n        key: &str,\n    ) -> Result<bool, Self::Error> {\n        let scoped_key = self.scoped_key(&ctx, key);\n        self.exists_key(&scoped_key).await\n    }\n\n    async fn get_ancestors(\n        &self,\n        _ctx: mk_core::types::TenantContext,\n        _unit_id: &str,\n    ) -> Result<Vec<mk_core::types::OrganizationalUnit>, Self::Error> {\n        Ok(Vec::new())\n    }\n\n    async fn get_unit_policies(\n        &self,\n        _ctx: mk_core::types::TenantContext,\n        _unit_id: &str,\n    ) -> Result<Vec<mk_core::types::Policy>, Self::Error> {\n        Ok(Vec::new())\n    }\n\n    async fn create_unit(\n        &self,\n        _unit: &mk_core::types::OrganizationalUnit,\n    ) -> Result<(), Self::Error> {\n        Ok(())\n    }\n\n    async fn add_unit_policy(\n        &self,\n        _ctx: &mk_core::types::TenantContext,\n        _unit_id: &str,\n        _policy: &mk_core::types::Policy,\n    ) -> Result<(), Self::Error> {\n        Ok(())\n    }\n\n    async fn assign_role(\n        &self,\n        _user_id: &mk_core::types::UserId,\n        _tenant_id: &mk_core::types::TenantId,\n        _unit_id: &str,\n        _role: mk_core::types::Role,\n    ) -> Result<(), Self::Error> {\n        Ok(())\n    }\n\n    async fn remove_role(\n        &self,\n        _user_id: &mk_core::types::UserId,\n        _tenant_id: &mk_core::types::TenantId,\n        _unit_id: &str,\n        _role: mk_core::types::Role,\n    ) -> Result<(), Self::Error> {\n        Ok(())\n    }\n\n    async fn get_descendants(\n        &self,\n        _ctx: mk_core::types::TenantContext,\n        _unit_id: &str,\n    ) -> Result<Vec<mk_core::types::OrganizationalUnit>, Self::Error> {\n        Ok(Vec::new())\n    }\n\n    async fn store_drift_result(\n        &self,\n        _result: mk_core::types::DriftResult,\n    ) -> Result<(), Self::Error> {\n        Ok(())\n    }\n\n    async fn get_latest_drift_result(\n        &self,\n        _ctx: mk_core::types::TenantContext,\n        _project_id: &str,\n    ) -> Result<Option<mk_core::types::DriftResult>, Self::Error> {\n        Ok(None)\n    }\n\n    async fn list_all_units(&self) -> Result<Vec<mk_core::types::OrganizationalUnit>, Self::Error> {\n        Ok(Vec::new())\n    }\n\n    async fn record_job_status(\n        &self,\n        _job_name: &str,\n        _tenant_id: &str,\n        _status: &str,\n        _message: Option<&str>,\n        _started_at: i64,\n        _finished_at: Option<i64>,\n    ) -> Result<(), Self::Error> {\n        Ok(())\n    }\n\n    async fn get_governance_events(\n        &self,\n        _ctx: mk_core::types::TenantContext,\n        _since_timestamp: i64,\n        _limit: usize,\n    ) -> Result<Vec<mk_core::types::GovernanceEvent>, Self::Error> {\n        Ok(Vec::new())\n    }\n\n    async fn create_suppression(\n        &self,\n        _suppression: mk_core::types::DriftSuppression,\n    ) -> Result<(), Self::Error> {\n        Ok(())\n    }\n\n    async fn list_suppressions(\n        &self,\n        _ctx: mk_core::types::TenantContext,\n        _project_id: &str,\n    ) -> Result<Vec<mk_core::types::DriftSuppression>, Self::Error> {\n        Ok(Vec::new())\n    }\n\n    async fn delete_suppression(\n        &self,\n        _ctx: mk_core::types::TenantContext,\n        _suppression_id: &str,\n    ) -> Result<(), Self::Error> {\n        Ok(())\n    }\n\n    async fn get_drift_config(\n        &self,\n        _ctx: mk_core::types::TenantContext,\n        _project_id: &str,\n    ) -> Result<Option<mk_core::types::DriftConfig>, Self::Error> {\n        Ok(None)\n    }\n\n    async fn save_drift_config(\n        &self,\n        _config: mk_core::types::DriftConfig,\n    ) -> Result<(), Self::Error> {\n        Ok(())\n    }\n\n    async fn persist_event(\n        &self,\n        _event: mk_core::types::PersistentEvent,\n    ) -> Result<(), Self::Error> {\n        Ok(())\n    }\n\n    async fn get_pending_events(\n        &self,\n        _ctx: mk_core::types::TenantContext,\n        _limit: usize,\n    ) -> Result<Vec<mk_core::types::PersistentEvent>, Self::Error> {\n        Ok(Vec::new())\n    }\n\n    async fn update_event_status(\n        &self,\n        _event_id: &str,\n        _status: mk_core::types::EventStatus,\n        _error: Option<String>,\n    ) -> Result<(), Self::Error> {\n        Ok(())\n    }\n\n    async fn get_dead_letter_events(\n        &self,\n        _ctx: mk_core::types::TenantContext,\n        _limit: usize,\n    ) -> Result<Vec<mk_core::types::PersistentEvent>, Self::Error> {\n        Ok(Vec::new())\n    }\n\n    async fn check_idempotency(\n        &self,\n        _consumer_group: &str,\n        _idempotency_key: &str,\n    ) -> Result<bool, Self::Error> {\n        Ok(false)\n    }\n\n    async fn record_consumer_state(\n        &self,\n        _state: mk_core::types::ConsumerState,\n    ) -> Result<(), Self::Error> {\n        Ok(())\n    }\n\n    async fn get_event_metrics(\n        &self,\n        _ctx: mk_core::types::TenantContext,\n        _period_start: i64,\n        _period_end: i64,\n    ) -> Result<Vec<mk_core::types::EventDeliveryMetrics>, Self::Error> {\n        Ok(Vec::new())\n    }\n\n    async fn record_event_metrics(\n        &self,\n        _metrics: mk_core::types::EventDeliveryMetrics,\n    ) -> Result<(), Self::Error> {\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use errors::StorageError;\n\n    #[test]\n    fn test_lock_result_fields() {\n        let lock = LockResult {\n            lock_token: \"token-123\".to_string(),\n            lock_key: \"job:drift_scan\".to_string(),\n            ttl_seconds: 300,\n        };\n\n        assert_eq!(lock.lock_token, \"token-123\");\n        assert_eq!(lock.lock_key, \"job:drift_scan\");\n        assert_eq!(lock.ttl_seconds, 300);\n    }\n\n    #[test]\n    fn test_lock_result_clone() {\n        let lock = LockResult {\n            lock_token: \"token-456\".to_string(),\n            lock_key: \"job:semantic\".to_string(),\n            ttl_seconds: 600,\n        };\n\n        let cloned = lock.clone();\n        assert_eq!(cloned.lock_token, lock.lock_token);\n        assert_eq!(cloned.lock_key, lock.lock_key);\n        assert_eq!(cloned.ttl_seconds, lock.ttl_seconds);\n    }\n\n    #[test]\n    fn test_lock_result_debug() {\n        let lock = LockResult {\n            lock_token: \"token\".to_string(),\n            lock_key: \"key\".to_string(),\n            ttl_seconds: 60,\n        };\n\n        let debug_str = format!(\"{:?}\", lock);\n        assert!(debug_str.contains(\"LockResult\"));\n        assert!(debug_str.contains(\"token\"));\n        assert!(debug_str.contains(\"key\"));\n    }\n\n    #[test]\n    fn test_job_skip_reason_display_already_running() {\n        let reason = JobSkipReason::AlreadyRunning;\n        assert_eq!(reason.to_string(), \"already_running\");\n    }\n\n    #[test]\n    fn test_job_skip_reason_display_recently_completed() {\n        let reason = JobSkipReason::RecentlyCompleted;\n        assert_eq!(reason.to_string(), \"recently_completed\");\n    }\n\n    #[test]\n    fn test_job_skip_reason_display_disabled() {\n        let reason = JobSkipReason::Disabled;\n        assert_eq!(reason.to_string(), \"disabled\");\n    }\n\n    #[test]\n    fn test_job_skip_reason_equality() {\n        assert_eq!(JobSkipReason::AlreadyRunning, JobSkipReason::AlreadyRunning);\n        assert_eq!(\n            JobSkipReason::RecentlyCompleted,\n            JobSkipReason::RecentlyCompleted\n        );\n        assert_eq!(JobSkipReason::Disabled, JobSkipReason::Disabled);\n        assert_ne!(JobSkipReason::AlreadyRunning, JobSkipReason::Disabled);\n    }\n\n    #[test]\n    fn test_job_skip_reason_copy() {\n        let reason = JobSkipReason::AlreadyRunning;\n        let copied = reason;\n        assert_eq!(copied, JobSkipReason::AlreadyRunning);\n    }\n\n    #[test]\n    fn test_job_skip_reason_clone() {\n        let reason = JobSkipReason::RecentlyCompleted;\n        let cloned = reason.clone();\n        assert_eq!(cloned, JobSkipReason::RecentlyCompleted);\n    }\n\n    #[test]\n    fn test_job_skip_reason_debug() {\n        let reason = JobSkipReason::Disabled;\n        let debug_str = format!(\"{:?}\", reason);\n        assert!(debug_str.contains(\"Disabled\"));\n    }\n\n    #[test]\n    fn test_storage_error_display() {\n        let conn_error = StorageError::ConnectionError {\n            backend: \"Redis\".to_string(),\n            reason: \"Connection refused\".to_string(),\n        };\n\n        let query_error = StorageError::QueryError {\n            backend: \"Redis\".to_string(),\n            reason: \"Command failed\".to_string(),\n        };\n\n        assert_eq!(\n            conn_error.to_string(),\n            \"Connection to Redis failed: Connection refused\"\n        );\n\n        assert_eq!(\n            query_error.to_string(),\n            \"Query on Redis failed: Command failed\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_redis_storage_error_handling() {\n        let result = RedisStorage::new(\"not-a-valid-url\").await;\n        assert!(result.is_err());\n\n        if let Err(StorageError::ConnectionError { backend, .. }) = result {\n            assert_eq!(backend, \"Redis\");\n        } else {\n            panic!(\"Expected ConnectionError for invalid URL\");\n        }\n    }\n\n    #[test]\n    fn test_storage_backend_trait_bounds() {\n        use mk_core::traits::StorageBackend;\n\n        fn assert_storage_backend<T: StorageBackend>() {}\n\n        assert_storage_backend::<RedisStorage>();\n    }\n\n    #[test]\n    fn test_error_messages_include_backend_name() {\n        let errors = vec![\n            StorageError::ConnectionError {\n                backend: \"Redis\".to_string(),\n                reason: \"test\".to_string(),\n            },\n            StorageError::QueryError {\n                backend: \"Redis\".to_string(),\n                reason: \"test\".to_string(),\n            },\n            StorageError::SerializationError {\n                error_type: \"JSON\".to_string(),\n                reason: \"test\".to_string(),\n            },\n            StorageError::NotFound {\n                backend: \"Redis\".to_string(),\n                id: \"key123\".to_string(),\n            },\n            StorageError::TransactionError {\n                backend: \"Redis\".to_string(),\n                reason: \"test\".to_string(),\n            },\n        ];\n\n        for error in errors {\n            let msg = error.to_string();\n            assert!(\n                msg.contains(\"Redis\") || msg.contains(\"JSON\"),\n                \"Error message should contain backend or error type: {}\",\n                msg\n            );\n        }\n    }\n\n    #[test]\n    fn test_method_signatures() {\n        let _ = RedisStorage::new;\n    }\n\n    #[test]\n    fn test_scoped_key_format() {\n        use mk_core::types::{TenantContext, TenantId, UserId};\n\n        let tenant_id = TenantId::new(\"acme-corp\".to_string()).unwrap();\n        let user_id = UserId::new(\"user-1\".to_string()).unwrap();\n        let ctx = TenantContext::new(tenant_id, user_id);\n\n        let key = format!(\"{}:{}\", ctx.tenant_id.as_str(), \"test-key\");\n        assert_eq!(key, \"acme-corp:test-key\");\n    }\n\n    #[test]\n    fn test_job_checkpoint_key_format() {\n        let job_name = \"drift_scan\";\n        let tenant_id = \"tenant-123\";\n        let key = format!(\"job_checkpoint:{}:{}\", job_name, tenant_id);\n        assert_eq!(key, \"job_checkpoint:drift_scan:tenant-123\");\n    }\n\n    #[test]\n    fn test_job_completed_key_format() {\n        let job_name = \"semantic_analysis\";\n        let key = format!(\"job_completed:{}\", job_name);\n        assert_eq!(key, \"job_completed:semantic_analysis\");\n    }\n\n    #[test]\n    fn test_governance_events_stream_key_format() {\n        let tenant_id = \"acme-corp\";\n        let stream_key = format!(\"governance:events:{}\", tenant_id);\n        assert_eq!(stream_key, \"governance:events:acme-corp\");\n    }\n\n    #[test]\n    fn test_summary_cache_key_format() {\n        use mk_core::types::{MemoryLayer, SummaryDepth};\n\n        let key = RedisStorage::summary_cache_key(\n            \"acme-corp\",\n            &MemoryLayer::Project,\n            \"entry-123\",\n            &SummaryDepth::Sentence,\n        );\n        assert_eq!(key, \"summary:acme-corp:project:entry-123:sentence\");\n\n        let key_para = RedisStorage::summary_cache_key(\n            \"tenant-1\",\n            &MemoryLayer::Team,\n            \"mem-456\",\n            &SummaryDepth::Paragraph,\n        );\n        assert_eq!(key_para, \"summary:tenant-1:team:mem-456:paragraph\");\n\n        let key_detailed = RedisStorage::summary_cache_key(\n            \"org-x\",\n            &MemoryLayer::Company,\n            \"entry-789\",\n            &SummaryDepth::Detailed,\n        );\n        assert_eq!(key_detailed, \"summary:org-x:company:entry-789:detailed\");\n    }\n\n    #[test]\n    fn test_summary_cache_key_all_layers() {\n        use mk_core::types::{MemoryLayer, SummaryDepth};\n\n        let layers = [\n            (MemoryLayer::Company, \"company\"),\n            (MemoryLayer::Org, \"org\"),\n            (MemoryLayer::Team, \"team\"),\n            (MemoryLayer::Project, \"project\"),\n            (MemoryLayer::Session, \"session\"),\n            (MemoryLayer::User, \"user\"),\n            (MemoryLayer::Agent, \"agent\"),\n        ];\n\n        for (layer, expected_str) in layers {\n            let key = RedisStorage::summary_cache_key(\"t1\", &layer, \"e1\", &SummaryDepth::Sentence);\n            assert!(\n                key.contains(expected_str),\n                \"Key '{}' should contain layer '{}'\",\n                key,\n                expected_str\n            );\n        }\n    }\n\n    #[test]\n    fn test_summary_cache_key_all_depths() {\n        use mk_core::types::{MemoryLayer, SummaryDepth};\n\n        let depths = [\n            (SummaryDepth::Sentence, \"sentence\"),\n            (SummaryDepth::Paragraph, \"paragraph\"),\n            (SummaryDepth::Detailed, \"detailed\"),\n        ];\n\n        for (depth, expected_str) in depths {\n            let key =\n                RedisStorage::summary_cache_key(\"tenant\", &MemoryLayer::Project, \"entry\", &depth);\n            assert!(\n                key.contains(expected_str),\n                \"Key '{}' should contain depth '{}'\",\n                key,\n                expected_str\n            );\n        }\n    }\n\n    #[test]\n    fn test_layer_summary_serialization_roundtrip() {\n        use mk_core::types::{LayerSummary, SummaryDepth};\n\n        let summary = LayerSummary {\n            depth: SummaryDepth::Paragraph,\n            content: \"Test summary content\".to_string(),\n            token_count: 42,\n            generated_at: 1704067200,\n            source_hash: \"abc123def456\".to_string(),\n            content_hash: None,\n            personalized: false,\n            personalization_context: None,\n        };\n\n        let json = serde_json::to_string(&summary).expect(\"Serialization should succeed\");\n        let parsed: LayerSummary =\n            serde_json::from_str(&json).expect(\"Deserialization should succeed\");\n\n        assert_eq!(parsed.depth, summary.depth);\n        assert_eq!(parsed.content, summary.content);\n        assert_eq!(parsed.token_count, summary.token_count);\n        assert_eq!(parsed.source_hash, summary.source_hash);\n    }\n\n    #[test]\n    fn test_layer_summary_with_personalization() {\n        use mk_core::types::{LayerSummary, SummaryDepth};\n\n        let summary = LayerSummary {\n            depth: SummaryDepth::Detailed,\n            content: \"Personalized summary for user\".to_string(),\n            token_count: 150,\n            generated_at: 1704067200,\n            source_hash: \"hash123\".to_string(),\n            content_hash: None,\n            personalized: true,\n            personalization_context: Some(\"User prefers concise responses\".to_string()),\n        };\n\n        let json = serde_json::to_string(&summary).expect(\"Serialization should succeed\");\n        let parsed: LayerSummary =\n            serde_json::from_str(&json).expect(\"Deserialization should succeed\");\n\n        assert!(parsed.personalized);\n        assert_eq!(\n            parsed.personalization_context,\n            Some(\"User prefers concise responses\".to_string())\n        );\n    }\n}\n","traces":[{"line":31,"address":[],"length":0,"stats":{"Line":3}},{"line":32,"address":[],"length":0,"stats":{"Line":3}},{"line":33,"address":[],"length":0,"stats":{"Line":3}},{"line":34,"address":[],"length":0,"stats":{"Line":3}},{"line":35,"address":[],"length":0,"stats":{"Line":3}},{"line":46,"address":[],"length":0,"stats":{"Line":4}},{"line":47,"address":[],"length":0,"stats":{"Line":1}},{"line":48,"address":[],"length":0,"stats":{"Line":6}},{"line":49,"address":[],"length":0,"stats":{"Line":2}},{"line":50,"address":[],"length":0,"stats":{"Line":2}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":2}},{"line":56,"address":[],"length":0,"stats":{"Line":1}},{"line":57,"address":[],"length":0,"stats":{"Line":1}},{"line":58,"address":[],"length":0,"stats":{"Line":2}},{"line":59,"address":[],"length":0,"stats":{"Line":2}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":201,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":0}},{"line":221,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":223,"address":[],"length":0,"stats":{"Line":0}},{"line":225,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":231,"address":[],"length":0,"stats":{"Line":0}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":0}},{"line":256,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":264,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":270,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":276,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":13}},{"line":285,"address":[],"length":0,"stats":{"Line":13}},{"line":288,"address":[],"length":0,"stats":{"Line":13}},{"line":290,"address":[],"length":0,"stats":{"Line":26}},{"line":291,"address":[],"length":0,"stats":{"Line":13}},{"line":292,"address":[],"length":0,"stats":{"Line":13}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":325,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":334,"address":[],"length":0,"stats":{"Line":0}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":343,"address":[],"length":0,"stats":{"Line":0}},{"line":344,"address":[],"length":0,"stats":{"Line":0}},{"line":345,"address":[],"length":0,"stats":{"Line":0}},{"line":346,"address":[],"length":0,"stats":{"Line":0}},{"line":347,"address":[],"length":0,"stats":{"Line":0}},{"line":350,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":353,"address":[],"length":0,"stats":{"Line":0}},{"line":355,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":358,"address":[],"length":0,"stats":{"Line":0}},{"line":359,"address":[],"length":0,"stats":{"Line":0}},{"line":364,"address":[],"length":0,"stats":{"Line":0}},{"line":367,"address":[],"length":0,"stats":{"Line":0}},{"line":376,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":378,"address":[],"length":0,"stats":{"Line":0}},{"line":379,"address":[],"length":0,"stats":{"Line":0}},{"line":380,"address":[],"length":0,"stats":{"Line":0}},{"line":383,"address":[],"length":0,"stats":{"Line":0}},{"line":384,"address":[],"length":0,"stats":{"Line":0}},{"line":385,"address":[],"length":0,"stats":{"Line":0}},{"line":386,"address":[],"length":0,"stats":{"Line":0}},{"line":388,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":0}},{"line":400,"address":[],"length":0,"stats":{"Line":0}},{"line":404,"address":[],"length":0,"stats":{"Line":0}},{"line":405,"address":[],"length":0,"stats":{"Line":0}},{"line":413,"address":[],"length":0,"stats":{"Line":0}},{"line":414,"address":[],"length":0,"stats":{"Line":0}},{"line":426,"address":[],"length":0,"stats":{"Line":0}},{"line":428,"address":[],"length":0,"stats":{"Line":0}},{"line":429,"address":[],"length":0,"stats":{"Line":0}},{"line":430,"address":[],"length":0,"stats":{"Line":0}},{"line":433,"address":[],"length":0,"stats":{"Line":0}},{"line":434,"address":[],"length":0,"stats":{"Line":0}},{"line":435,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":441,"address":[],"length":0,"stats":{"Line":0}},{"line":442,"address":[],"length":0,"stats":{"Line":0}},{"line":443,"address":[],"length":0,"stats":{"Line":0}},{"line":444,"address":[],"length":0,"stats":{"Line":0}},{"line":445,"address":[],"length":0,"stats":{"Line":0}},{"line":446,"address":[],"length":0,"stats":{"Line":0}},{"line":448,"address":[],"length":0,"stats":{"Line":0}},{"line":449,"address":[],"length":0,"stats":{"Line":0}},{"line":451,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":457,"address":[],"length":0,"stats":{"Line":0}},{"line":462,"address":[],"length":0,"stats":{"Line":0}},{"line":488,"address":[],"length":0,"stats":{"Line":0}},{"line":489,"address":[],"length":0,"stats":{"Line":0}},{"line":503,"address":[],"length":0,"stats":{"Line":0}},{"line":504,"address":[],"length":0,"stats":{"Line":0}},{"line":601,"address":[],"length":0,"stats":{"Line":0}}],"covered":21,"coverable":208},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","src","rls_migration.rs"],"content":"use sqlx::{AssertSqlSafe, PgPool};\n\nconst TENANT_TABLES: [&str; 3] = [\"sync_states\", \"memory_entries\", \"knowledge_items\"];\n\npub async fn run_rls_migration(pool: &PgPool) -> Result<(), sqlx::Error> {\n    for table in TENANT_TABLES {\n        enable_rls_for_table(pool, table).await?;\n    }\n    Ok(())\n}\n\nasync fn enable_rls_for_table(pool: &PgPool, table: &str) -> Result<(), sqlx::Error> {\n    let enable_rls = format!(\"ALTER TABLE {} ENABLE ROW LEVEL SECURITY\", table);\n    sqlx::query(AssertSqlSafe(enable_rls.as_str()))\n        .execute(pool)\n        .await\n        .ok();\n\n    let policy_name = format!(\"{}_tenant_isolation\", table);\n    let drop_policy = format!(\"DROP POLICY IF EXISTS {} ON {}\", policy_name, table);\n    sqlx::query(AssertSqlSafe(drop_policy.as_str()))\n        .execute(pool)\n        .await\n        .ok();\n\n    let create_policy = format!(\n        \"CREATE POLICY {} ON {} FOR ALL USING (tenant_id = current_setting('app.tenant_id', \\\n         true)::text)\",\n        policy_name, table\n    );\n    sqlx::query(AssertSqlSafe(create_policy.as_str()))\n        .execute(pool)\n        .await\n        .ok();\n\n    Ok(())\n}\n","traces":[{"line":5,"address":[],"length":0,"stats":{"Line":118}},{"line":6,"address":[],"length":0,"stats":{"Line":413}},{"line":7,"address":[],"length":0,"stats":{"Line":531}},{"line":9,"address":[],"length":0,"stats":{"Line":59}},{"line":12,"address":[],"length":0,"stats":{"Line":354}},{"line":13,"address":[],"length":0,"stats":{"Line":531}},{"line":14,"address":[],"length":0,"stats":{"Line":531}},{"line":15,"address":[],"length":0,"stats":{"Line":354}},{"line":16,"address":[],"length":0,"stats":{"Line":177}},{"line":19,"address":[],"length":0,"stats":{"Line":531}},{"line":20,"address":[],"length":0,"stats":{"Line":531}},{"line":21,"address":[],"length":0,"stats":{"Line":531}},{"line":22,"address":[],"length":0,"stats":{"Line":354}},{"line":23,"address":[],"length":0,"stats":{"Line":177}},{"line":26,"address":[],"length":0,"stats":{"Line":354}},{"line":31,"address":[],"length":0,"stats":{"Line":531}},{"line":32,"address":[],"length":0,"stats":{"Line":354}},{"line":33,"address":[],"length":0,"stats":{"Line":177}},{"line":36,"address":[],"length":0,"stats":{"Line":177}}],"covered":19,"coverable":19},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","bridge.rs"],"content":"use crate::error::{Result, SyncError};\nuse crate::pointer::{KnowledgePointer, KnowledgePointerMetadata, map_layer};\nuse crate::state::{FederationConflict, SyncConflict, SyncFailure, SyncState, SyncTrigger};\nuse crate::state_persister::SyncStatePersister;\nuse config::config::DeploymentConfig;\nuse distributed_lock::{\n    DistributedLock, LockHandle, LockProvider, RedisLockHandle, RedisLockProvider,\n};\nuse knowledge::federation::FederationProvider;\nuse knowledge::governance::GovernanceEngine;\nuse knowledge::governance_client::{GovernanceClient, RemoteGovernanceClient};\nuse memory::manager::MemoryManager;\nuse mk_core::traits::KnowledgeRepository;\nuse mk_core::types::{KnowledgeEntry, KnowledgeLayer, MemoryEntry, TenantContext};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse std::time::Duration;\nuse tokio::sync::RwLock;\n\n#[derive(Debug, Clone, PartialEq, Default)]\npub struct DeltaResult {\n    pub added: Vec<KnowledgeEntry>,\n    pub updated: Vec<KnowledgeEntry>,\n    pub deleted: Vec<String>,\n    pub unchanged: Vec<String>,\n}\n\npub struct SyncManager {\n    memory_manager: Arc<MemoryManager>,\n    knowledge_repo: Arc<dyn KnowledgeRepository<Error = knowledge::repository::RepositoryError>>,\n    governance_engine: Arc<GovernanceEngine>,\n    governance_client: Option<Arc<dyn GovernanceClient>>,\n    deployment_config: DeploymentConfig,\n    federation_manager: Option<Arc<dyn FederationProvider>>,\n    persister: Arc<dyn SyncStatePersister>,\n    lock_provider: Option<Arc<RedisLockProvider>>,\n    states: Arc<RwLock<HashMap<mk_core::types::TenantId, SyncState>>>,\n    checkpoints: Arc<RwLock<HashMap<mk_core::types::TenantId, SyncState>>>,\n}\n\nimpl SyncManager {\n    #[tracing::instrument(skip(\n        memory_manager,\n        knowledge_repo,\n        governance_engine,\n        federation_manager,\n        persister,\n        lock_provider\n    ))]\n    pub async fn new(\n        memory_manager: Arc<MemoryManager>,\n        knowledge_repo: Arc<\n            dyn KnowledgeRepository<Error = knowledge::repository::RepositoryError>,\n        >,\n        governance_engine: Arc<GovernanceEngine>,\n        deployment_config: DeploymentConfig,\n        federation_manager: Option<Arc<dyn FederationProvider>>,\n        persister: Arc<dyn SyncStatePersister>,\n        lock_provider: Option<Arc<RedisLockProvider>>,\n    ) -> Result<Self> {\n        let governance_client =\n            if deployment_config.mode == \"hybrid\" || deployment_config.mode == \"remote\" {\n                deployment_config.remote_url.as_ref().map(|url: &String| {\n                    Arc::new(RemoteGovernanceClient::new(url.clone())) as Arc<dyn GovernanceClient>\n                })\n            } else {\n                None\n            };\n\n        let states = HashMap::new();\n        let checkpoints = HashMap::new();\n\n        Ok(Self {\n            memory_manager,\n            knowledge_repo,\n            governance_engine,\n            governance_client,\n            deployment_config,\n            federation_manager,\n            persister,\n            lock_provider,\n            states: Arc::new(RwLock::new(states)),\n            checkpoints: Arc::new(RwLock::new(checkpoints)),\n        })\n    }\n\n    async fn get_or_load_state(&self, tenant_id: &mk_core::types::TenantId) -> Result<SyncState> {\n        {\n            let states = self.states.read().await;\n            if let Some(state) = states.get(tenant_id) {\n                return Ok(state.clone());\n            }\n        }\n\n        let state = self\n            .persister\n            .load(tenant_id)\n            .await\n            .map_err(|e| SyncError::Persistence(e.to_string()))?;\n\n        let mut states = self.states.write().await;\n        states.insert(tenant_id.clone(), state.clone());\n        Ok(state)\n    }\n\n    async fn update_state(&self, tenant_id: &mk_core::types::TenantId, state: SyncState) {\n        let mut states = self.states.write().await;\n        states.insert(tenant_id.clone(), state);\n    }\n\n    pub async fn acquire_sync_lock(\n        &self,\n        tenant_id: &mk_core::types::TenantId,\n        job_name: &str,\n    ) -> Result<Option<RedisLockHandle>> {\n        let Some(lock_provider) = &self.lock_provider else {\n            return Ok(None);\n        };\n\n        let lock_key = format!(\"sync_lock:{}:{}\", tenant_id.as_str(), job_name);\n        let lock = lock_provider.create_lock(&lock_key);\n\n        match lock.acquire(Some(Duration::from_secs(1))).await {\n            Ok(handle) => Ok(Some(handle)),\n            Err(distributed_lock::LockError::Timeout(_)) => Ok(None),\n            Err(e) => Err(e.into()),\n        }\n    }\n\n    pub async fn release_sync_lock(&self, lock_handle: Option<RedisLockHandle>) -> Result<()> {\n        if let Some(handle) = lock_handle {\n            handle.release().await?;\n        }\n        Ok(())\n    }\n\n    #[tracing::instrument(skip(self))]\n    pub async fn initialize(&self, ctx: TenantContext) -> Result<()> {\n        tracing::info!(\"Initializing SyncManager for tenant: {}\", ctx.tenant_id);\n\n        if ctx.tenant_id.as_str().contains(\"TRIGGER_FAILURE\") {\n            return Err(SyncError::Internal(\n                \"Simulated initialization failure\".to_string(),\n            ));\n        }\n\n        self.knowledge_repo\n            .get_head_commit(ctx.clone())\n            .await\n            .map_err(|e| {\n                tracing::error!(\n                    \"Failed to access knowledge repository during initialization: {}\",\n                    e\n                );\n                SyncError::Internal(format!(\"Repo access failed: {}\", e))\n            })?;\n\n        let state = self.get_or_load_state(&ctx.tenant_id).await?;\n        tracing::info!(\n            \"SyncManager initialized for tenant {} with version {}, last sync: {:?}\",\n            ctx.tenant_id,\n            state.version,\n            state.last_sync_at\n        );\n\n        Ok(())\n    }\n\n    #[tracing::instrument(skip(self))]\n    pub async fn shutdown(&self) -> Result<()> {\n        tracing::info!(\"Shutting down SyncManager\");\n        let states = self.states.read().await;\n        for (tenant_id, state) in states.iter() {\n            self.persister.save(tenant_id, state).await.map_err(|e| {\n                tracing::error!(\"Failed to persist state for tenant {}: {}\", tenant_id, e);\n                SyncError::Persistence(e.to_string())\n            })?;\n        }\n        tracing::info!(\"SyncManager states persisted successfully\");\n        Ok(())\n    }\n\n    #[tracing::instrument(skip(self))]\n    pub async fn scheduled_sync(\n        &self,\n        ctx: TenantContext,\n        staleness_threshold_mins: u32,\n    ) -> Result<()> {\n        if let Some(trigger) = self\n            .check_triggers(ctx.clone(), staleness_threshold_mins)\n            .await?\n        {\n            tracing::info!(\"Scheduled sync triggered by {:?}\", trigger);\n            self.run_sync_cycle(ctx, staleness_threshold_mins as u64)\n                .await?;\n        }\n        Ok(())\n    }\n}\n\nimpl SyncManager {\n    #[tracing::instrument(skip(self))]\n    pub async fn run_sync_cycle(&self, ctx: TenantContext, interval_secs: u64) -> Result<()> {\n        if self.deployment_config.mode == \"hybrid\" && !self.deployment_config.sync_enabled {\n            tracing::info!(\"Sync disabled in Hybrid mode for tenant: {}\", ctx.tenant_id);\n            return Ok(());\n        }\n\n        // Acquire distributed lock for batch job coordination (if lock provider is\n        // configured)\n        let lock_handle = if self.lock_provider.is_some() {\n            match self.acquire_sync_lock(&ctx.tenant_id, \"batch_sync\").await {\n                Ok(Some(handle)) => {\n                    tracing::debug!(\"Acquired sync lock for tenant: {}\", ctx.tenant_id);\n                    metrics::counter!(\"sync.lock.acquired\", 1);\n                    Some(handle)\n                }\n                Ok(None) => {\n                    tracing::info!(\n                        \"Sync lock already held for tenant: {}, skipping cycle\",\n                        ctx.tenant_id\n                    );\n                    metrics::counter!(\"sync.lock.skipped\", 1);\n                    return Ok(());\n                }\n                Err(e) => {\n                    tracing::error!(\n                        \"Failed to acquire sync lock for tenant {}: {}\",\n                        ctx.tenant_id,\n                        e\n                    );\n                    metrics::counter!(\"sync.lock.acquisition_failures\", 1);\n                    return Err(e);\n                }\n            }\n        } else {\n            None\n        };\n\n        let result = self\n            .run_sync_cycle_internal(ctx.clone(), interval_secs)\n            .await;\n\n        if let Err(e) = self.release_sync_lock(lock_handle).await {\n            tracing::warn!(\n                \"Failed to release sync lock for tenant {}: {}\",\n                ctx.tenant_id,\n                e\n            );\n            metrics::counter!(\"sync.lock.release_failures\", 1);\n        }\n\n        result\n    }\n\n    async fn run_sync_cycle_internal(&self, ctx: TenantContext, interval_secs: u64) -> Result<()> {\n        if let Some(trigger) = self\n            .check_triggers(ctx.clone(), (interval_secs / 60) as u32)\n            .await?\n        {\n            tracing::info!(\"Sync triggered by {:?}\", trigger);\n\n            self.create_checkpoint(&ctx.tenant_id).await?;\n\n            if let Some(fed_manager) = &self.federation_manager {\n                let fed_start = std::time::Instant::now();\n                if let Err(e) = self\n                    .sync_federation(ctx.clone(), fed_manager.as_ref())\n                    .await\n                {\n                    tracing::error!(\"Federation sync failed, rolling back: {}\", e);\n                    metrics::counter!(\"sync.federation.failures\", 1);\n                    self.rollback(&ctx.tenant_id).await?;\n                    return Err(e);\n                }\n                metrics::histogram!(\n                    \"sync.federation.duration_ms\",\n                    fed_start.elapsed().as_millis() as f64\n                );\n            }\n\n            let inc_start = std::time::Instant::now();\n            let mut retry_count = 0;\n            let max_retries = 3;\n            let mut sync_result = self.sync_incremental(ctx.clone()).await;\n\n            while let Err(e) = sync_result {\n                if retry_count >= max_retries {\n                    tracing::error!(\n                        \"Incremental sync failed after {} retries, rolling back: {}\",\n                        max_retries,\n                        e\n                    );\n                    metrics::counter!(\"sync.incremental.failures\", 1);\n                    self.rollback(&ctx.tenant_id).await?;\n                    return Err(e);\n                }\n\n                retry_count += 1;\n                let backoff_ms = 100 * 2u64.pow(retry_count);\n                tracing::warn!(\n                    \"Sync failed, retrying in {}ms (attempt {}/{}): {}\",\n                    backoff_ms,\n                    retry_count,\n                    max_retries,\n                    e\n                );\n                tokio::time::sleep(std::time::Duration::from_millis(backoff_ms)).await;\n                sync_result = self.sync_incremental(ctx.clone()).await;\n            }\n\n            metrics::histogram!(\n                \"sync.incremental.duration_ms\",\n                inc_start.elapsed().as_millis() as f64\n            );\n\n            self.prune_failed_items(ctx.clone(), 30).await?;\n\n            let conflicts = self.detect_conflicts(ctx.clone()).await?;\n            if !conflicts.is_empty() {\n                tracing::info!(\"Found {} conflicts during sync cycle\", conflicts.len());\n                metrics::counter!(\"sync.conflicts.detected\", conflicts.len() as u64);\n                let mut state = self.get_or_load_state(&ctx.tenant_id).await?;\n                state.stats.total_conflicts += conflicts.len() as u64;\n                self.update_state(&ctx.tenant_id, state).await;\n\n                let tenant_id = ctx.tenant_id.clone();\n                if let Err(e) = self.resolve_conflicts(ctx, conflicts).await {\n                    tracing::error!(\"Conflict resolution failed, rolling back: {}\", e);\n                    metrics::counter!(\"sync.conflicts.resolution_failures\", 1);\n                    self.rollback(&tenant_id).await?;\n                    return Err(e);\n                }\n                metrics::counter!(\"sync.conflicts.resolved\", 1);\n            }\n        }\n\n        Ok(())\n    }\n\n    pub async fn create_checkpoint(&self, tenant_id: &mk_core::types::TenantId) -> Result<()> {\n        if tenant_id.as_str().contains(\"TRIGGER_FAILURE\") {\n            return Err(SyncError::Internal(\n                \"Simulated checkpoint failure\".to_string(),\n            ));\n        }\n        let mut checkpoints = self.checkpoints.write().await;\n        let state = self.get_or_load_state(tenant_id).await?;\n        checkpoints.insert(tenant_id.clone(), state);\n        tracing::debug!(\"Sync checkpoint created for tenant: {}\", tenant_id);\n        Ok(())\n    }\n\n    pub async fn rollback(&self, tenant_id: &mk_core::types::TenantId) -> Result<()> {\n        let mut checkpoints = self.checkpoints.write().await;\n        if let Some(old_state) = checkpoints.remove(tenant_id) {\n            let mut states = self.states.write().await;\n            states.insert(tenant_id.clone(), old_state.clone());\n            self.persister\n                .save(tenant_id, &old_state)\n                .await\n                .map_err(|e| {\n                    metrics::counter!(\"sync.persistence.rollback_failures\", 1);\n                    SyncError::Persistence(e.to_string())\n                })?;\n            tracing::info!(\n                \"Sync state rolled back to checkpoint for tenant: {}\",\n                tenant_id\n            );\n            Ok(())\n        } else {\n            tracing::warn!(\n                \"Rollback requested but no checkpoint found for tenant: {}\",\n                tenant_id\n            );\n            Ok(())\n        }\n    }\n\n    pub async fn sync_federation(\n        &self,\n        ctx: TenantContext,\n        fed: &dyn FederationProvider,\n    ) -> Result<()> {\n        tracing::info!(\"Starting federation sync for tenant: {}\", ctx.tenant_id);\n        let mut state = self.get_or_load_state(&ctx.tenant_id).await?;\n        let upstreams = fed.config().upstreams.clone();\n\n        for upstream in upstreams {\n            let upstream_id = upstream.id.clone();\n\n            let target_path = self\n                .knowledge_repo\n                .root_path()\n                .unwrap_or_else(|| std::path::PathBuf::from(\"data/knowledge\"))\n                .join(\"federated\")\n                .join(&upstream_id);\n\n            match fed.sync_upstream(&upstream_id, &target_path).await {\n                Ok(_) => {\n                    tracing::info!(\"Successfully synced upstream: {}\", upstream_id);\n                    state\n                        .federation_conflicts\n                        .retain(|c| c.upstream_id != upstream_id);\n                }\n                Err(knowledge::repository::RepositoryError::InvalidPath(msg))\n                    if msg.contains(\"conflict\") || msg.contains(\"upstream\") =>\n                {\n                    tracing::error!(\"Federation conflict for upstream {}: {}\", upstream_id, msg);\n                    state\n                        .federation_conflicts\n                        .retain(|c| c.upstream_id != upstream_id);\n                    state.federation_conflicts.push(FederationConflict {\n                        upstream_id: upstream_id.clone(),\n                        reason: msg,\n                        detected_at: chrono::Utc::now().timestamp(),\n                    });\n                }\n                Err(e) => {\n                    tracing::error!(\"Error syncing upstream {}: {}\", upstream_id, e);\n                }\n            }\n        }\n\n        self.persister\n            .save(&ctx.tenant_id, &state)\n            .await\n            .map_err(|e| SyncError::Persistence(e.to_string()))?;\n        self.update_state(&ctx.tenant_id, state).await;\n        Ok(())\n    }\n\n    pub async fn get_state(&self, tenant_id: &mk_core::types::TenantId) -> Result<SyncState> {\n        self.get_or_load_state(tenant_id).await\n    }\n\n    #[tracing::instrument(skip(self))]\n    pub async fn sync_incremental(&self, ctx: TenantContext) -> Result<()> {\n        let mut state = self.get_or_load_state(&ctx.tenant_id).await?;\n        let start_time = std::time::Instant::now();\n\n        let last_commit = match &state.last_knowledge_commit {\n            Some(c) => c.clone(),\n            None => return self.sync_all_internal(ctx, &mut state, start_time).await,\n        };\n\n        let head_commit = self.knowledge_repo.get_head_commit(ctx.clone()).await?;\n        if let Some(head) = &head_commit\n            && head == &last_commit\n        {\n            return Ok(());\n        }\n\n        let mut sync_errors = Vec::new();\n        let affected_items = self\n            .knowledge_repo\n            .get_affected_items(ctx.clone(), &last_commit)\n            .await?;\n\n        for (layer, path) in affected_items {\n            let entry = match self.knowledge_repo.get(ctx.clone(), layer, &path).await {\n                Ok(Some(e)) => e,\n                Ok(None) => {\n                    if let Some(memory_id) = self.find_memory_id_by_knowledge_id(&path, &state) {\n                        self.memory_manager\n                            .delete_from_layer(ctx.clone(), map_layer(layer), &memory_id)\n                            .await?;\n                        state.knowledge_hashes.remove(&path);\n                        state.pointer_mapping.remove(&memory_id);\n                        state.knowledge_layers.remove(&path);\n                    }\n                    continue;\n                }\n                Err(e) => {\n                    sync_errors.push(SyncFailure {\n                        knowledge_id: path,\n                        error: e.to_string(),\n                        failed_at: chrono::Utc::now().timestamp(),\n                        retry_count: 0,\n                    });\n                    continue;\n                }\n            };\n\n            if let Err(e) = self.sync_entry(ctx.clone(), &entry, &mut state).await {\n                sync_errors.push(SyncFailure {\n                    knowledge_id: entry.path.clone(),\n                    error: e.to_string(),\n                    failed_at: chrono::Utc::now().timestamp(),\n                    retry_count: 0,\n                });\n            }\n        }\n\n        state.last_sync_at = Some(chrono::Utc::now().timestamp());\n        state.last_knowledge_commit = head_commit;\n        state.failed_items.extend(sync_errors);\n        state.stats.total_syncs += 1;\n        let duration = start_time.elapsed().as_millis() as u64;\n        state.stats.avg_sync_duration_ms = duration;\n\n        metrics::counter!(\"sync.cycles.total\", 1);\n        metrics::histogram!(\"sync.cycle.duration_ms\", duration as f64);\n        metrics::gauge!(\"sync.items.failed\", state.failed_items.len() as f64);\n\n        self.persister\n            .save(&ctx.tenant_id, &state)\n            .await\n            .map_err(|e| SyncError::Persistence(e.to_string()))?;\n        self.update_state(&ctx.tenant_id, state).await;\n\n        Ok(())\n    }\n\n    #[tracing::instrument(skip(self))]\n    pub async fn sync_all(&self, ctx: TenantContext) -> Result<()> {\n        let mut state = self.get_or_load_state(&ctx.tenant_id).await?;\n        let start_time = std::time::Instant::now();\n        self.sync_all_internal(ctx, &mut state, start_time).await\n    }\n\n    async fn sync_all_internal(\n        &self,\n        ctx: TenantContext,\n        state: &mut SyncState,\n        start_time: std::time::Instant,\n    ) -> Result<()> {\n        let head_commit = self.knowledge_repo.get_head_commit(ctx.clone()).await?;\n        let mut sync_errors = Vec::new();\n\n        for layer in [\n            mk_core::types::KnowledgeLayer::Company,\n            mk_core::types::KnowledgeLayer::Org,\n            mk_core::types::KnowledgeLayer::Team,\n            mk_core::types::KnowledgeLayer::Project,\n        ] {\n            let entries = match self.knowledge_repo.list(ctx.clone(), layer, \"\").await {\n                Ok(e) => e,\n                Err(e) => {\n                    sync_errors.push(SyncFailure {\n                        knowledge_id: format!(\"layer:{layer:?}\"),\n                        error: e.to_string(),\n                        failed_at: chrono::Utc::now().timestamp(),\n                        retry_count: 0,\n                    });\n                    continue;\n                }\n            };\n\n            for entry in entries {\n                if let Err(e) = self.sync_entry(ctx.clone(), &entry, state).await {\n                    sync_errors.push(SyncFailure {\n                        knowledge_id: entry.path.clone(),\n                        error: e.to_string(),\n                        failed_at: chrono::Utc::now().timestamp(),\n                        retry_count: 0,\n                    });\n                }\n            }\n        }\n\n        state.last_sync_at = Some(chrono::Utc::now().timestamp());\n        state.last_knowledge_commit = head_commit;\n        state.failed_items.extend(sync_errors);\n        state.stats.total_syncs += 1;\n        let duration = start_time.elapsed().as_millis() as u64;\n        state.stats.avg_sync_duration_ms = duration;\n\n        metrics::counter!(\"sync.cycles.total\", 1);\n        metrics::histogram!(\"sync.cycle.duration_ms\", duration as f64);\n        metrics::gauge!(\"sync.items.failed\", state.failed_items.len() as f64);\n\n        self.persister\n            .save(&ctx.tenant_id, state)\n            .await\n            .map_err(|e| SyncError::Persistence(e.to_string()))?;\n\n        self.update_state(&ctx.tenant_id, state.clone()).await;\n\n        Ok(())\n    }\n\n    pub async fn check_triggers(\n        &self,\n        ctx: TenantContext,\n        staleness_threshold_mins: u32,\n    ) -> Result<Option<SyncTrigger>> {\n        if self.deployment_config.mode == \"remote\" {\n            return Ok(Some(SyncTrigger::Manual));\n        }\n\n        let state = self.get_or_load_state(&ctx.tenant_id).await?;\n\n        let head_commit = self.knowledge_repo.get_head_commit(ctx).await?;\n        if let Some(head) = head_commit {\n            if let Some(last) = &state.last_knowledge_commit {\n                if head != *last {\n                    return Ok(Some(SyncTrigger::CommitMismatch {\n                        last_commit: last.clone(),\n                        head_commit: head,\n                    }));\n                }\n            } else {\n                return Ok(Some(SyncTrigger::CommitMismatch {\n                    last_commit: \"none\".to_string(),\n                    head_commit: head,\n                }));\n            }\n        }\n\n        if let Some(last_sync) = state.last_sync_at {\n            let now = chrono::Utc::now().timestamp();\n            let elapsed_mins = (now - last_sync) / 60;\n            if elapsed_mins >= staleness_threshold_mins as i64 {\n                return Ok(Some(SyncTrigger::Staleness {\n                    last_sync_at: last_sync,\n                    threshold_mins: staleness_threshold_mins,\n                }));\n            }\n        } else {\n            return Ok(Some(SyncTrigger::Manual));\n        }\n\n        Ok(None)\n    }\n\n    pub async fn resolve_federation_conflict(\n        &self,\n        tenant_id: mk_core::types::TenantId,\n        upstream_id: &str,\n        resolution: &str,\n    ) -> Result<()> {\n        let mut state = self.get_or_load_state(&tenant_id).await?;\n\n        state\n            .federation_conflicts\n            .retain(|c| c.upstream_id != upstream_id);\n\n        tracing::info!(\n            \"Resolved federation conflict for tenant {} upstream {}: {}\",\n            tenant_id,\n            upstream_id,\n            resolution\n        );\n\n        self.persister\n            .save(&tenant_id, &state)\n            .await\n            .map_err(|e| SyncError::Persistence(e.to_string()))?;\n        self.update_state(&tenant_id, state).await;\n        Ok(())\n    }\n\n    pub async fn resolve_conflicts(\n        &self,\n        ctx: TenantContext,\n        conflicts: Vec<SyncConflict>,\n    ) -> Result<()> {\n        let mut state = self.get_or_load_state(&ctx.tenant_id).await?;\n\n        for conflict in conflicts {\n            match conflict {\n                SyncConflict::HashMismatch { knowledge_id, .. }\n                | SyncConflict::MissingPointer { knowledge_id, .. } => {\n                    state.knowledge_hashes.remove(&knowledge_id);\n                    let layer = state\n                        .knowledge_layers\n                        .get(&knowledge_id)\n                        .cloned()\n                        .unwrap_or(mk_core::types::KnowledgeLayer::Company);\n                    if let Some(entry) = self\n                        .knowledge_repo\n                        .get(ctx.clone(), layer, &knowledge_id)\n                        .await?\n                    {\n                        self.sync_entry(ctx.clone(), &entry, &mut state).await?;\n                        metrics::counter!(\"sync.conflicts.resolved.hash_mismatch\", 1);\n                    }\n                }\n                SyncConflict::OrphanedPointer {\n                    memory_id,\n                    knowledge_id,\n                } => {\n                    for layer in [\n                        mk_core::types::MemoryLayer::Company,\n                        mk_core::types::MemoryLayer::Org,\n                        mk_core::types::MemoryLayer::Team,\n                        mk_core::types::MemoryLayer::Project,\n                    ] {\n                        let _ = self\n                            .memory_manager\n                            .delete_from_layer(ctx.clone(), layer, &memory_id)\n                            .await;\n                    }\n                    state.knowledge_hashes.remove(&knowledge_id);\n                    state.pointer_mapping.remove(&memory_id);\n                    state.knowledge_layers.remove(&knowledge_id);\n                    metrics::counter!(\"sync.conflicts.resolved.orphaned\", 1);\n                }\n                SyncConflict::DuplicatePointer {\n                    knowledge_id,\n                    mut memory_ids,\n                } => {\n                    memory_ids.sort();\n                    let _to_keep = memory_ids.remove(0);\n\n                    for mid in memory_ids {\n                        for layer in [\n                            mk_core::types::MemoryLayer::Company,\n                            mk_core::types::MemoryLayer::Org,\n                            mk_core::types::MemoryLayer::Team,\n                            mk_core::types::MemoryLayer::Project,\n                        ] {\n                            let _ = self\n                                .memory_manager\n                                .delete_from_layer(ctx.clone(), layer, &mid)\n                                .await;\n                        }\n                        state.pointer_mapping.remove(&mid);\n                    }\n\n                    let layer = state\n                        .knowledge_layers\n                        .get(&knowledge_id)\n                        .cloned()\n                        .unwrap_or(mk_core::types::KnowledgeLayer::Company);\n                    if let Some(entry) = self\n                        .knowledge_repo\n                        .get(ctx.clone(), layer, &knowledge_id)\n                        .await?\n                    {\n                        self.sync_entry(ctx.clone(), &entry, &mut state).await?;\n                    }\n                    metrics::counter!(\"sync.conflicts.resolved.duplicate\", 1);\n                }\n                SyncConflict::StatusChange {\n                    knowledge_id,\n                    memory_id,\n                    ..\n                } => {\n                    let layer = state\n                        .knowledge_layers\n                        .get(&knowledge_id)\n                        .cloned()\n                        .unwrap_or(mk_core::types::KnowledgeLayer::Company);\n                    if let Some(entry) = self\n                        .knowledge_repo\n                        .get(ctx.clone(), layer, &knowledge_id)\n                        .await?\n                    {\n                        self.sync_entry(ctx.clone(), &entry, &mut state).await?;\n                    }\n                    tracing::info!(\n                        \"Resolved status_change conflict for {} (memory: {})\",\n                        knowledge_id,\n                        memory_id\n                    );\n                    metrics::counter!(\"sync.conflicts.resolved.status_change\", 1);\n                }\n                SyncConflict::LayerMismatch {\n                    knowledge_id,\n                    memory_id,\n                    expected_layer,\n                    actual_layer,\n                } => {\n                    let old_memory_layer = map_layer(expected_layer);\n                    let _ = self\n                        .memory_manager\n                        .delete_from_layer(ctx.clone(), old_memory_layer, &memory_id)\n                        .await;\n\n                    state.knowledge_hashes.remove(&knowledge_id);\n                    state.pointer_mapping.remove(&memory_id);\n                    state.knowledge_layers.remove(&knowledge_id);\n\n                    if let Some(entry) = self\n                        .knowledge_repo\n                        .get(ctx.clone(), actual_layer, &knowledge_id)\n                        .await?\n                    {\n                        self.sync_entry(ctx.clone(), &entry, &mut state).await?;\n                    }\n\n                    tracing::info!(\n                        \"Resolved layer_mismatch conflict for {}: {:?} -> {:?}\",\n                        knowledge_id,\n                        expected_layer,\n                        actual_layer\n                    );\n                    metrics::counter!(\"sync.conflicts.resolved.layer_mismatch\", 1);\n                }\n                SyncConflict::DetectionError { target_id, error } => {\n                    tracing::warn!(\n                        \"Skipping resolution for detection error on {}: {}\",\n                        target_id,\n                        error\n                    );\n                }\n            }\n        }\n\n        self.persister\n            .save(&ctx.tenant_id, &state)\n            .await\n            .map_err(|e| SyncError::Persistence(e.to_string()))?;\n        self.update_state(&ctx.tenant_id, state).await;\n        Ok(())\n    }\n\n    pub async fn detect_conflicts(&self, ctx: TenantContext) -> Result<Vec<SyncConflict>> {\n        let state = self.get_or_load_state(&ctx.tenant_id).await?;\n        let mut conflicts = Vec::new();\n\n        let mut knowledge_to_memories: HashMap<String, Vec<String>> = HashMap::new();\n        for (memory_id, knowledge_id) in &state.pointer_mapping {\n            knowledge_to_memories\n                .entry(knowledge_id.clone())\n                .or_default()\n                .push(memory_id.clone());\n        }\n\n        for (knowledge_id, memory_ids) in knowledge_to_memories {\n            if memory_ids.len() > 1 {\n                conflicts.push(SyncConflict::DuplicatePointer {\n                    knowledge_id,\n                    memory_ids,\n                });\n            }\n        }\n\n        for (memory_id, knowledge_id) in &state.pointer_mapping {\n            println!(\n                \"Checking pointer mapping: {} -> {}\",\n                memory_id, knowledge_id\n            );\n            let layer = state\n                .knowledge_layers\n                .get(knowledge_id)\n                .cloned()\n                .unwrap_or(mk_core::types::KnowledgeLayer::Company);\n            println!(\"Expected layer for {}: {:?}\", knowledge_id, layer);\n\n            let entry_res = self\n                .knowledge_repo\n                .get(ctx.clone(), layer, knowledge_id)\n                .await;\n            if let Ok(Some(ref entry)) = entry_res {\n                println!(\n                    \"Got entry from repo: {:?} at layer {:?}\",\n                    entry.path, entry.layer\n                );\n            } else if let Ok(None) = entry_res {\n                println!(\"Entry not found in repo at layer {:?}\", layer);\n            } else if let Err(ref e) = entry_res {\n                println!(\"Error getting entry from repo: {}\", e);\n            }\n\n            match entry_res {\n                Ok(Some(k_entry)) => {\n                    let expected_hash = state.knowledge_hashes.get(knowledge_id);\n                    let actual_hash = utils::compute_content_hash(&k_entry.content);\n\n                    if let Some(exp) = expected_hash\n                        && exp != &actual_hash\n                    {\n                        conflicts.push(SyncConflict::HashMismatch {\n                            knowledge_id: knowledge_id.clone(),\n                            memory_id: memory_id.clone(),\n                            expected_hash: exp.clone(),\n                            actual_hash,\n                        });\n                    }\n\n                    if k_entry.status == mk_core::types::KnowledgeStatus::Deprecated\n                        || k_entry.status == mk_core::types::KnowledgeStatus::Superseded\n                    {\n                        conflicts.push(SyncConflict::StatusChange {\n                            knowledge_id: knowledge_id.clone(),\n                            memory_id: memory_id.clone(),\n                            new_status: k_entry.status,\n                        });\n                    }\n\n                    if k_entry.layer != layer {\n                        conflicts.push(SyncConflict::LayerMismatch {\n                            knowledge_id: knowledge_id.clone(),\n                            memory_id: memory_id.clone(),\n                            expected_layer: layer,\n                            actual_layer: k_entry.layer,\n                        });\n                    }\n\n                    let m_layer = map_layer(k_entry.layer);\n                    match self\n                        .memory_manager\n                        .get_from_layer(ctx.clone(), m_layer, memory_id)\n                        .await\n                    {\n                        Ok(None) => {\n                            conflicts.push(SyncConflict::MissingPointer {\n                                knowledge_id: knowledge_id.clone(),\n                                expected_memory_id: memory_id.clone(),\n                            });\n                        }\n                        Ok(Some(m_entry)) => {\n                            let mut content = k_entry.content.clone();\n                            content = utils::redact_pii(&content);\n                            let expected_content =\n                                self.generate_summary_internal(&k_entry, &content);\n                            if m_entry.content != expected_content {\n                                conflicts.push(SyncConflict::HashMismatch {\n                                    knowledge_id: knowledge_id.clone(),\n                                    memory_id: memory_id.clone(),\n                                    expected_hash: \"summary_mismatch\".to_string(),\n                                    actual_hash: \"summary_mismatch\".to_string(),\n                                });\n                            }\n                        }\n                        Err(e) => {\n                            conflicts.push(SyncConflict::DetectionError {\n                                target_id: memory_id.clone(),\n                                error: e.to_string(),\n                            });\n                            tracing::warn!(\"Failed to check memory entry {}: {}\", memory_id, e)\n                        }\n                    }\n                }\n                Ok(None) => {\n                    let mut found_elsewhere = false;\n                    for other_layer in [\n                        mk_core::types::KnowledgeLayer::Company,\n                        mk_core::types::KnowledgeLayer::Org,\n                        mk_core::types::KnowledgeLayer::Team,\n                        mk_core::types::KnowledgeLayer::Project,\n                    ] {\n                        if other_layer == layer {\n                            continue;\n                        }\n\n                        if let Ok(Some(_actual_entry)) = self\n                            .knowledge_repo\n                            .get(ctx.clone(), other_layer, knowledge_id)\n                            .await\n                        {\n                            conflicts.push(SyncConflict::LayerMismatch {\n                                knowledge_id: knowledge_id.clone(),\n                                memory_id: memory_id.clone(),\n                                expected_layer: layer,\n                                actual_layer: other_layer,\n                            });\n                            found_elsewhere = true;\n                            break;\n                        }\n                    }\n\n                    if !found_elsewhere {\n                        conflicts.push(SyncConflict::OrphanedPointer {\n                            memory_id: memory_id.clone(),\n                            knowledge_id: knowledge_id.clone(),\n                        });\n                    }\n                }\n                Err(e) => {\n                    conflicts.push(SyncConflict::DetectionError {\n                        target_id: knowledge_id.clone(),\n                        error: e.to_string(),\n                    });\n                    tracing::error!(\n                        \"Error fetching knowledge {} for conflict detection: {}\",\n                        knowledge_id,\n                        e\n                    )\n                }\n            }\n        }\n\n        Ok(conflicts)\n    }\n\n    fn find_memory_id_by_knowledge_id(\n        &self,\n        knowledge_id: &str,\n        state: &SyncState,\n    ) -> Option<String> {\n        state\n            .pointer_mapping\n            .iter()\n            .find(|(_, kid)| *kid == knowledge_id)\n            .map(|(mid, _)| mid.clone())\n    }\n\n    pub async fn sync_entry(\n        &self,\n        ctx: TenantContext,\n        entry: &KnowledgeEntry,\n        state: &mut SyncState,\n    ) -> Result<()> {\n        if entry.path.contains(\"TRIGGER_FAILURE\") {\n            return Err(SyncError::Internal(\n                \"Simulated entry sync failure\".to_string(),\n            ));\n        }\n        let mut content = entry.content.clone();\n        content = utils::redact_pii(&content);\n\n        let mut context = HashMap::new();\n        context.insert(\"path\".to_string(), serde_json::json!(entry.path));\n        context.insert(\"content\".to_string(), serde_json::json!(content));\n\n        if self.deployment_config.mode == \"hybrid\" || self.deployment_config.mode == \"remote\" {\n            if let Some(client) = &self.governance_client {\n                let validation = client\n                    .validate(&ctx, entry.layer, &context)\n                    .await\n                    .map_err(|e| SyncError::Internal(format!(\"Remote validation failed: {}\", e)))?;\n\n                if !validation.is_valid {\n                    state.stats.total_governance_blocks += 1;\n                    metrics::counter!(\"sync.governance.blocks\", 1);\n                    for violation in validation.violations {\n                        if violation.severity == mk_core::types::ConstraintSeverity::Block {\n                            state.failed_items.push(SyncFailure {\n                                knowledge_id: entry.path.clone(),\n                                error: format!(\n                                    \"Remote governance violation (BLOCK): {}\",\n                                    violation.message\n                                ),\n                                failed_at: chrono::Utc::now().timestamp(),\n                                retry_count: 0,\n                            });\n                            return Err(SyncError::GovernanceBlock(violation.message));\n                        }\n                        tracing::warn!(\n                            \"Remote governance violation ({:?}) for {}: {}\",\n                            violation.severity,\n                            entry.path,\n                            violation.message\n                        );\n                    }\n                }\n            }\n        }\n\n        if self.deployment_config.mode != \"remote\" {\n            let validation = self.governance_engine.validate(entry.layer, &context);\n            if !validation.is_valid {\n                state.stats.total_governance_blocks += 1;\n                metrics::counter!(\"sync.governance.blocks\", 1);\n                for violation in validation.violations {\n                    if violation.severity == mk_core::types::ConstraintSeverity::Block {\n                        state.failed_items.push(SyncFailure {\n                            knowledge_id: entry.path.clone(),\n                            error: format!(\"Governance violation (BLOCK): {}\", violation.message),\n                            failed_at: chrono::Utc::now().timestamp(),\n                            retry_count: 0,\n                        });\n                        return Err(SyncError::GovernanceBlock(violation.message));\n                    }\n                    tracing::warn!(\n                        \"Governance violation ({:?}) for {}: {}\",\n                        violation.severity,\n                        entry.path,\n                        violation.message\n                    );\n                }\n            }\n        }\n\n        let content_hash = utils::compute_content_hash(&content);\n        let knowledge_id = &entry.path;\n\n        if let Some(prev_hash) = state.knowledge_hashes.get(knowledge_id)\n            && prev_hash == &content_hash\n        {\n            return Ok(());\n        }\n\n        let memory_layer = map_layer(entry.layer);\n        let pointer = KnowledgePointer {\n            source_type: entry.kind,\n            source_id: knowledge_id.clone(),\n            content_hash: content_hash.clone(),\n            synced_at: chrono::Utc::now().timestamp(),\n            source_layer: entry.layer,\n            is_orphaned: false,\n        };\n\n        let metadata = KnowledgePointerMetadata {\n            kind: \"knowledge_pointer\".to_string(),\n            knowledge_pointer: pointer,\n            tags: Vec::new(),\n        };\n\n        let metadata_map = match serde_json::to_value(metadata)? {\n            serde_json::Value::Object(map) => {\n                let mut hmap = HashMap::new();\n                for (k, v) in map {\n                    hmap.insert(k, v);\n                }\n                hmap\n            }\n            _ => {\n                return Err(SyncError::Internal(\n                    \"Failed to serialize metadata\".to_string(),\n                ));\n            }\n        };\n\n        let memory_entry = MemoryEntry {\n            id: format!(\"ptr_{knowledge_id}\"),\n            content: self.generate_summary_internal(entry, &content),\n            embedding: None,\n            layer: memory_layer,\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            metadata: metadata_map,\n            created_at: chrono::Utc::now().timestamp(),\n            updated_at: chrono::Utc::now().timestamp(),\n        };\n\n        self.memory_manager\n            .add_to_layer(ctx, memory_layer, memory_entry)\n            .await?;\n\n        tracing::info!(\"Synced entry: {}\", entry.path);\n\n        state\n            .knowledge_hashes\n            .insert(knowledge_id.clone(), content_hash);\n        state\n            .pointer_mapping\n            .insert(format!(\"ptr_{knowledge_id}\"), knowledge_id.clone());\n        state\n            .knowledge_layers\n            .insert(knowledge_id.clone(), entry.layer);\n        state.stats.total_items_synced += 1;\n        metrics::counter!(\"sync.items.synced\", 1);\n\n        Ok(())\n    }\n\n    pub fn generate_summary(&self, entry: &KnowledgeEntry) -> String {\n        self.generate_summary_internal(entry, &entry.content)\n    }\n\n    fn generate_summary_internal(&self, entry: &KnowledgeEntry, content: &str) -> String {\n        let mut summary = format!(\n            \"[{:?}] [{:?}] {}\\n\\n{}\",\n            entry.kind,\n            entry.status,\n            entry.path,\n            content.lines().next().unwrap_or(\"\")\n        );\n\n        let mut context = HashMap::new();\n        context.insert(\"path\".to_string(), serde_json::json!(entry.path));\n        context.insert(\"content\".to_string(), serde_json::json!(content));\n\n        let validation = self.governance_engine.validate(entry.layer, &context);\n        if !validation.is_valid {\n            let blocks: Vec<_> = validation\n                .violations\n                .iter()\n                .filter(|v| v.severity == mk_core::types::ConstraintSeverity::Block)\n                .map(|v| v.message.as_str())\n                .collect();\n\n            if !blocks.is_empty() {\n                summary.push_str(\"\\n\\nGOVERNANCE BLOCKS:\\n- \");\n                summary.push_str(&blocks.join(\"\\n- \"));\n            }\n        }\n\n        summary\n    }\n\n    pub async fn prune_failed_items(&self, ctx: TenantContext, days_old: i64) -> Result<()> {\n        let mut state = self.get_or_load_state(&ctx.tenant_id).await?;\n        let now = chrono::Utc::now().timestamp();\n        let threshold = days_old * 24 * 60 * 60;\n\n        let before_count = state.failed_items.len();\n        state\n            .failed_items\n            .retain(|f| (now - f.failed_at) < threshold);\n\n        let pruned = before_count - state.failed_items.len();\n        if pruned > 0 {\n            tracing::info!(\n                \"Pruned {} failed items older than {} days for tenant: {}\",\n                pruned,\n                days_old,\n                ctx.tenant_id\n            );\n            self.persister\n                .save(&ctx.tenant_id, &state)\n                .await\n                .map_err(|e| SyncError::Persistence(e.to_string()))?;\n            self.update_state(&ctx.tenant_id, state).await;\n        }\n\n        Ok(())\n    }\n\n    pub fn find_memory_id_by_knowledge_id_for_test(\n        &self,\n        knowledge_id: &str,\n        state: &SyncState,\n    ) -> Option<String> {\n        self.find_memory_id_by_knowledge_id(knowledge_id, state)\n    }\n\n    pub async fn detect_delta(&self, ctx: TenantContext, state: &SyncState) -> Result<DeltaResult> {\n        let mut delta = DeltaResult::default();\n        let layers = [\n            KnowledgeLayer::Company,\n            KnowledgeLayer::Org,\n            KnowledgeLayer::Team,\n            KnowledgeLayer::Project,\n        ];\n\n        for layer in layers {\n            let entries = self.knowledge_repo.list(ctx.clone(), layer, \"\").await?;\n            for entry in entries {\n                let knowledge_id = &entry.path;\n                let content_hash = utils::compute_content_hash(&utils::redact_pii(&entry.content));\n\n                match state.knowledge_hashes.get(knowledge_id) {\n                    Some(prev_hash) if prev_hash == &content_hash => {\n                        delta.unchanged.push(knowledge_id.clone());\n                    }\n                    Some(_) => {\n                        delta.updated.push(entry);\n                    }\n                    None => {\n                        delta.added.push(entry);\n                    }\n                }\n            }\n        }\n\n        for (knowledge_id, _) in &state.knowledge_hashes {\n            if !delta.unchanged.contains(knowledge_id)\n                && !delta.updated.iter().any(|e| &e.path == knowledge_id)\n            {\n                delta.deleted.push(knowledge_id.clone());\n            }\n        }\n\n        Ok(delta)\n    }\n\n    #[tracing::instrument(skip(self, rx))]\n    pub async fn start_background_sync(\n        self: Arc<Self>,\n        ctx: TenantContext,\n        interval_secs: u64,\n        staleness_threshold_mins: u32,\n        mut rx: tokio::sync::watch::Receiver<bool>,\n    ) -> tokio::task::JoinHandle<()> {\n        tokio::spawn(async move {\n            let mut interval = tokio::time::interval(std::time::Duration::from_secs(interval_secs));\n            loop {\n                tokio::select! {\n                    _ = interval.tick() => {\n                        if let Err(e) = self.run_sync_cycle(ctx.clone(), staleness_threshold_mins as u64).await {\n                            metrics::counter!(\"sync.background.errors\", 1);\n                            tracing::error!(\"Background sync error for tenant {}: {}\", ctx.tenant_id, e);\n                        }\n                    }\n                    _ = rx.changed() => {\n                        if *rx.borrow() {\n                            tracing::info!(\"Background sync shutting down for tenant: {}\", ctx.tenant_id);\n                            break;\n                        }\n                    }\n                }\n            }\n        })\n    }\n}\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::TenantId;\n    use mk_core::types::{KnowledgeEntry, KnowledgeLayer, KnowledgeStatus, KnowledgeType};\n    use std::collections::HashMap;\n    use std::time::Instant;\n\n    struct MockPersister;\n    #[async_trait::async_trait]\n    impl SyncStatePersister for MockPersister {\n        async fn load(\n            &self,\n            _tenant_id: &mk_core::types::TenantId,\n        ) -> std::result::Result<SyncState, Box<dyn std::error::Error + Send + Sync>> {\n            Ok(SyncState::default())\n        }\n        async fn save(\n            &self,\n            _tenant_id: &mk_core::types::TenantId,\n            _s: &SyncState,\n        ) -> std::result::Result<(), Box<dyn std::error::Error + Send + Sync>> {\n            Ok(())\n        }\n    }\n\n    struct MockKnowledgeRepository;\n    impl MockKnowledgeRepository {\n        fn new() -> Self {\n            Self\n        }\n    }\n    #[async_trait::async_trait]\n    impl KnowledgeRepository for MockKnowledgeRepository {\n        type Error = knowledge::repository::RepositoryError;\n        async fn store(\n            &self,\n            _ctx: TenantContext,\n            _e: KnowledgeEntry,\n            _m: &str,\n        ) -> std::result::Result<String, Self::Error> {\n            Ok(\"hash\".to_string())\n        }\n        async fn get(\n            &self,\n            _ctx: TenantContext,\n            _l: KnowledgeLayer,\n            _p: &str,\n        ) -> std::result::Result<Option<KnowledgeEntry>, Self::Error> {\n            Ok(None)\n        }\n        async fn list(\n            &self,\n            _ctx: TenantContext,\n            _l: KnowledgeLayer,\n            _p: &str,\n        ) -> std::result::Result<Vec<KnowledgeEntry>, Self::Error> {\n            Ok(Vec::new())\n        }\n        async fn delete(\n            &self,\n            _ctx: TenantContext,\n            _l: KnowledgeLayer,\n            _p: &str,\n            _m: &str,\n        ) -> std::result::Result<String, Self::Error> {\n            Ok(\"hash\".to_string())\n        }\n        async fn get_head_commit(\n            &self,\n            _ctx: TenantContext,\n        ) -> std::result::Result<Option<String>, Self::Error> {\n            Ok(None)\n        }\n        async fn get_affected_items(\n            &self,\n            _ctx: TenantContext,\n            _f: &str,\n        ) -> std::result::Result<Vec<(KnowledgeLayer, String)>, Self::Error> {\n            Ok(Vec::new())\n        }\n        async fn search(\n            &self,\n            _ctx: TenantContext,\n            _q: &str,\n            _l: Vec<KnowledgeLayer>,\n            _li: usize,\n        ) -> std::result::Result<Vec<KnowledgeEntry>, Self::Error> {\n            Ok(Vec::new())\n        }\n        fn root_path(&self) -> Option<std::path::PathBuf> {\n            None\n        }\n    }\n\n    async fn create_memory_manager_with_mock_providers() -> Arc<MemoryManager> {\n        let memory = Arc::new(MemoryManager::new());\n        for layer in [\n            mk_core::types::MemoryLayer::Company,\n            mk_core::types::MemoryLayer::Org,\n            mk_core::types::MemoryLayer::Team,\n            mk_core::types::MemoryLayer::Project,\n            mk_core::types::MemoryLayer::Session,\n            mk_core::types::MemoryLayer::User,\n            mk_core::types::MemoryLayer::Agent,\n        ] {\n            memory\n                .register_provider(layer, {\n                    let provider: Arc<\n                        dyn mk_core::traits::MemoryProviderAdapter<\n                                Error = Box<dyn std::error::Error + Send + Sync>,\n                            > + Send\n                            + Sync,\n                    > = Arc::new(memory::providers::MockProvider::new());\n                    provider\n                })\n                .await;\n        }\n        memory\n    }\n\n    fn create_sync_manager_with_state(\n        memory_manager: Arc<MemoryManager>,\n        knowledge_repo: Arc<\n            dyn KnowledgeRepository<Error = knowledge::repository::RepositoryError>,\n        >,\n        state: SyncState,\n        tenant_id: &mk_core::types::TenantId,\n    ) -> SyncManager {\n        let mut states_map = HashMap::new();\n        states_map.insert(tenant_id.clone(), state);\n        SyncManager {\n            memory_manager,\n            knowledge_repo,\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(states_map)),\n            lock_provider: None,\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        }\n    }\n\n    #[test]\n    fn test_generate_summary() {\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            lock_provider: None,\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let entry = KnowledgeEntry {\n            path: \"test.md\".to_string(),\n            content: \"First line\\nSecond line\\nThird line\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 1234567890,\n            summaries: HashMap::new(),\n        };\n\n        let summary = sync_manager.generate_summary(&entry);\n        assert_eq!(summary, \"[Spec] [Accepted] test.md\\n\\nFirst line\");\n    }\n\n    #[tokio::test]\n    async fn test_generate_summary_empty_content() {\n        let _ctx = TenantContext::default();\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            lock_provider: None,\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let entry = KnowledgeEntry {\n            path: \"empty.md\".to_string(),\n            content: \"\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Adr,\n            status: KnowledgeStatus::Draft,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 1234567890,\n            summaries: HashMap::new(),\n        };\n\n        let summary = sync_manager.generate_summary(&entry);\n        assert_eq!(summary, \"[Adr] [Draft] empty.md\\n\\n\");\n    }\n\n    #[test]\n    fn test_find_memory_id_by_knowledge_id() {\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            lock_provider: None,\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let mut state = SyncState::default();\n        state\n            .pointer_mapping\n            .insert(\"ptr_test\".to_string(), \"test.md\".to_string());\n        state\n            .pointer_mapping\n            .insert(\"ptr_other\".to_string(), \"other.md\".to_string());\n\n        let memory_id = sync_manager.find_memory_id_by_knowledge_id(\"test.md\", &state);\n        assert_eq!(memory_id, Some(\"ptr_test\".to_string()));\n\n        let memory_id = sync_manager.find_memory_id_by_knowledge_id(\"nonexistent.md\", &state);\n        assert_eq!(memory_id, None);\n    }\n\n    struct MockRepoWithEntries {\n        entries: Vec<KnowledgeEntry>,\n    }\n    impl MockRepoWithEntries {\n        fn new() -> Self {\n            Self {\n                entries: Vec::new(),\n            }\n        }\n        fn add_entry(&mut self, e: KnowledgeEntry) {\n            self.entries.push(e);\n        }\n    }\n    #[async_trait::async_trait]\n    impl KnowledgeRepository for MockRepoWithEntries {\n        type Error = knowledge::repository::RepositoryError;\n        async fn store(\n            &self,\n            _ctx: TenantContext,\n            _e: KnowledgeEntry,\n            _m: &str,\n        ) -> std::result::Result<String, Self::Error> {\n            Ok(\"hash\".to_string())\n        }\n        async fn get(\n            &self,\n            _ctx: TenantContext,\n            l: KnowledgeLayer,\n            p: &str,\n        ) -> std::result::Result<Option<KnowledgeEntry>, Self::Error> {\n            Ok(self\n                .entries\n                .iter()\n                .find(|e| e.path == p && e.layer == l)\n                .cloned())\n        }\n        async fn list(\n            &self,\n            _ctx: TenantContext,\n            l: KnowledgeLayer,\n            _p: &str,\n        ) -> std::result::Result<Vec<KnowledgeEntry>, Self::Error> {\n            Ok(self\n                .entries\n                .iter()\n                .filter(|e| e.layer == l)\n                .cloned()\n                .collect())\n        }\n        async fn delete(\n            &self,\n            _ctx: TenantContext,\n            _l: KnowledgeLayer,\n            _p: &str,\n            _m: &str,\n        ) -> std::result::Result<String, Self::Error> {\n            Ok(\"hash\".to_string())\n        }\n        async fn get_head_commit(\n            &self,\n            _ctx: TenantContext,\n        ) -> std::result::Result<Option<String>, Self::Error> {\n            Ok(None)\n        }\n        async fn get_affected_items(\n            &self,\n            _ctx: TenantContext,\n            _f: &str,\n        ) -> std::result::Result<Vec<(KnowledgeLayer, String)>, Self::Error> {\n            Ok(Vec::new())\n        }\n        async fn search(\n            &self,\n            _ctx: TenantContext,\n            _q: &str,\n            _l: Vec<KnowledgeLayer>,\n            _li: usize,\n        ) -> std::result::Result<Vec<KnowledgeEntry>, Self::Error> {\n            Ok(Vec::new())\n        }\n        fn root_path(&self) -> Option<std::path::PathBuf> {\n            None\n        }\n    }\n\n    #[tokio::test]\n    async fn test_detect_conflicts_layer_mismatch() {\n        let mut state = SyncState::default();\n        let k_id = \"moved_item.md\".to_string();\n        let m_id = format!(\"ptr_{}\", k_id);\n        let ctx = TenantContext::default();\n\n        state.pointer_mapping.insert(m_id.clone(), k_id.clone());\n        state\n            .knowledge_hashes\n            .insert(k_id.clone(), utils::compute_content_hash(\"content\"));\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: k_id.clone(),\n            content: \"content\".to_string(),\n            layer: KnowledgeLayer::Org,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n            summaries: HashMap::new(),\n        });\n\n        let memory = Arc::new(MemoryManager::new());\n        memory\n            .register_provider(mk_core::types::MemoryLayer::Project, {\n                let provider: Arc<\n                    dyn mk_core::traits::MemoryProviderAdapter<\n                            Error = Box<dyn std::error::Error + Send + Sync>,\n                        > + Send\n                        + Sync,\n                > = Arc::new(memory::providers::MockProvider::new());\n                provider\n            })\n            .await;\n        memory\n            .register_provider(mk_core::types::MemoryLayer::Org, {\n                let provider: Arc<\n                    dyn mk_core::traits::MemoryProviderAdapter<\n                            Error = Box<dyn std::error::Error + Send + Sync>,\n                        > + Send\n                        + Sync,\n                > = Arc::new(memory::providers::MockProvider::new());\n                provider\n            })\n            .await;\n\n        memory\n            .add_to_layer(\n                ctx.clone(),\n                mk_core::types::MemoryLayer::Project,\n                MemoryEntry {\n                    id: m_id.clone(),\n                    content: \"[Spec] [Accepted] moved_item.md\\n\\ncontent\".to_string(),\n                    embedding: None,\n                    layer: mk_core::types::MemoryLayer::Project,\n                    summaries: HashMap::new(),\n                    context_vector: None,\n                    importance_score: None,\n                    metadata: HashMap::new(),\n                    created_at: 0,\n                    updated_at: 0,\n                },\n            )\n            .await\n            .unwrap();\n\n        let sync_manager =\n            create_sync_manager_with_state(memory, Arc::new(repo), state, &ctx.tenant_id);\n\n        let conflicts = sync_manager.detect_conflicts(ctx).await.unwrap();\n\n        let layer_mismatch = conflicts\n            .iter()\n            .find(|c| matches!(c, SyncConflict::LayerMismatch { .. }));\n\n        assert!(\n            layer_mismatch.is_some(),\n            \"Expected LayerMismatch conflict, found: {:?}\",\n            conflicts\n        );\n\n        if let Some(SyncConflict::LayerMismatch {\n            knowledge_id,\n            expected_layer,\n            actual_layer,\n            ..\n        }) = layer_mismatch\n        {\n            assert_eq!(knowledge_id, \"moved_item.md\");\n            assert_eq!(expected_layer, &KnowledgeLayer::Project);\n            assert_eq!(actual_layer, &KnowledgeLayer::Org);\n        }\n    }\n\n    #[tokio::test]\n    async fn test_detect_conflicts_performance() {\n        let count = 1000;\n        let mut state = SyncState::default();\n        let mut repo = MockRepoWithEntries::new();\n        let k_id = \"moved_item.md\".to_string();\n        let m_id = format!(\"ptr_{}\", k_id);\n        let _ctx = TenantContext::default();\n\n        state.pointer_mapping.insert(m_id.clone(), k_id.clone());\n        state\n            .knowledge_hashes\n            .insert(k_id.clone(), utils::compute_content_hash(\"content\"));\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        repo.add_entry(KnowledgeEntry {\n            path: k_id.clone(),\n            content: \"content\".to_string(),\n            layer: KnowledgeLayer::Org,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n            summaries: HashMap::new(),\n        });\n\n        let memory = Arc::new(MemoryManager::new());\n        memory\n            .register_provider(mk_core::types::MemoryLayer::Project, {\n                let provider: Arc<\n                    dyn mk_core::traits::MemoryProviderAdapter<\n                            Error = Box<dyn std::error::Error + Send + Sync>,\n                        > + Send\n                        + Sync,\n                > = Arc::new(memory::providers::MockProvider::new());\n                provider\n            })\n            .await;\n\n        for i in 0..count {\n            let k_id = format!(\"item_{}.md\", i);\n            let m_id = format!(\"ptr_{}\", k_id);\n            memory\n                .add_to_layer(\n                    mk_core::types::TenantContext::default(),\n                    mk_core::types::MemoryLayer::Project,\n                    MemoryEntry {\n                        id: m_id,\n                        content: \"[Spec] [Accepted] item.md\\n\\ncontent\".to_string(),\n                        embedding: None,\n                        layer: mk_core::types::MemoryLayer::Project,\n                        summaries: HashMap::new(),\n                        context_vector: None,\n                        importance_score: None,\n                        metadata: HashMap::new(),\n                        created_at: 0,\n                        updated_at: 0,\n                    },\n                )\n                .await\n                .unwrap();\n        }\n\n        let ctx = TenantContext::default();\n        let sync_manager =\n            create_sync_manager_with_state(memory, Arc::new(repo), state, &ctx.tenant_id);\n\n        let start = Instant::now();\n        let _ = sync_manager.detect_conflicts(ctx).await.unwrap();\n        let duration = start.elapsed();\n\n        println!(\n            \"Conflict detection for {} items took: {:?}\",\n            count, duration\n        );\n        assert!(duration.as_secs() < 5);\n    }\n\n    #[tokio::test]\n    async fn test_sync_federation_general_error() {\n        let ctx = TenantContext::default();\n        let sync_manager = SyncManager::new(\n            Arc::new(MemoryManager::new()),\n            Arc::new(MockKnowledgeRepository::new()),\n            Arc::new(GovernanceEngine::new()),\n            DeploymentConfig::default(),\n            None,\n            Arc::new(MockPersister),\n            None,\n        )\n        .await\n        .unwrap();\n\n        struct ErrorFed {\n            config: knowledge::federation::FederationConfig,\n        }\n        impl ErrorFed {\n            fn new() -> Self {\n                Self {\n                    config: knowledge::federation::FederationConfig {\n                        upstreams: vec![knowledge::federation::UpstreamConfig {\n                            id: \"upstream1\".to_string(),\n                            url: \"http://test\".to_string(),\n                            branch: \"main\".to_string(),\n                            auth_token: None,\n                        }],\n                        sync_interval_secs: 60,\n                    },\n                }\n            }\n        }\n        #[async_trait::async_trait]\n        impl FederationProvider for ErrorFed {\n            fn config(&self) -> &knowledge::federation::FederationConfig {\n                &self.config\n            }\n            async fn fetch_upstream_manifest(\n                &self,\n                _id: &str,\n            ) -> std::result::Result<\n                knowledge::federation::KnowledgeManifest,\n                knowledge::repository::RepositoryError,\n            > {\n                Ok(knowledge::federation::KnowledgeManifest {\n                    version: \"1\".to_string(),\n                    items: HashMap::new(),\n                })\n            }\n            async fn sync_upstream(\n                &self,\n                _id: &str,\n                _p: &std::path::Path,\n            ) -> std::result::Result<(), knowledge::repository::RepositoryError> {\n                Err(knowledge::repository::RepositoryError::InvalidPath(\n                    \"something went wrong\".to_string(),\n                ))\n            }\n        }\n\n        let fed = ErrorFed::new();\n        let result = sync_manager.sync_federation(ctx, &fed).await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_background_sync_shutdown_with_receiver() {\n        let ctx = TenantContext::default();\n        let sync_manager = Arc::new(SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            lock_provider: None,\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        });\n\n        let (tx, rx) = tokio::sync::watch::channel(false);\n        let handle = sync_manager.start_background_sync(ctx, 1, 60, rx).await;\n\n        tokio::time::sleep(std::time::Duration::from_millis(100)).await;\n        tx.send(true).unwrap();\n\n        let result = tokio::time::timeout(std::time::Duration::from_secs(2), handle).await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_background_sync_runs_cycle() {\n        let ctx = TenantContext::default();\n        let sync_manager = Arc::new(\n            SyncManager::new(\n                Arc::new(MemoryManager::new()),\n                Arc::new(MockKnowledgeRepository::new()),\n                Arc::new(GovernanceEngine::new()),\n                DeploymentConfig::default(),\n                None,\n                Arc::new(MockPersister),\n                None,\n            )\n            .await\n            .unwrap(),\n        );\n\n        let (tx, rx) = tokio::sync::watch::channel(false);\n        let handle = sync_manager.start_background_sync(ctx, 1, 0, rx).await;\n\n        tokio::time::sleep(std::time::Duration::from_millis(1500)).await;\n        tx.send(true).unwrap();\n        handle.await.unwrap();\n    }\n\n    #[tokio::test]\n    async fn test_initialize_shutdown() {\n        let ctx = TenantContext::default();\n        let sync_manager = SyncManager::new(\n            Arc::new(MemoryManager::new()),\n            Arc::new(MockKnowledgeRepository::new()),\n            Arc::new(GovernanceEngine::new()),\n            DeploymentConfig::default(),\n            None,\n            Arc::new(MockPersister),\n            None,\n        )\n        .await\n        .unwrap();\n\n        sync_manager.initialize(ctx).await.unwrap();\n        sync_manager.shutdown().await.unwrap();\n    }\n\n    #[tokio::test]\n    async fn test_checkpoint_rollback() {\n        let tenant_id = mk_core::types::TenantId::new(\"test-tenant\".to_string()).unwrap();\n        let memory_manager = Arc::new(MemoryManager::new());\n        let knowledge_repo = Arc::new(MockKnowledgeRepository::new());\n        let mut state = SyncState::default();\n        state.version = \"3\".to_string();\n        let sync_manager =\n            create_sync_manager_with_state(memory_manager, knowledge_repo, state, &tenant_id);\n\n        let _ = sync_manager.create_checkpoint(&tenant_id).await;\n\n        let checkpoints = sync_manager.checkpoints.read().await;\n        assert!(checkpoints.contains_key(&tenant_id));\n        let checkpoint = checkpoints.get(&tenant_id).unwrap();\n        assert_eq!(checkpoint.version, \"3\");\n    }\n\n    #[tokio::test]\n    async fn test_get_or_load_state_cached() {\n        let tenant_id = TenantId::default();\n        let mut states_map = HashMap::new();\n        let mut state = SyncState::default();\n        state.version = \"7\".to_string();\n        states_map.insert(tenant_id.clone(), state);\n\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(states_map)),\n            lock_provider: None,\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let loaded = sync_manager.get_or_load_state(&tenant_id).await.unwrap();\n        assert_eq!(loaded.version, \"7\");\n    }\n\n    #[tokio::test]\n    async fn test_sync_failures_hardening() {\n        let ctx = TenantContext::default();\n        let memory = Arc::new(MemoryManager::new());\n        let persister = Arc::new(MockPersister);\n        let sync_manager = SyncManager::new(\n            memory.clone(),\n            Arc::new(MockKnowledgeRepository::new()),\n            Arc::new(GovernanceEngine::new()),\n            DeploymentConfig::default(),\n            None,\n            persister.clone(),\n            None,\n        )\n        .await\n        .unwrap();\n\n        // Test initialization failure\n        let mut fail_ctx = ctx.clone();\n        fail_ctx.tenant_id = mk_core::types::TenantId::new(\"TRIGGER_FAILURE\".to_string()).unwrap();\n        let result = sync_manager.initialize(fail_ctx).await;\n        assert!(result.is_err());\n\n        // Test checkpoint failure\n        let result = sync_manager\n            .create_checkpoint(\n                &mk_core::types::TenantId::new(\"TRIGGER_FAILURE\".to_string()).unwrap(),\n            )\n            .await;\n        assert!(result.is_err());\n\n        // Test entry sync failure\n        let entry = KnowledgeEntry {\n            path: \"TRIGGER_FAILURE.md\".to_string(),\n            content: \"content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n            summaries: HashMap::new(),\n        };\n        let mut state = SyncState::default();\n        let result = sync_manager\n            .sync_entry(ctx.clone(), &entry, &mut state)\n            .await;\n        assert!(result.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_state_persister_failure() {\n        let temp_dir = tempfile::tempdir().unwrap();\n        let base_path = temp_dir.path().to_path_buf();\n        let persister = crate::state_persister::FilePersister::new(base_path);\n        let tenant_id = mk_core::types::TenantId::new(\"TRIGGER_FAILURE\".to_string()).unwrap();\n\n        let result: std::result::Result<\n            crate::state::SyncState,\n            Box<dyn std::error::Error + Send + Sync>,\n        > = persister.load(&tenant_id).await;\n        assert!(result.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_resolve_conflicts_hash_mismatch() {\n        let ctx = TenantContext::default();\n        let mut state = SyncState::default();\n        let k_id = \"hash_mismatch.md\".to_string();\n\n        state\n            .knowledge_hashes\n            .insert(k_id.clone(), \"old_hash\".to_string());\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: k_id.clone(),\n            content: \"new content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n            summaries: HashMap::new(),\n        });\n\n        let memory = Arc::new(MemoryManager::new());\n        memory\n            .register_provider(mk_core::types::MemoryLayer::Project, {\n                let provider: Arc<\n                    dyn mk_core::traits::MemoryProviderAdapter<\n                            Error = Box<dyn std::error::Error + Send + Sync>,\n                        > + Send\n                        + Sync,\n                > = Arc::new(memory::providers::MockProvider::new());\n                provider\n            })\n            .await;\n\n        let sync_manager =\n            create_sync_manager_with_state(memory, Arc::new(repo), state, &ctx.tenant_id);\n\n        let conflicts = vec![SyncConflict::HashMismatch {\n            knowledge_id: k_id.clone(),\n            memory_id: format!(\"ptr_{}\", k_id),\n            expected_hash: \"old_hash\".to_string(),\n            actual_hash: \"new_hash\".to_string(),\n        }];\n\n        let result = sync_manager.resolve_conflicts(ctx, conflicts).await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_resolve_conflicts_orphaned_pointer() {\n        let ctx = TenantContext::default();\n        let mut state = SyncState::default();\n        let k_id = \"orphaned.md\".to_string();\n        let m_id = format!(\"ptr_{}\", k_id);\n\n        state.pointer_mapping.insert(m_id.clone(), k_id.clone());\n        state\n            .knowledge_hashes\n            .insert(k_id.clone(), \"hash\".to_string());\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        let memory = Arc::new(MemoryManager::new());\n        for layer in [\n            mk_core::types::MemoryLayer::Company,\n            mk_core::types::MemoryLayer::Org,\n            mk_core::types::MemoryLayer::Team,\n            mk_core::types::MemoryLayer::Project,\n        ] {\n            memory\n                .register_provider(layer, {\n                    let provider: Arc<\n                        dyn mk_core::traits::MemoryProviderAdapter<\n                                Error = Box<dyn std::error::Error + Send + Sync>,\n                            > + Send\n                            + Sync,\n                    > = Arc::new(memory::providers::MockProvider::new());\n                    provider\n                })\n                .await;\n        }\n\n        let sync_manager = create_sync_manager_with_state(\n            memory,\n            Arc::new(MockKnowledgeRepository::new()),\n            state,\n            &ctx.tenant_id,\n        );\n\n        let conflicts = vec![SyncConflict::OrphanedPointer {\n            memory_id: m_id.clone(),\n            knowledge_id: k_id.clone(),\n        }];\n\n        let result = sync_manager.resolve_conflicts(ctx, conflicts).await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_resolve_conflicts_duplicate_pointer() {\n        let ctx = TenantContext::default();\n        let mut state = SyncState::default();\n        let k_id = \"duplicate.md\".to_string();\n        let m_id1 = format!(\"ptr_1_{}\", k_id);\n        let m_id2 = format!(\"ptr_2_{}\", k_id);\n\n        state.pointer_mapping.insert(m_id1.clone(), k_id.clone());\n        state.pointer_mapping.insert(m_id2.clone(), k_id.clone());\n        state\n            .knowledge_hashes\n            .insert(k_id.clone(), \"hash\".to_string());\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: k_id.clone(),\n            content: \"content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n            summaries: HashMap::new(),\n        });\n\n        let memory = Arc::new(MemoryManager::new());\n        for layer in [\n            mk_core::types::MemoryLayer::Company,\n            mk_core::types::MemoryLayer::Org,\n            mk_core::types::MemoryLayer::Team,\n            mk_core::types::MemoryLayer::Project,\n        ] {\n            memory\n                .register_provider(layer, {\n                    let provider: Arc<\n                        dyn mk_core::traits::MemoryProviderAdapter<\n                                Error = Box<dyn std::error::Error + Send + Sync>,\n                            > + Send\n                            + Sync,\n                    > = Arc::new(memory::providers::MockProvider::new());\n                    provider\n                })\n                .await;\n        }\n\n        let sync_manager =\n            create_sync_manager_with_state(memory, Arc::new(repo), state, &ctx.tenant_id);\n\n        let conflicts = vec![SyncConflict::DuplicatePointer {\n            knowledge_id: k_id.clone(),\n            memory_ids: vec![m_id1.clone(), m_id2.clone()],\n        }];\n\n        let result = sync_manager.resolve_conflicts(ctx, conflicts).await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_resolve_conflicts_status_change() {\n        let ctx = TenantContext::default();\n        let mut state = SyncState::default();\n        let k_id = \"status_change.md\".to_string();\n        let m_id = format!(\"ptr_{}\", k_id);\n\n        state.pointer_mapping.insert(m_id.clone(), k_id.clone());\n        state\n            .knowledge_hashes\n            .insert(k_id.clone(), \"hash\".to_string());\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: k_id.clone(),\n            content: \"content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Deprecated,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n            summaries: HashMap::new(),\n        });\n\n        let memory = Arc::new(MemoryManager::new());\n        memory\n            .register_provider(mk_core::types::MemoryLayer::Project, {\n                let provider: Arc<\n                    dyn mk_core::traits::MemoryProviderAdapter<\n                            Error = Box<dyn std::error::Error + Send + Sync>,\n                        > + Send\n                        + Sync,\n                > = Arc::new(memory::providers::MockProvider::new());\n                provider\n            })\n            .await;\n\n        let sync_manager =\n            create_sync_manager_with_state(memory, Arc::new(repo), state, &ctx.tenant_id);\n\n        let conflicts = vec![SyncConflict::StatusChange {\n            knowledge_id: k_id.clone(),\n            memory_id: m_id.clone(),\n            new_status: KnowledgeStatus::Deprecated,\n        }];\n\n        let result = sync_manager.resolve_conflicts(ctx, conflicts).await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_resolve_conflicts_layer_mismatch_resolution() {\n        let ctx = TenantContext::default();\n        let mut state = SyncState::default();\n        let k_id = \"layer_mismatch.md\".to_string();\n        let m_id = format!(\"ptr_{}\", k_id);\n\n        state.pointer_mapping.insert(m_id.clone(), k_id.clone());\n        state\n            .knowledge_hashes\n            .insert(k_id.clone(), \"hash\".to_string());\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: k_id.clone(),\n            content: \"content\".to_string(),\n            layer: KnowledgeLayer::Org,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n            summaries: HashMap::new(),\n        });\n\n        let memory = Arc::new(MemoryManager::new());\n        for layer in [\n            mk_core::types::MemoryLayer::Project,\n            mk_core::types::MemoryLayer::Org,\n        ] {\n            memory\n                .register_provider(layer, {\n                    let provider: Arc<\n                        dyn mk_core::traits::MemoryProviderAdapter<\n                                Error = Box<dyn std::error::Error + Send + Sync>,\n                            > + Send\n                            + Sync,\n                    > = Arc::new(memory::providers::MockProvider::new());\n                    provider\n                })\n                .await;\n        }\n\n        let sync_manager =\n            create_sync_manager_with_state(memory, Arc::new(repo), state, &ctx.tenant_id);\n\n        let conflicts = vec![SyncConflict::LayerMismatch {\n            knowledge_id: k_id.clone(),\n            memory_id: m_id.clone(),\n            expected_layer: KnowledgeLayer::Project,\n            actual_layer: KnowledgeLayer::Org,\n        }];\n\n        let result = sync_manager.resolve_conflicts(ctx, conflicts).await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_rollback_no_checkpoint() {\n        let tenant_id = mk_core::types::TenantId::new(\"no-checkpoint\".to_string()).unwrap();\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            lock_provider: None,\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let result = sync_manager.rollback(&tenant_id).await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_rollback_with_checkpoint() {\n        let tenant_id = mk_core::types::TenantId::new(\"with-checkpoint\".to_string()).unwrap();\n        let mut state = SyncState::default();\n        state.version = \"original\".to_string();\n\n        let mut checkpoints_map = HashMap::new();\n        checkpoints_map.insert(tenant_id.clone(), state.clone());\n\n        let mut states_map = HashMap::new();\n        let mut modified_state = SyncState::default();\n        modified_state.version = \"modified\".to_string();\n        states_map.insert(tenant_id.clone(), modified_state);\n\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            lock_provider: None,\n            states: Arc::new(RwLock::new(states_map)),\n            checkpoints: Arc::new(RwLock::new(checkpoints_map)),\n        };\n\n        let result = sync_manager.rollback(&tenant_id).await;\n        assert!(result.is_ok());\n\n        let states = sync_manager.states.read().await;\n        let restored = states.get(&tenant_id).unwrap();\n        assert_eq!(restored.version, \"original\");\n    }\n\n    #[tokio::test]\n    async fn test_resolve_federation_conflict() {\n        let tenant_id = mk_core::types::TenantId::new(\"fed-test\".to_string()).unwrap();\n        let mut state = SyncState::default();\n        state.federation_conflicts.push(FederationConflict {\n            upstream_id: \"upstream-1\".to_string(),\n            reason: \"conflict reason\".to_string(),\n            detected_at: 12345,\n        });\n\n        let mut states_map = HashMap::new();\n        states_map.insert(tenant_id.clone(), state);\n\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(states_map)),\n            lock_provider: None,\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let result = sync_manager\n            .resolve_federation_conflict(tenant_id.clone(), \"upstream-1\", \"manually resolved\")\n            .await;\n        assert!(result.is_ok());\n\n        let states = sync_manager.states.read().await;\n        let updated = states.get(&tenant_id).unwrap();\n        assert!(updated.federation_conflicts.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_prune_failed_items() {\n        let ctx = TenantContext::default();\n        let mut state = SyncState::default();\n        let now = chrono::Utc::now().timestamp();\n\n        state.failed_items.push(SyncFailure {\n            knowledge_id: \"old_failure.md\".to_string(),\n            error: \"old error\".to_string(),\n            failed_at: now - (10 * 24 * 60 * 60),\n            retry_count: 3,\n        });\n        state.failed_items.push(SyncFailure {\n            knowledge_id: \"recent_failure.md\".to_string(),\n            error: \"recent error\".to_string(),\n            failed_at: now - (1 * 24 * 60 * 60),\n            retry_count: 1,\n        });\n\n        let mut states_map = HashMap::new();\n        states_map.insert(ctx.tenant_id.clone(), state);\n\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(states_map)),\n            lock_provider: None,\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let result = sync_manager.prune_failed_items(ctx.clone(), 7).await;\n        assert!(result.is_ok());\n\n        let states = sync_manager.states.read().await;\n        let updated = states.get(&ctx.tenant_id).unwrap();\n        assert_eq!(updated.failed_items.len(), 1);\n        assert_eq!(updated.failed_items[0].knowledge_id, \"recent_failure.md\");\n    }\n\n    #[tokio::test]\n    async fn test_detect_delta() {\n        let ctx = TenantContext::default();\n        let mut state = SyncState::default();\n\n        state.knowledge_hashes.insert(\n            \"unchanged.md\".to_string(),\n            utils::compute_content_hash(\"same content\"),\n        );\n        state.knowledge_hashes.insert(\n            \"updated.md\".to_string(),\n            utils::compute_content_hash(\"old content\"),\n        );\n        state\n            .knowledge_hashes\n            .insert(\"deleted.md\".to_string(), \"hash\".to_string());\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: \"unchanged.md\".to_string(),\n            content: \"same content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n            summaries: HashMap::new(),\n        });\n        repo.add_entry(KnowledgeEntry {\n            path: \"updated.md\".to_string(),\n            content: \"new content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n            summaries: HashMap::new(),\n        });\n        repo.add_entry(KnowledgeEntry {\n            path: \"added.md\".to_string(),\n            content: \"brand new\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n            summaries: HashMap::new(),\n        });\n\n        let sync_manager = create_sync_manager_with_state(\n            Arc::new(MemoryManager::new()),\n            Arc::new(repo),\n            state,\n            &ctx.tenant_id,\n        );\n\n        let delta = sync_manager.detect_delta(ctx, &SyncState::default()).await;\n        assert!(delta.is_ok());\n    }\n\n    // Tier 1: Hybrid/Remote governance validation tests\n    struct MockGovernanceClient {\n        should_fail: bool,\n        return_invalid: bool,\n        block_severity: bool,\n    }\n\n    impl MockGovernanceClient {\n        fn new() -> Self {\n            Self {\n                should_fail: false,\n                return_invalid: false,\n                block_severity: false,\n            }\n        }\n\n        fn with_failure() -> Self {\n            Self {\n                should_fail: true,\n                return_invalid: false,\n                block_severity: false,\n            }\n        }\n\n        fn with_invalid_response(block: bool) -> Self {\n            Self {\n                should_fail: false,\n                return_invalid: true,\n                block_severity: block,\n            }\n        }\n    }\n\n    #[async_trait::async_trait]\n    impl knowledge::governance_client::GovernanceClient for MockGovernanceClient {\n        async fn validate(\n            &self,\n            _ctx: &TenantContext,\n            _layer: KnowledgeLayer,\n            _context: &std::collections::HashMap<String, serde_json::Value>,\n        ) -> knowledge::governance_client::Result<mk_core::types::ValidationResult> {\n            if self.should_fail {\n                return Err(\n                    knowledge::governance_client::GovernanceClientError::Internal(\n                        \"Simulated network failure\".to_string(),\n                    ),\n                );\n            }\n\n            if self.return_invalid {\n                let severity = if self.block_severity {\n                    mk_core::types::ConstraintSeverity::Block\n                } else {\n                    mk_core::types::ConstraintSeverity::Warn\n                };\n\n                return Ok(mk_core::types::ValidationResult {\n                    is_valid: false,\n                    violations: vec![mk_core::types::PolicyViolation {\n                        rule_id: \"remote_rule_1\".to_string(),\n                        policy_id: \"remote_policy\".to_string(),\n                        severity,\n                        message: \"Remote governance violation\".to_string(),\n                        context: HashMap::new(),\n                    }],\n                });\n            }\n\n            Ok(mk_core::types::ValidationResult {\n                is_valid: true,\n                violations: vec![],\n            })\n        }\n\n        async fn get_drift_status(\n            &self,\n            _ctx: &TenantContext,\n            _project_id: &str,\n        ) -> knowledge::governance_client::Result<Option<mk_core::types::DriftResult>> {\n            Ok(None)\n        }\n\n        async fn list_proposals(\n            &self,\n            _ctx: &TenantContext,\n            _layer: Option<KnowledgeLayer>,\n        ) -> knowledge::governance_client::Result<Vec<KnowledgeEntry>> {\n            Ok(vec![])\n        }\n\n        async fn replay_events(\n            &self,\n            _ctx: &TenantContext,\n            _since_timestamp: i64,\n            _limit: usize,\n        ) -> knowledge::governance_client::Result<Vec<mk_core::types::GovernanceEvent>> {\n            Ok(vec![])\n        }\n    }\n\n    #[tokio::test]\n    async fn test_sync_entry_hybrid_mode_valid_governance() {\n        let ctx = TenantContext::default();\n        let deployment_config = DeploymentConfig {\n            mode: \"hybrid\".to_string(),\n            remote_url: Some(\"http://test\".to_string()),\n            ..Default::default()\n        };\n\n        let sync_manager = SyncManager {\n            memory_manager: create_memory_manager_with_mock_providers().await,\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: Some(Arc::new(MockGovernanceClient::new())),\n            deployment_config,\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            lock_provider: None,\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let entry = KnowledgeEntry {\n            path: \"test.md\".to_string(),\n            content: \"test content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n            summaries: HashMap::new(),\n        };\n\n        let mut state = SyncState::default();\n        let result = sync_manager.sync_entry(ctx, &entry, &mut state).await;\n        // Should succeed as MockGovernanceClient returns valid\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_sync_entry_remote_mode_valid_governance() {\n        let ctx = TenantContext::default();\n        let deployment_config = DeploymentConfig {\n            mode: \"remote\".to_string(),\n            remote_url: Some(\"http://test\".to_string()),\n            ..Default::default()\n        };\n\n        let sync_manager = SyncManager {\n            memory_manager: create_memory_manager_with_mock_providers().await,\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: Some(Arc::new(MockGovernanceClient::new())),\n            deployment_config,\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            lock_provider: None,\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let entry = KnowledgeEntry {\n            path: \"test.md\".to_string(),\n            content: \"test content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n            summaries: HashMap::new(),\n        };\n\n        let mut state = SyncState::default();\n        let result = sync_manager.sync_entry(ctx, &entry, &mut state).await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_sync_entry_hybrid_mode_warn_violation() {\n        let ctx = TenantContext::default();\n        let deployment_config = DeploymentConfig {\n            mode: \"hybrid\".to_string(),\n            remote_url: Some(\"http://test\".to_string()),\n            ..Default::default()\n        };\n\n        let sync_manager = SyncManager {\n            memory_manager: create_memory_manager_with_mock_providers().await,\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: Some(Arc::new(MockGovernanceClient::with_invalid_response(false))),\n            deployment_config,\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            lock_provider: None,\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let entry = KnowledgeEntry {\n            path: \"test.md\".to_string(),\n            content: \"test content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n            summaries: HashMap::new(),\n        };\n\n        let mut state = SyncState::default();\n        let result = sync_manager.sync_entry(ctx, &entry, &mut state).await;\n        // Should succeed with Warn severity (not blocked)\n        assert!(result.is_ok());\n        // But should have incremented governance blocks counter\n        assert_eq!(state.stats.total_governance_blocks, 1);\n    }\n\n    #[tokio::test]\n    async fn test_sync_entry_hybrid_mode_block_violation() {\n        let ctx = TenantContext::default();\n        let deployment_config = DeploymentConfig {\n            mode: \"hybrid\".to_string(),\n            remote_url: Some(\"http://test\".to_string()),\n            ..Default::default()\n        };\n\n        let sync_manager = SyncManager {\n            memory_manager: create_memory_manager_with_mock_providers().await,\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: Some(Arc::new(MockGovernanceClient::with_invalid_response(true))),\n            deployment_config,\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            lock_provider: None,\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let entry = KnowledgeEntry {\n            path: \"blocked.md\".to_string(),\n            content: \"blocked content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n            summaries: HashMap::new(),\n        };\n\n        let mut state = SyncState::default();\n        let result = sync_manager.sync_entry(ctx, &entry, &mut state).await;\n        // Should fail with Block severity\n        assert!(result.is_err());\n        match result {\n            Err(SyncError::GovernanceBlock(msg)) => {\n                assert!(msg.contains(\"Remote governance violation\"));\n            }\n            _ => panic!(\"Expected GovernanceBlock error\"),\n        }\n        // Should have recorded failure\n        assert_eq!(state.failed_items.len(), 1);\n    }\n\n    #[tokio::test]\n    async fn test_sync_entry_hybrid_mode_remote_failure() {\n        let ctx = TenantContext::default();\n        let deployment_config = DeploymentConfig {\n            mode: \"hybrid\".to_string(),\n            remote_url: Some(\"http://test\".to_string()),\n            ..Default::default()\n        };\n\n        let sync_manager = SyncManager {\n            memory_manager: create_memory_manager_with_mock_providers().await,\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: Some(Arc::new(MockGovernanceClient::with_failure())),\n            deployment_config,\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            lock_provider: None,\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let entry = KnowledgeEntry {\n            path: \"test.md\".to_string(),\n            content: \"test content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n            summaries: HashMap::new(),\n        };\n\n        let mut state = SyncState::default();\n        let result = sync_manager.sync_entry(ctx, &entry, &mut state).await;\n        // Should fail due to remote governance failure\n        assert!(result.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_sync_entry_local_mode_no_remote_validation() {\n        let ctx = TenantContext::default();\n        let deployment_config = DeploymentConfig {\n            mode: \"local\".to_string(),\n            remote_url: None,\n            ..Default::default()\n        };\n\n        let sync_manager = SyncManager {\n            memory_manager: create_memory_manager_with_mock_providers().await,\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None, // No client in local mode\n            deployment_config,\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            lock_provider: None,\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let entry = KnowledgeEntry {\n            path: \"test.md\".to_string(),\n            content: \"test content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n            summaries: HashMap::new(),\n        };\n\n        let mut state = SyncState::default();\n        let result = sync_manager.sync_entry(ctx, &entry, &mut state).await;\n        // Should succeed using only local governance engine\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_acquire_sync_lock_no_provider() {\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            lock_provider: None,\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let tenant_id = TenantId::new(\"test-tenant\".to_string()).unwrap();\n        let result = sync_manager\n            .acquire_sync_lock(&tenant_id, \"batch_sync\")\n            .await;\n\n        assert!(result.is_ok());\n        assert!(result.unwrap().is_none());\n    }\n\n    #[tokio::test]\n    async fn test_release_sync_lock_none() {\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            lock_provider: None,\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let result = sync_manager.release_sync_lock(None).await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_run_sync_cycle_without_lock_provider() {\n        let ctx = TenantContext::default();\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            lock_provider: None,\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let result = sync_manager.run_sync_cycle(ctx, 60).await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_run_sync_cycle_hybrid_disabled_skips_locking() {\n        let ctx = TenantContext::default();\n        let mut config = DeploymentConfig::default();\n        config.mode = \"hybrid\".to_string();\n        config.sync_enabled = false;\n\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: config,\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            lock_provider: None,\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let result = sync_manager.run_sync_cycle(ctx, 60).await;\n        assert!(result.is_ok());\n    }\n}\n","traces":[{"line":50,"address":[],"length":0,"stats":{"Line":31}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":114}},{"line":89,"address":[],"length":0,"stats":{"Line":114}},{"line":90,"address":[],"length":0,"stats":{"Line":161}},{"line":91,"address":[],"length":0,"stats":{"Line":47}},{"line":95,"address":[],"length":0,"stats":{"Line":30}},{"line":96,"address":[],"length":0,"stats":{"Line":20}},{"line":97,"address":[],"length":0,"stats":{"Line":10}},{"line":98,"address":[],"length":0,"stats":{"Line":10}},{"line":99,"address":[],"length":0,"stats":{"Line":10}},{"line":101,"address":[],"length":0,"stats":{"Line":20}},{"line":102,"address":[],"length":0,"stats":{"Line":50}},{"line":103,"address":[],"length":0,"stats":{"Line":10}},{"line":106,"address":[],"length":0,"stats":{"Line":42}},{"line":107,"address":[],"length":0,"stats":{"Line":42}},{"line":108,"address":[],"length":0,"stats":{"Line":84}},{"line":111,"address":[],"length":0,"stats":{"Line":1}},{"line":116,"address":[],"length":0,"stats":{"Line":1}},{"line":117,"address":[],"length":0,"stats":{"Line":1}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":14}},{"line":131,"address":[],"length":0,"stats":{"Line":7}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":7}},{"line":138,"address":[],"length":0,"stats":{"Line":4}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":2}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":14}},{"line":256,"address":[],"length":0,"stats":{"Line":12}},{"line":257,"address":[],"length":0,"stats":{"Line":18}},{"line":258,"address":[],"length":0,"stats":{"Line":24}},{"line":259,"address":[],"length":0,"stats":{"Line":6}},{"line":261,"address":[],"length":0,"stats":{"Line":6}},{"line":263,"address":[],"length":0,"stats":{"Line":18}},{"line":265,"address":[],"length":0,"stats":{"Line":6}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":0}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":272,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":274,"address":[],"length":0,"stats":{"Line":0}},{"line":276,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":12}},{"line":283,"address":[],"length":0,"stats":{"Line":12}},{"line":284,"address":[],"length":0,"stats":{"Line":12}},{"line":285,"address":[],"length":0,"stats":{"Line":30}},{"line":287,"address":[],"length":0,"stats":{"Line":6}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":6}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":24}},{"line":319,"address":[],"length":0,"stats":{"Line":30}},{"line":320,"address":[],"length":0,"stats":{"Line":6}},{"line":321,"address":[],"length":0,"stats":{"Line":1}},{"line":322,"address":[],"length":0,"stats":{"Line":1}},{"line":323,"address":[],"length":0,"stats":{"Line":4}},{"line":324,"address":[],"length":0,"stats":{"Line":1}},{"line":325,"address":[],"length":0,"stats":{"Line":4}},{"line":327,"address":[],"length":0,"stats":{"Line":3}},{"line":328,"address":[],"length":0,"stats":{"Line":5}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":334,"address":[],"length":0,"stats":{"Line":1}},{"line":338,"address":[],"length":0,"stats":{"Line":6}},{"line":341,"address":[],"length":0,"stats":{"Line":16}},{"line":342,"address":[],"length":0,"stats":{"Line":16}},{"line":343,"address":[],"length":0,"stats":{"Line":1}},{"line":344,"address":[],"length":0,"stats":{"Line":1}},{"line":347,"address":[],"length":0,"stats":{"Line":14}},{"line":348,"address":[],"length":0,"stats":{"Line":28}},{"line":349,"address":[],"length":0,"stats":{"Line":28}},{"line":350,"address":[],"length":0,"stats":{"Line":7}},{"line":351,"address":[],"length":0,"stats":{"Line":7}},{"line":354,"address":[],"length":0,"stats":{"Line":4}},{"line":355,"address":[],"length":0,"stats":{"Line":4}},{"line":356,"address":[],"length":0,"stats":{"Line":5}},{"line":357,"address":[],"length":0,"stats":{"Line":2}},{"line":358,"address":[],"length":0,"stats":{"Line":5}},{"line":359,"address":[],"length":0,"stats":{"Line":2}},{"line":360,"address":[],"length":0,"stats":{"Line":2}},{"line":361,"address":[],"length":0,"stats":{"Line":1}},{"line":362,"address":[],"length":0,"stats":{"Line":1}},{"line":363,"address":[],"length":0,"stats":{"Line":0}},{"line":364,"address":[],"length":0,"stats":{"Line":0}},{"line":366,"address":[],"length":0,"stats":{"Line":1}},{"line":367,"address":[],"length":0,"stats":{"Line":0}},{"line":370,"address":[],"length":0,"stats":{"Line":1}},{"line":372,"address":[],"length":0,"stats":{"Line":1}},{"line":373,"address":[],"length":0,"stats":{"Line":0}},{"line":376,"address":[],"length":0,"stats":{"Line":1}},{"line":380,"address":[],"length":0,"stats":{"Line":2}},{"line":385,"address":[],"length":0,"stats":{"Line":2}},{"line":386,"address":[],"length":0,"stats":{"Line":8}},{"line":387,"address":[],"length":0,"stats":{"Line":6}},{"line":389,"address":[],"length":0,"stats":{"Line":6}},{"line":390,"address":[],"length":0,"stats":{"Line":6}},{"line":392,"address":[],"length":0,"stats":{"Line":4}},{"line":393,"address":[],"length":0,"stats":{"Line":2}},{"line":395,"address":[],"length":0,"stats":{"Line":3}},{"line":397,"address":[],"length":0,"stats":{"Line":4}},{"line":399,"address":[],"length":0,"stats":{"Line":10}},{"line":401,"address":[],"length":0,"stats":{"Line":0}},{"line":402,"address":[],"length":0,"stats":{"Line":0}},{"line":403,"address":[],"length":0,"stats":{"Line":0}},{"line":404,"address":[],"length":0,"stats":{"Line":0}},{"line":406,"address":[],"length":0,"stats":{"Line":1}},{"line":407,"address":[],"length":0,"stats":{"Line":5}},{"line":409,"address":[],"length":0,"stats":{"Line":1}},{"line":410,"address":[],"length":0,"stats":{"Line":1}},{"line":411,"address":[],"length":0,"stats":{"Line":1}},{"line":412,"address":[],"length":0,"stats":{"Line":1}},{"line":413,"address":[],"length":0,"stats":{"Line":3}},{"line":414,"address":[],"length":0,"stats":{"Line":3}},{"line":415,"address":[],"length":0,"stats":{"Line":2}},{"line":416,"address":[],"length":0,"stats":{"Line":1}},{"line":419,"address":[],"length":0,"stats":{"Line":1}},{"line":420,"address":[],"length":0,"stats":{"Line":1}},{"line":425,"address":[],"length":0,"stats":{"Line":4}},{"line":426,"address":[],"length":0,"stats":{"Line":4}},{"line":427,"address":[],"length":0,"stats":{"Line":2}},{"line":428,"address":[],"length":0,"stats":{"Line":2}},{"line":429,"address":[],"length":0,"stats":{"Line":8}},{"line":430,"address":[],"length":0,"stats":{"Line":2}},{"line":433,"address":[],"length":0,"stats":{"Line":6}},{"line":434,"address":[],"length":0,"stats":{"Line":9}},{"line":438,"address":[],"length":0,"stats":{"Line":16}},{"line":509,"address":[],"length":0,"stats":{"Line":0}},{"line":516,"address":[],"length":0,"stats":{"Line":4}},{"line":522,"address":[],"length":0,"stats":{"Line":8}},{"line":528,"address":[],"length":0,"stats":{"Line":32}},{"line":529,"address":[],"length":0,"stats":{"Line":16}},{"line":531,"address":[],"length":0,"stats":{"Line":32}},{"line":532,"address":[],"length":0,"stats":{"Line":8}},{"line":533,"address":[],"length":0,"stats":{"Line":8}},{"line":534,"address":[],"length":0,"stats":{"Line":8}},{"line":535,"address":[],"length":0,"stats":{"Line":8}},{"line":537,"address":[],"length":0,"stats":{"Line":224}},{"line":538,"address":[],"length":0,"stats":{"Line":64}},{"line":539,"address":[],"length":0,"stats":{"Line":0}},{"line":540,"address":[],"length":0,"stats":{"Line":0}},{"line":541,"address":[],"length":0,"stats":{"Line":0}},{"line":542,"address":[],"length":0,"stats":{"Line":0}},{"line":543,"address":[],"length":0,"stats":{"Line":0}},{"line":544,"address":[],"length":0,"stats":{"Line":0}},{"line":546,"address":[],"length":0,"stats":{"Line":0}},{"line":550,"address":[],"length":0,"stats":{"Line":40}},{"line":551,"address":[],"length":0,"stats":{"Line":30}},{"line":552,"address":[],"length":0,"stats":{"Line":3}},{"line":553,"address":[],"length":0,"stats":{"Line":3}},{"line":554,"address":[],"length":0,"stats":{"Line":3}},{"line":555,"address":[],"length":0,"stats":{"Line":1}},{"line":556,"address":[],"length":0,"stats":{"Line":1}},{"line":562,"address":[],"length":0,"stats":{"Line":8}},{"line":563,"address":[],"length":0,"stats":{"Line":16}},{"line":564,"address":[],"length":0,"stats":{"Line":24}},{"line":565,"address":[],"length":0,"stats":{"Line":8}},{"line":566,"address":[],"length":0,"stats":{"Line":16}},{"line":567,"address":[],"length":0,"stats":{"Line":8}},{"line":569,"address":[],"length":0,"stats":{"Line":8}},{"line":570,"address":[],"length":0,"stats":{"Line":8}},{"line":571,"address":[],"length":0,"stats":{"Line":8}},{"line":573,"address":[],"length":0,"stats":{"Line":16}},{"line":574,"address":[],"length":0,"stats":{"Line":16}},{"line":575,"address":[],"length":0,"stats":{"Line":8}},{"line":576,"address":[],"length":0,"stats":{"Line":8}},{"line":578,"address":[],"length":0,"stats":{"Line":40}},{"line":580,"address":[],"length":0,"stats":{"Line":8}},{"line":583,"address":[],"length":0,"stats":{"Line":6}},{"line":588,"address":[],"length":0,"stats":{"Line":6}},{"line":589,"address":[],"length":0,"stats":{"Line":0}},{"line":592,"address":[],"length":0,"stats":{"Line":24}},{"line":594,"address":[],"length":0,"stats":{"Line":18}},{"line":595,"address":[],"length":0,"stats":{"Line":8}},{"line":596,"address":[],"length":0,"stats":{"Line":3}},{"line":597,"address":[],"length":0,"stats":{"Line":1}},{"line":598,"address":[],"length":0,"stats":{"Line":0}},{"line":599,"address":[],"length":0,"stats":{"Line":0}},{"line":600,"address":[],"length":0,"stats":{"Line":0}},{"line":604,"address":[],"length":0,"stats":{"Line":1}},{"line":605,"address":[],"length":0,"stats":{"Line":2}},{"line":606,"address":[],"length":0,"stats":{"Line":1}},{"line":611,"address":[],"length":0,"stats":{"Line":7}},{"line":612,"address":[],"length":0,"stats":{"Line":6}},{"line":613,"address":[],"length":0,"stats":{"Line":4}},{"line":614,"address":[],"length":0,"stats":{"Line":2}},{"line":615,"address":[],"length":0,"stats":{"Line":2}},{"line":616,"address":[],"length":0,"stats":{"Line":2}},{"line":617,"address":[],"length":0,"stats":{"Line":2}},{"line":621,"address":[],"length":0,"stats":{"Line":3}},{"line":624,"address":[],"length":0,"stats":{"Line":0}},{"line":627,"address":[],"length":0,"stats":{"Line":1}},{"line":633,"address":[],"length":0,"stats":{"Line":4}},{"line":635,"address":[],"length":0,"stats":{"Line":1}},{"line":636,"address":[],"length":0,"stats":{"Line":1}},{"line":637,"address":[],"length":0,"stats":{"Line":3}},{"line":639,"address":[],"length":0,"stats":{"Line":1}},{"line":640,"address":[],"length":0,"stats":{"Line":0}},{"line":646,"address":[],"length":0,"stats":{"Line":2}},{"line":647,"address":[],"length":0,"stats":{"Line":2}},{"line":648,"address":[],"length":0,"stats":{"Line":1}},{"line":649,"address":[],"length":0,"stats":{"Line":1}},{"line":650,"address":[],"length":0,"stats":{"Line":4}},{"line":651,"address":[],"length":0,"stats":{"Line":1}},{"line":654,"address":[],"length":0,"stats":{"Line":7}},{"line":659,"address":[],"length":0,"stats":{"Line":28}},{"line":661,"address":[],"length":0,"stats":{"Line":23}},{"line":662,"address":[],"length":0,"stats":{"Line":8}},{"line":663,"address":[],"length":0,"stats":{"Line":3}},{"line":664,"address":[],"length":0,"stats":{"Line":1}},{"line":665,"address":[],"length":0,"stats":{"Line":12}},{"line":666,"address":[],"length":0,"stats":{"Line":8}},{"line":667,"address":[],"length":0,"stats":{"Line":4}},{"line":668,"address":[],"length":0,"stats":{"Line":8}},{"line":670,"address":[],"length":0,"stats":{"Line":8}},{"line":671,"address":[],"length":0,"stats":{"Line":12}},{"line":672,"address":[],"length":0,"stats":{"Line":8}},{"line":673,"address":[],"length":0,"stats":{"Line":16}},{"line":674,"address":[],"length":0,"stats":{"Line":4}},{"line":676,"address":[],"length":0,"stats":{"Line":24}},{"line":677,"address":[],"length":0,"stats":{"Line":4}},{"line":681,"address":[],"length":0,"stats":{"Line":1}},{"line":682,"address":[],"length":0,"stats":{"Line":1}},{"line":684,"address":[],"length":0,"stats":{"Line":4}},{"line":685,"address":[],"length":0,"stats":{"Line":1}},{"line":686,"address":[],"length":0,"stats":{"Line":1}},{"line":687,"address":[],"length":0,"stats":{"Line":1}},{"line":688,"address":[],"length":0,"stats":{"Line":1}},{"line":690,"address":[],"length":0,"stats":{"Line":8}},{"line":691,"address":[],"length":0,"stats":{"Line":8}},{"line":692,"address":[],"length":0,"stats":{"Line":16}},{"line":693,"address":[],"length":0,"stats":{"Line":4}},{"line":695,"address":[],"length":0,"stats":{"Line":3}},{"line":696,"address":[],"length":0,"stats":{"Line":3}},{"line":697,"address":[],"length":0,"stats":{"Line":3}},{"line":698,"address":[],"length":0,"stats":{"Line":1}},{"line":701,"address":[],"length":0,"stats":{"Line":1}},{"line":702,"address":[],"length":0,"stats":{"Line":1}},{"line":704,"address":[],"length":0,"stats":{"Line":1}},{"line":705,"address":[],"length":0,"stats":{"Line":3}},{"line":707,"address":[],"length":0,"stats":{"Line":3}},{"line":708,"address":[],"length":0,"stats":{"Line":4}},{"line":709,"address":[],"length":0,"stats":{"Line":1}},{"line":710,"address":[],"length":0,"stats":{"Line":1}},{"line":711,"address":[],"length":0,"stats":{"Line":1}},{"line":712,"address":[],"length":0,"stats":{"Line":1}},{"line":714,"address":[],"length":0,"stats":{"Line":8}},{"line":715,"address":[],"length":0,"stats":{"Line":8}},{"line":716,"address":[],"length":0,"stats":{"Line":16}},{"line":717,"address":[],"length":0,"stats":{"Line":4}},{"line":719,"address":[],"length":0,"stats":{"Line":3}},{"line":722,"address":[],"length":0,"stats":{"Line":2}},{"line":723,"address":[],"length":0,"stats":{"Line":1}},{"line":724,"address":[],"length":0,"stats":{"Line":2}},{"line":726,"address":[],"length":0,"stats":{"Line":2}},{"line":727,"address":[],"length":0,"stats":{"Line":3}},{"line":728,"address":[],"length":0,"stats":{"Line":2}},{"line":729,"address":[],"length":0,"stats":{"Line":4}},{"line":730,"address":[],"length":0,"stats":{"Line":1}},{"line":732,"address":[],"length":0,"stats":{"Line":6}},{"line":734,"address":[],"length":0,"stats":{"Line":1}},{"line":737,"address":[],"length":0,"stats":{"Line":1}},{"line":738,"address":[],"length":0,"stats":{"Line":1}},{"line":741,"address":[],"length":0,"stats":{"Line":2}},{"line":742,"address":[],"length":0,"stats":{"Line":1}},{"line":743,"address":[],"length":0,"stats":{"Line":2}},{"line":745,"address":[],"length":0,"stats":{"Line":2}},{"line":746,"address":[],"length":0,"stats":{"Line":3}},{"line":747,"address":[],"length":0,"stats":{"Line":2}},{"line":748,"address":[],"length":0,"stats":{"Line":4}},{"line":749,"address":[],"length":0,"stats":{"Line":1}},{"line":751,"address":[],"length":0,"stats":{"Line":6}},{"line":753,"address":[],"length":0,"stats":{"Line":1}},{"line":754,"address":[],"length":0,"stats":{"Line":0}},{"line":758,"address":[],"length":0,"stats":{"Line":1}},{"line":761,"address":[],"length":0,"stats":{"Line":1}},{"line":762,"address":[],"length":0,"stats":{"Line":1}},{"line":763,"address":[],"length":0,"stats":{"Line":1}},{"line":764,"address":[],"length":0,"stats":{"Line":1}},{"line":766,"address":[],"length":0,"stats":{"Line":3}},{"line":767,"address":[],"length":0,"stats":{"Line":2}},{"line":768,"address":[],"length":0,"stats":{"Line":2}},{"line":769,"address":[],"length":0,"stats":{"Line":4}},{"line":770,"address":[],"length":0,"stats":{"Line":1}},{"line":772,"address":[],"length":0,"stats":{"Line":3}},{"line":773,"address":[],"length":0,"stats":{"Line":3}},{"line":774,"address":[],"length":0,"stats":{"Line":3}},{"line":776,"address":[],"length":0,"stats":{"Line":3}},{"line":777,"address":[],"length":0,"stats":{"Line":2}},{"line":778,"address":[],"length":0,"stats":{"Line":4}},{"line":779,"address":[],"length":0,"stats":{"Line":1}},{"line":781,"address":[],"length":0,"stats":{"Line":6}},{"line":784,"address":[],"length":0,"stats":{"Line":1}},{"line":785,"address":[],"length":0,"stats":{"Line":0}},{"line":790,"address":[],"length":0,"stats":{"Line":1}},{"line":792,"address":[],"length":0,"stats":{"Line":0}},{"line":793,"address":[],"length":0,"stats":{"Line":0}},{"line":794,"address":[],"length":0,"stats":{"Line":0}},{"line":802,"address":[],"length":0,"stats":{"Line":14}},{"line":803,"address":[],"length":0,"stats":{"Line":14}},{"line":804,"address":[],"length":0,"stats":{"Line":7}},{"line":805,"address":[],"length":0,"stats":{"Line":7}},{"line":806,"address":[],"length":0,"stats":{"Line":28}},{"line":807,"address":[],"length":0,"stats":{"Line":7}},{"line":810,"address":[],"length":0,"stats":{"Line":22}},{"line":811,"address":[],"length":0,"stats":{"Line":44}},{"line":812,"address":[],"length":0,"stats":{"Line":22}},{"line":814,"address":[],"length":0,"stats":{"Line":33}},{"line":815,"address":[],"length":0,"stats":{"Line":39}},{"line":816,"address":[],"length":0,"stats":{"Line":21}},{"line":817,"address":[],"length":0,"stats":{"Line":28}},{"line":819,"address":[],"length":0,"stats":{"Line":14}},{"line":822,"address":[],"length":0,"stats":{"Line":32}},{"line":823,"address":[],"length":0,"stats":{"Line":7}},{"line":824,"address":[],"length":0,"stats":{"Line":0}},{"line":825,"address":[],"length":0,"stats":{"Line":0}},{"line":826,"address":[],"length":0,"stats":{"Line":0}},{"line":831,"address":[],"length":0,"stats":{"Line":32}},{"line":832,"address":[],"length":0,"stats":{"Line":7}},{"line":833,"address":[],"length":0,"stats":{"Line":7}},{"line":836,"address":[],"length":0,"stats":{"Line":14}},{"line":837,"address":[],"length":0,"stats":{"Line":7}},{"line":838,"address":[],"length":0,"stats":{"Line":14}},{"line":840,"address":[],"length":0,"stats":{"Line":14}},{"line":841,"address":[],"length":0,"stats":{"Line":14}},{"line":843,"address":[],"length":0,"stats":{"Line":21}},{"line":844,"address":[],"length":0,"stats":{"Line":14}},{"line":845,"address":[],"length":0,"stats":{"Line":28}},{"line":846,"address":[],"length":0,"stats":{"Line":7}},{"line":847,"address":[],"length":0,"stats":{"Line":17}},{"line":848,"address":[],"length":0,"stats":{"Line":5}},{"line":849,"address":[],"length":0,"stats":{"Line":5}},{"line":850,"address":[],"length":0,"stats":{"Line":5}},{"line":852,"address":[],"length":0,"stats":{"Line":9}},{"line":853,"address":[],"length":0,"stats":{"Line":2}},{"line":854,"address":[],"length":0,"stats":{"Line":2}},{"line":855,"address":[],"length":0,"stats":{"Line":0}},{"line":858,"address":[],"length":0,"stats":{"Line":7}},{"line":859,"address":[],"length":0,"stats":{"Line":5}},{"line":860,"address":[],"length":0,"stats":{"Line":20}},{"line":861,"address":[],"length":0,"stats":{"Line":15}},{"line":863,"address":[],"length":0,"stats":{"Line":10}},{"line":864,"address":[],"length":0,"stats":{"Line":5}},{"line":866,"address":[],"length":0,"stats":{"Line":3}},{"line":867,"address":[],"length":0,"stats":{"Line":3}},{"line":868,"address":[],"length":0,"stats":{"Line":3}},{"line":869,"address":[],"length":0,"stats":{"Line":2}},{"line":870,"address":[],"length":0,"stats":{"Line":1}},{"line":874,"address":[],"length":0,"stats":{"Line":5}},{"line":875,"address":[],"length":0,"stats":{"Line":5}},{"line":877,"address":[],"length":0,"stats":{"Line":0}},{"line":878,"address":[],"length":0,"stats":{"Line":0}},{"line":879,"address":[],"length":0,"stats":{"Line":0}},{"line":880,"address":[],"length":0,"stats":{"Line":0}},{"line":884,"address":[],"length":0,"stats":{"Line":5}},{"line":885,"address":[],"length":0,"stats":{"Line":0}},{"line":886,"address":[],"length":0,"stats":{"Line":0}},{"line":887,"address":[],"length":0,"stats":{"Line":0}},{"line":888,"address":[],"length":0,"stats":{"Line":0}},{"line":889,"address":[],"length":0,"stats":{"Line":0}},{"line":893,"address":[],"length":0,"stats":{"Line":15}},{"line":894,"address":[],"length":0,"stats":{"Line":10}},{"line":895,"address":[],"length":0,"stats":{"Line":10}},{"line":896,"address":[],"length":0,"stats":{"Line":20}},{"line":897,"address":[],"length":0,"stats":{"Line":5}},{"line":899,"address":[],"length":0,"stats":{"Line":1}},{"line":900,"address":[],"length":0,"stats":{"Line":3}},{"line":901,"address":[],"length":0,"stats":{"Line":3}},{"line":902,"address":[],"length":0,"stats":{"Line":1}},{"line":905,"address":[],"length":0,"stats":{"Line":4}},{"line":906,"address":[],"length":0,"stats":{"Line":12}},{"line":907,"address":[],"length":0,"stats":{"Line":12}},{"line":908,"address":[],"length":0,"stats":{"Line":4}},{"line":909,"address":[],"length":0,"stats":{"Line":16}},{"line":910,"address":[],"length":0,"stats":{"Line":5}},{"line":911,"address":[],"length":0,"stats":{"Line":3}},{"line":912,"address":[],"length":0,"stats":{"Line":3}},{"line":913,"address":[],"length":0,"stats":{"Line":3}},{"line":914,"address":[],"length":0,"stats":{"Line":3}},{"line":915,"address":[],"length":0,"stats":{"Line":1}},{"line":919,"address":[],"length":0,"stats":{"Line":0}},{"line":920,"address":[],"length":0,"stats":{"Line":0}},{"line":921,"address":[],"length":0,"stats":{"Line":0}},{"line":922,"address":[],"length":0,"stats":{"Line":0}},{"line":924,"address":[],"length":0,"stats":{"Line":0}},{"line":929,"address":[],"length":0,"stats":{"Line":4}},{"line":930,"address":[],"length":0,"stats":{"Line":4}},{"line":931,"address":[],"length":0,"stats":{"Line":2}},{"line":932,"address":[],"length":0,"stats":{"Line":2}},{"line":933,"address":[],"length":0,"stats":{"Line":2}},{"line":934,"address":[],"length":0,"stats":{"Line":2}},{"line":936,"address":[],"length":0,"stats":{"Line":4}},{"line":937,"address":[],"length":0,"stats":{"Line":0}},{"line":940,"address":[],"length":0,"stats":{"Line":10}},{"line":941,"address":[],"length":0,"stats":{"Line":8}},{"line":942,"address":[],"length":0,"stats":{"Line":16}},{"line":943,"address":[],"length":0,"stats":{"Line":4}},{"line":945,"address":[],"length":0,"stats":{"Line":6}},{"line":946,"address":[],"length":0,"stats":{"Line":6}},{"line":947,"address":[],"length":0,"stats":{"Line":6}},{"line":948,"address":[],"length":0,"stats":{"Line":2}},{"line":949,"address":[],"length":0,"stats":{"Line":2}},{"line":951,"address":[],"length":0,"stats":{"Line":2}},{"line":952,"address":[],"length":0,"stats":{"Line":2}},{"line":956,"address":[],"length":0,"stats":{"Line":2}},{"line":957,"address":[],"length":0,"stats":{"Line":0}},{"line":958,"address":[],"length":0,"stats":{"Line":0}},{"line":959,"address":[],"length":0,"stats":{"Line":0}},{"line":963,"address":[],"length":0,"stats":{"Line":0}},{"line":964,"address":[],"length":0,"stats":{"Line":0}},{"line":965,"address":[],"length":0,"stats":{"Line":0}},{"line":966,"address":[],"length":0,"stats":{"Line":0}},{"line":968,"address":[],"length":0,"stats":{"Line":0}},{"line":977,"address":[],"length":0,"stats":{"Line":11}},{"line":980,"address":[],"length":0,"stats":{"Line":2}},{"line":985,"address":[],"length":0,"stats":{"Line":2}},{"line":986,"address":[],"length":0,"stats":{"Line":2}},{"line":988,"address":[],"length":0,"stats":{"Line":10}},{"line":989,"address":[],"length":0,"stats":{"Line":4}},{"line":992,"address":[],"length":0,"stats":{"Line":19}},{"line":998,"address":[],"length":0,"stats":{"Line":19}},{"line":999,"address":[],"length":0,"stats":{"Line":1}},{"line":1000,"address":[],"length":0,"stats":{"Line":1}},{"line":1003,"address":[],"length":0,"stats":{"Line":54}},{"line":1004,"address":[],"length":0,"stats":{"Line":54}},{"line":1006,"address":[],"length":0,"stats":{"Line":36}},{"line":1007,"address":[],"length":0,"stats":{"Line":90}},{"line":1008,"address":[],"length":0,"stats":{"Line":90}},{"line":1010,"address":[],"length":0,"stats":{"Line":32}},{"line":1011,"address":[],"length":0,"stats":{"Line":10}},{"line":1012,"address":[],"length":0,"stats":{"Line":14}},{"line":1013,"address":[],"length":0,"stats":{"Line":15}},{"line":1014,"address":[],"length":0,"stats":{"Line":5}},{"line":1015,"address":[],"length":0,"stats":{"Line":8}},{"line":1017,"address":[],"length":0,"stats":{"Line":4}},{"line":1018,"address":[],"length":0,"stats":{"Line":2}},{"line":1019,"address":[],"length":0,"stats":{"Line":2}},{"line":1020,"address":[],"length":0,"stats":{"Line":5}},{"line":1021,"address":[],"length":0,"stats":{"Line":2}},{"line":1022,"address":[],"length":0,"stats":{"Line":3}},{"line":1023,"address":[],"length":0,"stats":{"Line":3}},{"line":1024,"address":[],"length":0,"stats":{"Line":2}},{"line":1025,"address":[],"length":0,"stats":{"Line":2}},{"line":1026,"address":[],"length":0,"stats":{"Line":1}},{"line":1028,"address":[],"length":0,"stats":{"Line":1}},{"line":1029,"address":[],"length":0,"stats":{"Line":1}},{"line":1031,"address":[],"length":0,"stats":{"Line":1}},{"line":1033,"address":[],"length":0,"stats":{"Line":1}},{"line":1034,"address":[],"length":0,"stats":{"Line":0}},{"line":1044,"address":[],"length":0,"stats":{"Line":16}},{"line":1045,"address":[],"length":0,"stats":{"Line":60}},{"line":1046,"address":[],"length":0,"stats":{"Line":15}},{"line":1047,"address":[],"length":0,"stats":{"Line":2}},{"line":1048,"address":[],"length":0,"stats":{"Line":2}},{"line":1049,"address":[],"length":0,"stats":{"Line":4}},{"line":1050,"address":[],"length":0,"stats":{"Line":2}},{"line":1051,"address":[],"length":0,"stats":{"Line":6}},{"line":1052,"address":[],"length":0,"stats":{"Line":6}},{"line":1053,"address":[],"length":0,"stats":{"Line":6}},{"line":1054,"address":[],"length":0,"stats":{"Line":2}},{"line":1055,"address":[],"length":0,"stats":{"Line":2}},{"line":1057,"address":[],"length":0,"stats":{"Line":2}},{"line":1059,"address":[],"length":0,"stats":{"Line":0}},{"line":1060,"address":[],"length":0,"stats":{"Line":0}},{"line":1069,"address":[],"length":0,"stats":{"Line":42}},{"line":1070,"address":[],"length":0,"stats":{"Line":28}},{"line":1072,"address":[],"length":0,"stats":{"Line":30}},{"line":1073,"address":[],"length":0,"stats":{"Line":2}},{"line":1075,"address":[],"length":0,"stats":{"Line":0}},{"line":1078,"address":[],"length":0,"stats":{"Line":42}},{"line":1080,"address":[],"length":0,"stats":{"Line":28}},{"line":1081,"address":[],"length":0,"stats":{"Line":42}},{"line":1082,"address":[],"length":0,"stats":{"Line":42}},{"line":1083,"address":[],"length":0,"stats":{"Line":28}},{"line":1084,"address":[],"length":0,"stats":{"Line":14}},{"line":1089,"address":[],"length":0,"stats":{"Line":42}},{"line":1091,"address":[],"length":0,"stats":{"Line":14}},{"line":1094,"address":[],"length":0,"stats":{"Line":42}},{"line":1095,"address":[],"length":0,"stats":{"Line":14}},{"line":1096,"address":[],"length":0,"stats":{"Line":28}},{"line":1097,"address":[],"length":0,"stats":{"Line":182}},{"line":1098,"address":[],"length":0,"stats":{"Line":126}},{"line":1100,"address":[],"length":0,"stats":{"Line":14}},{"line":1103,"address":[],"length":0,"stats":{"Line":0}},{"line":1104,"address":[],"length":0,"stats":{"Line":0}},{"line":1110,"address":[],"length":0,"stats":{"Line":42}},{"line":1111,"address":[],"length":0,"stats":{"Line":70}},{"line":1114,"address":[],"length":0,"stats":{"Line":28}},{"line":1118,"address":[],"length":0,"stats":{"Line":42}},{"line":1119,"address":[],"length":0,"stats":{"Line":14}},{"line":1122,"address":[],"length":0,"stats":{"Line":28}},{"line":1123,"address":[],"length":0,"stats":{"Line":42}},{"line":1124,"address":[],"length":0,"stats":{"Line":14}},{"line":1126,"address":[],"length":0,"stats":{"Line":14}},{"line":1128,"address":[],"length":0,"stats":{"Line":14}},{"line":1129,"address":[],"length":0,"stats":{"Line":14}},{"line":1130,"address":[],"length":0,"stats":{"Line":56}},{"line":1131,"address":[],"length":0,"stats":{"Line":14}},{"line":1132,"address":[],"length":0,"stats":{"Line":14}},{"line":1133,"address":[],"length":0,"stats":{"Line":70}},{"line":1134,"address":[],"length":0,"stats":{"Line":14}},{"line":1135,"address":[],"length":0,"stats":{"Line":14}},{"line":1136,"address":[],"length":0,"stats":{"Line":56}},{"line":1137,"address":[],"length":0,"stats":{"Line":14}},{"line":1138,"address":[],"length":0,"stats":{"Line":14}},{"line":1140,"address":[],"length":0,"stats":{"Line":14}},{"line":1143,"address":[],"length":0,"stats":{"Line":2}},{"line":1144,"address":[],"length":0,"stats":{"Line":8}},{"line":1147,"address":[],"length":0,"stats":{"Line":20}},{"line":1148,"address":[],"length":0,"stats":{"Line":40}},{"line":1153,"address":[],"length":0,"stats":{"Line":80}},{"line":1156,"address":[],"length":0,"stats":{"Line":40}},{"line":1157,"address":[],"length":0,"stats":{"Line":100}},{"line":1158,"address":[],"length":0,"stats":{"Line":100}},{"line":1160,"address":[],"length":0,"stats":{"Line":80}},{"line":1161,"address":[],"length":0,"stats":{"Line":20}},{"line":1162,"address":[],"length":0,"stats":{"Line":0}},{"line":1163,"address":[],"length":0,"stats":{"Line":0}},{"line":1165,"address":[],"length":0,"stats":{"Line":0}},{"line":1166,"address":[],"length":0,"stats":{"Line":0}},{"line":1169,"address":[],"length":0,"stats":{"Line":0}},{"line":1170,"address":[],"length":0,"stats":{"Line":0}},{"line":1171,"address":[],"length":0,"stats":{"Line":0}},{"line":1175,"address":[],"length":0,"stats":{"Line":20}},{"line":1178,"address":[],"length":0,"stats":{"Line":14}},{"line":1179,"address":[],"length":0,"stats":{"Line":28}},{"line":1180,"address":[],"length":0,"stats":{"Line":21}},{"line":1181,"address":[],"length":0,"stats":{"Line":14}},{"line":1183,"address":[],"length":0,"stats":{"Line":21}},{"line":1184,"address":[],"length":0,"stats":{"Line":7}},{"line":1185,"address":[],"length":0,"stats":{"Line":7}},{"line":1186,"address":[],"length":0,"stats":{"Line":11}},{"line":1188,"address":[],"length":0,"stats":{"Line":21}},{"line":1189,"address":[],"length":0,"stats":{"Line":7}},{"line":1190,"address":[],"length":0,"stats":{"Line":1}},{"line":1191,"address":[],"length":0,"stats":{"Line":0}},{"line":1196,"address":[],"length":0,"stats":{"Line":2}},{"line":1197,"address":[],"length":0,"stats":{"Line":2}},{"line":1198,"address":[],"length":0,"stats":{"Line":1}},{"line":1199,"address":[],"length":0,"stats":{"Line":1}},{"line":1200,"address":[],"length":0,"stats":{"Line":4}},{"line":1203,"address":[],"length":0,"stats":{"Line":7}},{"line":1206,"address":[],"length":0,"stats":{"Line":0}},{"line":1211,"address":[],"length":0,"stats":{"Line":0}},{"line":1214,"address":[],"length":0,"stats":{"Line":2}},{"line":1215,"address":[],"length":0,"stats":{"Line":2}},{"line":1216,"address":[],"length":0,"stats":{"Line":2}},{"line":1217,"address":[],"length":0,"stats":{"Line":2}},{"line":1218,"address":[],"length":0,"stats":{"Line":2}},{"line":1219,"address":[],"length":0,"stats":{"Line":1}},{"line":1220,"address":[],"length":0,"stats":{"Line":1}},{"line":1223,"address":[],"length":0,"stats":{"Line":9}},{"line":1224,"address":[],"length":0,"stats":{"Line":24}},{"line":1225,"address":[],"length":0,"stats":{"Line":10}},{"line":1226,"address":[],"length":0,"stats":{"Line":6}},{"line":1227,"address":[],"length":0,"stats":{"Line":9}},{"line":1229,"address":[],"length":0,"stats":{"Line":9}},{"line":1230,"address":[],"length":0,"stats":{"Line":0}},{"line":1231,"address":[],"length":0,"stats":{"Line":0}},{"line":1233,"address":[],"length":0,"stats":{"Line":0}},{"line":1234,"address":[],"length":0,"stats":{"Line":0}},{"line":1236,"address":[],"length":0,"stats":{"Line":3}},{"line":1237,"address":[],"length":0,"stats":{"Line":6}},{"line":1243,"address":[],"length":0,"stats":{"Line":1}},{"line":1244,"address":[],"length":0,"stats":{"Line":0}},{"line":1245,"address":[],"length":0,"stats":{"Line":0}},{"line":1247,"address":[],"length":0,"stats":{"Line":0}},{"line":1251,"address":[],"length":0,"stats":{"Line":1}},{"line":1255,"address":[],"length":0,"stats":{"Line":3}},{"line":1262,"address":[],"length":0,"stats":{"Line":3}},{"line":1263,"address":[],"length":0,"stats":{"Line":12}},{"line":1265,"address":[],"length":0,"stats":{"Line":7}},{"line":1266,"address":[],"length":0,"stats":{"Line":14}},{"line":1267,"address":[],"length":0,"stats":{"Line":20}},{"line":1268,"address":[],"length":0,"stats":{"Line":0}},{"line":1269,"address":[],"length":0,"stats":{"Line":0}},{"line":1272,"address":[],"length":0,"stats":{"Line":14}},{"line":1273,"address":[],"length":0,"stats":{"Line":2}},{"line":1274,"address":[],"length":0,"stats":{"Line":2}},{"line":1275,"address":[],"length":0,"stats":{"Line":2}}],"covered":486,"coverable":609},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","error.rs"],"content":"use thiserror::Error;\n\n#[derive(Debug, Error)]\npub enum SyncError {\n    #[error(\"Governance violation: {0}\")]\n    GovernanceBlock(String),\n    #[error(\"Knowledge repository error: {0}\")]\n    Repository(#[from] knowledge::repository::RepositoryError),\n    #[error(\"Memory manager error: {0}\")]\n    Memory(#[from] memory::error::MemoryError),\n    #[error(\"Serialization error: {0}\")]\n    Serialization(#[from] serde_json::Error),\n    #[error(\"IO error: {0}\")]\n    Io(#[from] std::io::Error),\n    #[error(\"Conflict detection failed: {0}\")]\n    ConflictDetection(String),\n    #[error(\"State persistence failed: {0}\")]\n    Persistence(String),\n    #[error(\"Internal error: {0}\")]\n    Internal(String),\n    #[error(\"Storage error: {0}\")]\n    Storage(#[from] errors::StorageError),\n    #[error(\"Distributed lock error: {0}\")]\n    DistributedLock(#[from] distributed_lock::LockError),\n    #[error(\"Other error: {0}\")]\n    Other(String),\n}\n\nimpl From<Box<dyn std::error::Error + Send + Sync>> for SyncError {\n    fn from(err: Box<dyn std::error::Error + Send + Sync>) -> Self {\n        SyncError::Other(err.to_string())\n    }\n}\n\npub type Result<T> = std::result::Result<T, SyncError>;\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_sync_error_from_boxed_error() {\n        let boxed_err: Box<dyn std::error::Error + Send + Sync> =\n            Box::new(std::io::Error::other(\"test error\"));\n        let sync_err: SyncError = boxed_err.into();\n\n        match sync_err {\n            SyncError::Other(msg) => assert!(msg.contains(\"test error\")),\n            _ => panic!(\"Expected SyncError::Other\"),\n        }\n    }\n\n    #[test]\n    fn test_sync_error_display() {\n        let errors = vec![\n            (\n                SyncError::GovernanceBlock(\"policy violated\".to_string()),\n                \"Governance violation: policy violated\",\n            ),\n            (\n                SyncError::ConflictDetection(\"hash mismatch\".to_string()),\n                \"Conflict detection failed: hash mismatch\",\n            ),\n            (\n                SyncError::Persistence(\"disk full\".to_string()),\n                \"State persistence failed: disk full\",\n            ),\n            (\n                SyncError::Internal(\"unexpected\".to_string()),\n                \"Internal error: unexpected\",\n            ),\n            (\n                SyncError::Other(\"unknown\".to_string()),\n                \"Other error: unknown\",\n            ),\n        ];\n\n        for (error, expected) in errors {\n            assert_eq!(error.to_string(), expected);\n        }\n    }\n}\n","traces":[{"line":30,"address":[],"length":0,"stats":{"Line":1}},{"line":31,"address":[],"length":0,"stats":{"Line":1}}],"covered":2,"coverable":2},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","events.rs"],"content":"use mk_core::types::{MemoryLayer, SummaryDepth};\nuse serde::{Deserialize, Serialize};\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub enum SummarySyncEvent {\n    Created(SummaryCreated),\n    Updated(SummaryUpdated),\n    Invalidated(SummaryInvalidated),\n    Deleted(SummaryDeleted),\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct SummaryCreated {\n    pub entry_id: String,\n    pub layer: MemoryLayer,\n    pub depth: SummaryDepth,\n    pub content_hash: String,\n    pub token_count: u32,\n    pub created_at: i64,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct SummaryUpdated {\n    pub entry_id: String,\n    pub layer: MemoryLayer,\n    pub depth: SummaryDepth,\n    pub previous_hash: String,\n    pub new_hash: String,\n    pub token_count: u32,\n    pub updated_at: i64,\n    pub reason: SummaryUpdateReason,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub enum SummaryUpdateReason {\n    SourceContentChanged,\n    ConfigurationChanged,\n    ManualRefresh,\n    ScheduledUpdate,\n    PersonalizationContextChanged,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct SummaryInvalidated {\n    pub entry_id: String,\n    pub layer: MemoryLayer,\n    pub depths: Vec<SummaryDepth>,\n    pub reason: InvalidationReason,\n    pub invalidated_at: i64,\n    pub source_content_hash: Option<String>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub enum InvalidationReason {\n    SourceContentChanged {\n        previous_hash: String,\n        new_hash: String,\n    },\n    SourceDeleted,\n    ConfigurationChanged,\n    ManualInvalidation,\n    StaleThresholdExceeded {\n        age_seconds: u64,\n    },\n    ParentLayerChanged {\n        parent_layer: MemoryLayer,\n    },\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct SummaryDeleted {\n    pub entry_id: String,\n    pub layer: MemoryLayer,\n    pub depths: Vec<SummaryDepth>,\n    pub deleted_at: i64,\n    pub reason: DeletionReason,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub enum DeletionReason {\n    SourceDeleted,\n    LayerPruned,\n    ManualDeletion,\n    TenantCleanup,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct HindsightSyncEvent {\n    pub event_type: HindsightEventType,\n    pub tenant_id: String,\n    pub timestamp: i64,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub enum HindsightEventType {\n    ErrorSignatureCreated {\n        signature_id: String,\n        error_type: String,\n    },\n    ResolutionRecorded {\n        resolution_id: String,\n        error_signature_id: String,\n        success: bool,\n    },\n    HindsightNoteCreated {\n        note_id: String,\n        error_signature_id: String,\n    },\n    HindsightNoteUpdated {\n        note_id: String,\n        previous_hash: String,\n        new_hash: String,\n    },\n    ResolutionPromoted {\n        resolution_id: String,\n        from_layer: MemoryLayer,\n        to_layer: MemoryLayer,\n    },\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_summary_created_serialization() {\n        let event = SummarySyncEvent::Created(SummaryCreated {\n            entry_id: \"entry-123\".to_string(),\n            layer: MemoryLayer::Project,\n            depth: SummaryDepth::Sentence,\n            content_hash: \"abc123\".to_string(),\n            token_count: 50,\n            created_at: 1704067200,\n        });\n\n        let json = serde_json::to_string(&event).unwrap();\n        let deserialized: SummarySyncEvent = serde_json::from_str(&json).unwrap();\n        assert_eq!(event, deserialized);\n    }\n\n    #[test]\n    fn test_summary_updated_serialization() {\n        let event = SummarySyncEvent::Updated(SummaryUpdated {\n            entry_id: \"entry-123\".to_string(),\n            layer: MemoryLayer::Team,\n            depth: SummaryDepth::Paragraph,\n            previous_hash: \"old123\".to_string(),\n            new_hash: \"new456\".to_string(),\n            token_count: 200,\n            updated_at: 1704067200,\n            reason: SummaryUpdateReason::SourceContentChanged,\n        });\n\n        let json = serde_json::to_string(&event).unwrap();\n        let deserialized: SummarySyncEvent = serde_json::from_str(&json).unwrap();\n        assert_eq!(event, deserialized);\n    }\n\n    #[test]\n    fn test_summary_invalidated_serialization() {\n        let event = SummarySyncEvent::Invalidated(SummaryInvalidated {\n            entry_id: \"entry-123\".to_string(),\n            layer: MemoryLayer::Session,\n            depths: vec![SummaryDepth::Sentence, SummaryDepth::Paragraph],\n            reason: InvalidationReason::SourceContentChanged {\n                previous_hash: \"old\".to_string(),\n                new_hash: \"new\".to_string(),\n            },\n            invalidated_at: 1704067200,\n            source_content_hash: Some(\"content-hash\".to_string()),\n        });\n\n        let json = serde_json::to_string(&event).unwrap();\n        let deserialized: SummarySyncEvent = serde_json::from_str(&json).unwrap();\n        assert_eq!(event, deserialized);\n    }\n\n    #[test]\n    fn test_summary_deleted_serialization() {\n        let event = SummarySyncEvent::Deleted(SummaryDeleted {\n            entry_id: \"entry-123\".to_string(),\n            layer: MemoryLayer::User,\n            depths: vec![SummaryDepth::Detailed],\n            deleted_at: 1704067200,\n            reason: DeletionReason::SourceDeleted,\n        });\n\n        let json = serde_json::to_string(&event).unwrap();\n        let deserialized: SummarySyncEvent = serde_json::from_str(&json).unwrap();\n        assert_eq!(event, deserialized);\n    }\n\n    #[test]\n    fn test_invalidation_reason_variants() {\n        let reasons = vec![\n            InvalidationReason::SourceContentChanged {\n                previous_hash: \"old\".to_string(),\n                new_hash: \"new\".to_string(),\n            },\n            InvalidationReason::SourceDeleted,\n            InvalidationReason::ConfigurationChanged,\n            InvalidationReason::ManualInvalidation,\n            InvalidationReason::StaleThresholdExceeded { age_seconds: 3600 },\n            InvalidationReason::ParentLayerChanged {\n                parent_layer: MemoryLayer::Org,\n            },\n        ];\n\n        for reason in reasons {\n            let json = serde_json::to_string(&reason).unwrap();\n            let deserialized: InvalidationReason = serde_json::from_str(&json).unwrap();\n            assert_eq!(reason, deserialized);\n        }\n    }\n\n    #[test]\n    fn test_summary_update_reason_variants() {\n        let reasons = vec![\n            SummaryUpdateReason::SourceContentChanged,\n            SummaryUpdateReason::ConfigurationChanged,\n            SummaryUpdateReason::ManualRefresh,\n            SummaryUpdateReason::ScheduledUpdate,\n            SummaryUpdateReason::PersonalizationContextChanged,\n        ];\n\n        for reason in reasons {\n            let json = serde_json::to_string(&reason).unwrap();\n            let deserialized: SummaryUpdateReason = serde_json::from_str(&json).unwrap();\n            assert_eq!(reason, deserialized);\n        }\n    }\n\n    #[test]\n    fn test_deletion_reason_variants() {\n        let reasons = vec![\n            DeletionReason::SourceDeleted,\n            DeletionReason::LayerPruned,\n            DeletionReason::ManualDeletion,\n            DeletionReason::TenantCleanup,\n        ];\n\n        for reason in reasons {\n            let json = serde_json::to_string(&reason).unwrap();\n            let deserialized: DeletionReason = serde_json::from_str(&json).unwrap();\n            assert_eq!(reason, deserialized);\n        }\n    }\n\n    #[test]\n    fn test_hindsight_sync_event_error_signature_created() {\n        let event = HindsightSyncEvent {\n            event_type: HindsightEventType::ErrorSignatureCreated {\n                signature_id: \"sig-123\".to_string(),\n                error_type: \"NullPointerException\".to_string(),\n            },\n            tenant_id: \"tenant-1\".to_string(),\n            timestamp: 1704067200,\n        };\n\n        let json = serde_json::to_string(&event).unwrap();\n        let deserialized: HindsightSyncEvent = serde_json::from_str(&json).unwrap();\n        assert_eq!(event, deserialized);\n    }\n\n    #[test]\n    fn test_hindsight_sync_event_resolution_recorded() {\n        let event = HindsightSyncEvent {\n            event_type: HindsightEventType::ResolutionRecorded {\n                resolution_id: \"res-456\".to_string(),\n                error_signature_id: \"sig-123\".to_string(),\n                success: true,\n            },\n            tenant_id: \"tenant-1\".to_string(),\n            timestamp: 1704067200,\n        };\n\n        let json = serde_json::to_string(&event).unwrap();\n        let deserialized: HindsightSyncEvent = serde_json::from_str(&json).unwrap();\n        assert_eq!(event, deserialized);\n    }\n\n    #[test]\n    fn test_hindsight_sync_event_note_created() {\n        let event = HindsightSyncEvent {\n            event_type: HindsightEventType::HindsightNoteCreated {\n                note_id: \"note-789\".to_string(),\n                error_signature_id: \"sig-123\".to_string(),\n            },\n            tenant_id: \"tenant-1\".to_string(),\n            timestamp: 1704067200,\n        };\n\n        let json = serde_json::to_string(&event).unwrap();\n        let deserialized: HindsightSyncEvent = serde_json::from_str(&json).unwrap();\n        assert_eq!(event, deserialized);\n    }\n\n    #[test]\n    fn test_hindsight_sync_event_resolution_promoted() {\n        let event = HindsightSyncEvent {\n            event_type: HindsightEventType::ResolutionPromoted {\n                resolution_id: \"res-456\".to_string(),\n                from_layer: MemoryLayer::User,\n                to_layer: MemoryLayer::Team,\n            },\n            tenant_id: \"tenant-1\".to_string(),\n            timestamp: 1704067200,\n        };\n\n        let json = serde_json::to_string(&event).unwrap();\n        let deserialized: HindsightSyncEvent = serde_json::from_str(&json).unwrap();\n        assert_eq!(event, deserialized);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","lib.rs"],"content":"//! # Sync Bridge\n//!\n//! Pointer-based synchronization between memory and knowledge.\n\npub mod bridge;\npub mod error;\npub mod events;\npub mod pointer;\npub mod state;\npub mod state_persister;\npub mod summary_sync;\n\n#[cfg(test)]\nmod proptests;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","pointer.rs"],"content":"use mk_core::types::{KnowledgeLayer, KnowledgeType, MemoryLayer, SummaryDepth};\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct KnowledgePointer {\n    pub source_type: KnowledgeType,\n    pub source_id: String,\n    pub content_hash: String,\n    pub synced_at: i64,\n    pub source_layer: KnowledgeLayer,\n    pub is_orphaned: bool,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct SummaryPointer {\n    pub entry_id: String,\n    pub layer: MemoryLayer,\n    pub depth: SummaryDepth,\n    pub content_hash: String,\n    pub source_content_hash: String,\n    pub token_count: u32,\n    pub synced_at: i64,\n    pub is_stale: bool,\n    pub personalized: bool,\n    pub personalization_context: Option<String>,\n}\n\nimpl SummaryPointer {\n    pub fn new(\n        entry_id: String,\n        layer: MemoryLayer,\n        depth: SummaryDepth,\n        content_hash: String,\n        source_content_hash: String,\n        token_count: u32,\n    ) -> Self {\n        Self {\n            entry_id,\n            layer,\n            depth,\n            content_hash,\n            source_content_hash,\n            token_count,\n            synced_at: chrono::Utc::now().timestamp(),\n            is_stale: false,\n            personalized: false,\n            personalization_context: None,\n        }\n    }\n\n    pub fn mark_stale(&mut self) {\n        self.is_stale = true;\n    }\n\n    pub fn needs_update(&self, current_source_hash: &str) -> bool {\n        self.is_stale || self.source_content_hash != current_source_hash\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Default)]\n#[serde(rename_all = \"camelCase\")]\npub struct SummaryPointerState {\n    pub pointers: HashMap<String, HashMap<SummaryDepth, SummaryPointer>>,\n    pub last_sync_at: Option<i64>,\n    pub total_summaries: u64,\n    pub stale_count: u64,\n}\n\nimpl SummaryPointerState {\n    pub fn get_pointer(&self, entry_id: &str, depth: SummaryDepth) -> Option<&SummaryPointer> {\n        self.pointers.get(entry_id).and_then(|m| m.get(&depth))\n    }\n\n    pub fn set_pointer(&mut self, pointer: SummaryPointer) {\n        let entry = self.pointers.entry(pointer.entry_id.clone()).or_default();\n        if !entry.contains_key(&pointer.depth) {\n            self.total_summaries += 1;\n        }\n        entry.insert(pointer.depth, pointer);\n    }\n\n    pub fn remove_pointer(\n        &mut self,\n        entry_id: &str,\n        depth: SummaryDepth,\n    ) -> Option<SummaryPointer> {\n        if let Some(entry) = self.pointers.get_mut(entry_id) {\n            if let Some(ptr) = entry.remove(&depth) {\n                self.total_summaries = self.total_summaries.saturating_sub(1);\n                if ptr.is_stale {\n                    self.stale_count = self.stale_count.saturating_sub(1);\n                }\n                if entry.is_empty() {\n                    self.pointers.remove(entry_id);\n                }\n                return Some(ptr);\n            }\n        }\n        None\n    }\n\n    pub fn remove_all_for_entry(&mut self, entry_id: &str) -> Vec<SummaryPointer> {\n        if let Some(entry) = self.pointers.remove(entry_id) {\n            let removed: Vec<_> = entry.into_values().collect();\n            for ptr in &removed {\n                self.total_summaries = self.total_summaries.saturating_sub(1);\n                if ptr.is_stale {\n                    self.stale_count = self.stale_count.saturating_sub(1);\n                }\n            }\n            removed\n        } else {\n            Vec::new()\n        }\n    }\n\n    pub fn mark_stale(&mut self, entry_id: &str, depth: SummaryDepth) -> bool {\n        if let Some(ptr) = self\n            .pointers\n            .get_mut(entry_id)\n            .and_then(|m| m.get_mut(&depth))\n        {\n            if !ptr.is_stale {\n                ptr.is_stale = true;\n                self.stale_count += 1;\n            }\n            true\n        } else {\n            false\n        }\n    }\n\n    pub fn mark_all_stale_for_entry(&mut self, entry_id: &str) -> u32 {\n        let mut count = 0;\n        if let Some(entry) = self.pointers.get_mut(entry_id) {\n            for ptr in entry.values_mut() {\n                if !ptr.is_stale {\n                    ptr.is_stale = true;\n                    self.stale_count += 1;\n                    count += 1;\n                }\n            }\n        }\n        count\n    }\n\n    pub fn get_stale_pointers(&self) -> Vec<&SummaryPointer> {\n        self.pointers\n            .values()\n            .flat_map(|m| m.values())\n            .filter(|p| p.is_stale)\n            .collect()\n    }\n\n    pub fn get_pointers_for_layer(&self, layer: MemoryLayer) -> Vec<&SummaryPointer> {\n        self.pointers\n            .values()\n            .flat_map(|m| m.values())\n            .filter(|p| p.layer == layer)\n            .collect()\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct HindsightPointer {\n    pub error_signature_id: String,\n    pub memory_entry_id: Option<String>,\n    pub resolution_ids: Vec<String>,\n    pub note_id: Option<String>,\n    pub source_layer: MemoryLayer,\n    pub synced_at: i64,\n    pub success_rate: f32,\n    pub application_count: u32,\n}\n\nimpl HindsightPointer {\n    pub fn new(error_signature_id: String, source_layer: MemoryLayer) -> Self {\n        Self {\n            error_signature_id,\n            memory_entry_id: None,\n            resolution_ids: Vec::new(),\n            note_id: None,\n            source_layer,\n            synced_at: chrono::Utc::now().timestamp(),\n            success_rate: 0.0,\n            application_count: 0,\n        }\n    }\n\n    pub fn add_resolution(&mut self, resolution_id: String) {\n        if !self.resolution_ids.contains(&resolution_id) {\n            self.resolution_ids.push(resolution_id);\n        }\n    }\n\n    pub fn update_success_rate(&mut self, success: bool) {\n        self.application_count += 1;\n        let current_successes = (self.success_rate * (self.application_count - 1) as f32).round();\n        let new_successes = if success {\n            current_successes + 1.0\n        } else {\n            current_successes\n        };\n        self.success_rate = new_successes / self.application_count as f32;\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Default)]\n#[serde(rename_all = \"camelCase\")]\npub struct HindsightPointerState {\n    pub pointers: HashMap<String, HindsightPointer>,\n    pub last_sync_at: Option<i64>,\n    pub total_patterns: u64,\n    pub total_resolutions: u64,\n}\n\nimpl HindsightPointerState {\n    pub fn get_pointer(&self, error_signature_id: &str) -> Option<&HindsightPointer> {\n        self.pointers.get(error_signature_id)\n    }\n\n    pub fn set_pointer(&mut self, pointer: HindsightPointer) {\n        let is_new = !self.pointers.contains_key(&pointer.error_signature_id);\n        let new_resolutions = pointer.resolution_ids.len() as u64;\n\n        if let Some(existing) = self.pointers.get(&pointer.error_signature_id) {\n            self.total_resolutions = self\n                .total_resolutions\n                .saturating_sub(existing.resolution_ids.len() as u64);\n        }\n\n        self.pointers\n            .insert(pointer.error_signature_id.clone(), pointer);\n\n        if is_new {\n            self.total_patterns += 1;\n        }\n        self.total_resolutions += new_resolutions;\n    }\n\n    pub fn remove_pointer(&mut self, error_signature_id: &str) -> Option<HindsightPointer> {\n        if let Some(ptr) = self.pointers.remove(error_signature_id) {\n            self.total_patterns = self.total_patterns.saturating_sub(1);\n            self.total_resolutions = self\n                .total_resolutions\n                .saturating_sub(ptr.resolution_ids.len() as u64);\n            Some(ptr)\n        } else {\n            None\n        }\n    }\n\n    pub fn get_pointers_by_layer(&self, layer: MemoryLayer) -> Vec<&HindsightPointer> {\n        self.pointers\n            .values()\n            .filter(|p| p.source_layer == layer)\n            .collect()\n    }\n\n    pub fn get_high_success_pointers(\n        &self,\n        min_rate: f32,\n        min_applications: u32,\n    ) -> Vec<&HindsightPointer> {\n        self.pointers\n            .values()\n            .filter(|p| p.success_rate >= min_rate && p.application_count >= min_applications)\n            .collect()\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct KnowledgePointerMetadata {\n    #[serde(rename = \"type\")]\n    pub kind: String,\n    pub knowledge_pointer: KnowledgePointer,\n    pub tags: Vec<String>,\n}\n\nimpl Default for KnowledgePointerMetadata {\n    fn default() -> Self {\n        Self {\n            kind: \"knowledge_pointer\".to_string(),\n            knowledge_pointer: KnowledgePointer {\n                source_type: KnowledgeType::Adr,\n                source_id: String::new(),\n                content_hash: String::new(),\n                synced_at: 0,\n                source_layer: KnowledgeLayer::Company,\n                is_orphaned: false,\n            },\n            tags: Vec::new(),\n        }\n    }\n}\n\npub fn map_layer(knowledge_layer: KnowledgeLayer) -> MemoryLayer {\n    match knowledge_layer {\n        KnowledgeLayer::Company => MemoryLayer::Company,\n        KnowledgeLayer::Org => MemoryLayer::Org,\n        KnowledgeLayer::Team => MemoryLayer::Team,\n        KnowledgeLayer::Project => MemoryLayer::Project,\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_knowledge_pointer_metadata_default() {\n        let metadata = KnowledgePointerMetadata::default();\n\n        assert_eq!(metadata.kind, \"knowledge_pointer\");\n        assert_eq!(metadata.knowledge_pointer.source_type, KnowledgeType::Adr);\n        assert!(metadata.knowledge_pointer.source_id.is_empty());\n        assert!(metadata.knowledge_pointer.content_hash.is_empty());\n        assert_eq!(metadata.knowledge_pointer.synced_at, 0);\n        assert_eq!(\n            metadata.knowledge_pointer.source_layer,\n            KnowledgeLayer::Company\n        );\n        assert!(!metadata.knowledge_pointer.is_orphaned);\n        assert!(metadata.tags.is_empty());\n    }\n\n    #[test]\n    fn test_map_layer_company() {\n        assert_eq!(map_layer(KnowledgeLayer::Company), MemoryLayer::Company);\n    }\n\n    #[test]\n    fn test_map_layer_org() {\n        assert_eq!(map_layer(KnowledgeLayer::Org), MemoryLayer::Org);\n    }\n\n    #[test]\n    fn test_map_layer_team() {\n        assert_eq!(map_layer(KnowledgeLayer::Team), MemoryLayer::Team);\n    }\n\n    #[test]\n    fn test_map_layer_project() {\n        assert_eq!(map_layer(KnowledgeLayer::Project), MemoryLayer::Project);\n    }\n\n    #[test]\n    fn test_summary_pointer_new() {\n        let ptr = SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            \"content-hash\".to_string(),\n            \"source-hash\".to_string(),\n            50,\n        );\n\n        assert_eq!(ptr.entry_id, \"entry-1\");\n        assert_eq!(ptr.layer, MemoryLayer::Project);\n        assert_eq!(ptr.depth, SummaryDepth::Sentence);\n        assert_eq!(ptr.content_hash, \"content-hash\");\n        assert_eq!(ptr.source_content_hash, \"source-hash\");\n        assert_eq!(ptr.token_count, 50);\n        assert!(!ptr.is_stale);\n        assert!(!ptr.personalized);\n        assert!(ptr.personalization_context.is_none());\n    }\n\n    #[test]\n    fn test_summary_pointer_mark_stale() {\n        let mut ptr = SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            \"hash\".to_string(),\n            \"source\".to_string(),\n            50,\n        );\n\n        assert!(!ptr.is_stale);\n        ptr.mark_stale();\n        assert!(ptr.is_stale);\n    }\n\n    #[test]\n    fn test_summary_pointer_needs_update() {\n        let ptr = SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            \"hash\".to_string(),\n            \"source-hash\".to_string(),\n            50,\n        );\n\n        assert!(!ptr.needs_update(\"source-hash\"));\n        assert!(ptr.needs_update(\"different-hash\"));\n    }\n\n    #[test]\n    fn test_summary_pointer_needs_update_when_stale() {\n        let mut ptr = SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            \"hash\".to_string(),\n            \"source-hash\".to_string(),\n            50,\n        );\n\n        ptr.mark_stale();\n        assert!(ptr.needs_update(\"source-hash\"));\n    }\n\n    #[test]\n    fn test_summary_pointer_state_set_get() {\n        let mut state = SummaryPointerState::default();\n        let ptr = SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            \"hash\".to_string(),\n            \"source\".to_string(),\n            50,\n        );\n\n        state.set_pointer(ptr.clone());\n\n        let retrieved = state.get_pointer(\"entry-1\", SummaryDepth::Sentence);\n        assert!(retrieved.is_some());\n        assert_eq!(retrieved.unwrap().content_hash, \"hash\");\n        assert_eq!(state.total_summaries, 1);\n    }\n\n    #[test]\n    fn test_summary_pointer_state_multiple_depths() {\n        let mut state = SummaryPointerState::default();\n\n        state.set_pointer(SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            \"hash1\".to_string(),\n            \"source\".to_string(),\n            50,\n        ));\n        state.set_pointer(SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Paragraph,\n            \"hash2\".to_string(),\n            \"source\".to_string(),\n            200,\n        ));\n\n        assert_eq!(state.total_summaries, 2);\n        assert!(\n            state\n                .get_pointer(\"entry-1\", SummaryDepth::Sentence)\n                .is_some()\n        );\n        assert!(\n            state\n                .get_pointer(\"entry-1\", SummaryDepth::Paragraph)\n                .is_some()\n        );\n        assert!(\n            state\n                .get_pointer(\"entry-1\", SummaryDepth::Detailed)\n                .is_none()\n        );\n    }\n\n    #[test]\n    fn test_summary_pointer_state_remove() {\n        let mut state = SummaryPointerState::default();\n\n        state.set_pointer(SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            \"hash\".to_string(),\n            \"source\".to_string(),\n            50,\n        ));\n\n        let removed = state.remove_pointer(\"entry-1\", SummaryDepth::Sentence);\n        assert!(removed.is_some());\n        assert_eq!(state.total_summaries, 0);\n        assert!(\n            state\n                .get_pointer(\"entry-1\", SummaryDepth::Sentence)\n                .is_none()\n        );\n    }\n\n    #[test]\n    fn test_summary_pointer_state_remove_all_for_entry() {\n        let mut state = SummaryPointerState::default();\n\n        state.set_pointer(SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            \"hash1\".to_string(),\n            \"source\".to_string(),\n            50,\n        ));\n        state.set_pointer(SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Paragraph,\n            \"hash2\".to_string(),\n            \"source\".to_string(),\n            200,\n        ));\n\n        assert_eq!(state.total_summaries, 2);\n\n        let removed = state.remove_all_for_entry(\"entry-1\");\n        assert_eq!(removed.len(), 2);\n        assert_eq!(state.total_summaries, 0);\n    }\n\n    #[test]\n    fn test_summary_pointer_state_mark_stale() {\n        let mut state = SummaryPointerState::default();\n\n        state.set_pointer(SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            \"hash\".to_string(),\n            \"source\".to_string(),\n            50,\n        ));\n\n        assert_eq!(state.stale_count, 0);\n        assert!(state.mark_stale(\"entry-1\", SummaryDepth::Sentence));\n        assert_eq!(state.stale_count, 1);\n\n        let ptr = state\n            .get_pointer(\"entry-1\", SummaryDepth::Sentence)\n            .unwrap();\n        assert!(ptr.is_stale);\n    }\n\n    #[test]\n    fn test_summary_pointer_state_mark_all_stale() {\n        let mut state = SummaryPointerState::default();\n\n        state.set_pointer(SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            \"hash1\".to_string(),\n            \"source\".to_string(),\n            50,\n        ));\n        state.set_pointer(SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Paragraph,\n            \"hash2\".to_string(),\n            \"source\".to_string(),\n            200,\n        ));\n\n        let count = state.mark_all_stale_for_entry(\"entry-1\");\n        assert_eq!(count, 2);\n        assert_eq!(state.stale_count, 2);\n    }\n\n    #[test]\n    fn test_summary_pointer_state_get_stale_pointers() {\n        let mut state = SummaryPointerState::default();\n\n        state.set_pointer(SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            \"hash1\".to_string(),\n            \"source\".to_string(),\n            50,\n        ));\n        state.set_pointer(SummaryPointer::new(\n            \"entry-2\".to_string(),\n            MemoryLayer::Team,\n            SummaryDepth::Paragraph,\n            \"hash2\".to_string(),\n            \"source\".to_string(),\n            200,\n        ));\n\n        state.mark_stale(\"entry-1\", SummaryDepth::Sentence);\n\n        let stale = state.get_stale_pointers();\n        assert_eq!(stale.len(), 1);\n        assert_eq!(stale[0].entry_id, \"entry-1\");\n    }\n\n    #[test]\n    fn test_summary_pointer_state_get_by_layer() {\n        let mut state = SummaryPointerState::default();\n\n        state.set_pointer(SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            \"hash1\".to_string(),\n            \"source\".to_string(),\n            50,\n        ));\n        state.set_pointer(SummaryPointer::new(\n            \"entry-2\".to_string(),\n            MemoryLayer::Team,\n            SummaryDepth::Paragraph,\n            \"hash2\".to_string(),\n            \"source\".to_string(),\n            200,\n        ));\n\n        let project_ptrs = state.get_pointers_for_layer(MemoryLayer::Project);\n        assert_eq!(project_ptrs.len(), 1);\n        assert_eq!(project_ptrs[0].entry_id, \"entry-1\");\n\n        let team_ptrs = state.get_pointers_for_layer(MemoryLayer::Team);\n        assert_eq!(team_ptrs.len(), 1);\n        assert_eq!(team_ptrs[0].entry_id, \"entry-2\");\n    }\n\n    #[test]\n    fn test_hindsight_pointer_new() {\n        let ptr = HindsightPointer::new(\"sig-123\".to_string(), MemoryLayer::User);\n\n        assert_eq!(ptr.error_signature_id, \"sig-123\");\n        assert!(ptr.memory_entry_id.is_none());\n        assert!(ptr.resolution_ids.is_empty());\n        assert!(ptr.note_id.is_none());\n        assert_eq!(ptr.source_layer, MemoryLayer::User);\n        assert_eq!(ptr.success_rate, 0.0);\n        assert_eq!(ptr.application_count, 0);\n    }\n\n    #[test]\n    fn test_hindsight_pointer_add_resolution() {\n        let mut ptr = HindsightPointer::new(\"sig-123\".to_string(), MemoryLayer::User);\n\n        ptr.add_resolution(\"res-1\".to_string());\n        assert_eq!(ptr.resolution_ids.len(), 1);\n\n        ptr.add_resolution(\"res-2\".to_string());\n        assert_eq!(ptr.resolution_ids.len(), 2);\n\n        ptr.add_resolution(\"res-1\".to_string());\n        assert_eq!(ptr.resolution_ids.len(), 2);\n    }\n\n    #[test]\n    fn test_hindsight_pointer_update_success_rate() {\n        let mut ptr = HindsightPointer::new(\"sig-123\".to_string(), MemoryLayer::User);\n\n        ptr.update_success_rate(true);\n        assert_eq!(ptr.application_count, 1);\n        assert_eq!(ptr.success_rate, 1.0);\n\n        ptr.update_success_rate(false);\n        assert_eq!(ptr.application_count, 2);\n        assert_eq!(ptr.success_rate, 0.5);\n\n        ptr.update_success_rate(true);\n        assert_eq!(ptr.application_count, 3);\n        assert!((ptr.success_rate - 0.666).abs() < 0.01);\n    }\n\n    #[test]\n    fn test_hindsight_pointer_state_set_get() {\n        let mut state = HindsightPointerState::default();\n        let ptr = HindsightPointer::new(\"sig-123\".to_string(), MemoryLayer::User);\n\n        state.set_pointer(ptr);\n\n        let retrieved = state.get_pointer(\"sig-123\");\n        assert!(retrieved.is_some());\n        assert_eq!(state.total_patterns, 1);\n    }\n\n    #[test]\n    fn test_hindsight_pointer_state_remove() {\n        let mut state = HindsightPointerState::default();\n        let mut ptr = HindsightPointer::new(\"sig-123\".to_string(), MemoryLayer::User);\n        ptr.add_resolution(\"res-1\".to_string());\n        ptr.add_resolution(\"res-2\".to_string());\n\n        state.set_pointer(ptr);\n        assert_eq!(state.total_patterns, 1);\n        assert_eq!(state.total_resolutions, 2);\n\n        let removed = state.remove_pointer(\"sig-123\");\n        assert!(removed.is_some());\n        assert_eq!(state.total_patterns, 0);\n        assert_eq!(state.total_resolutions, 0);\n    }\n\n    #[test]\n    fn test_hindsight_pointer_state_get_by_layer() {\n        let mut state = HindsightPointerState::default();\n\n        state.set_pointer(HindsightPointer::new(\n            \"sig-1\".to_string(),\n            MemoryLayer::User,\n        ));\n        state.set_pointer(HindsightPointer::new(\n            \"sig-2\".to_string(),\n            MemoryLayer::Team,\n        ));\n        state.set_pointer(HindsightPointer::new(\n            \"sig-3\".to_string(),\n            MemoryLayer::User,\n        ));\n\n        let user_ptrs = state.get_pointers_by_layer(MemoryLayer::User);\n        assert_eq!(user_ptrs.len(), 2);\n\n        let team_ptrs = state.get_pointers_by_layer(MemoryLayer::Team);\n        assert_eq!(team_ptrs.len(), 1);\n    }\n\n    #[test]\n    fn test_hindsight_pointer_state_get_high_success() {\n        let mut state = HindsightPointerState::default();\n\n        let mut ptr1 = HindsightPointer::new(\"sig-1\".to_string(), MemoryLayer::User);\n        for _ in 0..10 {\n            ptr1.update_success_rate(true);\n        }\n\n        let mut ptr2 = HindsightPointer::new(\"sig-2\".to_string(), MemoryLayer::User);\n        for i in 0..10 {\n            ptr2.update_success_rate(i < 5);\n        }\n\n        let mut ptr3 = HindsightPointer::new(\"sig-3\".to_string(), MemoryLayer::User);\n        ptr3.update_success_rate(true);\n\n        state.set_pointer(ptr1);\n        state.set_pointer(ptr2);\n        state.set_pointer(ptr3);\n\n        let high_success = state.get_high_success_pointers(0.8, 5);\n        assert_eq!(high_success.len(), 1);\n        assert_eq!(high_success[0].error_signature_id, \"sig-1\");\n    }\n\n    #[test]\n    fn test_summary_pointer_serialization() {\n        let ptr = SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            \"hash\".to_string(),\n            \"source\".to_string(),\n            50,\n        );\n\n        let json = serde_json::to_string(&ptr).unwrap();\n        let deserialized: SummaryPointer = serde_json::from_str(&json).unwrap();\n        assert_eq!(ptr, deserialized);\n    }\n\n    #[test]\n    fn test_hindsight_pointer_serialization() {\n        let mut ptr = HindsightPointer::new(\"sig-123\".to_string(), MemoryLayer::User);\n        ptr.add_resolution(\"res-1\".to_string());\n        ptr.note_id = Some(\"note-1\".to_string());\n\n        let json = serde_json::to_string(&ptr).unwrap();\n        let deserialized: HindsightPointer = serde_json::from_str(&json).unwrap();\n        assert_eq!(ptr, deserialized);\n    }\n}\n","traces":[{"line":32,"address":[],"length":0,"stats":{"Line":29}},{"line":47,"address":[],"length":0,"stats":{"Line":58}},{"line":54,"address":[],"length":0,"stats":{"Line":2}},{"line":55,"address":[],"length":0,"stats":{"Line":2}},{"line":58,"address":[],"length":0,"stats":{"Line":3}},{"line":59,"address":[],"length":0,"stats":{"Line":5}},{"line":73,"address":[],"length":0,"stats":{"Line":18}},{"line":74,"address":[],"length":0,"stats":{"Line":111}},{"line":77,"address":[],"length":0,"stats":{"Line":24}},{"line":78,"address":[],"length":0,"stats":{"Line":144}},{"line":79,"address":[],"length":0,"stats":{"Line":71}},{"line":80,"address":[],"length":0,"stats":{"Line":23}},{"line":82,"address":[],"length":0,"stats":{"Line":96}},{"line":85,"address":[],"length":0,"stats":{"Line":1}},{"line":90,"address":[],"length":0,"stats":{"Line":3}},{"line":91,"address":[],"length":0,"stats":{"Line":3}},{"line":92,"address":[],"length":0,"stats":{"Line":1}},{"line":93,"address":[],"length":0,"stats":{"Line":1}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":3}},{"line":97,"address":[],"length":0,"stats":{"Line":2}},{"line":99,"address":[],"length":0,"stats":{"Line":1}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":1}},{"line":106,"address":[],"length":0,"stats":{"Line":3}},{"line":107,"address":[],"length":0,"stats":{"Line":5}},{"line":108,"address":[],"length":0,"stats":{"Line":5}},{"line":109,"address":[],"length":0,"stats":{"Line":2}},{"line":110,"address":[],"length":0,"stats":{"Line":2}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":1}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":2}},{"line":121,"address":[],"length":0,"stats":{"Line":4}},{"line":122,"address":[],"length":0,"stats":{"Line":2}},{"line":123,"address":[],"length":0,"stats":{"Line":4}},{"line":124,"address":[],"length":0,"stats":{"Line":8}},{"line":126,"address":[],"length":0,"stats":{"Line":4}},{"line":127,"address":[],"length":0,"stats":{"Line":2}},{"line":128,"address":[],"length":0,"stats":{"Line":2}},{"line":130,"address":[],"length":0,"stats":{"Line":2}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":3}},{"line":137,"address":[],"length":0,"stats":{"Line":6}},{"line":138,"address":[],"length":0,"stats":{"Line":9}},{"line":139,"address":[],"length":0,"stats":{"Line":11}},{"line":140,"address":[],"length":0,"stats":{"Line":10}},{"line":141,"address":[],"length":0,"stats":{"Line":10}},{"line":142,"address":[],"length":0,"stats":{"Line":5}},{"line":143,"address":[],"length":0,"stats":{"Line":5}},{"line":147,"address":[],"length":0,"stats":{"Line":3}},{"line":150,"address":[],"length":0,"stats":{"Line":1}},{"line":151,"address":[],"length":0,"stats":{"Line":1}},{"line":153,"address":[],"length":0,"stats":{"Line":5}},{"line":154,"address":[],"length":0,"stats":{"Line":1}},{"line":158,"address":[],"length":0,"stats":{"Line":2}},{"line":159,"address":[],"length":0,"stats":{"Line":2}},{"line":161,"address":[],"length":0,"stats":{"Line":10}},{"line":162,"address":[],"length":0,"stats":{"Line":10}},{"line":181,"address":[],"length":0,"stats":{"Line":13}},{"line":185,"address":[],"length":0,"stats":{"Line":26}},{"line":188,"address":[],"length":0,"stats":{"Line":13}},{"line":194,"address":[],"length":0,"stats":{"Line":6}},{"line":195,"address":[],"length":0,"stats":{"Line":17}},{"line":196,"address":[],"length":0,"stats":{"Line":10}},{"line":200,"address":[],"length":0,"stats":{"Line":24}},{"line":201,"address":[],"length":0,"stats":{"Line":24}},{"line":202,"address":[],"length":0,"stats":{"Line":72}},{"line":203,"address":[],"length":0,"stats":{"Line":48}},{"line":204,"address":[],"length":0,"stats":{"Line":18}},{"line":206,"address":[],"length":0,"stats":{"Line":6}},{"line":208,"address":[],"length":0,"stats":{"Line":24}},{"line":222,"address":[],"length":0,"stats":{"Line":1}},{"line":223,"address":[],"length":0,"stats":{"Line":3}},{"line":226,"address":[],"length":0,"stats":{"Line":9}},{"line":227,"address":[],"length":0,"stats":{"Line":27}},{"line":228,"address":[],"length":0,"stats":{"Line":18}},{"line":230,"address":[],"length":0,"stats":{"Line":18}},{"line":231,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":9}},{"line":237,"address":[],"length":0,"stats":{"Line":36}},{"line":239,"address":[],"length":0,"stats":{"Line":18}},{"line":240,"address":[],"length":0,"stats":{"Line":9}},{"line":242,"address":[],"length":0,"stats":{"Line":9}},{"line":245,"address":[],"length":0,"stats":{"Line":1}},{"line":246,"address":[],"length":0,"stats":{"Line":3}},{"line":247,"address":[],"length":0,"stats":{"Line":1}},{"line":248,"address":[],"length":0,"stats":{"Line":2}},{"line":249,"address":[],"length":0,"stats":{"Line":2}},{"line":250,"address":[],"length":0,"stats":{"Line":2}},{"line":251,"address":[],"length":0,"stats":{"Line":1}},{"line":253,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":2}},{"line":258,"address":[],"length":0,"stats":{"Line":2}},{"line":260,"address":[],"length":0,"stats":{"Line":14}},{"line":264,"address":[],"length":0,"stats":{"Line":1}},{"line":269,"address":[],"length":0,"stats":{"Line":1}},{"line":271,"address":[],"length":0,"stats":{"Line":6}},{"line":286,"address":[],"length":0,"stats":{"Line":1}},{"line":288,"address":[],"length":0,"stats":{"Line":3}},{"line":289,"address":[],"length":0,"stats":{"Line":1}},{"line":297,"address":[],"length":0,"stats":{"Line":1}},{"line":302,"address":[],"length":0,"stats":{"Line":24}},{"line":303,"address":[],"length":0,"stats":{"Line":24}},{"line":304,"address":[],"length":0,"stats":{"Line":1}},{"line":305,"address":[],"length":0,"stats":{"Line":2}},{"line":306,"address":[],"length":0,"stats":{"Line":1}},{"line":307,"address":[],"length":0,"stats":{"Line":20}}],"covered":101,"coverable":110},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","proptests.rs"],"content":"#[cfg(test)]\nmod proptests {\n    use proptest::prelude::*;\n\n    proptest! {\n        #[test]\n        fn test_hash_consistency(content in \"\\\\PC*\") {\n            let hash1 = utils::compute_content_hash(&content);\n            let hash2 = utils::compute_content_hash(&content);\n            prop_assert_eq!(hash1, hash2);\n        }\n\n        #[test]\n        fn test_hash_different_for_different_content(c1 in \"\\\\PC*\", c2 in \"\\\\PC*\") {\n            if c1 != c2 {\n                let hash1 = utils::compute_content_hash(&c1);\n                let hash2 = utils::compute_content_hash(&c2);\n                prop_assert_ne!(hash1, hash2);\n            }\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","state.rs"],"content":"use crate::pointer::{HindsightPointerState, SummaryPointerState};\nuse mk_core::types::{MemoryLayer, SummaryDepth};\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct SyncState {\n    pub version: String,\n    pub last_sync_at: Option<i64>,\n    pub last_knowledge_commit: Option<String>,\n    pub knowledge_hashes: HashMap<String, String>,\n    pub pointer_mapping: HashMap<String, String>,\n    pub knowledge_layers: HashMap<String, mk_core::types::KnowledgeLayer>,\n    pub failed_items: Vec<SyncFailure>,\n    pub federation_conflicts: Vec<FederationConflict>,\n    pub upstream_commits: HashMap<String, String>,\n    pub stats: SyncStats,\n    #[serde(default)]\n    pub summary_state: SummaryPointerState,\n    #[serde(default)]\n    pub hindsight_state: HindsightPointerState,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct FederationConflict {\n    pub upstream_id: String,\n    pub reason: String,\n    pub detected_at: i64,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct SyncFailure {\n    pub knowledge_id: String,\n    pub error: String,\n    pub failed_at: i64,\n    pub retry_count: u32,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\npub enum SyncConflict {\n    HashMismatch {\n        knowledge_id: String,\n        memory_id: String,\n        expected_hash: String,\n        actual_hash: String,\n    },\n    OrphanedPointer {\n        memory_id: String,\n        knowledge_id: String,\n    },\n    MissingPointer {\n        knowledge_id: String,\n        expected_memory_id: String,\n    },\n    DuplicatePointer {\n        knowledge_id: String,\n        memory_ids: Vec<String>,\n    },\n    StatusChange {\n        knowledge_id: String,\n        memory_id: String,\n        new_status: mk_core::types::KnowledgeStatus,\n    },\n    LayerMismatch {\n        knowledge_id: String,\n        memory_id: String,\n        expected_layer: mk_core::types::KnowledgeLayer,\n        actual_layer: mk_core::types::KnowledgeLayer,\n    },\n    DetectionError {\n        target_id: String,\n        error: String,\n    },\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\npub enum SyncTrigger {\n    Staleness {\n        last_sync_at: i64,\n        threshold_mins: u32,\n    },\n    CommitMismatch {\n        last_commit: String,\n        head_commit: String,\n    },\n    Manual,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, Default, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct SyncStats {\n    pub total_syncs: u64,\n    pub total_items_synced: u64,\n    pub total_conflicts: u64,\n    pub total_governance_blocks: u64,\n    pub avg_sync_duration_ms: u64,\n    pub drift_score: f32,\n    pub policy_violations: u64,\n    pub total_summaries_synced: u64,\n    pub total_summaries_invalidated: u64,\n    pub total_hindsight_patterns: u64,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\npub enum SummarySyncTrigger {\n    SourceContentChanged {\n        entry_id: String,\n        layer: MemoryLayer,\n        previous_hash: String,\n        new_hash: String,\n    },\n    TimeThresholdExceeded {\n        entry_id: String,\n        layer: MemoryLayer,\n        age_seconds: u64,\n        threshold_seconds: u64,\n    },\n    ChangeCountExceeded {\n        entry_id: String,\n        layer: MemoryLayer,\n        change_count: u32,\n        threshold: u32,\n    },\n    ManualRefresh {\n        entry_id: String,\n        layer: MemoryLayer,\n    },\n    LayerConfigChanged {\n        layer: MemoryLayer,\n        depths_added: Vec<SummaryDepth>,\n        depths_removed: Vec<SummaryDepth>,\n    },\n    ParentSummaryInvalidated {\n        entry_id: String,\n        layer: MemoryLayer,\n        parent_layer: MemoryLayer,\n    },\n}\n\nimpl Default for SyncState {\n    fn default() -> Self {\n        Self {\n            version: \"1.0\".to_string(),\n            last_sync_at: None,\n            last_knowledge_commit: None,\n            knowledge_hashes: HashMap::new(),\n            pointer_mapping: HashMap::new(),\n            knowledge_layers: HashMap::new(),\n            failed_items: Vec::new(),\n            federation_conflicts: Vec::new(),\n            upstream_commits: HashMap::new(),\n            stats: SyncStats::default(),\n            summary_state: SummaryPointerState::default(),\n            hindsight_state: HindsightPointerState::default(),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_sync_state_default() {\n        let state = SyncState::default();\n        assert_eq!(state.version, \"1.0\");\n        assert!(state.last_sync_at.is_none());\n        assert!(state.summary_state.pointers.is_empty());\n        assert!(state.hindsight_state.pointers.is_empty());\n    }\n\n    #[test]\n    fn test_sync_stats_default() {\n        let stats = SyncStats::default();\n        assert_eq!(stats.total_summaries_synced, 0);\n        assert_eq!(stats.total_summaries_invalidated, 0);\n        assert_eq!(stats.total_hindsight_patterns, 0);\n    }\n\n    #[test]\n    fn test_summary_sync_trigger_serialization() {\n        let triggers = vec![\n            SummarySyncTrigger::SourceContentChanged {\n                entry_id: \"entry-1\".to_string(),\n                layer: MemoryLayer::Project,\n                previous_hash: \"old\".to_string(),\n                new_hash: \"new\".to_string(),\n            },\n            SummarySyncTrigger::TimeThresholdExceeded {\n                entry_id: \"entry-1\".to_string(),\n                layer: MemoryLayer::Project,\n                age_seconds: 3600,\n                threshold_seconds: 1800,\n            },\n            SummarySyncTrigger::ChangeCountExceeded {\n                entry_id: \"entry-1\".to_string(),\n                layer: MemoryLayer::Project,\n                change_count: 10,\n                threshold: 5,\n            },\n            SummarySyncTrigger::ManualRefresh {\n                entry_id: \"entry-1\".to_string(),\n                layer: MemoryLayer::Project,\n            },\n            SummarySyncTrigger::LayerConfigChanged {\n                layer: MemoryLayer::Project,\n                depths_added: vec![SummaryDepth::Detailed],\n                depths_removed: vec![],\n            },\n            SummarySyncTrigger::ParentSummaryInvalidated {\n                entry_id: \"entry-1\".to_string(),\n                layer: MemoryLayer::Project,\n                parent_layer: MemoryLayer::Team,\n            },\n        ];\n\n        for trigger in triggers {\n            let json = serde_json::to_string(&trigger).unwrap();\n            let deserialized: SummarySyncTrigger = serde_json::from_str(&json).unwrap();\n            assert_eq!(trigger, deserialized);\n        }\n    }\n\n    #[test]\n    fn test_sync_state_with_summary_state() {\n        let mut state = SyncState::default();\n\n        let ptr = crate::pointer::SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            \"hash\".to_string(),\n            \"source\".to_string(),\n            50,\n        );\n        state.summary_state.set_pointer(ptr);\n\n        assert_eq!(state.summary_state.total_summaries, 1);\n\n        let json = serde_json::to_string(&state).unwrap();\n        let deserialized: SyncState = serde_json::from_str(&json).unwrap();\n        assert_eq!(deserialized.summary_state.total_summaries, 1);\n    }\n\n    #[test]\n    fn test_sync_state_with_hindsight_state() {\n        let mut state = SyncState::default();\n\n        let ptr = crate::pointer::HindsightPointer::new(\"sig-123\".to_string(), MemoryLayer::User);\n        state.hindsight_state.set_pointer(ptr);\n\n        assert_eq!(state.hindsight_state.total_patterns, 1);\n\n        let json = serde_json::to_string(&state).unwrap();\n        let deserialized: SyncState = serde_json::from_str(&json).unwrap();\n        assert_eq!(deserialized.hindsight_state.total_patterns, 1);\n    }\n}\n","traces":[{"line":144,"address":[],"length":0,"stats":{"Line":48}},{"line":146,"address":[],"length":0,"stats":{"Line":144}},{"line":149,"address":[],"length":0,"stats":{"Line":96}},{"line":150,"address":[],"length":0,"stats":{"Line":96}},{"line":151,"address":[],"length":0,"stats":{"Line":96}},{"line":152,"address":[],"length":0,"stats":{"Line":96}},{"line":153,"address":[],"length":0,"stats":{"Line":96}},{"line":154,"address":[],"length":0,"stats":{"Line":96}},{"line":155,"address":[],"length":0,"stats":{"Line":96}},{"line":156,"address":[],"length":0,"stats":{"Line":48}},{"line":157,"address":[],"length":0,"stats":{"Line":48}}],"covered":11,"coverable":11},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","state_persister.rs"],"content":"use crate::state::SyncState;\nuse async_trait::async_trait;\nuse mk_core::traits::StorageBackend;\nuse std::path::PathBuf;\nuse std::sync::Arc;\n\n#[async_trait]\npub trait SyncStatePersister: Send + Sync {\n    async fn load(\n        &self,\n        tenant_id: &mk_core::types::TenantId,\n    ) -> Result<SyncState, Box<dyn std::error::Error + Send + Sync>>;\n    async fn save(\n        &self,\n        tenant_id: &mk_core::types::TenantId,\n        state: &SyncState,\n    ) -> Result<(), Box<dyn std::error::Error + Send + Sync>>;\n}\n\npub struct FilePersister {\n    base_path: PathBuf,\n}\n\nimpl FilePersister {\n    pub fn new(base_path: PathBuf) -> Self {\n        Self { base_path }\n    }\n\n    fn get_path(&self, tenant_id: &mk_core::types::TenantId) -> PathBuf {\n        self.base_path\n            .join(format!(\"sync_state_{}.json\", tenant_id.as_str()))\n    }\n}\n\n#[async_trait]\nimpl SyncStatePersister for FilePersister {\n    async fn load(\n        &self,\n        tenant_id: &mk_core::types::TenantId,\n    ) -> Result<SyncState, Box<dyn std::error::Error + Send + Sync>> {\n        if tenant_id.as_str().contains(\"TRIGGER_FAILURE\") {\n            return Err(\"Simulated persistence failure\".into());\n        }\n        let path = self.get_path(tenant_id);\n        match tokio::fs::read(&path).await {\n            Ok(data) => Ok(serde_json::from_slice(&data)?),\n            Err(e) if e.kind() == std::io::ErrorKind::NotFound => Ok(SyncState::default()),\n            Err(e) => Err(e.into()),\n        }\n    }\n\n    async fn save(\n        &self,\n        tenant_id: &mk_core::types::TenantId,\n        state: &SyncState,\n    ) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {\n        let path = self.get_path(tenant_id);\n        let data = serde_json::to_vec_pretty(state)?;\n        if let Some(parent) = path.parent() {\n            tokio::fs::create_dir_all(parent).await?;\n        }\n        tokio::fs::write(&path, data).await?;\n        Ok(())\n    }\n}\n\npub struct DatabasePersister<S: StorageBackend> {\n    storage: Arc<S>,\n    key_prefix: String,\n}\n\nimpl<S: StorageBackend> DatabasePersister<S> {\n    pub fn new(storage: Arc<S>, key_prefix: String) -> Self {\n        Self {\n            storage,\n            key_prefix,\n        }\n    }\n\n    fn get_key(&self, tenant_id: &mk_core::types::TenantId) -> String {\n        format!(\"{}:{}\", self.key_prefix, tenant_id.as_str())\n    }\n}\n\n#[async_trait]\nimpl<S: StorageBackend> SyncStatePersister for DatabasePersister<S>\nwhere\n    S::Error: std::error::Error + Send + Sync + 'static,\n{\n    async fn load(\n        &self,\n        tenant_id: &mk_core::types::TenantId,\n    ) -> Result<SyncState, Box<dyn std::error::Error + Send + Sync>> {\n        let key = self.get_key(tenant_id);\n        let ctx = mk_core::types::TenantContext::new(\n            tenant_id.clone(),\n            mk_core::types::UserId::default(),\n        );\n        match self.storage.retrieve(ctx, &key).await? {\n            Some(data) => Ok(serde_json::from_slice(&data)?),\n            None => Ok(SyncState::default()),\n        }\n    }\n\n    async fn save(\n        &self,\n        tenant_id: &mk_core::types::TenantId,\n        state: &SyncState,\n    ) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {\n        let key = self.get_key(tenant_id);\n        let data = serde_json::to_vec(state)?;\n        let ctx = mk_core::types::TenantContext::new(\n            tenant_id.clone(),\n            mk_core::types::UserId::default(),\n        );\n        self.storage.store(ctx, &key, &data).await?;\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use async_trait::async_trait;\n    use std::collections::HashMap;\n    use std::sync::Arc;\n    use tokio::sync::RwLock;\n\n    struct MockStorage {\n        data: Arc<RwLock<HashMap<String, Vec<u8>>>>,\n    }\n\n    impl MockStorage {\n        fn new() -> Self {\n            Self {\n                data: Arc::new(RwLock::new(HashMap::new())),\n            }\n        }\n    }\n\n    #[async_trait]\n    impl StorageBackend for MockStorage {\n        type Error = std::io::Error;\n\n        async fn store(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            key: &str,\n            value: &[u8],\n        ) -> Result<(), Self::Error> {\n            self.data\n                .write()\n                .await\n                .insert(key.to_string(), value.to_vec());\n            Ok(())\n        }\n\n        async fn retrieve(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            key: &str,\n        ) -> Result<Option<Vec<u8>>, Self::Error> {\n            Ok(self.data.read().await.get(key).cloned())\n        }\n\n        async fn delete(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            key: &str,\n        ) -> Result<(), Self::Error> {\n            self.data.write().await.remove(key);\n            Ok(())\n        }\n\n        async fn exists(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            key: &str,\n        ) -> Result<bool, Self::Error> {\n            Ok(self.data.read().await.contains_key(key))\n        }\n\n        async fn get_ancestors(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _unit_id: &str,\n        ) -> Result<Vec<mk_core::types::OrganizationalUnit>, Self::Error> {\n            Ok(vec![])\n        }\n\n        async fn get_descendants(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _unit_id: &str,\n        ) -> Result<Vec<mk_core::types::OrganizationalUnit>, Self::Error> {\n            Ok(vec![])\n        }\n\n        async fn get_unit_policies(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _unit_id: &str,\n        ) -> Result<Vec<mk_core::types::Policy>, Self::Error> {\n            Ok(vec![])\n        }\n\n        async fn create_unit(\n            &self,\n            _unit: &mk_core::types::OrganizationalUnit,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn add_unit_policy(\n            &self,\n            _ctx: &mk_core::types::TenantContext,\n            _unit_id: &str,\n            _policy: &mk_core::types::Policy,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn assign_role(\n            &self,\n            _user_id: &mk_core::types::UserId,\n            _tenant_id: &mk_core::types::TenantId,\n            _unit_id: &str,\n            _role: mk_core::types::Role,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn remove_role(\n            &self,\n            _user_id: &mk_core::types::UserId,\n            _tenant_id: &mk_core::types::TenantId,\n            _unit_id: &str,\n            _role: mk_core::types::Role,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn store_drift_result(\n            &self,\n            _result: mk_core::types::DriftResult,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn get_latest_drift_result(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _project_id: &str,\n        ) -> Result<Option<mk_core::types::DriftResult>, Self::Error> {\n            Ok(None)\n        }\n\n        async fn list_all_units(\n            &self,\n        ) -> Result<Vec<mk_core::types::OrganizationalUnit>, Self::Error> {\n            Ok(vec![])\n        }\n\n        async fn record_job_status(\n            &self,\n            _job_name: &str,\n            _tenant_id: &str,\n            _status: &str,\n            _message: Option<&str>,\n            _started_at: i64,\n            _finished_at: Option<i64>,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn get_governance_events(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _since_timestamp: i64,\n            _limit: usize,\n        ) -> Result<Vec<mk_core::types::GovernanceEvent>, Self::Error> {\n            Ok(vec![])\n        }\n\n        async fn create_suppression(\n            &self,\n            _suppression: mk_core::types::DriftSuppression,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn list_suppressions(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _project_id: &str,\n        ) -> Result<Vec<mk_core::types::DriftSuppression>, Self::Error> {\n            Ok(vec![])\n        }\n\n        async fn delete_suppression(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _suppression_id: &str,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn get_drift_config(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _project_id: &str,\n        ) -> Result<Option<mk_core::types::DriftConfig>, Self::Error> {\n            Ok(None)\n        }\n\n        async fn save_drift_config(\n            &self,\n            _config: mk_core::types::DriftConfig,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn persist_event(\n            &self,\n            _event: mk_core::types::PersistentEvent,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn get_pending_events(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _limit: usize,\n        ) -> Result<Vec<mk_core::types::PersistentEvent>, Self::Error> {\n            Ok(vec![])\n        }\n\n        async fn update_event_status(\n            &self,\n            _event_id: &str,\n            _status: mk_core::types::EventStatus,\n            _error: Option<String>,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn get_dead_letter_events(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _limit: usize,\n        ) -> Result<Vec<mk_core::types::PersistentEvent>, Self::Error> {\n            Ok(vec![])\n        }\n\n        async fn check_idempotency(\n            &self,\n            _consumer_group: &str,\n            _idempotency_key: &str,\n        ) -> Result<bool, Self::Error> {\n            Ok(false)\n        }\n\n        async fn record_consumer_state(\n            &self,\n            _state: mk_core::types::ConsumerState,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n\n        async fn get_event_metrics(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _period_start: i64,\n            _period_end: i64,\n        ) -> Result<Vec<mk_core::types::EventDeliveryMetrics>, Self::Error> {\n            Ok(vec![])\n        }\n\n        async fn record_event_metrics(\n            &self,\n            _metrics: mk_core::types::EventDeliveryMetrics,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n    }\n\n    #[tokio::test]\n    async fn test_file_persister_save_and_load() {\n        let temp_dir = tempfile::tempdir().unwrap();\n        let base_path = temp_dir.path().to_path_buf();\n        let persister = FilePersister::new(base_path);\n        let tenant_id = mk_core::types::TenantId::default();\n\n        let mut state = SyncState::default();\n        state.stats.total_syncs = 10;\n\n        persister.save(&tenant_id, &state).await.unwrap();\n\n        let loaded_state = persister.load(&tenant_id).await.unwrap();\n        assert_eq!(loaded_state.stats.total_syncs, 10);\n    }\n\n    #[tokio::test]\n    async fn test_file_persister_load_default() {\n        let temp_dir = tempfile::tempdir().unwrap();\n        let base_path = temp_dir.path().to_path_buf();\n        let persister = FilePersister::new(base_path);\n        let tenant_id = mk_core::types::TenantId::default();\n\n        let state = persister.load(&tenant_id).await.unwrap();\n        assert_eq!(state, SyncState::default());\n    }\n\n    #[tokio::test]\n    async fn test_database_persister_new() {\n        let storage = Arc::new(MockStorage::new());\n        let persister = DatabasePersister::new(storage, \"test_key\".to_string());\n        assert_eq!(persister.key_prefix, \"test_key\");\n    }\n\n    #[tokio::test]\n    async fn test_database_persister_load_default() {\n        let storage = Arc::new(MockStorage::new());\n        let persister = DatabasePersister::new(storage, \"test_key\".to_string());\n        let tenant_id = mk_core::types::TenantId::default();\n\n        let state = persister.load(&tenant_id).await.unwrap();\n        assert_eq!(state, SyncState::default());\n    }\n\n    #[tokio::test]\n    async fn test_database_persister_save_and_load() {\n        let storage = Arc::new(MockStorage::new());\n        let persister = DatabasePersister::new(storage, \"test_key\".to_string());\n        let tenant_id = mk_core::types::TenantId::default();\n\n        let mut state = SyncState::default();\n        state.stats.total_syncs = 5;\n        state.stats.total_items_synced = 42;\n\n        persister.save(&tenant_id, &state).await.unwrap();\n\n        let loaded_state = persister.load(&tenant_id).await.unwrap();\n        assert_eq!(loaded_state.stats.total_syncs, 5);\n        assert_eq!(loaded_state.stats.total_items_synced, 42);\n    }\n\n    #[tokio::test]\n    async fn test_database_persister_save_overwrites() {\n        let storage = Arc::new(MockStorage::new());\n        let persister = DatabasePersister::new(storage, \"test_key\".to_string());\n        let tenant_id = mk_core::types::TenantId::default();\n\n        let mut state1 = SyncState::default();\n        state1.stats.total_syncs = 1;\n\n        let mut state2 = SyncState::default();\n        state2.stats.total_syncs = 2;\n\n        persister.save(&tenant_id, &state1).await.unwrap();\n        persister.save(&tenant_id, &state2).await.unwrap();\n\n        let loaded_state = persister.load(&tenant_id).await.unwrap();\n        assert_eq!(loaded_state.stats.total_syncs, 2);\n    }\n\n    #[tokio::test]\n    async fn test_database_persister_different_keys() {\n        let storage = Arc::new(MockStorage::new());\n        let persister1 = DatabasePersister::new(storage.clone(), \"key1\".to_string());\n        let persister2 = DatabasePersister::new(storage, \"key2\".to_string());\n        let tenant_id = mk_core::types::TenantId::default();\n\n        let mut state1 = SyncState::default();\n        state1.stats.total_syncs = 100;\n\n        let mut state2 = SyncState::default();\n        state2.stats.total_syncs = 200;\n\n        persister1.save(&tenant_id, &state1).await.unwrap();\n        persister2.save(&tenant_id, &state2).await.unwrap();\n\n        let loaded1 = persister1.load(&tenant_id).await.unwrap();\n        let loaded2 = persister2.load(&tenant_id).await.unwrap();\n\n        assert_eq!(loaded1.stats.total_syncs, 100);\n        assert_eq!(loaded2.stats.total_syncs, 200);\n    }\n\n    #[tokio::test]\n    async fn test_database_persister_storage_error() {\n        struct ErrorStorage;\n\n        #[async_trait]\n        impl StorageBackend for ErrorStorage {\n            type Error = std::io::Error;\n\n            async fn store(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _key: &str,\n                _value: &[u8],\n            ) -> Result<(), Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn retrieve(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _key: &str,\n            ) -> Result<Option<Vec<u8>>, Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn delete(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _key: &str,\n            ) -> Result<(), Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn exists(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _key: &str,\n            ) -> Result<bool, Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn get_ancestors(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _unit_id: &str,\n            ) -> Result<Vec<mk_core::types::OrganizationalUnit>, Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn get_descendants(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _unit_id: &str,\n            ) -> Result<Vec<mk_core::types::OrganizationalUnit>, Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn get_unit_policies(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _unit_id: &str,\n            ) -> Result<Vec<mk_core::types::Policy>, Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn create_unit(\n                &self,\n                _unit: &mk_core::types::OrganizationalUnit,\n            ) -> Result<(), Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn add_unit_policy(\n                &self,\n                _ctx: &mk_core::types::TenantContext,\n                _unit_id: &str,\n                _policy: &mk_core::types::Policy,\n            ) -> Result<(), Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn assign_role(\n                &self,\n                _user_id: &mk_core::types::UserId,\n                _tenant_id: &mk_core::types::TenantId,\n                _unit_id: &str,\n                _role: mk_core::types::Role,\n            ) -> Result<(), Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn remove_role(\n                &self,\n                _user_id: &mk_core::types::UserId,\n                _tenant_id: &mk_core::types::TenantId,\n                _unit_id: &str,\n                _role: mk_core::types::Role,\n            ) -> Result<(), Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn store_drift_result(\n                &self,\n                _result: mk_core::types::DriftResult,\n            ) -> Result<(), Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn get_latest_drift_result(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _project_id: &str,\n            ) -> Result<Option<mk_core::types::DriftResult>, Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn list_all_units(\n                &self,\n            ) -> Result<Vec<mk_core::types::OrganizationalUnit>, Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn record_job_status(\n                &self,\n                _job_name: &str,\n                _tenant_id: &str,\n                _status: &str,\n                _message: Option<&str>,\n                _started_at: i64,\n                _finished_at: Option<i64>,\n            ) -> Result<(), Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn get_governance_events(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _since_timestamp: i64,\n                _limit: usize,\n            ) -> Result<Vec<mk_core::types::GovernanceEvent>, Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn create_suppression(\n                &self,\n                _suppression: mk_core::types::DriftSuppression,\n            ) -> Result<(), Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn list_suppressions(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _project_id: &str,\n            ) -> Result<Vec<mk_core::types::DriftSuppression>, Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn delete_suppression(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _suppression_id: &str,\n            ) -> Result<(), Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn get_drift_config(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _project_id: &str,\n            ) -> Result<Option<mk_core::types::DriftConfig>, Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn save_drift_config(\n                &self,\n                _config: mk_core::types::DriftConfig,\n            ) -> Result<(), Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn persist_event(\n                &self,\n                _event: mk_core::types::PersistentEvent,\n            ) -> Result<(), Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn get_pending_events(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _limit: usize,\n            ) -> Result<Vec<mk_core::types::PersistentEvent>, Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn update_event_status(\n                &self,\n                _event_id: &str,\n                _status: mk_core::types::EventStatus,\n                _error: Option<String>,\n            ) -> Result<(), Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn get_dead_letter_events(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _limit: usize,\n            ) -> Result<Vec<mk_core::types::PersistentEvent>, Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn check_idempotency(\n                &self,\n                _consumer_group: &str,\n                _idempotency_key: &str,\n            ) -> Result<bool, Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn record_consumer_state(\n                &self,\n                _state: mk_core::types::ConsumerState,\n            ) -> Result<(), Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn get_event_metrics(\n                &self,\n                _ctx: mk_core::types::TenantContext,\n                _period_start: i64,\n                _period_end: i64,\n            ) -> Result<Vec<mk_core::types::EventDeliveryMetrics>, Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn record_event_metrics(\n                &self,\n                _metrics: mk_core::types::EventDeliveryMetrics,\n            ) -> Result<(), Self::Error> {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n        }\n\n        let storage = Arc::new(ErrorStorage);\n        let persister = DatabasePersister::new(storage, \"test_key\".to_string());\n        let tenant_id = mk_core::types::TenantId::default();\n\n        let state = SyncState::default();\n        let save_result = persister.save(&tenant_id, &state).await;\n        assert!(save_result.is_err());\n\n        let load_result = persister.load(&tenant_id).await;\n        assert!(load_result.is_err());\n    }\n}\n","traces":[{"line":25,"address":[],"length":0,"stats":{"Line":3}},{"line":29,"address":[],"length":0,"stats":{"Line":3}},{"line":30,"address":[],"length":0,"stats":{"Line":6}},{"line":31,"address":[],"length":0,"stats":{"Line":12}},{"line":73,"address":[],"length":0,"stats":{"Line":8}},{"line":80,"address":[],"length":0,"stats":{"Line":12}},{"line":81,"address":[],"length":0,"stats":{"Line":48}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}}],"covered":7,"coverable":19},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","summary_sync.rs"],"content":"use crate::events::{\n    InvalidationReason, SummaryCreated, SummaryInvalidated, SummarySyncEvent, SummaryUpdateReason,\n    SummaryUpdated,\n};\nuse crate::pointer::{SummaryPointer, SummaryPointerState};\nuse crate::state::SummarySyncTrigger;\nuse mk_core::types::{LayerSummary, MemoryLayer, SummaryConfig, SummaryDepth};\nuse std::collections::HashMap;\n\npub struct SummarySyncResult {\n    pub created: Vec<SummarySyncEvent>,\n    pub updated: Vec<SummarySyncEvent>,\n    pub invalidated: Vec<SummarySyncEvent>,\n    pub errors: Vec<SummarySyncError>,\n}\n\nimpl Default for SummarySyncResult {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\nimpl SummarySyncResult {\n    pub fn new() -> Self {\n        Self {\n            created: Vec::new(),\n            updated: Vec::new(),\n            invalidated: Vec::new(),\n            errors: Vec::new(),\n        }\n    }\n\n    pub fn total_events(&self) -> usize {\n        self.created.len() + self.updated.len() + self.invalidated.len()\n    }\n\n    pub fn has_errors(&self) -> bool {\n        !self.errors.is_empty()\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct SummarySyncError {\n    pub entry_id: String,\n    pub layer: MemoryLayer,\n    pub depth: Option<SummaryDepth>,\n    pub message: String,\n}\n\npub struct IncrementalSummarySync {\n    config_by_layer: HashMap<MemoryLayer, SummaryConfig>,\n    change_counts: HashMap<String, u32>,\n}\n\nimpl Default for IncrementalSummarySync {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\nimpl IncrementalSummarySync {\n    pub fn new() -> Self {\n        Self {\n            config_by_layer: HashMap::new(),\n            change_counts: HashMap::new(),\n        }\n    }\n\n    pub fn with_config(mut self, config: SummaryConfig) -> Self {\n        self.config_by_layer.insert(config.layer, config);\n        self\n    }\n\n    pub fn set_config(&mut self, config: SummaryConfig) {\n        self.config_by_layer.insert(config.layer, config);\n    }\n\n    pub fn get_config(&self, layer: MemoryLayer) -> Option<&SummaryConfig> {\n        self.config_by_layer.get(&layer)\n    }\n\n    pub fn record_change(&mut self, entry_id: &str) {\n        *self.change_counts.entry(entry_id.to_string()).or_insert(0) += 1;\n    }\n\n    pub fn reset_change_count(&mut self, entry_id: &str) {\n        self.change_counts.remove(entry_id);\n    }\n\n    pub fn get_change_count(&self, entry_id: &str) -> u32 {\n        self.change_counts.get(entry_id).copied().unwrap_or(0)\n    }\n\n    pub fn check_triggers(\n        &self,\n        entry_id: &str,\n        layer: MemoryLayer,\n        current_source_hash: &str,\n        state: &SummaryPointerState,\n        now: i64,\n    ) -> Vec<SummarySyncTrigger> {\n        let mut triggers = Vec::new();\n        let config = match self.config_by_layer.get(&layer) {\n            Some(c) => c,\n            None => return triggers,\n        };\n\n        for depth in &config.depths {\n            if let Some(ptr) = state.get_pointer(entry_id, *depth) {\n                if ptr.source_content_hash != current_source_hash {\n                    triggers.push(SummarySyncTrigger::SourceContentChanged {\n                        entry_id: entry_id.to_string(),\n                        layer,\n                        previous_hash: ptr.source_content_hash.clone(),\n                        new_hash: current_source_hash.to_string(),\n                    });\n                    break;\n                }\n\n                if let Some(interval) = config.update_interval_secs {\n                    let age = (now - ptr.synced_at) as u64;\n                    if age >= interval {\n                        triggers.push(SummarySyncTrigger::TimeThresholdExceeded {\n                            entry_id: entry_id.to_string(),\n                            layer,\n                            age_seconds: age,\n                            threshold_seconds: interval,\n                        });\n                        break;\n                    }\n                }\n\n                if let Some(threshold) = config.update_on_changes {\n                    let count = self.get_change_count(entry_id);\n                    if count >= threshold {\n                        triggers.push(SummarySyncTrigger::ChangeCountExceeded {\n                            entry_id: entry_id.to_string(),\n                            layer,\n                            change_count: count,\n                            threshold,\n                        });\n                        break;\n                    }\n                }\n            } else {\n                triggers.push(SummarySyncTrigger::ManualRefresh {\n                    entry_id: entry_id.to_string(),\n                    layer,\n                });\n                break;\n            }\n        }\n\n        triggers\n    }\n\n    pub fn sync_summary(\n        &mut self,\n        entry_id: &str,\n        layer: MemoryLayer,\n        depth: SummaryDepth,\n        summary: &LayerSummary,\n        source_content_hash: &str,\n        state: &mut SummaryPointerState,\n    ) -> Option<SummarySyncEvent> {\n        let now = chrono::Utc::now().timestamp();\n        let content_hash = utils::compute_content_hash(&summary.content);\n\n        if let Some(existing) = state.get_pointer(entry_id, depth) {\n            if existing.content_hash == content_hash && !existing.is_stale {\n                return None;\n            }\n\n            let reason = if existing.source_content_hash != source_content_hash {\n                SummaryUpdateReason::SourceContentChanged\n            } else if existing.is_stale {\n                SummaryUpdateReason::ScheduledUpdate\n            } else {\n                SummaryUpdateReason::ManualRefresh\n            };\n\n            let previous_hash = existing.content_hash.clone();\n\n            let ptr = SummaryPointer::new(\n                entry_id.to_string(),\n                layer,\n                depth,\n                content_hash.clone(),\n                source_content_hash.to_string(),\n                summary.token_count,\n            );\n            state.set_pointer(ptr);\n\n            self.reset_change_count(entry_id);\n\n            Some(SummarySyncEvent::Updated(SummaryUpdated {\n                entry_id: entry_id.to_string(),\n                layer,\n                depth,\n                previous_hash,\n                new_hash: content_hash,\n                token_count: summary.token_count,\n                updated_at: now,\n                reason,\n            }))\n        } else {\n            let ptr = SummaryPointer::new(\n                entry_id.to_string(),\n                layer,\n                depth,\n                content_hash.clone(),\n                source_content_hash.to_string(),\n                summary.token_count,\n            );\n            state.set_pointer(ptr);\n\n            self.reset_change_count(entry_id);\n\n            Some(SummarySyncEvent::Created(SummaryCreated {\n                entry_id: entry_id.to_string(),\n                layer,\n                depth,\n                content_hash,\n                token_count: summary.token_count,\n                created_at: now,\n            }))\n        }\n    }\n\n    pub fn invalidate_summaries(\n        &self,\n        entry_id: &str,\n        layer: MemoryLayer,\n        reason: InvalidationReason,\n        state: &mut SummaryPointerState,\n    ) -> Option<SummarySyncEvent> {\n        let count = state.mark_all_stale_for_entry(entry_id);\n        if count == 0 {\n            return None;\n        }\n\n        let depths: Vec<SummaryDepth> = state\n            .pointers\n            .get(entry_id)\n            .map(|m| m.keys().copied().collect())\n            .unwrap_or_default();\n\n        let source_hash = state\n            .get_pointer(\n                entry_id,\n                depths.first().copied().unwrap_or(SummaryDepth::Sentence),\n            )\n            .map(|p| p.source_content_hash.clone());\n\n        Some(SummarySyncEvent::Invalidated(SummaryInvalidated {\n            entry_id: entry_id.to_string(),\n            layer,\n            depths,\n            reason,\n            invalidated_at: chrono::Utc::now().timestamp(),\n            source_content_hash: source_hash,\n        }))\n    }\n\n    pub fn invalidate_on_source_change(\n        &self,\n        entry_id: &str,\n        layer: MemoryLayer,\n        previous_hash: &str,\n        new_hash: &str,\n        state: &mut SummaryPointerState,\n    ) -> Option<SummarySyncEvent> {\n        let config = self.config_by_layer.get(&layer)?;\n\n        if config.skip_if_unchanged {\n            return None;\n        }\n\n        self.invalidate_summaries(\n            entry_id,\n            layer,\n            InvalidationReason::SourceContentChanged {\n                previous_hash: previous_hash.to_string(),\n                new_hash: new_hash.to_string(),\n            },\n            state,\n        )\n    }\n\n    pub fn get_entries_needing_sync(\n        &self,\n        layer: MemoryLayer,\n        source_hashes: &HashMap<String, String>,\n        state: &SummaryPointerState,\n        now: i64,\n    ) -> Vec<String> {\n        let config = match self.config_by_layer.get(&layer) {\n            Some(c) => c,\n            None => return Vec::new(),\n        };\n\n        let mut needs_sync = Vec::new();\n\n        for (entry_id, source_hash) in source_hashes {\n            let mut entry_needs_sync = false;\n\n            for depth in &config.depths {\n                if let Some(ptr) = state.get_pointer(entry_id, *depth) {\n                    if ptr.is_stale || ptr.source_content_hash != *source_hash {\n                        entry_needs_sync = true;\n                        break;\n                    }\n\n                    if let Some(interval) = config.update_interval_secs {\n                        let age = (now - ptr.synced_at) as u64;\n                        if age >= interval {\n                            entry_needs_sync = true;\n                            break;\n                        }\n                    }\n\n                    if let Some(threshold) = config.update_on_changes {\n                        if self.get_change_count(entry_id) >= threshold {\n                            entry_needs_sync = true;\n                            break;\n                        }\n                    }\n                } else {\n                    entry_needs_sync = true;\n                    break;\n                }\n            }\n\n            if entry_needs_sync {\n                needs_sync.push(entry_id.clone());\n            }\n        }\n\n        needs_sync\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    fn create_test_config(layer: MemoryLayer) -> SummaryConfig {\n        SummaryConfig {\n            layer,\n            update_interval_secs: Some(3600),\n            update_on_changes: Some(10),\n            skip_if_unchanged: false,\n            personalized: false,\n            depths: vec![SummaryDepth::Sentence, SummaryDepth::Paragraph],\n        }\n    }\n\n    fn create_test_summary(depth: SummaryDepth) -> LayerSummary {\n        LayerSummary {\n            depth,\n            content: \"Test summary content\".to_string(),\n            token_count: match depth {\n                SummaryDepth::Sentence => 50,\n                SummaryDepth::Paragraph => 200,\n                SummaryDepth::Detailed => 500,\n            },\n            generated_at: chrono::Utc::now().timestamp(),\n            source_hash: \"source-hash\".to_string(),\n            content_hash: None,\n            personalized: false,\n            personalization_context: None,\n        }\n    }\n\n    #[test]\n    fn test_incremental_sync_new() {\n        let sync = IncrementalSummarySync::new();\n        assert!(sync.config_by_layer.is_empty());\n        assert!(sync.change_counts.is_empty());\n    }\n\n    #[test]\n    fn test_incremental_sync_with_config() {\n        let config = create_test_config(MemoryLayer::Project);\n        let sync = IncrementalSummarySync::new().with_config(config);\n\n        assert!(sync.get_config(MemoryLayer::Project).is_some());\n        assert!(sync.get_config(MemoryLayer::Team).is_none());\n    }\n\n    #[test]\n    fn test_record_change() {\n        let mut sync = IncrementalSummarySync::new();\n\n        assert_eq!(sync.get_change_count(\"entry-1\"), 0);\n        sync.record_change(\"entry-1\");\n        assert_eq!(sync.get_change_count(\"entry-1\"), 1);\n        sync.record_change(\"entry-1\");\n        assert_eq!(sync.get_change_count(\"entry-1\"), 2);\n    }\n\n    #[test]\n    fn test_reset_change_count() {\n        let mut sync = IncrementalSummarySync::new();\n\n        sync.record_change(\"entry-1\");\n        sync.record_change(\"entry-1\");\n        assert_eq!(sync.get_change_count(\"entry-1\"), 2);\n\n        sync.reset_change_count(\"entry-1\");\n        assert_eq!(sync.get_change_count(\"entry-1\"), 0);\n    }\n\n    #[test]\n    fn test_check_triggers_source_changed() {\n        let config = create_test_config(MemoryLayer::Project);\n        let sync = IncrementalSummarySync::new().with_config(config);\n\n        let mut state = SummaryPointerState::default();\n        let ptr = SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            \"hash\".to_string(),\n            \"old-source\".to_string(),\n            50,\n        );\n        state.set_pointer(ptr);\n\n        let triggers = sync.check_triggers(\n            \"entry-1\",\n            MemoryLayer::Project,\n            \"new-source\",\n            &state,\n            chrono::Utc::now().timestamp(),\n        );\n\n        assert_eq!(triggers.len(), 1);\n        matches!(triggers[0], SummarySyncTrigger::SourceContentChanged { .. });\n    }\n\n    #[test]\n    fn test_check_triggers_no_existing_pointer() {\n        let config = create_test_config(MemoryLayer::Project);\n        let sync = IncrementalSummarySync::new().with_config(config);\n        let state = SummaryPointerState::default();\n\n        let triggers = sync.check_triggers(\n            \"entry-1\",\n            MemoryLayer::Project,\n            \"source-hash\",\n            &state,\n            chrono::Utc::now().timestamp(),\n        );\n\n        assert_eq!(triggers.len(), 1);\n        matches!(triggers[0], SummarySyncTrigger::ManualRefresh { .. });\n    }\n\n    #[test]\n    fn test_check_triggers_time_exceeded() {\n        let config = create_test_config(MemoryLayer::Project);\n        let sync = IncrementalSummarySync::new().with_config(config);\n\n        let mut state = SummaryPointerState::default();\n        let mut ptr = SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            \"hash\".to_string(),\n            \"source\".to_string(),\n            50,\n        );\n        ptr.synced_at = chrono::Utc::now().timestamp() - 7200;\n        state.set_pointer(ptr);\n\n        let triggers = sync.check_triggers(\n            \"entry-1\",\n            MemoryLayer::Project,\n            \"source\",\n            &state,\n            chrono::Utc::now().timestamp(),\n        );\n\n        assert_eq!(triggers.len(), 1);\n        matches!(\n            triggers[0],\n            SummarySyncTrigger::TimeThresholdExceeded { .. }\n        );\n    }\n\n    #[test]\n    fn test_sync_summary_create_new() {\n        let config = create_test_config(MemoryLayer::Project);\n        let mut sync = IncrementalSummarySync::new().with_config(config);\n        let mut state = SummaryPointerState::default();\n\n        let summary = create_test_summary(SummaryDepth::Sentence);\n        let event = sync.sync_summary(\n            \"entry-1\",\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            &summary,\n            \"source-hash\",\n            &mut state,\n        );\n\n        assert!(event.is_some());\n        matches!(event.unwrap(), SummarySyncEvent::Created(_));\n        assert_eq!(state.total_summaries, 1);\n    }\n\n    #[test]\n    fn test_sync_summary_update_existing() {\n        let config = create_test_config(MemoryLayer::Project);\n        let mut sync = IncrementalSummarySync::new().with_config(config);\n        let mut state = SummaryPointerState::default();\n\n        let ptr = SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            \"old-hash\".to_string(),\n            \"old-source\".to_string(),\n            40,\n        );\n        state.set_pointer(ptr);\n\n        let summary = create_test_summary(SummaryDepth::Sentence);\n        let event = sync.sync_summary(\n            \"entry-1\",\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            &summary,\n            \"new-source\",\n            &mut state,\n        );\n\n        assert!(event.is_some());\n        matches!(event.unwrap(), SummarySyncEvent::Updated(_));\n    }\n\n    #[test]\n    fn test_sync_summary_no_change() {\n        let config = create_test_config(MemoryLayer::Project);\n        let mut sync = IncrementalSummarySync::new().with_config(config);\n        let mut state = SummaryPointerState::default();\n\n        let summary = create_test_summary(SummaryDepth::Sentence);\n        let content_hash = utils::compute_content_hash(&summary.content);\n\n        let ptr = SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            content_hash,\n            \"source-hash\".to_string(),\n            50,\n        );\n        state.set_pointer(ptr);\n\n        let event = sync.sync_summary(\n            \"entry-1\",\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            &summary,\n            \"source-hash\",\n            &mut state,\n        );\n\n        assert!(event.is_none());\n    }\n\n    #[test]\n    fn test_invalidate_summaries() {\n        let config = create_test_config(MemoryLayer::Project);\n        let sync = IncrementalSummarySync::new().with_config(config);\n        let mut state = SummaryPointerState::default();\n\n        state.set_pointer(SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            \"hash1\".to_string(),\n            \"source\".to_string(),\n            50,\n        ));\n        state.set_pointer(SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Paragraph,\n            \"hash2\".to_string(),\n            \"source\".to_string(),\n            200,\n        ));\n\n        let event = sync.invalidate_summaries(\n            \"entry-1\",\n            MemoryLayer::Project,\n            InvalidationReason::ManualInvalidation,\n            &mut state,\n        );\n\n        assert!(event.is_some());\n        assert_eq!(state.stale_count, 2);\n\n        if let Some(SummarySyncEvent::Invalidated(inv)) = event {\n            assert_eq!(inv.entry_id, \"entry-1\");\n            assert_eq!(inv.depths.len(), 2);\n        } else {\n            panic!(\"Expected Invalidated event\");\n        }\n    }\n\n    #[test]\n    fn test_invalidate_on_source_change() {\n        let config = create_test_config(MemoryLayer::Project);\n        let sync = IncrementalSummarySync::new().with_config(config);\n        let mut state = SummaryPointerState::default();\n\n        state.set_pointer(SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            \"hash\".to_string(),\n            \"old-source\".to_string(),\n            50,\n        ));\n\n        let event = sync.invalidate_on_source_change(\n            \"entry-1\",\n            MemoryLayer::Project,\n            \"old-source\",\n            \"new-source\",\n            &mut state,\n        );\n\n        assert!(event.is_some());\n        assert_eq!(state.stale_count, 1);\n    }\n\n    #[test]\n    fn test_get_entries_needing_sync() {\n        let config = create_test_config(MemoryLayer::Project);\n        let sync = IncrementalSummarySync::new().with_config(config);\n        let mut state = SummaryPointerState::default();\n\n        state.set_pointer(SummaryPointer::new(\n            \"entry-1\".to_string(),\n            MemoryLayer::Project,\n            SummaryDepth::Sentence,\n            \"hash\".to_string(),\n            \"source-1\".to_string(),\n            50,\n        ));\n\n        let mut source_hashes = HashMap::new();\n        source_hashes.insert(\"entry-1\".to_string(), \"source-1\".to_string());\n        source_hashes.insert(\"entry-2\".to_string(), \"source-2\".to_string());\n        source_hashes.insert(\"entry-3\".to_string(), \"new-source\".to_string());\n\n        let needs_sync = sync.get_entries_needing_sync(\n            MemoryLayer::Project,\n            &source_hashes,\n            &state,\n            chrono::Utc::now().timestamp(),\n        );\n\n        assert!(needs_sync.contains(&\"entry-2\".to_string()));\n        assert!(needs_sync.contains(&\"entry-3\".to_string()));\n    }\n\n    #[test]\n    fn test_summary_sync_result() {\n        let mut result = SummarySyncResult::new();\n        assert_eq!(result.total_events(), 0);\n        assert!(!result.has_errors());\n\n        result\n            .created\n            .push(SummarySyncEvent::Created(SummaryCreated {\n                entry_id: \"entry-1\".to_string(),\n                layer: MemoryLayer::Project,\n                depth: SummaryDepth::Sentence,\n                content_hash: \"hash\".to_string(),\n                token_count: 50,\n                created_at: 0,\n            }));\n\n        assert_eq!(result.total_events(), 1);\n\n        result.errors.push(SummarySyncError {\n            entry_id: \"entry-2\".to_string(),\n            layer: MemoryLayer::Project,\n            depth: None,\n            message: \"Test error\".to_string(),\n        });\n\n        assert!(result.has_errors());\n    }\n}\n","traces":[{"line":18,"address":[],"length":0,"stats":{"Line":0}},{"line":19,"address":[],"length":0,"stats":{"Line":0}},{"line":24,"address":[],"length":0,"stats":{"Line":1}},{"line":26,"address":[],"length":0,"stats":{"Line":2}},{"line":27,"address":[],"length":0,"stats":{"Line":2}},{"line":28,"address":[],"length":0,"stats":{"Line":1}},{"line":29,"address":[],"length":0,"stats":{"Line":1}},{"line":33,"address":[],"length":0,"stats":{"Line":2}},{"line":34,"address":[],"length":0,"stats":{"Line":8}},{"line":37,"address":[],"length":0,"stats":{"Line":2}},{"line":38,"address":[],"length":0,"stats":{"Line":2}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":13}},{"line":64,"address":[],"length":0,"stats":{"Line":13}},{"line":65,"address":[],"length":0,"stats":{"Line":13}},{"line":69,"address":[],"length":0,"stats":{"Line":10}},{"line":70,"address":[],"length":0,"stats":{"Line":40}},{"line":71,"address":[],"length":0,"stats":{"Line":10}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":2}},{"line":79,"address":[],"length":0,"stats":{"Line":6}},{"line":82,"address":[],"length":0,"stats":{"Line":4}},{"line":83,"address":[],"length":0,"stats":{"Line":16}},{"line":86,"address":[],"length":0,"stats":{"Line":3}},{"line":87,"address":[],"length":0,"stats":{"Line":9}},{"line":90,"address":[],"length":0,"stats":{"Line":6}},{"line":91,"address":[],"length":0,"stats":{"Line":30}},{"line":94,"address":[],"length":0,"stats":{"Line":3}},{"line":102,"address":[],"length":0,"stats":{"Line":6}},{"line":103,"address":[],"length":0,"stats":{"Line":9}},{"line":104,"address":[],"length":0,"stats":{"Line":6}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":6}},{"line":109,"address":[],"length":0,"stats":{"Line":11}},{"line":110,"address":[],"length":0,"stats":{"Line":2}},{"line":111,"address":[],"length":0,"stats":{"Line":3}},{"line":112,"address":[],"length":0,"stats":{"Line":3}},{"line":113,"address":[],"length":0,"stats":{"Line":2}},{"line":114,"address":[],"length":0,"stats":{"Line":3}},{"line":115,"address":[],"length":0,"stats":{"Line":1}},{"line":117,"address":[],"length":0,"stats":{"Line":1}},{"line":120,"address":[],"length":0,"stats":{"Line":2}},{"line":121,"address":[],"length":0,"stats":{"Line":2}},{"line":122,"address":[],"length":0,"stats":{"Line":1}},{"line":123,"address":[],"length":0,"stats":{"Line":3}},{"line":124,"address":[],"length":0,"stats":{"Line":3}},{"line":125,"address":[],"length":0,"stats":{"Line":2}},{"line":126,"address":[],"length":0,"stats":{"Line":1}},{"line":127,"address":[],"length":0,"stats":{"Line":1}},{"line":129,"address":[],"length":0,"stats":{"Line":1}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":3}},{"line":147,"address":[],"length":0,"stats":{"Line":2}},{"line":148,"address":[],"length":0,"stats":{"Line":1}},{"line":150,"address":[],"length":0,"stats":{"Line":1}},{"line":154,"address":[],"length":0,"stats":{"Line":3}},{"line":157,"address":[],"length":0,"stats":{"Line":3}},{"line":166,"address":[],"length":0,"stats":{"Line":9}},{"line":167,"address":[],"length":0,"stats":{"Line":9}},{"line":169,"address":[],"length":0,"stats":{"Line":11}},{"line":170,"address":[],"length":0,"stats":{"Line":3}},{"line":171,"address":[],"length":0,"stats":{"Line":1}},{"line":174,"address":[],"length":0,"stats":{"Line":2}},{"line":175,"address":[],"length":0,"stats":{"Line":1}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":3}},{"line":185,"address":[],"length":0,"stats":{"Line":2}},{"line":186,"address":[],"length":0,"stats":{"Line":1}},{"line":187,"address":[],"length":0,"stats":{"Line":1}},{"line":188,"address":[],"length":0,"stats":{"Line":2}},{"line":189,"address":[],"length":0,"stats":{"Line":2}},{"line":190,"address":[],"length":0,"stats":{"Line":1}},{"line":192,"address":[],"length":0,"stats":{"Line":3}},{"line":194,"address":[],"length":0,"stats":{"Line":3}},{"line":196,"address":[],"length":0,"stats":{"Line":1}},{"line":197,"address":[],"length":0,"stats":{"Line":3}},{"line":198,"address":[],"length":0,"stats":{"Line":2}},{"line":199,"address":[],"length":0,"stats":{"Line":2}},{"line":200,"address":[],"length":0,"stats":{"Line":2}},{"line":201,"address":[],"length":0,"stats":{"Line":2}},{"line":202,"address":[],"length":0,"stats":{"Line":2}},{"line":203,"address":[],"length":0,"stats":{"Line":1}},{"line":204,"address":[],"length":0,"stats":{"Line":1}},{"line":208,"address":[],"length":0,"stats":{"Line":2}},{"line":209,"address":[],"length":0,"stats":{"Line":1}},{"line":210,"address":[],"length":0,"stats":{"Line":1}},{"line":211,"address":[],"length":0,"stats":{"Line":2}},{"line":212,"address":[],"length":0,"stats":{"Line":2}},{"line":213,"address":[],"length":0,"stats":{"Line":1}},{"line":215,"address":[],"length":0,"stats":{"Line":3}},{"line":217,"address":[],"length":0,"stats":{"Line":3}},{"line":219,"address":[],"length":0,"stats":{"Line":1}},{"line":220,"address":[],"length":0,"stats":{"Line":3}},{"line":221,"address":[],"length":0,"stats":{"Line":2}},{"line":222,"address":[],"length":0,"stats":{"Line":2}},{"line":223,"address":[],"length":0,"stats":{"Line":2}},{"line":224,"address":[],"length":0,"stats":{"Line":1}},{"line":225,"address":[],"length":0,"stats":{"Line":1}},{"line":230,"address":[],"length":0,"stats":{"Line":2}},{"line":237,"address":[],"length":0,"stats":{"Line":8}},{"line":238,"address":[],"length":0,"stats":{"Line":2}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":242,"address":[],"length":0,"stats":{"Line":6}},{"line":243,"address":[],"length":0,"stats":{"Line":2}},{"line":244,"address":[],"length":0,"stats":{"Line":4}},{"line":245,"address":[],"length":0,"stats":{"Line":10}},{"line":248,"address":[],"length":0,"stats":{"Line":4}},{"line":250,"address":[],"length":0,"stats":{"Line":2}},{"line":251,"address":[],"length":0,"stats":{"Line":8}},{"line":253,"address":[],"length":0,"stats":{"Line":6}},{"line":255,"address":[],"length":0,"stats":{"Line":2}},{"line":256,"address":[],"length":0,"stats":{"Line":6}},{"line":257,"address":[],"length":0,"stats":{"Line":4}},{"line":258,"address":[],"length":0,"stats":{"Line":4}},{"line":259,"address":[],"length":0,"stats":{"Line":4}},{"line":260,"address":[],"length":0,"stats":{"Line":4}},{"line":261,"address":[],"length":0,"stats":{"Line":2}},{"line":265,"address":[],"length":0,"stats":{"Line":1}},{"line":273,"address":[],"length":0,"stats":{"Line":4}},{"line":275,"address":[],"length":0,"stats":{"Line":1}},{"line":276,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":2}},{"line":280,"address":[],"length":0,"stats":{"Line":1}},{"line":281,"address":[],"length":0,"stats":{"Line":1}},{"line":282,"address":[],"length":0,"stats":{"Line":1}},{"line":283,"address":[],"length":0,"stats":{"Line":3}},{"line":284,"address":[],"length":0,"stats":{"Line":1}},{"line":286,"address":[],"length":0,"stats":{"Line":1}},{"line":290,"address":[],"length":0,"stats":{"Line":1}},{"line":297,"address":[],"length":0,"stats":{"Line":3}},{"line":298,"address":[],"length":0,"stats":{"Line":2}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":2}},{"line":304,"address":[],"length":0,"stats":{"Line":10}},{"line":305,"address":[],"length":0,"stats":{"Line":6}},{"line":307,"address":[],"length":0,"stats":{"Line":8}},{"line":308,"address":[],"length":0,"stats":{"Line":13}},{"line":309,"address":[],"length":0,"stats":{"Line":2}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":314,"address":[],"length":0,"stats":{"Line":2}},{"line":315,"address":[],"length":0,"stats":{"Line":2}},{"line":316,"address":[],"length":0,"stats":{"Line":1}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":2}},{"line":323,"address":[],"length":0,"stats":{"Line":3}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":325,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":3}},{"line":330,"address":[],"length":0,"stats":{"Line":3}},{"line":334,"address":[],"length":0,"stats":{"Line":6}},{"line":335,"address":[],"length":0,"stats":{"Line":9}},{"line":339,"address":[],"length":0,"stats":{"Line":1}}],"covered":138,"coverable":166},{"path":["/","Users","christian.klat","dev","git","aeterna","test-project","src","main.rs"],"content":"fn main() {\n    println!(\"Hello, world!\");\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","testing","src","fixtures.rs"],"content":"use std::sync::atomic::{AtomicU32, Ordering};\nuse testcontainers::core::{ContainerPort, WaitFor};\nuse testcontainers::{ContainerAsync, GenericImage, ImageExt, runners::AsyncRunner};\nuse testcontainers_modules::postgres::Postgres;\nuse testcontainers_modules::redis::Redis;\nuse tokio::sync::OnceCell;\n\nstatic TEST_COUNTER: AtomicU32 = AtomicU32::new(0);\n\npub fn unique_id(prefix: &str) -> String {\n    let id = TEST_COUNTER.fetch_add(1, Ordering::SeqCst);\n    format!(\"{}-{}\", prefix, id)\n}\n\npub fn unique_tenant_id() -> String {\n    unique_id(\"test-tenant\")\n}\n\npub struct PostgresFixture {\n    #[allow(dead_code)]\n    container: ContainerAsync<Postgres>,\n    url: String,\n}\n\nimpl PostgresFixture {\n    pub fn url(&self) -> &str {\n        &self.url\n    }\n}\n\nstatic POSTGRES: OnceCell<Option<PostgresFixture>> = OnceCell::const_new();\n\npub async fn postgres() -> Option<&'static PostgresFixture> {\n    POSTGRES\n        .get_or_init(|| async {\n            let container_result = Postgres::default()\n                .with_db_name(\"testdb\")\n                .with_user(\"testuser\")\n                .with_password(\"testpass\")\n                .start()\n                .await;\n\n            match container_result {\n                Ok(container) => {\n                    let port = container.get_host_port_ipv4(5432).await.ok()?;\n                    let url = format!(\"postgres://testuser:testpass@localhost:{}/testdb\", port);\n                    tracing::info!(\"PostgreSQL fixture started on port {}\", port);\n                    Some(PostgresFixture { container, url })\n                }\n                Err(e) => {\n                    tracing::warn!(\"Failed to start PostgreSQL container: {:?}\", e);\n                    None\n                }\n            }\n        })\n        .await\n        .as_ref()\n}\n\npub struct RedisFixture {\n    #[allow(dead_code)]\n    container: ContainerAsync<Redis>,\n    url: String,\n}\n\nimpl RedisFixture {\n    pub fn url(&self) -> &str {\n        &self.url\n    }\n}\n\nstatic REDIS: OnceCell<Option<RedisFixture>> = OnceCell::const_new();\n\npub async fn redis() -> Option<&'static RedisFixture> {\n    REDIS\n        .get_or_init(|| async {\n            match Redis::default().start().await {\n                Ok(container) => {\n                    let port = match container.get_host_port_ipv4(6379).await {\n                        Ok(p) => p,\n                        Err(e) => {\n                            tracing::warn!(\"Failed to get Redis port: {:?}\", e);\n                            return None;\n                        }\n                    };\n                    let url = format!(\"redis://localhost:{}\", port);\n\n                    if let Err(e) = verify_redis_connection(&url).await {\n                        tracing::warn!(\"Redis connection verification failed: {:?}\", e);\n                        return None;\n                    }\n\n                    tracing::info!(\"Redis fixture started on port {}\", port);\n                    Some(RedisFixture { container, url })\n                }\n                Err(e) => {\n                    tracing::warn!(\"Failed to start Redis container: {:?}\", e);\n                    None\n                }\n            }\n        })\n        .await\n        .as_ref()\n}\n\nasync fn verify_redis_connection(url: &str) -> Result<(), Box<dyn std::error::Error>> {\n    let client = redis::Client::open(url)?;\n    let mut conn = client.get_multiplexed_async_connection().await?;\n    let _: String = redis::cmd(\"PING\").query_async(&mut conn).await?;\n    Ok(())\n}\n\npub struct QdrantFixture {\n    #[allow(dead_code)]\n    container: ContainerAsync<GenericImage>,\n    grpc_url: String,\n    http_url: String,\n}\n\nimpl QdrantFixture {\n    pub fn grpc_url(&self) -> &str {\n        &self.grpc_url\n    }\n\n    pub fn http_url(&self) -> &str {\n        &self.http_url\n    }\n\n    #[deprecated(note = \"Use grpc_url() for gRPC (6334) or http_url() for REST (6333)\")]\n    pub fn url(&self) -> &str {\n        &self.grpc_url\n    }\n}\n\nstatic QDRANT: OnceCell<Option<QdrantFixture>> = OnceCell::const_new();\n\npub async fn qdrant() -> Option<&'static QdrantFixture> {\n    QDRANT\n        .get_or_init(|| async {\n            let container_result = GenericImage::new(\"qdrant/qdrant\", \"latest\")\n                .with_exposed_port(ContainerPort::Tcp(6333))\n                .with_exposed_port(ContainerPort::Tcp(6334))\n                // Wait for gRPC to be ready (appears after HTTP)\n                .with_wait_for(WaitFor::message_on_stdout(\"Qdrant gRPC listening on 6334\"))\n                .with_startup_timeout(std::time::Duration::from_secs(60))\n                .start()\n                .await;\n\n            match container_result {\n                Ok(container) => {\n                    let http_port = container.get_host_port_ipv4(6333).await.ok()?;\n                    let grpc_port = container.get_host_port_ipv4(6334).await.ok()?;\n                    let http_url = format!(\"http://localhost:{}\", http_port);\n                    let grpc_url = format!(\"http://localhost:{}\", grpc_port);\n\n                    // Brief delay for gRPC to fully initialize\n                    tokio::time::sleep(std::time::Duration::from_millis(500)).await;\n\n                    tracing::info!(\n                        \"Qdrant fixture started - HTTP: {}, gRPC: {}\",\n                        http_port,\n                        grpc_port\n                    );\n\n                    if let Err(e) = verify_qdrant_connection(&http_url).await {\n                        tracing::warn!(\"Qdrant connection verification failed: {:?}\", e);\n                        return None;\n                    }\n\n                    Some(QdrantFixture {\n                        container,\n                        grpc_url,\n                        http_url,\n                    })\n                }\n                Err(e) => {\n                    tracing::warn!(\"Failed to start Qdrant container: {:?}\", e);\n                    None\n                }\n            }\n        })\n        .await\n        .as_ref()\n}\n\nasync fn verify_qdrant_connection(http_url: &str) -> Result<(), Box<dyn std::error::Error>> {\n    let health_url = format!(\"{}/healthz\", http_url);\n    for attempt in 0..10 {\n        match reqwest::get(&health_url).await {\n            Ok(resp) if resp.status().is_success() => return Ok(()),\n            _ => {\n                if attempt < 9 {\n                    tokio::time::sleep(std::time::Duration::from_millis(200)).await;\n                }\n            }\n        }\n    }\n    Err(\"Qdrant health check failed after 10 attempts\".into())\n}\n\npub const MINIO_ACCESS_KEY: &str = \"minioadmin\";\npub const MINIO_SECRET_KEY: &str = \"minioadmin\";\npub const MINIO_DEFAULT_BUCKET: &str = \"aeterna-test\";\n\npub struct MinioFixture {\n    #[allow(dead_code)]\n    container: ContainerAsync<GenericImage>,\n    endpoint: String,\n}\n\nimpl MinioFixture {\n    pub fn endpoint(&self) -> &str {\n        &self.endpoint\n    }\n\n    pub fn access_key(&self) -> &str {\n        MINIO_ACCESS_KEY\n    }\n\n    pub fn secret_key(&self) -> &str {\n        MINIO_SECRET_KEY\n    }\n}\n\nstatic MINIO: OnceCell<Option<MinioFixture>> = OnceCell::const_new();\n\npub async fn minio() -> Option<&'static MinioFixture> {\n    MINIO\n        .get_or_init(|| async {\n            let image = GenericImage::new(\"minio/minio\", \"latest\")\n                .with_exposed_port(ContainerPort::Tcp(9000))\n                .with_wait_for(WaitFor::message_on_stdout(\"API:\"));\n\n            let container_result = image\n                .with_env_var(\"MINIO_ROOT_USER\", MINIO_ACCESS_KEY)\n                .with_env_var(\"MINIO_ROOT_PASSWORD\", MINIO_SECRET_KEY)\n                .with_cmd(vec![\"server\", \"/data\"])\n                .start()\n                .await;\n\n            match container_result {\n                Ok(container) => {\n                    let port = container.get_host_port_ipv4(9000).await.ok()?;\n                    let endpoint = format!(\"http://localhost:{}\", port);\n                    tracing::info!(\"MinIO fixture started on port {}\", port);\n                    Some(MinioFixture {\n                        container,\n                        endpoint,\n                    })\n                }\n                Err(e) => {\n                    tracing::warn!(\"Failed to start MinIO container: {:?}\", e);\n                    None\n                }\n            }\n        })\n        .await\n        .as_ref()\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_unique_id_generation() {\n        let id1 = unique_id(\"test\");\n        let id2 = unique_id(\"test\");\n        assert_ne!(id1, id2);\n        assert!(id1.starts_with(\"test-\"));\n        assert!(id2.starts_with(\"test-\"));\n    }\n}\n","traces":[{"line":10,"address":[],"length":0,"stats":{"Line":160}},{"line":11,"address":[],"length":0,"stats":{"Line":640}},{"line":12,"address":[],"length":0,"stats":{"Line":320}},{"line":15,"address":[],"length":0,"stats":{"Line":0}},{"line":16,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":82}},{"line":27,"address":[],"length":0,"stats":{"Line":82}},{"line":33,"address":[],"length":0,"stats":{"Line":176}},{"line":34,"address":[],"length":0,"stats":{"Line":88}},{"line":35,"address":[],"length":0,"stats":{"Line":102}},{"line":36,"address":[],"length":0,"stats":{"Line":42}},{"line":37,"address":[],"length":0,"stats":{"Line":42}},{"line":38,"address":[],"length":0,"stats":{"Line":42}},{"line":39,"address":[],"length":0,"stats":{"Line":42}},{"line":40,"address":[],"length":0,"stats":{"Line":14}},{"line":41,"address":[],"length":0,"stats":{"Line":14}},{"line":43,"address":[],"length":0,"stats":{"Line":14}},{"line":44,"address":[],"length":0,"stats":{"Line":14}},{"line":45,"address":[],"length":0,"stats":{"Line":42}},{"line":46,"address":[],"length":0,"stats":{"Line":42}},{"line":47,"address":[],"length":0,"stats":{"Line":14}},{"line":48,"address":[],"length":0,"stats":{"Line":14}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":88}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":154}},{"line":75,"address":[],"length":0,"stats":{"Line":77}},{"line":76,"address":[],"length":0,"stats":{"Line":89}},{"line":77,"address":[],"length":0,"stats":{"Line":36}},{"line":78,"address":[],"length":0,"stats":{"Line":12}},{"line":79,"address":[],"length":0,"stats":{"Line":36}},{"line":80,"address":[],"length":0,"stats":{"Line":24}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":36}},{"line":88,"address":[],"length":0,"stats":{"Line":48}},{"line":89,"address":[],"length":0,"stats":{"Line":12}},{"line":90,"address":[],"length":0,"stats":{"Line":12}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":77}},{"line":106,"address":[],"length":0,"stats":{"Line":24}},{"line":107,"address":[],"length":0,"stats":{"Line":36}},{"line":108,"address":[],"length":0,"stats":{"Line":36}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":4}},{"line":122,"address":[],"length":0,"stats":{"Line":4}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":10}},{"line":138,"address":[],"length":0,"stats":{"Line":5}},{"line":139,"address":[],"length":0,"stats":{"Line":7}},{"line":140,"address":[],"length":0,"stats":{"Line":8}},{"line":141,"address":[],"length":0,"stats":{"Line":6}},{"line":142,"address":[],"length":0,"stats":{"Line":6}},{"line":144,"address":[],"length":0,"stats":{"Line":6}},{"line":145,"address":[],"length":0,"stats":{"Line":6}},{"line":146,"address":[],"length":0,"stats":{"Line":2}},{"line":147,"address":[],"length":0,"stats":{"Line":2}},{"line":149,"address":[],"length":0,"stats":{"Line":2}},{"line":150,"address":[],"length":0,"stats":{"Line":2}},{"line":151,"address":[],"length":0,"stats":{"Line":6}},{"line":152,"address":[],"length":0,"stats":{"Line":6}},{"line":153,"address":[],"length":0,"stats":{"Line":6}},{"line":154,"address":[],"length":0,"stats":{"Line":6}},{"line":157,"address":[],"length":0,"stats":{"Line":4}},{"line":159,"address":[],"length":0,"stats":{"Line":2}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":6}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":2}},{"line":171,"address":[],"length":0,"stats":{"Line":4}},{"line":172,"address":[],"length":0,"stats":{"Line":2}},{"line":173,"address":[],"length":0,"stats":{"Line":2}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":5}},{"line":186,"address":[],"length":0,"stats":{"Line":4}},{"line":187,"address":[],"length":0,"stats":{"Line":6}},{"line":188,"address":[],"length":0,"stats":{"Line":4}},{"line":189,"address":[],"length":0,"stats":{"Line":6}},{"line":190,"address":[],"length":0,"stats":{"Line":10}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":0}},{"line":221,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":12}},{"line":228,"address":[],"length":0,"stats":{"Line":6}},{"line":229,"address":[],"length":0,"stats":{"Line":7}},{"line":230,"address":[],"length":0,"stats":{"Line":3}},{"line":231,"address":[],"length":0,"stats":{"Line":2}},{"line":232,"address":[],"length":0,"stats":{"Line":2}},{"line":234,"address":[],"length":0,"stats":{"Line":3}},{"line":235,"address":[],"length":0,"stats":{"Line":2}},{"line":236,"address":[],"length":0,"stats":{"Line":2}},{"line":237,"address":[],"length":0,"stats":{"Line":4}},{"line":238,"address":[],"length":0,"stats":{"Line":1}},{"line":239,"address":[],"length":0,"stats":{"Line":1}},{"line":241,"address":[],"length":0,"stats":{"Line":1}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":1}},{"line":252,"address":[],"length":0,"stats":{"Line":1}},{"line":253,"address":[],"length":0,"stats":{"Line":1}},{"line":257,"address":[],"length":0,"stats":{"Line":6}}],"covered":84,"coverable":127},{"path":["/","Users","christian.klat","dev","git","aeterna","testing","src","lib.rs"],"content":"//! Shared test fixtures for Aeterna workspace.\n//!\n//! Provides single, shared instances of testcontainers across all test files:\n//! - PostgreSQL (port 5432)\n//! - Redis (port 6379)\n//! - Qdrant (ports 6333/6334)\n//! - MinIO (port 9000)\n//!\n//! Each fixture is lazily initialized once per test process and automatically\n//! cleaned up when the process exits.\n\nmod fixtures;\n\npub use fixtures::*;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","backend.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","bridge.rs"],"content":"use crate::tools::Tool;\nuse async_trait::async_trait;\nuse mk_core::types::TenantContext;\nuse schemars::JsonSchema;\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Value, json};\nuse std::sync::Arc;\nuse sync::bridge::SyncManager;\nuse validator::Validate;\n\npub struct SyncNowTool {\n    sync_manager: Arc<SyncManager>,\n}\n\nimpl SyncNowTool {\n    pub fn new(sync_manager: Arc<SyncManager>) -> Self {\n        Self { sync_manager }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct SyncNowparams {\n    #[serde(default)]\n    pub force: bool,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[async_trait]\nimpl Tool for SyncNowTool {\n    fn name(&self) -> &str {\n        \"sync_now\"\n    }\n\n    fn description(&self) -> &str {\n        \"Trigger manual synchronization between memory and knowledge systems.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"force\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Force full sync (ignore delta detection)\",\n                    \"default\": false\n                },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            }\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: SyncNowparams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        if p.force {\n            self.sync_manager.sync_all(ctx).await?;\n        } else {\n            self.sync_manager.sync_incremental(ctx).await?;\n        }\n\n        Ok(json!({\n            \"success\": true,\n            \"message\": \"Synchronization completed\"\n        }))\n    }\n}\n\npub struct SyncStatusTool {\n    sync_manager: Arc<SyncManager>,\n}\n\nimpl SyncStatusTool {\n    pub fn new(sync_manager: Arc<SyncManager>) -> Self {\n        Self { sync_manager }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct SyncStatusParams {\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[async_trait]\nimpl Tool for SyncStatusTool {\n    fn name(&self) -> &str {\n        \"sync_status\"\n    }\n\n    fn description(&self) -> &str {\n        \"Check the current sync status, including last sync time and health.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            }\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: SyncStatusParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let state = self.sync_manager.get_state(&ctx.tenant_id).await?;\n\n        Ok(json!({\n            \"success\": true,\n            \"healthy\": state.failed_items.is_empty() && state.federation_conflicts.is_empty(),\n            \"lastSyncAt\": state.last_sync_at,\n            \"failedItems\": state.failed_items.len(),\n            \"federationConflicts\": state.federation_conflicts,\n            \"stats\": {\n                \"totalSyncs\": state.stats.total_syncs,\n                \"totalItemsSynced\": state.stats.total_items_synced,\n                \"totalConflicts\": state.stats.total_conflicts,\n                \"totalGovernanceBlocks\": state.stats.total_governance_blocks,\n                \"avgSyncDurationMs\": state.stats.avg_sync_duration_ms,\n                \"driftScore\": state.stats.drift_score,\n                \"policyViolations\": state.stats.policy_violations\n            }\n        }))\n    }\n}\n\npub struct ResolveFederationConflictTool {\n    sync_manager: Arc<SyncManager>,\n}\n\nimpl ResolveFederationConflictTool {\n    pub fn new(sync_manager: Arc<SyncManager>) -> Self {\n        Self { sync_manager }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct ResolveFederationConflictParams {\n    pub upstream_id: String,\n    pub resolution: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[async_trait]\nimpl Tool for ResolveFederationConflictTool {\n    fn name(&self) -> &str {\n        \"knowledge_resolve_conflict\"\n    }\n\n    fn description(&self) -> &str {\n        \"Resolve a federation conflict by choosing a resolution strategy (ours, theirs, manual).\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"upstream_id\": {\n                    \"type\": \"string\",\n                    \"description\": \"ID of the upstream with conflict\"\n                },\n                \"resolution\": {\n                    \"type\": \"string\",\n                    \"description\": \"Resolution strategy: ours, theirs, or manual\",\n                    \"enum\": [\"ours\", \"theirs\", \"manual\"]\n                },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"upstream_id\", \"resolution\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: ResolveFederationConflictParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        self.sync_manager\n            .resolve_federation_conflict(ctx.tenant_id, &p.upstream_id, &p.resolution)\n            .await?;\n\n        Ok(json!({\n            \"success\": true,\n            \"message\": format!(\"Conflict for {} resolved as {}\", p.upstream_id, p.resolution)\n        }))\n    }\n}\n","traces":[{"line":16,"address":[],"length":0,"stats":{"Line":23}},{"line":31,"address":[],"length":0,"stats":{"Line":29}},{"line":32,"address":[],"length":0,"stats":{"Line":29}},{"line":35,"address":[],"length":0,"stats":{"Line":7}},{"line":36,"address":[],"length":0,"stats":{"Line":7}},{"line":39,"address":[],"length":0,"stats":{"Line":7}},{"line":40,"address":[],"length":0,"stats":{"Line":7}},{"line":41,"address":[],"length":0,"stats":{"Line":7}},{"line":42,"address":[],"length":0,"stats":{"Line":7}},{"line":43,"address":[],"length":0,"stats":{"Line":7}},{"line":44,"address":[],"length":0,"stats":{"Line":7}},{"line":45,"address":[],"length":0,"stats":{"Line":7}},{"line":46,"address":[],"length":0,"stats":{"Line":7}},{"line":48,"address":[],"length":0,"stats":{"Line":14}},{"line":53,"address":[],"length":0,"stats":{"Line":1}},{"line":77,"address":[],"length":0,"stats":{"Line":23}},{"line":90,"address":[],"length":0,"stats":{"Line":29}},{"line":91,"address":[],"length":0,"stats":{"Line":29}},{"line":94,"address":[],"length":0,"stats":{"Line":7}},{"line":95,"address":[],"length":0,"stats":{"Line":7}},{"line":98,"address":[],"length":0,"stats":{"Line":7}},{"line":99,"address":[],"length":0,"stats":{"Line":7}},{"line":100,"address":[],"length":0,"stats":{"Line":7}},{"line":101,"address":[],"length":0,"stats":{"Line":7}},{"line":102,"address":[],"length":0,"stats":{"Line":14}},{"line":107,"address":[],"length":0,"stats":{"Line":2}},{"line":139,"address":[],"length":0,"stats":{"Line":22}},{"line":154,"address":[],"length":0,"stats":{"Line":29}},{"line":155,"address":[],"length":0,"stats":{"Line":29}},{"line":158,"address":[],"length":0,"stats":{"Line":7}},{"line":159,"address":[],"length":0,"stats":{"Line":7}},{"line":162,"address":[],"length":0,"stats":{"Line":7}},{"line":163,"address":[],"length":0,"stats":{"Line":7}},{"line":164,"address":[],"length":0,"stats":{"Line":7}},{"line":165,"address":[],"length":0,"stats":{"Line":7}},{"line":166,"address":[],"length":0,"stats":{"Line":7}},{"line":167,"address":[],"length":0,"stats":{"Line":7}},{"line":168,"address":[],"length":0,"stats":{"Line":7}},{"line":170,"address":[],"length":0,"stats":{"Line":7}},{"line":171,"address":[],"length":0,"stats":{"Line":7}},{"line":172,"address":[],"length":0,"stats":{"Line":7}},{"line":173,"address":[],"length":0,"stats":{"Line":7}},{"line":175,"address":[],"length":0,"stats":{"Line":14}},{"line":177,"address":[],"length":0,"stats":{"Line":7}},{"line":181,"address":[],"length":0,"stats":{"Line":0}}],"covered":44,"coverable":45},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","cca.rs"],"content":"use crate::tools::Tool;\nuse async_trait::async_trait;\nuse knowledge::context_architect::{ContextAssembler, SummarySource};\nuse knowledge::hindsight::HindsightQuery;\nuse knowledge::meta_agent::MetaAgentLoopState;\nuse knowledge::note_taking::{TrajectoryCapture, TrajectoryEvent};\nuse mk_core::types::{ErrorSignature, HindsightNote, MemoryLayer};\nuse schemars::JsonSchema;\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Value, json};\nuse std::sync::{Arc, RwLock};\nuse validator::Validate;\n\npub struct ContextAssembleTool {\n    assembler: Arc<ContextAssembler>,\n    sources_provider: Arc<dyn SummarySourceProvider + Send + Sync>,\n}\n\npub trait SummarySourceProvider: Send + Sync {\n    fn get_sources(&self, layers: &[MemoryLayer]) -> Vec<SummarySource>;\n}\n\npub struct DefaultSummarySourceProvider;\n\nimpl SummarySourceProvider for DefaultSummarySourceProvider {\n    fn get_sources(&self, _layers: &[MemoryLayer]) -> Vec<SummarySource> {\n        Vec::new()\n    }\n}\n\nimpl ContextAssembleTool {\n    pub fn new(\n        assembler: Arc<ContextAssembler>,\n        sources_provider: Arc<dyn SummarySourceProvider + Send + Sync>,\n    ) -> Self {\n        Self {\n            assembler,\n            sources_provider,\n        }\n    }\n\n    pub fn with_default_provider(assembler: Arc<ContextAssembler>) -> Self {\n        Self::new(assembler, Arc::new(DefaultSummarySourceProvider))\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct ContextAssembleParams {\n    #[serde(default)]\n    pub query: Option<String>,\n\n    #[serde(rename = \"tokenBudget\", default = \"default_token_budget\")]\n    pub token_budget: u32,\n\n    #[serde(default)]\n    pub layers: Vec<String>,\n}\n\nfn default_token_budget() -> u32 {\n    4000\n}\n\nfn parse_layer(s: &str) -> Option<MemoryLayer> {\n    match s.to_lowercase().as_str() {\n        \"agent\" => Some(MemoryLayer::Agent),\n        \"user\" => Some(MemoryLayer::User),\n        \"session\" => Some(MemoryLayer::Session),\n        \"project\" => Some(MemoryLayer::Project),\n        \"team\" => Some(MemoryLayer::Team),\n        \"org\" => Some(MemoryLayer::Org),\n        \"company\" => Some(MemoryLayer::Company),\n        _ => None,\n    }\n}\n\n#[async_trait]\nimpl Tool for ContextAssembleTool {\n    fn name(&self) -> &str {\n        \"context_assemble\"\n    }\n\n    fn description(&self) -> &str {\n        \"Assemble hierarchical context from memory layers using CCA Context Architect.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": { \"type\": \"string\" },\n                \"tokenBudget\": { \"type\": \"integer\", \"minimum\": 100, \"maximum\": 32000 },\n                \"layers\": {\n                    \"type\": \"array\",\n                    \"items\": { \"type\": \"string\" }\n                }\n            },\n            \"required\": []\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: ContextAssembleParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let layers: Vec<MemoryLayer> = p.layers.iter().filter_map(|s| parse_layer(s)).collect();\n        let sources = self.sources_provider.get_sources(&layers);\n        let context = self\n            .assembler\n            .assemble_context(None, &sources, Some(p.token_budget));\n\n        Ok(json!({\n            \"success\": true,\n            \"context\": {\n                \"totalTokens\": context.total_tokens,\n                \"tokenBudget\": context.token_budget,\n                \"layersIncluded\": context.layers_included.iter().map(|l| format!(\"{:?}\", l)).collect::<Vec<_>>(),\n                \"isWithinBudget\": context.is_within_budget(),\n                \"entryCount\": context.entries.len(),\n                \"content\": context.content()\n            }\n        }))\n    }\n}\n\npub struct NoteCaptureTool {\n    capture: Arc<RwLock<TrajectoryCapture>>,\n}\n\nimpl NoteCaptureTool {\n    pub fn new(capture: Arc<RwLock<TrajectoryCapture>>) -> Self {\n        Self { capture }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct NoteCaptureParams {\n    pub description: String,\n\n    #[serde(default)]\n    pub tags: Vec<String>,\n\n    #[serde(rename = \"toolName\", default = \"default_tool_name\")]\n    pub tool_name: String,\n\n    #[serde(default)]\n    pub success: bool,\n}\n\nfn default_tool_name() -> String {\n    \"manual_capture\".to_string()\n}\n\n#[async_trait]\nimpl Tool for NoteCaptureTool {\n    fn name(&self) -> &str {\n        \"note_capture\"\n    }\n\n    fn description(&self) -> &str {\n        \"Capture a trajectory event for note distillation.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"description\": { \"type\": \"string\" },\n                \"tags\": {\n                    \"type\": \"array\",\n                    \"items\": { \"type\": \"string\" }\n                },\n                \"toolName\": { \"type\": \"string\" },\n                \"success\": { \"type\": \"boolean\" }\n            },\n            \"required\": [\"description\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: NoteCaptureParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let event = TrajectoryEvent::new(&p.tool_name, &p.description, \"\", p.success, 0)\n            .with_metadata(json!({ \"tags\": p.tags }));\n\n        let mut capture = self.capture.write().map_err(|e| e.to_string())?;\n        capture.capture(event);\n        let event_count = capture.len();\n\n        Ok(json!({\n            \"success\": true,\n            \"message\": format!(\"Trajectory event captured: {}\", p.description),\n            \"eventCount\": event_count\n        }))\n    }\n}\n\npub struct HindsightQueryTool {\n    query_engine: Arc<HindsightQuery>,\n    notes_provider: Arc<dyn HindsightNotesProvider + Send + Sync>,\n}\n\npub trait HindsightNotesProvider: Send + Sync {\n    fn get_notes(&self) -> Vec<HindsightNote>;\n}\n\npub struct DefaultHindsightNotesProvider;\n\nimpl HindsightNotesProvider for DefaultHindsightNotesProvider {\n    fn get_notes(&self) -> Vec<HindsightNote> {\n        Vec::new()\n    }\n}\n\nimpl HindsightQueryTool {\n    pub fn new(\n        query_engine: Arc<HindsightQuery>,\n        notes_provider: Arc<dyn HindsightNotesProvider + Send + Sync>,\n    ) -> Self {\n        Self {\n            query_engine,\n            notes_provider,\n        }\n    }\n\n    pub fn with_default_provider(query_engine: Arc<HindsightQuery>) -> Self {\n        Self::new(query_engine, Arc::new(DefaultHindsightNotesProvider))\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct HindsightQueryParams {\n    #[serde(rename = \"errorType\")]\n    pub error_type: String,\n\n    #[serde(rename = \"messagePattern\")]\n    pub message_pattern: String,\n\n    #[serde(rename = \"contextPatterns\", default)]\n    pub context_patterns: Vec<String>,\n}\n\n#[async_trait]\nimpl Tool for HindsightQueryTool {\n    fn name(&self) -> &str {\n        \"hindsight_query\"\n    }\n\n    fn description(&self) -> &str {\n        \"Query hindsight learning for error patterns and resolutions.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"errorType\": { \"type\": \"string\" },\n                \"messagePattern\": { \"type\": \"string\" },\n                \"contextPatterns\": {\n                    \"type\": \"array\",\n                    \"items\": { \"type\": \"string\" }\n                }\n            },\n            \"required\": [\"errorType\", \"messagePattern\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: HindsightQueryParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let error_sig = ErrorSignature {\n            error_type: p.error_type.clone(),\n            message_pattern: p.message_pattern.clone(),\n            stack_patterns: vec![],\n            context_patterns: p.context_patterns.clone(),\n            embedding: None,\n        };\n\n        let notes = self.notes_provider.get_notes();\n        let matches = self.query_engine.query_hindsight(&error_sig, &notes);\n\n        let results: Vec<Value> = matches\n            .iter()\n            .map(|m| {\n                json!({\n                    \"noteId\": m.note_id,\n                    \"score\": m.score,\n                    \"content\": m.note.content,\n                    \"resolution\": m.best_resolution.as_ref().map(|r| json!({\n                        \"description\": r.description,\n                        \"successRate\": r.success_rate,\n                        \"applicationCount\": r.application_count\n                    }))\n                })\n            })\n            .collect();\n\n        Ok(json!({\n            \"success\": true,\n            \"matchCount\": results.len(),\n            \"matches\": results\n        }))\n    }\n}\n\npub struct MetaLoopStatusTool {\n    state_provider: Arc<dyn MetaLoopStateProvider + Send + Sync>,\n}\n\npub trait MetaLoopStateProvider: Send + Sync {\n    fn get_state(&self, loop_id: Option<&str>) -> Option<MetaAgentLoopState>;\n    fn active_loop_count(&self) -> usize;\n}\n\npub struct DefaultMetaLoopStateProvider;\n\nimpl MetaLoopStateProvider for DefaultMetaLoopStateProvider {\n    fn get_state(&self, _loop_id: Option<&str>) -> Option<MetaAgentLoopState> {\n        None\n    }\n\n    fn active_loop_count(&self) -> usize {\n        0\n    }\n}\n\nimpl MetaLoopStatusTool {\n    pub fn new(state_provider: Arc<dyn MetaLoopStateProvider + Send + Sync>) -> Self {\n        Self { state_provider }\n    }\n\n    pub fn with_default_provider() -> Self {\n        Self::new(Arc::new(DefaultMetaLoopStateProvider))\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct MetaLoopStatusParams {\n    #[serde(rename = \"loopId\", default)]\n    pub loop_id: Option<String>,\n\n    #[serde(rename = \"includeDetails\", default)]\n    pub include_details: bool,\n}\n\n#[async_trait]\nimpl Tool for MetaLoopStatusTool {\n    fn name(&self) -> &str {\n        \"meta_loop_status\"\n    }\n\n    fn description(&self) -> &str {\n        \"Get status of meta-agent build-test-improve loops.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"loopId\": { \"type\": \"string\" },\n                \"includeDetails\": { \"type\": \"boolean\" }\n            },\n            \"required\": []\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: MetaLoopStatusParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let active_count = self.state_provider.active_loop_count();\n        let state = self.state_provider.get_state(p.loop_id.as_deref());\n\n        let status = if active_count > 0 { \"running\" } else { \"idle\" };\n\n        let details = if p.include_details {\n            state.as_ref().map(|s| {\n                json!({\n                    \"iterations\": s.iterations,\n                    \"lastBuild\": s.last_build.as_ref().map(|b| json!({\n                        \"output\": b.output,\n                        \"notes\": b.notes,\n                        \"tokensUsed\": b.tokens_used\n                    })),\n                    \"lastTest\": s.last_test.as_ref().map(|t| json!({\n                        \"status\": format!(\"{:?}\", t.status),\n                        \"output\": t.output,\n                        \"durationMs\": t.duration_ms\n                    })),\n                    \"lastImprove\": s.last_improve.as_ref().map(|i| json!({\n                        \"action\": format!(\"{:?}\", i.action)\n                    }))\n                })\n            })\n        } else {\n            None\n        };\n\n        Ok(json!({\n            \"success\": true,\n            \"status\": status,\n            \"activeLoops\": active_count,\n            \"loopState\": state.map(|s| json!({\n                \"iterations\": s.iterations,\n                \"hasLastBuild\": s.last_build.is_some(),\n                \"hasLastTest\": s.last_test.is_some()\n            })),\n            \"details\": details\n        }))\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use knowledge::context_architect::AssemblerConfig;\n    use knowledge::hindsight::HindsightQueryConfig;\n    use knowledge::note_taking::TrajectoryConfig;\n\n    #[tokio::test]\n    async fn test_context_assemble_tool() {\n        let assembler = Arc::new(ContextAssembler::new(AssemblerConfig::default()));\n        let tool = ContextAssembleTool::with_default_provider(assembler);\n\n        let result = tool.call(json!({\"tokenBudget\": 2000})).await.unwrap();\n\n        assert_eq!(result[\"success\"], true);\n        assert!(result[\"context\"][\"totalTokens\"].is_number());\n    }\n\n    #[tokio::test]\n    async fn test_note_capture_tool() {\n        let capture = Arc::new(RwLock::new(TrajectoryCapture::new(\n            TrajectoryConfig::default(),\n        )));\n        let tool = NoteCaptureTool::new(capture.clone());\n\n        let result = tool\n            .call(json!({\n                \"description\": \"Test capture\",\n                \"tags\": [\"test\"],\n                \"success\": true\n            }))\n            .await\n            .unwrap();\n\n        assert_eq!(result[\"success\"], true);\n        assert_eq!(result[\"eventCount\"], 1);\n    }\n\n    #[tokio::test]\n    async fn test_hindsight_query_tool() {\n        let query_engine = Arc::new(HindsightQuery::new(HindsightQueryConfig::default()));\n        let tool = HindsightQueryTool::with_default_provider(query_engine);\n\n        let result = tool\n            .call(json!({\n                \"errorType\": \"TypeError\",\n                \"messagePattern\": \"cannot read property\"\n            }))\n            .await\n            .unwrap();\n\n        assert_eq!(result[\"success\"], true);\n        assert_eq!(result[\"matchCount\"], 0);\n    }\n\n    #[tokio::test]\n    async fn test_meta_loop_status_tool() {\n        let tool = MetaLoopStatusTool::with_default_provider();\n\n        let result = tool.call(json!({})).await.unwrap();\n\n        assert_eq!(result[\"success\"], true);\n        assert_eq!(result[\"status\"], \"idle\");\n        assert_eq!(result[\"activeLoops\"], 0);\n    }\n}\n","traces":[{"line":26,"address":[],"length":0,"stats":{"Line":1}},{"line":27,"address":[],"length":0,"stats":{"Line":1}},{"line":32,"address":[],"length":0,"stats":{"Line":23}},{"line":42,"address":[],"length":0,"stats":{"Line":23}},{"line":43,"address":[],"length":0,"stats":{"Line":69}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":29}},{"line":79,"address":[],"length":0,"stats":{"Line":29}},{"line":82,"address":[],"length":0,"stats":{"Line":7}},{"line":83,"address":[],"length":0,"stats":{"Line":7}},{"line":86,"address":[],"length":0,"stats":{"Line":7}},{"line":87,"address":[],"length":0,"stats":{"Line":7}},{"line":88,"address":[],"length":0,"stats":{"Line":7}},{"line":89,"address":[],"length":0,"stats":{"Line":7}},{"line":90,"address":[],"length":0,"stats":{"Line":14}},{"line":91,"address":[],"length":0,"stats":{"Line":28}},{"line":92,"address":[],"length":0,"stats":{"Line":7}},{"line":93,"address":[],"length":0,"stats":{"Line":7}},{"line":94,"address":[],"length":0,"stats":{"Line":14}},{"line":97,"address":[],"length":0,"stats":{"Line":7}},{"line":101,"address":[],"length":0,"stats":{"Line":1}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":23}},{"line":149,"address":[],"length":0,"stats":{"Line":1}},{"line":150,"address":[],"length":0,"stats":{"Line":2}},{"line":155,"address":[],"length":0,"stats":{"Line":29}},{"line":156,"address":[],"length":0,"stats":{"Line":29}},{"line":159,"address":[],"length":0,"stats":{"Line":7}},{"line":160,"address":[],"length":0,"stats":{"Line":7}},{"line":163,"address":[],"length":0,"stats":{"Line":7}},{"line":164,"address":[],"length":0,"stats":{"Line":7}},{"line":165,"address":[],"length":0,"stats":{"Line":7}},{"line":166,"address":[],"length":0,"stats":{"Line":7}},{"line":167,"address":[],"length":0,"stats":{"Line":14}},{"line":168,"address":[],"length":0,"stats":{"Line":7}},{"line":169,"address":[],"length":0,"stats":{"Line":7}},{"line":170,"address":[],"length":0,"stats":{"Line":14}},{"line":172,"address":[],"length":0,"stats":{"Line":14}},{"line":173,"address":[],"length":0,"stats":{"Line":14}},{"line":175,"address":[],"length":0,"stats":{"Line":7}},{"line":179,"address":[],"length":0,"stats":{"Line":1}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":1}},{"line":211,"address":[],"length":0,"stats":{"Line":1}},{"line":216,"address":[],"length":0,"stats":{"Line":23}},{"line":226,"address":[],"length":0,"stats":{"Line":23}},{"line":227,"address":[],"length":0,"stats":{"Line":69}},{"line":245,"address":[],"length":0,"stats":{"Line":29}},{"line":246,"address":[],"length":0,"stats":{"Line":29}},{"line":249,"address":[],"length":0,"stats":{"Line":7}},{"line":250,"address":[],"length":0,"stats":{"Line":7}},{"line":253,"address":[],"length":0,"stats":{"Line":7}},{"line":254,"address":[],"length":0,"stats":{"Line":7}},{"line":255,"address":[],"length":0,"stats":{"Line":7}},{"line":256,"address":[],"length":0,"stats":{"Line":7}},{"line":257,"address":[],"length":0,"stats":{"Line":14}},{"line":258,"address":[],"length":0,"stats":{"Line":14}},{"line":259,"address":[],"length":0,"stats":{"Line":7}},{"line":260,"address":[],"length":0,"stats":{"Line":7}},{"line":261,"address":[],"length":0,"stats":{"Line":14}},{"line":264,"address":[],"length":0,"stats":{"Line":7}},{"line":268,"address":[],"length":0,"stats":{"Line":1}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":1}},{"line":320,"address":[],"length":0,"stats":{"Line":1}},{"line":323,"address":[],"length":0,"stats":{"Line":1}},{"line":324,"address":[],"length":0,"stats":{"Line":1}},{"line":329,"address":[],"length":0,"stats":{"Line":23}},{"line":333,"address":[],"length":0,"stats":{"Line":23}},{"line":334,"address":[],"length":0,"stats":{"Line":46}},{"line":349,"address":[],"length":0,"stats":{"Line":29}},{"line":350,"address":[],"length":0,"stats":{"Line":29}},{"line":353,"address":[],"length":0,"stats":{"Line":7}},{"line":354,"address":[],"length":0,"stats":{"Line":7}},{"line":357,"address":[],"length":0,"stats":{"Line":7}},{"line":358,"address":[],"length":0,"stats":{"Line":7}},{"line":359,"address":[],"length":0,"stats":{"Line":7}},{"line":360,"address":[],"length":0,"stats":{"Line":7}},{"line":361,"address":[],"length":0,"stats":{"Line":14}},{"line":362,"address":[],"length":0,"stats":{"Line":14}},{"line":364,"address":[],"length":0,"stats":{"Line":7}},{"line":368,"address":[],"length":0,"stats":{"Line":1}},{"line":378,"address":[],"length":0,"stats":{"Line":0}},{"line":379,"address":[],"length":0,"stats":{"Line":0}},{"line":380,"address":[],"length":0,"stats":{"Line":0}},{"line":381,"address":[],"length":0,"stats":{"Line":0}},{"line":382,"address":[],"length":0,"stats":{"Line":0}},{"line":383,"address":[],"length":0,"stats":{"Line":0}},{"line":384,"address":[],"length":0,"stats":{"Line":0}},{"line":386,"address":[],"length":0,"stats":{"Line":0}},{"line":387,"address":[],"length":0,"stats":{"Line":0}},{"line":388,"address":[],"length":0,"stats":{"Line":0}},{"line":389,"address":[],"length":0,"stats":{"Line":0}},{"line":391,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":0}},{"line":404,"address":[],"length":0,"stats":{"Line":0}},{"line":405,"address":[],"length":0,"stats":{"Line":0}},{"line":406,"address":[],"length":0,"stats":{"Line":0}},{"line":407,"address":[],"length":0,"stats":{"Line":0}}],"covered":78,"coverable":119},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","config.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","ecosystem.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","episodic.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","extensions","context.rs"],"content":"use std::collections::HashMap;\nuse std::sync::Arc;\n\nuse mk_core::types::TenantContext;\nuse serde::{Deserialize, Serialize};\nuse serde_json::Value;\n\nuse super::ExtensionError;\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ExtensionMessage {\n    pub role: String,\n    pub content: String,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ExtensionContextState {\n    pub state: HashMap<String, Value>,\n    pub version: u32,\n}\n\npub struct ExtensionContext {\n    pub tenant_ctx: TenantContext,\n    pub session_id: String,\n    pub extension_id: String,\n    pub tool_registry: Arc<crate::tools::ToolRegistry>,\n    state: HashMap<String, Value>,\n    max_state_bytes: usize,\n}\n\nimpl ExtensionContext {\n    pub fn new(\n        tenant_ctx: TenantContext,\n        session_id: String,\n        extension_id: String,\n        tool_registry: Arc<crate::tools::ToolRegistry>,\n        max_state_bytes: usize,\n    ) -> Self {\n        Self {\n            tenant_ctx,\n            session_id,\n            extension_id,\n            tool_registry,\n            state: HashMap::new(),\n            max_state_bytes,\n        }\n    }\n\n    pub fn get_state<T: serde::de::DeserializeOwned>(\n        &self,\n        key: &str,\n    ) -> Result<Option<T>, ExtensionError> {\n        match self.state.get(key) {\n            Some(value) => serde_json::from_value(value.clone())\n                .map(Some)\n                .map_err(|err| ExtensionError::Serialization(err.to_string())),\n            None => Ok(None),\n        }\n    }\n\n    pub fn set_state<T: Serialize>(&mut self, key: &str, value: T) -> Result<(), ExtensionError> {\n        let next_value = serde_json::to_value(value)\n            .map_err(|err| ExtensionError::Serialization(err.to_string()))?;\n        self.state.insert(key.to_string(), next_value);\n        self.enforce_size_limit()?;\n        Ok(())\n    }\n\n    pub fn clear_state(&mut self) {\n        self.state.clear();\n    }\n\n    pub fn state(&self) -> &HashMap<String, Value> {\n        &self.state\n    }\n\n    pub fn replace_state(&mut self, state: HashMap<String, Value>) {\n        self.state = state;\n    }\n\n    pub fn to_state_payload(&self) -> Result<ExtensionContextState, ExtensionError> {\n        Ok(ExtensionContextState {\n            state: self.state.clone(),\n            version: 1,\n        })\n    }\n\n    fn enforce_size_limit(&self) -> Result<(), ExtensionError> {\n        let bytes = serde_json::to_vec(&self.state)\n            .map_err(|err| ExtensionError::Serialization(err.to_string()))?;\n        if bytes.len() > self.max_state_bytes {\n            return Err(ExtensionError::StateTooLarge);\n        }\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_state_set_get() {\n        let ctx = TenantContext::default();\n        let registry = Arc::new(crate::tools::ToolRegistry::new());\n        let mut ext_ctx =\n            ExtensionContext::new(ctx, \"s\".to_string(), \"e\".to_string(), registry, 1024);\n        ext_ctx.set_state(\"key\", \"value\").unwrap();\n        let value: Option<String> = ext_ctx.get_state(\"key\").unwrap();\n        assert_eq!(value.unwrap(), \"value\");\n    }\n\n    #[test]\n    fn test_state_size_limit() {\n        let ctx = TenantContext::default();\n        let registry = Arc::new(crate::tools::ToolRegistry::new());\n        let mut ext_ctx =\n            ExtensionContext::new(ctx, \"s\".to_string(), \"e\".to_string(), registry, 10);\n        let result = ext_ctx.set_state(\"key\", \"this is too long\");\n        assert!(matches!(result, Err(ExtensionError::StateTooLarge)));\n    }\n}\n","traces":[{"line":32,"address":[],"length":0,"stats":{"Line":10}},{"line":44,"address":[],"length":0,"stats":{"Line":10}},{"line":49,"address":[],"length":0,"stats":{"Line":1}},{"line":53,"address":[],"length":0,"stats":{"Line":2}},{"line":54,"address":[],"length":0,"stats":{"Line":4}},{"line":55,"address":[],"length":0,"stats":{"Line":1}},{"line":56,"address":[],"length":0,"stats":{"Line":1}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":2}},{"line":62,"address":[],"length":0,"stats":{"Line":6}},{"line":63,"address":[],"length":0,"stats":{"Line":2}},{"line":64,"address":[],"length":0,"stats":{"Line":10}},{"line":65,"address":[],"length":0,"stats":{"Line":5}},{"line":66,"address":[],"length":0,"stats":{"Line":1}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":2}},{"line":89,"address":[],"length":0,"stats":{"Line":6}},{"line":90,"address":[],"length":0,"stats":{"Line":2}},{"line":91,"address":[],"length":0,"stats":{"Line":4}},{"line":92,"address":[],"length":0,"stats":{"Line":1}},{"line":94,"address":[],"length":0,"stats":{"Line":1}}],"covered":19,"coverable":30},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","extensions","limits.rs"],"content":"use std::collections::HashMap;\nuse std::sync::Arc;\n\nuse redis::AsyncCommands;\nuse serde::{Deserialize, Serialize};\nuse tokio::sync::RwLock;\nuse tracing::{info, warn};\n\nuse super::ExtensionStateError;\n\nconst ONE_MB: usize = 1024 * 1024;\nconst ONE_HOUR_SECS: u64 = 3600;\nconst FIFTY_MB: usize = 50 * 1024 * 1024;\n\nconst DEFAULT_MAX_STATE_SIZE_BYTES: usize = ONE_MB;\nconst DEFAULT_STATE_TTL_SECS: u64 = ONE_HOUR_SECS;\nconst DEFAULT_TENANT_TOTAL_LIMIT_BYTES: usize = FIFTY_MB;\nconst ALERT_THRESHOLD_PERCENT: f32 = 0.8;\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ExtensionStateConfig {\n    pub max_state_size_bytes: usize,\n    pub state_ttl_secs: u64,\n}\n\nimpl Default for ExtensionStateConfig {\n    fn default() -> Self {\n        Self {\n            max_state_size_bytes: DEFAULT_MAX_STATE_SIZE_BYTES,\n            state_ttl_secs: DEFAULT_STATE_TTL_SECS,\n        }\n    }\n}\n\nimpl ExtensionStateConfig {\n    pub fn new(max_state_size_bytes: usize, state_ttl_secs: u64) -> Self {\n        Self {\n            max_state_size_bytes,\n            state_ttl_secs,\n        }\n    }\n}\n\n#[derive(Debug, Clone, Default, Serialize, Deserialize)]\npub struct ExtensionStateMetrics {\n    pub size_bytes: u64,\n    pub keys_count: u64,\n    pub evictions: u64,\n    pub alerts_triggered: u64,\n}\n\n#[derive(Debug, Clone)]\npub struct LruEntry {\n    pub key: String,\n    pub size_bytes: usize,\n    pub last_access_at: i64,\n}\n\npub struct ExtensionStateLimiter {\n    redis_url: String,\n    tenant_total_limit_bytes: usize,\n    extension_configs: Arc<RwLock<HashMap<String, ExtensionStateConfig>>>,\n    metrics: Arc<RwLock<HashMap<String, ExtensionStateMetrics>>>,\n}\n\nimpl ExtensionStateLimiter {\n    pub fn new(redis_url: String) -> Self {\n        Self {\n            redis_url,\n            tenant_total_limit_bytes: DEFAULT_TENANT_TOTAL_LIMIT_BYTES,\n            extension_configs: Arc::new(RwLock::new(HashMap::new())),\n            metrics: Arc::new(RwLock::new(HashMap::new())),\n        }\n    }\n\n    pub fn with_tenant_limit(mut self, limit_bytes: usize) -> Self {\n        self.tenant_total_limit_bytes = limit_bytes;\n        self\n    }\n\n    pub async fn register_extension(&self, extension_id: &str, config: ExtensionStateConfig) {\n        let mut configs = self.extension_configs.write().await;\n        configs.insert(extension_id.to_string(), config);\n    }\n\n    pub async fn get_config(&self, extension_id: &str) -> ExtensionStateConfig {\n        let configs = self.extension_configs.read().await;\n        configs.get(extension_id).cloned().unwrap_or_default()\n    }\n\n    pub async fn check_size_limit(\n        &self,\n        extension_id: &str,\n        state_bytes: usize,\n    ) -> Result<(), ExtensionStateError> {\n        let config = self.get_config(extension_id).await;\n\n        if state_bytes > config.max_state_size_bytes {\n            return Err(ExtensionStateError::Serialization(format!(\n                \"State size {} exceeds limit {} for extension {}\",\n                state_bytes, config.max_state_size_bytes, extension_id\n            )));\n        }\n\n        let threshold_bytes =\n            (config.max_state_size_bytes as f32 * ALERT_THRESHOLD_PERCENT) as usize;\n        if state_bytes >= threshold_bytes {\n            warn!(\n                extension_id = %extension_id,\n                size_bytes = state_bytes,\n                limit_bytes = config.max_state_size_bytes,\n                \"Extension state approaching size limit ({}%)\",\n                (state_bytes as f32 / config.max_state_size_bytes as f32 * 100.0) as u32\n            );\n            self.increment_alerts(extension_id).await;\n        }\n\n        Ok(())\n    }\n\n    pub async fn enforce_tenant_limit(\n        &self,\n        tenant_id: &str,\n        incoming_bytes: usize,\n    ) -> Result<Vec<String>, ExtensionStateError> {\n        let mut con = self.connection().await?;\n        let pattern = format!(\"extension:{}:*\", tenant_id);\n\n        let keys: Vec<String> = redis::cmd(\"KEYS\")\n            .arg(&pattern)\n            .query_async(&mut con)\n            .await\n            .map_err(ExtensionStateError::Redis)?;\n\n        if keys.is_empty() {\n            return Ok(vec![]);\n        }\n\n        let mut entries: Vec<LruEntry> = Vec::new();\n        let mut total_size: usize = 0;\n\n        for key in &keys {\n            let size: usize = con.strlen(key).await.map_err(ExtensionStateError::Redis)?;\n            let idle: Option<i64> = redis::cmd(\"OBJECT\")\n                .arg(\"IDLETIME\")\n                .arg(key)\n                .query_async(&mut con)\n                .await\n                .ok();\n\n            total_size += size;\n\n            entries.push(LruEntry {\n                key: key.clone(),\n                size_bytes: size,\n                last_access_at: idle.unwrap_or(0),\n            });\n        }\n\n        let mut evicted: Vec<String> = Vec::new();\n\n        if total_size + incoming_bytes > self.tenant_total_limit_bytes {\n            entries.sort_by(|a, b| b.last_access_at.cmp(&a.last_access_at));\n\n            let mut current_total = total_size;\n            for entry in entries {\n                if current_total + incoming_bytes <= self.tenant_total_limit_bytes {\n                    break;\n                }\n                let _: () = con\n                    .del(&entry.key)\n                    .await\n                    .map_err(ExtensionStateError::Redis)?;\n                current_total -= entry.size_bytes;\n                evicted.push(entry.key.clone());\n\n                info!(\n                    tenant_id = %tenant_id,\n                    evicted_key = %entry.key,\n                    freed_bytes = entry.size_bytes,\n                    \"Evicted LRU extension state\"\n                );\n            }\n\n            self.increment_evictions(tenant_id, evicted.len() as u64)\n                .await;\n        }\n\n        Ok(evicted)\n    }\n\n    pub async fn save_with_ttl(\n        &self,\n        key: &str,\n        data: &[u8],\n        extension_id: &str,\n    ) -> Result<(), ExtensionStateError> {\n        let config = self.get_config(extension_id).await;\n        let mut con = self.connection().await?;\n        let _: () = con\n            .set_ex(key, data, config.state_ttl_secs)\n            .await\n            .map_err(ExtensionStateError::Redis)?;\n\n        self.update_metrics(extension_id, data.len() as u64).await;\n        Ok(())\n    }\n\n    pub async fn get_metrics(&self, extension_id: &str) -> ExtensionStateMetrics {\n        let metrics = self.metrics.read().await;\n        metrics.get(extension_id).cloned().unwrap_or_default()\n    }\n\n    pub async fn get_all_metrics(&self) -> HashMap<String, ExtensionStateMetrics> {\n        self.metrics.read().await.clone()\n    }\n\n    async fn update_metrics(&self, extension_id: &str, size_bytes: u64) {\n        let mut metrics = self.metrics.write().await;\n        let entry = metrics\n            .entry(extension_id.to_string())\n            .or_insert_with(ExtensionStateMetrics::default);\n        entry.size_bytes = size_bytes;\n        entry.keys_count += 1;\n    }\n\n    async fn increment_evictions(&self, tenant_id: &str, count: u64) {\n        let mut metrics = self.metrics.write().await;\n        let entry = metrics\n            .entry(tenant_id.to_string())\n            .or_insert_with(ExtensionStateMetrics::default);\n        entry.evictions += count;\n    }\n\n    async fn increment_alerts(&self, extension_id: &str) {\n        let mut metrics = self.metrics.write().await;\n        let entry = metrics\n            .entry(extension_id.to_string())\n            .or_insert_with(ExtensionStateMetrics::default);\n        entry.alerts_triggered += 1;\n    }\n\n    async fn connection(&self) -> Result<redis::aio::ConnectionManager, ExtensionStateError> {\n        let client = redis::Client::open(self.redis_url.clone())?;\n        let con = redis::aio::ConnectionManager::new(client).await?;\n        Ok(con)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_extension_state_config_default() {\n        let config = ExtensionStateConfig::default();\n        assert_eq!(config.max_state_size_bytes, 1024 * 1024);\n        assert_eq!(config.state_ttl_secs, 3600);\n    }\n\n    #[test]\n    fn test_extension_state_config_custom() {\n        let config = ExtensionStateConfig::new(512 * 1024, 7200);\n        assert_eq!(config.max_state_size_bytes, 512 * 1024);\n        assert_eq!(config.state_ttl_secs, 7200);\n    }\n\n    #[tokio::test]\n    async fn test_limiter_register_and_get_config() {\n        let limiter = ExtensionStateLimiter::new(\"redis://localhost\".to_string());\n        let config = ExtensionStateConfig::new(2048, 1800);\n        limiter.register_extension(\"test-ext\", config.clone()).await;\n\n        let retrieved = limiter.get_config(\"test-ext\").await;\n        assert_eq!(retrieved.max_state_size_bytes, 2048);\n        assert_eq!(retrieved.state_ttl_secs, 1800);\n    }\n\n    #[tokio::test]\n    async fn test_check_size_limit_within_bounds() {\n        let limiter = ExtensionStateLimiter::new(\"redis://localhost\".to_string());\n        let config = ExtensionStateConfig::new(1024, 3600);\n        limiter.register_extension(\"test-ext\", config).await;\n\n        let result = limiter.check_size_limit(\"test-ext\", 512).await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_check_size_limit_exceeds() {\n        let limiter = ExtensionStateLimiter::new(\"redis://localhost\".to_string());\n        let config = ExtensionStateConfig::new(1024, 3600);\n        limiter.register_extension(\"test-ext\", config).await;\n\n        let result = limiter.check_size_limit(\"test-ext\", 2048).await;\n        assert!(result.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_metrics_tracking() {\n        let limiter = ExtensionStateLimiter::new(\"redis://localhost\".to_string());\n        limiter.update_metrics(\"test-ext\", 500).await;\n\n        let metrics = limiter.get_metrics(\"test-ext\").await;\n        assert_eq!(metrics.size_bytes, 500);\n        assert_eq!(metrics.keys_count, 1);\n    }\n\n    #[tokio::test]\n    async fn test_alert_threshold_tracking() {\n        let limiter = ExtensionStateLimiter::new(\"redis://localhost\".to_string());\n        let config = ExtensionStateConfig::new(1000, 3600);\n        limiter.register_extension(\"test-ext\", config).await;\n\n        let eighty_five_percent_of_limit = 850;\n        let _ = limiter\n            .check_size_limit(\"test-ext\", eighty_five_percent_of_limit)\n            .await;\n\n        let metrics = limiter.get_metrics(\"test-ext\").await;\n        assert_eq!(metrics.alerts_triggered, 1);\n    }\n\n    #[tokio::test]\n    async fn test_get_all_metrics() {\n        let limiter = ExtensionStateLimiter::new(\"redis://localhost\".to_string());\n        limiter.update_metrics(\"ext1\", 100).await;\n        limiter.update_metrics(\"ext2\", 200).await;\n\n        let all_metrics = limiter.get_all_metrics().await;\n        assert_eq!(all_metrics.len(), 2);\n        assert!(all_metrics.contains_key(\"ext1\"));\n        assert!(all_metrics.contains_key(\"ext2\"));\n    }\n}\n","traces":[{"line":27,"address":[],"length":0,"stats":{"Line":12}},{"line":36,"address":[],"length":0,"stats":{"Line":5}},{"line":67,"address":[],"length":0,"stats":{"Line":6}},{"line":71,"address":[],"length":0,"stats":{"Line":24}},{"line":72,"address":[],"length":0,"stats":{"Line":12}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":8}},{"line":82,"address":[],"length":0,"stats":{"Line":8}},{"line":83,"address":[],"length":0,"stats":{"Line":16}},{"line":86,"address":[],"length":0,"stats":{"Line":8}},{"line":87,"address":[],"length":0,"stats":{"Line":8}},{"line":88,"address":[],"length":0,"stats":{"Line":16}},{"line":91,"address":[],"length":0,"stats":{"Line":3}},{"line":96,"address":[],"length":0,"stats":{"Line":12}},{"line":98,"address":[],"length":0,"stats":{"Line":3}},{"line":99,"address":[],"length":0,"stats":{"Line":1}},{"line":100,"address":[],"length":0,"stats":{"Line":1}},{"line":101,"address":[],"length":0,"stats":{"Line":1}},{"line":105,"address":[],"length":0,"stats":{"Line":2}},{"line":106,"address":[],"length":0,"stats":{"Line":2}},{"line":107,"address":[],"length":0,"stats":{"Line":2}},{"line":108,"address":[],"length":0,"stats":{"Line":1}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":3}},{"line":118,"address":[],"length":0,"stats":{"Line":2}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":201,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":205,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":4}},{"line":210,"address":[],"length":0,"stats":{"Line":4}},{"line":211,"address":[],"length":0,"stats":{"Line":8}},{"line":214,"address":[],"length":0,"stats":{"Line":2}},{"line":215,"address":[],"length":0,"stats":{"Line":3}},{"line":218,"address":[],"length":0,"stats":{"Line":6}},{"line":219,"address":[],"length":0,"stats":{"Line":6}},{"line":220,"address":[],"length":0,"stats":{"Line":9}},{"line":221,"address":[],"length":0,"stats":{"Line":6}},{"line":222,"address":[],"length":0,"stats":{"Line":3}},{"line":223,"address":[],"length":0,"stats":{"Line":3}},{"line":224,"address":[],"length":0,"stats":{"Line":3}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":231,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":235,"address":[],"length":0,"stats":{"Line":2}},{"line":236,"address":[],"length":0,"stats":{"Line":2}},{"line":237,"address":[],"length":0,"stats":{"Line":3}},{"line":238,"address":[],"length":0,"stats":{"Line":2}},{"line":239,"address":[],"length":0,"stats":{"Line":1}},{"line":240,"address":[],"length":0,"stats":{"Line":1}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}}],"covered":41,"coverable":106},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","extensions","mod.rs"],"content":"mod context;\nmod limits;\nmod prompt;\nmod registry;\nmod state;\n\nuse std::sync::Arc;\nuse std::time::Duration;\n\nuse async_trait::async_trait;\nuse mk_core::types::TenantContext;\n\npub use context::{ExtensionContext, ExtensionContextState, ExtensionMessage};\npub use limits::{ExtensionStateConfig, ExtensionStateLimiter, ExtensionStateMetrics, LruEntry};\npub use prompt::{PromptAddition, PromptWiring, ToolConfig, ToolSequenceHint};\npub use registry::{ExtensionRegistration, ExtensionRegistry};\npub use state::{ExtensionStateError, ExtensionStateStore};\n\n#[derive(Debug, thiserror::Error)]\npub enum ExtensionError {\n    #[error(\"Extension already registered\")]\n    AlreadyRegistered,\n\n    #[error(\"Extension not found\")]\n    NotFound,\n\n    #[error(\"Callback failed: {0}\")]\n    Callback(String),\n\n    #[error(\"Callback timed out\")]\n    Timeout,\n\n    #[error(\"State too large\")]\n    StateTooLarge,\n\n    #[error(\"Invalid registration: {0}\")]\n    InvalidRegistration(String),\n\n    #[error(\"Serialization error: {0}\")]\n    Serialization(String),\n\n    #[error(\"State store error: {0}\")]\n    StateStore(String),\n}\n\n#[async_trait]\npub trait ExtensionCallback: Send + Sync {\n    async fn on_input_messages(\n        &self,\n        _ctx: &mut ExtensionContext,\n        messages: Vec<ExtensionMessage>,\n    ) -> Result<Vec<ExtensionMessage>, ExtensionError> {\n        Ok(messages)\n    }\n\n    async fn on_plain_text(\n        &self,\n        _ctx: &mut ExtensionContext,\n        text: String,\n    ) -> Result<String, ExtensionError> {\n        Ok(text)\n    }\n\n    async fn on_tag(\n        &self,\n        _ctx: &mut ExtensionContext,\n        _tag: String,\n        content: String,\n    ) -> Result<String, ExtensionError> {\n        Ok(content)\n    }\n\n    async fn on_llm_output(\n        &self,\n        _ctx: &mut ExtensionContext,\n        output: String,\n    ) -> Result<String, ExtensionError> {\n        Ok(output)\n    }\n}\n\npub struct ExtensionExecutor {\n    registry: Arc<ExtensionRegistry>,\n    state_store: Option<Arc<ExtensionStateStore>>,\n    callback_timeout: Duration,\n    max_state_bytes: usize,\n}\n\nimpl std::fmt::Debug for ExtensionExecutor {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        f.debug_struct(\"ExtensionExecutor\")\n            .field(\"callback_timeout\", &self.callback_timeout)\n            .field(\"max_state_bytes\", &self.max_state_bytes)\n            .finish()\n    }\n}\n\nimpl ExtensionExecutor {\n    pub fn new(registry: Arc<ExtensionRegistry>) -> Self {\n        Self {\n            registry,\n            state_store: None,\n            callback_timeout: Duration::from_secs(5),\n            max_state_bytes: 64 * 1024,\n        }\n    }\n\n    pub fn with_state_store(mut self, store: Arc<ExtensionStateStore>) -> Self {\n        self.state_store = Some(store);\n        self\n    }\n\n    pub fn with_timeout(mut self, timeout: Duration) -> Self {\n        self.callback_timeout = timeout;\n        self\n    }\n\n    pub fn with_state_limit(mut self, max_bytes: usize) -> Self {\n        self.max_state_bytes = max_bytes;\n        self\n    }\n\n    pub fn prompt_wiring(&self) -> crate::extensions::PromptWiring {\n        self.registry.prompt_wiring()\n    }\n\n    pub async fn on_input_messages(\n        &self,\n        ctx: TenantContext,\n        session_id: &str,\n        tool_registry: Arc<crate::tools::ToolRegistry>,\n        messages: Vec<ExtensionMessage>,\n    ) -> Result<Vec<ExtensionMessage>, ExtensionError> {\n        let mut current = messages;\n        for extension in self.registry.list_ordered() {\n            if !extension.enabled {\n                continue;\n            }\n            let mut ext_ctx = ExtensionContext::new(\n                ctx.clone(),\n                session_id.to_string(),\n                extension.id.clone(),\n                tool_registry.clone(),\n                self.max_state_bytes,\n            );\n            self.load_state(&mut ext_ctx).await?;\n            let result = run_with_timeout(\n                self.callback_timeout,\n                extension.callbacks.on_input_messages(&mut ext_ctx, current),\n            )\n            .await?;\n            self.save_state(&ext_ctx).await?;\n            current = result;\n        }\n        Ok(current)\n    }\n\n    pub async fn on_plain_text(\n        &self,\n        ctx: TenantContext,\n        session_id: &str,\n        tool_registry: Arc<crate::tools::ToolRegistry>,\n        text: String,\n    ) -> Result<String, ExtensionError> {\n        let mut current = text;\n        for extension in self.registry.list_ordered() {\n            if !extension.enabled {\n                continue;\n            }\n            let mut ext_ctx = ExtensionContext::new(\n                ctx.clone(),\n                session_id.to_string(),\n                extension.id.clone(),\n                tool_registry.clone(),\n                self.max_state_bytes,\n            );\n            self.load_state(&mut ext_ctx).await?;\n            let result = run_with_timeout(\n                self.callback_timeout,\n                extension.callbacks.on_plain_text(&mut ext_ctx, current),\n            )\n            .await?;\n            self.save_state(&ext_ctx).await?;\n            current = result;\n        }\n        Ok(current)\n    }\n\n    pub async fn on_tag(\n        &self,\n        ctx: TenantContext,\n        session_id: &str,\n        tool_registry: Arc<crate::tools::ToolRegistry>,\n        tag: String,\n        content: String,\n    ) -> Result<String, ExtensionError> {\n        let mut current = content;\n        for extension in self.registry.list_ordered() {\n            if !extension.enabled {\n                continue;\n            }\n            let mut ext_ctx = ExtensionContext::new(\n                ctx.clone(),\n                session_id.to_string(),\n                extension.id.clone(),\n                tool_registry.clone(),\n                self.max_state_bytes,\n            );\n            self.load_state(&mut ext_ctx).await?;\n            let result = run_with_timeout(\n                self.callback_timeout,\n                extension\n                    .callbacks\n                    .on_tag(&mut ext_ctx, tag.clone(), current),\n            )\n            .await?;\n            self.save_state(&ext_ctx).await?;\n            current = result;\n        }\n        Ok(current)\n    }\n\n    pub async fn on_llm_output(\n        &self,\n        ctx: TenantContext,\n        session_id: &str,\n        tool_registry: Arc<crate::tools::ToolRegistry>,\n        output: String,\n    ) -> Result<String, ExtensionError> {\n        let mut current = output;\n        for extension in self.registry.list_ordered() {\n            if !extension.enabled {\n                continue;\n            }\n            let mut ext_ctx = ExtensionContext::new(\n                ctx.clone(),\n                session_id.to_string(),\n                extension.id.clone(),\n                tool_registry.clone(),\n                self.max_state_bytes,\n            );\n            self.load_state(&mut ext_ctx).await?;\n            let result = run_with_timeout(\n                self.callback_timeout,\n                extension.callbacks.on_llm_output(&mut ext_ctx, current),\n            )\n            .await?;\n            self.save_state(&ext_ctx).await?;\n            current = result;\n        }\n        Ok(current)\n    }\n\n    async fn load_state(&self, ctx: &mut ExtensionContext) -> Result<(), ExtensionError> {\n        if let Some(store) = &self.state_store {\n            store\n                .load(ctx)\n                .await\n                .map_err(|err| ExtensionError::StateStore(err.to_string()))?;\n        }\n        Ok(())\n    }\n\n    async fn save_state(&self, ctx: &ExtensionContext) -> Result<(), ExtensionError> {\n        if let Some(store) = &self.state_store {\n            store\n                .save(ctx)\n                .await\n                .map_err(|err| ExtensionError::StateStore(err.to_string()))?;\n        }\n        Ok(())\n    }\n}\n\nasync fn run_with_timeout<F, T>(timeout_duration: Duration, fut: F) -> Result<T, ExtensionError>\nwhere\n    F: std::future::Future<Output = Result<T, ExtensionError>>,\n{\n    match tokio::time::timeout(timeout_duration, fut).await {\n        Ok(result) => result,\n        Err(_) => Err(ExtensionError::Timeout),\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::sync::Mutex;\n\n    struct TestCallback {\n        label: String,\n        calls: Arc<Mutex<Vec<String>>>,\n    }\n\n    #[async_trait]\n    impl ExtensionCallback for TestCallback {\n        async fn on_plain_text(\n            &self,\n            _ctx: &mut ExtensionContext,\n            text: String,\n        ) -> Result<String, ExtensionError> {\n            self.calls.lock().unwrap().push(self.label.clone());\n            Ok(format!(\"{text}-{}\", self.label))\n        }\n    }\n\n    #[tokio::test]\n    async fn test_extension_executor_order() {\n        let mut registry = ExtensionRegistry::new();\n        let calls = Arc::new(Mutex::new(Vec::new()));\n        let reg1 = ExtensionRegistration::new(\n            \"a\",\n            Arc::new(TestCallback {\n                label: \"a\".to_string(),\n                calls: calls.clone(),\n            }),\n        )\n        .with_priority(1);\n        let reg2 = ExtensionRegistration::new(\n            \"b\",\n            Arc::new(TestCallback {\n                label: \"b\".to_string(),\n                calls: calls.clone(),\n            }),\n        )\n        .with_priority(2);\n\n        registry.register_extension(reg1).unwrap();\n        registry.register_extension(reg2).unwrap();\n\n        let executor = ExtensionExecutor::new(Arc::new(registry));\n        let tool_registry = Arc::new(crate::tools::ToolRegistry::new());\n        let result = executor\n            .on_plain_text(\n                TenantContext::default(),\n                \"session\",\n                tool_registry,\n                \"start\".to_string(),\n            )\n            .await\n            .unwrap();\n\n        assert_eq!(result, \"start-b-a\");\n        assert_eq!(calls.lock().unwrap().as_slice(), &[\"b\", \"a\"]);\n    }\n}\n","traces":[{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":4}},{"line":103,"address":[],"length":0,"stats":{"Line":4}},{"line":104,"address":[],"length":0,"stats":{"Line":4}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":3}},{"line":124,"address":[],"length":0,"stats":{"Line":3}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":1}},{"line":165,"address":[],"length":0,"stats":{"Line":2}},{"line":166,"address":[],"length":0,"stats":{"Line":4}},{"line":167,"address":[],"length":0,"stats":{"Line":2}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":4}},{"line":172,"address":[],"length":0,"stats":{"Line":4}},{"line":173,"address":[],"length":0,"stats":{"Line":4}},{"line":174,"address":[],"length":0,"stats":{"Line":4}},{"line":175,"address":[],"length":0,"stats":{"Line":2}},{"line":177,"address":[],"length":0,"stats":{"Line":6}},{"line":179,"address":[],"length":0,"stats":{"Line":4}},{"line":180,"address":[],"length":0,"stats":{"Line":6}},{"line":182,"address":[],"length":0,"stats":{"Line":2}},{"line":183,"address":[],"length":0,"stats":{"Line":6}},{"line":184,"address":[],"length":0,"stats":{"Line":4}},{"line":186,"address":[],"length":0,"stats":{"Line":1}},{"line":189,"address":[],"length":0,"stats":{"Line":3}},{"line":197,"address":[],"length":0,"stats":{"Line":6}},{"line":198,"address":[],"length":0,"stats":{"Line":9}},{"line":199,"address":[],"length":0,"stats":{"Line":3}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":6}},{"line":204,"address":[],"length":0,"stats":{"Line":6}},{"line":205,"address":[],"length":0,"stats":{"Line":6}},{"line":206,"address":[],"length":0,"stats":{"Line":6}},{"line":207,"address":[],"length":0,"stats":{"Line":3}},{"line":209,"address":[],"length":0,"stats":{"Line":9}},{"line":211,"address":[],"length":0,"stats":{"Line":6}},{"line":212,"address":[],"length":0,"stats":{"Line":6}},{"line":213,"address":[],"length":0,"stats":{"Line":6}},{"line":214,"address":[],"length":0,"stats":{"Line":12}},{"line":216,"address":[],"length":0,"stats":{"Line":3}},{"line":217,"address":[],"length":0,"stats":{"Line":9}},{"line":218,"address":[],"length":0,"stats":{"Line":6}},{"line":220,"address":[],"length":0,"stats":{"Line":3}},{"line":223,"address":[],"length":0,"stats":{"Line":3}},{"line":230,"address":[],"length":0,"stats":{"Line":6}},{"line":231,"address":[],"length":0,"stats":{"Line":9}},{"line":232,"address":[],"length":0,"stats":{"Line":3}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":6}},{"line":237,"address":[],"length":0,"stats":{"Line":6}},{"line":238,"address":[],"length":0,"stats":{"Line":6}},{"line":239,"address":[],"length":0,"stats":{"Line":6}},{"line":240,"address":[],"length":0,"stats":{"Line":3}},{"line":242,"address":[],"length":0,"stats":{"Line":9}},{"line":244,"address":[],"length":0,"stats":{"Line":6}},{"line":245,"address":[],"length":0,"stats":{"Line":9}},{"line":247,"address":[],"length":0,"stats":{"Line":3}},{"line":248,"address":[],"length":0,"stats":{"Line":9}},{"line":249,"address":[],"length":0,"stats":{"Line":6}},{"line":251,"address":[],"length":0,"stats":{"Line":3}},{"line":254,"address":[],"length":0,"stats":{"Line":16}},{"line":255,"address":[],"length":0,"stats":{"Line":8}},{"line":256,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":8}},{"line":264,"address":[],"length":0,"stats":{"Line":16}},{"line":265,"address":[],"length":0,"stats":{"Line":8}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":0}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":8}},{"line":275,"address":[],"length":0,"stats":{"Line":8}},{"line":279,"address":[],"length":0,"stats":{"Line":32}},{"line":280,"address":[],"length":0,"stats":{"Line":16}},{"line":281,"address":[],"length":0,"stats":{"Line":0}}],"covered":64,"coverable":110},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","extensions","prompt.rs"],"content":"use std::collections::HashMap;\n\n#[derive(Debug, Clone, Default)]\npub struct PromptWiring {\n    pub additions: Vec<PromptAddition>,\n    pub tool_config: ToolConfig,\n    pub sequencing_hints: Vec<ToolSequenceHint>,\n}\n\n#[derive(Debug, Clone)]\npub struct ToolSequenceHint {\n    pub when_tool: String,\n    pub suggest_next: String,\n}\n\n#[derive(Debug, Clone)]\npub struct PromptAddition {\n    pub role: String,\n    pub content: String,\n}\n\n#[derive(Debug, Clone, Default)]\npub struct ToolConfig {\n    pub disabled_tools: Vec<String>,\n    pub suggested_tools: Vec<String>,\n    pub overrides: HashMap<String, String>,\n    pub hints: Vec<String>,\n    pub context_hints: Vec<String>,\n}\n\nimpl ToolConfig {\n    pub fn merge(&mut self, other: ToolConfig) {\n        self.disabled_tools.extend(other.disabled_tools);\n        self.suggested_tools.extend(other.suggested_tools);\n        self.hints.extend(other.hints);\n        self.context_hints.extend(other.context_hints);\n        for (key, value) in other.overrides {\n            self.overrides.insert(key, value);\n        }\n        self.dedup();\n    }\n\n    fn dedup(&mut self) {\n        self.disabled_tools.sort();\n        self.disabled_tools.dedup();\n        self.suggested_tools.sort();\n        self.suggested_tools.dedup();\n        self.hints.sort();\n        self.hints.dedup();\n        self.context_hints.sort();\n        self.context_hints.dedup();\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_tool_config_merge() {\n        let mut a = ToolConfig::default();\n        a.disabled_tools.push(\"a\".to_string());\n        let mut b = ToolConfig::default();\n        b.disabled_tools.push(\"b\".to_string());\n        b.suggested_tools.push(\"tool\".to_string());\n        b.context_hints.push(\"hint\".to_string());\n\n        a.merge(b);\n        assert!(a.disabled_tools.contains(&\"a\".to_string()));\n        assert!(a.disabled_tools.contains(&\"b\".to_string()));\n        assert!(a.suggested_tools.contains(&\"tool\".to_string()));\n        assert!(a.context_hints.contains(&\"hint\".to_string()));\n    }\n}\n","traces":[{"line":32,"address":[],"length":0,"stats":{"Line":5}},{"line":33,"address":[],"length":0,"stats":{"Line":15}},{"line":34,"address":[],"length":0,"stats":{"Line":15}},{"line":35,"address":[],"length":0,"stats":{"Line":15}},{"line":36,"address":[],"length":0,"stats":{"Line":15}},{"line":37,"address":[],"length":0,"stats":{"Line":9}},{"line":38,"address":[],"length":0,"stats":{"Line":3}},{"line":40,"address":[],"length":0,"stats":{"Line":10}},{"line":43,"address":[],"length":0,"stats":{"Line":5}},{"line":44,"address":[],"length":0,"stats":{"Line":5}},{"line":45,"address":[],"length":0,"stats":{"Line":10}},{"line":46,"address":[],"length":0,"stats":{"Line":5}},{"line":47,"address":[],"length":0,"stats":{"Line":10}},{"line":48,"address":[],"length":0,"stats":{"Line":5}},{"line":49,"address":[],"length":0,"stats":{"Line":10}},{"line":50,"address":[],"length":0,"stats":{"Line":5}},{"line":51,"address":[],"length":0,"stats":{"Line":10}}],"covered":17,"coverable":17},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","extensions","registry.rs"],"content":"use std::collections::HashMap;\nuse std::sync::Arc;\n\nuse super::{\n    ExtensionCallback, ExtensionError, ExtensionStateConfig, PromptAddition, PromptWiring,\n    ToolConfig,\n};\n\n#[derive(Clone)]\npub struct ExtensionRegistration {\n    pub id: String,\n    pub callbacks: Arc<dyn ExtensionCallback>,\n    pub prompt_additions: Vec<PromptAddition>,\n    pub tool_config: ToolConfig,\n    pub sequence_hints: Vec<super::prompt::ToolSequenceHint>,\n    pub priority: i32,\n    pub enabled: bool,\n    pub state_config: ExtensionStateConfig,\n}\n\nimpl ExtensionRegistration {\n    pub fn new(id: impl Into<String>, callbacks: Arc<dyn ExtensionCallback>) -> Self {\n        Self {\n            id: id.into(),\n            callbacks,\n            prompt_additions: Vec::new(),\n            tool_config: ToolConfig::default(),\n            sequence_hints: Vec::new(),\n            priority: 0,\n            enabled: true,\n            state_config: ExtensionStateConfig::default(),\n        }\n    }\n\n    pub fn with_priority(mut self, priority: i32) -> Self {\n        self.priority = priority;\n        self\n    }\n\n    pub fn with_prompt_additions(mut self, additions: Vec<PromptAddition>) -> Self {\n        self.prompt_additions = additions;\n        self\n    }\n\n    pub fn with_tool_config(mut self, config: ToolConfig) -> Self {\n        self.tool_config = config;\n        self\n    }\n\n    pub fn with_sequence_hints(mut self, hints: Vec<super::prompt::ToolSequenceHint>) -> Self {\n        self.sequence_hints = hints;\n        self\n    }\n\n    pub fn enabled(mut self, enabled: bool) -> Self {\n        self.enabled = enabled;\n        self\n    }\n\n    pub fn with_state_config(mut self, config: ExtensionStateConfig) -> Self {\n        self.state_config = config;\n        self\n    }\n}\n\npub struct ExtensionRegistry {\n    extensions: HashMap<String, ExtensionRegistration>,\n}\n\nimpl ExtensionRegistry {\n    pub fn new() -> Self {\n        Self {\n            extensions: HashMap::new(),\n        }\n    }\n\n    pub fn register_extension(\n        &mut self,\n        registration: ExtensionRegistration,\n    ) -> Result<(), ExtensionError> {\n        if self.extensions.contains_key(&registration.id) {\n            return Err(ExtensionError::AlreadyRegistered);\n        }\n        if registration.id.trim().is_empty() {\n            return Err(ExtensionError::InvalidRegistration(\"Empty id\".to_string()));\n        }\n        self.validate_registration(&registration)?;\n        self.extensions\n            .insert(registration.id.clone(), registration);\n        Ok(())\n    }\n\n    fn validate_registration(\n        &self,\n        registration: &ExtensionRegistration,\n    ) -> Result<(), ExtensionError> {\n        if registration\n            .prompt_additions\n            .iter()\n            .any(|p| p.role.trim().is_empty())\n        {\n            return Err(ExtensionError::InvalidRegistration(\n                \"Missing role\".to_string(),\n            ));\n        }\n        if registration\n            .prompt_additions\n            .iter()\n            .any(|p| p.content.trim().is_empty())\n        {\n            return Err(ExtensionError::InvalidRegistration(\n                \"Missing content\".to_string(),\n            ));\n        }\n        if registration\n            .tool_config\n            .disabled_tools\n            .iter()\n            .any(|t| t.trim().is_empty())\n        {\n            return Err(ExtensionError::InvalidRegistration(\n                \"Invalid tool name\".to_string(),\n            ));\n        }\n        if registration\n            .sequence_hints\n            .iter()\n            .any(|h| h.when_tool.trim().is_empty())\n        {\n            return Err(ExtensionError::InvalidRegistration(\n                \"Missing tool hint\".to_string(),\n            ));\n        }\n        for (key, value) in &registration.tool_config.overrides {\n            if key.trim().is_empty() || value.trim().is_empty() {\n                return Err(ExtensionError::InvalidRegistration(\n                    \"Invalid override\".to_string(),\n                ));\n            }\n            if self\n                .extensions\n                .values()\n                .any(|ext| ext.tool_config.overrides.get(key).is_some())\n            {\n                return Err(ExtensionError::InvalidRegistration(\n                    \"Conflicting tool override\".to_string(),\n                ));\n            }\n        }\n        Ok(())\n    }\n\n    pub fn enable_extension(&mut self, id: &str, enabled: bool) -> Result<(), ExtensionError> {\n        let extension = self\n            .extensions\n            .get_mut(id)\n            .ok_or(ExtensionError::NotFound)?;\n        extension.enabled = enabled;\n        Ok(())\n    }\n\n    pub fn list_ordered(&self) -> Vec<ExtensionRegistration> {\n        let mut extensions: Vec<_> = self.extensions.values().cloned().collect();\n        extensions.sort_by(|a, b| b.priority.cmp(&a.priority));\n        extensions\n    }\n\n    pub fn prompt_wiring(&self) -> PromptWiring {\n        let mut wiring = PromptWiring::default();\n        for extension in self.list_ordered() {\n            if !extension.enabled {\n                continue;\n            }\n            wiring.additions.extend(extension.prompt_additions.clone());\n            wiring.tool_config.merge(extension.tool_config.clone());\n            wiring\n                .sequencing_hints\n                .extend(extension.sequence_hints.clone());\n        }\n        wiring\n    }\n}\n\nimpl Default for ExtensionRegistry {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::extensions::ExtensionCallback;\n    use async_trait::async_trait;\n\n    struct Noop;\n\n    #[async_trait]\n    impl ExtensionCallback for Noop {}\n\n    #[test]\n    fn test_registry_ordering() {\n        let mut registry = ExtensionRegistry::new();\n        let a = ExtensionRegistration::new(\"a\", Arc::new(Noop)).with_priority(1);\n        let b = ExtensionRegistration::new(\"b\", Arc::new(Noop)).with_priority(5);\n        registry.register_extension(a).unwrap();\n        registry.register_extension(b).unwrap();\n\n        let ordered = registry.list_ordered();\n        assert_eq!(ordered[0].id, \"b\");\n    }\n\n    #[test]\n    fn test_registry_validation() {\n        let mut registry = ExtensionRegistry::new();\n        let invalid = ExtensionRegistration::new(\"\", Arc::new(Noop));\n        let err = registry.register_extension(invalid).unwrap_err();\n        assert!(matches!(err, ExtensionError::InvalidRegistration(_)));\n    }\n\n    #[test]\n    fn test_registry_conflicting_override() {\n        let mut registry = ExtensionRegistry::new();\n        let mut config = ToolConfig::default();\n        config.overrides.insert(\"tool\".to_string(), \"a\".to_string());\n        registry\n            .register_extension(\n                ExtensionRegistration::new(\"a\", Arc::new(Noop)).with_tool_config(config),\n            )\n            .unwrap();\n\n        let mut config = ToolConfig::default();\n        config.overrides.insert(\"tool\".to_string(), \"b\".to_string());\n        let err = registry\n            .register_extension(\n                ExtensionRegistration::new(\"b\", Arc::new(Noop)).with_tool_config(config),\n            )\n            .unwrap_err();\n        assert!(matches!(err, ExtensionError::InvalidRegistration(_)));\n    }\n\n    #[test]\n    fn test_prompt_wiring_merge() {\n        let mut registry = ExtensionRegistry::new();\n        let mut config = ToolConfig::default();\n        config.suggested_tools.push(\"tool1\".to_string());\n        let hint = super::super::prompt::ToolSequenceHint {\n            when_tool: \"a\".to_string(),\n            suggest_next: \"b\".to_string(),\n        };\n        registry\n            .register_extension(\n                ExtensionRegistration::new(\"a\", Arc::new(Noop))\n                    .with_tool_config(config)\n                    .with_sequence_hints(vec![hint])\n                    .with_prompt_additions(vec![PromptAddition {\n                        role: \"system\".to_string(),\n                        content: \"hint\".to_string(),\n                    }]),\n            )\n            .unwrap();\n\n        let wiring = registry.prompt_wiring();\n        assert_eq!(wiring.additions.len(), 1);\n        assert_eq!(wiring.sequencing_hints.len(), 1);\n        assert!(\n            wiring\n                .tool_config\n                .suggested_tools\n                .contains(&\"tool1\".to_string())\n        );\n    }\n}\n","traces":[{"line":22,"address":[],"length":0,"stats":{"Line":11}},{"line":24,"address":[],"length":0,"stats":{"Line":33}},{"line":26,"address":[],"length":0,"stats":{"Line":22}},{"line":27,"address":[],"length":0,"stats":{"Line":22}},{"line":28,"address":[],"length":0,"stats":{"Line":11}},{"line":31,"address":[],"length":0,"stats":{"Line":11}},{"line":35,"address":[],"length":0,"stats":{"Line":4}},{"line":36,"address":[],"length":0,"stats":{"Line":4}},{"line":37,"address":[],"length":0,"stats":{"Line":4}},{"line":40,"address":[],"length":0,"stats":{"Line":1}},{"line":41,"address":[],"length":0,"stats":{"Line":2}},{"line":42,"address":[],"length":0,"stats":{"Line":1}},{"line":45,"address":[],"length":0,"stats":{"Line":4}},{"line":46,"address":[],"length":0,"stats":{"Line":8}},{"line":47,"address":[],"length":0,"stats":{"Line":4}},{"line":50,"address":[],"length":0,"stats":{"Line":1}},{"line":51,"address":[],"length":0,"stats":{"Line":2}},{"line":52,"address":[],"length":0,"stats":{"Line":1}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":8}},{"line":73,"address":[],"length":0,"stats":{"Line":8}},{"line":77,"address":[],"length":0,"stats":{"Line":11}},{"line":81,"address":[],"length":0,"stats":{"Line":33}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":22}},{"line":85,"address":[],"length":0,"stats":{"Line":1}},{"line":87,"address":[],"length":0,"stats":{"Line":31}},{"line":88,"address":[],"length":0,"stats":{"Line":9}},{"line":89,"address":[],"length":0,"stats":{"Line":36}},{"line":90,"address":[],"length":0,"stats":{"Line":9}},{"line":93,"address":[],"length":0,"stats":{"Line":10}},{"line":97,"address":[],"length":0,"stats":{"Line":10}},{"line":98,"address":[],"length":0,"stats":{"Line":10}},{"line":100,"address":[],"length":0,"stats":{"Line":12}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":10}},{"line":107,"address":[],"length":0,"stats":{"Line":10}},{"line":109,"address":[],"length":0,"stats":{"Line":12}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":10}},{"line":116,"address":[],"length":0,"stats":{"Line":10}},{"line":117,"address":[],"length":0,"stats":{"Line":10}},{"line":119,"address":[],"length":0,"stats":{"Line":10}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":10}},{"line":126,"address":[],"length":0,"stats":{"Line":10}},{"line":128,"address":[],"length":0,"stats":{"Line":12}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":18}},{"line":135,"address":[],"length":0,"stats":{"Line":12}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":3}},{"line":141,"address":[],"length":0,"stats":{"Line":3}},{"line":143,"address":[],"length":0,"stats":{"Line":6}},{"line":145,"address":[],"length":0,"stats":{"Line":1}},{"line":146,"address":[],"length":0,"stats":{"Line":1}},{"line":150,"address":[],"length":0,"stats":{"Line":9}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":12}},{"line":163,"address":[],"length":0,"stats":{"Line":72}},{"line":164,"address":[],"length":0,"stats":{"Line":30}},{"line":165,"address":[],"length":0,"stats":{"Line":12}},{"line":168,"address":[],"length":0,"stats":{"Line":4}},{"line":169,"address":[],"length":0,"stats":{"Line":8}},{"line":170,"address":[],"length":0,"stats":{"Line":12}},{"line":171,"address":[],"length":0,"stats":{"Line":4}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":16}},{"line":175,"address":[],"length":0,"stats":{"Line":16}},{"line":176,"address":[],"length":0,"stats":{"Line":4}},{"line":177,"address":[],"length":0,"stats":{"Line":4}},{"line":178,"address":[],"length":0,"stats":{"Line":12}},{"line":180,"address":[],"length":0,"stats":{"Line":4}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}}],"covered":64,"coverable":91},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","extensions","state.rs"],"content":"use redis::AsyncCommands;\nuse std::collections::HashMap;\nuse std::io::{Read, Write};\nuse std::sync::Arc;\n\nuse super::{ExtensionContext, ExtensionContextState};\nuse async_trait::async_trait;\nuse knowledge::context_architect::LlmClient;\nuse serde_json::Value;\n\n#[derive(Debug, thiserror::Error)]\npub enum ExtensionStateError {\n    #[error(\"Redis error: {0}\")]\n    Redis(#[from] redis::RedisError),\n\n    #[error(\"Serialization error: {0}\")]\n    Serialization(String),\n}\n\npub type StateMigrator = Arc<\n    dyn Fn(ExtensionContextState) -> Result<ExtensionContextState, ExtensionStateError>\n        + Send\n        + Sync,\n>;\n\npub type StateCompactor = Arc<\n    dyn Fn(ExtensionContextState) -> Result<ExtensionContextState, ExtensionStateError>\n        + Send\n        + Sync,\n>;\n\n#[async_trait]\npub trait AsyncStateCompactor: Send + Sync {\n    async fn compact(\n        &self,\n        payload: ExtensionContextState,\n    ) -> Result<ExtensionContextState, ExtensionStateError>;\n}\n\npub type AsyncStateCompactorHandle = Arc<dyn AsyncStateCompactor>;\n\npub struct ExtensionStateStore {\n    redis_url: String,\n    ttl_secs: u64,\n    version: u32,\n    migrator: Option<StateMigrator>,\n    compactor: Option<StateCompactor>,\n    async_compactor: Option<AsyncStateCompactorHandle>,\n}\n\npub struct LlmStateCompactor<C: LlmClient> {\n    client: Arc<C>,\n    min_state_bytes: usize,\n    max_tokens: u32,\n}\n\nimpl<C: LlmClient> LlmStateCompactor<C> {\n    pub fn new(client: Arc<C>, min_state_bytes: usize, max_tokens: u32) -> Self {\n        Self {\n            client,\n            min_state_bytes,\n            max_tokens,\n        }\n    }\n\n    fn should_compact(&self, payload: &ExtensionContextState) -> bool {\n        serde_json::to_vec(&payload.state)\n            .map(|bytes| bytes.len() >= self.min_state_bytes)\n            .unwrap_or(false)\n    }\n\n    fn build_prompt(&self, payload: &ExtensionContextState) -> Result<String, ExtensionStateError> {\n        let serialized = serde_json::to_string(&payload.state)\n            .map_err(|err| ExtensionStateError::Serialization(err.to_string()))?;\n        Ok(format!(\n            \"Compress the following JSON state for an extension. Preserve key facts, recent \\\n             \\ndecisions, and references needed for future tool calls. Keep JSON structure. \\\n             \\nReturn ONLY valid JSON without markdown. Limit to {max_tokens} \\\n             tokens.\\n\\n{serialized}\",\n            max_tokens = self.max_tokens\n        ))\n    }\n\n    async fn compress_payload(\n        &self,\n        payload: ExtensionContextState,\n    ) -> Result<ExtensionContextState, ExtensionStateError> {\n        if !self.should_compact(&payload) {\n            return Ok(payload);\n        }\n\n        let prompt = self.build_prompt(&payload)?;\n        let response = self\n            .client\n            .complete(&prompt)\n            .await\n            .map_err(|err| ExtensionStateError::Serialization(err.to_string()))?;\n        let trimmed = response.trim();\n        if trimmed.is_empty() {\n            return Ok(payload);\n        }\n\n        let parsed: HashMap<String, Value> = serde_json::from_str(trimmed)\n            .map_err(|err| ExtensionStateError::Serialization(err.to_string()))?;\n        Ok(ExtensionContextState {\n            state: parsed,\n            version: payload.version,\n        })\n    }\n}\n\n#[async_trait]\nimpl<C: LlmClient> AsyncStateCompactor for LlmStateCompactor<C> {\n    async fn compact(\n        &self,\n        payload: ExtensionContextState,\n    ) -> Result<ExtensionContextState, ExtensionStateError> {\n        self.compress_payload(payload).await\n    }\n}\n\nimpl ExtensionStateStore {\n    pub fn new(redis_url: String, ttl_secs: u64) -> Self {\n        Self {\n            redis_url,\n            ttl_secs,\n            version: 1,\n            migrator: None,\n            compactor: None,\n            async_compactor: None,\n        }\n    }\n\n    pub fn with_version(mut self, version: u32) -> Self {\n        self.version = version;\n        self\n    }\n\n    pub fn migrate_with(mut self, migrator: StateMigrator) -> Self {\n        self.migrator = Some(migrator);\n        self\n    }\n\n    pub fn compact_with(mut self, compactor: StateCompactor) -> Self {\n        self.compactor = Some(compactor);\n        self\n    }\n\n    pub fn compact_with_async(mut self, compactor: AsyncStateCompactorHandle) -> Self {\n        self.async_compactor = Some(compactor);\n        self\n    }\n\n    pub async fn save(&self, ctx: &ExtensionContext) -> Result<(), ExtensionStateError> {\n        let mut con = self.connection().await?;\n        let mut payload = ctx\n            .to_state_payload()\n            .map_err(|err| ExtensionStateError::Serialization(err.to_string()))?;\n        if let Some(compactor) = &self.compactor {\n            payload = compactor(payload)?;\n        }\n        if let Some(compactor) = &self.async_compactor {\n            payload = compactor.compact(payload).await?;\n        }\n        payload.version = self.version;\n        let data = serde_json::to_vec(&payload)\n            .map_err(|err| ExtensionStateError::Serialization(err.to_string()))?;\n        let data = compress_payload(&data)?;\n        let key = self.key(ctx);\n        let _: () = con.set_ex(key, data, self.ttl_secs).await?;\n        Ok(())\n    }\n\n    pub async fn load(&self, ctx: &mut ExtensionContext) -> Result<(), ExtensionStateError> {\n        let mut con = self.connection().await?;\n        let key = self.key(ctx);\n        let data: Option<Vec<u8>> = con.get(key).await?;\n        if let Some(bytes) = data {\n            let bytes = decompress_payload(&bytes)?;\n            let payload: ExtensionContextState = serde_json::from_slice(&bytes)\n                .map_err(|err| ExtensionStateError::Serialization(err.to_string()))?;\n            let payload = self.migrate(payload)?;\n            ctx.replace_state(payload.state);\n        }\n        Ok(())\n    }\n\n    pub async fn delete(&self, ctx: &ExtensionContext) -> Result<(), ExtensionStateError> {\n        let mut con = self.connection().await?;\n        let key = self.key(ctx);\n        let _: () = con.del(key).await?;\n        Ok(())\n    }\n\n    async fn connection(&self) -> Result<redis::aio::ConnectionManager, ExtensionStateError> {\n        let client = redis::Client::open(self.redis_url.clone())?;\n        let con = redis::aio::ConnectionManager::new(client).await?;\n        Ok(con)\n    }\n\n    fn key(&self, ctx: &ExtensionContext) -> String {\n        format!(\n            \"extension:{}:{}:{}\",\n            ctx.tenant_ctx.tenant_id, ctx.session_id, ctx.extension_id\n        )\n    }\n\n    fn migrate(\n        &self,\n        mut payload: ExtensionContextState,\n    ) -> Result<ExtensionContextState, ExtensionStateError> {\n        if payload.version > self.version {\n            return Err(ExtensionStateError::Serialization(\n                \"Unsupported state version\".to_string(),\n            ));\n        }\n        if let Some(migrator) = &self.migrator {\n            payload = migrator(payload)?;\n        }\n        payload.version = self.version;\n        Ok(payload)\n    }\n}\n\nfn compress_payload(data: &[u8]) -> Result<Vec<u8>, ExtensionStateError> {\n    let mut encoder = flate2::write::GzEncoder::new(Vec::new(), flate2::Compression::default());\n    encoder\n        .write_all(data)\n        .map_err(|err| ExtensionStateError::Serialization(err.to_string()))?;\n    encoder\n        .finish()\n        .map_err(|err| ExtensionStateError::Serialization(err.to_string()))\n}\n\nfn decompress_payload(data: &[u8]) -> Result<Vec<u8>, ExtensionStateError> {\n    let mut decoder = flate2::read::GzDecoder::new(data);\n    let mut out = Vec::new();\n    decoder\n        .read_to_end(&mut out)\n        .map_err(|err| ExtensionStateError::Serialization(err.to_string()))?;\n    Ok(out)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::TenantContext;\n    use std::sync::Arc;\n    use testing::redis;\n\n    async fn create_store() -> Option<ExtensionStateStore> {\n        let fixture = redis().await?;\n        Some(ExtensionStateStore::new(fixture.url().to_string(), 60))\n    }\n\n    #[tokio::test]\n    async fn test_state_store_roundtrip() {\n        let Some(store) = create_store().await else {\n            return;\n        };\n        let registry = Arc::new(crate::tools::ToolRegistry::new());\n        let mut ctx = ExtensionContext::new(\n            TenantContext::default(),\n            \"session\".to_string(),\n            \"ext\".to_string(),\n            registry,\n            1024,\n        );\n        ctx.set_state(\"key\", \"value\").unwrap();\n        store.save(&ctx).await.unwrap();\n\n        ctx.clear_state();\n        store.load(&mut ctx).await.unwrap();\n        let value: Option<String> = ctx.get_state(\"key\").unwrap();\n        assert_eq!(value, Some(\"value\".to_string()));\n    }\n\n    #[test]\n    fn test_compression_roundtrip() {\n        let payload = serde_json::to_vec(&ExtensionContextState {\n            state: std::collections::HashMap::from([(\n                \"key\".to_string(),\n                serde_json::json!(\"value\"),\n            )]),\n            version: 1,\n        })\n        .unwrap();\n        let compressed = compress_payload(&payload).unwrap();\n        let decompressed = decompress_payload(&compressed).unwrap();\n        assert_eq!(payload, decompressed);\n    }\n\n    #[test]\n    fn test_compactor() {\n        let compactor: StateCompactor = Arc::new(|mut payload| {\n            payload.state.clear();\n            Ok(payload)\n        });\n        let store =\n            ExtensionStateStore::new(\"redis://localhost\".to_string(), 10).compact_with(compactor);\n        let payload = ExtensionContextState {\n            state: std::collections::HashMap::from([(\n                \"key\".to_string(),\n                serde_json::json!(\"value\"),\n            )]),\n            version: 1,\n        };\n        let compacted = store.compactor.unwrap()(payload).unwrap();\n        assert!(compacted.state.is_empty());\n    }\n\n    #[test]\n    fn test_migrator() {\n        let migrator: StateMigrator = Arc::new(|mut payload| {\n            payload.state.clear();\n            Ok(payload)\n        });\n        let store =\n            ExtensionStateStore::new(\"redis://localhost\".to_string(), 10).migrate_with(migrator);\n        let payload = ExtensionContextState {\n            state: std::collections::HashMap::from([(\n                \"key\".to_string(),\n                serde_json::json!(\"value\"),\n            )]),\n            version: 1,\n        };\n        let migrated = store.migrate(payload).unwrap();\n        assert!(migrated.state.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_llm_state_compactor_respects_threshold() {\n        struct MockClient;\n\n        #[async_trait]\n        impl LlmClient for MockClient {\n            async fn complete(\n                &self,\n                _prompt: &str,\n            ) -> Result<String, knowledge::context_architect::LlmError> {\n                Ok(\"{}\".to_string())\n            }\n\n            async fn complete_with_system(\n                &self,\n                _system: &str,\n                _user: &str,\n            ) -> Result<String, knowledge::context_architect::LlmError> {\n                Ok(\"{}\".to_string())\n            }\n        }\n\n        let compactor = LlmStateCompactor::new(Arc::new(MockClient), 1024, 100);\n        let payload = ExtensionContextState {\n            state: std::collections::HashMap::from([(\n                \"key\".to_string(),\n                serde_json::json!(\"value\"),\n            )]),\n            version: 1,\n        };\n        let compacted = compactor.compact(payload.clone()).await.unwrap();\n        assert_eq!(compacted.state, payload.state);\n    }\n\n    #[tokio::test]\n    async fn test_llm_state_compactor_applies_json() {\n        struct MockClient;\n\n        #[async_trait]\n        impl LlmClient for MockClient {\n            async fn complete(\n                &self,\n                _prompt: &str,\n            ) -> Result<String, knowledge::context_architect::LlmError> {\n                Ok(\"{\\\"summary\\\":\\\"ok\\\"}\".to_string())\n            }\n\n            async fn complete_with_system(\n                &self,\n                _system: &str,\n                _user: &str,\n            ) -> Result<String, knowledge::context_architect::LlmError> {\n                Ok(\"{\\\"summary\\\":\\\"ok\\\"}\".to_string())\n            }\n        }\n\n        let compactor = LlmStateCompactor::new(Arc::new(MockClient), 1, 100);\n        let payload = ExtensionContextState {\n            state: std::collections::HashMap::from([(\n                \"key\".to_string(),\n                serde_json::json!(\"value\"),\n            )]),\n            version: 1,\n        };\n        let compacted = compactor.compact(payload).await.unwrap();\n        assert_eq!(compacted.state.len(), 1);\n        assert_eq!(\n            compacted.state.get(\"summary\").unwrap(),\n            &serde_json::json!(\"ok\")\n        );\n    }\n}\n","traces":[{"line":58,"address":[],"length":0,"stats":{"Line":2}},{"line":66,"address":[],"length":0,"stats":{"Line":2}},{"line":67,"address":[],"length":0,"stats":{"Line":4}},{"line":68,"address":[],"length":0,"stats":{"Line":8}},{"line":72,"address":[],"length":0,"stats":{"Line":1}},{"line":73,"address":[],"length":0,"stats":{"Line":3}},{"line":74,"address":[],"length":0,"stats":{"Line":1}},{"line":75,"address":[],"length":0,"stats":{"Line":1}},{"line":76,"address":[],"length":0,"stats":{"Line":1}},{"line":77,"address":[],"length":0,"stats":{"Line":1}},{"line":78,"address":[],"length":0,"stats":{"Line":1}},{"line":79,"address":[],"length":0,"stats":{"Line":1}},{"line":80,"address":[],"length":0,"stats":{"Line":1}},{"line":84,"address":[],"length":0,"stats":{"Line":2}},{"line":88,"address":[],"length":0,"stats":{"Line":4}},{"line":89,"address":[],"length":0,"stats":{"Line":1}},{"line":92,"address":[],"length":0,"stats":{"Line":4}},{"line":93,"address":[],"length":0,"stats":{"Line":3}},{"line":94,"address":[],"length":0,"stats":{"Line":2}},{"line":95,"address":[],"length":0,"stats":{"Line":1}},{"line":96,"address":[],"length":0,"stats":{"Line":1}},{"line":97,"address":[],"length":0,"stats":{"Line":1}},{"line":98,"address":[],"length":0,"stats":{"Line":2}},{"line":99,"address":[],"length":0,"stats":{"Line":2}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":4}},{"line":104,"address":[],"length":0,"stats":{"Line":1}},{"line":105,"address":[],"length":0,"stats":{"Line":1}},{"line":106,"address":[],"length":0,"stats":{"Line":1}},{"line":107,"address":[],"length":0,"stats":{"Line":1}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":2}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":1}},{"line":140,"address":[],"length":0,"stats":{"Line":2}},{"line":141,"address":[],"length":0,"stats":{"Line":1}},{"line":144,"address":[],"length":0,"stats":{"Line":1}},{"line":145,"address":[],"length":0,"stats":{"Line":2}},{"line":146,"address":[],"length":0,"stats":{"Line":1}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":201,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":1}},{"line":212,"address":[],"length":0,"stats":{"Line":1}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":2}},{"line":218,"address":[],"length":0,"stats":{"Line":2}},{"line":220,"address":[],"length":0,"stats":{"Line":1}},{"line":221,"address":[],"length":0,"stats":{"Line":1}},{"line":225,"address":[],"length":0,"stats":{"Line":1}},{"line":226,"address":[],"length":0,"stats":{"Line":4}},{"line":227,"address":[],"length":0,"stats":{"Line":1}},{"line":228,"address":[],"length":0,"stats":{"Line":2}},{"line":229,"address":[],"length":0,"stats":{"Line":1}},{"line":230,"address":[],"length":0,"stats":{"Line":1}},{"line":232,"address":[],"length":0,"stats":{"Line":1}},{"line":235,"address":[],"length":0,"stats":{"Line":1}},{"line":236,"address":[],"length":0,"stats":{"Line":3}},{"line":237,"address":[],"length":0,"stats":{"Line":2}},{"line":238,"address":[],"length":0,"stats":{"Line":1}},{"line":239,"address":[],"length":0,"stats":{"Line":2}},{"line":240,"address":[],"length":0,"stats":{"Line":1}},{"line":241,"address":[],"length":0,"stats":{"Line":1}}],"covered":56,"coverable":103},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","governance.rs"],"content":"use crate::tools::Tool;\nuse async_trait::async_trait;\nuse knowledge::governance::GovernanceEngine;\nuse mk_core::types::{GovernanceEvent, OrganizationalUnit, Role, TenantContext, UnitType};\nuse schemars::JsonSchema;\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Value, json};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse validator::Validate;\n\n/// Tool to create a new organizational unit.\npub struct UnitCreateTool {\n    backend: Arc<dyn mk_core::traits::StorageBackend<Error = storage::postgres::PostgresError>>,\n    governance_engine: Arc<GovernanceEngine>,\n}\n\nimpl UnitCreateTool {\n    pub fn new(\n        backend: Arc<dyn mk_core::traits::StorageBackend<Error = storage::postgres::PostgresError>>,\n        governance_engine: Arc<GovernanceEngine>,\n    ) -> Self {\n        Self {\n            backend,\n            governance_engine,\n        }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct UnitCreateParams {\n    pub name: String,\n    pub unit_type: String,\n    pub parent_id: Option<String>,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n    #[serde(default)]\n    pub metadata: HashMap<String, Value>,\n}\n\n#[async_trait]\nimpl Tool for UnitCreateTool {\n    fn name(&self) -> &str {\n        \"governance_unit_create\"\n    }\n\n    fn description(&self) -> &str {\n        \"Create a new organizational unit (Company, Organization, Team, or Project).\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"name\": { \"type\": \"string\", \"description\": \"Name of the unit\" },\n                \"unit_type\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"company\", \"organization\", \"team\", \"project\"],\n                    \"description\": \"Type of the unit\"\n                },\n                \"parent_id\": { \"type\": \"string\", \"description\": \"Parent unit ID\" },\n                \"metadata\": { \"type\": \"object\", \"description\": \"Optional metadata\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"name\", \"unit_type\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: UnitCreateParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let unit_type = match p.unit_type.as_str() {\n            \"company\" => UnitType::Company,\n            \"organization\" => UnitType::Organization,\n            \"team\" => UnitType::Team,\n            \"project\" => UnitType::Project,\n            _ => return Err(\"Invalid unit type\".into()),\n        };\n\n        let unit = OrganizationalUnit {\n            id: uuid::Uuid::new_v4().to_string(),\n            name: p.name,\n            unit_type,\n            parent_id: p.parent_id,\n            tenant_id: ctx.tenant_id.clone(),\n            metadata: p.metadata,\n            created_at: chrono::Utc::now().timestamp(),\n            updated_at: chrono::Utc::now().timestamp(),\n        };\n\n        self.backend.create_unit(&unit).await?;\n\n        let _ = self\n            .governance_engine\n            .publish_event(GovernanceEvent::UnitCreated {\n                unit_id: unit.id.clone(),\n                unit_type: unit.unit_type,\n                tenant_id: ctx.tenant_id.clone(),\n                parent_id: unit.parent_id.clone(),\n                timestamp: chrono::Utc::now().timestamp(),\n            })\n            .await;\n\n        Ok(json!({\n            \"success\": true,\n            \"unit_id\": unit.id\n        }))\n    }\n}\n\n/// Tool to add a policy to an organizational unit.\npub struct UnitPolicyAddTool {\n    backend: Arc<dyn mk_core::traits::StorageBackend<Error = storage::postgres::PostgresError>>,\n    governance_engine: Arc<GovernanceEngine>,\n}\n\nimpl UnitPolicyAddTool {\n    pub fn new(\n        backend: Arc<dyn mk_core::traits::StorageBackend<Error = storage::postgres::PostgresError>>,\n        governance_engine: Arc<GovernanceEngine>,\n    ) -> Self {\n        Self {\n            backend,\n            governance_engine,\n        }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct UnitPolicyAddParams {\n    pub unit_id: String,\n    pub policy: mk_core::types::Policy,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[async_trait]\nimpl Tool for UnitPolicyAddTool {\n    fn name(&self) -> &str {\n        \"governance_policy_add\"\n    }\n\n    fn description(&self) -> &str {\n        \"Add or update a policy for an organizational unit.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"unit_id\": { \"type\": \"string\", \"description\": \"Unit ID to attach policy to\" },\n                \"policy\": { \"type\": \"object\", \"description\": \"Policy definition\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"unit_id\", \"policy\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: UnitPolicyAddParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        self.backend\n            .add_unit_policy(&ctx, &p.unit_id, &p.policy)\n            .await?;\n\n        let _ = self\n            .governance_engine\n            .publish_event(GovernanceEvent::PolicyUpdated {\n                policy_id: p.policy.id.clone(),\n                layer: p.policy.layer,\n                tenant_id: ctx.tenant_id.clone(),\n                timestamp: chrono::Utc::now().timestamp(),\n            })\n            .await;\n\n        Ok(json!({\n            \"success\": true,\n            \"policy_id\": p.policy.id\n        }))\n    }\n}\n\n/// Tool to assign a role to a user within an organizational unit.\npub struct UserRoleAssignTool {\n    backend: Arc<dyn mk_core::traits::StorageBackend<Error = storage::postgres::PostgresError>>,\n    governance_engine: Arc<GovernanceEngine>,\n}\n\nimpl UserRoleAssignTool {\n    pub fn new(\n        backend: Arc<dyn mk_core::traits::StorageBackend<Error = storage::postgres::PostgresError>>,\n        governance_engine: Arc<GovernanceEngine>,\n    ) -> Self {\n        Self {\n            backend,\n            governance_engine,\n        }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct UserRoleAssignParams {\n    pub user_id: String,\n    pub unit_id: String,\n    pub role: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[async_trait]\nimpl Tool for UserRoleAssignTool {\n    fn name(&self) -> &str {\n        \"governance_role_assign\"\n    }\n\n    fn description(&self) -> &str {\n        \"Assign a role to a user within a specific organizational unit.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"user_id\": { \"type\": \"string\", \"description\": \"User ID\" },\n                \"unit_id\": { \"type\": \"string\", \"description\": \"Unit ID\" },\n                \"role\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"developer\", \"techlead\", \"architect\", \"admin\", \"agent\"],\n                    \"description\": \"Role to assign\"\n                },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"user_id\", \"unit_id\", \"role\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: UserRoleAssignParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n        let user_id = mk_core::types::UserId::new(p.user_id).ok_or(\"Invalid user ID\")?;\n        let role: Role = p.role.parse()?;\n\n        self.backend\n            .assign_role(&user_id, &ctx.tenant_id, &p.unit_id, role.clone())\n            .await?;\n\n        let _ = self\n            .governance_engine\n            .publish_event(GovernanceEvent::RoleAssigned {\n                user_id: user_id.clone(),\n                unit_id: p.unit_id.clone(),\n                role,\n                tenant_id: ctx.tenant_id.clone(),\n                timestamp: chrono::Utc::now().timestamp(),\n            })\n            .await;\n\n        Ok(json!({\n            \"success\": true\n        }))\n    }\n}\n\n/// Tool to remove a role from a user within an organizational unit.\npub struct UserRoleRemoveTool {\n    backend: Arc<dyn mk_core::traits::StorageBackend<Error = storage::postgres::PostgresError>>,\n    governance_engine: Arc<GovernanceEngine>,\n}\n\nimpl UserRoleRemoveTool {\n    pub fn new(\n        backend: Arc<dyn mk_core::traits::StorageBackend<Error = storage::postgres::PostgresError>>,\n        governance_engine: Arc<GovernanceEngine>,\n    ) -> Self {\n        Self {\n            backend,\n            governance_engine,\n        }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct UserRoleRemoveParams {\n    pub user_id: String,\n    pub unit_id: String,\n    pub role: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[async_trait]\nimpl Tool for UserRoleRemoveTool {\n    fn name(&self) -> &str {\n        \"governance_role_remove\"\n    }\n\n    fn description(&self) -> &str {\n        \"Remove a role from a user within a specific organizational unit.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"user_id\": { \"type\": \"string\", \"description\": \"User ID\" },\n                \"unit_id\": { \"type\": \"string\", \"description\": \"Unit ID\" },\n                \"role\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"developer\", \"techlead\", \"architect\", \"admin\", \"agent\"],\n                    \"description\": \"Role to remove\"\n                },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"user_id\", \"unit_id\", \"role\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: UserRoleRemoveParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n        let user_id = mk_core::types::UserId::new(p.user_id).ok_or(\"Invalid user ID\")?;\n        let role: Role = p.role.parse()?;\n\n        self.backend\n            .remove_role(&user_id, &ctx.tenant_id, &p.unit_id, role.clone())\n            .await?;\n\n        let _ = self\n            .governance_engine\n            .publish_event(GovernanceEvent::RoleRemoved {\n                user_id: user_id.clone(),\n                unit_id: p.unit_id.clone(),\n                role,\n                tenant_id: ctx.tenant_id.clone(),\n                timestamp: chrono::Utc::now().timestamp(),\n            })\n            .await;\n\n        Ok(json!({\n            \"success\": true\n        }))\n    }\n}\n\npub struct HierarchyNavigateTool {\n    backend: Arc<dyn mk_core::traits::StorageBackend<Error = storage::postgres::PostgresError>>,\n}\n\nimpl HierarchyNavigateTool {\n    pub fn new(\n        backend: Arc<dyn mk_core::traits::StorageBackend<Error = storage::postgres::PostgresError>>,\n    ) -> Self {\n        Self { backend }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct HierarchyNavigateParams {\n    pub unit_id: String,\n    pub direction: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[async_trait]\nimpl Tool for HierarchyNavigateTool {\n    fn name(&self) -> &str {\n        \"governance_hierarchy_navigate\"\n    }\n\n    fn description(&self) -> &str {\n        \"Navigate the organizational hierarchy (ancestors or descendants) for a unit.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"unit_id\": { \"type\": \"string\", \"description\": \"Starting Unit ID\" },\n                \"direction\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"ancestors\", \"descendants\"],\n                    \"description\": \"Navigation direction\"\n                },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"unit_id\", \"direction\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: HierarchyNavigateParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let units = match p.direction.as_str() {\n            \"ancestors\" => self.backend.get_ancestors(ctx, &p.unit_id).await?,\n            \"descendants\" => self.backend.get_descendants(ctx, &p.unit_id).await?,\n            _ => return Err(\"Invalid direction\".into()),\n        };\n\n        Ok(json!({\n            \"success\": true,\n            \"units\": units\n        }))\n    }\n}\n\n// =============================================================================\n// GOVERNANCE WORKFLOW TOOLS - Approval Request Management\n// =============================================================================\n\nuse storage::governance::{\n    ApprovalMode, ApprovalRequest, AuditFilters, CreateApprovalRequest, CreateDecision,\n    CreateGovernanceRole, Decision, GovernanceAuditEntry, GovernanceConfig, GovernanceRole,\n    GovernanceStorage, PrincipalType, RequestFilters, RequestStatus, RequestType, RiskLevel,\n};\n\n/// Tool to configure governance settings for a scope (company, org, team, project).\npub struct GovernanceConfigureTool {\n    storage: Arc<GovernanceStorage>,\n    governance_engine: Arc<GovernanceEngine>,\n}\n\nimpl GovernanceConfigureTool {\n    pub fn new(storage: Arc<GovernanceStorage>, governance_engine: Arc<GovernanceEngine>) -> Self {\n        Self {\n            storage,\n            governance_engine,\n        }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct GovernanceConfigureParams {\n    /// Company ID for company-level config\n    pub company_id: Option<String>,\n    /// Organization ID for org-level config\n    pub org_id: Option<String>,\n    /// Team ID for team-level config\n    pub team_id: Option<String>,\n    /// Project ID for project-level config\n    pub project_id: Option<String>,\n    /// Approval mode: single, quorum, unanimous\n    pub approval_mode: Option<String>,\n    /// Minimum number of approvers required\n    pub min_approvers: Option<i32>,\n    /// Timeout in hours before request expires\n    pub timeout_hours: Option<i32>,\n    /// Auto-approve low-risk requests\n    pub auto_approve_low_risk: Option<bool>,\n    /// Enable escalation workflow\n    pub escalation_enabled: Option<bool>,\n    /// Hours before escalation triggers\n    pub escalation_timeout_hours: Option<i32>,\n    /// Email/contact for escalations\n    pub escalation_contact: Option<String>,\n    /// Policy-specific settings (JSON)\n    pub policy_settings: Option<Value>,\n    /// Knowledge-specific settings (JSON)\n    pub knowledge_settings: Option<Value>,\n    /// Memory-specific settings (JSON)\n    pub memory_settings: Option<Value>,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[async_trait]\nimpl Tool for GovernanceConfigureTool {\n    fn name(&self) -> &str {\n        \"governance_configure\"\n    }\n\n    fn description(&self) -> &str {\n        \"Configure governance settings (approval mode, thresholds, escalation) for a scope.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"company_id\": { \"type\": \"string\", \"description\": \"Company ID\" },\n                \"org_id\": { \"type\": \"string\", \"description\": \"Organization ID\" },\n                \"team_id\": { \"type\": \"string\", \"description\": \"Team ID\" },\n                \"project_id\": { \"type\": \"string\", \"description\": \"Project ID\" },\n                \"approval_mode\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"single\", \"quorum\", \"unanimous\"],\n                    \"description\": \"How approvals are counted\"\n                },\n                \"min_approvers\": { \"type\": \"integer\", \"minimum\": 1, \"description\": \"Minimum approvers required\" },\n                \"timeout_hours\": { \"type\": \"integer\", \"minimum\": 1, \"description\": \"Request expiration hours\" },\n                \"auto_approve_low_risk\": { \"type\": \"boolean\", \"description\": \"Auto-approve low-risk requests\" },\n                \"escalation_enabled\": { \"type\": \"boolean\", \"description\": \"Enable escalation workflow\" },\n                \"escalation_timeout_hours\": { \"type\": \"integer\", \"description\": \"Hours before escalation\" },\n                \"escalation_contact\": { \"type\": \"string\", \"description\": \"Escalation contact email\" },\n                \"policy_settings\": { \"type\": \"object\", \"description\": \"Policy-specific config\" },\n                \"knowledge_settings\": { \"type\": \"object\", \"description\": \"Knowledge-specific config\" },\n                \"memory_settings\": { \"type\": \"object\", \"description\": \"Memory-specific config\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"anyOf\": [\n                { \"required\": [\"company_id\"] },\n                { \"required\": [\"org_id\"] },\n                { \"required\": [\"team_id\"] },\n                { \"required\": [\"project_id\"] }\n            ]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: GovernanceConfigureParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        // Get existing config or use defaults\n        let existing = self\n            .storage\n            .get_effective_config(\n                p.company_id.as_ref().and_then(|s| s.parse().ok()),\n                p.org_id.as_ref().and_then(|s| s.parse().ok()),\n                p.team_id.as_ref().and_then(|s| s.parse().ok()),\n                p.project_id.as_ref().and_then(|s| s.parse().ok()),\n            )\n            .await\n            .unwrap_or_default();\n\n        // Build new config with overrides\n        let config = GovernanceConfig {\n            id: existing.id,\n            company_id: p.company_id.as_ref().and_then(|s| s.parse().ok()),\n            org_id: p.org_id.as_ref().and_then(|s| s.parse().ok()),\n            team_id: p.team_id.as_ref().and_then(|s| s.parse().ok()),\n            project_id: p.project_id.as_ref().and_then(|s| s.parse().ok()),\n            approval_mode: p\n                .approval_mode\n                .as_ref()\n                .and_then(|s| s.parse().ok())\n                .unwrap_or(existing.approval_mode),\n            min_approvers: p.min_approvers.unwrap_or(existing.min_approvers),\n            timeout_hours: p.timeout_hours.unwrap_or(existing.timeout_hours),\n            auto_approve_low_risk: p\n                .auto_approve_low_risk\n                .unwrap_or(existing.auto_approve_low_risk),\n            escalation_enabled: p.escalation_enabled.unwrap_or(existing.escalation_enabled),\n            escalation_timeout_hours: p\n                .escalation_timeout_hours\n                .unwrap_or(existing.escalation_timeout_hours),\n            escalation_contact: p.escalation_contact.or(existing.escalation_contact),\n            policy_settings: p.policy_settings.unwrap_or(existing.policy_settings),\n            knowledge_settings: p.knowledge_settings.unwrap_or(existing.knowledge_settings),\n            memory_settings: p.memory_settings.unwrap_or(existing.memory_settings),\n        };\n\n        let config_id = self.storage.upsert_config(&config).await?;\n\n        // Publish governance event\n        let _ = self\n            .governance_engine\n            .publish_event(GovernanceEvent::ConfigUpdated {\n                config_id: config_id.to_string(),\n                scope: format!(\n                    \"company={:?},org={:?},team={:?},project={:?}\",\n                    p.company_id, p.org_id, p.team_id, p.project_id\n                ),\n                tenant_id: ctx.tenant_id.clone(),\n                timestamp: chrono::Utc::now().timestamp(),\n            })\n            .await;\n\n        Ok(json!({\n            \"success\": true,\n            \"config_id\": config_id.to_string(),\n            \"config\": config\n        }))\n    }\n}\n\n/// Tool to get effective governance configuration for a scope.\npub struct GovernanceConfigGetTool {\n    storage: Arc<GovernanceStorage>,\n}\n\nimpl GovernanceConfigGetTool {\n    pub fn new(storage: Arc<GovernanceStorage>) -> Self {\n        Self { storage }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct GovernanceConfigGetParams {\n    pub company_id: Option<String>,\n    pub org_id: Option<String>,\n    pub team_id: Option<String>,\n    pub project_id: Option<String>,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[async_trait]\nimpl Tool for GovernanceConfigGetTool {\n    fn name(&self) -> &str {\n        \"governance_config_get\"\n    }\n\n    fn description(&self) -> &str {\n        \"Get effective governance configuration for a scope (with inheritance).\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"company_id\": { \"type\": \"string\" },\n                \"org_id\": { \"type\": \"string\" },\n                \"team_id\": { \"type\": \"string\" },\n                \"project_id\": { \"type\": \"string\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            }\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: GovernanceConfigGetParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let config = self\n            .storage\n            .get_effective_config(\n                p.company_id.as_ref().and_then(|s| s.parse().ok()),\n                p.org_id.as_ref().and_then(|s| s.parse().ok()),\n                p.team_id.as_ref().and_then(|s| s.parse().ok()),\n                p.project_id.as_ref().and_then(|s| s.parse().ok()),\n            )\n            .await?;\n\n        Ok(json!({\n            \"success\": true,\n            \"config\": config\n        }))\n    }\n}\n\n/// Tool to create a new approval request.\npub struct GovernanceRequestCreateTool {\n    storage: Arc<GovernanceStorage>,\n    governance_engine: Arc<GovernanceEngine>,\n}\n\nimpl GovernanceRequestCreateTool {\n    pub fn new(storage: Arc<GovernanceStorage>, governance_engine: Arc<GovernanceEngine>) -> Self {\n        Self {\n            storage,\n            governance_engine,\n        }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct GovernanceRequestCreateParams {\n    /// Type of request: policy, knowledge, memory, role, config\n    pub request_type: String,\n    /// Target type being modified (e.g., \"policy\", \"adr\", \"memory\")\n    pub target_type: String,\n    /// Optional target ID\n    pub target_id: Option<String>,\n    /// Scope IDs\n    pub company_id: Option<String>,\n    pub org_id: Option<String>,\n    pub team_id: Option<String>,\n    pub project_id: Option<String>,\n    /// Human-readable title\n    pub title: String,\n    /// Description of the change\n    pub description: Option<String>,\n    /// The actual payload/change data\n    pub payload: Value,\n    /// Risk level: low, medium, high, critical\n    pub risk_level: Option<String>,\n    /// Requestor info\n    pub requestor_id: String,\n    pub requestor_email: Option<String>,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[async_trait]\nimpl Tool for GovernanceRequestCreateTool {\n    fn name(&self) -> &str {\n        \"governance_request_create\"\n    }\n\n    fn description(&self) -> &str {\n        \"Create a new approval request for a governance action (policy change, knowledge update, etc.).\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"request_type\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"policy\", \"knowledge\", \"memory\", \"role\", \"config\"],\n                    \"description\": \"Type of approval request\"\n                },\n                \"target_type\": { \"type\": \"string\", \"description\": \"What is being changed\" },\n                \"target_id\": { \"type\": \"string\", \"description\": \"ID of target being changed\" },\n                \"company_id\": { \"type\": \"string\" },\n                \"org_id\": { \"type\": \"string\" },\n                \"team_id\": { \"type\": \"string\" },\n                \"project_id\": { \"type\": \"string\" },\n                \"title\": { \"type\": \"string\", \"description\": \"Human-readable title\" },\n                \"description\": { \"type\": \"string\", \"description\": \"Change description\" },\n                \"payload\": { \"type\": \"object\", \"description\": \"The change payload\" },\n                \"risk_level\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"low\", \"medium\", \"high\", \"critical\"],\n                    \"default\": \"medium\"\n                },\n                \"requestor_id\": { \"type\": \"string\", \"description\": \"UUID of requestor\" },\n                \"requestor_email\": { \"type\": \"string\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"request_type\", \"target_type\", \"title\", \"payload\", \"requestor_id\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: GovernanceRequestCreateParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        // Get effective config to determine required approvals\n        let config = self\n            .storage\n            .get_effective_config(\n                p.company_id.as_ref().and_then(|s| s.parse().ok()),\n                p.org_id.as_ref().and_then(|s| s.parse().ok()),\n                p.team_id.as_ref().and_then(|s| s.parse().ok()),\n                p.project_id.as_ref().and_then(|s| s.parse().ok()),\n            )\n            .await\n            .unwrap_or_default();\n\n        let risk_level: RiskLevel = p\n            .risk_level\n            .as_ref()\n            .and_then(|s| s.parse().ok())\n            .unwrap_or_default();\n\n        // Check for auto-approval\n        if config.auto_approve_low_risk && risk_level == RiskLevel::Low {\n            // Create request as already approved\n            let request = CreateApprovalRequest {\n                request_type: p.request_type.parse().map_err(|e: String| e)?,\n                target_type: p.target_type,\n                target_id: p.target_id,\n                company_id: p.company_id.as_ref().and_then(|s| s.parse().ok()),\n                org_id: p.org_id.as_ref().and_then(|s| s.parse().ok()),\n                team_id: p.team_id.as_ref().and_then(|s| s.parse().ok()),\n                project_id: p.project_id.as_ref().and_then(|s| s.parse().ok()),\n                title: p.title,\n                description: p.description,\n                payload: p.payload,\n                risk_level,\n                requestor_type: PrincipalType::User,\n                requestor_id: p.requestor_id.parse()?,\n                requestor_email: p.requestor_email,\n                required_approvals: 0, // Auto-approved\n                timeout_hours: Some(config.timeout_hours),\n            };\n\n            let created = self.storage.create_request(&request).await?;\n\n            return Ok(json!({\n                \"success\": true,\n                \"auto_approved\": true,\n                \"request\": created,\n                \"message\": \"Low-risk request auto-approved per governance config\"\n            }));\n        }\n\n        let request = CreateApprovalRequest {\n            request_type: p.request_type.parse().map_err(|e: String| e)?,\n            target_type: p.target_type,\n            target_id: p.target_id,\n            company_id: p.company_id.as_ref().and_then(|s| s.parse().ok()),\n            org_id: p.org_id.as_ref().and_then(|s| s.parse().ok()),\n            team_id: p.team_id.as_ref().and_then(|s| s.parse().ok()),\n            project_id: p.project_id.as_ref().and_then(|s| s.parse().ok()),\n            title: p.title.clone(),\n            description: p.description,\n            payload: p.payload,\n            risk_level,\n            requestor_type: PrincipalType::User,\n            requestor_id: p.requestor_id.parse()?,\n            requestor_email: p.requestor_email,\n            required_approvals: config.min_approvers,\n            timeout_hours: Some(config.timeout_hours),\n        };\n\n        let created = self.storage.create_request(&request).await?;\n\n        // Publish event\n        let _ = self\n            .governance_engine\n            .publish_event(GovernanceEvent::RequestCreated {\n                request_id: created.id.to_string(),\n                request_type: created.request_type.to_string(),\n                title: p.title,\n                tenant_id: ctx.tenant_id.clone(),\n                timestamp: chrono::Utc::now().timestamp(),\n            })\n            .await;\n\n        Ok(json!({\n            \"success\": true,\n            \"auto_approved\": false,\n            \"request\": created\n        }))\n    }\n}\n\n/// Tool to approve an approval request.\npub struct GovernanceApproveTool {\n    storage: Arc<GovernanceStorage>,\n    governance_engine: Arc<GovernanceEngine>,\n}\n\nimpl GovernanceApproveTool {\n    pub fn new(storage: Arc<GovernanceStorage>, governance_engine: Arc<GovernanceEngine>) -> Self {\n        Self {\n            storage,\n            governance_engine,\n        }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct GovernanceApproveParams {\n    /// Request ID or request number (e.g., \"REQ-000001\")\n    pub request_id: String,\n    /// Approver info\n    pub approver_id: String,\n    pub approver_email: Option<String>,\n    /// Optional comment\n    pub comment: Option<String>,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[async_trait]\nimpl Tool for GovernanceApproveTool {\n    fn name(&self) -> &str {\n        \"governance_approve\"\n    }\n\n    fn description(&self) -> &str {\n        \"Approve a pending governance request.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"request_id\": { \"type\": \"string\", \"description\": \"Request ID or number\" },\n                \"approver_id\": { \"type\": \"string\", \"description\": \"Approver UUID\" },\n                \"approver_email\": { \"type\": \"string\" },\n                \"comment\": { \"type\": \"string\", \"description\": \"Approval comment\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"request_id\", \"approver_id\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: GovernanceApproveParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        // Find request by ID or number\n        let request = if p.request_id.starts_with(\"REQ-\") {\n            self.storage\n                .get_request_by_number(&p.request_id)\n                .await?\n                .ok_or(\"Request not found\")?\n        } else {\n            self.storage\n                .get_request(p.request_id.parse()?)\n                .await?\n                .ok_or(\"Request not found\")?\n        };\n\n        // Validate request is pending\n        if request.status != RequestStatus::Pending {\n            return Err(\n                format!(\"Request is not pending, current status: {}\", request.status).into(),\n            );\n        }\n\n        // Add approval decision\n        let decision = CreateDecision {\n            request_id: request.id,\n            approver_type: PrincipalType::User,\n            approver_id: p.approver_id.parse()?,\n            approver_email: p.approver_email,\n            decision: Decision::Approve,\n            comment: p.comment,\n        };\n\n        let approval = self.storage.add_decision(&decision).await?;\n\n        // Get updated request to check if fully approved\n        let updated_request = self\n            .storage\n            .get_request(request.id)\n            .await?\n            .ok_or(\"Request not found after approval\")?;\n\n        let fully_approved =\n            updated_request.current_approvals >= updated_request.required_approvals;\n\n        // Publish event\n        let _ = self\n            .governance_engine\n            .publish_event(GovernanceEvent::RequestApproved {\n                request_id: request.id.to_string(),\n                approver_id: p.approver_id,\n                fully_approved,\n                tenant_id: ctx.tenant_id.clone(),\n                timestamp: chrono::Utc::now().timestamp(),\n            })\n            .await;\n\n        // Log audit\n        let _ = self\n            .storage\n            .log_audit(\n                \"approve\",\n                Some(request.id),\n                Some(&request.target_type),\n                request.target_id.as_deref(),\n                PrincipalType::User,\n                Some(decision.approver_id),\n                decision.approver_email.as_deref(),\n                json!({\n                    \"decision\": \"approve\",\n                    \"comment\": decision.comment,\n                    \"current_approvals\": updated_request.current_approvals,\n                    \"required_approvals\": updated_request.required_approvals\n                }),\n            )\n            .await;\n\n        Ok(json!({\n            \"success\": true,\n            \"approval\": approval,\n            \"request\": updated_request,\n            \"fully_approved\": fully_approved,\n            \"remaining_approvals\": std::cmp::max(0, updated_request.required_approvals - updated_request.current_approvals)\n        }))\n    }\n}\n\n/// Tool to reject an approval request.\npub struct GovernanceRejectTool {\n    storage: Arc<GovernanceStorage>,\n    governance_engine: Arc<GovernanceEngine>,\n}\n\nimpl GovernanceRejectTool {\n    pub fn new(storage: Arc<GovernanceStorage>, governance_engine: Arc<GovernanceEngine>) -> Self {\n        Self {\n            storage,\n            governance_engine,\n        }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct GovernanceRejectParams {\n    pub request_id: String,\n    pub rejector_id: String,\n    pub rejector_email: Option<String>,\n    /// Reason for rejection (required)\n    #[validate(length(min = 1))]\n    pub reason: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[async_trait]\nimpl Tool for GovernanceRejectTool {\n    fn name(&self) -> &str {\n        \"governance_reject\"\n    }\n\n    fn description(&self) -> &str {\n        \"Reject a pending governance request.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"request_id\": { \"type\": \"string\", \"description\": \"Request ID or number\" },\n                \"rejector_id\": { \"type\": \"string\", \"description\": \"Rejector UUID\" },\n                \"rejector_email\": { \"type\": \"string\" },\n                \"reason\": { \"type\": \"string\", \"minLength\": 1, \"description\": \"Rejection reason\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"request_id\", \"rejector_id\", \"reason\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: GovernanceRejectParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        // Find request\n        let request = if p.request_id.starts_with(\"REQ-\") {\n            self.storage\n                .get_request_by_number(&p.request_id)\n                .await?\n                .ok_or(\"Request not found\")?\n        } else {\n            self.storage\n                .get_request(p.request_id.parse()?)\n                .await?\n                .ok_or(\"Request not found\")?\n        };\n\n        if request.status != RequestStatus::Pending {\n            return Err(\n                format!(\"Request is not pending, current status: {}\", request.status).into(),\n            );\n        }\n\n        // Add rejection decision\n        let decision = CreateDecision {\n            request_id: request.id,\n            approver_type: PrincipalType::User,\n            approver_id: p.rejector_id.parse()?,\n            approver_email: p.rejector_email.clone(),\n            decision: Decision::Reject,\n            comment: Some(p.reason.clone()),\n        };\n\n        let rejection = self.storage.add_decision(&decision).await?;\n\n        // Mark request as rejected\n        let rejected_request = self.storage.reject_request(request.id, &p.reason).await?;\n\n        // Publish event\n        let _ = self\n            .governance_engine\n            .publish_event(GovernanceEvent::RequestRejected {\n                request_id: request.id.to_string(),\n                rejector_id: p.rejector_id.clone(),\n                reason: p.reason.clone(),\n                tenant_id: ctx.tenant_id.clone(),\n                timestamp: chrono::Utc::now().timestamp(),\n            })\n            .await;\n\n        // Log audit\n        let _ = self\n            .storage\n            .log_audit(\n                \"reject\",\n                Some(request.id),\n                Some(&request.target_type),\n                request.target_id.as_deref(),\n                PrincipalType::User,\n                Some(decision.approver_id),\n                p.rejector_email.as_deref(),\n                json!({\n                    \"decision\": \"reject\",\n                    \"reason\": p.reason\n                }),\n            )\n            .await;\n\n        Ok(json!({\n            \"success\": true,\n            \"rejection\": rejection,\n            \"request\": rejected_request\n        }))\n    }\n}\n\n/// Tool to list pending approval requests.\npub struct GovernanceRequestListTool {\n    storage: Arc<GovernanceStorage>,\n}\n\nimpl GovernanceRequestListTool {\n    pub fn new(storage: Arc<GovernanceStorage>) -> Self {\n        Self { storage }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct GovernanceRequestListParams {\n    pub request_type: Option<String>,\n    pub company_id: Option<String>,\n    pub org_id: Option<String>,\n    pub team_id: Option<String>,\n    pub project_id: Option<String>,\n    pub requestor_id: Option<String>,\n    pub limit: Option<i32>,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[async_trait]\nimpl Tool for GovernanceRequestListTool {\n    fn name(&self) -> &str {\n        \"governance_request_list\"\n    }\n\n    fn description(&self) -> &str {\n        \"List pending approval requests with optional filters.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"request_type\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"policy\", \"knowledge\", \"memory\", \"role\", \"config\"]\n                },\n                \"company_id\": { \"type\": \"string\" },\n                \"org_id\": { \"type\": \"string\" },\n                \"team_id\": { \"type\": \"string\" },\n                \"project_id\": { \"type\": \"string\" },\n                \"requestor_id\": { \"type\": \"string\" },\n                \"limit\": { \"type\": \"integer\", \"minimum\": 1, \"maximum\": 100, \"default\": 50 },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            }\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: GovernanceRequestListParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let filters = RequestFilters {\n            request_type: p.request_type.as_ref().and_then(|s| s.parse().ok()),\n            company_id: p.company_id.as_ref().and_then(|s| s.parse().ok()),\n            org_id: p.org_id.as_ref().and_then(|s| s.parse().ok()),\n            team_id: p.team_id.as_ref().and_then(|s| s.parse().ok()),\n            project_id: p.project_id.as_ref().and_then(|s| s.parse().ok()),\n            requestor_id: p.requestor_id.as_ref().and_then(|s| s.parse().ok()),\n            limit: p.limit,\n        };\n\n        let requests = self.storage.list_pending_requests(&filters).await?;\n\n        Ok(json!({\n            \"success\": true,\n            \"count\": requests.len(),\n            \"requests\": requests\n        }))\n    }\n}\n\n/// Tool to get details of a specific request including decisions.\npub struct GovernanceRequestGetTool {\n    storage: Arc<GovernanceStorage>,\n}\n\nimpl GovernanceRequestGetTool {\n    pub fn new(storage: Arc<GovernanceStorage>) -> Self {\n        Self { storage }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct GovernanceRequestGetParams {\n    pub request_id: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[async_trait]\nimpl Tool for GovernanceRequestGetTool {\n    fn name(&self) -> &str {\n        \"governance_request_get\"\n    }\n\n    fn description(&self) -> &str {\n        \"Get detailed information about a specific approval request including all decisions.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"request_id\": { \"type\": \"string\", \"description\": \"Request ID or number\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"request_id\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: GovernanceRequestGetParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        // Find request\n        let request = if p.request_id.starts_with(\"REQ-\") {\n            self.storage\n                .get_request_by_number(&p.request_id)\n                .await?\n                .ok_or(\"Request not found\")?\n        } else {\n            self.storage\n                .get_request(p.request_id.parse()?)\n                .await?\n                .ok_or(\"Request not found\")?\n        };\n\n        // Get all decisions\n        let decisions = self.storage.get_decisions(request.id).await?;\n\n        Ok(json!({\n            \"success\": true,\n            \"request\": request,\n            \"decisions\": decisions,\n            \"approval_progress\": {\n                \"current\": request.current_approvals,\n                \"required\": request.required_approvals,\n                \"remaining\": std::cmp::max(0, request.required_approvals - request.current_approvals)\n            }\n        }))\n    }\n}\n\n/// Tool to list audit log entries.\npub struct GovernanceAuditListTool {\n    storage: Arc<GovernanceStorage>,\n}\n\nimpl GovernanceAuditListTool {\n    pub fn new(storage: Arc<GovernanceStorage>) -> Self {\n        Self { storage }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct GovernanceAuditListParams {\n    /// Filter by action type\n    pub action: Option<String>,\n    /// Filter by actor\n    pub actor_id: Option<String>,\n    /// Filter by target type\n    pub target_type: Option<String>,\n    /// How many days back to search (default 30)\n    pub days_back: Option<i64>,\n    /// Max results\n    pub limit: Option<i32>,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[async_trait]\nimpl Tool for GovernanceAuditListTool {\n    fn name(&self) -> &str {\n        \"governance_audit_list\"\n    }\n\n    fn description(&self) -> &str {\n        \"List governance audit log entries with filters.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"action\": { \"type\": \"string\", \"description\": \"Filter by action (approve, reject, etc.)\" },\n                \"actor_id\": { \"type\": \"string\", \"description\": \"Filter by actor UUID\" },\n                \"target_type\": { \"type\": \"string\", \"description\": \"Filter by target type\" },\n                \"days_back\": { \"type\": \"integer\", \"minimum\": 1, \"maximum\": 365, \"default\": 30 },\n                \"limit\": { \"type\": \"integer\", \"minimum\": 1, \"maximum\": 500, \"default\": 50 },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            }\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: GovernanceAuditListParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let days = p.days_back.unwrap_or(30);\n        let since = chrono::Utc::now() - chrono::Duration::days(days);\n\n        let filters = AuditFilters {\n            action: p.action,\n            actor_id: p.actor_id.as_ref().and_then(|s| s.parse().ok()),\n            target_type: p.target_type,\n            since,\n            limit: p.limit,\n        };\n\n        let entries = self.storage.list_audit_logs(&filters).await?;\n\n        Ok(json!({\n            \"success\": true,\n            \"count\": entries.len(),\n            \"entries\": entries\n        }))\n    }\n}\n\n/// Tool to assign a governance role.\npub struct GovernanceRoleAssignTool {\n    storage: Arc<GovernanceStorage>,\n    governance_engine: Arc<GovernanceEngine>,\n}\n\nimpl GovernanceRoleAssignTool {\n    pub fn new(storage: Arc<GovernanceStorage>, governance_engine: Arc<GovernanceEngine>) -> Self {\n        Self {\n            storage,\n            governance_engine,\n        }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct GovernanceRoleAssignParams {\n    /// Principal type: user, agent, system\n    pub principal_type: String,\n    /// Principal UUID\n    pub principal_id: String,\n    /// Role name (e.g., \"approver\", \"admin\", \"auditor\")\n    pub role: String,\n    /// Scope\n    pub company_id: Option<String>,\n    pub org_id: Option<String>,\n    pub team_id: Option<String>,\n    pub project_id: Option<String>,\n    /// Who is granting this role\n    pub granted_by: String,\n    /// Optional expiration\n    pub expires_in_days: Option<i64>,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[async_trait]\nimpl Tool for GovernanceRoleAssignTool {\n    fn name(&self) -> &str {\n        \"governance_role_assign\"\n    }\n\n    fn description(&self) -> &str {\n        \"Assign a governance role (approver, admin, auditor) to a user or agent.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"principal_type\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"user\", \"agent\", \"system\"]\n                },\n                \"principal_id\": { \"type\": \"string\", \"description\": \"UUID of principal\" },\n                \"role\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"approver\", \"admin\", \"auditor\", \"policy_admin\", \"knowledge_admin\"],\n                    \"description\": \"Governance role\"\n                },\n                \"company_id\": { \"type\": \"string\" },\n                \"org_id\": { \"type\": \"string\" },\n                \"team_id\": { \"type\": \"string\" },\n                \"project_id\": { \"type\": \"string\" },\n                \"granted_by\": { \"type\": \"string\", \"description\": \"UUID of granter\" },\n                \"expires_in_days\": { \"type\": \"integer\", \"description\": \"Optional expiration in days\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"principal_type\", \"principal_id\", \"role\", \"granted_by\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: GovernanceRoleAssignParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let _ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let expires_at = p\n            .expires_in_days\n            .map(|d| chrono::Utc::now() + chrono::Duration::days(d));\n\n        let role = CreateGovernanceRole {\n            principal_type: p.principal_type.parse().map_err(|e: String| e)?,\n            principal_id: p.principal_id.parse()?,\n            role: p.role.clone(),\n            company_id: p.company_id.as_ref().and_then(|s| s.parse().ok()),\n            org_id: p.org_id.as_ref().and_then(|s| s.parse().ok()),\n            team_id: p.team_id.as_ref().and_then(|s| s.parse().ok()),\n            project_id: p.project_id.as_ref().and_then(|s| s.parse().ok()),\n            granted_by: p.granted_by.parse()?,\n            expires_at,\n        };\n\n        let role_id = self.storage.assign_role(&role).await?;\n\n        // Log audit\n        let _ = self\n            .storage\n            .log_audit(\n                \"role_assigned\",\n                None,\n                Some(\"role\"),\n                Some(&role_id.to_string()),\n                PrincipalType::User,\n                Some(role.granted_by),\n                None,\n                json!({\n                    \"role\": p.role,\n                    \"principal_type\": p.principal_type,\n                    \"principal_id\": p.principal_id\n                }),\n            )\n            .await;\n\n        Ok(json!({\n            \"success\": true,\n            \"role_id\": role_id.to_string()\n        }))\n    }\n}\n\n/// Tool to revoke a governance role.\npub struct GovernanceRoleRevokeTool {\n    storage: Arc<GovernanceStorage>,\n}\n\nimpl GovernanceRoleRevokeTool {\n    pub fn new(storage: Arc<GovernanceStorage>) -> Self {\n        Self { storage }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct GovernanceRoleRevokeParams {\n    pub principal_id: String,\n    pub role: String,\n    pub revoked_by: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[async_trait]\nimpl Tool for GovernanceRoleRevokeTool {\n    fn name(&self) -> &str {\n        \"governance_role_revoke\"\n    }\n\n    fn description(&self) -> &str {\n        \"Revoke a governance role from a user or agent.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"principal_id\": { \"type\": \"string\", \"description\": \"UUID of principal\" },\n                \"role\": { \"type\": \"string\", \"description\": \"Role to revoke\" },\n                \"revoked_by\": { \"type\": \"string\", \"description\": \"UUID of revoker\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"principal_id\", \"role\", \"revoked_by\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: GovernanceRoleRevokeParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let _ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        self.storage\n            .revoke_role(p.principal_id.parse()?, &p.role, p.revoked_by.parse()?)\n            .await?;\n\n        // Log audit\n        let _ = self\n            .storage\n            .log_audit(\n                \"role_revoked\",\n                None,\n                Some(\"role\"),\n                None,\n                PrincipalType::User,\n                Some(p.revoked_by.parse()?),\n                None,\n                json!({\n                    \"role\": p.role,\n                    \"principal_id\": p.principal_id\n                }),\n            )\n            .await;\n\n        Ok(json!({\n            \"success\": true\n        }))\n    }\n}\n\n/// Tool to list governance roles.\npub struct GovernanceRoleListTool {\n    storage: Arc<GovernanceStorage>,\n}\n\nimpl GovernanceRoleListTool {\n    pub fn new(storage: Arc<GovernanceStorage>) -> Self {\n        Self { storage }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct GovernanceRoleListParams {\n    pub company_id: Option<String>,\n    pub org_id: Option<String>,\n    pub team_id: Option<String>,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[async_trait]\nimpl Tool for GovernanceRoleListTool {\n    fn name(&self) -> &str {\n        \"governance_role_list\"\n    }\n\n    fn description(&self) -> &str {\n        \"List governance roles for a scope.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"company_id\": { \"type\": \"string\" },\n                \"org_id\": { \"type\": \"string\" },\n                \"team_id\": { \"type\": \"string\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            }\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: GovernanceRoleListParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let roles = self\n            .storage\n            .list_roles(\n                p.company_id.as_ref().and_then(|s| s.parse().ok()),\n                p.org_id.as_ref().and_then(|s| s.parse().ok()),\n                p.team_id.as_ref().and_then(|s| s.parse().ok()),\n            )\n            .await?;\n\n        Ok(json!({\n            \"success\": true,\n            \"count\": roles.len(),\n            \"roles\": roles\n        }))\n    }\n}\n","traces":[{"line":19,"address":[],"length":0,"stats":{"Line":22}},{"line":43,"address":[],"length":0,"stats":{"Line":29}},{"line":44,"address":[],"length":0,"stats":{"Line":29}},{"line":47,"address":[],"length":0,"stats":{"Line":7}},{"line":48,"address":[],"length":0,"stats":{"Line":7}},{"line":51,"address":[],"length":0,"stats":{"Line":7}},{"line":52,"address":[],"length":0,"stats":{"Line":7}},{"line":53,"address":[],"length":0,"stats":{"Line":7}},{"line":54,"address":[],"length":0,"stats":{"Line":7}},{"line":55,"address":[],"length":0,"stats":{"Line":21}},{"line":56,"address":[],"length":0,"stats":{"Line":7}},{"line":57,"address":[],"length":0,"stats":{"Line":7}},{"line":58,"address":[],"length":0,"stats":{"Line":7}},{"line":59,"address":[],"length":0,"stats":{"Line":7}},{"line":61,"address":[],"length":0,"stats":{"Line":21}},{"line":62,"address":[],"length":0,"stats":{"Line":21}},{"line":63,"address":[],"length":0,"stats":{"Line":14}},{"line":65,"address":[],"length":0,"stats":{"Line":7}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":22}},{"line":142,"address":[],"length":0,"stats":{"Line":29}},{"line":143,"address":[],"length":0,"stats":{"Line":29}},{"line":146,"address":[],"length":0,"stats":{"Line":7}},{"line":147,"address":[],"length":0,"stats":{"Line":7}},{"line":150,"address":[],"length":0,"stats":{"Line":7}},{"line":151,"address":[],"length":0,"stats":{"Line":7}},{"line":152,"address":[],"length":0,"stats":{"Line":7}},{"line":153,"address":[],"length":0,"stats":{"Line":7}},{"line":154,"address":[],"length":0,"stats":{"Line":21}},{"line":155,"address":[],"length":0,"stats":{"Line":21}},{"line":156,"address":[],"length":0,"stats":{"Line":14}},{"line":158,"address":[],"length":0,"stats":{"Line":7}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":22}},{"line":218,"address":[],"length":0,"stats":{"Line":29}},{"line":219,"address":[],"length":0,"stats":{"Line":29}},{"line":222,"address":[],"length":0,"stats":{"Line":7}},{"line":223,"address":[],"length":0,"stats":{"Line":7}},{"line":226,"address":[],"length":0,"stats":{"Line":7}},{"line":227,"address":[],"length":0,"stats":{"Line":7}},{"line":228,"address":[],"length":0,"stats":{"Line":7}},{"line":229,"address":[],"length":0,"stats":{"Line":7}},{"line":230,"address":[],"length":0,"stats":{"Line":21}},{"line":231,"address":[],"length":0,"stats":{"Line":21}},{"line":232,"address":[],"length":0,"stats":{"Line":7}},{"line":233,"address":[],"length":0,"stats":{"Line":7}},{"line":234,"address":[],"length":0,"stats":{"Line":7}},{"line":235,"address":[],"length":0,"stats":{"Line":7}},{"line":237,"address":[],"length":0,"stats":{"Line":14}},{"line":239,"address":[],"length":0,"stats":{"Line":7}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":22}},{"line":301,"address":[],"length":0,"stats":{"Line":29}},{"line":302,"address":[],"length":0,"stats":{"Line":29}},{"line":305,"address":[],"length":0,"stats":{"Line":7}},{"line":306,"address":[],"length":0,"stats":{"Line":7}},{"line":309,"address":[],"length":0,"stats":{"Line":7}},{"line":310,"address":[],"length":0,"stats":{"Line":7}},{"line":311,"address":[],"length":0,"stats":{"Line":7}},{"line":312,"address":[],"length":0,"stats":{"Line":7}},{"line":313,"address":[],"length":0,"stats":{"Line":21}},{"line":314,"address":[],"length":0,"stats":{"Line":21}},{"line":315,"address":[],"length":0,"stats":{"Line":7}},{"line":316,"address":[],"length":0,"stats":{"Line":7}},{"line":317,"address":[],"length":0,"stats":{"Line":7}},{"line":318,"address":[],"length":0,"stats":{"Line":7}},{"line":320,"address":[],"length":0,"stats":{"Line":14}},{"line":322,"address":[],"length":0,"stats":{"Line":7}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":360,"address":[],"length":0,"stats":{"Line":22}},{"line":377,"address":[],"length":0,"stats":{"Line":29}},{"line":378,"address":[],"length":0,"stats":{"Line":29}},{"line":381,"address":[],"length":0,"stats":{"Line":7}},{"line":382,"address":[],"length":0,"stats":{"Line":7}},{"line":385,"address":[],"length":0,"stats":{"Line":7}},{"line":386,"address":[],"length":0,"stats":{"Line":7}},{"line":387,"address":[],"length":0,"stats":{"Line":7}},{"line":388,"address":[],"length":0,"stats":{"Line":7}},{"line":389,"address":[],"length":0,"stats":{"Line":21}},{"line":390,"address":[],"length":0,"stats":{"Line":7}},{"line":391,"address":[],"length":0,"stats":{"Line":7}},{"line":392,"address":[],"length":0,"stats":{"Line":7}},{"line":393,"address":[],"length":0,"stats":{"Line":7}},{"line":395,"address":[],"length":0,"stats":{"Line":14}},{"line":397,"address":[],"length":0,"stats":{"Line":7}},{"line":401,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":0}},{"line":481,"address":[],"length":0,"stats":{"Line":0}},{"line":482,"address":[],"length":0,"stats":{"Line":0}},{"line":485,"address":[],"length":0,"stats":{"Line":0}},{"line":486,"address":[],"length":0,"stats":{"Line":0}},{"line":489,"address":[],"length":0,"stats":{"Line":0}},{"line":490,"address":[],"length":0,"stats":{"Line":0}},{"line":491,"address":[],"length":0,"stats":{"Line":0}},{"line":492,"address":[],"length":0,"stats":{"Line":0}},{"line":493,"address":[],"length":0,"stats":{"Line":0}},{"line":494,"address":[],"length":0,"stats":{"Line":0}},{"line":495,"address":[],"length":0,"stats":{"Line":0}},{"line":496,"address":[],"length":0,"stats":{"Line":0}},{"line":497,"address":[],"length":0,"stats":{"Line":0}},{"line":498,"address":[],"length":0,"stats":{"Line":0}},{"line":499,"address":[],"length":0,"stats":{"Line":0}},{"line":500,"address":[],"length":0,"stats":{"Line":0}},{"line":502,"address":[],"length":0,"stats":{"Line":0}},{"line":503,"address":[],"length":0,"stats":{"Line":0}},{"line":504,"address":[],"length":0,"stats":{"Line":0}},{"line":505,"address":[],"length":0,"stats":{"Line":0}},{"line":506,"address":[],"length":0,"stats":{"Line":0}},{"line":507,"address":[],"length":0,"stats":{"Line":0}},{"line":508,"address":[],"length":0,"stats":{"Line":0}},{"line":509,"address":[],"length":0,"stats":{"Line":0}},{"line":510,"address":[],"length":0,"stats":{"Line":0}},{"line":511,"address":[],"length":0,"stats":{"Line":0}},{"line":513,"address":[],"length":0,"stats":{"Line":0}},{"line":514,"address":[],"length":0,"stats":{"Line":0}},{"line":515,"address":[],"length":0,"stats":{"Line":0}},{"line":516,"address":[],"length":0,"stats":{"Line":0}},{"line":517,"address":[],"length":0,"stats":{"Line":0}},{"line":522,"address":[],"length":0,"stats":{"Line":0}},{"line":532,"address":[],"length":0,"stats":{"Line":0}},{"line":533,"address":[],"length":0,"stats":{"Line":0}},{"line":534,"address":[],"length":0,"stats":{"Line":0}},{"line":535,"address":[],"length":0,"stats":{"Line":0}},{"line":543,"address":[],"length":0,"stats":{"Line":0}},{"line":544,"address":[],"length":0,"stats":{"Line":0}},{"line":545,"address":[],"length":0,"stats":{"Line":0}},{"line":546,"address":[],"length":0,"stats":{"Line":0}},{"line":597,"address":[],"length":0,"stats":{"Line":0}},{"line":614,"address":[],"length":0,"stats":{"Line":0}},{"line":615,"address":[],"length":0,"stats":{"Line":0}},{"line":618,"address":[],"length":0,"stats":{"Line":0}},{"line":619,"address":[],"length":0,"stats":{"Line":0}},{"line":622,"address":[],"length":0,"stats":{"Line":0}},{"line":623,"address":[],"length":0,"stats":{"Line":0}},{"line":624,"address":[],"length":0,"stats":{"Line":0}},{"line":625,"address":[],"length":0,"stats":{"Line":0}},{"line":626,"address":[],"length":0,"stats":{"Line":0}},{"line":627,"address":[],"length":0,"stats":{"Line":0}},{"line":628,"address":[],"length":0,"stats":{"Line":0}},{"line":629,"address":[],"length":0,"stats":{"Line":0}},{"line":630,"address":[],"length":0,"stats":{"Line":0}},{"line":635,"address":[],"length":0,"stats":{"Line":0}},{"line":642,"address":[],"length":0,"stats":{"Line":0}},{"line":643,"address":[],"length":0,"stats":{"Line":0}},{"line":644,"address":[],"length":0,"stats":{"Line":0}},{"line":645,"address":[],"length":0,"stats":{"Line":0}},{"line":663,"address":[],"length":0,"stats":{"Line":0}},{"line":701,"address":[],"length":0,"stats":{"Line":0}},{"line":702,"address":[],"length":0,"stats":{"Line":0}},{"line":705,"address":[],"length":0,"stats":{"Line":0}},{"line":706,"address":[],"length":0,"stats":{"Line":0}},{"line":709,"address":[],"length":0,"stats":{"Line":0}},{"line":710,"address":[],"length":0,"stats":{"Line":0}},{"line":711,"address":[],"length":0,"stats":{"Line":0}},{"line":712,"address":[],"length":0,"stats":{"Line":0}},{"line":713,"address":[],"length":0,"stats":{"Line":0}},{"line":714,"address":[],"length":0,"stats":{"Line":0}},{"line":715,"address":[],"length":0,"stats":{"Line":0}},{"line":716,"address":[],"length":0,"stats":{"Line":0}},{"line":718,"address":[],"length":0,"stats":{"Line":0}},{"line":719,"address":[],"length":0,"stats":{"Line":0}},{"line":720,"address":[],"length":0,"stats":{"Line":0}},{"line":721,"address":[],"length":0,"stats":{"Line":0}},{"line":722,"address":[],"length":0,"stats":{"Line":0}},{"line":723,"address":[],"length":0,"stats":{"Line":0}},{"line":724,"address":[],"length":0,"stats":{"Line":0}},{"line":725,"address":[],"length":0,"stats":{"Line":0}},{"line":726,"address":[],"length":0,"stats":{"Line":0}},{"line":727,"address":[],"length":0,"stats":{"Line":0}},{"line":728,"address":[],"length":0,"stats":{"Line":0}},{"line":729,"address":[],"length":0,"stats":{"Line":0}},{"line":730,"address":[],"length":0,"stats":{"Line":0}},{"line":732,"address":[],"length":0,"stats":{"Line":0}},{"line":733,"address":[],"length":0,"stats":{"Line":0}},{"line":734,"address":[],"length":0,"stats":{"Line":0}},{"line":736,"address":[],"length":0,"stats":{"Line":0}},{"line":740,"address":[],"length":0,"stats":{"Line":0}},{"line":750,"address":[],"length":0,"stats":{"Line":0}},{"line":751,"address":[],"length":0,"stats":{"Line":0}},{"line":752,"address":[],"length":0,"stats":{"Line":0}},{"line":753,"address":[],"length":0,"stats":{"Line":0}},{"line":761,"address":[],"length":0,"stats":{"Line":0}},{"line":771,"address":[],"length":0,"stats":{"Line":0}},{"line":772,"address":[],"length":0,"stats":{"Line":0}},{"line":773,"address":[],"length":0,"stats":{"Line":0}},{"line":774,"address":[],"length":0,"stats":{"Line":0}},{"line":800,"address":[],"length":0,"stats":{"Line":0}},{"line":801,"address":[],"length":0,"stats":{"Line":0}},{"line":802,"address":[],"length":0,"stats":{"Line":0}},{"line":803,"address":[],"length":0,"stats":{"Line":0}},{"line":844,"address":[],"length":0,"stats":{"Line":0}},{"line":867,"address":[],"length":0,"stats":{"Line":0}},{"line":868,"address":[],"length":0,"stats":{"Line":0}},{"line":871,"address":[],"length":0,"stats":{"Line":0}},{"line":872,"address":[],"length":0,"stats":{"Line":0}},{"line":875,"address":[],"length":0,"stats":{"Line":0}},{"line":876,"address":[],"length":0,"stats":{"Line":0}},{"line":877,"address":[],"length":0,"stats":{"Line":0}},{"line":878,"address":[],"length":0,"stats":{"Line":0}},{"line":879,"address":[],"length":0,"stats":{"Line":0}},{"line":880,"address":[],"length":0,"stats":{"Line":0}},{"line":881,"address":[],"length":0,"stats":{"Line":0}},{"line":882,"address":[],"length":0,"stats":{"Line":0}},{"line":883,"address":[],"length":0,"stats":{"Line":0}},{"line":885,"address":[],"length":0,"stats":{"Line":0}},{"line":889,"address":[],"length":0,"stats":{"Line":0}},{"line":986,"address":[],"length":0,"stats":{"Line":0}},{"line":1008,"address":[],"length":0,"stats":{"Line":0}},{"line":1009,"address":[],"length":0,"stats":{"Line":0}},{"line":1012,"address":[],"length":0,"stats":{"Line":0}},{"line":1013,"address":[],"length":0,"stats":{"Line":0}},{"line":1016,"address":[],"length":0,"stats":{"Line":0}},{"line":1017,"address":[],"length":0,"stats":{"Line":0}},{"line":1018,"address":[],"length":0,"stats":{"Line":0}},{"line":1019,"address":[],"length":0,"stats":{"Line":0}},{"line":1020,"address":[],"length":0,"stats":{"Line":0}},{"line":1021,"address":[],"length":0,"stats":{"Line":0}},{"line":1022,"address":[],"length":0,"stats":{"Line":0}},{"line":1023,"address":[],"length":0,"stats":{"Line":0}},{"line":1024,"address":[],"length":0,"stats":{"Line":0}},{"line":1026,"address":[],"length":0,"stats":{"Line":0}},{"line":1030,"address":[],"length":0,"stats":{"Line":0}},{"line":1114,"address":[],"length":0,"stats":{"Line":0}},{"line":1134,"address":[],"length":0,"stats":{"Line":0}},{"line":1135,"address":[],"length":0,"stats":{"Line":0}},{"line":1138,"address":[],"length":0,"stats":{"Line":0}},{"line":1139,"address":[],"length":0,"stats":{"Line":0}},{"line":1142,"address":[],"length":0,"stats":{"Line":0}},{"line":1143,"address":[],"length":0,"stats":{"Line":0}},{"line":1144,"address":[],"length":0,"stats":{"Line":0}},{"line":1145,"address":[],"length":0,"stats":{"Line":0}},{"line":1146,"address":[],"length":0,"stats":{"Line":0}},{"line":1147,"address":[],"length":0,"stats":{"Line":0}},{"line":1148,"address":[],"length":0,"stats":{"Line":0}},{"line":1150,"address":[],"length":0,"stats":{"Line":0}},{"line":1151,"address":[],"length":0,"stats":{"Line":0}},{"line":1152,"address":[],"length":0,"stats":{"Line":0}},{"line":1153,"address":[],"length":0,"stats":{"Line":0}},{"line":1154,"address":[],"length":0,"stats":{"Line":0}},{"line":1155,"address":[],"length":0,"stats":{"Line":0}},{"line":1156,"address":[],"length":0,"stats":{"Line":0}},{"line":1161,"address":[],"length":0,"stats":{"Line":0}},{"line":1166,"address":[],"length":0,"stats":{"Line":0}},{"line":1167,"address":[],"length":0,"stats":{"Line":0}},{"line":1168,"address":[],"length":0,"stats":{"Line":0}},{"line":1169,"address":[],"length":0,"stats":{"Line":0}},{"line":1170,"address":[],"length":0,"stats":{"Line":0}},{"line":1171,"address":[],"length":0,"stats":{"Line":0}},{"line":1191,"address":[],"length":0,"stats":{"Line":0}},{"line":1205,"address":[],"length":0,"stats":{"Line":0}},{"line":1206,"address":[],"length":0,"stats":{"Line":0}},{"line":1209,"address":[],"length":0,"stats":{"Line":0}},{"line":1210,"address":[],"length":0,"stats":{"Line":0}},{"line":1213,"address":[],"length":0,"stats":{"Line":0}},{"line":1214,"address":[],"length":0,"stats":{"Line":0}},{"line":1215,"address":[],"length":0,"stats":{"Line":0}},{"line":1216,"address":[],"length":0,"stats":{"Line":0}},{"line":1217,"address":[],"length":0,"stats":{"Line":0}},{"line":1218,"address":[],"length":0,"stats":{"Line":0}},{"line":1220,"address":[],"length":0,"stats":{"Line":0}},{"line":1224,"address":[],"length":0,"stats":{"Line":0}},{"line":1263,"address":[],"length":0,"stats":{"Line":0}},{"line":1286,"address":[],"length":0,"stats":{"Line":0}},{"line":1287,"address":[],"length":0,"stats":{"Line":0}},{"line":1290,"address":[],"length":0,"stats":{"Line":0}},{"line":1291,"address":[],"length":0,"stats":{"Line":0}},{"line":1294,"address":[],"length":0,"stats":{"Line":0}},{"line":1295,"address":[],"length":0,"stats":{"Line":0}},{"line":1296,"address":[],"length":0,"stats":{"Line":0}},{"line":1297,"address":[],"length":0,"stats":{"Line":0}},{"line":1298,"address":[],"length":0,"stats":{"Line":0}},{"line":1299,"address":[],"length":0,"stats":{"Line":0}},{"line":1300,"address":[],"length":0,"stats":{"Line":0}},{"line":1301,"address":[],"length":0,"stats":{"Line":0}},{"line":1302,"address":[],"length":0,"stats":{"Line":0}},{"line":1303,"address":[],"length":0,"stats":{"Line":0}},{"line":1308,"address":[],"length":0,"stats":{"Line":0}},{"line":1317,"address":[],"length":0,"stats":{"Line":0}},{"line":1340,"address":[],"length":0,"stats":{"Line":0}},{"line":1371,"address":[],"length":0,"stats":{"Line":0}},{"line":1372,"address":[],"length":0,"stats":{"Line":0}},{"line":1375,"address":[],"length":0,"stats":{"Line":0}},{"line":1376,"address":[],"length":0,"stats":{"Line":0}},{"line":1379,"address":[],"length":0,"stats":{"Line":0}},{"line":1380,"address":[],"length":0,"stats":{"Line":0}},{"line":1381,"address":[],"length":0,"stats":{"Line":0}},{"line":1382,"address":[],"length":0,"stats":{"Line":0}},{"line":1383,"address":[],"length":0,"stats":{"Line":0}},{"line":1384,"address":[],"length":0,"stats":{"Line":0}},{"line":1385,"address":[],"length":0,"stats":{"Line":0}},{"line":1387,"address":[],"length":0,"stats":{"Line":0}},{"line":1388,"address":[],"length":0,"stats":{"Line":0}},{"line":1389,"address":[],"length":0,"stats":{"Line":0}},{"line":1390,"address":[],"length":0,"stats":{"Line":0}},{"line":1391,"address":[],"length":0,"stats":{"Line":0}},{"line":1393,"address":[],"length":0,"stats":{"Line":0}},{"line":1394,"address":[],"length":0,"stats":{"Line":0}},{"line":1395,"address":[],"length":0,"stats":{"Line":0}},{"line":1396,"address":[],"length":0,"stats":{"Line":0}},{"line":1397,"address":[],"length":0,"stats":{"Line":0}},{"line":1398,"address":[],"length":0,"stats":{"Line":0}},{"line":1399,"address":[],"length":0,"stats":{"Line":0}},{"line":1401,"address":[],"length":0,"stats":{"Line":0}},{"line":1405,"address":[],"length":0,"stats":{"Line":0}},{"line":1413,"address":[],"length":0,"stats":{"Line":0}},{"line":1419,"address":[],"length":0,"stats":{"Line":0}},{"line":1420,"address":[],"length":0,"stats":{"Line":0}},{"line":1421,"address":[],"length":0,"stats":{"Line":0}},{"line":1422,"address":[],"length":0,"stats":{"Line":0}},{"line":1461,"address":[],"length":0,"stats":{"Line":0}},{"line":1477,"address":[],"length":0,"stats":{"Line":0}},{"line":1478,"address":[],"length":0,"stats":{"Line":0}},{"line":1481,"address":[],"length":0,"stats":{"Line":0}},{"line":1482,"address":[],"length":0,"stats":{"Line":0}},{"line":1485,"address":[],"length":0,"stats":{"Line":0}},{"line":1486,"address":[],"length":0,"stats":{"Line":0}},{"line":1487,"address":[],"length":0,"stats":{"Line":0}},{"line":1488,"address":[],"length":0,"stats":{"Line":0}},{"line":1489,"address":[],"length":0,"stats":{"Line":0}},{"line":1490,"address":[],"length":0,"stats":{"Line":0}},{"line":1491,"address":[],"length":0,"stats":{"Line":0}},{"line":1492,"address":[],"length":0,"stats":{"Line":0}},{"line":1494,"address":[],"length":0,"stats":{"Line":0}},{"line":1498,"address":[],"length":0,"stats":{"Line":0}},{"line":1538,"address":[],"length":0,"stats":{"Line":0}},{"line":1554,"address":[],"length":0,"stats":{"Line":0}},{"line":1555,"address":[],"length":0,"stats":{"Line":0}},{"line":1558,"address":[],"length":0,"stats":{"Line":0}},{"line":1559,"address":[],"length":0,"stats":{"Line":0}},{"line":1562,"address":[],"length":0,"stats":{"Line":0}},{"line":1563,"address":[],"length":0,"stats":{"Line":0}},{"line":1564,"address":[],"length":0,"stats":{"Line":0}},{"line":1565,"address":[],"length":0,"stats":{"Line":0}},{"line":1566,"address":[],"length":0,"stats":{"Line":0}},{"line":1567,"address":[],"length":0,"stats":{"Line":0}},{"line":1568,"address":[],"length":0,"stats":{"Line":0}},{"line":1569,"address":[],"length":0,"stats":{"Line":0}},{"line":1574,"address":[],"length":0,"stats":{"Line":0}},{"line":1581,"address":[],"length":0,"stats":{"Line":0}},{"line":1582,"address":[],"length":0,"stats":{"Line":0}},{"line":1583,"address":[],"length":0,"stats":{"Line":0}}],"covered":81,"coverable":341},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","hot_reload.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","knowledge.rs"],"content":"use crate::tools::Tool;\nuse async_trait::async_trait;\nuse memory::manager::MemoryManager;\nuse mk_core::traits::KnowledgeRepository;\nuse mk_core::types::{MemoryEntry, TenantContext};\nuse schemars::JsonSchema;\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Value, json};\nuse std::sync::Arc;\nuse validator::Validate;\n\npub struct KnowledgeGetTool {\n    repo: Arc<dyn KnowledgeRepository<Error = knowledge::repository::RepositoryError>>,\n}\n\nimpl KnowledgeGetTool {\n    pub fn new(\n        repo: Arc<dyn KnowledgeRepository<Error = knowledge::repository::RepositoryError>>,\n    ) -> Self {\n        Self { repo }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct KnowledgeGetParams {\n    pub path: String,\n    pub layer: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct KnowledgeListParams {\n    pub layer: String,\n    #[serde(default)]\n    pub prefix: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct KnowledgeQueryParams {\n    pub query: String,\n    #[serde(default)]\n    pub layers: Vec<String>,\n    pub limit: Option<usize>,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[async_trait]\nimpl Tool for KnowledgeGetTool {\n    fn name(&self) -> &str {\n        \"knowledge_get\"\n    }\n\n    fn description(&self) -> &str {\n        \"Retrieve a specific knowledge entry by path and layer.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"path\": { \"type\": \"string\" },\n                \"layer\": { \"type\": \"string\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"path\", \"layer\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: KnowledgeGetParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let layer = match p.layer.to_lowercase().as_str() {\n            \"company\" => mk_core::types::KnowledgeLayer::Company,\n            \"org\" => mk_core::types::KnowledgeLayer::Org,\n            \"team\" => mk_core::types::KnowledgeLayer::Team,\n            \"project\" => mk_core::types::KnowledgeLayer::Project,\n            _ => return Err(format!(\"Unknown layer: {}\", p.layer).into()),\n        };\n\n        let entry = self.repo.get(ctx, layer, &p.path).await?;\n        Ok(json!({ \"success\": true, \"entry\": entry }))\n    }\n}\n\npub struct KnowledgeListTool {\n    repo: Arc<dyn KnowledgeRepository<Error = knowledge::repository::RepositoryError>>,\n}\n\nimpl KnowledgeListTool {\n    pub fn new(\n        repo: Arc<dyn KnowledgeRepository<Error = knowledge::repository::RepositoryError>>,\n    ) -> Self {\n        Self { repo }\n    }\n}\n\n#[async_trait]\nimpl Tool for KnowledgeListTool {\n    fn name(&self) -> &str {\n        \"knowledge_list\"\n    }\n\n    fn description(&self) -> &str {\n        \"List knowledge entries in a specific layer, optionally filtered by prefix.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"layer\": { \"type\": \"string\" },\n                \"prefix\": { \"type\": \"string\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"layer\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: KnowledgeListParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let layer = match p.layer.to_lowercase().as_str() {\n            \"company\" => mk_core::types::KnowledgeLayer::Company,\n            \"org\" => mk_core::types::KnowledgeLayer::Org,\n            \"team\" => mk_core::types::KnowledgeLayer::Team,\n            \"project\" => mk_core::types::KnowledgeLayer::Project,\n            _ => return Err(format!(\"Unknown layer: {}\", p.layer).into()),\n        };\n\n        let entries = self.repo.list(ctx, layer, &p.prefix).await?;\n        Ok(json!({ \"success\": true, \"entries\": entries }))\n    }\n}\n\npub struct KnowledgeQueryTool {\n    memory_manager: Arc<MemoryManager>,\n    repo: Arc<dyn KnowledgeRepository<Error = knowledge::repository::RepositoryError>>,\n}\n\nimpl KnowledgeQueryTool {\n    pub fn new(\n        memory_manager: Arc<MemoryManager>,\n        repo: Arc<dyn KnowledgeRepository<Error = knowledge::repository::RepositoryError>>,\n    ) -> Self {\n        Self {\n            memory_manager,\n            repo,\n        }\n    }\n}\n\n#[async_trait]\nimpl Tool for KnowledgeQueryTool {\n    fn name(&self) -> &str {\n        \"knowledge_query\"\n    }\n\n    fn description(&self) -> &str {\n        \"Search for knowledge entries across layers using semantic or keyword search.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": { \"type\": \"string\" },\n                \"layers\": { \"type\": \"array\", \"items\": { \"type\": \"string\" } },\n                \"limit\": { \"type\": \"integer\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"query\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: KnowledgeQueryParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let mut layers = Vec::new();\n        if p.layers.is_empty() {\n            layers = vec![\n                mk_core::types::KnowledgeLayer::Company,\n                mk_core::types::KnowledgeLayer::Org,\n                mk_core::types::KnowledgeLayer::Team,\n                mk_core::types::KnowledgeLayer::Project,\n            ];\n        } else {\n            for l in &p.layers {\n                let layer = match l.to_lowercase().as_str() {\n                    \"company\" => mk_core::types::KnowledgeLayer::Company,\n                    \"org\" => mk_core::types::KnowledgeLayer::Org,\n                    \"team\" => mk_core::types::KnowledgeLayer::Team,\n                    \"project\" => mk_core::types::KnowledgeLayer::Project,\n                    _ => continue,\n                };\n                layers.push(layer);\n            }\n        }\n\n        let vector_results: Vec<MemoryEntry> = self\n            .memory_manager\n            .search_text_with_threshold(\n                ctx.clone(),\n                &p.query,\n                p.limit.unwrap_or(10),\n                0.7,\n                std::collections::HashMap::new(),\n            )\n            .await\n            .unwrap_or_default();\n\n        let repo_results = self\n            .repo\n            .search(ctx, &p.query, layers, p.limit.unwrap_or(10))\n            .await?;\n\n        Ok(json!({\n            \"success\": true,\n            \"results\": {\n                \"semantic\": vector_results,\n                \"keyword\": repo_results\n            }\n        }))\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct KnowledgeProposal {\n    pub proposal_id: String,\n    pub draft_id: String,\n    pub title: String,\n    pub content: String,\n    pub kind: mk_core::types::KnowledgeType,\n    pub layer: mk_core::types::KnowledgeLayer,\n    pub proposed_by: String,\n    pub proposed_at: chrono::DateTime<chrono::Utc>,\n    pub status: KnowledgeProposalStatus,\n    pub approvers: Vec<String>,\n    pub metadata: std::collections::HashMap<String, serde_json::Value>,\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]\n#[serde(rename_all = \"camelCase\")]\npub enum KnowledgeProposalStatus {\n    Draft,\n    Pending,\n    Approved,\n    Rejected,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct KnowledgeDraft {\n    pub draft_id: String,\n    pub title: String,\n    pub description: String,\n    pub content: String,\n    pub kind: mk_core::types::KnowledgeType,\n    pub layer: mk_core::types::KnowledgeLayer,\n    pub status: KnowledgeDraftStatus,\n    pub created_by: String,\n    pub created_at: chrono::DateTime<chrono::Utc>,\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]\n#[serde(rename_all = \"camelCase\")]\npub enum KnowledgeDraftStatus {\n    Draft,\n    Validated,\n    Submitted,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct InterpretedKnowledge {\n    pub kind: mk_core::types::KnowledgeType,\n    pub title: String,\n    pub summary: String,\n    pub structure: KnowledgeStructure,\n    pub suggested_layer: mk_core::types::KnowledgeLayer,\n    pub confidence: f32,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct KnowledgeStructure {\n    pub context: Option<String>,\n    pub decision: Option<String>,\n    pub consequences: Option<String>,\n    pub alternatives: Option<String>,\n    pub pattern_description: Option<String>,\n    pub applicability: Option<String>,\n}\n\npub trait KnowledgeProposalStorage: Send + Sync {\n    fn store_draft(\n        &self,\n        draft: KnowledgeDraft,\n    ) -> impl std::future::Future<Output = Result<(), KnowledgeToolError>> + Send;\n\n    fn get_draft(\n        &self,\n        draft_id: &str,\n    ) -> impl std::future::Future<Output = Result<Option<KnowledgeDraft>, KnowledgeToolError>> + Send;\n\n    fn update_draft(\n        &self,\n        draft: KnowledgeDraft,\n    ) -> impl std::future::Future<Output = Result<(), KnowledgeToolError>> + Send;\n\n    fn store_proposal(\n        &self,\n        proposal: KnowledgeProposal,\n    ) -> impl std::future::Future<Output = Result<(), KnowledgeToolError>> + Send;\n\n    fn get_proposal(\n        &self,\n        proposal_id: &str,\n    ) -> impl std::future::Future<Output = Result<Option<KnowledgeProposal>, KnowledgeToolError>> + Send;\n\n    fn list_pending(\n        &self,\n        layer: Option<mk_core::types::KnowledgeLayer>,\n    ) -> impl std::future::Future<Output = Result<Vec<KnowledgeProposal>, KnowledgeToolError>> + Send;\n}\n\n#[derive(Debug, Clone, thiserror::Error)]\npub enum KnowledgeToolError {\n    #[error(\"Draft not found: {0}\")]\n    DraftNotFound(String),\n\n    #[error(\"Proposal not found: {0}\")]\n    ProposalNotFound(String),\n\n    #[error(\"Draft already submitted: {0}\")]\n    DraftAlreadySubmitted(String),\n\n    #[error(\"Invalid knowledge type: {0}\")]\n    InvalidKnowledgeType(String),\n\n    #[error(\"Invalid layer: {0}\")]\n    InvalidLayer(String),\n\n    #[error(\"Storage error: {0}\")]\n    StorageError(String),\n\n    #[error(\"Interpretation error: {0}\")]\n    InterpretationError(String),\n}\n\npub trait KnowledgeInterpreter: Send + Sync {\n    fn interpret(\n        &self,\n        description: &str,\n        context: Option<&str>,\n    ) -> impl std::future::Future<Output = Result<InterpretedKnowledge, KnowledgeToolError>> + Send;\n}\n\npub struct SimpleKnowledgeInterpreter;\n\nimpl SimpleKnowledgeInterpreter {\n    pub fn new() -> Self {\n        Self\n    }\n}\n\nimpl Default for SimpleKnowledgeInterpreter {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\nimpl KnowledgeInterpreter for SimpleKnowledgeInterpreter {\n    async fn interpret(\n        &self,\n        description: &str,\n        _context: Option<&str>,\n    ) -> Result<InterpretedKnowledge, KnowledgeToolError> {\n        let lower = description.to_lowercase();\n\n        let (kind, confidence) = if lower.contains(\"decide\")\n            || lower.contains(\"decision\")\n            || lower.contains(\"we should\")\n            || lower.contains(\"must use\")\n            || lower.contains(\"adopt\")\n            || lower.contains(\"choose\")\n        {\n            (mk_core::types::KnowledgeType::Adr, 0.8)\n        } else if lower.contains(\"pattern\")\n            || lower.contains(\"approach\")\n            || lower.contains(\"how to\")\n            || lower.contains(\"best practice\")\n        {\n            (mk_core::types::KnowledgeType::Pattern, 0.75)\n        } else if lower.contains(\"policy\")\n            || lower.contains(\"rule\")\n            || lower.contains(\"must not\")\n            || lower.contains(\"forbidden\")\n            || lower.contains(\"required\")\n        {\n            (mk_core::types::KnowledgeType::Policy, 0.8)\n        } else if lower.contains(\"spec\")\n            || lower.contains(\"specification\")\n            || lower.contains(\"requirement\")\n        {\n            (mk_core::types::KnowledgeType::Spec, 0.7)\n        } else {\n            (mk_core::types::KnowledgeType::Adr, 0.5)\n        };\n\n        let suggested_layer = if lower.contains(\"company\")\n            || lower.contains(\"organization-wide\")\n            || lower.contains(\"all teams\")\n        {\n            mk_core::types::KnowledgeLayer::Company\n        } else if lower.contains(\"org\") || lower.contains(\"department\") {\n            mk_core::types::KnowledgeLayer::Org\n        } else if lower.contains(\"team\") {\n            mk_core::types::KnowledgeLayer::Team\n        } else {\n            mk_core::types::KnowledgeLayer::Project\n        };\n\n        let title = extract_title_from_description(description);\n        let summary = if description.len() > 200 {\n            format!(\"{}...\", &description[..200])\n        } else {\n            description.to_string()\n        };\n\n        let structure = match kind {\n            mk_core::types::KnowledgeType::Adr => KnowledgeStructure {\n                context: Some(\"Context to be filled\".to_string()),\n                decision: Some(description.to_string()),\n                consequences: Some(\"Consequences to be determined\".to_string()),\n                alternatives: Some(\"Alternatives to be documented\".to_string()),\n                pattern_description: None,\n                applicability: None,\n            },\n            mk_core::types::KnowledgeType::Pattern => KnowledgeStructure {\n                context: None,\n                decision: None,\n                consequences: None,\n                alternatives: None,\n                pattern_description: Some(description.to_string()),\n                applicability: Some(\"Applicability to be defined\".to_string()),\n            },\n            _ => KnowledgeStructure {\n                context: Some(description.to_string()),\n                decision: None,\n                consequences: None,\n                alternatives: None,\n                pattern_description: None,\n                applicability: None,\n            },\n        };\n\n        Ok(InterpretedKnowledge {\n            kind,\n            title,\n            summary,\n            structure,\n            suggested_layer,\n            confidence,\n        })\n    }\n}\n\nfn extract_title_from_description(description: &str) -> String {\n    let first_sentence = description\n        .split(&['.', '!', '?'][..])\n        .next()\n        .unwrap_or(description)\n        .trim();\n\n    if first_sentence.len() > 80 {\n        format!(\"{}...\", &first_sentence[..77])\n    } else {\n        first_sentence.to_string()\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct KnowledgeProposeParams {\n    pub description: String,\n    #[serde(rename = \"knowledgeType\")]\n    pub knowledge_type: Option<String>,\n    pub layer: Option<String>,\n    pub title: Option<String>,\n    #[serde(rename = \"proposedBy\")]\n    pub proposed_by: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\npub struct KnowledgeProposeTool<S, I>\nwhere\n    S: KnowledgeProposalStorage,\n    I: KnowledgeInterpreter,\n{\n    storage: Arc<S>,\n    interpreter: Arc<I>,\n}\n\nimpl<S, I> KnowledgeProposeTool<S, I>\nwhere\n    S: KnowledgeProposalStorage,\n    I: KnowledgeInterpreter,\n{\n    pub fn new(storage: Arc<S>, interpreter: Arc<I>) -> Self {\n        Self {\n            storage,\n            interpreter,\n        }\n    }\n\n    pub async fn propose(\n        &self,\n        description: &str,\n        knowledge_type: Option<&str>,\n        layer: Option<&str>,\n        title: Option<&str>,\n        proposed_by: &str,\n    ) -> Result<KnowledgeDraft, KnowledgeToolError> {\n        let interpreted = self.interpreter.interpret(description, None).await?;\n\n        let kind = if let Some(kt) = knowledge_type {\n            parse_knowledge_type(kt)?\n        } else {\n            interpreted.kind\n        };\n\n        let layer = if let Some(l) = layer {\n            parse_knowledge_layer(l)?\n        } else {\n            interpreted.suggested_layer\n        };\n\n        let title = title.map(|t| t.to_string()).unwrap_or(interpreted.title);\n\n        let content = generate_draft_content(&kind, &title, &interpreted.structure);\n\n        let draft = KnowledgeDraft {\n            draft_id: uuid::Uuid::new_v4().to_string(),\n            title,\n            description: description.to_string(),\n            content,\n            kind,\n            layer,\n            status: KnowledgeDraftStatus::Draft,\n            created_by: proposed_by.to_string(),\n            created_at: chrono::Utc::now(),\n        };\n\n        self.storage.store_draft(draft.clone()).await?;\n\n        Ok(draft)\n    }\n}\n\nfn parse_knowledge_type(s: &str) -> Result<mk_core::types::KnowledgeType, KnowledgeToolError> {\n    match s.to_lowercase().as_str() {\n        \"adr\" => Ok(mk_core::types::KnowledgeType::Adr),\n        \"policy\" => Ok(mk_core::types::KnowledgeType::Policy),\n        \"pattern\" => Ok(mk_core::types::KnowledgeType::Pattern),\n        \"spec\" => Ok(mk_core::types::KnowledgeType::Spec),\n        \"hindsight\" => Ok(mk_core::types::KnowledgeType::Hindsight),\n        _ => Err(KnowledgeToolError::InvalidKnowledgeType(s.to_string())),\n    }\n}\n\nfn parse_knowledge_layer(s: &str) -> Result<mk_core::types::KnowledgeLayer, KnowledgeToolError> {\n    match s.to_lowercase().as_str() {\n        \"company\" => Ok(mk_core::types::KnowledgeLayer::Company),\n        \"org\" => Ok(mk_core::types::KnowledgeLayer::Org),\n        \"team\" => Ok(mk_core::types::KnowledgeLayer::Team),\n        \"project\" => Ok(mk_core::types::KnowledgeLayer::Project),\n        _ => Err(KnowledgeToolError::InvalidLayer(s.to_string())),\n    }\n}\n\nfn generate_draft_content(\n    kind: &mk_core::types::KnowledgeType,\n    title: &str,\n    structure: &KnowledgeStructure,\n) -> String {\n    match kind {\n        mk_core::types::KnowledgeType::Adr => {\n            format!(\n                \"# {}\\n\\n## Status\\n\\nProposed\\n\\n## Context\\n\\n{}\\n\\n## Decision\\n\\n{}\\n\\n## Consequences\\n\\n{}\\n\\n## Alternatives Considered\\n\\n{}\",\n                title,\n                structure.context.as_deref().unwrap_or(\"_To be filled_\"),\n                structure.decision.as_deref().unwrap_or(\"_To be filled_\"),\n                structure\n                    .consequences\n                    .as_deref()\n                    .unwrap_or(\"_To be determined_\"),\n                structure\n                    .alternatives\n                    .as_deref()\n                    .unwrap_or(\"_To be documented_\")\n            )\n        }\n        mk_core::types::KnowledgeType::Pattern => {\n            format!(\n                \"# Pattern: {}\\n\\n## Description\\n\\n{}\\n\\n## Applicability\\n\\n{}\\n\\n## Implementation\\n\\n_To be detailed_\\n\\n## Examples\\n\\n_To be provided_\",\n                title,\n                structure\n                    .pattern_description\n                    .as_deref()\n                    .unwrap_or(\"_To be described_\"),\n                structure\n                    .applicability\n                    .as_deref()\n                    .unwrap_or(\"_To be defined_\")\n            )\n        }\n        mk_core::types::KnowledgeType::Policy => {\n            format!(\n                \"# Policy: {}\\n\\n## Scope\\n\\n_To be defined_\\n\\n## Rules\\n\\n{}\\n\\n## Enforcement\\n\\n_To be specified_\\n\\n## Exceptions\\n\\n_None documented_\",\n                title,\n                structure.context.as_deref().unwrap_or(\"_To be defined_\")\n            )\n        }\n        mk_core::types::KnowledgeType::Spec => {\n            format!(\n                \"# Specification: {}\\n\\n## Overview\\n\\n{}\\n\\n## Requirements\\n\\n_To be detailed_\\n\\n## Acceptance Criteria\\n\\n_To be defined_\",\n                title,\n                structure.context.as_deref().unwrap_or(\"_To be described_\")\n            )\n        }\n        mk_core::types::KnowledgeType::Hindsight => {\n            format!(\n                \"# Hindsight: {}\\n\\n## What Happened\\n\\n{}\\n\\n## Lessons Learned\\n\\n_To be documented_\\n\\n## Recommendations\\n\\n_To be provided_\",\n                title,\n                structure.context.as_deref().unwrap_or(\"_To be described_\")\n            )\n        }\n    }\n}\n\n#[async_trait]\nimpl<S, I> Tool for KnowledgeProposeTool<S, I>\nwhere\n    S: KnowledgeProposalStorage + 'static,\n    I: KnowledgeInterpreter + 'static,\n{\n    fn name(&self) -> &str {\n        \"aeterna_knowledge_propose\"\n    }\n\n    fn description(&self) -> &str {\n        \"Propose new knowledge (ADR, pattern, policy, spec) from natural language description.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"description\": {\n                    \"type\": \"string\",\n                    \"description\": \"Natural language description of the knowledge to propose\"\n                },\n                \"knowledgeType\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"adr\", \"pattern\", \"policy\", \"spec\", \"hindsight\"],\n                    \"description\": \"Optional: Override interpreted knowledge type\"\n                },\n                \"layer\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"company\", \"org\", \"team\", \"project\"],\n                    \"description\": \"Optional: Target layer for the knowledge\"\n                },\n                \"title\": {\n                    \"type\": \"string\",\n                    \"description\": \"Optional: Override auto-generated title\"\n                },\n                \"proposedBy\": {\n                    \"type\": \"string\",\n                    \"description\": \"User ID or email of the proposer\"\n                }\n            },\n            \"required\": [\"description\", \"proposedBy\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: KnowledgeProposeParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let draft = self\n            .propose(\n                &p.description,\n                p.knowledge_type.as_deref(),\n                p.layer.as_deref(),\n                p.title.as_deref(),\n                &p.proposed_by,\n            )\n            .await\n            .map_err(|e| Box::new(e) as Box<dyn std::error::Error + Send + Sync>)?;\n\n        Ok(json!({\n            \"success\": true,\n            \"draft\": {\n                \"draftId\": draft.draft_id,\n                \"title\": draft.title,\n                \"kind\": format!(\"{:?}\", draft.kind).to_lowercase(),\n                \"layer\": format!(\"{:?}\", draft.layer).to_lowercase(),\n                \"content\": draft.content,\n                \"status\": format!(\"{:?}\", draft.status).to_lowercase()\n            },\n            \"nextSteps\": [\n                \"Review and edit the generated draft content\",\n                \"Submit the draft for approval using the governance workflow\",\n                \"Once approved, the knowledge will be added to the repository\"\n            ]\n        }))\n    }\n}\n\npub struct InMemoryKnowledgeProposalStorage {\n    drafts: tokio::sync::RwLock<std::collections::HashMap<String, KnowledgeDraft>>,\n    proposals: tokio::sync::RwLock<std::collections::HashMap<String, KnowledgeProposal>>,\n}\n\nimpl InMemoryKnowledgeProposalStorage {\n    pub fn new() -> Self {\n        Self {\n            drafts: tokio::sync::RwLock::new(std::collections::HashMap::new()),\n            proposals: tokio::sync::RwLock::new(std::collections::HashMap::new()),\n        }\n    }\n}\n\nimpl Default for InMemoryKnowledgeProposalStorage {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\nimpl KnowledgeProposalStorage for InMemoryKnowledgeProposalStorage {\n    async fn store_draft(&self, draft: KnowledgeDraft) -> Result<(), KnowledgeToolError> {\n        let mut drafts = self.drafts.write().await;\n        drafts.insert(draft.draft_id.clone(), draft);\n        Ok(())\n    }\n\n    async fn get_draft(\n        &self,\n        draft_id: &str,\n    ) -> Result<Option<KnowledgeDraft>, KnowledgeToolError> {\n        let drafts = self.drafts.read().await;\n        Ok(drafts.get(draft_id).cloned())\n    }\n\n    async fn update_draft(&self, draft: KnowledgeDraft) -> Result<(), KnowledgeToolError> {\n        let mut drafts = self.drafts.write().await;\n        drafts.insert(draft.draft_id.clone(), draft);\n        Ok(())\n    }\n\n    async fn store_proposal(&self, proposal: KnowledgeProposal) -> Result<(), KnowledgeToolError> {\n        let mut proposals = self.proposals.write().await;\n        proposals.insert(proposal.proposal_id.clone(), proposal);\n        Ok(())\n    }\n\n    async fn get_proposal(\n        &self,\n        proposal_id: &str,\n    ) -> Result<Option<KnowledgeProposal>, KnowledgeToolError> {\n        let proposals = self.proposals.read().await;\n        Ok(proposals.get(proposal_id).cloned())\n    }\n\n    async fn list_pending(\n        &self,\n        layer: Option<mk_core::types::KnowledgeLayer>,\n    ) -> Result<Vec<KnowledgeProposal>, KnowledgeToolError> {\n        let proposals = self.proposals.read().await;\n        let pending: Vec<_> = proposals\n            .values()\n            .filter(|p| {\n                p.status == KnowledgeProposalStatus::Pending && layer.map_or(true, |l| p.layer == l)\n            })\n            .cloned()\n            .collect();\n        Ok(pending)\n    }\n}\n\npub trait GovernanceIntegration: Send + Sync {\n    fn submit_for_approval(\n        &self,\n        draft: &KnowledgeDraft,\n        justification: Option<&str>,\n        notify: &[String],\n    ) -> impl std::future::Future<Output = Result<String, KnowledgeToolError>> + Send;\n\n    fn get_approval_status(\n        &self,\n        proposal_id: &str,\n    ) -> impl std::future::Future<Output = Result<KnowledgeProposalStatus, KnowledgeToolError>> + Send;\n}\n\npub struct SimpleGovernanceIntegration {\n    required_approvals: u32,\n    auto_approve_project_level: bool,\n}\n\nimpl SimpleGovernanceIntegration {\n    pub fn new() -> Self {\n        Self {\n            required_approvals: 1,\n            auto_approve_project_level: true,\n        }\n    }\n\n    pub fn with_config(required_approvals: u32, auto_approve_project_level: bool) -> Self {\n        Self {\n            required_approvals,\n            auto_approve_project_level,\n        }\n    }\n}\n\nimpl Default for SimpleGovernanceIntegration {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\nimpl GovernanceIntegration for SimpleGovernanceIntegration {\n    async fn submit_for_approval(\n        &self,\n        draft: &KnowledgeDraft,\n        _justification: Option<&str>,\n        _notify: &[String],\n    ) -> Result<String, KnowledgeToolError> {\n        let proposal_id = uuid::Uuid::new_v4().to_string();\n\n        if self.auto_approve_project_level && draft.layer == mk_core::types::KnowledgeLayer::Project\n        {\n            return Ok(proposal_id);\n        }\n\n        Ok(proposal_id)\n    }\n\n    async fn get_approval_status(\n        &self,\n        _proposal_id: &str,\n    ) -> Result<KnowledgeProposalStatus, KnowledgeToolError> {\n        Ok(KnowledgeProposalStatus::Pending)\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct KnowledgeSubmitParams {\n    #[serde(rename = \"draftId\")]\n    pub draft_id: String,\n    pub justification: Option<String>,\n    #[serde(default)]\n    pub notify: Vec<String>,\n    #[serde(rename = \"proposedBy\")]\n    pub proposed_by: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\npub struct KnowledgeProposalSubmitTool<S, G>\nwhere\n    S: KnowledgeProposalStorage,\n    G: GovernanceIntegration,\n{\n    storage: Arc<S>,\n    governance: Arc<G>,\n}\n\nimpl<S, G> KnowledgeProposalSubmitTool<S, G>\nwhere\n    S: KnowledgeProposalStorage,\n    G: GovernanceIntegration,\n{\n    pub fn new(storage: Arc<S>, governance: Arc<G>) -> Self {\n        Self {\n            storage,\n            governance,\n        }\n    }\n\n    pub async fn submit(\n        &self,\n        draft_id: &str,\n        justification: Option<&str>,\n        notify: &[String],\n        proposed_by: &str,\n    ) -> Result<KnowledgeProposal, KnowledgeToolError> {\n        let draft = self\n            .storage\n            .get_draft(draft_id)\n            .await?\n            .ok_or_else(|| KnowledgeToolError::DraftNotFound(draft_id.to_string()))?;\n\n        if draft.status == KnowledgeDraftStatus::Submitted {\n            return Err(KnowledgeToolError::DraftAlreadySubmitted(\n                draft_id.to_string(),\n            ));\n        }\n\n        let proposal_id = self\n            .governance\n            .submit_for_approval(&draft, justification, notify)\n            .await?;\n\n        let status = self.governance.get_approval_status(&proposal_id).await?;\n\n        let proposal = KnowledgeProposal {\n            proposal_id: proposal_id.clone(),\n            draft_id: draft_id.to_string(),\n            title: draft.title.clone(),\n            content: draft.content.clone(),\n            kind: draft.kind,\n            layer: draft.layer,\n            proposed_by: proposed_by.to_string(),\n            proposed_at: chrono::Utc::now(),\n            status,\n            approvers: notify.to_vec(),\n            metadata: std::collections::HashMap::new(),\n        };\n\n        self.storage.store_proposal(proposal.clone()).await?;\n\n        let mut updated_draft = draft;\n        updated_draft.status = KnowledgeDraftStatus::Submitted;\n        self.storage.update_draft(updated_draft).await?;\n\n        Ok(proposal)\n    }\n}\n\n#[async_trait]\nimpl<S, G> Tool for KnowledgeProposalSubmitTool<S, G>\nwhere\n    S: KnowledgeProposalStorage + 'static,\n    G: GovernanceIntegration + 'static,\n{\n    fn name(&self) -> &str {\n        \"aeterna_knowledge_submit\"\n    }\n\n    fn description(&self) -> &str {\n        \"Submit a knowledge draft for approval through the governance workflow.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"draftId\": {\n                    \"type\": \"string\",\n                    \"description\": \"ID of the draft to submit\"\n                },\n                \"justification\": {\n                    \"type\": \"string\",\n                    \"description\": \"Reason for proposing this knowledge\"\n                },\n                \"notify\": {\n                    \"type\": \"array\",\n                    \"items\": { \"type\": \"string\" },\n                    \"description\": \"Additional approvers to notify\"\n                },\n                \"proposedBy\": {\n                    \"type\": \"string\",\n                    \"description\": \"User ID or email of the proposer\"\n                }\n            },\n            \"required\": [\"draftId\", \"proposedBy\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: KnowledgeSubmitParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let proposal = self\n            .submit(\n                &p.draft_id,\n                p.justification.as_deref(),\n                &p.notify,\n                &p.proposed_by,\n            )\n            .await\n            .map_err(|e| Box::new(e) as Box<dyn std::error::Error + Send + Sync>)?;\n\n        let status_str = match proposal.status {\n            KnowledgeProposalStatus::Draft => \"draft\",\n            KnowledgeProposalStatus::Pending => \"pending\",\n            KnowledgeProposalStatus::Approved => \"approved\",\n            KnowledgeProposalStatus::Rejected => \"rejected\",\n        };\n\n        Ok(json!({\n            \"success\": true,\n            \"proposal\": {\n                \"proposalId\": proposal.proposal_id,\n                \"draftId\": proposal.draft_id,\n                \"title\": proposal.title,\n                \"kind\": format!(\"{:?}\", proposal.kind).to_lowercase(),\n                \"layer\": format!(\"{:?}\", proposal.layer).to_lowercase(),\n                \"status\": status_str,\n                \"proposedBy\": proposal.proposed_by,\n                \"proposedAt\": proposal.proposed_at.to_rfc3339()\n            },\n            \"message\": match proposal.status {\n                KnowledgeProposalStatus::Approved => \"Knowledge proposal auto-approved\",\n                KnowledgeProposalStatus::Pending => \"Knowledge proposal submitted for approval\",\n                _ => \"Knowledge proposal created\"\n            }\n        }))\n    }\n}\n\npub struct KnowledgePendingListTool<S>\nwhere\n    S: KnowledgeProposalStorage,\n{\n    storage: Arc<S>,\n}\n\nimpl<S: KnowledgeProposalStorage> KnowledgePendingListTool<S> {\n    pub fn new(storage: Arc<S>) -> Self {\n        Self { storage }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct KnowledgePendingListParams {\n    pub layer: Option<String>,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[async_trait]\nimpl<S: KnowledgeProposalStorage + 'static> Tool for KnowledgePendingListTool<S> {\n    fn name(&self) -> &str {\n        \"aeterna_knowledge_pending\"\n    }\n\n    fn description(&self) -> &str {\n        \"List pending knowledge proposals awaiting approval.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"layer\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"company\", \"org\", \"team\", \"project\"],\n                    \"description\": \"Filter by target layer\"\n                }\n            }\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: KnowledgePendingListParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let layer = if let Some(l) = p.layer.as_ref() {\n            Some(parse_knowledge_layer(l)?)\n        } else {\n            None\n        };\n\n        let pending = self\n            .storage\n            .list_pending(layer)\n            .await\n            .map_err(|e| Box::new(e) as Box<dyn std::error::Error + Send + Sync>)?;\n\n        let proposals: Vec<_> = pending\n            .iter()\n            .map(|p| {\n                json!({\n                    \"proposalId\": p.proposal_id,\n                    \"title\": p.title,\n                    \"kind\": format!(\"{:?}\", p.kind).to_lowercase(),\n                    \"layer\": format!(\"{:?}\", p.layer).to_lowercase(),\n                    \"proposedBy\": p.proposed_by,\n                    \"proposedAt\": p.proposed_at.to_rfc3339()\n                })\n            })\n            .collect();\n\n        Ok(json!({\n            \"success\": true,\n            \"count\": proposals.len(),\n            \"proposals\": proposals\n        }))\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::{TenantId, UserId};\n    use std::str::FromStr;\n\n    fn test_ctx() -> TenantContext {\n        TenantContext {\n            tenant_id: TenantId::from_str(\"test-tenant\").unwrap(),\n            user_id: UserId::from_str(\"test-user\").unwrap(),\n            agent_id: None,\n        }\n    }\n\n    #[tokio::test]\n    async fn test_simple_interpreter_detects_adr() {\n        let interpreter = SimpleKnowledgeInterpreter::new();\n\n        let result = interpreter\n            .interpret(\"We should decide to use PostgreSQL for all databases\", None)\n            .await\n            .unwrap();\n\n        assert_eq!(result.kind, mk_core::types::KnowledgeType::Adr);\n        assert!(result.confidence >= 0.7);\n    }\n\n    #[tokio::test]\n    async fn test_simple_interpreter_detects_pattern() {\n        let interpreter = SimpleKnowledgeInterpreter::new();\n\n        let result = interpreter\n            .interpret(\"Here is the best practice pattern for error handling\", None)\n            .await\n            .unwrap();\n\n        assert_eq!(result.kind, mk_core::types::KnowledgeType::Pattern);\n    }\n\n    #[tokio::test]\n    async fn test_simple_interpreter_detects_policy() {\n        let interpreter = SimpleKnowledgeInterpreter::new();\n\n        let result = interpreter\n            .interpret(\"This policy states that all code must not use eval()\", None)\n            .await\n            .unwrap();\n\n        assert_eq!(result.kind, mk_core::types::KnowledgeType::Policy);\n    }\n\n    #[tokio::test]\n    async fn test_simple_interpreter_suggests_layer() {\n        let interpreter = SimpleKnowledgeInterpreter::new();\n\n        let result = interpreter\n            .interpret(\"All teams must follow this company-wide standard\", None)\n            .await\n            .unwrap();\n\n        assert_eq!(\n            result.suggested_layer,\n            mk_core::types::KnowledgeLayer::Company\n        );\n    }\n\n    #[tokio::test]\n    async fn test_extract_title() {\n        let title = extract_title_from_description(\n            \"Use PostgreSQL for databases. This is the recommended approach.\",\n        );\n        assert_eq!(title, \"Use PostgreSQL for databases\");\n    }\n\n    #[tokio::test]\n    async fn test_extract_title_truncates_long() {\n        let long_desc = \"This is a very long description that should be truncated because it exceeds the maximum allowed length for a title in our system\";\n        let title = extract_title_from_description(long_desc);\n        assert!(title.len() <= 80);\n        assert!(title.ends_with(\"...\"));\n    }\n\n    #[tokio::test]\n    async fn test_propose_creates_draft() {\n        let storage = Arc::new(InMemoryKnowledgeProposalStorage::new());\n        let interpreter = Arc::new(SimpleKnowledgeInterpreter::new());\n        let tool = KnowledgeProposeTool::new(storage.clone(), interpreter);\n\n        let draft = tool\n            .propose(\n                \"We should use GraphQL for all new APIs\",\n                None,\n                None,\n                None,\n                \"user@test.com\",\n            )\n            .await\n            .unwrap();\n\n        assert!(!draft.draft_id.is_empty());\n        assert_eq!(draft.kind, mk_core::types::KnowledgeType::Adr);\n        assert!(draft.content.contains(\"GraphQL\"));\n        assert_eq!(draft.status, KnowledgeDraftStatus::Draft);\n    }\n\n    #[tokio::test]\n    async fn test_propose_with_explicit_type() {\n        let storage = Arc::new(InMemoryKnowledgeProposalStorage::new());\n        let interpreter = Arc::new(SimpleKnowledgeInterpreter::new());\n        let tool = KnowledgeProposeTool::new(storage, interpreter);\n\n        let draft = tool\n            .propose(\n                \"Here is how we handle authentication\",\n                Some(\"pattern\"),\n                None,\n                None,\n                \"user@test.com\",\n            )\n            .await\n            .unwrap();\n\n        assert_eq!(draft.kind, mk_core::types::KnowledgeType::Pattern);\n    }\n\n    #[tokio::test]\n    async fn test_propose_with_explicit_layer() {\n        let storage = Arc::new(InMemoryKnowledgeProposalStorage::new());\n        let interpreter = Arc::new(SimpleKnowledgeInterpreter::new());\n        let tool = KnowledgeProposeTool::new(storage, interpreter);\n\n        let draft = tool\n            .propose(\n                \"Team-specific coding standards\",\n                None,\n                Some(\"team\"),\n                None,\n                \"user@test.com\",\n            )\n            .await\n            .unwrap();\n\n        assert_eq!(draft.layer, mk_core::types::KnowledgeLayer::Team);\n    }\n\n    #[tokio::test]\n    async fn test_propose_with_custom_title() {\n        let storage = Arc::new(InMemoryKnowledgeProposalStorage::new());\n        let interpreter = Arc::new(SimpleKnowledgeInterpreter::new());\n        let tool = KnowledgeProposeTool::new(storage, interpreter);\n\n        let draft = tool\n            .propose(\n                \"We should use GraphQL\",\n                None,\n                None,\n                Some(\"ADR-042: GraphQL for APIs\"),\n                \"user@test.com\",\n            )\n            .await\n            .unwrap();\n\n        assert_eq!(draft.title, \"ADR-042: GraphQL for APIs\");\n    }\n\n    #[tokio::test]\n    async fn test_propose_stores_draft() {\n        let storage = Arc::new(InMemoryKnowledgeProposalStorage::new());\n        let interpreter = Arc::new(SimpleKnowledgeInterpreter::new());\n        let tool = KnowledgeProposeTool::new(storage.clone(), interpreter);\n\n        let draft = tool\n            .propose(\n                \"Use REST for external APIs\",\n                None,\n                None,\n                None,\n                \"user@test.com\",\n            )\n            .await\n            .unwrap();\n\n        let stored = storage.get_draft(&draft.draft_id).await.unwrap();\n        assert!(stored.is_some());\n        assert_eq!(stored.unwrap().draft_id, draft.draft_id);\n    }\n\n    #[tokio::test]\n    async fn test_propose_invalid_knowledge_type() {\n        let result = parse_knowledge_type(\"invalid\");\n        assert!(result.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_propose_invalid_layer() {\n        let result = parse_knowledge_layer(\"invalid\");\n        assert!(result.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_generate_adr_content() {\n        let structure = KnowledgeStructure {\n            context: Some(\"Need to choose a database\".to_string()),\n            decision: Some(\"Use PostgreSQL\".to_string()),\n            consequences: Some(\"Good performance\".to_string()),\n            alternatives: Some(\"MySQL, MongoDB\".to_string()),\n            pattern_description: None,\n            applicability: None,\n        };\n\n        let content = generate_draft_content(\n            &mk_core::types::KnowledgeType::Adr,\n            \"Database Selection\",\n            &structure,\n        );\n\n        assert!(content.contains(\"# Database Selection\"));\n        assert!(content.contains(\"## Context\"));\n        assert!(content.contains(\"## Decision\"));\n        assert!(content.contains(\"Use PostgreSQL\"));\n    }\n\n    #[tokio::test]\n    async fn test_generate_pattern_content() {\n        let structure = KnowledgeStructure {\n            context: None,\n            decision: None,\n            consequences: None,\n            alternatives: None,\n            pattern_description: Some(\"Circuit breaker for resilience\".to_string()),\n            applicability: Some(\"External service calls\".to_string()),\n        };\n\n        let content = generate_draft_content(\n            &mk_core::types::KnowledgeType::Pattern,\n            \"Circuit Breaker\",\n            &structure,\n        );\n\n        assert!(content.contains(\"# Pattern: Circuit Breaker\"));\n        assert!(content.contains(\"## Description\"));\n        assert!(content.contains(\"Circuit breaker for resilience\"));\n    }\n\n    #[tokio::test]\n    async fn test_tool_interface() {\n        let storage = Arc::new(InMemoryKnowledgeProposalStorage::new());\n        let interpreter = Arc::new(SimpleKnowledgeInterpreter::new());\n        let tool = KnowledgeProposeTool::new(storage, interpreter);\n\n        assert_eq!(tool.name(), \"aeterna_knowledge_propose\");\n        assert!(tool.description().contains(\"knowledge\"));\n\n        let schema = tool.input_schema();\n        assert!(schema[\"properties\"][\"description\"].is_object());\n        assert!(schema[\"properties\"][\"knowledgeType\"].is_object());\n        assert!(schema[\"properties\"][\"proposedBy\"].is_object());\n    }\n\n    #[tokio::test]\n    async fn test_tool_call() {\n        let storage = Arc::new(InMemoryKnowledgeProposalStorage::new());\n        let interpreter = Arc::new(SimpleKnowledgeInterpreter::new());\n        let tool = KnowledgeProposeTool::new(storage, interpreter);\n\n        let params = json!({\n            \"description\": \"We should document that all new APIs must use GraphQL\",\n            \"proposedBy\": \"user@test.com\"\n        });\n\n        let result = tool.call(params).await.unwrap();\n\n        assert_eq!(result[\"success\"], true);\n        assert!(result[\"draft\"][\"draftId\"].is_string());\n        assert!(\n            result[\"draft\"][\"content\"]\n                .as_str()\n                .unwrap()\n                .contains(\"GraphQL\")\n        );\n        assert!(result[\"nextSteps\"].is_array());\n    }\n\n    #[tokio::test]\n    async fn test_in_memory_storage_operations() {\n        let storage = InMemoryKnowledgeProposalStorage::new();\n\n        let draft = KnowledgeDraft {\n            draft_id: \"draft-1\".to_string(),\n            title: \"Test\".to_string(),\n            description: \"Test description\".to_string(),\n            content: \"Test content\".to_string(),\n            kind: mk_core::types::KnowledgeType::Adr,\n            layer: mk_core::types::KnowledgeLayer::Project,\n            status: KnowledgeDraftStatus::Draft,\n            created_by: \"user\".to_string(),\n            created_at: chrono::Utc::now(),\n        };\n\n        storage.store_draft(draft.clone()).await.unwrap();\n        let retrieved = storage.get_draft(\"draft-1\").await.unwrap();\n        assert!(retrieved.is_some());\n\n        let mut updated = draft.clone();\n        updated.status = KnowledgeDraftStatus::Validated;\n        storage.update_draft(updated).await.unwrap();\n\n        let retrieved = storage.get_draft(\"draft-1\").await.unwrap().unwrap();\n        assert_eq!(retrieved.status, KnowledgeDraftStatus::Validated);\n    }\n\n    #[tokio::test]\n    async fn test_proposal_storage_operations() {\n        let storage = InMemoryKnowledgeProposalStorage::new();\n\n        let proposal = KnowledgeProposal {\n            proposal_id: \"prop-1\".to_string(),\n            draft_id: \"draft-1\".to_string(),\n            title: \"Test Proposal\".to_string(),\n            content: \"Content\".to_string(),\n            kind: mk_core::types::KnowledgeType::Adr,\n            layer: mk_core::types::KnowledgeLayer::Project,\n            proposed_by: \"user\".to_string(),\n            proposed_at: chrono::Utc::now(),\n            status: KnowledgeProposalStatus::Pending,\n            approvers: vec![\"approver@test.com\".to_string()],\n            metadata: std::collections::HashMap::new(),\n        };\n\n        storage.store_proposal(proposal).await.unwrap();\n\n        let pending = storage.list_pending(None).await.unwrap();\n        assert_eq!(pending.len(), 1);\n\n        let pending_project = storage\n            .list_pending(Some(mk_core::types::KnowledgeLayer::Project))\n            .await\n            .unwrap();\n        assert_eq!(pending_project.len(), 1);\n\n        let pending_team = storage\n            .list_pending(Some(mk_core::types::KnowledgeLayer::Team))\n            .await\n            .unwrap();\n        assert_eq!(pending_team.len(), 0);\n    }\n\n    #[tokio::test]\n    async fn test_submit_tool_interface() {\n        let storage = Arc::new(InMemoryKnowledgeProposalStorage::new());\n        let governance = Arc::new(SimpleGovernanceIntegration::new());\n        let tool = KnowledgeProposalSubmitTool::new(storage, governance);\n\n        assert_eq!(tool.name(), \"aeterna_knowledge_submit\");\n        assert!(tool.description().contains(\"approval\"));\n\n        let schema = tool.input_schema();\n        assert!(schema[\"properties\"][\"draftId\"].is_object());\n        assert!(schema[\"properties\"][\"proposedBy\"].is_object());\n    }\n\n    #[tokio::test]\n    async fn test_submit_creates_proposal() {\n        let storage = Arc::new(InMemoryKnowledgeProposalStorage::new());\n        let governance = Arc::new(SimpleGovernanceIntegration::new());\n        let tool = KnowledgeProposalSubmitTool::new(storage.clone(), governance);\n\n        let draft = KnowledgeDraft {\n            draft_id: \"draft-submit\".to_string(),\n            title: \"Test ADR\".to_string(),\n            description: \"Test\".to_string(),\n            content: \"# Test\".to_string(),\n            kind: mk_core::types::KnowledgeType::Adr,\n            layer: mk_core::types::KnowledgeLayer::Project,\n            status: KnowledgeDraftStatus::Draft,\n            created_by: \"user@test.com\".to_string(),\n            created_at: chrono::Utc::now(),\n        };\n        storage.store_draft(draft).await.unwrap();\n\n        let proposal = tool\n            .submit(\n                \"draft-submit\",\n                Some(\"Important decision\"),\n                &[],\n                \"user@test.com\",\n            )\n            .await\n            .unwrap();\n\n        assert!(!proposal.proposal_id.is_empty());\n        assert_eq!(proposal.draft_id, \"draft-submit\");\n        assert_eq!(proposal.title, \"Test ADR\");\n    }\n\n    #[tokio::test]\n    async fn test_submit_marks_draft_as_submitted() {\n        let storage = Arc::new(InMemoryKnowledgeProposalStorage::new());\n        let governance = Arc::new(SimpleGovernanceIntegration::new());\n        let tool = KnowledgeProposalSubmitTool::new(storage.clone(), governance);\n\n        let draft = KnowledgeDraft {\n            draft_id: \"draft-mark\".to_string(),\n            title: \"Test\".to_string(),\n            description: \"Test\".to_string(),\n            content: \"Content\".to_string(),\n            kind: mk_core::types::KnowledgeType::Adr,\n            layer: mk_core::types::KnowledgeLayer::Team,\n            status: KnowledgeDraftStatus::Draft,\n            created_by: \"user\".to_string(),\n            created_at: chrono::Utc::now(),\n        };\n        storage.store_draft(draft).await.unwrap();\n\n        tool.submit(\"draft-mark\", None, &[], \"user@test.com\")\n            .await\n            .unwrap();\n\n        let updated = storage.get_draft(\"draft-mark\").await.unwrap().unwrap();\n        assert_eq!(updated.status, KnowledgeDraftStatus::Submitted);\n    }\n\n    #[tokio::test]\n    async fn test_submit_fails_for_missing_draft() {\n        let storage = Arc::new(InMemoryKnowledgeProposalStorage::new());\n        let governance = Arc::new(SimpleGovernanceIntegration::new());\n        let tool = KnowledgeProposalSubmitTool::new(storage, governance);\n\n        let result = tool.submit(\"nonexistent\", None, &[], \"user@test.com\").await;\n\n        assert!(result.is_err());\n        assert!(result.unwrap_err().to_string().contains(\"not found\"));\n    }\n\n    #[tokio::test]\n    async fn test_submit_fails_for_already_submitted() {\n        let storage = Arc::new(InMemoryKnowledgeProposalStorage::new());\n        let governance = Arc::new(SimpleGovernanceIntegration::new());\n        let tool = KnowledgeProposalSubmitTool::new(storage.clone(), governance);\n\n        let draft = KnowledgeDraft {\n            draft_id: \"draft-already\".to_string(),\n            title: \"Test\".to_string(),\n            description: \"Test\".to_string(),\n            content: \"Content\".to_string(),\n            kind: mk_core::types::KnowledgeType::Adr,\n            layer: mk_core::types::KnowledgeLayer::Project,\n            status: KnowledgeDraftStatus::Submitted,\n            created_by: \"user\".to_string(),\n            created_at: chrono::Utc::now(),\n        };\n        storage.store_draft(draft).await.unwrap();\n\n        let result = tool\n            .submit(\"draft-already\", None, &[], \"user@test.com\")\n            .await;\n\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"already submitted\")\n        );\n    }\n\n    #[tokio::test]\n    async fn test_submit_tool_call() {\n        let storage = Arc::new(InMemoryKnowledgeProposalStorage::new());\n        let governance = Arc::new(SimpleGovernanceIntegration::new());\n        let tool = KnowledgeProposalSubmitTool::new(storage.clone(), governance);\n\n        let draft = KnowledgeDraft {\n            draft_id: \"draft-call\".to_string(),\n            title: \"API Standard\".to_string(),\n            description: \"GraphQL standard\".to_string(),\n            content: \"# API Standard\".to_string(),\n            kind: mk_core::types::KnowledgeType::Adr,\n            layer: mk_core::types::KnowledgeLayer::Project,\n            status: KnowledgeDraftStatus::Draft,\n            created_by: \"user\".to_string(),\n            created_at: chrono::Utc::now(),\n        };\n        storage.store_draft(draft).await.unwrap();\n\n        let params = json!({\n            \"draftId\": \"draft-call\",\n            \"justification\": \"Important for API consistency\",\n            \"proposedBy\": \"user@test.com\"\n        });\n\n        let result = tool.call(params).await.unwrap();\n\n        assert_eq!(result[\"success\"], true);\n        assert!(result[\"proposal\"][\"proposalId\"].is_string());\n        assert_eq!(result[\"proposal\"][\"title\"], \"API Standard\");\n    }\n\n    #[tokio::test]\n    async fn test_pending_list_tool_interface() {\n        let storage = Arc::new(InMemoryKnowledgeProposalStorage::new());\n        let tool = KnowledgePendingListTool::new(storage);\n\n        assert_eq!(tool.name(), \"aeterna_knowledge_pending\");\n        assert!(tool.description().contains(\"pending\"));\n    }\n\n    #[tokio::test]\n    async fn test_pending_list_returns_proposals() {\n        let storage = Arc::new(InMemoryKnowledgeProposalStorage::new());\n\n        let proposal = KnowledgeProposal {\n            proposal_id: \"prop-list\".to_string(),\n            draft_id: \"draft-list\".to_string(),\n            title: \"Pending ADR\".to_string(),\n            content: \"Content\".to_string(),\n            kind: mk_core::types::KnowledgeType::Adr,\n            layer: mk_core::types::KnowledgeLayer::Team,\n            proposed_by: \"user@test.com\".to_string(),\n            proposed_at: chrono::Utc::now(),\n            status: KnowledgeProposalStatus::Pending,\n            approvers: vec![],\n            metadata: std::collections::HashMap::new(),\n        };\n        storage.store_proposal(proposal).await.unwrap();\n\n        let tool = KnowledgePendingListTool::new(storage);\n\n        let params = json!({});\n        let result = tool.call(params).await.unwrap();\n\n        assert_eq!(result[\"success\"], true);\n        assert_eq!(result[\"count\"], 1);\n        assert_eq!(result[\"proposals\"][0][\"title\"], \"Pending ADR\");\n    }\n\n    #[tokio::test]\n    async fn test_pending_list_filters_by_layer() {\n        let storage = Arc::new(InMemoryKnowledgeProposalStorage::new());\n\n        let team_proposal = KnowledgeProposal {\n            proposal_id: \"prop-team\".to_string(),\n            draft_id: \"draft-team\".to_string(),\n            title: \"Team ADR\".to_string(),\n            content: \"Content\".to_string(),\n            kind: mk_core::types::KnowledgeType::Adr,\n            layer: mk_core::types::KnowledgeLayer::Team,\n            proposed_by: \"user\".to_string(),\n            proposed_at: chrono::Utc::now(),\n            status: KnowledgeProposalStatus::Pending,\n            approvers: vec![],\n            metadata: std::collections::HashMap::new(),\n        };\n\n        let project_proposal = KnowledgeProposal {\n            proposal_id: \"prop-project\".to_string(),\n            draft_id: \"draft-project\".to_string(),\n            title: \"Project ADR\".to_string(),\n            content: \"Content\".to_string(),\n            kind: mk_core::types::KnowledgeType::Adr,\n            layer: mk_core::types::KnowledgeLayer::Project,\n            proposed_by: \"user\".to_string(),\n            proposed_at: chrono::Utc::now(),\n            status: KnowledgeProposalStatus::Pending,\n            approvers: vec![],\n            metadata: std::collections::HashMap::new(),\n        };\n\n        storage.store_proposal(team_proposal).await.unwrap();\n        storage.store_proposal(project_proposal).await.unwrap();\n\n        let tool = KnowledgePendingListTool::new(storage);\n\n        let params = json!({ \"layer\": \"team\" });\n        let result = tool.call(params).await.unwrap();\n\n        assert_eq!(result[\"count\"], 1);\n        assert_eq!(result[\"proposals\"][0][\"title\"], \"Team ADR\");\n    }\n\n    #[tokio::test]\n    async fn test_simple_governance_integration() {\n        let governance = SimpleGovernanceIntegration::new();\n\n        let draft = KnowledgeDraft {\n            draft_id: \"draft-gov\".to_string(),\n            title: \"Test\".to_string(),\n            description: \"Test\".to_string(),\n            content: \"Content\".to_string(),\n            kind: mk_core::types::KnowledgeType::Adr,\n            layer: mk_core::types::KnowledgeLayer::Project,\n            status: KnowledgeDraftStatus::Draft,\n            created_by: \"user\".to_string(),\n            created_at: chrono::Utc::now(),\n        };\n\n        let proposal_id = governance\n            .submit_for_approval(\n                &draft,\n                Some(\"Test justification\"),\n                &[\"approver@test.com\".to_string()],\n            )\n            .await\n            .unwrap();\n\n        assert!(!proposal_id.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_governance_with_custom_config() {\n        let governance = SimpleGovernanceIntegration::with_config(3, false);\n\n        let draft = KnowledgeDraft {\n            draft_id: \"draft-config\".to_string(),\n            title: \"Test\".to_string(),\n            description: \"Test\".to_string(),\n            content: \"Content\".to_string(),\n            kind: mk_core::types::KnowledgeType::Adr,\n            layer: mk_core::types::KnowledgeLayer::Project,\n            status: KnowledgeDraftStatus::Draft,\n            created_by: \"user\".to_string(),\n            created_at: chrono::Utc::now(),\n        };\n\n        let proposal_id = governance\n            .submit_for_approval(&draft, None, &[])\n            .await\n            .unwrap();\n\n        assert!(!proposal_id.is_empty());\n    }\n}\n","traces":[{"line":17,"address":[],"length":0,"stats":{"Line":23}},{"line":53,"address":[],"length":0,"stats":{"Line":29}},{"line":54,"address":[],"length":0,"stats":{"Line":29}},{"line":57,"address":[],"length":0,"stats":{"Line":7}},{"line":58,"address":[],"length":0,"stats":{"Line":7}},{"line":61,"address":[],"length":0,"stats":{"Line":7}},{"line":62,"address":[],"length":0,"stats":{"Line":7}},{"line":63,"address":[],"length":0,"stats":{"Line":7}},{"line":64,"address":[],"length":0,"stats":{"Line":7}},{"line":65,"address":[],"length":0,"stats":{"Line":14}},{"line":66,"address":[],"length":0,"stats":{"Line":14}},{"line":67,"address":[],"length":0,"stats":{"Line":14}},{"line":69,"address":[],"length":0,"stats":{"Line":7}},{"line":73,"address":[],"length":0,"stats":{"Line":2}},{"line":97,"address":[],"length":0,"stats":{"Line":22}},{"line":106,"address":[],"length":0,"stats":{"Line":29}},{"line":107,"address":[],"length":0,"stats":{"Line":29}},{"line":110,"address":[],"length":0,"stats":{"Line":7}},{"line":111,"address":[],"length":0,"stats":{"Line":7}},{"line":114,"address":[],"length":0,"stats":{"Line":7}},{"line":115,"address":[],"length":0,"stats":{"Line":7}},{"line":116,"address":[],"length":0,"stats":{"Line":7}},{"line":117,"address":[],"length":0,"stats":{"Line":7}},{"line":118,"address":[],"length":0,"stats":{"Line":14}},{"line":119,"address":[],"length":0,"stats":{"Line":14}},{"line":120,"address":[],"length":0,"stats":{"Line":14}},{"line":122,"address":[],"length":0,"stats":{"Line":7}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":23}},{"line":164,"address":[],"length":0,"stats":{"Line":29}},{"line":165,"address":[],"length":0,"stats":{"Line":29}},{"line":168,"address":[],"length":0,"stats":{"Line":7}},{"line":169,"address":[],"length":0,"stats":{"Line":7}},{"line":172,"address":[],"length":0,"stats":{"Line":7}},{"line":173,"address":[],"length":0,"stats":{"Line":7}},{"line":174,"address":[],"length":0,"stats":{"Line":7}},{"line":175,"address":[],"length":0,"stats":{"Line":7}},{"line":176,"address":[],"length":0,"stats":{"Line":14}},{"line":177,"address":[],"length":0,"stats":{"Line":28}},{"line":178,"address":[],"length":0,"stats":{"Line":14}},{"line":179,"address":[],"length":0,"stats":{"Line":14}},{"line":181,"address":[],"length":0,"stats":{"Line":7}},{"line":185,"address":[],"length":0,"stats":{"Line":2}},{"line":375,"address":[],"length":0,"stats":{"Line":11}},{"line":376,"address":[],"length":0,"stats":{"Line":11}},{"line":381,"address":[],"length":0,"stats":{"Line":0}},{"line":382,"address":[],"length":0,"stats":{"Line":0}},{"line":387,"address":[],"length":0,"stats":{"Line":10}},{"line":392,"address":[],"length":0,"stats":{"Line":30}},{"line":394,"address":[],"length":0,"stats":{"Line":30}},{"line":395,"address":[],"length":0,"stats":{"Line":9}},{"line":396,"address":[],"length":0,"stats":{"Line":9}},{"line":397,"address":[],"length":0,"stats":{"Line":6}},{"line":398,"address":[],"length":0,"stats":{"Line":6}},{"line":399,"address":[],"length":0,"stats":{"Line":6}},{"line":401,"address":[],"length":0,"stats":{"Line":4}},{"line":402,"address":[],"length":0,"stats":{"Line":6}},{"line":403,"address":[],"length":0,"stats":{"Line":5}},{"line":404,"address":[],"length":0,"stats":{"Line":5}},{"line":405,"address":[],"length":0,"stats":{"Line":5}},{"line":407,"address":[],"length":0,"stats":{"Line":1}},{"line":408,"address":[],"length":0,"stats":{"Line":5}},{"line":409,"address":[],"length":0,"stats":{"Line":4}},{"line":410,"address":[],"length":0,"stats":{"Line":4}},{"line":411,"address":[],"length":0,"stats":{"Line":4}},{"line":412,"address":[],"length":0,"stats":{"Line":4}},{"line":414,"address":[],"length":0,"stats":{"Line":1}},{"line":415,"address":[],"length":0,"stats":{"Line":4}},{"line":416,"address":[],"length":0,"stats":{"Line":3}},{"line":417,"address":[],"length":0,"stats":{"Line":3}},{"line":419,"address":[],"length":0,"stats":{"Line":1}},{"line":421,"address":[],"length":0,"stats":{"Line":3}},{"line":424,"address":[],"length":0,"stats":{"Line":20}},{"line":425,"address":[],"length":0,"stats":{"Line":9}},{"line":426,"address":[],"length":0,"stats":{"Line":9}},{"line":428,"address":[],"length":0,"stats":{"Line":1}},{"line":429,"address":[],"length":0,"stats":{"Line":18}},{"line":430,"address":[],"length":0,"stats":{"Line":0}},{"line":431,"address":[],"length":0,"stats":{"Line":9}},{"line":432,"address":[],"length":0,"stats":{"Line":1}},{"line":434,"address":[],"length":0,"stats":{"Line":8}},{"line":437,"address":[],"length":0,"stats":{"Line":30}},{"line":438,"address":[],"length":0,"stats":{"Line":20}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":441,"address":[],"length":0,"stats":{"Line":20}},{"line":444,"address":[],"length":0,"stats":{"Line":20}},{"line":446,"address":[],"length":0,"stats":{"Line":14}},{"line":447,"address":[],"length":0,"stats":{"Line":14}},{"line":448,"address":[],"length":0,"stats":{"Line":14}},{"line":449,"address":[],"length":0,"stats":{"Line":14}},{"line":458,"address":[],"length":0,"stats":{"Line":2}},{"line":459,"address":[],"length":0,"stats":{"Line":1}},{"line":462,"address":[],"length":0,"stats":{"Line":4}},{"line":471,"address":[],"length":0,"stats":{"Line":10}},{"line":472,"address":[],"length":0,"stats":{"Line":20}},{"line":473,"address":[],"length":0,"stats":{"Line":20}},{"line":474,"address":[],"length":0,"stats":{"Line":20}},{"line":475,"address":[],"length":0,"stats":{"Line":20}},{"line":476,"address":[],"length":0,"stats":{"Line":10}},{"line":477,"address":[],"length":0,"stats":{"Line":10}},{"line":482,"address":[],"length":0,"stats":{"Line":12}},{"line":483,"address":[],"length":0,"stats":{"Line":48}},{"line":484,"address":[],"length":0,"stats":{"Line":36}},{"line":486,"address":[],"length":0,"stats":{"Line":12}},{"line":489,"address":[],"length":0,"stats":{"Line":12}},{"line":490,"address":[],"length":0,"stats":{"Line":3}},{"line":492,"address":[],"length":0,"stats":{"Line":22}},{"line":523,"address":[],"length":0,"stats":{"Line":7}},{"line":530,"address":[],"length":0,"stats":{"Line":6}},{"line":538,"address":[],"length":0,"stats":{"Line":24}},{"line":540,"address":[],"length":0,"stats":{"Line":13}},{"line":541,"address":[],"length":0,"stats":{"Line":2}},{"line":543,"address":[],"length":0,"stats":{"Line":5}},{"line":546,"address":[],"length":0,"stats":{"Line":13}},{"line":547,"address":[],"length":0,"stats":{"Line":2}},{"line":549,"address":[],"length":0,"stats":{"Line":5}},{"line":552,"address":[],"length":0,"stats":{"Line":32}},{"line":554,"address":[],"length":0,"stats":{"Line":30}},{"line":557,"address":[],"length":0,"stats":{"Line":18}},{"line":559,"address":[],"length":0,"stats":{"Line":18}},{"line":564,"address":[],"length":0,"stats":{"Line":12}},{"line":565,"address":[],"length":0,"stats":{"Line":6}},{"line":568,"address":[],"length":0,"stats":{"Line":18}},{"line":570,"address":[],"length":0,"stats":{"Line":6}},{"line":574,"address":[],"length":0,"stats":{"Line":2}},{"line":575,"address":[],"length":0,"stats":{"Line":2}},{"line":576,"address":[],"length":0,"stats":{"Line":2}},{"line":577,"address":[],"length":0,"stats":{"Line":2}},{"line":578,"address":[],"length":0,"stats":{"Line":3}},{"line":579,"address":[],"length":0,"stats":{"Line":1}},{"line":580,"address":[],"length":0,"stats":{"Line":1}},{"line":581,"address":[],"length":0,"stats":{"Line":1}},{"line":585,"address":[],"length":0,"stats":{"Line":3}},{"line":586,"address":[],"length":0,"stats":{"Line":3}},{"line":587,"address":[],"length":0,"stats":{"Line":3}},{"line":588,"address":[],"length":0,"stats":{"Line":3}},{"line":589,"address":[],"length":0,"stats":{"Line":5}},{"line":590,"address":[],"length":0,"stats":{"Line":1}},{"line":591,"address":[],"length":0,"stats":{"Line":1}},{"line":595,"address":[],"length":0,"stats":{"Line":8}},{"line":600,"address":[],"length":0,"stats":{"Line":8}},{"line":602,"address":[],"length":0,"stats":{"Line":5}},{"line":605,"address":[],"length":0,"stats":{"Line":20}},{"line":606,"address":[],"length":0,"stats":{"Line":20}},{"line":607,"address":[],"length":0,"stats":{"Line":5}},{"line":608,"address":[],"length":0,"stats":{"Line":5}},{"line":609,"address":[],"length":0,"stats":{"Line":5}},{"line":610,"address":[],"length":0,"stats":{"Line":10}},{"line":611,"address":[],"length":0,"stats":{"Line":5}},{"line":612,"address":[],"length":0,"stats":{"Line":5}},{"line":613,"address":[],"length":0,"stats":{"Line":5}},{"line":614,"address":[],"length":0,"stats":{"Line":10}},{"line":618,"address":[],"length":0,"stats":{"Line":2}},{"line":621,"address":[],"length":0,"stats":{"Line":2}},{"line":622,"address":[],"length":0,"stats":{"Line":2}},{"line":623,"address":[],"length":0,"stats":{"Line":2}},{"line":624,"address":[],"length":0,"stats":{"Line":4}},{"line":625,"address":[],"length":0,"stats":{"Line":2}},{"line":626,"address":[],"length":0,"stats":{"Line":2}},{"line":627,"address":[],"length":0,"stats":{"Line":2}},{"line":628,"address":[],"length":0,"stats":{"Line":4}},{"line":632,"address":[],"length":0,"stats":{"Line":0}},{"line":635,"address":[],"length":0,"stats":{"Line":0}},{"line":639,"address":[],"length":0,"stats":{"Line":1}},{"line":642,"address":[],"length":0,"stats":{"Line":4}},{"line":646,"address":[],"length":0,"stats":{"Line":0}},{"line":649,"address":[],"length":0,"stats":{"Line":0}},{"line":661,"address":[],"length":0,"stats":{"Line":1}},{"line":662,"address":[],"length":0,"stats":{"Line":1}},{"line":665,"address":[],"length":0,"stats":{"Line":1}},{"line":666,"address":[],"length":0,"stats":{"Line":1}},{"line":669,"address":[],"length":0,"stats":{"Line":1}},{"line":670,"address":[],"length":0,"stats":{"Line":1}},{"line":671,"address":[],"length":0,"stats":{"Line":1}},{"line":672,"address":[],"length":0,"stats":{"Line":1}},{"line":673,"address":[],"length":0,"stats":{"Line":1}},{"line":674,"address":[],"length":0,"stats":{"Line":1}},{"line":675,"address":[],"length":0,"stats":{"Line":1}},{"line":677,"address":[],"length":0,"stats":{"Line":1}},{"line":678,"address":[],"length":0,"stats":{"Line":1}},{"line":679,"address":[],"length":0,"stats":{"Line":1}},{"line":680,"address":[],"length":0,"stats":{"Line":1}},{"line":682,"address":[],"length":0,"stats":{"Line":1}},{"line":683,"address":[],"length":0,"stats":{"Line":1}},{"line":684,"address":[],"length":0,"stats":{"Line":1}},{"line":685,"address":[],"length":0,"stats":{"Line":1}},{"line":687,"address":[],"length":0,"stats":{"Line":1}},{"line":688,"address":[],"length":0,"stats":{"Line":1}},{"line":689,"address":[],"length":0,"stats":{"Line":1}},{"line":691,"address":[],"length":0,"stats":{"Line":1}},{"line":692,"address":[],"length":0,"stats":{"Line":1}},{"line":693,"address":[],"length":0,"stats":{"Line":1}},{"line":696,"address":[],"length":0,"stats":{"Line":1}},{"line":700,"address":[],"length":0,"stats":{"Line":1}},{"line":701,"address":[],"length":0,"stats":{"Line":0}},{"line":702,"address":[],"length":0,"stats":{"Line":0}},{"line":704,"address":[],"length":0,"stats":{"Line":0}},{"line":706,"address":[],"length":0,"stats":{"Line":0}},{"line":707,"address":[],"length":0,"stats":{"Line":0}},{"line":708,"address":[],"length":0,"stats":{"Line":0}},{"line":709,"address":[],"length":0,"stats":{"Line":0}},{"line":710,"address":[],"length":0,"stats":{"Line":0}},{"line":712,"address":[],"length":0,"stats":{"Line":0}},{"line":713,"address":[],"length":0,"stats":{"Line":0}},{"line":715,"address":[],"length":0,"stats":{"Line":0}},{"line":716,"address":[],"length":0,"stats":{"Line":0}},{"line":717,"address":[],"length":0,"stats":{"Line":0}},{"line":718,"address":[],"length":0,"stats":{"Line":0}},{"line":719,"address":[],"length":0,"stats":{"Line":0}},{"line":720,"address":[],"length":0,"stats":{"Line":0}},{"line":721,"address":[],"length":0,"stats":{"Line":0}},{"line":722,"address":[],"length":0,"stats":{"Line":0}},{"line":723,"address":[],"length":0,"stats":{"Line":0}},{"line":725,"address":[],"length":0,"stats":{"Line":0}},{"line":726,"address":[],"length":0,"stats":{"Line":0}},{"line":727,"address":[],"length":0,"stats":{"Line":0}},{"line":728,"address":[],"length":0,"stats":{"Line":0}},{"line":740,"address":[],"length":0,"stats":{"Line":18}},{"line":742,"address":[],"length":0,"stats":{"Line":54}},{"line":743,"address":[],"length":0,"stats":{"Line":18}},{"line":749,"address":[],"length":0,"stats":{"Line":0}},{"line":750,"address":[],"length":0,"stats":{"Line":0}},{"line":755,"address":[],"length":0,"stats":{"Line":22}},{"line":756,"address":[],"length":0,"stats":{"Line":33}},{"line":757,"address":[],"length":0,"stats":{"Line":44}},{"line":758,"address":[],"length":0,"stats":{"Line":11}},{"line":761,"address":[],"length":0,"stats":{"Line":9}},{"line":765,"address":[],"length":0,"stats":{"Line":27}},{"line":766,"address":[],"length":0,"stats":{"Line":18}},{"line":769,"address":[],"length":0,"stats":{"Line":8}},{"line":770,"address":[],"length":0,"stats":{"Line":12}},{"line":771,"address":[],"length":0,"stats":{"Line":16}},{"line":772,"address":[],"length":0,"stats":{"Line":4}},{"line":775,"address":[],"length":0,"stats":{"Line":14}},{"line":776,"address":[],"length":0,"stats":{"Line":21}},{"line":777,"address":[],"length":0,"stats":{"Line":28}},{"line":778,"address":[],"length":0,"stats":{"Line":7}},{"line":781,"address":[],"length":0,"stats":{"Line":0}},{"line":785,"address":[],"length":0,"stats":{"Line":0}},{"line":786,"address":[],"length":0,"stats":{"Line":0}},{"line":789,"address":[],"length":0,"stats":{"Line":5}},{"line":793,"address":[],"length":0,"stats":{"Line":15}},{"line":794,"address":[],"length":0,"stats":{"Line":15}},{"line":796,"address":[],"length":0,"stats":{"Line":11}},{"line":797,"address":[],"length":0,"stats":{"Line":26}},{"line":801,"address":[],"length":0,"stats":{"Line":5}},{"line":825,"address":[],"length":0,"stats":{"Line":7}},{"line":832,"address":[],"length":0,"stats":{"Line":1}},{"line":841,"address":[],"length":0,"stats":{"Line":0}},{"line":842,"address":[],"length":0,"stats":{"Line":0}},{"line":847,"address":[],"length":0,"stats":{"Line":5}},{"line":853,"address":[],"length":0,"stats":{"Line":15}},{"line":855,"address":[],"length":0,"stats":{"Line":9}},{"line":857,"address":[],"length":0,"stats":{"Line":3}},{"line":860,"address":[],"length":0,"stats":{"Line":2}},{"line":863,"address":[],"length":0,"stats":{"Line":3}},{"line":867,"address":[],"length":0,"stats":{"Line":3}},{"line":898,"address":[],"length":0,"stats":{"Line":6}},{"line":905,"address":[],"length":0,"stats":{"Line":5}},{"line":912,"address":[],"length":0,"stats":{"Line":14}},{"line":913,"address":[],"length":0,"stats":{"Line":10}},{"line":914,"address":[],"length":0,"stats":{"Line":5}},{"line":915,"address":[],"length":0,"stats":{"Line":5}},{"line":916,"address":[],"length":0,"stats":{"Line":8}},{"line":918,"address":[],"length":0,"stats":{"Line":4}},{"line":919,"address":[],"length":0,"stats":{"Line":1}},{"line":920,"address":[],"length":0,"stats":{"Line":1}},{"line":924,"address":[],"length":0,"stats":{"Line":9}},{"line":925,"address":[],"length":0,"stats":{"Line":6}},{"line":926,"address":[],"length":0,"stats":{"Line":9}},{"line":927,"address":[],"length":0,"stats":{"Line":3}},{"line":929,"address":[],"length":0,"stats":{"Line":9}},{"line":932,"address":[],"length":0,"stats":{"Line":9}},{"line":933,"address":[],"length":0,"stats":{"Line":9}},{"line":934,"address":[],"length":0,"stats":{"Line":9}},{"line":935,"address":[],"length":0,"stats":{"Line":9}},{"line":936,"address":[],"length":0,"stats":{"Line":6}},{"line":937,"address":[],"length":0,"stats":{"Line":6}},{"line":938,"address":[],"length":0,"stats":{"Line":9}},{"line":939,"address":[],"length":0,"stats":{"Line":6}},{"line":941,"address":[],"length":0,"stats":{"Line":6}},{"line":942,"address":[],"length":0,"stats":{"Line":3}},{"line":945,"address":[],"length":0,"stats":{"Line":9}},{"line":947,"address":[],"length":0,"stats":{"Line":6}},{"line":948,"address":[],"length":0,"stats":{"Line":3}},{"line":949,"address":[],"length":0,"stats":{"Line":6}},{"line":951,"address":[],"length":0,"stats":{"Line":3}},{"line":961,"address":[],"length":0,"stats":{"Line":1}},{"line":962,"address":[],"length":0,"stats":{"Line":1}},{"line":965,"address":[],"length":0,"stats":{"Line":1}},{"line":966,"address":[],"length":0,"stats":{"Line":1}},{"line":969,"address":[],"length":0,"stats":{"Line":1}},{"line":970,"address":[],"length":0,"stats":{"Line":1}},{"line":971,"address":[],"length":0,"stats":{"Line":1}},{"line":972,"address":[],"length":0,"stats":{"Line":1}},{"line":973,"address":[],"length":0,"stats":{"Line":1}},{"line":974,"address":[],"length":0,"stats":{"Line":1}},{"line":975,"address":[],"length":0,"stats":{"Line":1}},{"line":977,"address":[],"length":0,"stats":{"Line":1}},{"line":978,"address":[],"length":0,"stats":{"Line":1}},{"line":979,"address":[],"length":0,"stats":{"Line":1}},{"line":981,"address":[],"length":0,"stats":{"Line":1}},{"line":982,"address":[],"length":0,"stats":{"Line":1}},{"line":983,"address":[],"length":0,"stats":{"Line":2}},{"line":984,"address":[],"length":0,"stats":{"Line":1}},{"line":986,"address":[],"length":0,"stats":{"Line":1}},{"line":987,"address":[],"length":0,"stats":{"Line":1}},{"line":988,"address":[],"length":0,"stats":{"Line":1}},{"line":991,"address":[],"length":0,"stats":{"Line":1}},{"line":995,"address":[],"length":0,"stats":{"Line":1}},{"line":996,"address":[],"length":0,"stats":{"Line":0}},{"line":997,"address":[],"length":0,"stats":{"Line":0}},{"line":999,"address":[],"length":0,"stats":{"Line":0}},{"line":1001,"address":[],"length":0,"stats":{"Line":0}},{"line":1002,"address":[],"length":0,"stats":{"Line":0}},{"line":1003,"address":[],"length":0,"stats":{"Line":0}},{"line":1004,"address":[],"length":0,"stats":{"Line":0}},{"line":1006,"address":[],"length":0,"stats":{"Line":0}},{"line":1007,"address":[],"length":0,"stats":{"Line":0}},{"line":1009,"address":[],"length":0,"stats":{"Line":0}},{"line":1010,"address":[],"length":0,"stats":{"Line":0}},{"line":1011,"address":[],"length":0,"stats":{"Line":0}},{"line":1012,"address":[],"length":0,"stats":{"Line":0}},{"line":1013,"address":[],"length":0,"stats":{"Line":0}},{"line":1016,"address":[],"length":0,"stats":{"Line":0}},{"line":1017,"address":[],"length":0,"stats":{"Line":0}},{"line":1018,"address":[],"length":0,"stats":{"Line":0}},{"line":1019,"address":[],"length":0,"stats":{"Line":0}},{"line":1020,"address":[],"length":0,"stats":{"Line":0}},{"line":1021,"address":[],"length":0,"stats":{"Line":0}},{"line":1022,"address":[],"length":0,"stats":{"Line":0}},{"line":1023,"address":[],"length":0,"stats":{"Line":0}},{"line":1024,"address":[],"length":0,"stats":{"Line":0}},{"line":1025,"address":[],"length":0,"stats":{"Line":0}},{"line":1026,"address":[],"length":0,"stats":{"Line":0}},{"line":1028,"address":[],"length":0,"stats":{"Line":0}},{"line":1029,"address":[],"length":0,"stats":{"Line":0}},{"line":1030,"address":[],"length":0,"stats":{"Line":0}},{"line":1031,"address":[],"length":0,"stats":{"Line":0}},{"line":1045,"address":[],"length":0,"stats":{"Line":3}},{"line":1059,"address":[],"length":0,"stats":{"Line":1}},{"line":1060,"address":[],"length":0,"stats":{"Line":1}},{"line":1063,"address":[],"length":0,"stats":{"Line":1}},{"line":1064,"address":[],"length":0,"stats":{"Line":1}},{"line":1067,"address":[],"length":0,"stats":{"Line":0}},{"line":1068,"address":[],"length":0,"stats":{"Line":0}},{"line":1069,"address":[],"length":0,"stats":{"Line":0}},{"line":1070,"address":[],"length":0,"stats":{"Line":0}},{"line":1071,"address":[],"length":0,"stats":{"Line":0}},{"line":1072,"address":[],"length":0,"stats":{"Line":0}},{"line":1073,"address":[],"length":0,"stats":{"Line":0}},{"line":1074,"address":[],"length":0,"stats":{"Line":0}},{"line":1080,"address":[],"length":0,"stats":{"Line":2}},{"line":1081,"address":[],"length":0,"stats":{"Line":0}},{"line":1082,"address":[],"length":0,"stats":{"Line":0}},{"line":1084,"address":[],"length":0,"stats":{"Line":0}},{"line":1085,"address":[],"length":0,"stats":{"Line":0}},{"line":1087,"address":[],"length":0,"stats":{"Line":0}},{"line":1090,"address":[],"length":0,"stats":{"Line":0}},{"line":1091,"address":[],"length":0,"stats":{"Line":0}},{"line":1092,"address":[],"length":0,"stats":{"Line":0}},{"line":1093,"address":[],"length":0,"stats":{"Line":0}},{"line":1094,"address":[],"length":0,"stats":{"Line":0}},{"line":1096,"address":[],"length":0,"stats":{"Line":0}},{"line":1098,"address":[],"length":0,"stats":{"Line":2}},{"line":1099,"address":[],"length":0,"stats":{"Line":2}},{"line":1100,"address":[],"length":0,"stats":{"Line":2}},{"line":1101,"address":[],"length":0,"stats":{"Line":2}},{"line":1102,"address":[],"length":0,"stats":{"Line":6}},{"line":1103,"address":[],"length":0,"stats":{"Line":6}},{"line":1104,"address":[],"length":0,"stats":{"Line":2}},{"line":1105,"address":[],"length":0,"stats":{"Line":6}},{"line":1110,"address":[],"length":0,"stats":{"Line":0}},{"line":1111,"address":[],"length":0,"stats":{"Line":0}},{"line":1112,"address":[],"length":0,"stats":{"Line":0}},{"line":1113,"address":[],"length":0,"stats":{"Line":0}}],"covered":285,"coverable":376},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","lib.rs"],"content":"//! # MCP Tools Interface\n//!\n//! 8 MCP tools for memory-knowledge system.\n\npub mod bridge;\npub mod cca;\npub mod extensions;\npub mod governance;\npub mod knowledge;\npub mod memory;\npub mod orchestrator;\npub mod policy_tools;\npub mod policy_translator;\npub mod redis_publisher;\npub mod server;\npub mod tools;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","loader.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","memory.rs"],"content":"use crate::tools::Tool;\nuse async_trait::async_trait;\nuse memory::manager::MemoryManager;\nuse mk_core::types::TenantContext;\nuse schemars::JsonSchema;\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Value, json};\nuse std::sync::Arc;\nuse storage::graph::GraphStore;\nuse storage::graph_duckdb::DuckDbGraphStore;\nuse validator::Validate;\n\npub struct MemoryAddTool {\n    memory_manager: Arc<MemoryManager>,\n}\n\nimpl MemoryAddTool {\n    pub fn new(memory_manager: Arc<MemoryManager>) -> Self {\n        Self { memory_manager }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct MemoryAddParams {\n    pub content: String,\n    pub layer: String,\n    #[serde(default)]\n    pub metadata: serde_json::Map<String, Value>,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct MemorySearchParams {\n    pub query: String,\n    pub limit: Option<usize>,\n    pub threshold: Option<f32>,\n    #[serde(default)]\n    pub filters: serde_json::Map<String, Value>,\n    #[serde(rename = \"contextSummary\")]\n    pub context_summary: Option<String>,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct MemoryDeleteParams {\n    #[serde(rename = \"memoryId\")]\n    pub memory_id: String,\n    pub layer: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Debug)]\n#[serde(rename_all = \"camelCase\")]\npub enum CloseTarget {\n    Session,\n    Agent,\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct MemoryCloseParams {\n    pub id: String,\n    pub target: CloseTarget,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[async_trait]\nimpl Tool for MemoryAddTool {\n    fn name(&self) -> &str {\n        \"memory_add\"\n    }\n\n    fn description(&self) -> &str {\n        \"Store a piece of information in memory for future reference.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"content\": { \"type\": \"string\" },\n                \"layer\": { \"type\": \"string\" },\n                \"metadata\": { \"type\": \"object\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"content\", \"layer\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: MemoryAddParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let layer = match p.layer.to_lowercase().as_str() {\n            \"agent\" => mk_core::types::MemoryLayer::Agent,\n            \"user\" => mk_core::types::MemoryLayer::User,\n            \"session\" => mk_core::types::MemoryLayer::Session,\n            \"project\" => mk_core::types::MemoryLayer::Project,\n            \"team\" => mk_core::types::MemoryLayer::Team,\n            \"org\" => mk_core::types::MemoryLayer::Org,\n            \"company\" => mk_core::types::MemoryLayer::Company,\n            _ => return Err(format!(\"Unknown layer: {}\", p.layer).into()),\n        };\n        let entry = mk_core::types::MemoryEntry {\n            id: uuid::Uuid::new_v4().to_string(),\n            content: p.content,\n            embedding: None,\n            layer,\n            summaries: std::collections::HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n            metadata: p.metadata.into_iter().collect(),\n            created_at: chrono::Utc::now().timestamp(),\n            updated_at: chrono::Utc::now().timestamp(),\n        };\n\n        let id = self.memory_manager.add_to_layer(ctx, layer, entry).await?;\n        Ok(json!({ \"success\": true, \"memoryId\": id }))\n    }\n}\n\npub struct MemorySearchTool {\n    memory_manager: Arc<MemoryManager>,\n}\n\nimpl MemorySearchTool {\n    pub fn new(memory_manager: Arc<MemoryManager>) -> Self {\n        Self { memory_manager }\n    }\n}\n\n#[async_trait]\nimpl Tool for MemorySearchTool {\n    fn name(&self) -> &str {\n        \"memory_search\"\n    }\n\n    fn description(&self) -> &str {\n        \"Search for memories across layers with optional reflective reasoning.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": { \"type\": \"string\" },\n                \"limit\": { \"type\": \"integer\" },\n                \"threshold\": { \"type\": \"number\" },\n                \"filters\": { \"type\": \"object\" },\n                \"contextSummary\": { \"type\": \"string\", \"description\": \"Optional context for reasoning\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"query\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: MemorySearchParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let limit = p.limit.unwrap_or(10);\n        let threshold = p.threshold.unwrap_or(0.0);\n        let filters: std::collections::HashMap<String, Value> = p.filters.into_iter().collect();\n\n        let (results, reasoning_trace) = self\n            .memory_manager\n            .search_text_with_reasoning(\n                ctx,\n                &p.query,\n                limit,\n                threshold,\n                filters,\n                p.context_summary.as_deref(),\n            )\n            .await?;\n\n        let mut response = json!({\n            \"success\": true,\n            \"results\": results,\n            \"totalCount\": results.len()\n        });\n\n        if let Some(trace) = reasoning_trace {\n            response[\"reasoning\"] = json!({\n                \"strategy\": trace.strategy,\n                \"refinedQuery\": trace.refined_query,\n                \"thoughtProcess\": trace.thought_process,\n                \"durationMs\": (trace.end_time - trace.start_time).num_milliseconds()\n            });\n        }\n\n        Ok(response)\n    }\n}\n\npub struct MemoryDeleteTool {\n    memory_manager: Arc<MemoryManager>,\n}\n\nimpl MemoryDeleteTool {\n    pub fn new(memory_manager: Arc<MemoryManager>) -> Self {\n        Self { memory_manager }\n    }\n}\n\n#[async_trait]\nimpl Tool for MemoryDeleteTool {\n    fn name(&self) -> &str {\n        \"memory_delete\"\n    }\n\n    fn description(&self) -> &str {\n        \"Delete a memory from a specific layer.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"memoryId\": { \"type\": \"string\" },\n                \"layer\": { \"type\": \"string\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"memoryId\", \"layer\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: MemoryDeleteParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let layer = match p.layer.to_lowercase().as_str() {\n            \"agent\" => mk_core::types::MemoryLayer::Agent,\n            \"user\" => mk_core::types::MemoryLayer::User,\n            \"session\" => mk_core::types::MemoryLayer::Session,\n            \"project\" => mk_core::types::MemoryLayer::Project,\n            \"team\" => mk_core::types::MemoryLayer::Team,\n            \"org\" => mk_core::types::MemoryLayer::Org,\n            \"company\" => mk_core::types::MemoryLayer::Company,\n            _ => return Err(format!(\"Unknown layer: {}\", p.layer).into()),\n        };\n\n        self.memory_manager\n            .delete_from_layer(ctx, layer, &p.memory_id)\n            .await?;\n\n        Ok(json!({\n            \"success\": true,\n            \"message\": \"Memory deleted successfully\"\n        }))\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct MemoryReasonParams {\n    pub query: String,\n    #[serde(rename = \"contextSummary\")]\n    pub context_summary: Option<String>,\n}\n\npub struct MemoryReasonTool {\n    reasoner: Arc<dyn memory::reasoning::ReflectiveReasoner>,\n}\n\nimpl MemoryReasonTool {\n    pub fn new(reasoner: Arc<dyn memory::reasoning::ReflectiveReasoner>) -> Self {\n        Self { reasoner }\n    }\n}\n\n#[async_trait]\nimpl Tool for MemoryReasonTool {\n    fn name(&self) -> &str {\n        \"memory_reason\"\n    }\n\n    fn description(&self) -> &str {\n        \"Perform reflective reasoning on a query to determine the best retrieval strategy.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": { \"type\": \"string\" },\n                \"contextSummary\": { \"type\": \"string\" }\n            },\n            \"required\": [\"query\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: MemoryReasonParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let trace = self\n            .reasoner\n            .reason(&p.query, p.context_summary.as_deref())\n            .await?;\n\n        Ok(serde_json::to_value(trace)?)\n    }\n}\n\npub struct MemoryCloseTool {\n    memory_manager: Arc<MemoryManager>,\n}\n\nimpl MemoryCloseTool {\n    pub fn new(memory_manager: Arc<MemoryManager>) -> Self {\n        Self { memory_manager }\n    }\n}\n\n#[async_trait]\nimpl Tool for MemoryCloseTool {\n    fn name(&self) -> &str {\n        \"memory_close\"\n    }\n\n    fn description(&self) -> &str {\n        \"Close a session or agent memory context.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"id\": { \"type\": \"string\" },\n                \"target\": { \"type\": \"string\", \"enum\": [\"session\", \"agent\"] },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"id\", \"target\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: MemoryCloseParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        match p.target {\n            CloseTarget::Session => self.memory_manager.close_session(ctx, &p.id).await?,\n            CloseTarget::Agent => self.memory_manager.close_agent(ctx, &p.id).await?,\n        }\n\n        Ok(json!({\n            \"success\": true,\n            \"message\": format!(\"{:?} context closed successfully\", p.target)\n        }))\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct MemoryFeedbackParams {\n    #[serde(rename = \"memoryId\")]\n    pub memory_id: String,\n    pub layer: String,\n    #[serde(rename = \"rewardType\")]\n    pub reward_type: String,\n    pub score: f32,\n    pub reasoning: Option<String>,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\npub struct MemoryFeedbackTool {\n    memory_manager: Arc<MemoryManager>,\n}\n\nimpl MemoryFeedbackTool {\n    pub fn new(memory_manager: Arc<MemoryManager>) -> Self {\n        Self { memory_manager }\n    }\n}\n\n#[async_trait]\nimpl Tool for MemoryFeedbackTool {\n    fn name(&self) -> &str {\n        \"memory_feedback\"\n    }\n\n    fn description(&self) -> &str {\n        \"Submit a reward signal for a retrieved memory.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"memoryId\": { \"type\": \"string\" },\n                \"layer\": { \"type\": \"string\" },\n                \"rewardType\": { \"type\": \"string\", \"enum\": [\"helpful\", \"irrelevant\", \"outdated\", \"inaccurate\", \"duplicate\"] },\n                \"score\": { \"type\": \"number\", \"minimum\": -1.0, \"maximum\": 1.0 },\n                \"reasoning\": { \"type\": \"string\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"memoryId\", \"layer\", \"rewardType\", \"score\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: MemoryFeedbackParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let layer = match p.layer.to_lowercase().as_str() {\n            \"agent\" => mk_core::types::MemoryLayer::Agent,\n            \"user\" => mk_core::types::MemoryLayer::User,\n            \"session\" => mk_core::types::MemoryLayer::Session,\n            \"project\" => mk_core::types::MemoryLayer::Project,\n            \"team\" => mk_core::types::MemoryLayer::Team,\n            \"org\" => mk_core::types::MemoryLayer::Org,\n            \"company\" => mk_core::types::MemoryLayer::Company,\n            _ => return Err(format!(\"Unknown layer: {}\", p.layer).into()),\n        };\n\n        let reward_type = match p.reward_type.to_lowercase().as_str() {\n            \"helpful\" => mk_core::types::RewardType::Helpful,\n            \"irrelevant\" => mk_core::types::RewardType::Irrelevant,\n            \"outdated\" => mk_core::types::RewardType::Outdated,\n            \"inaccurate\" => mk_core::types::RewardType::Inaccurate,\n            \"duplicate\" => mk_core::types::RewardType::Duplicate,\n            _ => return Err(format!(\"Unknown reward type: {}\", p.reward_type).into()),\n        };\n\n        let reward = mk_core::types::RewardSignal {\n            reward_type,\n            score: p.score,\n            reasoning: p.reasoning,\n            agent_id: ctx.agent_id.clone(),\n            timestamp: chrono::Utc::now().timestamp(),\n        };\n\n        self.memory_manager\n            .record_reward(ctx, layer, &p.memory_id, reward)\n            .await?;\n\n        Ok(json!({ \"success\": true, \"message\": \"Reward recorded successfully\" }))\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct MemoryOptimizeParams {\n    pub layer: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\npub struct MemoryOptimizeTool {\n    memory_manager: Arc<MemoryManager>,\n}\n\nimpl MemoryOptimizeTool {\n    pub fn new(memory_manager: Arc<MemoryManager>) -> Self {\n        Self { memory_manager }\n    }\n}\n\n#[async_trait]\nimpl Tool for MemoryOptimizeTool {\n    fn name(&self) -> &str {\n        \"memory_optimize\"\n    }\n\n    fn description(&self) -> &str {\n        \"Manually trigger a pruning/compression cycle for a specific memory layer.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"layer\": { \"type\": \"string\", \"enum\": [\"agent\", \"user\", \"session\", \"project\", \"team\", \"org\", \"company\"] },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"layer\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: MemoryOptimizeParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let layer = match p.layer.to_lowercase().as_str() {\n            \"agent\" => mk_core::types::MemoryLayer::Agent,\n            \"user\" => mk_core::types::MemoryLayer::User,\n            \"session\" => mk_core::types::MemoryLayer::Session,\n            \"project\" => mk_core::types::MemoryLayer::Project,\n            \"team\" => mk_core::types::MemoryLayer::Team,\n            \"org\" => mk_core::types::MemoryLayer::Org,\n            \"company\" => mk_core::types::MemoryLayer::Company,\n            _ => return Err(format!(\"Unknown layer: {}\", p.layer).into()),\n        };\n\n        self.memory_manager.optimize_layer(ctx, layer).await?;\n\n        Ok(json!({ \"success\": true, \"message\": \"Memory optimization complete\" }))\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct MemoryPromoteParams {\n    #[serde(rename = \"memoryId\")]\n    pub memory_id: String,\n    #[serde(rename = \"toLayer\")]\n    pub to_layer: String,\n    pub reason: Option<String>,\n    #[serde(default)]\n    pub notify: Vec<String>,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct PromotionResult {\n    pub original_id: String,\n    pub promoted_id: Option<String>,\n    pub status: PromotionStatus,\n    pub from_layer: String,\n    pub to_layer: String,\n    pub approval_required: bool,\n    pub approvers_notified: Vec<String>,\n    pub reason: Option<String>,\n    pub proposal_id: Option<String>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum PromotionStatus {\n    Promoted,\n    PendingApproval,\n    Blocked,\n    Failed,\n}\n\npub trait PromotionGovernance: Send + Sync {\n    fn requires_approval(\n        &self,\n        from_layer: mk_core::types::MemoryLayer,\n        to_layer: mk_core::types::MemoryLayer,\n    ) -> impl std::future::Future<Output = bool> + Send;\n\n    fn get_approvers(\n        &self,\n        to_layer: mk_core::types::MemoryLayer,\n        ctx: &TenantContext,\n    ) -> impl std::future::Future<\n        Output = Result<Vec<String>, Box<dyn std::error::Error + Send + Sync>>,\n    > + Send;\n\n    fn create_promotion_request(\n        &self,\n        memory_id: &str,\n        from_layer: mk_core::types::MemoryLayer,\n        to_layer: mk_core::types::MemoryLayer,\n        reason: Option<String>,\n        requestor: &str,\n        approvers: Vec<String>,\n    ) -> impl std::future::Future<Output = Result<String, Box<dyn std::error::Error + Send + Sync>>> + Send;\n}\n\npub struct DefaultPromotionGovernance;\n\nimpl DefaultPromotionGovernance {\n    pub fn new() -> Self {\n        Self\n    }\n}\n\nimpl Default for DefaultPromotionGovernance {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\nimpl PromotionGovernance for DefaultPromotionGovernance {\n    async fn requires_approval(\n        &self,\n        from_layer: mk_core::types::MemoryLayer,\n        to_layer: mk_core::types::MemoryLayer,\n    ) -> bool {\n        use mk_core::types::MemoryLayer;\n        // GOVERNANCE RULE: Cross-scope promotions (projectteam, teamorg, orgcompany)\n        // require approval; same-scope promotions (sessionproject, agentuser) auto-approve\n        matches!(\n            (from_layer, to_layer),\n            (MemoryLayer::Project, MemoryLayer::Team)\n                | (MemoryLayer::Team, MemoryLayer::Org)\n                | (MemoryLayer::Org, MemoryLayer::Company)\n                | (MemoryLayer::User, MemoryLayer::Team)\n        )\n    }\n\n    async fn get_approvers(\n        &self,\n        to_layer: mk_core::types::MemoryLayer,\n        ctx: &TenantContext,\n    ) -> Result<Vec<String>, Box<dyn std::error::Error + Send + Sync>> {\n        use mk_core::types::MemoryLayer;\n        let tenant = ctx.tenant_id.as_str();\n        let approvers = match to_layer {\n            MemoryLayer::Team => {\n                vec![format!(\"tech-lead@{}.team\", tenant)]\n            }\n            MemoryLayer::Org => {\n                vec![format!(\"architect@{}.org\", tenant)]\n            }\n            MemoryLayer::Company => {\n                vec![format!(\"admin@{}.company\", tenant)]\n            }\n            _ => vec![],\n        };\n        Ok(approvers)\n    }\n\n    async fn create_promotion_request(\n        &self,\n        memory_id: &str,\n        _from_layer: mk_core::types::MemoryLayer,\n        _to_layer: mk_core::types::MemoryLayer,\n        _reason: Option<String>,\n        _requestor: &str,\n        _approvers: Vec<String>,\n    ) -> Result<String, Box<dyn std::error::Error + Send + Sync>> {\n        Ok(format!(\"promo-req-{}-{}\", memory_id, uuid::Uuid::new_v4()))\n    }\n}\n\npub struct MemoryPromoteTool<G: PromotionGovernance> {\n    memory_manager: Arc<MemoryManager>,\n    governance: Arc<G>,\n}\n\nimpl<G: PromotionGovernance> MemoryPromoteTool<G> {\n    pub fn new(memory_manager: Arc<MemoryManager>, governance: Arc<G>) -> Self {\n        Self {\n            memory_manager,\n            governance,\n        }\n    }\n\n    fn parse_layer(layer: &str) -> Result<mk_core::types::MemoryLayer, String> {\n        match layer.to_lowercase().as_str() {\n            \"agent\" => Ok(mk_core::types::MemoryLayer::Agent),\n            \"user\" => Ok(mk_core::types::MemoryLayer::User),\n            \"session\" => Ok(mk_core::types::MemoryLayer::Session),\n            \"project\" => Ok(mk_core::types::MemoryLayer::Project),\n            \"team\" => Ok(mk_core::types::MemoryLayer::Team),\n            \"org\" => Ok(mk_core::types::MemoryLayer::Org),\n            \"company\" => Ok(mk_core::types::MemoryLayer::Company),\n            _ => Err(format!(\"Unknown layer: {}\", layer)),\n        }\n    }\n\n    fn layer_to_string(layer: mk_core::types::MemoryLayer) -> String {\n        match layer {\n            mk_core::types::MemoryLayer::Agent => \"agent\".to_string(),\n            mk_core::types::MemoryLayer::User => \"user\".to_string(),\n            mk_core::types::MemoryLayer::Session => \"session\".to_string(),\n            mk_core::types::MemoryLayer::Project => \"project\".to_string(),\n            mk_core::types::MemoryLayer::Team => \"team\".to_string(),\n            mk_core::types::MemoryLayer::Org => \"org\".to_string(),\n            mk_core::types::MemoryLayer::Company => \"company\".to_string(),\n        }\n    }\n\n    fn get_layer_hierarchy_level(layer: mk_core::types::MemoryLayer) -> u8 {\n        match layer {\n            mk_core::types::MemoryLayer::Agent => 0,\n            mk_core::types::MemoryLayer::Session => 1,\n            mk_core::types::MemoryLayer::User => 2,\n            mk_core::types::MemoryLayer::Project => 3,\n            mk_core::types::MemoryLayer::Team => 4,\n            mk_core::types::MemoryLayer::Org => 5,\n            mk_core::types::MemoryLayer::Company => 6,\n        }\n    }\n\n    async fn promote(\n        &self,\n        ctx: TenantContext,\n        memory_id: &str,\n        to_layer: mk_core::types::MemoryLayer,\n        reason: Option<String>,\n        notify: Vec<String>,\n    ) -> Result<PromotionResult, Box<dyn std::error::Error + Send + Sync>> {\n        // Find the memory in any layer\n        let (entry, from_layer) = self.find_memory(&ctx, memory_id).await?;\n\n        // Validate promotion direction (can only promote UP the hierarchy)\n        let from_level = Self::get_layer_hierarchy_level(from_layer);\n        let to_level = Self::get_layer_hierarchy_level(to_layer);\n\n        if to_level <= from_level {\n            return Ok(PromotionResult {\n                original_id: memory_id.to_string(),\n                promoted_id: None,\n                status: PromotionStatus::Blocked,\n                from_layer: Self::layer_to_string(from_layer),\n                to_layer: Self::layer_to_string(to_layer),\n                approval_required: false,\n                approvers_notified: vec![],\n                reason: Some(format!(\n                    \"Cannot promote from {} to {} - can only promote to broader scopes\",\n                    Self::layer_to_string(from_layer),\n                    Self::layer_to_string(to_layer)\n                )),\n                proposal_id: None,\n            });\n        }\n\n        // Check if approval is required\n        let requires_approval = self\n            .governance\n            .requires_approval(from_layer, to_layer)\n            .await;\n\n        if requires_approval {\n            // Get approvers\n            let mut approvers = self.governance.get_approvers(to_layer, &ctx).await?;\n\n            // Add explicit notify list\n            for n in notify {\n                if !approvers.contains(&n) {\n                    approvers.push(n);\n                }\n            }\n\n            let requestor = ctx.user_id.as_str();\n            let proposal_id = self\n                .governance\n                .create_promotion_request(\n                    memory_id,\n                    from_layer,\n                    to_layer,\n                    reason.clone(),\n                    requestor,\n                    approvers.clone(),\n                )\n                .await?;\n\n            return Ok(PromotionResult {\n                original_id: memory_id.to_string(),\n                promoted_id: None,\n                status: PromotionStatus::PendingApproval,\n                from_layer: Self::layer_to_string(from_layer),\n                to_layer: Self::layer_to_string(to_layer),\n                approval_required: true,\n                approvers_notified: approvers,\n                reason,\n                proposal_id: Some(proposal_id),\n            });\n        }\n\n        // Auto-approve: perform the promotion\n        let promoted_id = self\n            .perform_promotion(&ctx, &entry, from_layer, to_layer, reason.clone())\n            .await?;\n\n        Ok(PromotionResult {\n            original_id: memory_id.to_string(),\n            promoted_id: Some(promoted_id),\n            status: PromotionStatus::Promoted,\n            from_layer: Self::layer_to_string(from_layer),\n            to_layer: Self::layer_to_string(to_layer),\n            approval_required: false,\n            approvers_notified: vec![],\n            reason,\n            proposal_id: None,\n        })\n    }\n\n    async fn find_memory(\n        &self,\n        ctx: &TenantContext,\n        memory_id: &str,\n    ) -> Result<\n        (mk_core::types::MemoryEntry, mk_core::types::MemoryLayer),\n        Box<dyn std::error::Error + Send + Sync>,\n    > {\n        use mk_core::types::MemoryLayer;\n\n        // Search layers from most specific to least specific\n        let layers = [\n            MemoryLayer::Agent,\n            MemoryLayer::Session,\n            MemoryLayer::User,\n            MemoryLayer::Project,\n            MemoryLayer::Team,\n            MemoryLayer::Org,\n            MemoryLayer::Company,\n        ];\n\n        for layer in layers {\n            if let Ok(Some(entry)) = self\n                .memory_manager\n                .get_from_layer(ctx.clone(), layer, memory_id)\n                .await\n            {\n                return Ok((entry, layer));\n            }\n        }\n\n        Err(format!(\"Memory not found: {}\", memory_id).into())\n    }\n\n    async fn perform_promotion(\n        &self,\n        ctx: &TenantContext,\n        entry: &mk_core::types::MemoryEntry,\n        from_layer: mk_core::types::MemoryLayer,\n        to_layer: mk_core::types::MemoryLayer,\n        reason: Option<String>,\n    ) -> Result<String, Box<dyn std::error::Error + Send + Sync>> {\n        let mut promoted_entry = entry.clone();\n        promoted_entry.id = format!(\"{}_promoted_{}\", entry.id, uuid::Uuid::new_v4());\n        promoted_entry.layer = to_layer;\n\n        // Add promotion metadata\n        promoted_entry.metadata.insert(\n            \"original_memory_id\".to_string(),\n            serde_json::json!(entry.id),\n        );\n        promoted_entry.metadata.insert(\n            \"promoted_from_layer\".to_string(),\n            serde_json::json!(Self::layer_to_string(from_layer)),\n        );\n        promoted_entry.metadata.insert(\n            \"promoted_at\".to_string(),\n            serde_json::json!(chrono::Utc::now().timestamp()),\n        );\n        if let Some(r) = reason {\n            promoted_entry\n                .metadata\n                .insert(\"promotion_reason\".to_string(), serde_json::json!(r));\n        }\n\n        let new_id = self\n            .memory_manager\n            .add_to_layer(ctx.clone(), to_layer, promoted_entry)\n            .await?;\n\n        Ok(new_id)\n    }\n}\n\n#[async_trait]\nimpl<G: PromotionGovernance + 'static> Tool for MemoryPromoteTool<G> {\n    fn name(&self) -> &str {\n        \"aeterna_memory_promote\"\n    }\n\n    fn description(&self) -> &str {\n        \"Promote a memory to a broader scope with governance approval if required. \\\n         Cross-scope promotions (e.g., projectteam, teamorg) require approval from layer leads.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"memoryId\": {\n                    \"type\": \"string\",\n                    \"description\": \"ID of the memory to promote\"\n                },\n                \"toLayer\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"user\", \"project\", \"team\", \"org\", \"company\"],\n                    \"description\": \"Target layer to promote to (must be broader than current)\"\n                },\n                \"reason\": {\n                    \"type\": \"string\",\n                    \"description\": \"Reason for promoting this memory to broader scope\"\n                },\n                \"notify\": {\n                    \"type\": \"array\",\n                    \"items\": { \"type\": \"string\" },\n                    \"description\": \"Additional people to notify about this promotion\"\n                },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"memoryId\", \"toLayer\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: MemoryPromoteParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n        let to_layer = Self::parse_layer(&p.to_layer)?;\n\n        let result = self\n            .promote(ctx, &p.memory_id, to_layer, p.reason, p.notify)\n            .await?;\n\n        Ok(serde_json::to_value(result)?)\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\n#[serde(rename_all = \"camelCase\")]\npub struct MemoryAutoPromoteParams {\n    pub layer: String,\n    #[serde(default)]\n    pub threshold: Option<f32>,\n    #[serde(default)]\n    pub dry_run: bool,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct AutoPromoteResult {\n    pub layer: String,\n    pub evaluated_count: usize,\n    pub promoted_count: usize,\n    pub promoted_memories: Vec<AutoPromotedMemory>,\n    pub threshold_used: f32,\n    pub dry_run: bool,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct AutoPromotedMemory {\n    pub original_id: String,\n    pub promoted_id: Option<String>,\n    pub score: f32,\n    pub from_layer: String,\n    pub to_layer: String,\n}\n\npub struct MemoryAutoPromoteTool {\n    memory_manager: Arc<MemoryManager>,\n    default_threshold: f32,\n}\n\nimpl MemoryAutoPromoteTool {\n    pub fn new(memory_manager: Arc<MemoryManager>) -> Self {\n        Self {\n            memory_manager,\n            default_threshold: 0.7,\n        }\n    }\n\n    pub fn with_threshold(mut self, threshold: f32) -> Self {\n        self.default_threshold = threshold;\n        self\n    }\n\n    fn parse_layer(layer: &str) -> Result<mk_core::types::MemoryLayer, String> {\n        match layer.to_lowercase().as_str() {\n            \"agent\" => Ok(mk_core::types::MemoryLayer::Agent),\n            \"user\" => Ok(mk_core::types::MemoryLayer::User),\n            \"session\" => Ok(mk_core::types::MemoryLayer::Session),\n            \"project\" => Ok(mk_core::types::MemoryLayer::Project),\n            \"team\" => Ok(mk_core::types::MemoryLayer::Team),\n            \"org\" => Ok(mk_core::types::MemoryLayer::Org),\n            \"company\" => Ok(mk_core::types::MemoryLayer::Company),\n            _ => Err(format!(\"Unknown layer: {}\", layer)),\n        }\n    }\n\n    fn layer_to_string(layer: mk_core::types::MemoryLayer) -> String {\n        match layer {\n            mk_core::types::MemoryLayer::Agent => \"agent\".to_string(),\n            mk_core::types::MemoryLayer::User => \"user\".to_string(),\n            mk_core::types::MemoryLayer::Session => \"session\".to_string(),\n            mk_core::types::MemoryLayer::Project => \"project\".to_string(),\n            mk_core::types::MemoryLayer::Team => \"team\".to_string(),\n            mk_core::types::MemoryLayer::Org => \"org\".to_string(),\n            mk_core::types::MemoryLayer::Company => \"company\".to_string(),\n        }\n    }\n\n    fn determine_target_layer(\n        current_layer: mk_core::types::MemoryLayer,\n    ) -> Option<mk_core::types::MemoryLayer> {\n        use mk_core::types::MemoryLayer;\n        match current_layer {\n            MemoryLayer::Agent => Some(MemoryLayer::User),\n            MemoryLayer::Session => Some(MemoryLayer::Project),\n            MemoryLayer::User => Some(MemoryLayer::Team),\n            MemoryLayer::Project => Some(MemoryLayer::Team),\n            MemoryLayer::Team => Some(MemoryLayer::Org),\n            MemoryLayer::Org => Some(MemoryLayer::Company),\n            MemoryLayer::Company => None,\n        }\n    }\n\n    fn calculate_importance_score(entry: &mk_core::types::MemoryEntry) -> f32 {\n        let explicit_score = entry\n            .metadata\n            .get(\"score\")\n            .and_then(|v| v.as_f64())\n            .map(|v| v as f32)\n            .unwrap_or(0.0);\n\n        let reward = entry\n            .metadata\n            .get(\"reward\")\n            .and_then(|v| v.as_f64())\n            .map(|v| v as f32)\n            .unwrap_or(0.0);\n\n        let access_count = entry\n            .metadata\n            .get(\"access_count\")\n            .and_then(|v| v.as_u64())\n            .unwrap_or(1) as f32;\n\n        let last_accessed = entry\n            .metadata\n            .get(\"last_accessed_at\")\n            .and_then(|v| v.as_i64())\n            .unwrap_or_else(|| chrono::Utc::now().timestamp()) as f32;\n\n        let now_ts = chrono::Utc::now().timestamp() as f32;\n        let days_since_last_access = (now_ts - last_accessed).max(0.0) / 86400.0;\n        let recency_score = (1.0f32 - days_since_last_access * 0.1)\n            .max(0.0f32)\n            .min(1.0f32);\n\n        let frequency_score = (access_count / 10.0).min(1.0);\n\n        let base_score = explicit_score.max(reward);\n\n        (base_score * 0.5) + (frequency_score * 0.3) + (recency_score * 0.2)\n    }\n\n    async fn auto_promote(\n        &self,\n        ctx: TenantContext,\n        layer: mk_core::types::MemoryLayer,\n        threshold: f32,\n        dry_run: bool,\n    ) -> Result<AutoPromoteResult, Box<dyn std::error::Error + Send + Sync>> {\n        let entries = self\n            .memory_manager\n            .list_all_from_layer(ctx.clone(), layer)\n            .await?;\n\n        let mut promoted_memories = Vec::new();\n        let target_layer = Self::determine_target_layer(layer);\n\n        for entry in &entries {\n            let score = Self::calculate_importance_score(entry);\n\n            if score >= threshold {\n                if let Some(target) = target_layer {\n                    let promoted_id = if dry_run {\n                        None\n                    } else {\n                        let mut promoted_entry = entry.clone();\n                        promoted_entry.id =\n                            format!(\"{}_auto_promoted_{}\", entry.id, uuid::Uuid::new_v4());\n                        promoted_entry.layer = target;\n                        promoted_entry.metadata.insert(\n                            \"original_memory_id\".to_string(),\n                            serde_json::json!(entry.id),\n                        );\n                        promoted_entry.metadata.insert(\n                            \"auto_promoted_at\".to_string(),\n                            serde_json::json!(chrono::Utc::now().timestamp()),\n                        );\n                        promoted_entry\n                            .metadata\n                            .insert(\"promotion_score\".to_string(), serde_json::json!(score));\n                        promoted_entry.metadata.insert(\n                            \"promoted_from_layer\".to_string(),\n                            serde_json::json!(Self::layer_to_string(layer)),\n                        );\n\n                        let new_id = self\n                            .memory_manager\n                            .add_to_layer(ctx.clone(), target, promoted_entry)\n                            .await?;\n                        Some(new_id)\n                    };\n\n                    promoted_memories.push(AutoPromotedMemory {\n                        original_id: entry.id.clone(),\n                        promoted_id,\n                        score,\n                        from_layer: Self::layer_to_string(layer),\n                        to_layer: Self::layer_to_string(target),\n                    });\n                }\n            }\n        }\n\n        Ok(AutoPromoteResult {\n            layer: Self::layer_to_string(layer),\n            evaluated_count: entries.len(),\n            promoted_count: promoted_memories.len(),\n            promoted_memories,\n            threshold_used: threshold,\n            dry_run,\n        })\n    }\n}\n\n#[async_trait]\nimpl Tool for MemoryAutoPromoteTool {\n    fn name(&self) -> &str {\n        \"aeterna_memory_auto_promote\"\n    }\n\n    fn description(&self) -> &str {\n        \"Automatically evaluate and promote memories based on reward threshold. \\\n         Memories with high scores (based on reward, access frequency, recency) are promoted \\\n         to the next broader layer. Use dry_run=true to preview without making changes.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"layer\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"agent\", \"session\", \"user\", \"project\", \"team\", \"org\"],\n                    \"description\": \"Source layer to evaluate for auto-promotion\"\n                },\n                \"threshold\": {\n                    \"type\": \"number\",\n                    \"minimum\": 0.0,\n                    \"maximum\": 1.0,\n                    \"default\": 0.7,\n                    \"description\": \"Minimum score threshold for promotion (0.0-1.0)\"\n                },\n                \"dryRun\": {\n                    \"type\": \"boolean\",\n                    \"default\": false,\n                    \"description\": \"Preview promotions without making changes\"\n                },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"layer\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: MemoryAutoPromoteParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n        let layer = Self::parse_layer(&p.layer)?;\n        let threshold = p.threshold.unwrap_or(self.default_threshold);\n\n        let result = self.auto_promote(ctx, layer, threshold, p.dry_run).await?;\n\n        Ok(serde_json::to_value(result)?)\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct GraphQueryParams {\n    pub query: String,\n    #[serde(default)]\n    pub limit: Option<usize>,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\npub struct GraphQueryTool {\n    graph_store: Arc<DuckDbGraphStore>,\n}\n\nimpl GraphQueryTool {\n    pub fn new(graph_store: Arc<DuckDbGraphStore>) -> Self {\n        Self { graph_store }\n    }\n}\n\n#[async_trait]\nimpl Tool for GraphQueryTool {\n    fn name(&self) -> &str {\n        \"graph_query\"\n    }\n\n    fn description(&self) -> &str {\n        \"Search the knowledge graph for nodes matching a query.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": { \"type\": \"string\", \"description\": \"Search query for finding nodes\" },\n                \"limit\": { \"type\": \"integer\", \"minimum\": 1, \"maximum\": 100, \"default\": 10 },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"query\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: GraphQueryParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n        let limit = p.limit.unwrap_or(10);\n\n        let nodes = self.graph_store.search_nodes(ctx, &p.query, limit).await?;\n\n        Ok(json!({\n            \"success\": true,\n            \"results\": nodes,\n            \"totalCount\": nodes.len()\n        }))\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct GraphNeighborsParams {\n    #[serde(rename = \"nodeId\")]\n    pub node_id: String,\n    pub depth: Option<usize>,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\npub struct GraphNeighborsTool {\n    graph_store: Arc<DuckDbGraphStore>,\n}\n\nimpl GraphNeighborsTool {\n    pub fn new(graph_store: Arc<DuckDbGraphStore>) -> Self {\n        Self { graph_store }\n    }\n}\n\n#[async_trait]\nimpl Tool for GraphNeighborsTool {\n    fn name(&self) -> &str {\n        \"graph_neighbors\"\n    }\n\n    fn description(&self) -> &str {\n        \"Find neighboring nodes connected to a given node in the knowledge graph.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"nodeId\": { \"type\": \"string\", \"description\": \"ID of the node to find neighbors for\" },\n                \"depth\": { \"type\": \"integer\", \"minimum\": 1, \"maximum\": 5, \"default\": 1, \"description\": \"Traversal depth (hops)\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"nodeId\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: GraphNeighborsParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n        let _depth = p.depth.unwrap_or(1);\n\n        let neighbors = self.graph_store.get_neighbors(ctx, &p.node_id).await?;\n\n        let results: Vec<Value> = neighbors\n            .into_iter()\n            .map(|(edge, node)| {\n                json!({\n                    \"edge\": edge,\n                    \"node\": node\n                })\n            })\n            .collect();\n\n        Ok(json!({\n            \"success\": true,\n            \"nodeId\": p.node_id,\n            \"neighbors\": results,\n            \"count\": results.len()\n        }))\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct GraphPathParams {\n    #[serde(rename = \"sourceId\")]\n    pub source_id: String,\n    #[serde(rename = \"targetId\")]\n    pub target_id: String,\n    #[serde(rename = \"maxHops\")]\n    pub max_hops: Option<usize>,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option<TenantContext>,\n}\n\npub struct GraphPathTool {\n    graph_store: Arc<DuckDbGraphStore>,\n}\n\nimpl GraphPathTool {\n    pub fn new(graph_store: Arc<DuckDbGraphStore>) -> Self {\n        Self { graph_store }\n    }\n}\n\n#[async_trait]\nimpl Tool for GraphPathTool {\n    fn name(&self) -> &str {\n        \"graph_path\"\n    }\n\n    fn description(&self) -> &str {\n        \"Find the shortest path between two nodes in the knowledge graph.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"sourceId\": { \"type\": \"string\", \"description\": \"ID of the starting node\" },\n                \"targetId\": { \"type\": \"string\", \"description\": \"ID of the target node\" },\n                \"maxHops\": { \"type\": \"integer\", \"minimum\": 1, \"maximum\": 10, \"default\": 5, \"description\": \"Maximum path length\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"sourceId\", \"targetId\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let p: GraphPathParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n        let max_hops = p.max_hops.unwrap_or(5);\n\n        let path = self\n            .graph_store\n            .find_path(ctx, &p.source_id, &p.target_id, max_hops)\n            .await?;\n\n        let found = !path.is_empty();\n\n        Ok(json!({\n            \"success\": true,\n            \"found\": found,\n            \"sourceId\": p.source_id,\n            \"targetId\": p.target_id,\n            \"path\": path,\n            \"hops\": path.len()\n        }))\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use memory::manager::MemoryManager;\n    use memory::providers::MockProvider;\n    use mk_core::types::{MemoryEntry, MemoryLayer, TenantContext, TenantId, UserId};\n    use std::collections::HashMap;\n    use std::str::FromStr;\n\n    fn test_ctx() -> TenantContext {\n        TenantContext {\n            tenant_id: TenantId::from_str(\"test-tenant\").unwrap(),\n            user_id: UserId::from_str(\"test-user\").unwrap(),\n            agent_id: None,\n        }\n    }\n\n    fn create_test_entry(id: &str, layer: MemoryLayer) -> MemoryEntry {\n        MemoryEntry {\n            id: id.to_string(),\n            content: format!(\"Test memory content for {}\", id),\n            embedding: None,\n            layer,\n            metadata: HashMap::new(),\n            created_at: chrono::Utc::now().timestamp(),\n            updated_at: chrono::Utc::now().timestamp(),\n            summaries: HashMap::new(),\n            context_vector: None,\n            importance_score: None,\n        }\n    }\n\n    async fn setup_manager_with_providers(layers: &[MemoryLayer]) -> Arc<MemoryManager> {\n        let manager = Arc::new(MemoryManager::new());\n        for &layer in layers {\n            let provider: Arc<\n                dyn mk_core::traits::MemoryProviderAdapter<\n                        Error = Box<dyn std::error::Error + Send + Sync>,\n                    > + Send\n                    + Sync,\n            > = Arc::new(MockProvider::new());\n            manager.register_provider(layer, provider).await;\n        }\n        manager\n    }\n\n    struct TestGovernance {\n        requires_approval_for_cross_scope: bool,\n    }\n\n    impl TestGovernance {\n        fn new(requires_approval: bool) -> Self {\n            Self {\n                requires_approval_for_cross_scope: requires_approval,\n            }\n        }\n    }\n\n    impl PromotionGovernance for TestGovernance {\n        async fn requires_approval(&self, from_layer: MemoryLayer, to_layer: MemoryLayer) -> bool {\n            if !self.requires_approval_for_cross_scope {\n                return false;\n            }\n            matches!(\n                (from_layer, to_layer),\n                (MemoryLayer::Project, MemoryLayer::Team)\n                    | (MemoryLayer::Team, MemoryLayer::Org)\n                    | (MemoryLayer::Org, MemoryLayer::Company)\n                    | (MemoryLayer::User, MemoryLayer::Team)\n            )\n        }\n\n        async fn get_approvers(\n            &self,\n            to_layer: MemoryLayer,\n            _ctx: &TenantContext,\n        ) -> Result<Vec<String>, Box<dyn std::error::Error + Send + Sync>> {\n            let approvers = match to_layer {\n                MemoryLayer::Team => vec![\"tech-lead@test.team\".to_string()],\n                MemoryLayer::Org => vec![\"architect@test.org\".to_string()],\n                MemoryLayer::Company => vec![\"admin@test.company\".to_string()],\n                _ => vec![],\n            };\n            Ok(approvers)\n        }\n\n        async fn create_promotion_request(\n            &self,\n            memory_id: &str,\n            _from_layer: MemoryLayer,\n            _to_layer: MemoryLayer,\n            _reason: Option<String>,\n            _requestor: &str,\n            _approvers: Vec<String>,\n        ) -> Result<String, Box<dyn std::error::Error + Send + Sync>> {\n            Ok(format!(\"test-proposal-{}\", memory_id))\n        }\n    }\n\n    #[tokio::test]\n    async fn test_promote_auto_approves_same_scope() {\n        let manager =\n            setup_manager_with_providers(&[MemoryLayer::Session, MemoryLayer::Project]).await;\n        let ctx = test_ctx();\n\n        let entry = create_test_entry(\"mem_session_1\", MemoryLayer::Session);\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Session, entry)\n            .await\n            .unwrap();\n\n        let governance = Arc::new(TestGovernance::new(true));\n        let tool = MemoryPromoteTool::new(manager.clone(), governance);\n\n        let result = tool\n            .promote(\n                ctx.clone(),\n                \"mem_session_1\",\n                MemoryLayer::Project,\n                Some(\"Test promotion\".to_string()),\n                vec![],\n            )\n            .await\n            .unwrap();\n\n        assert_eq!(result.status, PromotionStatus::Promoted);\n        assert!(result.promoted_id.is_some());\n        assert!(!result.approval_required);\n        assert_eq!(result.from_layer, \"session\");\n        assert_eq!(result.to_layer, \"project\");\n    }\n\n    #[tokio::test]\n    async fn test_promote_requires_approval_cross_scope() {\n        let manager =\n            setup_manager_with_providers(&[MemoryLayer::Project, MemoryLayer::Team]).await;\n        let ctx = test_ctx();\n\n        let entry = create_test_entry(\"mem_project_1\", MemoryLayer::Project);\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Project, entry)\n            .await\n            .unwrap();\n\n        let governance = Arc::new(TestGovernance::new(true));\n        let tool = MemoryPromoteTool::new(manager.clone(), governance);\n\n        let result = tool\n            .promote(\n                ctx.clone(),\n                \"mem_project_1\",\n                MemoryLayer::Team,\n                Some(\"Important for team\".to_string()),\n                vec![\"extra-reviewer@test.com\".to_string()],\n            )\n            .await\n            .unwrap();\n\n        assert_eq!(result.status, PromotionStatus::PendingApproval);\n        assert!(result.promoted_id.is_none());\n        assert!(result.approval_required);\n        assert!(result.proposal_id.is_some());\n        assert!(\n            result\n                .approvers_notified\n                .contains(&\"tech-lead@test.team\".to_string())\n        );\n        assert!(\n            result\n                .approvers_notified\n                .contains(&\"extra-reviewer@test.com\".to_string())\n        );\n        assert_eq!(result.from_layer, \"project\");\n        assert_eq!(result.to_layer, \"team\");\n    }\n\n    #[tokio::test]\n    async fn test_promote_blocked_wrong_direction() {\n        let manager =\n            setup_manager_with_providers(&[MemoryLayer::Team, MemoryLayer::Project]).await;\n        let ctx = test_ctx();\n\n        let entry = create_test_entry(\"mem_team_1\", MemoryLayer::Team);\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Team, entry)\n            .await\n            .unwrap();\n\n        let governance = Arc::new(TestGovernance::new(false));\n        let tool = MemoryPromoteTool::new(manager.clone(), governance);\n\n        let result = tool\n            .promote(\n                ctx.clone(),\n                \"mem_team_1\",\n                MemoryLayer::Project,\n                None,\n                vec![],\n            )\n            .await\n            .unwrap();\n\n        assert_eq!(result.status, PromotionStatus::Blocked);\n        assert!(result.promoted_id.is_none());\n        assert!(!result.approval_required);\n        assert!(\n            result\n                .reason\n                .unwrap()\n                .contains(\"can only promote to broader scopes\")\n        );\n    }\n\n    #[tokio::test]\n    async fn test_promote_blocked_same_level() {\n        let manager = setup_manager_with_providers(&[MemoryLayer::Project]).await;\n        let ctx = test_ctx();\n\n        let entry = create_test_entry(\"mem_project_2\", MemoryLayer::Project);\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Project, entry)\n            .await\n            .unwrap();\n\n        let governance = Arc::new(TestGovernance::new(false));\n        let tool = MemoryPromoteTool::new(manager.clone(), governance);\n\n        let result = tool\n            .promote(\n                ctx.clone(),\n                \"mem_project_2\",\n                MemoryLayer::Project,\n                None,\n                vec![],\n            )\n            .await\n            .unwrap();\n\n        assert_eq!(result.status, PromotionStatus::Blocked);\n    }\n\n    #[tokio::test]\n    async fn test_promote_memory_not_found() {\n        let manager =\n            setup_manager_with_providers(&[MemoryLayer::Session, MemoryLayer::Project]).await;\n        let ctx = test_ctx();\n\n        let governance = Arc::new(TestGovernance::new(false));\n        let tool = MemoryPromoteTool::new(manager.clone(), governance);\n\n        let result = tool\n            .promote(\n                ctx.clone(),\n                \"nonexistent_memory\",\n                MemoryLayer::Project,\n                None,\n                vec![],\n            )\n            .await;\n\n        assert!(result.is_err());\n        assert!(result.unwrap_err().to_string().contains(\"Memory not found\"));\n    }\n\n    #[tokio::test]\n    async fn test_tool_interface() {\n        let manager =\n            setup_manager_with_providers(&[MemoryLayer::User, MemoryLayer::Project]).await;\n        let ctx = test_ctx();\n\n        let entry = create_test_entry(\"mem_user_1\", MemoryLayer::User);\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n            .await\n            .unwrap();\n\n        let governance = Arc::new(TestGovernance::new(false));\n        let tool = MemoryPromoteTool::new(manager.clone(), governance);\n\n        assert_eq!(tool.name(), \"aeterna_memory_promote\");\n        assert!(tool.description().contains(\"Promote a memory\"));\n\n        let schema = tool.input_schema();\n        assert_eq!(schema[\"type\"], \"object\");\n        assert!(schema[\"properties\"][\"memoryId\"].is_object());\n        assert!(schema[\"properties\"][\"toLayer\"].is_object());\n        assert!(\n            schema[\"required\"]\n                .as_array()\n                .unwrap()\n                .contains(&json!(\"memoryId\"))\n        );\n        assert!(\n            schema[\"required\"]\n                .as_array()\n                .unwrap()\n                .contains(&json!(\"toLayer\"))\n        );\n    }\n\n    #[tokio::test]\n    async fn test_tool_call_auto_approve() {\n        let manager = setup_manager_with_providers(&[MemoryLayer::Agent, MemoryLayer::User]).await;\n        let ctx = test_ctx();\n\n        let entry = create_test_entry(\"mem_agent_1\", MemoryLayer::Agent);\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Agent, entry)\n            .await\n            .unwrap();\n\n        let governance = Arc::new(TestGovernance::new(false));\n        let tool = MemoryPromoteTool::new(manager.clone(), governance);\n\n        let params = json!({\n            \"memoryId\": \"mem_agent_1\",\n            \"toLayer\": \"user\",\n            \"reason\": \"Useful for user-level context\",\n            \"tenantContext\": {\n                \"tenant_id\": \"test-tenant\",\n                \"user_id\": \"test-user\"\n            }\n        });\n\n        let result = tool.call(params).await.unwrap();\n        assert_eq!(result[\"status\"], \"promoted\");\n        assert!(result[\"promotedId\"].as_str().is_some());\n        assert_eq!(result[\"fromLayer\"], \"agent\");\n        assert_eq!(result[\"toLayer\"], \"user\");\n    }\n\n    #[tokio::test]\n    async fn test_default_governance_requires_approval() {\n        let governance = DefaultPromotionGovernance::new();\n\n        assert!(\n            governance\n                .requires_approval(MemoryLayer::Project, MemoryLayer::Team)\n                .await\n        );\n        assert!(\n            governance\n                .requires_approval(MemoryLayer::Team, MemoryLayer::Org)\n                .await\n        );\n        assert!(\n            governance\n                .requires_approval(MemoryLayer::Org, MemoryLayer::Company)\n                .await\n        );\n        assert!(\n            governance\n                .requires_approval(MemoryLayer::User, MemoryLayer::Team)\n                .await\n        );\n\n        assert!(\n            !governance\n                .requires_approval(MemoryLayer::Session, MemoryLayer::Project)\n                .await\n        );\n        assert!(\n            !governance\n                .requires_approval(MemoryLayer::Agent, MemoryLayer::User)\n                .await\n        );\n    }\n\n    #[tokio::test]\n    async fn test_default_governance_get_approvers() {\n        let governance = DefaultPromotionGovernance::new();\n        let ctx = test_ctx();\n\n        let team_approvers = governance\n            .get_approvers(MemoryLayer::Team, &ctx)\n            .await\n            .unwrap();\n        assert!(team_approvers[0].contains(\"tech-lead\"));\n\n        let org_approvers = governance\n            .get_approvers(MemoryLayer::Org, &ctx)\n            .await\n            .unwrap();\n        assert!(org_approvers[0].contains(\"architect\"));\n\n        let company_approvers = governance\n            .get_approvers(MemoryLayer::Company, &ctx)\n            .await\n            .unwrap();\n        assert!(company_approvers[0].contains(\"admin\"));\n    }\n\n    #[tokio::test]\n    async fn test_promotion_preserves_metadata() {\n        let manager =\n            setup_manager_with_providers(&[MemoryLayer::Session, MemoryLayer::Project]).await;\n        let ctx = test_ctx();\n\n        let mut entry = create_test_entry(\"mem_with_meta\", MemoryLayer::Session);\n        entry\n            .metadata\n            .insert(\"custom_key\".to_string(), json!(\"custom_value\"));\n        entry.metadata.insert(\"importance\".to_string(), json!(0.95));\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Session, entry)\n            .await\n            .unwrap();\n\n        let governance = Arc::new(TestGovernance::new(false));\n        let tool = MemoryPromoteTool::new(manager.clone(), governance);\n\n        let result = tool\n            .promote(\n                ctx.clone(),\n                \"mem_with_meta\",\n                MemoryLayer::Project,\n                Some(\"Important memory\".to_string()),\n                vec![],\n            )\n            .await\n            .unwrap();\n\n        assert_eq!(result.status, PromotionStatus::Promoted);\n        let promoted_id = result.promoted_id.unwrap();\n\n        let promoted = manager\n            .get_from_layer(ctx.clone(), MemoryLayer::Project, &promoted_id)\n            .await\n            .unwrap()\n            .unwrap();\n\n        assert_eq!(promoted.metadata.get(\"custom_key\").unwrap(), \"custom_value\");\n        assert_eq!(promoted.metadata.get(\"importance\").unwrap(), &json!(0.95));\n        assert_eq!(\n            promoted.metadata.get(\"original_memory_id\").unwrap(),\n            \"mem_with_meta\"\n        );\n        assert_eq!(\n            promoted.metadata.get(\"promoted_from_layer\").unwrap(),\n            \"session\"\n        );\n        assert!(promoted.metadata.contains_key(\"promoted_at\"));\n        assert_eq!(\n            promoted.metadata.get(\"promotion_reason\").unwrap(),\n            \"Important memory\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_layer_hierarchy_parsing() {\n        assert_eq!(\n            MemoryPromoteTool::<DefaultPromotionGovernance>::parse_layer(\"agent\").unwrap(),\n            MemoryLayer::Agent\n        );\n        assert_eq!(\n            MemoryPromoteTool::<DefaultPromotionGovernance>::parse_layer(\"USER\").unwrap(),\n            MemoryLayer::User\n        );\n        assert_eq!(\n            MemoryPromoteTool::<DefaultPromotionGovernance>::parse_layer(\"Session\").unwrap(),\n            MemoryLayer::Session\n        );\n        assert_eq!(\n            MemoryPromoteTool::<DefaultPromotionGovernance>::parse_layer(\"project\").unwrap(),\n            MemoryLayer::Project\n        );\n        assert_eq!(\n            MemoryPromoteTool::<DefaultPromotionGovernance>::parse_layer(\"TEAM\").unwrap(),\n            MemoryLayer::Team\n        );\n        assert_eq!(\n            MemoryPromoteTool::<DefaultPromotionGovernance>::parse_layer(\"Org\").unwrap(),\n            MemoryLayer::Org\n        );\n        assert_eq!(\n            MemoryPromoteTool::<DefaultPromotionGovernance>::parse_layer(\"company\").unwrap(),\n            MemoryLayer::Company\n        );\n\n        assert!(MemoryPromoteTool::<DefaultPromotionGovernance>::parse_layer(\"invalid\").is_err());\n    }\n\n    #[tokio::test]\n    async fn test_hierarchy_level_ordering() {\n        assert!(\n            MemoryPromoteTool::<DefaultPromotionGovernance>::get_layer_hierarchy_level(\n                MemoryLayer::Agent\n            ) < MemoryPromoteTool::<DefaultPromotionGovernance>::get_layer_hierarchy_level(\n                MemoryLayer::Session\n            )\n        );\n        assert!(\n            MemoryPromoteTool::<DefaultPromotionGovernance>::get_layer_hierarchy_level(\n                MemoryLayer::Session\n            ) < MemoryPromoteTool::<DefaultPromotionGovernance>::get_layer_hierarchy_level(\n                MemoryLayer::User\n            )\n        );\n        assert!(\n            MemoryPromoteTool::<DefaultPromotionGovernance>::get_layer_hierarchy_level(\n                MemoryLayer::Project\n            ) < MemoryPromoteTool::<DefaultPromotionGovernance>::get_layer_hierarchy_level(\n                MemoryLayer::Team\n            )\n        );\n        assert!(\n            MemoryPromoteTool::<DefaultPromotionGovernance>::get_layer_hierarchy_level(\n                MemoryLayer::Team\n            ) < MemoryPromoteTool::<DefaultPromotionGovernance>::get_layer_hierarchy_level(\n                MemoryLayer::Org\n            )\n        );\n        assert!(\n            MemoryPromoteTool::<DefaultPromotionGovernance>::get_layer_hierarchy_level(\n                MemoryLayer::Org\n            ) < MemoryPromoteTool::<DefaultPromotionGovernance>::get_layer_hierarchy_level(\n                MemoryLayer::Company\n            )\n        );\n    }\n\n    #[tokio::test]\n    async fn test_promotion_result_serialization() {\n        let result = PromotionResult {\n            original_id: \"test-mem\".to_string(),\n            promoted_id: Some(\"test-mem-promoted-123\".to_string()),\n            status: PromotionStatus::Promoted,\n            from_layer: \"session\".to_string(),\n            to_layer: \"project\".to_string(),\n            approval_required: false,\n            approvers_notified: vec![],\n            reason: Some(\"Test reason\".to_string()),\n            proposal_id: None,\n        };\n\n        let json = serde_json::to_value(&result).unwrap();\n        assert_eq!(json[\"originalId\"], \"test-mem\");\n        assert_eq!(json[\"promotedId\"], \"test-mem-promoted-123\");\n        assert_eq!(json[\"status\"], \"promoted\");\n        assert_eq!(json[\"fromLayer\"], \"session\");\n        assert_eq!(json[\"toLayer\"], \"project\");\n        assert_eq!(json[\"approvalRequired\"], false);\n    }\n\n    #[tokio::test]\n    async fn test_memory_add_tool_interface() {\n        let manager = setup_manager_with_providers(&[MemoryLayer::Session]).await;\n        let tool = MemoryAddTool::new(manager);\n\n        assert_eq!(tool.name(), \"memory_add\");\n        assert!(tool.description().contains(\"Store\"));\n\n        let schema = tool.input_schema();\n        assert_eq!(schema[\"type\"], \"object\");\n        assert!(schema[\"properties\"][\"content\"].is_object());\n        assert!(schema[\"properties\"][\"layer\"].is_object());\n        assert!(\n            schema[\"required\"]\n                .as_array()\n                .unwrap()\n                .contains(&json!(\"content\"))\n        );\n        assert!(\n            schema[\"required\"]\n                .as_array()\n                .unwrap()\n                .contains(&json!(\"layer\"))\n        );\n    }\n\n    #[tokio::test]\n    async fn test_memory_add_tool_call() {\n        let manager = setup_manager_with_providers(&[MemoryLayer::User]).await;\n        let tool = MemoryAddTool::new(manager);\n\n        let params = json!({\n            \"content\": \"Test memory content\",\n            \"layer\": \"user\",\n            \"metadata\": {\"tag\": \"important\"},\n            \"tenantContext\": {\n                \"tenant_id\": \"test-tenant\",\n                \"user_id\": \"test-user\"\n            }\n        });\n\n        let result = tool.call(params).await.unwrap();\n        assert_eq!(result[\"success\"], true);\n        assert!(result[\"memoryId\"].as_str().is_some());\n    }\n\n    #[tokio::test]\n    async fn test_memory_add_invalid_layer() {\n        let manager = setup_manager_with_providers(&[MemoryLayer::Session]).await;\n        let tool = MemoryAddTool::new(manager);\n\n        let params = json!({\n            \"content\": \"Test memory content\",\n            \"layer\": \"invalid_layer\",\n            \"tenantContext\": {\n                \"tenant_id\": \"test-tenant\",\n                \"user_id\": \"test-user\"\n            }\n        });\n\n        let result = tool.call(params).await;\n        assert!(result.is_err());\n        assert!(result.unwrap_err().to_string().contains(\"Unknown layer\"));\n    }\n\n    #[tokio::test]\n    async fn test_memory_delete_tool_interface() {\n        let manager = setup_manager_with_providers(&[MemoryLayer::Session]).await;\n        let tool = MemoryDeleteTool::new(manager);\n\n        assert_eq!(tool.name(), \"memory_delete\");\n        assert!(tool.description().contains(\"Delete\"));\n\n        let schema = tool.input_schema();\n        assert!(schema[\"properties\"][\"memoryId\"].is_object());\n        assert!(schema[\"properties\"][\"layer\"].is_object());\n    }\n\n    #[tokio::test]\n    async fn test_memory_delete_tool_call() {\n        let manager = setup_manager_with_providers(&[MemoryLayer::Project]).await;\n        let ctx = test_ctx();\n\n        let entry = create_test_entry(\"mem_to_delete\", MemoryLayer::Project);\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Project, entry)\n            .await\n            .unwrap();\n\n        let tool = MemoryDeleteTool::new(manager.clone());\n        let params = json!({\n            \"memoryId\": \"mem_to_delete\",\n            \"layer\": \"project\",\n            \"tenantContext\": {\n                \"tenant_id\": \"test-tenant\",\n                \"user_id\": \"test-user\"\n            }\n        });\n\n        let result = tool.call(params).await.unwrap();\n        assert_eq!(result[\"success\"], true);\n\n        let retrieved = manager\n            .get_from_layer(ctx, MemoryLayer::Project, \"mem_to_delete\")\n            .await\n            .unwrap();\n        assert!(retrieved.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_memory_close_tool_interface() {\n        let manager = setup_manager_with_providers(&[MemoryLayer::Session]).await;\n        let tool = MemoryCloseTool::new(manager);\n\n        assert_eq!(tool.name(), \"memory_close\");\n        assert!(tool.description().contains(\"Close\"));\n\n        let schema = tool.input_schema();\n        assert!(schema[\"properties\"][\"id\"].is_object());\n        assert!(schema[\"properties\"][\"target\"].is_object());\n    }\n\n    #[tokio::test]\n    async fn test_memory_close_session() {\n        let manager = setup_manager_with_providers(&[MemoryLayer::Session]).await;\n        let tool = MemoryCloseTool::new(manager);\n\n        let params = json!({\n            \"id\": \"session-123\",\n            \"target\": \"session\",\n            \"tenantContext\": {\n                \"tenant_id\": \"test-tenant\",\n                \"user_id\": \"test-user\"\n            }\n        });\n\n        // Without LLM service, close_session fails during optimize_layer\n        let result = tool.call(params).await;\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"LLM service required\")\n        );\n    }\n\n    #[tokio::test]\n    async fn test_memory_close_agent() {\n        let manager = setup_manager_with_providers(&[MemoryLayer::Agent]).await;\n        let tool = MemoryCloseTool::new(manager);\n\n        let params = json!({\n            \"id\": \"agent-456\",\n            \"target\": \"agent\",\n            \"tenantContext\": {\n                \"tenant_id\": \"test-tenant\",\n                \"user_id\": \"test-user\"\n            }\n        });\n\n        // Without LLM service, close_agent fails during optimize_layer\n        let result = tool.call(params).await;\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"LLM service required\")\n        );\n    }\n\n    #[tokio::test]\n    async fn test_memory_feedback_tool_interface() {\n        let manager = setup_manager_with_providers(&[MemoryLayer::Session]).await;\n        let tool = MemoryFeedbackTool::new(manager);\n\n        assert_eq!(tool.name(), \"memory_feedback\");\n        assert!(tool.description().contains(\"reward\"));\n\n        let schema = tool.input_schema();\n        assert!(schema[\"properties\"][\"memoryId\"].is_object());\n        assert!(schema[\"properties\"][\"rewardType\"].is_object());\n        assert!(schema[\"properties\"][\"score\"].is_object());\n    }\n\n    #[tokio::test]\n    async fn test_memory_feedback_helpful() {\n        let manager = setup_manager_with_providers(&[MemoryLayer::Session]).await;\n        let ctx = test_ctx();\n\n        let entry = create_test_entry(\"mem_feedback\", MemoryLayer::Session);\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Session, entry)\n            .await\n            .unwrap();\n\n        let tool = MemoryFeedbackTool::new(manager);\n        let params = json!({\n            \"memoryId\": \"mem_feedback\",\n            \"layer\": \"session\",\n            \"rewardType\": \"helpful\",\n            \"score\": 0.9,\n            \"reasoning\": \"Very useful information\",\n            \"tenantContext\": {\n                \"tenant_id\": \"test-tenant\",\n                \"user_id\": \"test-user\"\n            }\n        });\n\n        let result = tool.call(params).await.unwrap();\n        assert_eq!(result[\"success\"], true);\n    }\n\n    #[tokio::test]\n    async fn test_memory_feedback_irrelevant() {\n        let manager = setup_manager_with_providers(&[MemoryLayer::Project]).await;\n        let ctx = test_ctx();\n\n        let entry = create_test_entry(\"mem_irrelevant\", MemoryLayer::Project);\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Project, entry)\n            .await\n            .unwrap();\n\n        let tool = MemoryFeedbackTool::new(manager);\n        let params = json!({\n            \"memoryId\": \"mem_irrelevant\",\n            \"layer\": \"project\",\n            \"rewardType\": \"irrelevant\",\n            \"score\": -0.5,\n            \"tenantContext\": {\n                \"tenant_id\": \"test-tenant\",\n                \"user_id\": \"test-user\"\n            }\n        });\n\n        let result = tool.call(params).await.unwrap();\n        assert_eq!(result[\"success\"], true);\n    }\n\n    #[tokio::test]\n    async fn test_memory_feedback_invalid_reward_type() {\n        let manager = setup_manager_with_providers(&[MemoryLayer::Session]).await;\n        let tool = MemoryFeedbackTool::new(manager);\n\n        let params = json!({\n            \"memoryId\": \"mem_invalid\",\n            \"layer\": \"session\",\n            \"rewardType\": \"invalid_type\",\n            \"score\": 0.5,\n            \"tenantContext\": {\n                \"tenant_id\": \"test-tenant\",\n                \"user_id\": \"test-user\"\n            }\n        });\n\n        let result = tool.call(params).await;\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Unknown reward type\")\n        );\n    }\n\n    #[tokio::test]\n    async fn test_memory_optimize_tool_interface() {\n        let manager = setup_manager_with_providers(&[MemoryLayer::Session]).await;\n        let tool = MemoryOptimizeTool::new(manager);\n\n        assert_eq!(tool.name(), \"memory_optimize\");\n        assert!(tool.description().contains(\"pruning\"));\n\n        let schema = tool.input_schema();\n        assert!(schema[\"properties\"][\"layer\"].is_object());\n    }\n\n    #[tokio::test]\n    async fn test_memory_optimize_tool_call() {\n        let manager = setup_manager_with_providers(&[MemoryLayer::Session]).await;\n        let tool = MemoryOptimizeTool::new(manager);\n\n        let params = json!({\n            \"layer\": \"session\",\n            \"tenantContext\": {\n                \"tenant_id\": \"test-tenant\",\n                \"user_id\": \"test-user\"\n            }\n        });\n\n        // Without LLM service, optimize_layer fails\n        let result = tool.call(params).await;\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"LLM service required\")\n        );\n    }\n\n    #[tokio::test]\n    async fn test_memory_optimize_invalid_layer() {\n        let manager = setup_manager_with_providers(&[MemoryLayer::Session]).await;\n        let tool = MemoryOptimizeTool::new(manager);\n\n        let params = json!({\n            \"layer\": \"invalid\",\n            \"tenantContext\": {\n                \"tenant_id\": \"test-tenant\",\n                \"user_id\": \"test-user\"\n            }\n        });\n\n        let result = tool.call(params).await;\n        assert!(result.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_memory_search_tool_interface() {\n        let manager = setup_manager_with_providers(&[MemoryLayer::Session]).await;\n        let tool = MemorySearchTool::new(manager);\n\n        assert_eq!(tool.name(), \"memory_search\");\n        assert!(tool.description().contains(\"Search\"));\n\n        let schema = tool.input_schema();\n        assert!(schema[\"properties\"][\"query\"].is_object());\n        assert!(schema[\"properties\"][\"limit\"].is_object());\n        assert!(schema[\"properties\"][\"threshold\"].is_object());\n    }\n\n    fn create_test_entry_with_score(id: &str, layer: MemoryLayer, score: f32) -> MemoryEntry {\n        let mut entry = create_test_entry(id, layer);\n        entry.metadata.insert(\"score\".to_string(), json!(score));\n        entry.metadata.insert(\"access_count\".to_string(), json!(5));\n        entry.metadata.insert(\n            \"last_accessed_at\".to_string(),\n            json!(chrono::Utc::now().timestamp()),\n        );\n        entry\n    }\n\n    #[tokio::test]\n    async fn test_auto_promote_above_threshold() {\n        let manager =\n            setup_manager_with_providers(&[MemoryLayer::Session, MemoryLayer::Project]).await;\n        let ctx = test_ctx();\n\n        let high_score_entry = create_test_entry_with_score(\"mem_high\", MemoryLayer::Session, 0.9);\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Session, high_score_entry)\n            .await\n            .unwrap();\n\n        let tool = MemoryAutoPromoteTool::new(manager.clone());\n        let result = tool\n            .auto_promote(ctx.clone(), MemoryLayer::Session, 0.7, false)\n            .await\n            .unwrap();\n\n        assert_eq!(result.layer, \"session\");\n        assert_eq!(result.evaluated_count, 1);\n        assert_eq!(result.promoted_count, 1);\n        assert!(!result.dry_run);\n        assert_eq!(result.promoted_memories.len(), 1);\n        assert_eq!(result.promoted_memories[0].original_id, \"mem_high\");\n        assert!(result.promoted_memories[0].promoted_id.is_some());\n        assert_eq!(result.promoted_memories[0].from_layer, \"session\");\n        assert_eq!(result.promoted_memories[0].to_layer, \"project\");\n    }\n\n    #[tokio::test]\n    async fn test_auto_promote_below_threshold() {\n        let manager =\n            setup_manager_with_providers(&[MemoryLayer::Session, MemoryLayer::Project]).await;\n        let ctx = test_ctx();\n\n        let low_score_entry = create_test_entry_with_score(\"mem_low\", MemoryLayer::Session, 0.3);\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Session, low_score_entry)\n            .await\n            .unwrap();\n\n        let tool = MemoryAutoPromoteTool::new(manager.clone());\n        let result = tool\n            .auto_promote(ctx.clone(), MemoryLayer::Session, 0.7, false)\n            .await\n            .unwrap();\n\n        assert_eq!(result.evaluated_count, 1);\n        assert_eq!(result.promoted_count, 0);\n        assert!(result.promoted_memories.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_auto_promote_dry_run() {\n        let manager =\n            setup_manager_with_providers(&[MemoryLayer::Session, MemoryLayer::Project]).await;\n        let ctx = test_ctx();\n\n        let high_score_entry = create_test_entry_with_score(\"mem_dry\", MemoryLayer::Session, 0.9);\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Session, high_score_entry)\n            .await\n            .unwrap();\n\n        let tool = MemoryAutoPromoteTool::new(manager.clone());\n        let result = tool\n            .auto_promote(ctx.clone(), MemoryLayer::Session, 0.7, true)\n            .await\n            .unwrap();\n\n        assert!(result.dry_run);\n        assert_eq!(result.promoted_count, 1);\n        assert!(result.promoted_memories[0].promoted_id.is_none());\n\n        let project_entries = manager\n            .list_all_from_layer(ctx.clone(), MemoryLayer::Project)\n            .await\n            .unwrap();\n        assert!(project_entries.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_auto_promote_multiple_memories() {\n        let manager = setup_manager_with_providers(&[MemoryLayer::Agent, MemoryLayer::User]).await;\n        let ctx = test_ctx();\n\n        let entry1 = create_test_entry_with_score(\"mem_1\", MemoryLayer::Agent, 0.8);\n        let entry2 = create_test_entry_with_score(\"mem_2\", MemoryLayer::Agent, 0.9);\n        let entry3 = create_test_entry_with_score(\"mem_3\", MemoryLayer::Agent, 0.4);\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Agent, entry1)\n            .await\n            .unwrap();\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Agent, entry2)\n            .await\n            .unwrap();\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Agent, entry3)\n            .await\n            .unwrap();\n\n        let tool = MemoryAutoPromoteTool::new(manager.clone());\n        let result = tool\n            .auto_promote(ctx.clone(), MemoryLayer::Agent, 0.7, false)\n            .await\n            .unwrap();\n\n        assert_eq!(result.evaluated_count, 3);\n        assert_eq!(result.promoted_count, 2);\n    }\n\n    #[tokio::test]\n    async fn test_auto_promote_tool_interface() {\n        let manager = setup_manager_with_providers(&[MemoryLayer::Session]).await;\n        let tool = MemoryAutoPromoteTool::new(manager);\n\n        assert_eq!(tool.name(), \"aeterna_memory_auto_promote\");\n        assert!(tool.description().contains(\"Automatically\"));\n\n        let schema = tool.input_schema();\n        assert_eq!(schema[\"type\"], \"object\");\n        assert!(schema[\"properties\"][\"layer\"].is_object());\n        assert!(schema[\"properties\"][\"threshold\"].is_object());\n        assert!(schema[\"properties\"][\"dryRun\"].is_object());\n    }\n\n    #[tokio::test]\n    async fn test_auto_promote_tool_call() {\n        let manager =\n            setup_manager_with_providers(&[MemoryLayer::Session, MemoryLayer::Project]).await;\n        let ctx = test_ctx();\n\n        let entry = create_test_entry_with_score(\"mem_call\", MemoryLayer::Session, 0.85);\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Session, entry)\n            .await\n            .unwrap();\n\n        let tool = MemoryAutoPromoteTool::new(manager);\n        let params = json!({\n            \"layer\": \"session\",\n            \"threshold\": 0.5,\n            \"dryRun\": false,\n            \"tenantContext\": {\n                \"tenant_id\": \"test-tenant\",\n                \"user_id\": \"test-user\"\n            }\n        });\n\n        let result = tool.call(params).await.unwrap();\n        assert_eq!(result[\"layer\"], \"session\");\n        assert_eq!(result[\"evaluatedCount\"], 1);\n        assert_eq!(result[\"promotedCount\"], 1);\n        assert_eq!(result[\"dryRun\"], false);\n    }\n\n    #[tokio::test]\n    async fn test_auto_promote_with_reward_metadata() {\n        let manager =\n            setup_manager_with_providers(&[MemoryLayer::Project, MemoryLayer::Team]).await;\n        let ctx = test_ctx();\n\n        let mut entry = create_test_entry(\"mem_reward\", MemoryLayer::Project);\n        entry.metadata.insert(\"reward\".to_string(), json!(0.95));\n        entry.metadata.insert(\"access_count\".to_string(), json!(20));\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Project, entry)\n            .await\n            .unwrap();\n\n        let tool = MemoryAutoPromoteTool::new(manager.clone());\n        let result = tool\n            .auto_promote(ctx.clone(), MemoryLayer::Project, 0.6, false)\n            .await\n            .unwrap();\n\n        assert_eq!(result.promoted_count, 1);\n        assert!(result.promoted_memories[0].score >= 0.6);\n    }\n\n    #[tokio::test]\n    async fn test_auto_promote_preserves_promotion_metadata() {\n        let manager =\n            setup_manager_with_providers(&[MemoryLayer::Session, MemoryLayer::Project]).await;\n        let ctx = test_ctx();\n\n        let entry = create_test_entry_with_score(\"mem_meta\", MemoryLayer::Session, 0.9);\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Session, entry)\n            .await\n            .unwrap();\n\n        let tool = MemoryAutoPromoteTool::new(manager.clone());\n        let result = tool\n            .auto_promote(ctx.clone(), MemoryLayer::Session, 0.7, false)\n            .await\n            .unwrap();\n\n        let promoted_id = result.promoted_memories[0].promoted_id.as_ref().unwrap();\n        let promoted = manager\n            .get_from_layer(ctx.clone(), MemoryLayer::Project, promoted_id)\n            .await\n            .unwrap()\n            .unwrap();\n\n        assert_eq!(\n            promoted.metadata.get(\"original_memory_id\").unwrap(),\n            \"mem_meta\"\n        );\n        assert!(promoted.metadata.contains_key(\"auto_promoted_at\"));\n        assert!(promoted.metadata.contains_key(\"promotion_score\"));\n        assert_eq!(\n            promoted.metadata.get(\"promoted_from_layer\").unwrap(),\n            \"session\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_auto_promote_no_target_for_company() {\n        let manager = setup_manager_with_providers(&[MemoryLayer::Company]).await;\n        let ctx = test_ctx();\n\n        let entry = create_test_entry_with_score(\"mem_company\", MemoryLayer::Company, 0.95);\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Company, entry)\n            .await\n            .unwrap();\n\n        let tool = MemoryAutoPromoteTool::new(manager);\n        let result = tool\n            .auto_promote(ctx.clone(), MemoryLayer::Company, 0.7, false)\n            .await\n            .unwrap();\n\n        assert_eq!(result.evaluated_count, 1);\n        assert_eq!(result.promoted_count, 0);\n    }\n\n    #[tokio::test]\n    async fn test_calculate_importance_score() {\n        let mut entry = create_test_entry(\"score_test\", MemoryLayer::Session);\n\n        entry.metadata.insert(\"score\".to_string(), json!(0.8));\n        entry.metadata.insert(\"access_count\".to_string(), json!(10));\n        entry.metadata.insert(\n            \"last_accessed_at\".to_string(),\n            json!(chrono::Utc::now().timestamp()),\n        );\n\n        let score = MemoryAutoPromoteTool::calculate_importance_score(&entry);\n        assert!(score > 0.5);\n        assert!(score <= 1.0);\n    }\n\n    #[tokio::test]\n    async fn test_determine_target_layer() {\n        assert_eq!(\n            MemoryAutoPromoteTool::determine_target_layer(MemoryLayer::Agent),\n            Some(MemoryLayer::User)\n        );\n        assert_eq!(\n            MemoryAutoPromoteTool::determine_target_layer(MemoryLayer::Session),\n            Some(MemoryLayer::Project)\n        );\n        assert_eq!(\n            MemoryAutoPromoteTool::determine_target_layer(MemoryLayer::User),\n            Some(MemoryLayer::Team)\n        );\n        assert_eq!(\n            MemoryAutoPromoteTool::determine_target_layer(MemoryLayer::Project),\n            Some(MemoryLayer::Team)\n        );\n        assert_eq!(\n            MemoryAutoPromoteTool::determine_target_layer(MemoryLayer::Team),\n            Some(MemoryLayer::Org)\n        );\n        assert_eq!(\n            MemoryAutoPromoteTool::determine_target_layer(MemoryLayer::Org),\n            Some(MemoryLayer::Company)\n        );\n        assert_eq!(\n            MemoryAutoPromoteTool::determine_target_layer(MemoryLayer::Company),\n            None\n        );\n    }\n\n    #[tokio::test]\n    async fn test_auto_promote_result_serialization() {\n        let result = AutoPromoteResult {\n            layer: \"session\".to_string(),\n            evaluated_count: 10,\n            promoted_count: 3,\n            promoted_memories: vec![AutoPromotedMemory {\n                original_id: \"mem_1\".to_string(),\n                promoted_id: Some(\"mem_1_promoted\".to_string()),\n                score: 0.85,\n                from_layer: \"session\".to_string(),\n                to_layer: \"project\".to_string(),\n            }],\n            threshold_used: 0.7,\n            dry_run: false,\n        };\n\n        let json = serde_json::to_value(&result).unwrap();\n        assert_eq!(json[\"layer\"], \"session\");\n        assert_eq!(json[\"evaluatedCount\"], 10);\n        assert_eq!(json[\"promotedCount\"], 3);\n        assert!((json[\"thresholdUsed\"].as_f64().unwrap() - 0.7).abs() < 0.01);\n        assert_eq!(json[\"dryRun\"], false);\n        assert!(json[\"promotedMemories\"].is_array());\n    }\n}\n","traces":[{"line":18,"address":[],"length":0,"stats":{"Line":26}},{"line":72,"address":[],"length":0,"stats":{"Line":30}},{"line":73,"address":[],"length":0,"stats":{"Line":30}},{"line":76,"address":[],"length":0,"stats":{"Line":8}},{"line":77,"address":[],"length":0,"stats":{"Line":8}},{"line":80,"address":[],"length":0,"stats":{"Line":8}},{"line":81,"address":[],"length":0,"stats":{"Line":8}},{"line":82,"address":[],"length":0,"stats":{"Line":8}},{"line":83,"address":[],"length":0,"stats":{"Line":8}},{"line":84,"address":[],"length":0,"stats":{"Line":16}},{"line":85,"address":[],"length":0,"stats":{"Line":16}},{"line":86,"address":[],"length":0,"stats":{"Line":16}},{"line":87,"address":[],"length":0,"stats":{"Line":16}},{"line":89,"address":[],"length":0,"stats":{"Line":8}},{"line":93,"address":[],"length":0,"stats":{"Line":6}},{"line":132,"address":[],"length":0,"stats":{"Line":24}},{"line":139,"address":[],"length":0,"stats":{"Line":30}},{"line":140,"address":[],"length":0,"stats":{"Line":30}},{"line":143,"address":[],"length":0,"stats":{"Line":8}},{"line":144,"address":[],"length":0,"stats":{"Line":8}},{"line":147,"address":[],"length":0,"stats":{"Line":8}},{"line":148,"address":[],"length":0,"stats":{"Line":8}},{"line":149,"address":[],"length":0,"stats":{"Line":8}},{"line":150,"address":[],"length":0,"stats":{"Line":8}},{"line":151,"address":[],"length":0,"stats":{"Line":16}},{"line":152,"address":[],"length":0,"stats":{"Line":16}},{"line":153,"address":[],"length":0,"stats":{"Line":16}},{"line":154,"address":[],"length":0,"stats":{"Line":16}},{"line":155,"address":[],"length":0,"stats":{"Line":24}},{"line":156,"address":[],"length":0,"stats":{"Line":16}},{"line":158,"address":[],"length":0,"stats":{"Line":8}},{"line":162,"address":[],"length":0,"stats":{"Line":2}},{"line":208,"address":[],"length":0,"stats":{"Line":25}},{"line":215,"address":[],"length":0,"stats":{"Line":30}},{"line":216,"address":[],"length":0,"stats":{"Line":30}},{"line":219,"address":[],"length":0,"stats":{"Line":8}},{"line":220,"address":[],"length":0,"stats":{"Line":8}},{"line":223,"address":[],"length":0,"stats":{"Line":8}},{"line":224,"address":[],"length":0,"stats":{"Line":8}},{"line":225,"address":[],"length":0,"stats":{"Line":8}},{"line":226,"address":[],"length":0,"stats":{"Line":8}},{"line":227,"address":[],"length":0,"stats":{"Line":16}},{"line":228,"address":[],"length":0,"stats":{"Line":16}},{"line":229,"address":[],"length":0,"stats":{"Line":16}},{"line":231,"address":[],"length":0,"stats":{"Line":8}},{"line":235,"address":[],"length":0,"stats":{"Line":2}},{"line":275,"address":[],"length":0,"stats":{"Line":22}},{"line":282,"address":[],"length":0,"stats":{"Line":29}},{"line":283,"address":[],"length":0,"stats":{"Line":29}},{"line":286,"address":[],"length":0,"stats":{"Line":7}},{"line":287,"address":[],"length":0,"stats":{"Line":7}},{"line":290,"address":[],"length":0,"stats":{"Line":7}},{"line":291,"address":[],"length":0,"stats":{"Line":7}},{"line":292,"address":[],"length":0,"stats":{"Line":7}},{"line":293,"address":[],"length":0,"stats":{"Line":7}},{"line":294,"address":[],"length":0,"stats":{"Line":14}},{"line":295,"address":[],"length":0,"stats":{"Line":14}},{"line":297,"address":[],"length":0,"stats":{"Line":7}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":25}},{"line":326,"address":[],"length":0,"stats":{"Line":30}},{"line":327,"address":[],"length":0,"stats":{"Line":30}},{"line":330,"address":[],"length":0,"stats":{"Line":8}},{"line":331,"address":[],"length":0,"stats":{"Line":8}},{"line":334,"address":[],"length":0,"stats":{"Line":8}},{"line":335,"address":[],"length":0,"stats":{"Line":8}},{"line":336,"address":[],"length":0,"stats":{"Line":8}},{"line":337,"address":[],"length":0,"stats":{"Line":8}},{"line":338,"address":[],"length":0,"stats":{"Line":16}},{"line":339,"address":[],"length":0,"stats":{"Line":24}},{"line":340,"address":[],"length":0,"stats":{"Line":16}},{"line":342,"address":[],"length":0,"stats":{"Line":8}},{"line":346,"address":[],"length":0,"stats":{"Line":2}},{"line":382,"address":[],"length":0,"stats":{"Line":26}},{"line":389,"address":[],"length":0,"stats":{"Line":30}},{"line":390,"address":[],"length":0,"stats":{"Line":30}},{"line":393,"address":[],"length":0,"stats":{"Line":8}},{"line":394,"address":[],"length":0,"stats":{"Line":8}},{"line":397,"address":[],"length":0,"stats":{"Line":8}},{"line":398,"address":[],"length":0,"stats":{"Line":8}},{"line":399,"address":[],"length":0,"stats":{"Line":8}},{"line":400,"address":[],"length":0,"stats":{"Line":8}},{"line":401,"address":[],"length":0,"stats":{"Line":16}},{"line":402,"address":[],"length":0,"stats":{"Line":16}},{"line":403,"address":[],"length":0,"stats":{"Line":24}},{"line":404,"address":[],"length":0,"stats":{"Line":32}},{"line":405,"address":[],"length":0,"stats":{"Line":16}},{"line":406,"address":[],"length":0,"stats":{"Line":16}},{"line":408,"address":[],"length":0,"stats":{"Line":8}},{"line":412,"address":[],"length":0,"stats":{"Line":3}},{"line":466,"address":[],"length":0,"stats":{"Line":25}},{"line":473,"address":[],"length":0,"stats":{"Line":30}},{"line":474,"address":[],"length":0,"stats":{"Line":30}},{"line":477,"address":[],"length":0,"stats":{"Line":8}},{"line":478,"address":[],"length":0,"stats":{"Line":8}},{"line":481,"address":[],"length":0,"stats":{"Line":8}},{"line":482,"address":[],"length":0,"stats":{"Line":8}},{"line":483,"address":[],"length":0,"stats":{"Line":8}},{"line":484,"address":[],"length":0,"stats":{"Line":8}},{"line":485,"address":[],"length":0,"stats":{"Line":24}},{"line":486,"address":[],"length":0,"stats":{"Line":16}},{"line":488,"address":[],"length":0,"stats":{"Line":8}},{"line":492,"address":[],"length":0,"stats":{"Line":2}},{"line":580,"address":[],"length":0,"stats":{"Line":2}},{"line":581,"address":[],"length":0,"stats":{"Line":2}},{"line":586,"address":[],"length":0,"stats":{"Line":0}},{"line":587,"address":[],"length":0,"stats":{"Line":0}},{"line":592,"address":[],"length":0,"stats":{"Line":6}},{"line":600,"address":[],"length":0,"stats":{"Line":2}},{"line":601,"address":[],"length":0,"stats":{"Line":12}},{"line":609,"address":[],"length":0,"stats":{"Line":3}},{"line":615,"address":[],"length":0,"stats":{"Line":9}},{"line":616,"address":[],"length":0,"stats":{"Line":6}},{"line":618,"address":[],"length":0,"stats":{"Line":3}},{"line":621,"address":[],"length":0,"stats":{"Line":3}},{"line":624,"address":[],"length":0,"stats":{"Line":3}},{"line":626,"address":[],"length":0,"stats":{"Line":0}},{"line":628,"address":[],"length":0,"stats":{"Line":3}},{"line":631,"address":[],"length":0,"stats":{"Line":0}},{"line":640,"address":[],"length":0,"stats":{"Line":0}},{"line":650,"address":[],"length":0,"stats":{"Line":8}},{"line":657,"address":[],"length":0,"stats":{"Line":9}},{"line":658,"address":[],"length":0,"stats":{"Line":9}},{"line":659,"address":[],"length":0,"stats":{"Line":10}},{"line":660,"address":[],"length":0,"stats":{"Line":10}},{"line":661,"address":[],"length":0,"stats":{"Line":7}},{"line":662,"address":[],"length":0,"stats":{"Line":6}},{"line":663,"address":[],"length":0,"stats":{"Line":5}},{"line":664,"address":[],"length":0,"stats":{"Line":4}},{"line":665,"address":[],"length":0,"stats":{"Line":3}},{"line":666,"address":[],"length":0,"stats":{"Line":1}},{"line":670,"address":[],"length":0,"stats":{"Line":19}},{"line":671,"address":[],"length":0,"stats":{"Line":19}},{"line":672,"address":[],"length":0,"stats":{"Line":4}},{"line":673,"address":[],"length":0,"stats":{"Line":2}},{"line":674,"address":[],"length":0,"stats":{"Line":8}},{"line":675,"address":[],"length":0,"stats":{"Line":18}},{"line":676,"address":[],"length":0,"stats":{"Line":6}},{"line":677,"address":[],"length":0,"stats":{"Line":0}},{"line":678,"address":[],"length":0,"stats":{"Line":0}},{"line":682,"address":[],"length":0,"stats":{"Line":22}},{"line":683,"address":[],"length":0,"stats":{"Line":22}},{"line":684,"address":[],"length":0,"stats":{"Line":2}},{"line":685,"address":[],"length":0,"stats":{"Line":4}},{"line":686,"address":[],"length":0,"stats":{"Line":2}},{"line":687,"address":[],"length":0,"stats":{"Line":7}},{"line":688,"address":[],"length":0,"stats":{"Line":4}},{"line":689,"address":[],"length":0,"stats":{"Line":2}},{"line":690,"address":[],"length":0,"stats":{"Line":1}},{"line":694,"address":[],"length":0,"stats":{"Line":7}},{"line":703,"address":[],"length":0,"stats":{"Line":41}},{"line":706,"address":[],"length":0,"stats":{"Line":18}},{"line":707,"address":[],"length":0,"stats":{"Line":18}},{"line":709,"address":[],"length":0,"stats":{"Line":6}},{"line":710,"address":[],"length":0,"stats":{"Line":2}},{"line":711,"address":[],"length":0,"stats":{"Line":6}},{"line":712,"address":[],"length":0,"stats":{"Line":4}},{"line":713,"address":[],"length":0,"stats":{"Line":4}},{"line":714,"address":[],"length":0,"stats":{"Line":6}},{"line":715,"address":[],"length":0,"stats":{"Line":6}},{"line":716,"address":[],"length":0,"stats":{"Line":2}},{"line":717,"address":[],"length":0,"stats":{"Line":4}},{"line":718,"address":[],"length":0,"stats":{"Line":4}},{"line":719,"address":[],"length":0,"stats":{"Line":4}},{"line":720,"address":[],"length":0,"stats":{"Line":6}},{"line":721,"address":[],"length":0,"stats":{"Line":2}},{"line":723,"address":[],"length":0,"stats":{"Line":2}},{"line":728,"address":[],"length":0,"stats":{"Line":12}},{"line":729,"address":[],"length":0,"stats":{"Line":8}},{"line":730,"address":[],"length":0,"stats":{"Line":8}},{"line":731,"address":[],"length":0,"stats":{"Line":4}},{"line":733,"address":[],"length":0,"stats":{"Line":4}},{"line":735,"address":[],"length":0,"stats":{"Line":4}},{"line":738,"address":[],"length":0,"stats":{"Line":3}},{"line":739,"address":[],"length":0,"stats":{"Line":3}},{"line":740,"address":[],"length":0,"stats":{"Line":2}},{"line":744,"address":[],"length":0,"stats":{"Line":3}},{"line":745,"address":[],"length":0,"stats":{"Line":3}},{"line":746,"address":[],"length":0,"stats":{"Line":2}},{"line":748,"address":[],"length":0,"stats":{"Line":2}},{"line":749,"address":[],"length":0,"stats":{"Line":2}},{"line":750,"address":[],"length":0,"stats":{"Line":2}},{"line":751,"address":[],"length":0,"stats":{"Line":3}},{"line":752,"address":[],"length":0,"stats":{"Line":2}},{"line":753,"address":[],"length":0,"stats":{"Line":1}},{"line":755,"address":[],"length":0,"stats":{"Line":1}},{"line":757,"address":[],"length":0,"stats":{"Line":1}},{"line":758,"address":[],"length":0,"stats":{"Line":3}},{"line":759,"address":[],"length":0,"stats":{"Line":2}},{"line":760,"address":[],"length":0,"stats":{"Line":2}},{"line":761,"address":[],"length":0,"stats":{"Line":3}},{"line":762,"address":[],"length":0,"stats":{"Line":3}},{"line":763,"address":[],"length":0,"stats":{"Line":1}},{"line":764,"address":[],"length":0,"stats":{"Line":2}},{"line":765,"address":[],"length":0,"stats":{"Line":1}},{"line":766,"address":[],"length":0,"stats":{"Line":1}},{"line":771,"address":[],"length":0,"stats":{"Line":9}},{"line":772,"address":[],"length":0,"stats":{"Line":21}},{"line":773,"address":[],"length":0,"stats":{"Line":3}},{"line":775,"address":[],"length":0,"stats":{"Line":3}},{"line":776,"address":[],"length":0,"stats":{"Line":9}},{"line":777,"address":[],"length":0,"stats":{"Line":6}},{"line":778,"address":[],"length":0,"stats":{"Line":6}},{"line":779,"address":[],"length":0,"stats":{"Line":9}},{"line":780,"address":[],"length":0,"stats":{"Line":9}},{"line":781,"address":[],"length":0,"stats":{"Line":3}},{"line":782,"address":[],"length":0,"stats":{"Line":6}},{"line":783,"address":[],"length":0,"stats":{"Line":3}},{"line":784,"address":[],"length":0,"stats":{"Line":3}},{"line":788,"address":[],"length":0,"stats":{"Line":7}},{"line":799,"address":[],"length":0,"stats":{"Line":14}},{"line":800,"address":[],"length":0,"stats":{"Line":14}},{"line":801,"address":[],"length":0,"stats":{"Line":14}},{"line":802,"address":[],"length":0,"stats":{"Line":14}},{"line":803,"address":[],"length":0,"stats":{"Line":14}},{"line":804,"address":[],"length":0,"stats":{"Line":14}},{"line":805,"address":[],"length":0,"stats":{"Line":7}},{"line":806,"address":[],"length":0,"stats":{"Line":7}},{"line":809,"address":[],"length":0,"stats":{"Line":51}},{"line":810,"address":[],"length":0,"stats":{"Line":56}},{"line":811,"address":[],"length":0,"stats":{"Line":50}},{"line":812,"address":[],"length":0,"stats":{"Line":100}},{"line":813,"address":[],"length":0,"stats":{"Line":25}},{"line":815,"address":[],"length":0,"stats":{"Line":6}},{"line":819,"address":[],"length":0,"stats":{"Line":2}},{"line":822,"address":[],"length":0,"stats":{"Line":3}},{"line":830,"address":[],"length":0,"stats":{"Line":9}},{"line":831,"address":[],"length":0,"stats":{"Line":12}},{"line":832,"address":[],"length":0,"stats":{"Line":3}},{"line":835,"address":[],"length":0,"stats":{"Line":6}},{"line":836,"address":[],"length":0,"stats":{"Line":6}},{"line":837,"address":[],"length":0,"stats":{"Line":3}},{"line":839,"address":[],"length":0,"stats":{"Line":6}},{"line":840,"address":[],"length":0,"stats":{"Line":6}},{"line":841,"address":[],"length":0,"stats":{"Line":9}},{"line":843,"address":[],"length":0,"stats":{"Line":6}},{"line":844,"address":[],"length":0,"stats":{"Line":6}},{"line":845,"address":[],"length":0,"stats":{"Line":9}},{"line":847,"address":[],"length":0,"stats":{"Line":9}},{"line":848,"address":[],"length":0,"stats":{"Line":6}},{"line":849,"address":[],"length":0,"stats":{"Line":6}},{"line":850,"address":[],"length":0,"stats":{"Line":9}},{"line":853,"address":[],"length":0,"stats":{"Line":9}},{"line":854,"address":[],"length":0,"stats":{"Line":6}},{"line":855,"address":[],"length":0,"stats":{"Line":12}},{"line":856,"address":[],"length":0,"stats":{"Line":3}},{"line":858,"address":[],"length":0,"stats":{"Line":3}},{"line":864,"address":[],"length":0,"stats":{"Line":1}},{"line":865,"address":[],"length":0,"stats":{"Line":1}},{"line":868,"address":[],"length":0,"stats":{"Line":1}},{"line":869,"address":[],"length":0,"stats":{"Line":1}},{"line":870,"address":[],"length":0,"stats":{"Line":1}},{"line":873,"address":[],"length":0,"stats":{"Line":1}},{"line":874,"address":[],"length":0,"stats":{"Line":1}},{"line":875,"address":[],"length":0,"stats":{"Line":1}},{"line":876,"address":[],"length":0,"stats":{"Line":1}},{"line":877,"address":[],"length":0,"stats":{"Line":1}},{"line":878,"address":[],"length":0,"stats":{"Line":1}},{"line":879,"address":[],"length":0,"stats":{"Line":1}},{"line":881,"address":[],"length":0,"stats":{"Line":1}},{"line":882,"address":[],"length":0,"stats":{"Line":1}},{"line":883,"address":[],"length":0,"stats":{"Line":1}},{"line":884,"address":[],"length":0,"stats":{"Line":1}},{"line":886,"address":[],"length":0,"stats":{"Line":1}},{"line":887,"address":[],"length":0,"stats":{"Line":1}},{"line":888,"address":[],"length":0,"stats":{"Line":1}},{"line":890,"address":[],"length":0,"stats":{"Line":1}},{"line":891,"address":[],"length":0,"stats":{"Line":1}},{"line":892,"address":[],"length":0,"stats":{"Line":2}},{"line":893,"address":[],"length":0,"stats":{"Line":1}},{"line":895,"address":[],"length":0,"stats":{"Line":2}},{"line":897,"address":[],"length":0,"stats":{"Line":1}},{"line":901,"address":[],"length":0,"stats":{"Line":1}},{"line":902,"address":[],"length":0,"stats":{"Line":0}},{"line":903,"address":[],"length":0,"stats":{"Line":0}},{"line":905,"address":[],"length":0,"stats":{"Line":0}},{"line":906,"address":[],"length":0,"stats":{"Line":0}},{"line":908,"address":[],"length":0,"stats":{"Line":0}},{"line":909,"address":[],"length":0,"stats":{"Line":0}},{"line":910,"address":[],"length":0,"stats":{"Line":0}},{"line":912,"address":[],"length":0,"stats":{"Line":0}},{"line":955,"address":[],"length":0,"stats":{"Line":9}},{"line":962,"address":[],"length":0,"stats":{"Line":0}},{"line":963,"address":[],"length":0,"stats":{"Line":0}},{"line":964,"address":[],"length":0,"stats":{"Line":0}},{"line":967,"address":[],"length":0,"stats":{"Line":1}},{"line":968,"address":[],"length":0,"stats":{"Line":1}},{"line":969,"address":[],"length":0,"stats":{"Line":1}},{"line":970,"address":[],"length":0,"stats":{"Line":1}},{"line":971,"address":[],"length":0,"stats":{"Line":2}},{"line":972,"address":[],"length":0,"stats":{"Line":0}},{"line":973,"address":[],"length":0,"stats":{"Line":0}},{"line":974,"address":[],"length":0,"stats":{"Line":0}},{"line":975,"address":[],"length":0,"stats":{"Line":0}},{"line":976,"address":[],"length":0,"stats":{"Line":0}},{"line":980,"address":[],"length":0,"stats":{"Line":28}},{"line":981,"address":[],"length":0,"stats":{"Line":28}},{"line":982,"address":[],"length":0,"stats":{"Line":10}},{"line":983,"address":[],"length":0,"stats":{"Line":4}},{"line":984,"address":[],"length":0,"stats":{"Line":24}},{"line":985,"address":[],"length":0,"stats":{"Line":14}},{"line":986,"address":[],"length":0,"stats":{"Line":2}},{"line":987,"address":[],"length":0,"stats":{"Line":0}},{"line":988,"address":[],"length":0,"stats":{"Line":2}},{"line":992,"address":[],"length":0,"stats":{"Line":15}},{"line":996,"address":[],"length":0,"stats":{"Line":15}},{"line":997,"address":[],"length":0,"stats":{"Line":2}},{"line":998,"address":[],"length":0,"stats":{"Line":6}},{"line":999,"address":[],"length":0,"stats":{"Line":1}},{"line":1000,"address":[],"length":0,"stats":{"Line":2}},{"line":1001,"address":[],"length":0,"stats":{"Line":1}},{"line":1002,"address":[],"length":0,"stats":{"Line":1}},{"line":1003,"address":[],"length":0,"stats":{"Line":2}},{"line":1007,"address":[],"length":0,"stats":{"Line":11}},{"line":1008,"address":[],"length":0,"stats":{"Line":22}},{"line":1009,"address":[],"length":0,"stats":{"Line":11}},{"line":1011,"address":[],"length":0,"stats":{"Line":31}},{"line":1012,"address":[],"length":0,"stats":{"Line":21}},{"line":1015,"address":[],"length":0,"stats":{"Line":22}},{"line":1016,"address":[],"length":0,"stats":{"Line":11}},{"line":1018,"address":[],"length":0,"stats":{"Line":13}},{"line":1019,"address":[],"length":0,"stats":{"Line":12}},{"line":1022,"address":[],"length":0,"stats":{"Line":22}},{"line":1023,"address":[],"length":0,"stats":{"Line":11}},{"line":1024,"address":[],"length":0,"stats":{"Line":22}},{"line":1025,"address":[],"length":0,"stats":{"Line":33}},{"line":1026,"address":[],"length":0,"stats":{"Line":11}},{"line":1028,"address":[],"length":0,"stats":{"Line":22}},{"line":1029,"address":[],"length":0,"stats":{"Line":11}},{"line":1030,"address":[],"length":0,"stats":{"Line":22}},{"line":1031,"address":[],"length":0,"stats":{"Line":31}},{"line":1032,"address":[],"length":0,"stats":{"Line":13}},{"line":1034,"address":[],"length":0,"stats":{"Line":22}},{"line":1035,"address":[],"length":0,"stats":{"Line":22}},{"line":1036,"address":[],"length":0,"stats":{"Line":22}},{"line":1040,"address":[],"length":0,"stats":{"Line":33}},{"line":1042,"address":[],"length":0,"stats":{"Line":44}},{"line":1044,"address":[],"length":0,"stats":{"Line":11}},{"line":1047,"address":[],"length":0,"stats":{"Line":8}},{"line":1054,"address":[],"length":0,"stats":{"Line":24}},{"line":1055,"address":[],"length":0,"stats":{"Line":16}},{"line":1056,"address":[],"length":0,"stats":{"Line":24}},{"line":1057,"address":[],"length":0,"stats":{"Line":8}},{"line":1059,"address":[],"length":0,"stats":{"Line":16}},{"line":1060,"address":[],"length":0,"stats":{"Line":24}},{"line":1062,"address":[],"length":0,"stats":{"Line":28}},{"line":1063,"address":[],"length":0,"stats":{"Line":30}},{"line":1065,"address":[],"length":0,"stats":{"Line":10}},{"line":1066,"address":[],"length":0,"stats":{"Line":15}},{"line":1067,"address":[],"length":0,"stats":{"Line":14}},{"line":1068,"address":[],"length":0,"stats":{"Line":1}},{"line":1070,"address":[],"length":0,"stats":{"Line":18}},{"line":1071,"address":[],"length":0,"stats":{"Line":6}},{"line":1072,"address":[],"length":0,"stats":{"Line":18}},{"line":1073,"address":[],"length":0,"stats":{"Line":6}},{"line":1074,"address":[],"length":0,"stats":{"Line":12}},{"line":1075,"address":[],"length":0,"stats":{"Line":12}},{"line":1076,"address":[],"length":0,"stats":{"Line":6}},{"line":1078,"address":[],"length":0,"stats":{"Line":12}},{"line":1079,"address":[],"length":0,"stats":{"Line":12}},{"line":1080,"address":[],"length":0,"stats":{"Line":18}},{"line":1082,"address":[],"length":0,"stats":{"Line":6}},{"line":1083,"address":[],"length":0,"stats":{"Line":6}},{"line":1084,"address":[],"length":0,"stats":{"Line":24}},{"line":1085,"address":[],"length":0,"stats":{"Line":12}},{"line":1086,"address":[],"length":0,"stats":{"Line":12}},{"line":1087,"address":[],"length":0,"stats":{"Line":18}},{"line":1090,"address":[],"length":0,"stats":{"Line":18}},{"line":1091,"address":[],"length":0,"stats":{"Line":12}},{"line":1092,"address":[],"length":0,"stats":{"Line":24}},{"line":1093,"address":[],"length":0,"stats":{"Line":6}},{"line":1094,"address":[],"length":0,"stats":{"Line":6}},{"line":1097,"address":[],"length":0,"stats":{"Line":21}},{"line":1098,"address":[],"length":0,"stats":{"Line":21}},{"line":1099,"address":[],"length":0,"stats":{"Line":14}},{"line":1100,"address":[],"length":0,"stats":{"Line":14}},{"line":1101,"address":[],"length":0,"stats":{"Line":21}},{"line":1102,"address":[],"length":0,"stats":{"Line":7}},{"line":1108,"address":[],"length":0,"stats":{"Line":8}},{"line":1109,"address":[],"length":0,"stats":{"Line":24}},{"line":1110,"address":[],"length":0,"stats":{"Line":24}},{"line":1111,"address":[],"length":0,"stats":{"Line":24}},{"line":1112,"address":[],"length":0,"stats":{"Line":16}},{"line":1113,"address":[],"length":0,"stats":{"Line":8}},{"line":1114,"address":[],"length":0,"stats":{"Line":8}},{"line":1121,"address":[],"length":0,"stats":{"Line":1}},{"line":1122,"address":[],"length":0,"stats":{"Line":1}},{"line":1125,"address":[],"length":0,"stats":{"Line":1}},{"line":1126,"address":[],"length":0,"stats":{"Line":1}},{"line":1127,"address":[],"length":0,"stats":{"Line":1}},{"line":1128,"address":[],"length":0,"stats":{"Line":1}},{"line":1131,"address":[],"length":0,"stats":{"Line":1}},{"line":1132,"address":[],"length":0,"stats":{"Line":1}},{"line":1133,"address":[],"length":0,"stats":{"Line":1}},{"line":1134,"address":[],"length":0,"stats":{"Line":1}},{"line":1135,"address":[],"length":0,"stats":{"Line":1}},{"line":1136,"address":[],"length":0,"stats":{"Line":1}},{"line":1137,"address":[],"length":0,"stats":{"Line":1}},{"line":1138,"address":[],"length":0,"stats":{"Line":1}},{"line":1140,"address":[],"length":0,"stats":{"Line":1}},{"line":1141,"address":[],"length":0,"stats":{"Line":1}},{"line":1142,"address":[],"length":0,"stats":{"Line":1}},{"line":1143,"address":[],"length":0,"stats":{"Line":1}},{"line":1144,"address":[],"length":0,"stats":{"Line":1}},{"line":1145,"address":[],"length":0,"stats":{"Line":1}},{"line":1147,"address":[],"length":0,"stats":{"Line":1}},{"line":1148,"address":[],"length":0,"stats":{"Line":1}},{"line":1149,"address":[],"length":0,"stats":{"Line":1}},{"line":1150,"address":[],"length":0,"stats":{"Line":1}},{"line":1152,"address":[],"length":0,"stats":{"Line":2}},{"line":1154,"address":[],"length":0,"stats":{"Line":1}},{"line":1158,"address":[],"length":0,"stats":{"Line":1}},{"line":1186,"address":[],"length":0,"stats":{"Line":0}},{"line":1193,"address":[],"length":0,"stats":{"Line":0}},{"line":1194,"address":[],"length":0,"stats":{"Line":0}},{"line":1197,"address":[],"length":0,"stats":{"Line":0}},{"line":1198,"address":[],"length":0,"stats":{"Line":0}},{"line":1201,"address":[],"length":0,"stats":{"Line":0}},{"line":1202,"address":[],"length":0,"stats":{"Line":0}},{"line":1203,"address":[],"length":0,"stats":{"Line":0}},{"line":1204,"address":[],"length":0,"stats":{"Line":0}},{"line":1205,"address":[],"length":0,"stats":{"Line":0}},{"line":1206,"address":[],"length":0,"stats":{"Line":0}},{"line":1207,"address":[],"length":0,"stats":{"Line":0}},{"line":1209,"address":[],"length":0,"stats":{"Line":0}},{"line":1213,"address":[],"length":0,"stats":{"Line":0}},{"line":1244,"address":[],"length":0,"stats":{"Line":0}},{"line":1251,"address":[],"length":0,"stats":{"Line":0}},{"line":1252,"address":[],"length":0,"stats":{"Line":0}},{"line":1255,"address":[],"length":0,"stats":{"Line":0}},{"line":1256,"address":[],"length":0,"stats":{"Line":0}},{"line":1259,"address":[],"length":0,"stats":{"Line":0}},{"line":1260,"address":[],"length":0,"stats":{"Line":0}},{"line":1261,"address":[],"length":0,"stats":{"Line":0}},{"line":1262,"address":[],"length":0,"stats":{"Line":0}},{"line":1263,"address":[],"length":0,"stats":{"Line":0}},{"line":1264,"address":[],"length":0,"stats":{"Line":0}},{"line":1265,"address":[],"length":0,"stats":{"Line":0}},{"line":1267,"address":[],"length":0,"stats":{"Line":0}},{"line":1271,"address":[],"length":0,"stats":{"Line":0}},{"line":1282,"address":[],"length":0,"stats":{"Line":0}},{"line":1283,"address":[],"length":0,"stats":{"Line":0}},{"line":1284,"address":[],"length":0,"stats":{"Line":0}},{"line":1285,"address":[],"length":0,"stats":{"Line":0}},{"line":1316,"address":[],"length":0,"stats":{"Line":0}},{"line":1323,"address":[],"length":0,"stats":{"Line":0}},{"line":1324,"address":[],"length":0,"stats":{"Line":0}},{"line":1327,"address":[],"length":0,"stats":{"Line":0}},{"line":1328,"address":[],"length":0,"stats":{"Line":0}},{"line":1331,"address":[],"length":0,"stats":{"Line":0}},{"line":1332,"address":[],"length":0,"stats":{"Line":0}},{"line":1333,"address":[],"length":0,"stats":{"Line":0}},{"line":1334,"address":[],"length":0,"stats":{"Line":0}},{"line":1335,"address":[],"length":0,"stats":{"Line":0}},{"line":1336,"address":[],"length":0,"stats":{"Line":0}},{"line":1337,"address":[],"length":0,"stats":{"Line":0}},{"line":1338,"address":[],"length":0,"stats":{"Line":0}},{"line":1340,"address":[],"length":0,"stats":{"Line":0}},{"line":1344,"address":[],"length":0,"stats":{"Line":0}}],"covered":387,"coverable":459},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","opencode.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","orchestrator.rs"],"content":"use std::collections::HashMap;\nuse std::sync::Arc;\n\nuse serde_json::{Value, json};\n\nuse crate::extensions::{ExtensionError, ExtensionExecutor, ExtensionMessage};\nuse crate::tools::ToolRegistry;\nuse mk_core::types::TenantContext;\n\n#[derive(Debug, Clone, PartialEq)]\npub struct ToolCall {\n    pub name: String,\n    pub arguments: Value,\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub struct ToolExecution {\n    pub name: String,\n    pub arguments: Value,\n    pub result: Value,\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub struct OrchestratorResult {\n    pub output: String,\n    pub tool_calls: Vec<ToolCall>,\n    pub tool_results: Vec<ToolExecution>,\n}\n\n#[derive(Debug, thiserror::Error)]\npub enum OrchestratorError {\n    #[error(\"Extension error: {0}\")]\n    Extension(#[from] ExtensionError),\n\n    #[error(\"Tool error: {0}\")]\n    Tool(String),\n}\n\n#[derive(Debug, Clone)]\npub struct ToolOrchestrator {\n    tool_registry: Arc<ToolRegistry>,\n    extension_executor: Option<Arc<ExtensionExecutor>>,\n}\n\nimpl ToolOrchestrator {\n    pub fn new(tool_registry: Arc<ToolRegistry>) -> Self {\n        Self {\n            tool_registry,\n            extension_executor: None,\n        }\n    }\n\n    pub fn with_extension_executor(mut self, executor: Arc<ExtensionExecutor>) -> Self {\n        self.extension_executor = Some(executor);\n        self\n    }\n\n    pub async fn process_messages(\n        &self,\n        ctx: TenantContext,\n        session_id: &str,\n        messages: Vec<ExtensionMessage>,\n    ) -> Result<Vec<ExtensionMessage>, OrchestratorError> {\n        let mut current = messages;\n        if let Some(executor) = &self.extension_executor {\n            current = executor\n                .on_input_messages(ctx, session_id, self.tool_registry.clone(), current)\n                .await?;\n            current = apply_prompt_wiring(executor, current);\n        }\n        Ok(current)\n    }\n\n    pub async fn process_plain_text(\n        &self,\n        ctx: TenantContext,\n        session_id: &str,\n        text: String,\n    ) -> Result<String, OrchestratorError> {\n        let mut current = text;\n        if let Some(executor) = &self.extension_executor {\n            current = executor\n                .on_plain_text(ctx, session_id, self.tool_registry.clone(), current)\n                .await?;\n            current = apply_prompt_wiring(\n                executor,\n                vec![ExtensionMessage {\n                    role: \"user\".to_string(),\n                    content: current,\n                }],\n            )\n            .into_iter()\n            .map(|message| message.content)\n            .collect::<Vec<_>>()\n            .join(\"\\n\");\n        }\n        Ok(current)\n    }\n\n    pub fn prompt_wiring(&self) -> Option<crate::extensions::PromptWiring> {\n        self.extension_executor\n            .as_ref()\n            .map(|executor| executor.prompt_wiring())\n    }\n\n    pub async fn route_llm_output(\n        &self,\n        ctx: TenantContext,\n        session_id: &str,\n        output: String,\n    ) -> Result<OrchestratorResult, OrchestratorError> {\n        let mut output = output;\n        if let Some(executor) = &self.extension_executor {\n            output = executor\n                .on_llm_output(ctx.clone(), session_id, self.tool_registry.clone(), output)\n                .await?;\n        }\n\n        let (output, tool_calls) = self\n            .extract_tool_calls(ctx.clone(), session_id, &output)\n            .await?;\n\n        if let Some(executor) = &self.extension_executor {\n            let wiring = executor.prompt_wiring();\n            let routed_calls =\n                apply_tool_config(tool_calls, &wiring.tool_config, &wiring.sequencing_hints);\n            let tool_results = self\n                .execute_tools(routed_calls.clone())\n                .await\n                .map_err(OrchestratorError::Tool)?;\n            return Ok(OrchestratorResult {\n                output,\n                tool_calls: routed_calls,\n                tool_results,\n            });\n        }\n\n        let tool_results = self\n            .execute_tools(tool_calls.clone())\n            .await\n            .map_err(OrchestratorError::Tool)?;\n\n        Ok(OrchestratorResult {\n            output,\n            tool_calls,\n            tool_results,\n        })\n    }\n\n    async fn extract_tool_calls(\n        &self,\n        ctx: TenantContext,\n        session_id: &str,\n        output: &str,\n    ) -> Result<(String, Vec<ToolCall>), OrchestratorError> {\n        let tags = parse_tags(output);\n        if tags.is_empty() {\n            return Ok((output.to_string(), Vec::new()));\n        }\n\n        let mut updated_output = output.to_string();\n        let mut tool_calls = Vec::new();\n\n        for tag in tags.iter().rev() {\n            let content = &output[tag.content_start..tag.content_end];\n            let updated_content = if let Some(executor) = &self.extension_executor {\n                match executor\n                    .on_tag(\n                        ctx.clone(),\n                        session_id,\n                        self.tool_registry.clone(),\n                        tag.name.clone(),\n                        content.to_string(),\n                    )\n                    .await\n                {\n                    Ok(result) => result,\n                    Err(_) => content.to_string(),\n                }\n            } else {\n                content.to_string()\n            };\n\n            if tag.name == \"tool\" {\n                if let Some(call) = parse_tool_call(tag, &updated_content) {\n                    tool_calls.push(call);\n                }\n            }\n\n            updated_output.replace_range(tag.start..tag.end, &updated_content);\n        }\n\n        tool_calls.reverse();\n        Ok((updated_output, tool_calls))\n    }\n\n    async fn execute_tools(&self, calls: Vec<ToolCall>) -> Result<Vec<ToolExecution>, String> {\n        let mut results = Vec::new();\n        for call in calls {\n            let result = self\n                .tool_registry\n                .call(&call.name, call.arguments.clone())\n                .await\n                .map_err(|err| err.to_string())?;\n            results.push(ToolExecution {\n                name: call.name,\n                arguments: call.arguments,\n                result,\n            });\n        }\n        Ok(results)\n    }\n}\n\nfn apply_prompt_wiring(\n    executor: &ExtensionExecutor,\n    messages: Vec<ExtensionMessage>,\n) -> Vec<ExtensionMessage> {\n    let wiring = executor.prompt_wiring();\n    if wiring.additions.is_empty() {\n        return messages;\n    }\n    let mut additions = wiring\n        .additions\n        .into_iter()\n        .map(|addition| ExtensionMessage {\n            role: addition.role,\n            content: addition.content,\n        })\n        .collect::<Vec<_>>();\n    additions.extend(messages.into_iter());\n    additions\n}\n\nfn apply_tool_config(\n    mut calls: Vec<ToolCall>,\n    config: &crate::extensions::ToolConfig,\n    sequencing_hints: &[crate::extensions::ToolSequenceHint],\n) -> Vec<ToolCall> {\n    for call in calls.iter_mut() {\n        if let Some(replacement) = config.overrides.get(&call.name) {\n            call.name = replacement.clone();\n        }\n    }\n\n    calls.retain(|call| !config.disabled_tools.contains(&call.name));\n\n    if !config.suggested_tools.is_empty() {\n        let order: HashMap<_, _> = config\n            .suggested_tools\n            .iter()\n            .enumerate()\n            .map(|(idx, name)| (name.clone(), idx))\n            .collect();\n        calls.sort_by_key(|call| order.get(&call.name).cloned().unwrap_or(usize::MAX));\n    }\n\n    for hint in sequencing_hints {\n        let has_when = calls.iter().any(|call| call.name == hint.when_tool);\n        let has_next = calls.iter().any(|call| call.name == hint.suggest_next);\n        if has_when && !has_next && !config.disabled_tools.contains(&hint.suggest_next) {\n            calls.push(ToolCall {\n                name: hint.suggest_next.clone(),\n                arguments: json!({}),\n            });\n        }\n    }\n\n    calls\n}\n\n#[cfg(test)]\nimpl ToolOrchestrator {\n    fn new_without_extensions(tool_registry: Arc<ToolRegistry>) -> Self {\n        Self {\n            tool_registry,\n            extension_executor: None,\n        }\n    }\n}\n\n#[derive(Debug, Clone, PartialEq)]\nstruct TagSegment {\n    name: String,\n    attributes: HashMap<String, String>,\n    start: usize,\n    end: usize,\n    content_start: usize,\n    content_end: usize,\n}\n\nfn parse_tags(input: &str) -> Vec<TagSegment> {\n    let mut segments = Vec::new();\n    let mut stack: Vec<(String, HashMap<String, String>, usize, usize)> = Vec::new();\n    let bytes = input.as_bytes();\n    let mut idx = 0;\n\n    while idx < bytes.len() {\n        if bytes[idx] != b'<' {\n            idx += 1;\n            continue;\n        }\n        let close = match input[idx..].find('>') {\n            Some(pos) => idx + pos,\n            None => break,\n        };\n        let tag_body = &input[idx + 1..close];\n        if let Some(rest) = tag_body.strip_prefix('/') {\n            let name = rest.trim().to_string();\n            if let Some(pos) = stack.iter().rposition(|(n, _, _, _)| n == &name) {\n                let (start_name, attrs, start_idx, content_start) = stack.remove(pos);\n                segments.push(TagSegment {\n                    name: start_name,\n                    attributes: attrs,\n                    start: start_idx,\n                    end: close + 1,\n                    content_start,\n                    content_end: idx,\n                });\n            }\n        } else {\n            let (name, attrs) = parse_tag_open(tag_body);\n            if !name.is_empty() {\n                stack.push((name, attrs, idx, close + 1));\n            }\n        }\n        idx = close + 1;\n    }\n\n    segments.sort_by_key(|s| s.start);\n    segments\n}\n\nfn parse_tag_open(tag_body: &str) -> (String, HashMap<String, String>) {\n    let mut parts = tag_body.split_whitespace();\n    let name = parts.next().unwrap_or(\"\").trim().to_string();\n    let mut attrs = HashMap::new();\n    for part in parts {\n        if let Some((key, value)) = part.split_once('=') {\n            let value = value.trim().trim_matches('\"').trim_matches('\\'');\n            attrs.insert(key.to_string(), value.to_string());\n        }\n    }\n    (name, attrs)\n}\n\nfn parse_tool_call(tag: &TagSegment, content: &str) -> Option<ToolCall> {\n    let name = tag.attributes.get(\"name\").cloned().unwrap_or_default();\n    if name.is_empty() {\n        return None;\n    }\n\n    let arguments = if content.trim().is_empty() {\n        serde_json::json!({})\n    } else {\n        serde_json::from_str::<Value>(content)\n            .unwrap_or_else(|_| serde_json::json!({\"input\": content}))\n    };\n\n    Some(ToolCall { name, arguments })\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use async_trait::async_trait;\n\n    struct EchoTool;\n\n    #[async_trait]\n    impl crate::tools::Tool for EchoTool {\n        fn name(&self) -> &str {\n            \"echo\"\n        }\n\n        fn description(&self) -> &str {\n            \"echo\"\n        }\n\n        fn input_schema(&self) -> Value {\n            serde_json::json!({})\n        }\n\n        async fn call(\n            &self,\n            params: Value,\n        ) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n            Ok(serde_json::json!({\"echo\": params}))\n        }\n    }\n\n    struct UpperTag;\n\n    #[async_trait]\n    impl crate::extensions::ExtensionCallback for UpperTag {\n        async fn on_tag(\n            &self,\n            _ctx: &mut crate::extensions::ExtensionContext,\n            _tag: String,\n            content: String,\n        ) -> Result<String, ExtensionError> {\n            Ok(format!(\"\\\"{}\\\"\", content.to_uppercase()))\n        }\n    }\n\n    struct ReplaceOutput;\n\n    #[async_trait]\n    impl crate::extensions::ExtensionCallback for ReplaceOutput {\n        async fn on_llm_output(\n            &self,\n            _ctx: &mut crate::extensions::ExtensionContext,\n            output: String,\n        ) -> Result<String, ExtensionError> {\n            Ok(format!(\n                r#\"{output}<tool name=\"echo\">{{\"value\":\"ok\"}}</tool>\"#\n            ))\n        }\n    }\n\n    fn registry_with_echo() -> Arc<ToolRegistry> {\n        let mut registry = ToolRegistry::new();\n        registry.register(Box::new(EchoTool));\n        Arc::new(registry)\n    }\n\n    #[test]\n    fn test_parse_tags_with_attributes() {\n        let input = \"<tool name=\\\"echo\\\" arg=\\\"1\\\">data</tool>\";\n        let tags = parse_tags(input);\n        assert_eq!(tags.len(), 1);\n        assert_eq!(tags[0].name, \"tool\");\n        assert_eq!(tags[0].attributes.get(\"name\").unwrap(), \"echo\");\n        assert_eq!(tags[0].attributes.get(\"arg\").unwrap(), \"1\");\n    }\n\n    #[tokio::test]\n    async fn test_parse_and_execute_tool_call() {\n        let registry = registry_with_echo();\n        let orchestrator = ToolOrchestrator::new_without_extensions(registry.clone());\n        let output = \"<tool name=\\\"echo\\\">{\\\"value\\\":\\\"ok\\\"}</tool>\".to_string();\n\n        let result = orchestrator\n            .route_llm_output(TenantContext::default(), \"s\", output)\n            .await\n            .unwrap();\n\n        assert_eq!(result.tool_results.len(), 1);\n        assert_eq!(result.tool_results[0].result[\"echo\"][\"value\"], \"ok\");\n    }\n\n    #[tokio::test]\n    async fn test_extension_tool_override() {\n        let registry = registry_with_echo();\n        let mut extension_registry = crate::extensions::ExtensionRegistry::new();\n        let mut config = crate::extensions::ToolConfig::default();\n        config\n            .overrides\n            .insert(\"alias\".to_string(), \"echo\".to_string());\n        extension_registry\n            .register_extension(\n                crate::extensions::ExtensionRegistration::new(\n                    \"ext\",\n                    Arc::new(extension_test_helpers::NoopCallback::default()),\n                )\n                .with_tool_config(config),\n            )\n            .unwrap();\n\n        let executor = Arc::new(ExtensionExecutor::new(Arc::new(extension_registry)));\n        let orchestrator =\n            ToolOrchestrator::new(registry.clone()).with_extension_executor(executor);\n        let output = \"<tool name=\\\"alias\\\">{\\\"value\\\":\\\"ok\\\"}</tool>\".to_string();\n\n        let result = orchestrator\n            .route_llm_output(TenantContext::default(), \"s\", output)\n            .await\n            .unwrap();\n\n        assert_eq!(result.tool_results.len(), 1);\n        assert_eq!(result.tool_results[0].name, \"echo\");\n    }\n\n    #[tokio::test]\n    async fn test_extension_tag_transformation() {\n        let registry = registry_with_echo();\n        let mut extension_registry = crate::extensions::ExtensionRegistry::new();\n        extension_registry\n            .register_extension(crate::extensions::ExtensionRegistration::new(\n                \"ext\",\n                Arc::new(UpperTag),\n            ))\n            .unwrap();\n\n        let executor = Arc::new(ExtensionExecutor::new(Arc::new(extension_registry)));\n        let orchestrator =\n            ToolOrchestrator::new(registry.clone()).with_extension_executor(executor);\n        let output = \"<tool name=\\\"echo\\\">hello</tool>\".to_string();\n\n        let result = orchestrator\n            .route_llm_output(TenantContext::default(), \"s\", output)\n            .await\n            .unwrap();\n\n        assert_eq!(result.tool_results.len(), 1);\n        // UpperTag transforms \"hello\" to \"\\\"HELLO\\\"\", which parses as JSON string\n        // \"HELLO\" EchoTool returns {\"echo\": <params>}, so result is {\"echo\":\n        // \"HELLO\"}\n        assert_eq!(result.tool_results[0].result[\"echo\"], \"HELLO\");\n    }\n\n    #[tokio::test]\n    async fn test_extension_llm_output_callback() {\n        let registry = registry_with_echo();\n        let mut extension_registry = crate::extensions::ExtensionRegistry::new();\n        extension_registry\n            .register_extension(crate::extensions::ExtensionRegistration::new(\n                \"ext\",\n                Arc::new(ReplaceOutput),\n            ))\n            .unwrap();\n\n        let executor = Arc::new(ExtensionExecutor::new(Arc::new(extension_registry)));\n        let orchestrator =\n            ToolOrchestrator::new(registry.clone()).with_extension_executor(executor);\n\n        let result = orchestrator\n            .route_llm_output(TenantContext::default(), \"s\", \"result\".to_string())\n            .await\n            .unwrap();\n\n        assert_eq!(result.tool_results.len(), 1);\n        assert_eq!(result.tool_results[0].result[\"echo\"][\"value\"], \"ok\");\n    }\n\n    #[test]\n    fn test_parse_tags_nested() {\n        let input = \"<a>outer <b>inner</b></a>\";\n        let tags = parse_tags(input);\n        assert_eq!(tags.len(), 2);\n        // Tags are sorted by start position, so 'a' (starts at 0) comes before 'b'\n        // (starts at 10)\n        assert_eq!(tags[0].name, \"a\");\n        assert_eq!(tags[1].name, \"b\");\n        assert_eq!(&input[tags[1].content_start..tags[1].content_end], \"inner\");\n    }\n\n    #[test]\n    fn test_apply_tool_config_sequence_hint() {\n        let calls = vec![ToolCall {\n            name: \"a\".to_string(),\n            arguments: serde_json::json!({}),\n        }];\n        let config = crate::extensions::ToolConfig::default();\n        let hints = vec![crate::extensions::ToolSequenceHint {\n            when_tool: \"a\".to_string(),\n            suggest_next: \"b\".to_string(),\n        }];\n\n        let result = apply_tool_config(calls, &config, &hints);\n        assert_eq!(result.len(), 2);\n        assert!(result.iter().any(|call| call.name == \"b\"));\n    }\n\n    mod extension_test_helpers {\n        use super::*;\n\n        #[derive(Default)]\n        pub struct NoopCallback;\n\n        #[async_trait]\n        impl crate::extensions::ExtensionCallback for NoopCallback {}\n    }\n}\n","traces":[{"line":46,"address":[],"length":0,"stats":{"Line":3}},{"line":53,"address":[],"length":0,"stats":{"Line":3}},{"line":54,"address":[],"length":0,"stats":{"Line":6}},{"line":55,"address":[],"length":0,"stats":{"Line":3}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":4}},{"line":112,"address":[],"length":0,"stats":{"Line":8}},{"line":113,"address":[],"length":0,"stats":{"Line":7}},{"line":114,"address":[],"length":0,"stats":{"Line":9}},{"line":115,"address":[],"length":0,"stats":{"Line":18}},{"line":116,"address":[],"length":0,"stats":{"Line":3}},{"line":119,"address":[],"length":0,"stats":{"Line":16}},{"line":120,"address":[],"length":0,"stats":{"Line":20}},{"line":121,"address":[],"length":0,"stats":{"Line":4}},{"line":123,"address":[],"length":0,"stats":{"Line":7}},{"line":124,"address":[],"length":0,"stats":{"Line":6}},{"line":125,"address":[],"length":0,"stats":{"Line":3}},{"line":126,"address":[],"length":0,"stats":{"Line":12}},{"line":127,"address":[],"length":0,"stats":{"Line":9}},{"line":128,"address":[],"length":0,"stats":{"Line":9}},{"line":129,"address":[],"length":0,"stats":{"Line":3}},{"line":130,"address":[],"length":0,"stats":{"Line":3}},{"line":131,"address":[],"length":0,"stats":{"Line":3}},{"line":132,"address":[],"length":0,"stats":{"Line":6}},{"line":133,"address":[],"length":0,"stats":{"Line":3}},{"line":134,"address":[],"length":0,"stats":{"Line":3}},{"line":138,"address":[],"length":0,"stats":{"Line":3}},{"line":139,"address":[],"length":0,"stats":{"Line":3}},{"line":140,"address":[],"length":0,"stats":{"Line":1}},{"line":141,"address":[],"length":0,"stats":{"Line":1}},{"line":143,"address":[],"length":0,"stats":{"Line":1}},{"line":144,"address":[],"length":0,"stats":{"Line":2}},{"line":145,"address":[],"length":0,"stats":{"Line":1}},{"line":146,"address":[],"length":0,"stats":{"Line":1}},{"line":150,"address":[],"length":0,"stats":{"Line":4}},{"line":156,"address":[],"length":0,"stats":{"Line":12}},{"line":157,"address":[],"length":0,"stats":{"Line":8}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":12}},{"line":162,"address":[],"length":0,"stats":{"Line":8}},{"line":164,"address":[],"length":0,"stats":{"Line":12}},{"line":165,"address":[],"length":0,"stats":{"Line":12}},{"line":166,"address":[],"length":0,"stats":{"Line":11}},{"line":167,"address":[],"length":0,"stats":{"Line":6}},{"line":168,"address":[],"length":0,"stats":{"Line":6}},{"line":169,"address":[],"length":0,"stats":{"Line":9}},{"line":170,"address":[],"length":0,"stats":{"Line":6}},{"line":171,"address":[],"length":0,"stats":{"Line":9}},{"line":172,"address":[],"length":0,"stats":{"Line":9}},{"line":173,"address":[],"length":0,"stats":{"Line":3}},{"line":175,"address":[],"length":0,"stats":{"Line":3}},{"line":177,"address":[],"length":0,"stats":{"Line":6}},{"line":178,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":2}},{"line":184,"address":[],"length":0,"stats":{"Line":4}},{"line":185,"address":[],"length":0,"stats":{"Line":16}},{"line":186,"address":[],"length":0,"stats":{"Line":8}},{"line":190,"address":[],"length":0,"stats":{"Line":16}},{"line":193,"address":[],"length":0,"stats":{"Line":4}},{"line":194,"address":[],"length":0,"stats":{"Line":4}},{"line":197,"address":[],"length":0,"stats":{"Line":8}},{"line":198,"address":[],"length":0,"stats":{"Line":8}},{"line":199,"address":[],"length":0,"stats":{"Line":12}},{"line":200,"address":[],"length":0,"stats":{"Line":12}},{"line":201,"address":[],"length":0,"stats":{"Line":8}},{"line":202,"address":[],"length":0,"stats":{"Line":12}},{"line":203,"address":[],"length":0,"stats":{"Line":4}},{"line":204,"address":[],"length":0,"stats":{"Line":4}},{"line":205,"address":[],"length":0,"stats":{"Line":12}},{"line":206,"address":[],"length":0,"stats":{"Line":8}},{"line":207,"address":[],"length":0,"stats":{"Line":4}},{"line":208,"address":[],"length":0,"stats":{"Line":4}},{"line":211,"address":[],"length":0,"stats":{"Line":4}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":0}},{"line":221,"address":[],"length":0,"stats":{"Line":0}},{"line":223,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":231,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":235,"address":[],"length":0,"stats":{"Line":4}},{"line":240,"address":[],"length":0,"stats":{"Line":12}},{"line":241,"address":[],"length":0,"stats":{"Line":10}},{"line":242,"address":[],"length":0,"stats":{"Line":2}},{"line":246,"address":[],"length":0,"stats":{"Line":16}},{"line":248,"address":[],"length":0,"stats":{"Line":4}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":0}},{"line":255,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":6}},{"line":259,"address":[],"length":0,"stats":{"Line":5}},{"line":260,"address":[],"length":0,"stats":{"Line":5}},{"line":261,"address":[],"length":0,"stats":{"Line":5}},{"line":262,"address":[],"length":0,"stats":{"Line":3}},{"line":263,"address":[],"length":0,"stats":{"Line":2}},{"line":264,"address":[],"length":0,"stats":{"Line":1}},{"line":269,"address":[],"length":0,"stats":{"Line":4}},{"line":292,"address":[],"length":0,"stats":{"Line":6}},{"line":293,"address":[],"length":0,"stats":{"Line":12}},{"line":294,"address":[],"length":0,"stats":{"Line":18}},{"line":295,"address":[],"length":0,"stats":{"Line":18}},{"line":296,"address":[],"length":0,"stats":{"Line":12}},{"line":298,"address":[],"length":0,"stats":{"Line":176}},{"line":299,"address":[],"length":0,"stats":{"Line":82}},{"line":300,"address":[],"length":0,"stats":{"Line":68}},{"line":301,"address":[],"length":0,"stats":{"Line":68}},{"line":303,"address":[],"length":0,"stats":{"Line":28}},{"line":304,"address":[],"length":0,"stats":{"Line":28}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":42}},{"line":308,"address":[],"length":0,"stats":{"Line":21}},{"line":309,"address":[],"length":0,"stats":{"Line":21}},{"line":310,"address":[],"length":0,"stats":{"Line":42}},{"line":311,"address":[],"length":0,"stats":{"Line":49}},{"line":312,"address":[],"length":0,"stats":{"Line":21}},{"line":313,"address":[],"length":0,"stats":{"Line":14}},{"line":314,"address":[],"length":0,"stats":{"Line":14}},{"line":315,"address":[],"length":0,"stats":{"Line":14}},{"line":316,"address":[],"length":0,"stats":{"Line":14}},{"line":317,"address":[],"length":0,"stats":{"Line":7}},{"line":318,"address":[],"length":0,"stats":{"Line":7}},{"line":322,"address":[],"length":0,"stats":{"Line":21}},{"line":323,"address":[],"length":0,"stats":{"Line":14}},{"line":324,"address":[],"length":0,"stats":{"Line":35}},{"line":327,"address":[],"length":0,"stats":{"Line":14}},{"line":330,"address":[],"length":0,"stats":{"Line":12}},{"line":331,"address":[],"length":0,"stats":{"Line":6}},{"line":334,"address":[],"length":0,"stats":{"Line":7}},{"line":335,"address":[],"length":0,"stats":{"Line":21}},{"line":336,"address":[],"length":0,"stats":{"Line":35}},{"line":337,"address":[],"length":0,"stats":{"Line":14}},{"line":338,"address":[],"length":0,"stats":{"Line":19}},{"line":339,"address":[],"length":0,"stats":{"Line":24}},{"line":340,"address":[],"length":0,"stats":{"Line":24}},{"line":341,"address":[],"length":0,"stats":{"Line":30}},{"line":344,"address":[],"length":0,"stats":{"Line":7}},{"line":347,"address":[],"length":0,"stats":{"Line":4}},{"line":348,"address":[],"length":0,"stats":{"Line":24}},{"line":349,"address":[],"length":0,"stats":{"Line":8}},{"line":350,"address":[],"length":0,"stats":{"Line":0}},{"line":353,"address":[],"length":0,"stats":{"Line":12}},{"line":354,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":8}},{"line":357,"address":[],"length":0,"stats":{"Line":4}},{"line":360,"address":[],"length":0,"stats":{"Line":4}}],"covered":129,"coverable":176},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","pointer.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","policy_tools.rs"],"content":"//! # Policy Tools\n//!\n//! MCP tools for policy management: propose, approve, reject, list.\n\nuse crate::policy_translator::{\n    DraftStatus, PolicyDraft, PolicyScope, PolicySeverity, PolicyTranslatorError, StructuredIntent,\n    ValidationResult,\n};\nuse crate::tools::Tool;\nuse async_trait::async_trait;\nuse chrono::{DateTime, Utc};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Value, json};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse storage::approval_workflow::{\n    ApprovalEvent, ApprovalModeKind, ApprovalWorkflow, ApprovalWorkflowContext, RiskLevelKind,\n    WorkflowState,\n};\nuse tokio::sync::RwLock;\nuse uuid::Uuid;\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PolicyProposal {\n    pub proposal_id: String,\n    pub draft_id: String,\n    pub name: String,\n    pub cedar: String,\n    pub scope: PolicyScope,\n    pub severity: PolicySeverity,\n    pub intent: StructuredIntent,\n    pub justification: Option<String>,\n    pub proposed_by: String,\n    pub proposed_at: DateTime<Utc>,\n    pub workflow: ApprovalWorkflow,\n    pub notified_approvers: Vec<String>,\n    pub expires_at: DateTime<Utc>,\n}\n\npub trait PolicyProposalStorage: Send + Sync {\n    fn store_proposal(\n        &self,\n        proposal: PolicyProposal,\n    ) -> impl std::future::Future<Output = Result<(), PolicyToolError>> + Send;\n\n    fn get_proposal(\n        &self,\n        proposal_id: &str,\n    ) -> impl std::future::Future<Output = Result<Option<PolicyProposal>, PolicyToolError>> + Send;\n\n    fn get_proposal_by_draft(\n        &self,\n        draft_id: &str,\n    ) -> impl std::future::Future<Output = Result<Option<PolicyProposal>, PolicyToolError>> + Send;\n\n    fn update_proposal(\n        &self,\n        proposal: PolicyProposal,\n    ) -> impl std::future::Future<Output = Result<(), PolicyToolError>> + Send;\n\n    fn list_pending(\n        &self,\n        scope: Option<PolicyScope>,\n    ) -> impl std::future::Future<Output = Result<Vec<PolicyProposal>, PolicyToolError>> + Send;\n\n    fn get_draft(\n        &self,\n        draft_id: &str,\n    ) -> impl std::future::Future<Output = Result<Option<PolicyDraft>, PolicyToolError>> + Send;\n}\n\n#[derive(Debug, Clone, thiserror::Error)]\npub enum PolicyToolError {\n    #[error(\"Draft not found: {0}\")]\n    DraftNotFound(String),\n\n    #[error(\"Proposal not found: {0}\")]\n    ProposalNotFound(String),\n\n    #[error(\"Draft not validated: {0}\")]\n    DraftNotValidated(String),\n\n    #[error(\"Draft already submitted: {0}\")]\n    DraftAlreadySubmitted(String),\n\n    #[error(\"Missing required field: {0}\")]\n    MissingField(String),\n\n    #[error(\"Invalid state transition: {0}\")]\n    InvalidStateTransition(String),\n\n    #[error(\"Storage error: {0}\")]\n    StorageError(String),\n\n    #[error(\"Notification error: {0}\")]\n    NotificationError(String),\n\n    #[error(\"Unauthorized: {0}\")]\n    Unauthorized(String),\n}\n\npub trait ApproverResolver: Send + Sync {\n    fn get_approvers(\n        &self,\n        scope: &PolicyScope,\n        severity: &PolicySeverity,\n    ) -> impl std::future::Future<Output = Result<Vec<String>, PolicyToolError>> + Send;\n\n    fn get_required_approvals(\n        &self,\n        scope: &PolicyScope,\n        severity: &PolicySeverity,\n    ) -> impl std::future::Future<Output = Result<u32, PolicyToolError>> + Send;\n\n    fn get_approval_timeout_hours(\n        &self,\n        scope: &PolicyScope,\n    ) -> impl std::future::Future<Output = Result<u32, PolicyToolError>> + Send;\n}\n\npub trait NotificationService: Send + Sync {\n    fn notify_approvers(\n        &self,\n        approvers: &[String],\n        proposal: &PolicyProposal,\n    ) -> impl std::future::Future<Output = Result<(), PolicyToolError>> + Send;\n\n    fn notify_proposer(\n        &self,\n        proposer: &str,\n        proposal: &PolicyProposal,\n        status: &str,\n        comment: Option<&str>,\n    ) -> impl std::future::Future<Output = Result<(), PolicyToolError>> + Send;\n}\n\npub struct PolicyProposeTool<S, R, N>\nwhere\n    S: PolicyProposalStorage,\n    R: ApproverResolver,\n    N: NotificationService,\n{\n    storage: Arc<S>,\n    approver_resolver: Arc<R>,\n    notification_service: Arc<N>,\n}\n\nimpl<S, R, N> PolicyProposeTool<S, R, N>\nwhere\n    S: PolicyProposalStorage,\n    R: ApproverResolver,\n    N: NotificationService,\n{\n    pub fn new(storage: Arc<S>, approver_resolver: Arc<R>, notification_service: Arc<N>) -> Self {\n        Self {\n            storage,\n            approver_resolver,\n            notification_service,\n        }\n    }\n\n    pub async fn propose(\n        &self,\n        draft_id: &str,\n        justification: Option<String>,\n        notify: Vec<String>,\n        proposed_by: &str,\n    ) -> Result<PolicyProposal, PolicyToolError> {\n        let draft = self\n            .storage\n            .get_draft(draft_id)\n            .await?\n            .ok_or_else(|| PolicyToolError::DraftNotFound(draft_id.to_string()))?;\n\n        if draft.status == DraftStatus::Submitted {\n            return Err(PolicyToolError::DraftAlreadySubmitted(draft_id.to_string()));\n        }\n\n        if draft.status == DraftStatus::ValidationFailed {\n            return Err(PolicyToolError::DraftNotValidated(draft_id.to_string()));\n        }\n\n        if let Some(existing) = self.storage.get_proposal_by_draft(draft_id).await? {\n            return Err(PolicyToolError::DraftAlreadySubmitted(existing.proposal_id));\n        }\n\n        let scope = self.extract_scope_from_cedar(&draft.cedar);\n        let severity = draft.intent.severity;\n\n        let required_approvals = self\n            .approver_resolver\n            .get_required_approvals(&scope, &severity)\n            .await?;\n\n        let timeout_hours = self\n            .approver_resolver\n            .get_approval_timeout_hours(&scope)\n            .await?;\n\n        let mut approvers = self\n            .approver_resolver\n            .get_approvers(&scope, &severity)\n            .await?;\n\n        for explicit in &notify {\n            if !approvers.contains(explicit) {\n                approvers.push(explicit.clone());\n            }\n        }\n\n        let proposal_id = format!(\"prop-{}\", Uuid::new_v4());\n        let now = Utc::now();\n        let expires_at = now + chrono::Duration::hours(timeout_hours as i64);\n\n        let risk_level = match severity {\n            PolicySeverity::Block => RiskLevelKind::High,\n            PolicySeverity::Error => RiskLevelKind::Medium,\n            PolicySeverity::Warn => RiskLevelKind::Low,\n            PolicySeverity::Info => RiskLevelKind::Low,\n        };\n\n        let approval_mode = match scope {\n            PolicyScope::Company => ApprovalModeKind::Unanimous,\n            PolicyScope::Org => ApprovalModeKind::Quorum,\n            _ => ApprovalModeKind::Single,\n        };\n\n        let workflow_ctx = ApprovalWorkflowContext {\n            request_id: Uuid::new_v4(),\n            request_type: \"policy_proposal\".to_string(),\n            required_approvals: required_approvals as i32,\n            current_approvals: 0,\n            approval_mode,\n            timeout_hours: timeout_hours as i32,\n            auto_approve_low_risk: false,\n            risk_level,\n        };\n\n        let mut workflow = ApprovalWorkflow::new(workflow_ctx);\n        workflow\n            .handle(ApprovalEvent::Submit {\n                requestor_id: Uuid::new_v4(),\n                submitted_at: now,\n            })\n            .map_err(|e| PolicyToolError::InvalidStateTransition(e.to_string()))?;\n\n        let proposal = PolicyProposal {\n            proposal_id: proposal_id.clone(),\n            draft_id: draft_id.to_string(),\n            name: draft.name,\n            cedar: draft.cedar,\n            scope,\n            severity,\n            intent: draft.intent,\n            justification,\n            proposed_by: proposed_by.to_string(),\n            proposed_at: now,\n            workflow,\n            notified_approvers: approvers.clone(),\n            expires_at,\n        };\n\n        self.storage.store_proposal(proposal.clone()).await?;\n\n        self.notification_service\n            .notify_approvers(&approvers, &proposal)\n            .await?;\n\n        Ok(proposal)\n    }\n\n    fn extract_scope_from_cedar(&self, cedar: &str) -> PolicyScope {\n        if cedar.contains(\"Scope: company\") {\n            PolicyScope::Company\n        } else if cedar.contains(\"Scope: org\") {\n            PolicyScope::Org\n        } else if cedar.contains(\"Scope: team\") {\n            PolicyScope::Team\n        } else {\n            PolicyScope::Project\n        }\n    }\n}\n\n#[async_trait]\nimpl<S, R, N> Tool for PolicyProposeTool<S, R, N>\nwhere\n    S: PolicyProposalStorage + 'static,\n    R: ApproverResolver + 'static,\n    N: NotificationService + 'static,\n{\n    fn name(&self) -> &str {\n        \"aeterna_policy_propose\"\n    }\n\n    fn description(&self) -> &str {\n        \"Submit a validated policy draft for approval. Notifies configured approvers and starts the approval workflow.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"draft_id\": {\n                    \"type\": \"string\",\n                    \"description\": \"ID of the validated draft to propose\"\n                },\n                \"justification\": {\n                    \"type\": \"string\",\n                    \"description\": \"Why this policy is needed\"\n                },\n                \"notify\": {\n                    \"type\": \"array\",\n                    \"items\": { \"type\": \"string\" },\n                    \"description\": \"Additional approvers to notify (emails or user IDs)\"\n                },\n                \"proposed_by\": {\n                    \"type\": \"string\",\n                    \"description\": \"User ID or email of the proposer\"\n                }\n            },\n            \"required\": [\"draft_id\", \"proposed_by\"]\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        #[derive(Deserialize)]\n        struct ProposeParams {\n            draft_id: String,\n            justification: Option<String>,\n            #[serde(default)]\n            notify: Vec<String>,\n            proposed_by: String,\n        }\n\n        let p: ProposeParams = serde_json::from_value(params)?;\n\n        let proposal = self\n            .propose(&p.draft_id, p.justification, p.notify, &p.proposed_by)\n            .await?;\n\n        Ok(json!({\n            \"proposal_id\": proposal.proposal_id,\n            \"status\": \"pending_approval\",\n            \"required_approvers\": proposal.workflow.context.required_approvals,\n            \"current_approvals\": 0,\n            \"approvers_notified\": proposal.notified_approvers,\n            \"expires_at\": proposal.expires_at.to_rfc3339(),\n        }))\n    }\n}\n\npub struct PolicyListPendingTool<S>\nwhere\n    S: PolicyProposalStorage,\n{\n    storage: Arc<S>,\n}\n\nimpl<S: PolicyProposalStorage> PolicyListPendingTool<S> {\n    pub fn new(storage: Arc<S>) -> Self {\n        Self { storage }\n    }\n}\n\n#[async_trait]\nimpl<S> Tool for PolicyListPendingTool<S>\nwhere\n    S: PolicyProposalStorage + 'static,\n{\n    fn name(&self) -> &str {\n        \"aeterna_policy_list_pending\"\n    }\n\n    fn description(&self) -> &str {\n        \"List pending policy proposals awaiting approval.\"\n    }\n\n    fn input_schema(&self) -> Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"scope\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"company\", \"org\", \"team\", \"project\"],\n                    \"description\": \"Filter by scope (optional)\"\n                }\n            }\n        })\n    }\n\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        #[derive(Deserialize)]\n        struct ListParams {\n            scope: Option<String>,\n        }\n\n        let p: ListParams = serde_json::from_value(params)?;\n        let scope = p.scope.and_then(|s| s.parse::<PolicyScope>().ok());\n\n        let proposals = self.storage.list_pending(scope).await?;\n\n        let results: Vec<Value> = proposals\n            .into_iter()\n            .map(|p| {\n                json!({\n                    \"proposal_id\": p.proposal_id,\n                    \"name\": p.name,\n                    \"scope\": p.scope.to_string(),\n                    \"severity\": p.severity.to_string(),\n                    \"proposed_by\": p.proposed_by,\n                    \"proposed_at\": p.proposed_at.to_rfc3339(),\n                    \"required_approvals\": p.workflow.context.required_approvals,\n                    \"current_approvals\": p.workflow.context.current_approvals,\n                    \"expires_at\": p.expires_at.to_rfc3339(),\n                })\n            })\n            .collect();\n\n        Ok(json!({\n            \"proposals\": results,\n            \"total\": results.len()\n        }))\n    }\n}\n\npub struct InMemoryPolicyStorage {\n    proposals: RwLock<HashMap<String, PolicyProposal>>,\n    drafts: RwLock<HashMap<String, PolicyDraft>>,\n}\n\nimpl InMemoryPolicyStorage {\n    pub fn new() -> Self {\n        Self {\n            proposals: RwLock::new(HashMap::new()),\n            drafts: RwLock::new(HashMap::new()),\n        }\n    }\n\n    pub async fn store_draft(&self, draft: PolicyDraft) {\n        let mut drafts = self.drafts.write().await;\n        drafts.insert(draft.draft_id.clone(), draft);\n    }\n}\n\nimpl Default for InMemoryPolicyStorage {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\nimpl PolicyProposalStorage for InMemoryPolicyStorage {\n    async fn store_proposal(&self, proposal: PolicyProposal) -> Result<(), PolicyToolError> {\n        let mut proposals = self.proposals.write().await;\n        proposals.insert(proposal.proposal_id.clone(), proposal);\n        Ok(())\n    }\n\n    async fn get_proposal(\n        &self,\n        proposal_id: &str,\n    ) -> Result<Option<PolicyProposal>, PolicyToolError> {\n        let proposals = self.proposals.read().await;\n        Ok(proposals.get(proposal_id).cloned())\n    }\n\n    async fn get_proposal_by_draft(\n        &self,\n        draft_id: &str,\n    ) -> Result<Option<PolicyProposal>, PolicyToolError> {\n        let proposals = self.proposals.read().await;\n        Ok(proposals.values().find(|p| p.draft_id == draft_id).cloned())\n    }\n\n    async fn update_proposal(&self, proposal: PolicyProposal) -> Result<(), PolicyToolError> {\n        let mut proposals = self.proposals.write().await;\n        proposals.insert(proposal.proposal_id.clone(), proposal);\n        Ok(())\n    }\n\n    async fn list_pending(\n        &self,\n        scope: Option<PolicyScope>,\n    ) -> Result<Vec<PolicyProposal>, PolicyToolError> {\n        let proposals = self.proposals.read().await;\n        let pending: Vec<_> = proposals\n            .values()\n            .filter(|p| {\n                matches!(p.workflow.state, WorkflowState::Pending { .. })\n                    && scope.as_ref().map_or(true, |s| &p.scope == s)\n            })\n            .cloned()\n            .collect();\n        Ok(pending)\n    }\n\n    async fn get_draft(&self, draft_id: &str) -> Result<Option<PolicyDraft>, PolicyToolError> {\n        let drafts = self.drafts.read().await;\n        Ok(drafts.get(draft_id).cloned())\n    }\n}\n\npub struct DefaultApproverResolver {\n    approvers_by_scope: HashMap<PolicyScope, Vec<String>>,\n}\n\nimpl DefaultApproverResolver {\n    pub fn new() -> Self {\n        let mut approvers = HashMap::new();\n        approvers.insert(PolicyScope::Company, vec![\"admin@company.com\".to_string()]);\n        approvers.insert(PolicyScope::Org, vec![\"architect@company.com\".to_string()]);\n        approvers.insert(PolicyScope::Team, vec![\"tech-lead@company.com\".to_string()]);\n        approvers.insert(\n            PolicyScope::Project,\n            vec![\"tech-lead@company.com\".to_string()],\n        );\n\n        Self {\n            approvers_by_scope: approvers,\n        }\n    }\n\n    pub fn with_approvers(mut self, scope: PolicyScope, approvers: Vec<String>) -> Self {\n        self.approvers_by_scope.insert(scope, approvers);\n        self\n    }\n}\n\nimpl Default for DefaultApproverResolver {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\nimpl ApproverResolver for DefaultApproverResolver {\n    async fn get_approvers(\n        &self,\n        scope: &PolicyScope,\n        _severity: &PolicySeverity,\n    ) -> Result<Vec<String>, PolicyToolError> {\n        Ok(self\n            .approvers_by_scope\n            .get(scope)\n            .cloned()\n            .unwrap_or_default())\n    }\n\n    async fn get_required_approvals(\n        &self,\n        scope: &PolicyScope,\n        severity: &PolicySeverity,\n    ) -> Result<u32, PolicyToolError> {\n        let base = match scope {\n            PolicyScope::Company => 2,\n            PolicyScope::Org => 2,\n            PolicyScope::Team => 1,\n            PolicyScope::Project => 1,\n        };\n\n        let severity_bonus = match severity {\n            PolicySeverity::Block => 1,\n            _ => 0,\n        };\n\n        Ok(base + severity_bonus)\n    }\n\n    async fn get_approval_timeout_hours(\n        &self,\n        scope: &PolicyScope,\n    ) -> Result<u32, PolicyToolError> {\n        Ok(match scope {\n            PolicyScope::Company => 72,\n            PolicyScope::Org => 48,\n            PolicyScope::Team => 24,\n            PolicyScope::Project => 24,\n        })\n    }\n}\n\npub struct NoOpNotificationService;\n\nimpl NotificationService for NoOpNotificationService {\n    async fn notify_approvers(\n        &self,\n        _approvers: &[String],\n        _proposal: &PolicyProposal,\n    ) -> Result<(), PolicyToolError> {\n        Ok(())\n    }\n\n    async fn notify_proposer(\n        &self,\n        _proposer: &str,\n        _proposal: &PolicyProposal,\n        _status: &str,\n        _comment: Option<&str>,\n    ) -> Result<(), PolicyToolError> {\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::policy_translator::{PolicyAction, TargetType};\n\n    fn create_test_draft(draft_id: &str, status: DraftStatus) -> PolicyDraft {\n        PolicyDraft {\n            draft_id: draft_id.to_string(),\n            status,\n            name: \"test-policy\".to_string(),\n            cedar: \"// Scope: project\\nforbid(principal, action, resource);\".to_string(),\n            explanation: \"Test policy\".to_string(),\n            validation: ValidationResult {\n                syntax_valid: true,\n                schema_valid: true,\n                errors: vec![],\n                warnings: vec![],\n            },\n            intent: StructuredIntent {\n                original: \"Block test\".to_string(),\n                interpreted: \"Block test dependency\".to_string(),\n                action: PolicyAction::Deny,\n                target_type: TargetType::Dependency,\n                target_value: \"test\".to_string(),\n                condition: None,\n                severity: PolicySeverity::Warn,\n                confidence: 0.9,\n            },\n        }\n    }\n\n    #[tokio::test]\n    async fn test_propose_creates_proposal() {\n        let storage = Arc::new(InMemoryPolicyStorage::new());\n        let resolver = Arc::new(DefaultApproverResolver::new());\n        let notifier = Arc::new(NoOpNotificationService);\n\n        let draft = create_test_draft(\"draft-123\", DraftStatus::Validated);\n        storage.store_draft(draft).await;\n\n        let tool = PolicyProposeTool::new(storage.clone(), resolver, notifier);\n\n        let proposal = tool\n            .propose(\n                \"draft-123\",\n                Some(\"Testing\".to_string()),\n                vec![],\n                \"user@test.com\",\n            )\n            .await\n            .unwrap();\n\n        assert!(proposal.proposal_id.starts_with(\"prop-\"));\n        assert_eq!(proposal.draft_id, \"draft-123\");\n        assert_eq!(proposal.proposed_by, \"user@test.com\");\n        assert!(matches!(\n            proposal.workflow.state,\n            WorkflowState::Pending { .. }\n        ));\n    }\n\n    #[tokio::test]\n    async fn test_propose_fails_for_invalid_draft() {\n        let storage = Arc::new(InMemoryPolicyStorage::new());\n        let resolver = Arc::new(DefaultApproverResolver::new());\n        let notifier = Arc::new(NoOpNotificationService);\n\n        let draft = create_test_draft(\"draft-invalid\", DraftStatus::ValidationFailed);\n        storage.store_draft(draft).await;\n\n        let tool = PolicyProposeTool::new(storage, resolver, notifier);\n\n        let result = tool\n            .propose(\"draft-invalid\", None, vec![], \"user@test.com\")\n            .await;\n\n        assert!(matches!(result, Err(PolicyToolError::DraftNotValidated(_))));\n    }\n\n    #[tokio::test]\n    async fn test_propose_fails_for_already_submitted() {\n        let storage = Arc::new(InMemoryPolicyStorage::new());\n        let resolver = Arc::new(DefaultApproverResolver::new());\n        let notifier = Arc::new(NoOpNotificationService);\n\n        let draft = create_test_draft(\"draft-submitted\", DraftStatus::Submitted);\n        storage.store_draft(draft).await;\n\n        let tool = PolicyProposeTool::new(storage, resolver, notifier);\n\n        let result = tool\n            .propose(\"draft-submitted\", None, vec![], \"user@test.com\")\n            .await;\n\n        assert!(matches!(\n            result,\n            Err(PolicyToolError::DraftAlreadySubmitted(_))\n        ));\n    }\n\n    #[tokio::test]\n    async fn test_propose_fails_for_missing_draft() {\n        let storage = Arc::new(InMemoryPolicyStorage::new());\n        let resolver = Arc::new(DefaultApproverResolver::new());\n        let notifier = Arc::new(NoOpNotificationService);\n\n        let tool = PolicyProposeTool::new(storage, resolver, notifier);\n\n        let result = tool\n            .propose(\"nonexistent\", None, vec![], \"user@test.com\")\n            .await;\n\n        assert!(matches!(result, Err(PolicyToolError::DraftNotFound(_))));\n    }\n\n    #[tokio::test]\n    async fn test_propose_adds_explicit_approvers() {\n        let storage = Arc::new(InMemoryPolicyStorage::new());\n        let resolver = Arc::new(DefaultApproverResolver::new());\n        let notifier = Arc::new(NoOpNotificationService);\n\n        let draft = create_test_draft(\"draft-456\", DraftStatus::Validated);\n        storage.store_draft(draft).await;\n\n        let tool = PolicyProposeTool::new(storage, resolver, notifier);\n\n        let proposal = tool\n            .propose(\n                \"draft-456\",\n                None,\n                vec![\"extra@approver.com\".to_string()],\n                \"user@test.com\",\n            )\n            .await\n            .unwrap();\n\n        assert!(\n            proposal\n                .notified_approvers\n                .contains(&\"extra@approver.com\".to_string())\n        );\n    }\n\n    #[tokio::test]\n    async fn test_list_pending_returns_only_pending() {\n        let storage = Arc::new(InMemoryPolicyStorage::new());\n        let resolver = Arc::new(DefaultApproverResolver::new());\n        let notifier = Arc::new(NoOpNotificationService);\n\n        let draft1 = create_test_draft(\"draft-1\", DraftStatus::Validated);\n        let draft2 = create_test_draft(\"draft-2\", DraftStatus::Validated);\n        storage.store_draft(draft1).await;\n        storage.store_draft(draft2).await;\n\n        let tool = PolicyProposeTool::new(storage.clone(), resolver, notifier);\n\n        tool.propose(\"draft-1\", None, vec![], \"user@test.com\")\n            .await\n            .unwrap();\n        tool.propose(\"draft-2\", None, vec![], \"user@test.com\")\n            .await\n            .unwrap();\n\n        let list_tool = PolicyListPendingTool::new(storage);\n        let result = list_tool.call(json!({})).await.unwrap();\n\n        assert_eq!(result[\"total\"], 2);\n    }\n\n    #[tokio::test]\n    async fn test_required_approvals_by_scope() {\n        let resolver = DefaultApproverResolver::new();\n\n        let company_approvals = resolver\n            .get_required_approvals(&PolicyScope::Company, &PolicySeverity::Warn)\n            .await\n            .unwrap();\n        assert_eq!(company_approvals, 2);\n\n        let project_approvals = resolver\n            .get_required_approvals(&PolicyScope::Project, &PolicySeverity::Warn)\n            .await\n            .unwrap();\n        assert_eq!(project_approvals, 1);\n\n        let blocking_approvals = resolver\n            .get_required_approvals(&PolicyScope::Project, &PolicySeverity::Block)\n            .await\n            .unwrap();\n        assert_eq!(blocking_approvals, 2);\n    }\n\n    #[tokio::test]\n    async fn test_timeout_hours_by_scope() {\n        let resolver = DefaultApproverResolver::new();\n\n        let company_timeout = resolver\n            .get_approval_timeout_hours(&PolicyScope::Company)\n            .await\n            .unwrap();\n        assert_eq!(company_timeout, 72);\n\n        let project_timeout = resolver\n            .get_approval_timeout_hours(&PolicyScope::Project)\n            .await\n            .unwrap();\n        assert_eq!(project_timeout, 24);\n    }\n\n    #[tokio::test]\n    async fn test_extract_scope_from_cedar() {\n        let storage = Arc::new(InMemoryPolicyStorage::new());\n        let resolver = Arc::new(DefaultApproverResolver::new());\n        let notifier = Arc::new(NoOpNotificationService);\n\n        let tool = PolicyProposeTool::new(storage, resolver, notifier);\n\n        assert_eq!(\n            tool.extract_scope_from_cedar(\"// Scope: company\\nforbid(...)\"),\n            PolicyScope::Company\n        );\n        assert_eq!(\n            tool.extract_scope_from_cedar(\"// Scope: org\\nforbid(...)\"),\n            PolicyScope::Org\n        );\n        assert_eq!(\n            tool.extract_scope_from_cedar(\"// Scope: team\\nforbid(...)\"),\n            PolicyScope::Team\n        );\n        assert_eq!(\n            tool.extract_scope_from_cedar(\"forbid(...)\"),\n            PolicyScope::Project\n        );\n    }\n\n    #[tokio::test]\n    async fn test_tool_interface() {\n        let storage = Arc::new(InMemoryPolicyStorage::new());\n        let resolver = Arc::new(DefaultApproverResolver::new());\n        let notifier = Arc::new(NoOpNotificationService);\n\n        let draft = create_test_draft(\"draft-tool\", DraftStatus::Validated);\n        storage.store_draft(draft).await;\n\n        let tool = PolicyProposeTool::new(storage, resolver, notifier);\n\n        assert_eq!(tool.name(), \"aeterna_policy_propose\");\n        assert!(tool.description().contains(\"approval\"));\n\n        let result = tool\n            .call(json!({\n                \"draft_id\": \"draft-tool\",\n                \"proposed_by\": \"user@test.com\"\n            }))\n            .await\n            .unwrap();\n\n        assert_eq!(result[\"status\"], \"pending_approval\");\n        assert!(result[\"proposal_id\"].as_str().unwrap().starts_with(\"prop-\"));\n    }\n}\n","traces":[{"line":154,"address":[],"length":0,"stats":{"Line":8}},{"line":162,"address":[],"length":0,"stats":{"Line":8}},{"line":169,"address":[],"length":0,"stats":{"Line":23}},{"line":170,"address":[],"length":0,"stats":{"Line":16}},{"line":171,"address":[],"length":0,"stats":{"Line":8}},{"line":172,"address":[],"length":0,"stats":{"Line":8}},{"line":173,"address":[],"length":0,"stats":{"Line":11}},{"line":175,"address":[],"length":0,"stats":{"Line":7}},{"line":176,"address":[],"length":0,"stats":{"Line":1}},{"line":179,"address":[],"length":0,"stats":{"Line":6}},{"line":180,"address":[],"length":0,"stats":{"Line":1}},{"line":183,"address":[],"length":0,"stats":{"Line":10}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":20}},{"line":188,"address":[],"length":0,"stats":{"Line":10}},{"line":190,"address":[],"length":0,"stats":{"Line":15}},{"line":191,"address":[],"length":0,"stats":{"Line":10}},{"line":192,"address":[],"length":0,"stats":{"Line":10}},{"line":193,"address":[],"length":0,"stats":{"Line":5}},{"line":195,"address":[],"length":0,"stats":{"Line":15}},{"line":196,"address":[],"length":0,"stats":{"Line":10}},{"line":197,"address":[],"length":0,"stats":{"Line":5}},{"line":198,"address":[],"length":0,"stats":{"Line":5}},{"line":200,"address":[],"length":0,"stats":{"Line":15}},{"line":201,"address":[],"length":0,"stats":{"Line":10}},{"line":202,"address":[],"length":0,"stats":{"Line":10}},{"line":203,"address":[],"length":0,"stats":{"Line":5}},{"line":205,"address":[],"length":0,"stats":{"Line":7}},{"line":206,"address":[],"length":0,"stats":{"Line":3}},{"line":207,"address":[],"length":0,"stats":{"Line":3}},{"line":211,"address":[],"length":0,"stats":{"Line":20}},{"line":212,"address":[],"length":0,"stats":{"Line":10}},{"line":213,"address":[],"length":0,"stats":{"Line":15}},{"line":215,"address":[],"length":0,"stats":{"Line":10}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":5}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":10}},{"line":223,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":225,"address":[],"length":0,"stats":{"Line":5}},{"line":229,"address":[],"length":0,"stats":{"Line":10}},{"line":230,"address":[],"length":0,"stats":{"Line":15}},{"line":231,"address":[],"length":0,"stats":{"Line":10}},{"line":234,"address":[],"length":0,"stats":{"Line":5}},{"line":239,"address":[],"length":0,"stats":{"Line":15}},{"line":240,"address":[],"length":0,"stats":{"Line":5}},{"line":241,"address":[],"length":0,"stats":{"Line":10}},{"line":242,"address":[],"length":0,"stats":{"Line":5}},{"line":243,"address":[],"length":0,"stats":{"Line":5}},{"line":245,"address":[],"length":0,"stats":{"Line":5}},{"line":248,"address":[],"length":0,"stats":{"Line":15}},{"line":249,"address":[],"length":0,"stats":{"Line":15}},{"line":250,"address":[],"length":0,"stats":{"Line":10}},{"line":251,"address":[],"length":0,"stats":{"Line":10}},{"line":254,"address":[],"length":0,"stats":{"Line":10}},{"line":256,"address":[],"length":0,"stats":{"Line":15}},{"line":259,"address":[],"length":0,"stats":{"Line":10}},{"line":263,"address":[],"length":0,"stats":{"Line":15}},{"line":265,"address":[],"length":0,"stats":{"Line":10}},{"line":266,"address":[],"length":0,"stats":{"Line":10}},{"line":267,"address":[],"length":0,"stats":{"Line":5}},{"line":269,"address":[],"length":0,"stats":{"Line":5}},{"line":272,"address":[],"length":0,"stats":{"Line":9}},{"line":273,"address":[],"length":0,"stats":{"Line":18}},{"line":274,"address":[],"length":0,"stats":{"Line":1}},{"line":275,"address":[],"length":0,"stats":{"Line":16}},{"line":276,"address":[],"length":0,"stats":{"Line":1}},{"line":277,"address":[],"length":0,"stats":{"Line":14}},{"line":278,"address":[],"length":0,"stats":{"Line":1}},{"line":280,"address":[],"length":0,"stats":{"Line":6}},{"line":292,"address":[],"length":0,"stats":{"Line":1}},{"line":293,"address":[],"length":0,"stats":{"Line":1}},{"line":296,"address":[],"length":0,"stats":{"Line":1}},{"line":297,"address":[],"length":0,"stats":{"Line":1}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":1}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":338,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":342,"address":[],"length":0,"stats":{"Line":0}},{"line":343,"address":[],"length":0,"stats":{"Line":0}},{"line":344,"address":[],"length":0,"stats":{"Line":0}},{"line":345,"address":[],"length":0,"stats":{"Line":0}},{"line":346,"address":[],"length":0,"stats":{"Line":0}},{"line":347,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":361,"address":[],"length":0,"stats":{"Line":1}},{"line":371,"address":[],"length":0,"stats":{"Line":0}},{"line":372,"address":[],"length":0,"stats":{"Line":0}},{"line":375,"address":[],"length":0,"stats":{"Line":0}},{"line":376,"address":[],"length":0,"stats":{"Line":0}},{"line":379,"address":[],"length":0,"stats":{"Line":0}},{"line":380,"address":[],"length":0,"stats":{"Line":0}},{"line":381,"address":[],"length":0,"stats":{"Line":0}},{"line":382,"address":[],"length":0,"stats":{"Line":0}},{"line":383,"address":[],"length":0,"stats":{"Line":0}},{"line":384,"address":[],"length":0,"stats":{"Line":0}},{"line":385,"address":[],"length":0,"stats":{"Line":0}},{"line":386,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":1}},{"line":398,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":401,"address":[],"length":0,"stats":{"Line":0}},{"line":403,"address":[],"length":0,"stats":{"Line":0}},{"line":405,"address":[],"length":0,"stats":{"Line":2}},{"line":406,"address":[],"length":0,"stats":{"Line":2}},{"line":407,"address":[],"length":0,"stats":{"Line":2}},{"line":408,"address":[],"length":0,"stats":{"Line":2}},{"line":409,"address":[],"length":0,"stats":{"Line":6}},{"line":410,"address":[],"length":0,"stats":{"Line":6}},{"line":411,"address":[],"length":0,"stats":{"Line":2}},{"line":412,"address":[],"length":0,"stats":{"Line":6}},{"line":413,"address":[],"length":0,"stats":{"Line":2}},{"line":414,"address":[],"length":0,"stats":{"Line":2}},{"line":415,"address":[],"length":0,"stats":{"Line":6}},{"line":420,"address":[],"length":0,"stats":{"Line":0}},{"line":421,"address":[],"length":0,"stats":{"Line":0}},{"line":422,"address":[],"length":0,"stats":{"Line":0}},{"line":433,"address":[],"length":0,"stats":{"Line":8}},{"line":435,"address":[],"length":0,"stats":{"Line":24}},{"line":436,"address":[],"length":0,"stats":{"Line":8}},{"line":440,"address":[],"length":0,"stats":{"Line":14}},{"line":441,"address":[],"length":0,"stats":{"Line":21}},{"line":442,"address":[],"length":0,"stats":{"Line":28}},{"line":447,"address":[],"length":0,"stats":{"Line":0}},{"line":448,"address":[],"length":0,"stats":{"Line":0}},{"line":453,"address":[],"length":0,"stats":{"Line":10}},{"line":454,"address":[],"length":0,"stats":{"Line":15}},{"line":455,"address":[],"length":0,"stats":{"Line":20}},{"line":456,"address":[],"length":0,"stats":{"Line":5}},{"line":459,"address":[],"length":0,"stats":{"Line":0}},{"line":463,"address":[],"length":0,"stats":{"Line":0}},{"line":464,"address":[],"length":0,"stats":{"Line":0}},{"line":467,"address":[],"length":0,"stats":{"Line":5}},{"line":471,"address":[],"length":0,"stats":{"Line":15}},{"line":472,"address":[],"length":0,"stats":{"Line":17}},{"line":475,"address":[],"length":0,"stats":{"Line":0}},{"line":476,"address":[],"length":0,"stats":{"Line":0}},{"line":477,"address":[],"length":0,"stats":{"Line":0}},{"line":478,"address":[],"length":0,"stats":{"Line":0}},{"line":481,"address":[],"length":0,"stats":{"Line":1}},{"line":485,"address":[],"length":0,"stats":{"Line":3}},{"line":486,"address":[],"length":0,"stats":{"Line":3}},{"line":488,"address":[],"length":0,"stats":{"Line":3}},{"line":489,"address":[],"length":0,"stats":{"Line":2}},{"line":490,"address":[],"length":0,"stats":{"Line":6}},{"line":494,"address":[],"length":0,"stats":{"Line":1}},{"line":497,"address":[],"length":0,"stats":{"Line":16}},{"line":498,"address":[],"length":0,"stats":{"Line":24}},{"line":499,"address":[],"length":0,"stats":{"Line":16}},{"line":508,"address":[],"length":0,"stats":{"Line":10}},{"line":509,"address":[],"length":0,"stats":{"Line":20}},{"line":510,"address":[],"length":0,"stats":{"Line":60}},{"line":511,"address":[],"length":0,"stats":{"Line":60}},{"line":512,"address":[],"length":0,"stats":{"Line":60}},{"line":513,"address":[],"length":0,"stats":{"Line":20}},{"line":514,"address":[],"length":0,"stats":{"Line":10}},{"line":515,"address":[],"length":0,"stats":{"Line":30}},{"line":523,"address":[],"length":0,"stats":{"Line":0}},{"line":524,"address":[],"length":0,"stats":{"Line":0}},{"line":525,"address":[],"length":0,"stats":{"Line":0}},{"line":530,"address":[],"length":0,"stats":{"Line":0}},{"line":531,"address":[],"length":0,"stats":{"Line":0}},{"line":536,"address":[],"length":0,"stats":{"Line":5}},{"line":541,"address":[],"length":0,"stats":{"Line":10}},{"line":542,"address":[],"length":0,"stats":{"Line":10}},{"line":543,"address":[],"length":0,"stats":{"Line":15}},{"line":544,"address":[],"length":0,"stats":{"Line":5}},{"line":545,"address":[],"length":0,"stats":{"Line":5}},{"line":548,"address":[],"length":0,"stats":{"Line":8}},{"line":553,"address":[],"length":0,"stats":{"Line":16}},{"line":554,"address":[],"length":0,"stats":{"Line":1}},{"line":555,"address":[],"length":0,"stats":{"Line":0}},{"line":556,"address":[],"length":0,"stats":{"Line":0}},{"line":557,"address":[],"length":0,"stats":{"Line":7}},{"line":560,"address":[],"length":0,"stats":{"Line":16}},{"line":561,"address":[],"length":0,"stats":{"Line":1}},{"line":562,"address":[],"length":0,"stats":{"Line":7}},{"line":565,"address":[],"length":0,"stats":{"Line":8}},{"line":568,"address":[],"length":0,"stats":{"Line":7}},{"line":572,"address":[],"length":0,"stats":{"Line":7}},{"line":573,"address":[],"length":0,"stats":{"Line":1}},{"line":574,"address":[],"length":0,"stats":{"Line":0}},{"line":575,"address":[],"length":0,"stats":{"Line":0}},{"line":576,"address":[],"length":0,"stats":{"Line":6}},{"line":584,"address":[],"length":0,"stats":{"Line":5}},{"line":589,"address":[],"length":0,"stats":{"Line":5}},{"line":592,"address":[],"length":0,"stats":{"Line":0}},{"line":599,"address":[],"length":0,"stats":{"Line":0}}],"covered":135,"coverable":209},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","policy_translator.rs"],"content":"//! # Policy Translator\n//!\n//! LLM-powered translation from natural language to Cedar policies.\n//! Implements the UX-First Architecture's Translation Layer.\n//!\n//! Pipeline: Natural Language  Structured Intent  Cedar  Validation\n\nuse async_trait::async_trait;\nuse knowledge::context_architect::{LlmClient, LlmError};\nuse serde::{Deserialize, Serialize};\nuse std::sync::Arc;\n\n/// Policy action type\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]\n#[serde(rename_all = \"lowercase\")]\npub enum PolicyAction {\n    Allow,\n    Deny,\n}\n\nimpl std::fmt::Display for PolicyAction {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            PolicyAction::Allow => write!(f, \"allow\"),\n            PolicyAction::Deny => write!(f, \"deny\"),\n        }\n    }\n}\n\nimpl std::str::FromStr for PolicyAction {\n    type Err = PolicyTranslatorError;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        match s.to_lowercase().as_str() {\n            \"allow\" | \"permit\" | \"enable\" | \"require\" => Ok(PolicyAction::Allow),\n            \"deny\" | \"forbid\" | \"block\" | \"prevent\" | \"disallow\" => Ok(PolicyAction::Deny),\n            _ => Err(PolicyTranslatorError::InvalidAction(s.to_string())),\n        }\n    }\n}\n\n/// Target type for policy rules\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]\n#[serde(rename_all = \"lowercase\")]\npub enum TargetType {\n    Dependency,\n    File,\n    Code,\n    Import,\n    Config,\n    Api,\n}\n\nimpl std::fmt::Display for TargetType {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            TargetType::Dependency => write!(f, \"dependency\"),\n            TargetType::File => write!(f, \"file\"),\n            TargetType::Code => write!(f, \"code\"),\n            TargetType::Import => write!(f, \"import\"),\n            TargetType::Config => write!(f, \"config\"),\n            TargetType::Api => write!(f, \"api\"),\n        }\n    }\n}\n\nimpl std::str::FromStr for TargetType {\n    type Err = PolicyTranslatorError;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        match s.to_lowercase().as_str() {\n            \"dependency\" | \"dep\" | \"package\" | \"library\" => Ok(TargetType::Dependency),\n            \"file\" | \"path\" => Ok(TargetType::File),\n            \"code\" | \"pattern\" | \"regex\" => Ok(TargetType::Code),\n            \"import\" | \"module\" => Ok(TargetType::Import),\n            \"config\" | \"configuration\" | \"setting\" => Ok(TargetType::Config),\n            \"api\" | \"endpoint\" | \"route\" => Ok(TargetType::Api),\n            _ => Err(PolicyTranslatorError::InvalidTargetType(s.to_string())),\n        }\n    }\n}\n\n/// Severity level for policy violations\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]\n#[serde(rename_all = \"lowercase\")]\npub enum PolicySeverity {\n    Info,\n    Warn,\n    Error,\n    Block,\n}\n\nimpl std::fmt::Display for PolicySeverity {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            PolicySeverity::Info => write!(f, \"info\"),\n            PolicySeverity::Warn => write!(f, \"warn\"),\n            PolicySeverity::Error => write!(f, \"error\"),\n            PolicySeverity::Block => write!(f, \"block\"),\n        }\n    }\n}\n\nimpl std::str::FromStr for PolicySeverity {\n    type Err = PolicyTranslatorError;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        match s.to_lowercase().as_str() {\n            \"info\" | \"information\" => Ok(PolicySeverity::Info),\n            \"warn\" | \"warning\" => Ok(PolicySeverity::Warn),\n            \"error\" | \"err\" => Ok(PolicySeverity::Error),\n            \"block\" | \"blocking\" | \"critical\" => Ok(PolicySeverity::Block),\n            _ => Err(PolicyTranslatorError::InvalidSeverity(s.to_string())),\n        }\n    }\n}\n\n/// Policy scope/layer\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]\n#[serde(rename_all = \"lowercase\")]\npub enum PolicyScope {\n    Company,\n    Org,\n    Team,\n    Project,\n}\n\nimpl std::fmt::Display for PolicyScope {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            PolicyScope::Company => write!(f, \"company\"),\n            PolicyScope::Org => write!(f, \"org\"),\n            PolicyScope::Team => write!(f, \"team\"),\n            PolicyScope::Project => write!(f, \"project\"),\n        }\n    }\n}\n\nimpl std::str::FromStr for PolicyScope {\n    type Err = PolicyTranslatorError;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        match s.to_lowercase().as_str() {\n            \"company\" | \"enterprise\" | \"global\" => Ok(PolicyScope::Company),\n            \"org\" | \"organization\" | \"department\" => Ok(PolicyScope::Org),\n            \"team\" | \"group\" => Ok(PolicyScope::Team),\n            \"project\" | \"repository\" | \"repo\" => Ok(PolicyScope::Project),\n            _ => Err(PolicyTranslatorError::InvalidScope(s.to_string())),\n        }\n    }\n}\n\n/// Structured intent extracted from natural language\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct StructuredIntent {\n    /// Original natural language input\n    pub original: String,\n    /// Interpreted description\n    pub interpreted: String,\n    /// Action to take (allow/deny)\n    pub action: PolicyAction,\n    /// Type of target (dependency, file, code, etc.)\n    pub target_type: TargetType,\n    /// Specific target value or pattern\n    pub target_value: String,\n    /// Optional condition\n    pub condition: Option<String>,\n    /// Severity level\n    pub severity: PolicySeverity,\n    /// Confidence score (0.0 - 1.0)\n    pub confidence: f32,\n}\n\n/// Translation context for policy creation\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TranslationContext {\n    /// Policy scope\n    pub scope: PolicyScope,\n    /// Project name (if available)\n    pub project: Option<String>,\n    /// Team name (if available)\n    pub team: Option<String>,\n    /// Organization name (if available)\n    pub org: Option<String>,\n    /// Additional context hints\n    pub hints: Vec<String>,\n}\n\nimpl Default for TranslationContext {\n    fn default() -> Self {\n        Self {\n            scope: PolicyScope::Project,\n            project: None,\n            team: None,\n            org: None,\n            hints: Vec::new(),\n        }\n    }\n}\n\n/// Validation result for Cedar policy\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ValidationResult {\n    /// Whether syntax is valid\n    pub syntax_valid: bool,\n    /// Whether schema is valid\n    pub schema_valid: bool,\n    /// Validation errors\n    pub errors: Vec<ValidationError>,\n    /// Validation warnings\n    pub warnings: Vec<String>,\n}\n\n/// Validation error with details\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ValidationError {\n    /// Error type\n    pub error_type: String,\n    /// Error message\n    pub message: String,\n    /// Line number (if applicable)\n    pub line: Option<u32>,\n    /// Suggested fix\n    pub suggestion: Option<String>,\n}\n\n/// Complete policy draft from translation\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PolicyDraft {\n    /// Unique draft ID\n    pub draft_id: String,\n    /// Draft status\n    pub status: DraftStatus,\n    /// Structured intent\n    pub intent: StructuredIntent,\n    /// Generated Cedar policy\n    pub cedar: String,\n    /// Human-readable explanation\n    pub explanation: String,\n    /// Validation result\n    pub validation: ValidationResult,\n    /// Generated policy name\n    pub name: String,\n}\n\n/// Draft status\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]\n#[serde(rename_all = \"snake_case\")]\npub enum DraftStatus {\n    PendingReview,\n    Validated,\n    ValidationFailed,\n    Submitted,\n    Approved,\n    Rejected,\n}\n\nimpl std::fmt::Display for DraftStatus {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            DraftStatus::PendingReview => write!(f, \"pending_review\"),\n            DraftStatus::Validated => write!(f, \"validated\"),\n            DraftStatus::ValidationFailed => write!(f, \"validation_failed\"),\n            DraftStatus::Submitted => write!(f, \"submitted\"),\n            DraftStatus::Approved => write!(f, \"approved\"),\n            DraftStatus::Rejected => write!(f, \"rejected\"),\n        }\n    }\n}\n\n/// Policy translator errors\n#[derive(Debug, Clone, thiserror::Error)]\npub enum PolicyTranslatorError {\n    #[error(\"LLM error: {0}\")]\n    LlmError(String),\n\n    #[error(\"Failed to parse LLM response: {0}\")]\n    ParseError(String),\n\n    #[error(\"Invalid action: {0}\")]\n    InvalidAction(String),\n\n    #[error(\"Invalid target type: {0}\")]\n    InvalidTargetType(String),\n\n    #[error(\"Invalid severity: {0}\")]\n    InvalidSeverity(String),\n\n    #[error(\"Invalid scope: {0}\")]\n    InvalidScope(String),\n\n    #[error(\"Cedar validation failed: {0}\")]\n    CedarValidationFailed(String),\n\n    #[error(\"Template not found: {0}\")]\n    TemplateNotFound(String),\n\n    #[error(\"Intent extraction failed: {0}\")]\n    IntentExtractionFailed(String),\n}\n\nimpl From<LlmError> for PolicyTranslatorError {\n    fn from(err: LlmError) -> Self {\n        PolicyTranslatorError::LlmError(err.to_string())\n    }\n}\n\n/// Configuration for the policy translator\n#[derive(Debug, Clone)]\npub struct PolicyTranslatorConfig {\n    /// Use templates for common patterns (faster, deterministic)\n    pub use_templates: bool,\n    /// Minimum confidence threshold for LLM extraction\n    pub min_confidence: f32,\n    /// Maximum retries for LLM calls\n    pub max_retries: u32,\n    /// Validate Cedar syntax strictly\n    pub strict_validation: bool,\n}\n\nimpl Default for PolicyTranslatorConfig {\n    fn default() -> Self {\n        Self {\n            use_templates: true,\n            min_confidence: 0.7,\n            max_retries: 2,\n            strict_validation: true,\n        }\n    }\n}\n\n/// Translation example for few-shot prompting\n#[derive(Debug, Clone)]\npub struct TranslationExample {\n    pub natural_language: String,\n    pub structured_intent: StructuredIntent,\n    pub cedar: String,\n}\n\n/// LLM-powered policy translator\npub struct PolicyTranslator<C: LlmClient> {\n    client: Arc<C>,\n    config: PolicyTranslatorConfig,\n    examples: Vec<TranslationExample>,\n}\n\nimpl<C: LlmClient> PolicyTranslator<C> {\n    /// Create a new policy translator\n    pub fn new(client: Arc<C>, config: PolicyTranslatorConfig) -> Self {\n        Self {\n            client,\n            config,\n            examples: Self::default_examples(),\n        }\n    }\n\n    /// Create with custom examples\n    pub fn with_examples(\n        client: Arc<C>,\n        config: PolicyTranslatorConfig,\n        examples: Vec<TranslationExample>,\n    ) -> Self {\n        Self {\n            client,\n            config,\n            examples,\n        }\n    }\n\n    /// Translate natural language to a policy draft\n    pub async fn translate(\n        &self,\n        intent: &str,\n        context: &TranslationContext,\n    ) -> Result<PolicyDraft, PolicyTranslatorError> {\n        // Step 1: Extract structured intent\n        let structured = self.extract_intent(intent, context).await?;\n\n        // Step 2: Generate Cedar from structured intent\n        let cedar = self.generate_cedar(&structured, context)?;\n\n        // Step 3: Validate generated Cedar\n        let validation = self.validate_cedar(&cedar)?;\n\n        // Step 4: Generate human-readable explanation\n        let explanation = self.generate_explanation(&structured, &cedar).await?;\n\n        // Generate draft ID\n        let draft_id = format!(\n            \"draft-{}-{}\",\n            self.generate_policy_name(&structured),\n            chrono::Utc::now().timestamp()\n        );\n\n        let status = if validation.syntax_valid && validation.schema_valid {\n            DraftStatus::Validated\n        } else {\n            DraftStatus::ValidationFailed\n        };\n\n        Ok(PolicyDraft {\n            draft_id,\n            status,\n            name: self.generate_policy_name(&structured),\n            intent: structured,\n            cedar,\n            explanation,\n            validation,\n        })\n    }\n\n    /// Extract structured intent from natural language using LLM\n    async fn extract_intent(\n        &self,\n        natural: &str,\n        ctx: &TranslationContext,\n    ) -> Result<StructuredIntent, PolicyTranslatorError> {\n        // First, try template-based extraction for common patterns\n        if self.config.use_templates {\n            if let Some(intent) = self.template_extract(natural, ctx) {\n                return Ok(intent);\n            }\n        }\n\n        // Fall back to LLM extraction\n        let system_prompt = r#\"You are a policy intent extractor. Given a natural language description of a policy, extract structured information.\n\nOutput ONLY valid JSON with this exact structure:\n{\n  \"action\": \"allow\" or \"deny\",\n  \"target_type\": \"dependency\" | \"file\" | \"code\" | \"import\" | \"config\" | \"api\",\n  \"target_value\": \"specific value or pattern\",\n  \"condition\": \"optional condition or null\",\n  \"severity\": \"info\" | \"warn\" | \"error\" | \"block\",\n  \"interpreted\": \"clear interpretation of the intent\",\n  \"confidence\": 0.0 to 1.0\n}\n\nRules:\n- \"block\", \"forbid\", \"prevent\", \"disallow\"  action: \"deny\"\n- \"allow\", \"permit\", \"require\", \"must have\"  action: \"allow\"\n- For dependencies: target_type is \"dependency\"\n- For file requirements: target_type is \"file\"\n- For code patterns: target_type is \"code\"\n- severity \"block\" means the action is prevented\n- severity \"warn\" means warning only\n- Always provide a clear \"interpreted\" explanation\"#;\n\n        let user_prompt = format!(\n            \"Extract policy intent from: \\\"{}\\\"\\n\\nContext: scope={}, project={}, team={}\",\n            natural,\n            ctx.scope,\n            ctx.project.as_deref().unwrap_or(\"unknown\"),\n            ctx.team.as_deref().unwrap_or(\"unknown\")\n        );\n\n        let response = self\n            .client\n            .complete_with_system(system_prompt, &user_prompt)\n            .await?;\n\n        self.parse_intent_response(&response, natural)\n    }\n\n    /// Template-based extraction for common patterns (faster, deterministic)\n    fn template_extract(\n        &self,\n        natural: &str,\n        _ctx: &TranslationContext,\n    ) -> Option<StructuredIntent> {\n        let lower = natural.to_lowercase();\n\n        // Pattern: \"block/forbid/prevent X\" for dependencies\n        let block_dep_patterns = [\n            (r\"block\\s+(\\w+)\", PolicyAction::Deny),\n            (r\"forbid\\s+(\\w+)\", PolicyAction::Deny),\n            (r\"prevent\\s+(\\w+)\", PolicyAction::Deny),\n            (r\"disallow\\s+(\\w+)\", PolicyAction::Deny),\n            (r\"no\\s+(\\w+)\", PolicyAction::Deny),\n            (r\"ban\\s+(\\w+)\", PolicyAction::Deny),\n        ];\n\n        for (pattern, action) in block_dep_patterns {\n            if let Some(caps) = regex::Regex::new(pattern).ok()?.captures(&lower) {\n                let target = caps.get(1)?.as_str();\n                // Check if it looks like a dependency name\n                if self.is_likely_dependency(target) {\n                    return Some(StructuredIntent {\n                        original: natural.to_string(),\n                        interpreted: format!(\"{} usage of {} dependency\", action, target),\n                        action,\n                        target_type: TargetType::Dependency,\n                        target_value: target.to_string(),\n                        condition: None,\n                        severity: PolicySeverity::Block,\n                        confidence: 0.95,\n                    });\n                }\n            }\n        }\n\n        // Pattern: \"require X\" for files\n        let require_file_patterns = [\n            (r\"require\\s+([\\w\\.]+)\", \"file\"),\n            (r\"must\\s+have\\s+([\\w\\.]+)\", \"file\"),\n            (r\"needs?\\s+([\\w\\.]+)\", \"file\"),\n        ];\n\n        for (pattern, _) in require_file_patterns {\n            if let Some(caps) = regex::Regex::new(pattern).ok()?.captures(&lower) {\n                let target = caps.get(1)?.as_str();\n                if self.is_likely_file(target) {\n                    return Some(StructuredIntent {\n                        original: natural.to_string(),\n                        interpreted: format!(\"Require {} file to exist\", target),\n                        action: PolicyAction::Allow,\n                        target_type: TargetType::File,\n                        target_value: target.to_string(),\n                        condition: Some(\"must_exist\".to_string()),\n                        severity: PolicySeverity::Warn,\n                        confidence: 0.9,\n                    });\n                }\n            }\n        }\n\n        None\n    }\n\n    /// Check if a string looks like a dependency name\n    fn is_likely_dependency(&self, s: &str) -> bool {\n        let common_deps = [\n            \"mysql\",\n            \"mysql2\",\n            \"mongodb\",\n            \"postgres\",\n            \"postgresql\",\n            \"redis\",\n            \"lodash\",\n            \"jquery\",\n            \"moment\",\n            \"express\",\n            \"react\",\n            \"vue\",\n            \"angular\",\n            \"axios\",\n            \"fetch\",\n            \"request\",\n            \"sqlite\",\n            \"mariadb\",\n            \"oracle\",\n        ];\n        common_deps.contains(&s.to_lowercase().as_str()) ||\n            // npm-style package names\n            s.chars().all(|c| c.is_alphanumeric() || c == '-' || c == '_' || c == '@' || c == '/')\n    }\n\n    /// Check if a string looks like a file name\n    fn is_likely_file(&self, s: &str) -> bool {\n        s.contains('.')\n            || [\n                \"readme\",\n                \"license\",\n                \"changelog\",\n                \"security\",\n                \"contributing\",\n                \"dockerfile\",\n                \"makefile\",\n            ]\n            .contains(&s.to_lowercase().as_str())\n    }\n\n    /// Parse LLM response into structured intent\n    fn parse_intent_response(\n        &self,\n        response: &str,\n        original: &str,\n    ) -> Result<StructuredIntent, PolicyTranslatorError> {\n        // Try to extract JSON from response (handle markdown code blocks)\n        let json_str = if response.contains(\"```json\") {\n            response\n                .split(\"```json\")\n                .nth(1)\n                .and_then(|s| s.split(\"```\").next())\n                .unwrap_or(response)\n        } else if response.contains(\"```\") {\n            response.split(\"```\").nth(1).unwrap_or(response)\n        } else {\n            response\n        };\n\n        #[derive(Deserialize)]\n        struct LlmIntentResponse {\n            action: String,\n            target_type: String,\n            target_value: String,\n            condition: Option<String>,\n            severity: String,\n            interpreted: String,\n            confidence: f32,\n        }\n\n        let parsed: LlmIntentResponse = serde_json::from_str(json_str.trim())\n            .map_err(|e| PolicyTranslatorError::ParseError(format!(\"JSON parse error: {}\", e)))?;\n\n        Ok(StructuredIntent {\n            original: original.to_string(),\n            interpreted: parsed.interpreted,\n            action: parsed.action.parse()?,\n            target_type: parsed.target_type.parse()?,\n            target_value: parsed.target_value,\n            condition: parsed.condition,\n            severity: parsed.severity.parse()?,\n            confidence: parsed.confidence,\n        })\n    }\n\n    /// Generate Cedar policy from structured intent\n    fn generate_cedar(\n        &self,\n        intent: &StructuredIntent,\n        ctx: &TranslationContext,\n    ) -> Result<String, PolicyTranslatorError> {\n        let cedar = match (&intent.action, &intent.target_type) {\n            (PolicyAction::Deny, TargetType::Dependency) => {\n                format!(\n                    r#\"// Policy: Deny {} dependency\n// Scope: {}\n// Severity: {}\n\nforbid(\n  principal,\n  action == Action::\"UseDependency\",\n  resource\n)\nwhen {{\n  resource.dependency == \"{}\"\n}};\"#,\n                    intent.target_value, ctx.scope, intent.severity, intent.target_value\n                )\n            }\n            (PolicyAction::Deny, TargetType::Import) => {\n                format!(\n                    r#\"// Policy: Deny {} import\n// Scope: {}\n// Severity: {}\n\nforbid(\n  principal,\n  action == Action::\"ImportModule\",\n  resource\n)\nwhen {{\n  resource.module == \"{}\"\n}};\"#,\n                    intent.target_value, ctx.scope, intent.severity, intent.target_value\n                )\n            }\n            (PolicyAction::Allow, TargetType::File)\n                if intent.condition.as_deref() == Some(\"must_exist\") =>\n            {\n                format!(\n                    r#\"// Policy: Require {} file\n// Scope: {}\n// Severity: {}\n\npermit(\n  principal,\n  action == Action::\"Deploy\",\n  resource\n)\nwhen {{\n  resource.files.contains(\"{}\")\n}};\"#,\n                    intent.target_value, ctx.scope, intent.severity, intent.target_value\n                )\n            }\n            (PolicyAction::Deny, TargetType::Code) => {\n                format!(\n                    r#\"// Policy: Deny code pattern\n// Scope: {}\n// Severity: {}\n\nforbid(\n  principal,\n  action == Action::\"Commit\",\n  resource\n)\nwhen {{\n  resource.content.matches(\"{}\")\n}};\"#,\n                    ctx.scope,\n                    intent.severity,\n                    intent.target_value.replace(\"\\\"\", \"\\\\\\\"\")\n                )\n            }\n            (PolicyAction::Deny, TargetType::Config) => {\n                format!(\n                    r#\"// Policy: Deny config value\n// Scope: {}\n// Severity: {}\n\nforbid(\n  principal,\n  action == Action::\"Configure\",\n  resource\n)\nwhen {{\n  resource.config.contains(\"{}\")\n}};\"#,\n                    ctx.scope, intent.severity, intent.target_value\n                )\n            }\n            (PolicyAction::Allow, TargetType::Dependency) => {\n                format!(\n                    r#\"// Policy: Require {} dependency\n// Scope: {}\n// Severity: {}\n\npermit(\n  principal,\n  action == Action::\"Build\",\n  resource\n)\nwhen {{\n  resource.dependencies.contains(\"{}\")\n}};\"#,\n                    intent.target_value, ctx.scope, intent.severity, intent.target_value\n                )\n            }\n            _ => {\n                // Generic template for unsupported combinations\n                let effect = match intent.action {\n                    PolicyAction::Allow => \"permit\",\n                    PolicyAction::Deny => \"forbid\",\n                };\n                format!(\n                    r#\"// Policy: {} {} {}\n// Scope: {}\n// Severity: {}\n\n{}(\n  principal,\n  action,\n  resource\n)\nwhen {{\n  resource.{} == \"{}\"\n}};\"#,\n                    intent.action,\n                    intent.target_type,\n                    intent.target_value,\n                    ctx.scope,\n                    intent.severity,\n                    effect,\n                    intent.target_type,\n                    intent.target_value\n                )\n            }\n        };\n\n        Ok(cedar)\n    }\n\n    /// Validate Cedar policy syntax\n    fn validate_cedar(&self, cedar: &str) -> Result<ValidationResult, PolicyTranslatorError> {\n        let mut errors = Vec::new();\n        let mut warnings = Vec::new();\n\n        // Basic syntax checks (Cedar parser would be used in production)\n        // For now, we do structural validation\n\n        // Check for balanced braces\n        let open_braces = cedar.matches('{').count();\n        let close_braces = cedar.matches('}').count();\n        if open_braces != close_braces {\n            errors.push(ValidationError {\n                error_type: \"syntax\".to_string(),\n                message: \"Unbalanced braces\".to_string(),\n                line: None,\n                suggestion: Some(\"Check opening and closing braces\".to_string()),\n            });\n        }\n\n        // Check for required keywords\n        if !cedar.contains(\"permit\") && !cedar.contains(\"forbid\") {\n            errors.push(ValidationError {\n                error_type: \"syntax\".to_string(),\n                message: \"Policy must contain 'permit' or 'forbid' keyword\".to_string(),\n                line: None,\n                suggestion: Some(\"Start policy with 'permit(' or 'forbid('\".to_string()),\n            });\n        }\n\n        // Check for principal, action, resource\n        if !cedar.contains(\"principal\") {\n            warnings.push(\"Policy does not reference 'principal'\".to_string());\n        }\n        if !cedar.contains(\"action\") {\n            warnings.push(\"Policy does not reference 'action'\".to_string());\n        }\n        if !cedar.contains(\"resource\") {\n            warnings.push(\"Policy does not reference 'resource'\".to_string());\n        }\n\n        // Check for terminating semicolon\n        let trimmed = cedar.trim();\n        if !trimmed.ends_with(';') {\n            warnings.push(\"Policy should end with semicolon\".to_string());\n        }\n\n        Ok(ValidationResult {\n            syntax_valid: errors.is_empty(),\n            schema_valid: errors.is_empty(), // Would check against Cedar schema in production\n            errors,\n            warnings,\n        })\n    }\n\n    /// Generate human-readable explanation using LLM\n    async fn generate_explanation(\n        &self,\n        intent: &StructuredIntent,\n        cedar: &str,\n    ) -> Result<String, PolicyTranslatorError> {\n        // For simple cases, use template-based explanation\n        let explanation = match (&intent.action, &intent.target_type) {\n            (PolicyAction::Deny, TargetType::Dependency) => {\n                format!(\n                    \"This policy blocks the use of '{}' as a dependency. When violated, the action will be {}.\",\n                    intent.target_value,\n                    severity_effect(&intent.severity)\n                )\n            }\n            (PolicyAction::Allow, TargetType::File) => {\n                format!(\n                    \"This policy requires the file '{}' to exist. When missing, a {} will be raised.\",\n                    intent.target_value, intent.severity\n                )\n            }\n            (PolicyAction::Deny, TargetType::Code) => {\n                format!(\n                    \"This policy prevents code matching pattern '{}'. Violations will be {}.\",\n                    intent.target_value,\n                    severity_effect(&intent.severity)\n                )\n            }\n            _ => {\n                // Use LLM for complex explanations\n                let prompt = format!(\n                    \"Explain this Cedar policy in plain English (2-3 sentences):\\n\\n{}\\n\\nOriginal intent: {}\",\n                    cedar, intent.original\n                );\n                self.client.complete(&prompt).await?\n            }\n        };\n\n        Ok(explanation)\n    }\n\n    /// Generate a policy name from intent\n    fn generate_policy_name(&self, intent: &StructuredIntent) -> String {\n        let action_prefix = match intent.action {\n            PolicyAction::Allow => \"require\",\n            PolicyAction::Deny => \"no\",\n        };\n\n        let target = intent\n            .target_value\n            .replace('@', \"\")\n            .replace('/', \"-\")\n            .replace('.', \"-\")\n            .to_lowercase();\n\n        let target = if target.len() > 20 {\n            target[..20].to_string()\n        } else {\n            target\n        };\n\n        format!(\"{}-{}\", action_prefix, target)\n    }\n\n    /// Default translation examples for few-shot prompting\n    fn default_examples() -> Vec<TranslationExample> {\n        vec![\n            TranslationExample {\n                natural_language: \"Block MySQL\".to_string(),\n                structured_intent: StructuredIntent {\n                    original: \"Block MySQL\".to_string(),\n                    interpreted: \"Deny usage of MySQL database dependency\".to_string(),\n                    action: PolicyAction::Deny,\n                    target_type: TargetType::Dependency,\n                    target_value: \"mysql\".to_string(),\n                    condition: None,\n                    severity: PolicySeverity::Block,\n                    confidence: 0.95,\n                },\n                cedar: r#\"forbid(principal, action == Action::\"UseDependency\", resource) when { resource.dependency == \"mysql\" };\"#.to_string(),\n            },\n            TranslationExample {\n                natural_language: \"Require README.md\".to_string(),\n                structured_intent: StructuredIntent {\n                    original: \"Require README.md\".to_string(),\n                    interpreted: \"Require README.md file to exist\".to_string(),\n                    action: PolicyAction::Allow,\n                    target_type: TargetType::File,\n                    target_value: \"README.md\".to_string(),\n                    condition: Some(\"must_exist\".to_string()),\n                    severity: PolicySeverity::Warn,\n                    confidence: 0.92,\n                },\n                cedar: r#\"permit(principal, action == Action::\"Deploy\", resource) when { resource.files.contains(\"README.md\") };\"#.to_string(),\n            },\n            TranslationExample {\n                natural_language: \"Prevent console.log in production\".to_string(),\n                structured_intent: StructuredIntent {\n                    original: \"Prevent console.log in production\".to_string(),\n                    interpreted: \"Deny console.log statements in code\".to_string(),\n                    action: PolicyAction::Deny,\n                    target_type: TargetType::Code,\n                    target_value: \"console\\\\.log\".to_string(),\n                    condition: None,\n                    severity: PolicySeverity::Warn,\n                    confidence: 0.88,\n                },\n                cedar: r#\"forbid(principal, action == Action::\"Commit\", resource) when { resource.content.matches(\"console\\\\.log\") };\"#.to_string(),\n            },\n        ]\n    }\n}\n\n/// Get severity effect description\nfn severity_effect(severity: &PolicySeverity) -> &'static str {\n    match severity {\n        PolicySeverity::Info => \"logged as information\",\n        PolicySeverity::Warn => \"warned\",\n        PolicySeverity::Error => \"flagged as an error\",\n        PolicySeverity::Block => \"blocked\",\n    }\n}\n\n/// Trait for policy translation (allows mocking)\n#[async_trait]\npub trait PolicyTranslate: Send + Sync {\n    async fn translate(\n        &self,\n        intent: &str,\n        context: &TranslationContext,\n    ) -> Result<PolicyDraft, PolicyTranslatorError>;\n\n    fn validate(&self, cedar: &str) -> Result<ValidationResult, PolicyTranslatorError>;\n}\n\n#[async_trait]\nimpl<C: LlmClient> PolicyTranslate for PolicyTranslator<C> {\n    async fn translate(\n        &self,\n        intent: &str,\n        context: &TranslationContext,\n    ) -> Result<PolicyDraft, PolicyTranslatorError> {\n        PolicyTranslator::translate(self, intent, context).await\n    }\n\n    fn validate(&self, cedar: &str) -> Result<ValidationResult, PolicyTranslatorError> {\n        self.validate_cedar(cedar)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::collections::VecDeque;\n    use std::sync::Mutex;\n\n    struct MockLlmClient {\n        responses: Mutex<VecDeque<String>>,\n    }\n\n    impl MockLlmClient {\n        fn new(responses: Vec<String>) -> Self {\n            Self {\n                responses: Mutex::new(responses.into()),\n            }\n        }\n    }\n\n    #[async_trait]\n    impl LlmClient for MockLlmClient {\n        async fn complete(&self, _prompt: &str) -> Result<String, LlmError> {\n            self.responses\n                .lock()\n                .unwrap()\n                .pop_front()\n                .ok_or_else(|| LlmError::RequestFailed(\"No mock response\".to_string()))\n        }\n\n        async fn complete_with_system(\n            &self,\n            _system: &str,\n            _user: &str,\n        ) -> Result<String, LlmError> {\n            self.responses\n                .lock()\n                .unwrap()\n                .pop_front()\n                .ok_or_else(|| LlmError::RequestFailed(\"No mock response\".to_string()))\n        }\n    }\n\n    #[test]\n    fn test_policy_action_parse() {\n        assert_eq!(\"block\".parse::<PolicyAction>().unwrap(), PolicyAction::Deny);\n        assert_eq!(\n            \"allow\".parse::<PolicyAction>().unwrap(),\n            PolicyAction::Allow\n        );\n        assert_eq!(\n            \"forbid\".parse::<PolicyAction>().unwrap(),\n            PolicyAction::Deny\n        );\n        assert_eq!(\n            \"permit\".parse::<PolicyAction>().unwrap(),\n            PolicyAction::Allow\n        );\n    }\n\n    #[test]\n    fn test_target_type_parse() {\n        assert_eq!(\n            \"dependency\".parse::<TargetType>().unwrap(),\n            TargetType::Dependency\n        );\n        assert_eq!(\"file\".parse::<TargetType>().unwrap(), TargetType::File);\n        assert_eq!(\"code\".parse::<TargetType>().unwrap(), TargetType::Code);\n        assert_eq!(\n            \"package\".parse::<TargetType>().unwrap(),\n            TargetType::Dependency\n        );\n    }\n\n    #[test]\n    fn test_severity_parse() {\n        assert_eq!(\n            \"block\".parse::<PolicySeverity>().unwrap(),\n            PolicySeverity::Block\n        );\n        assert_eq!(\n            \"warn\".parse::<PolicySeverity>().unwrap(),\n            PolicySeverity::Warn\n        );\n        assert_eq!(\n            \"info\".parse::<PolicySeverity>().unwrap(),\n            PolicySeverity::Info\n        );\n        assert_eq!(\n            \"error\".parse::<PolicySeverity>().unwrap(),\n            PolicySeverity::Error\n        );\n    }\n\n    #[test]\n    fn test_scope_parse() {\n        assert_eq!(\n            \"project\".parse::<PolicyScope>().unwrap(),\n            PolicyScope::Project\n        );\n        assert_eq!(\"team\".parse::<PolicyScope>().unwrap(), PolicyScope::Team);\n        assert_eq!(\"org\".parse::<PolicyScope>().unwrap(), PolicyScope::Org);\n        assert_eq!(\n            \"company\".parse::<PolicyScope>().unwrap(),\n            PolicyScope::Company\n        );\n    }\n\n    #[tokio::test]\n    async fn test_template_extraction_block_mysql() {\n        let client = Arc::new(MockLlmClient::new(vec![]));\n        let translator = PolicyTranslator::new(client, PolicyTranslatorConfig::default());\n        let ctx = TranslationContext::default();\n\n        let intent = translator.template_extract(\"Block MySQL\", &ctx);\n        assert!(intent.is_some());\n        let intent = intent.unwrap();\n        assert_eq!(intent.action, PolicyAction::Deny);\n        assert_eq!(intent.target_type, TargetType::Dependency);\n        assert_eq!(intent.target_value, \"mysql\");\n    }\n\n    #[tokio::test]\n    async fn test_template_extraction_require_readme() {\n        let client = Arc::new(MockLlmClient::new(vec![]));\n        let translator = PolicyTranslator::new(client, PolicyTranslatorConfig::default());\n        let ctx = TranslationContext::default();\n\n        let intent = translator.template_extract(\"Require README.md\", &ctx);\n        assert!(intent.is_some());\n        let intent = intent.unwrap();\n        assert_eq!(intent.action, PolicyAction::Allow);\n        assert_eq!(intent.target_type, TargetType::File);\n        assert_eq!(intent.target_value, \"readme.md\");\n    }\n\n    #[tokio::test]\n    async fn test_generate_cedar_deny_dependency() {\n        let client = Arc::new(MockLlmClient::new(vec![]));\n        let translator = PolicyTranslator::new(client, PolicyTranslatorConfig::default());\n        let ctx = TranslationContext::default();\n\n        let intent = StructuredIntent {\n            original: \"Block mysql\".to_string(),\n            interpreted: \"Deny mysql dependency\".to_string(),\n            action: PolicyAction::Deny,\n            target_type: TargetType::Dependency,\n            target_value: \"mysql\".to_string(),\n            condition: None,\n            severity: PolicySeverity::Block,\n            confidence: 0.95,\n        };\n\n        let cedar = translator.generate_cedar(&intent, &ctx).unwrap();\n        assert!(cedar.contains(\"forbid\"));\n        assert!(cedar.contains(\"mysql\"));\n        assert!(cedar.contains(\"UseDependency\"));\n    }\n\n    #[tokio::test]\n    async fn test_validate_cedar_valid() {\n        let client = Arc::new(MockLlmClient::new(vec![]));\n        let translator = PolicyTranslator::new(client, PolicyTranslatorConfig::default());\n\n        let cedar = r#\"forbid(principal, action, resource) when { resource.dep == \"mysql\" };\"#;\n        let result = translator.validate_cedar(cedar).unwrap();\n        assert!(result.syntax_valid);\n    }\n\n    #[tokio::test]\n    async fn test_validate_cedar_unbalanced_braces() {\n        let client = Arc::new(MockLlmClient::new(vec![]));\n        let translator = PolicyTranslator::new(client, PolicyTranslatorConfig::default());\n\n        let cedar = r#\"forbid(principal, action, resource) when { resource.dep == \"mysql\" }\"#;\n        let result = translator.validate_cedar(cedar).unwrap();\n        assert!(result.syntax_valid);\n    }\n\n    #[tokio::test]\n    async fn test_translate_with_template() {\n        let client = Arc::new(MockLlmClient::new(vec![\n            \"This policy blocks mysql dependency.\".to_string(),\n        ]));\n        let translator = PolicyTranslator::new(client, PolicyTranslatorConfig::default());\n        let ctx = TranslationContext::default();\n\n        let draft = translator.translate(\"Block MySQL\", &ctx).await.unwrap();\n        assert_eq!(draft.intent.action, PolicyAction::Deny);\n        assert_eq!(draft.intent.target_type, TargetType::Dependency);\n        assert!(draft.cedar.contains(\"mysql\"));\n        assert!(draft.validation.syntax_valid);\n    }\n\n    #[tokio::test]\n    async fn test_translate_with_llm() {\n        let llm_response = r#\"{\n            \"action\": \"deny\",\n            \"target_type\": \"dependency\",\n            \"target_value\": \"lodash\",\n            \"condition\": null,\n            \"severity\": \"warn\",\n            \"interpreted\": \"Deny usage of lodash library\",\n            \"confidence\": 0.85\n        }\"#;\n\n        let client = Arc::new(MockLlmClient::new(vec![\n            llm_response.to_string(),\n            \"This policy warns about lodash usage.\".to_string(),\n        ]));\n\n        let mut config = PolicyTranslatorConfig::default();\n        config.use_templates = false;\n\n        let translator = PolicyTranslator::new(client, config);\n        let ctx = TranslationContext::default();\n\n        let draft = translator\n            .translate(\"Warn about lodash usage\", &ctx)\n            .await\n            .unwrap();\n        assert_eq!(draft.intent.action, PolicyAction::Deny);\n        assert_eq!(draft.intent.target_value, \"lodash\");\n        assert_eq!(draft.intent.severity, PolicySeverity::Warn);\n    }\n\n    #[test]\n    fn test_generate_policy_name() {\n        let client = Arc::new(MockLlmClient::new(vec![]));\n        let translator = PolicyTranslator::new(client, PolicyTranslatorConfig::default());\n\n        let intent = StructuredIntent {\n            original: \"test\".to_string(),\n            interpreted: \"test\".to_string(),\n            action: PolicyAction::Deny,\n            target_type: TargetType::Dependency,\n            target_value: \"mysql\".to_string(),\n            condition: None,\n            severity: PolicySeverity::Block,\n            confidence: 0.9,\n        };\n\n        let name = translator.generate_policy_name(&intent);\n        assert_eq!(name, \"no-mysql\");\n\n        let intent2 = StructuredIntent {\n            original: \"test\".to_string(),\n            interpreted: \"test\".to_string(),\n            action: PolicyAction::Allow,\n            target_type: TargetType::File,\n            target_value: \"README.md\".to_string(),\n            condition: None,\n            severity: PolicySeverity::Warn,\n            confidence: 0.9,\n        };\n\n        let name2 = translator.generate_policy_name(&intent2);\n        assert_eq!(name2, \"require-readme-md\");\n    }\n\n    #[test]\n    fn test_parse_intent_response_with_code_block() {\n        let client = Arc::new(MockLlmClient::new(vec![]));\n        let translator = PolicyTranslator::new(client, PolicyTranslatorConfig::default());\n\n        let response = r#\"```json\n{\n    \"action\": \"deny\",\n    \"target_type\": \"dependency\",\n    \"target_value\": \"mysql\",\n    \"condition\": null,\n    \"severity\": \"block\",\n    \"interpreted\": \"Block mysql\",\n    \"confidence\": 0.9\n}\n```\"#;\n\n        let intent = translator\n            .parse_intent_response(response, \"Block mysql\")\n            .unwrap();\n        assert_eq!(intent.action, PolicyAction::Deny);\n        assert_eq!(intent.target_value, \"mysql\");\n    }\n\n    #[test]\n    fn test_is_likely_dependency() {\n        let client = Arc::new(MockLlmClient::new(vec![]));\n        let translator = PolicyTranslator::new(client, PolicyTranslatorConfig::default());\n\n        assert!(translator.is_likely_dependency(\"mysql\"));\n        assert!(translator.is_likely_dependency(\"lodash\"));\n        assert!(translator.is_likely_dependency(\"@types/node\"));\n        assert!(translator.is_likely_dependency(\"my-package\"));\n    }\n\n    #[test]\n    fn test_is_likely_file() {\n        let client = Arc::new(MockLlmClient::new(vec![]));\n        let translator = PolicyTranslator::new(client, PolicyTranslatorConfig::default());\n\n        assert!(translator.is_likely_file(\"README.md\"));\n        assert!(translator.is_likely_file(\"package.json\"));\n        assert!(translator.is_likely_file(\"Dockerfile\"));\n        assert!(translator.is_likely_file(\"SECURITY\"));\n    }\n}\n","traces":[{"line":22,"address":[],"length":0,"stats":{"Line":2}},{"line":23,"address":[],"length":0,"stats":{"Line":2}},{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":6}},{"line":33,"address":[],"length":0,"stats":{"Line":6}},{"line":34,"address":[],"length":0,"stats":{"Line":6}},{"line":35,"address":[],"length":0,"stats":{"Line":21}},{"line":36,"address":[],"length":0,"stats":{"Line":11}},{"line":37,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":6}},{"line":71,"address":[],"length":0,"stats":{"Line":6}},{"line":72,"address":[],"length":0,"stats":{"Line":18}},{"line":73,"address":[],"length":0,"stats":{"Line":4}},{"line":74,"address":[],"length":0,"stats":{"Line":2}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":5}},{"line":95,"address":[],"length":0,"stats":{"Line":5}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":9}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":6}},{"line":107,"address":[],"length":0,"stats":{"Line":6}},{"line":108,"address":[],"length":0,"stats":{"Line":6}},{"line":109,"address":[],"length":0,"stats":{"Line":12}},{"line":110,"address":[],"length":0,"stats":{"Line":10}},{"line":111,"address":[],"length":0,"stats":{"Line":6}},{"line":112,"address":[],"length":0,"stats":{"Line":4}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":6}},{"line":130,"address":[],"length":0,"stats":{"Line":6}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":18}},{"line":142,"address":[],"length":0,"stats":{"Line":4}},{"line":143,"address":[],"length":0,"stats":{"Line":4}},{"line":144,"address":[],"length":0,"stats":{"Line":11}},{"line":145,"address":[],"length":0,"stats":{"Line":8}},{"line":146,"address":[],"length":0,"stats":{"Line":4}},{"line":147,"address":[],"length":0,"stats":{"Line":2}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":5}},{"line":196,"address":[],"length":0,"stats":{"Line":5}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":264,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":11}},{"line":349,"address":[],"length":0,"stats":{"Line":11}},{"line":353,"address":[],"length":0,"stats":{"Line":11}},{"line":358,"address":[],"length":0,"stats":{"Line":0}},{"line":371,"address":[],"length":0,"stats":{"Line":2}},{"line":377,"address":[],"length":0,"stats":{"Line":10}},{"line":380,"address":[],"length":0,"stats":{"Line":10}},{"line":383,"address":[],"length":0,"stats":{"Line":8}},{"line":386,"address":[],"length":0,"stats":{"Line":10}},{"line":389,"address":[],"length":0,"stats":{"Line":4}},{"line":391,"address":[],"length":0,"stats":{"Line":6}},{"line":392,"address":[],"length":0,"stats":{"Line":4}},{"line":395,"address":[],"length":0,"stats":{"Line":6}},{"line":396,"address":[],"length":0,"stats":{"Line":2}},{"line":398,"address":[],"length":0,"stats":{"Line":0}},{"line":401,"address":[],"length":0,"stats":{"Line":2}},{"line":402,"address":[],"length":0,"stats":{"Line":4}},{"line":403,"address":[],"length":0,"stats":{"Line":4}},{"line":404,"address":[],"length":0,"stats":{"Line":8}},{"line":405,"address":[],"length":0,"stats":{"Line":4}},{"line":406,"address":[],"length":0,"stats":{"Line":4}},{"line":407,"address":[],"length":0,"stats":{"Line":2}},{"line":408,"address":[],"length":0,"stats":{"Line":2}},{"line":413,"address":[],"length":0,"stats":{"Line":2}},{"line":419,"address":[],"length":0,"stats":{"Line":2}},{"line":420,"address":[],"length":0,"stats":{"Line":4}},{"line":421,"address":[],"length":0,"stats":{"Line":1}},{"line":426,"address":[],"length":0,"stats":{"Line":2}},{"line":428,"address":[],"length":0,"stats":{"Line":1}},{"line":430,"address":[],"length":0,"stats":{"Line":1}},{"line":431,"address":[],"length":0,"stats":{"Line":1}},{"line":432,"address":[],"length":0,"stats":{"Line":1}},{"line":433,"address":[],"length":0,"stats":{"Line":1}},{"line":434,"address":[],"length":0,"stats":{"Line":1}},{"line":435,"address":[],"length":0,"stats":{"Line":1}},{"line":436,"address":[],"length":0,"stats":{"Line":1}},{"line":439,"address":[],"length":0,"stats":{"Line":1}},{"line":440,"address":[],"length":0,"stats":{"Line":1}},{"line":441,"address":[],"length":0,"stats":{"Line":1}},{"line":442,"address":[],"length":0,"stats":{"Line":1}},{"line":443,"address":[],"length":0,"stats":{"Line":1}},{"line":444,"address":[],"length":0,"stats":{"Line":1}},{"line":445,"address":[],"length":0,"stats":{"Line":1}},{"line":446,"address":[],"length":0,"stats":{"Line":1}},{"line":447,"address":[],"length":0,"stats":{"Line":1}},{"line":449,"address":[],"length":0,"stats":{"Line":2}},{"line":451,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":453,"address":[],"length":0,"stats":{"Line":4}},{"line":454,"address":[],"length":0,"stats":{"Line":4}},{"line":457,"address":[],"length":0,"stats":{"Line":3}},{"line":458,"address":[],"length":0,"stats":{"Line":2}},{"line":459,"address":[],"length":0,"stats":{"Line":2}},{"line":460,"address":[],"length":0,"stats":{"Line":1}},{"line":462,"address":[],"length":0,"stats":{"Line":4}},{"line":466,"address":[],"length":0,"stats":{"Line":3}},{"line":471,"address":[],"length":0,"stats":{"Line":9}},{"line":474,"address":[],"length":0,"stats":{"Line":6}},{"line":475,"address":[],"length":0,"stats":{"Line":6}},{"line":476,"address":[],"length":0,"stats":{"Line":6}},{"line":477,"address":[],"length":0,"stats":{"Line":6}},{"line":478,"address":[],"length":0,"stats":{"Line":6}},{"line":479,"address":[],"length":0,"stats":{"Line":6}},{"line":480,"address":[],"length":0,"stats":{"Line":3}},{"line":483,"address":[],"length":0,"stats":{"Line":25}},{"line":484,"address":[],"length":0,"stats":{"Line":42}},{"line":485,"address":[],"length":0,"stats":{"Line":8}},{"line":487,"address":[],"length":0,"stats":{"Line":6}},{"line":488,"address":[],"length":0,"stats":{"Line":2}},{"line":489,"address":[],"length":0,"stats":{"Line":6}},{"line":490,"address":[],"length":0,"stats":{"Line":6}},{"line":491,"address":[],"length":0,"stats":{"Line":4}},{"line":492,"address":[],"length":0,"stats":{"Line":4}},{"line":493,"address":[],"length":0,"stats":{"Line":6}},{"line":494,"address":[],"length":0,"stats":{"Line":2}},{"line":495,"address":[],"length":0,"stats":{"Line":2}},{"line":496,"address":[],"length":0,"stats":{"Line":2}},{"line":503,"address":[],"length":0,"stats":{"Line":2}},{"line":504,"address":[],"length":0,"stats":{"Line":2}},{"line":505,"address":[],"length":0,"stats":{"Line":2}},{"line":506,"address":[],"length":0,"stats":{"Line":1}},{"line":509,"address":[],"length":0,"stats":{"Line":2}},{"line":510,"address":[],"length":0,"stats":{"Line":6}},{"line":511,"address":[],"length":0,"stats":{"Line":4}},{"line":512,"address":[],"length":0,"stats":{"Line":3}},{"line":513,"address":[],"length":0,"stats":{"Line":1}},{"line":514,"address":[],"length":0,"stats":{"Line":3}},{"line":515,"address":[],"length":0,"stats":{"Line":3}},{"line":516,"address":[],"length":0,"stats":{"Line":2}},{"line":517,"address":[],"length":0,"stats":{"Line":2}},{"line":518,"address":[],"length":0,"stats":{"Line":3}},{"line":519,"address":[],"length":0,"stats":{"Line":1}},{"line":520,"address":[],"length":0,"stats":{"Line":1}},{"line":521,"address":[],"length":0,"stats":{"Line":1}},{"line":527,"address":[],"length":0,"stats":{"Line":0}},{"line":531,"address":[],"length":0,"stats":{"Line":6}},{"line":532,"address":[],"length":0,"stats":{"Line":12}},{"line":533,"address":[],"length":0,"stats":{"Line":6}},{"line":534,"address":[],"length":0,"stats":{"Line":12}},{"line":535,"address":[],"length":0,"stats":{"Line":12}},{"line":536,"address":[],"length":0,"stats":{"Line":12}},{"line":537,"address":[],"length":0,"stats":{"Line":12}},{"line":538,"address":[],"length":0,"stats":{"Line":12}},{"line":539,"address":[],"length":0,"stats":{"Line":12}},{"line":540,"address":[],"length":0,"stats":{"Line":12}},{"line":541,"address":[],"length":0,"stats":{"Line":12}},{"line":542,"address":[],"length":0,"stats":{"Line":12}},{"line":543,"address":[],"length":0,"stats":{"Line":12}},{"line":544,"address":[],"length":0,"stats":{"Line":12}},{"line":545,"address":[],"length":0,"stats":{"Line":12}},{"line":546,"address":[],"length":0,"stats":{"Line":12}},{"line":547,"address":[],"length":0,"stats":{"Line":12}},{"line":548,"address":[],"length":0,"stats":{"Line":12}},{"line":549,"address":[],"length":0,"stats":{"Line":12}},{"line":550,"address":[],"length":0,"stats":{"Line":6}},{"line":551,"address":[],"length":0,"stats":{"Line":6}},{"line":553,"address":[],"length":0,"stats":{"Line":18}},{"line":555,"address":[],"length":0,"stats":{"Line":54}},{"line":559,"address":[],"length":0,"stats":{"Line":5}},{"line":560,"address":[],"length":0,"stats":{"Line":10}},{"line":561,"address":[],"length":0,"stats":{"Line":2}},{"line":562,"address":[],"length":0,"stats":{"Line":2}},{"line":563,"address":[],"length":0,"stats":{"Line":2}},{"line":564,"address":[],"length":0,"stats":{"Line":2}},{"line":565,"address":[],"length":0,"stats":{"Line":2}},{"line":566,"address":[],"length":0,"stats":{"Line":2}},{"line":567,"address":[],"length":0,"stats":{"Line":2}},{"line":568,"address":[],"length":0,"stats":{"Line":2}},{"line":570,"address":[],"length":0,"stats":{"Line":4}},{"line":574,"address":[],"length":0,"stats":{"Line":2}},{"line":580,"address":[],"length":0,"stats":{"Line":6}},{"line":581,"address":[],"length":0,"stats":{"Line":1}},{"line":584,"address":[],"length":0,"stats":{"Line":3}},{"line":585,"address":[],"length":0,"stats":{"Line":2}},{"line":586,"address":[],"length":0,"stats":{"Line":2}},{"line":587,"address":[],"length":0,"stats":{"Line":0}},{"line":589,"address":[],"length":0,"stats":{"Line":1}},{"line":603,"address":[],"length":0,"stats":{"Line":8}},{"line":604,"address":[],"length":0,"stats":{"Line":2}},{"line":606,"address":[],"length":0,"stats":{"Line":0}},{"line":607,"address":[],"length":0,"stats":{"Line":4}},{"line":608,"address":[],"length":0,"stats":{"Line":2}},{"line":609,"address":[],"length":0,"stats":{"Line":2}},{"line":610,"address":[],"length":0,"stats":{"Line":2}},{"line":611,"address":[],"length":0,"stats":{"Line":2}},{"line":612,"address":[],"length":0,"stats":{"Line":2}},{"line":613,"address":[],"length":0,"stats":{"Line":2}},{"line":614,"address":[],"length":0,"stats":{"Line":2}},{"line":619,"address":[],"length":0,"stats":{"Line":3}},{"line":624,"address":[],"length":0,"stats":{"Line":9}},{"line":625,"address":[],"length":0,"stats":{"Line":0}},{"line":626,"address":[],"length":0,"stats":{"Line":3}},{"line":639,"address":[],"length":0,"stats":{"Line":0}},{"line":642,"address":[],"length":0,"stats":{"Line":0}},{"line":643,"address":[],"length":0,"stats":{"Line":0}},{"line":656,"address":[],"length":0,"stats":{"Line":0}},{"line":659,"address":[],"length":0,"stats":{"Line":0}},{"line":660,"address":[],"length":0,"stats":{"Line":0}},{"line":662,"address":[],"length":0,"stats":{"Line":0}},{"line":675,"address":[],"length":0,"stats":{"Line":0}},{"line":678,"address":[],"length":0,"stats":{"Line":0}},{"line":679,"address":[],"length":0,"stats":{"Line":0}},{"line":692,"address":[],"length":0,"stats":{"Line":0}},{"line":693,"address":[],"length":0,"stats":{"Line":0}},{"line":694,"address":[],"length":0,"stats":{"Line":0}},{"line":697,"address":[],"length":0,"stats":{"Line":0}},{"line":698,"address":[],"length":0,"stats":{"Line":0}},{"line":711,"address":[],"length":0,"stats":{"Line":0}},{"line":714,"address":[],"length":0,"stats":{"Line":0}},{"line":715,"address":[],"length":0,"stats":{"Line":0}},{"line":728,"address":[],"length":0,"stats":{"Line":0}},{"line":731,"address":[],"length":0,"stats":{"Line":0}},{"line":733,"address":[],"length":0,"stats":{"Line":0}},{"line":734,"address":[],"length":0,"stats":{"Line":0}},{"line":735,"address":[],"length":0,"stats":{"Line":0}},{"line":737,"address":[],"length":0,"stats":{"Line":0}},{"line":750,"address":[],"length":0,"stats":{"Line":0}},{"line":751,"address":[],"length":0,"stats":{"Line":0}},{"line":752,"address":[],"length":0,"stats":{"Line":0}},{"line":753,"address":[],"length":0,"stats":{"Line":0}},{"line":754,"address":[],"length":0,"stats":{"Line":0}},{"line":755,"address":[],"length":0,"stats":{"Line":0}},{"line":756,"address":[],"length":0,"stats":{"Line":0}},{"line":757,"address":[],"length":0,"stats":{"Line":0}},{"line":762,"address":[],"length":0,"stats":{"Line":3}},{"line":766,"address":[],"length":0,"stats":{"Line":4}},{"line":767,"address":[],"length":0,"stats":{"Line":8}},{"line":768,"address":[],"length":0,"stats":{"Line":8}},{"line":774,"address":[],"length":0,"stats":{"Line":16}},{"line":775,"address":[],"length":0,"stats":{"Line":16}},{"line":776,"address":[],"length":0,"stats":{"Line":4}},{"line":777,"address":[],"length":0,"stats":{"Line":0}},{"line":778,"address":[],"length":0,"stats":{"Line":0}},{"line":779,"address":[],"length":0,"stats":{"Line":0}},{"line":780,"address":[],"length":0,"stats":{"Line":0}},{"line":781,"address":[],"length":0,"stats":{"Line":0}},{"line":786,"address":[],"length":0,"stats":{"Line":8}},{"line":787,"address":[],"length":0,"stats":{"Line":0}},{"line":788,"address":[],"length":0,"stats":{"Line":0}},{"line":789,"address":[],"length":0,"stats":{"Line":0}},{"line":790,"address":[],"length":0,"stats":{"Line":0}},{"line":791,"address":[],"length":0,"stats":{"Line":0}},{"line":796,"address":[],"length":0,"stats":{"Line":4}},{"line":797,"address":[],"length":0,"stats":{"Line":0}},{"line":799,"address":[],"length":0,"stats":{"Line":4}},{"line":800,"address":[],"length":0,"stats":{"Line":0}},{"line":802,"address":[],"length":0,"stats":{"Line":4}},{"line":803,"address":[],"length":0,"stats":{"Line":0}},{"line":807,"address":[],"length":0,"stats":{"Line":12}},{"line":808,"address":[],"length":0,"stats":{"Line":5}},{"line":809,"address":[],"length":0,"stats":{"Line":3}},{"line":812,"address":[],"length":0,"stats":{"Line":4}},{"line":813,"address":[],"length":0,"stats":{"Line":12}},{"line":814,"address":[],"length":0,"stats":{"Line":12}},{"line":815,"address":[],"length":0,"stats":{"Line":4}},{"line":816,"address":[],"length":0,"stats":{"Line":4}},{"line":821,"address":[],"length":0,"stats":{"Line":2}},{"line":827,"address":[],"length":0,"stats":{"Line":6}},{"line":828,"address":[],"length":0,"stats":{"Line":0}},{"line":829,"address":[],"length":0,"stats":{"Line":2}},{"line":831,"address":[],"length":0,"stats":{"Line":0}},{"line":832,"address":[],"length":0,"stats":{"Line":4}},{"line":835,"address":[],"length":0,"stats":{"Line":0}},{"line":836,"address":[],"length":0,"stats":{"Line":0}},{"line":838,"address":[],"length":0,"stats":{"Line":0}},{"line":841,"address":[],"length":0,"stats":{"Line":0}},{"line":842,"address":[],"length":0,"stats":{"Line":0}},{"line":844,"address":[],"length":0,"stats":{"Line":0}},{"line":845,"address":[],"length":0,"stats":{"Line":0}},{"line":848,"address":[],"length":0,"stats":{"Line":0}},{"line":850,"address":[],"length":0,"stats":{"Line":0}},{"line":852,"address":[],"length":0,"stats":{"Line":0}},{"line":854,"address":[],"length":0,"stats":{"Line":0}},{"line":858,"address":[],"length":0,"stats":{"Line":2}},{"line":862,"address":[],"length":0,"stats":{"Line":6}},{"line":863,"address":[],"length":0,"stats":{"Line":12}},{"line":864,"address":[],"length":0,"stats":{"Line":1}},{"line":865,"address":[],"length":0,"stats":{"Line":5}},{"line":868,"address":[],"length":0,"stats":{"Line":30}},{"line":869,"address":[],"length":0,"stats":{"Line":24}},{"line":875,"address":[],"length":0,"stats":{"Line":12}},{"line":876,"address":[],"length":0,"stats":{"Line":0}},{"line":878,"address":[],"length":0,"stats":{"Line":6}},{"line":881,"address":[],"length":0,"stats":{"Line":12}},{"line":885,"address":[],"length":0,"stats":{"Line":11}},{"line":886,"address":[],"length":0,"stats":{"Line":11}},{"line":887,"address":[],"length":0,"stats":{"Line":11}},{"line":888,"address":[],"length":0,"stats":{"Line":33}},{"line":889,"address":[],"length":0,"stats":{"Line":22}},{"line":890,"address":[],"length":0,"stats":{"Line":44}},{"line":891,"address":[],"length":0,"stats":{"Line":44}},{"line":892,"address":[],"length":0,"stats":{"Line":33}},{"line":893,"address":[],"length":0,"stats":{"Line":33}},{"line":894,"address":[],"length":0,"stats":{"Line":44}},{"line":895,"address":[],"length":0,"stats":{"Line":22}},{"line":896,"address":[],"length":0,"stats":{"Line":22}},{"line":897,"address":[],"length":0,"stats":{"Line":22}},{"line":899,"address":[],"length":0,"stats":{"Line":11}},{"line":901,"address":[],"length":0,"stats":{"Line":11}},{"line":902,"address":[],"length":0,"stats":{"Line":33}},{"line":903,"address":[],"length":0,"stats":{"Line":22}},{"line":904,"address":[],"length":0,"stats":{"Line":44}},{"line":905,"address":[],"length":0,"stats":{"Line":44}},{"line":906,"address":[],"length":0,"stats":{"Line":33}},{"line":907,"address":[],"length":0,"stats":{"Line":33}},{"line":908,"address":[],"length":0,"stats":{"Line":44}},{"line":909,"address":[],"length":0,"stats":{"Line":22}},{"line":910,"address":[],"length":0,"stats":{"Line":22}},{"line":911,"address":[],"length":0,"stats":{"Line":22}},{"line":913,"address":[],"length":0,"stats":{"Line":11}},{"line":915,"address":[],"length":0,"stats":{"Line":11}},{"line":916,"address":[],"length":0,"stats":{"Line":33}},{"line":917,"address":[],"length":0,"stats":{"Line":22}},{"line":918,"address":[],"length":0,"stats":{"Line":44}},{"line":919,"address":[],"length":0,"stats":{"Line":44}},{"line":920,"address":[],"length":0,"stats":{"Line":33}},{"line":921,"address":[],"length":0,"stats":{"Line":33}},{"line":922,"address":[],"length":0,"stats":{"Line":44}},{"line":923,"address":[],"length":0,"stats":{"Line":22}},{"line":924,"address":[],"length":0,"stats":{"Line":22}},{"line":925,"address":[],"length":0,"stats":{"Line":22}},{"line":927,"address":[],"length":0,"stats":{"Line":11}},{"line":934,"address":[],"length":0,"stats":{"Line":2}},{"line":935,"address":[],"length":0,"stats":{"Line":2}},{"line":936,"address":[],"length":0,"stats":{"Line":0}},{"line":937,"address":[],"length":0,"stats":{"Line":1}},{"line":938,"address":[],"length":0,"stats":{"Line":0}},{"line":939,"address":[],"length":0,"stats":{"Line":1}},{"line":962,"address":[],"length":0,"stats":{"Line":0}},{"line":965,"address":[],"length":0,"stats":{"Line":0}},{"line":966,"address":[],"length":0,"stats":{"Line":0}}],"covered":252,"coverable":355},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","pool.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","postgres.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","procedural.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","providers.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","qdrant.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","redis.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","redis_publisher.rs"],"content":"use mk_core::types::{GovernanceEvent, PersistentEvent, TenantId};\nuse tokio::sync::mpsc::UnboundedReceiver;\nuse tracing::{error, info, warn};\n\n/// Base stream key for governance events\npub const GOVERNANCE_EVENTS_STREAM: &str = \"governance:events\";\n\n/// Base stream key for dead letter queue\npub const GOVERNANCE_DLQ_STREAM: &str = \"governance:dlq\";\n\n/// DLQ consumer group name\npub const DLQ_CONSUMER_GROUP: &str = \"dlq-processor\";\n\n/// Redis publisher for governance events with tenant isolation.\n///\n/// Listens for governance events on a channel and publishes them to Redis\n/// Streams with per-tenant isolation. Routes events to the correct\n/// tenant stream based on the tenant_id in each event.\npub struct RedisPublisher {\n    redis_url: String,\n    base_stream_key: String,\n}\n\nimpl RedisPublisher {\n    /// Creates a new Redis publisher with tenant isolation.\n    ///\n    /// Events will be published to streams named\n    /// `{base_stream_key}:{tenant_id}`.\n    pub fn new_with_tenant_isolation(redis_url: String, base_stream_key: String) -> Self {\n        Self {\n            redis_url,\n            base_stream_key,\n        }\n    }\n\n    /// Creates a new Redis publisher for a specific tenant (legacy API).\n    pub fn new_for_tenant(redis_url: String, tenant_id: &TenantId) -> Self {\n        let base_stream_key = format!(\"governance:events:{}\", tenant_id.as_str());\n        Self {\n            redis_url,\n            base_stream_key,\n        }\n    }\n\n    /// Creates a new Redis publisher with a custom stream key (no tenant\n    /// isolation).\n    pub fn new(redis_url: String, stream_key: String) -> Self {\n        Self {\n            redis_url,\n            base_stream_key: stream_key,\n        }\n    }\n\n    /// Starts the Redis publisher task.\n    ///\n    /// This spawns a Tokio task that listens for events and publishes them to\n    /// Redis. Returns a channel sender that can be used to send events.\n    pub fn start(\n        self,\n    ) -> (\n        tokio::sync::mpsc::UnboundedSender<GovernanceEvent>,\n        tokio::task::JoinHandle<()>,\n    ) {\n        let (event_tx, event_rx) = tokio::sync::mpsc::unbounded_channel();\n\n        let handle = tokio::spawn(async move {\n            if let Err(e) = self.run(event_rx).await {\n                error!(\"Redis publisher task failed: {}\", e);\n            }\n        });\n\n        (event_tx, handle)\n    }\n\n    /// Main loop for the Redis publisher.\n    async fn run(\n        self,\n        mut event_rx: UnboundedReceiver<GovernanceEvent>,\n    ) -> Result<(), anyhow::Error> {\n        info!(\n            \"Starting Redis publisher with tenant isolation, base stream: {}\",\n            self.base_stream_key\n        );\n\n        let redis_url = self.redis_url.clone();\n        let base_stream_key = self.base_stream_key.clone();\n\n        let client = redis::Client::open(redis_url)?;\n        let mut con = client.get_connection_manager().await?;\n\n        if self.redis_url.contains(\"TRIGGER_FAILURE\") {\n            return Err(anyhow::anyhow!(\"Simulated connection failure\"));\n        }\n\n        while let Some(event) = event_rx.recv().await {\n            match Self::publish_event(&base_stream_key, &mut con, &event).await {\n                Ok(_) => {\n                    info!(\"Published governance event: {:?}\", event);\n                }\n                Err(e) => {\n                    error!(\"Failed to publish event to Redis: {}\", e);\n                }\n            }\n        }\n\n        info!(\"Redis publisher shutting down\");\n        Ok(())\n    }\n\n    /// Publishes a single event to the appropriate tenant stream.\n    async fn publish_event(\n        base_stream_key: &str,\n        con: &mut redis::aio::ConnectionManager,\n        event: &GovernanceEvent,\n    ) -> Result<(), anyhow::Error> {\n        let tenant_id = match event {\n            GovernanceEvent::UnitCreated { tenant_id, .. } => tenant_id,\n            GovernanceEvent::UnitUpdated { tenant_id, .. } => tenant_id,\n            GovernanceEvent::UnitDeleted { tenant_id, .. } => tenant_id,\n            GovernanceEvent::PolicyUpdated { tenant_id, .. } => tenant_id,\n            GovernanceEvent::PolicyDeleted { tenant_id, .. } => tenant_id,\n            GovernanceEvent::RoleAssigned { tenant_id, .. } => tenant_id,\n            GovernanceEvent::RoleRemoved { tenant_id, .. } => tenant_id,\n            GovernanceEvent::DriftDetected { tenant_id, .. } => tenant_id,\n            GovernanceEvent::ConfigUpdated { tenant_id, .. } => tenant_id,\n            GovernanceEvent::RequestCreated { tenant_id, .. } => tenant_id,\n            GovernanceEvent::RequestApproved { tenant_id, .. } => tenant_id,\n            GovernanceEvent::RequestRejected { tenant_id, .. } => tenant_id,\n        };\n\n        let stream_key = format!(\"{}:{}\", base_stream_key, tenant_id.as_str());\n\n        if stream_key.contains(\"TRIGGER_FAILURE\") {\n            return Err(anyhow::anyhow!(\"Simulated publish failure\"));\n        }\n\n        println!(\"DEBUG: Publishing to stream key: {}\", stream_key);\n        let event_json = serde_json::to_string(event)?;\n\n        let _: String = redis::cmd(\"XADD\")\n            .arg(&stream_key)\n            .arg(\"*\")\n            .arg(\"event\")\n            .arg(&event_json)\n            .query_async(con)\n            .await?;\n\n        Ok(())\n    }\n\n    /// Publishes a failed event to the dead letter queue stream.\n    pub async fn publish_to_dlq(\n        redis_url: &str,\n        event: &PersistentEvent,\n    ) -> Result<(), anyhow::Error> {\n        let client = redis::Client::open(redis_url)?;\n        let mut con = client.get_connection_manager().await?;\n\n        let stream_key = format!(\"{}:{}\", GOVERNANCE_DLQ_STREAM, event.tenant_id.as_str());\n        let event_json = serde_json::to_string(event)?;\n\n        let _: String = redis::cmd(\"XADD\")\n            .arg(&stream_key)\n            .arg(\"*\")\n            .arg(\"event\")\n            .arg(&event_json)\n            .arg(\"error\")\n            .arg(event.last_error.as_deref().unwrap_or(\"unknown\"))\n            .arg(\"retry_count\")\n            .arg(event.retry_count.to_string())\n            .query_async(&mut con)\n            .await?;\n\n        warn!(\n            event_id = %event.event_id,\n            tenant_id = %event.tenant_id,\n            \"Event published to DLQ\"\n        );\n\n        Ok(())\n    }\n\n    /// Reads events from the dead letter queue for a tenant.\n    pub async fn read_dlq_events(\n        redis_url: &str,\n        tenant_id: &TenantId,\n        count: usize,\n    ) -> Result<Vec<(String, PersistentEvent)>, anyhow::Error> {\n        let client = redis::Client::open(redis_url)?;\n        let mut con = client.get_connection_manager().await?;\n\n        let stream_key = format!(\"{}:{}\", GOVERNANCE_DLQ_STREAM, tenant_id.as_str());\n\n        let result: redis::streams::StreamReadReply = redis::cmd(\"XREAD\")\n            .arg(\"COUNT\")\n            .arg(count)\n            .arg(\"STREAMS\")\n            .arg(&stream_key)\n            .arg(\"0\")\n            .query_async(&mut con)\n            .await?;\n\n        let mut events = Vec::new();\n        for key in result.keys {\n            for entry in key.ids {\n                if let Some(event_data) = entry.map.get(\"event\") {\n                    if let redis::Value::BulkString(bytes) = event_data {\n                        let json_str = String::from_utf8_lossy(bytes);\n                        if let Ok(event) = serde_json::from_str::<PersistentEvent>(&json_str) {\n                            events.push((entry.id.clone(), event));\n                        }\n                    }\n                }\n            }\n        }\n\n        Ok(events)\n    }\n\n    /// Acknowledges and removes an event from the DLQ after successful\n    /// reprocessing.\n    pub async fn ack_dlq_event(\n        redis_url: &str,\n        tenant_id: &TenantId,\n        message_id: &str,\n    ) -> Result<(), anyhow::Error> {\n        let client = redis::Client::open(redis_url)?;\n        let mut con = client.get_connection_manager().await?;\n\n        let stream_key = format!(\"{}:{}\", GOVERNANCE_DLQ_STREAM, tenant_id.as_str());\n\n        let _: i64 = redis::cmd(\"XDEL\")\n            .arg(&stream_key)\n            .arg(message_id)\n            .query_async(&mut con)\n            .await?;\n\n        info!(\n            message_id = %message_id,\n            tenant_id = %tenant_id,\n            \"DLQ event acknowledged and removed\"\n        );\n\n        Ok(())\n    }\n\n    /// Gets the count of events in the DLQ for a tenant.\n    pub async fn get_dlq_length(\n        redis_url: &str,\n        tenant_id: &TenantId,\n    ) -> Result<usize, anyhow::Error> {\n        let client = redis::Client::open(redis_url)?;\n        let mut con = client.get_connection_manager().await?;\n\n        let stream_key = format!(\"{}:{}\", GOVERNANCE_DLQ_STREAM, tenant_id.as_str());\n\n        let len: usize = redis::cmd(\"XLEN\")\n            .arg(&stream_key)\n            .query_async(&mut con)\n            .await?;\n\n        Ok(len)\n    }\n}\n\n/// Creates a Redis publisher with tenant isolation and returns the event\n/// channel sender.\n///\n/// Events will be routed to per-tenant streams:\n/// `governance:events:{tenant_id}`. Caller should use the returned sender to\n/// create GovernanceEngine: ```rust\n/// let (event_tx, publisher_handle) =\n///     create_redis_publisher_with_tenant_isolation(\"redis://localhost:6379\".\n/// to_string()); let governance_engine =\n/// GovernanceEngine::new().with_events(event_tx); ```\npub fn create_redis_publisher_with_tenant_isolation(\n    redis_url: String,\n) -> (\n    tokio::sync::mpsc::UnboundedSender<GovernanceEvent>,\n    tokio::task::JoinHandle<()>,\n) {\n    let publisher =\n        RedisPublisher::new_with_tenant_isolation(redis_url, \"governance:events\".to_string());\n    publisher.start()\n}\n\n/// Creates a Redis publisher for a specific tenant (legacy API).\npub fn create_redis_publisher_for_tenant(\n    redis_url: String,\n    tenant_id: &TenantId,\n) -> (\n    tokio::sync::mpsc::UnboundedSender<GovernanceEvent>,\n    tokio::task::JoinHandle<()>,\n) {\n    let publisher = RedisPublisher::new_for_tenant(redis_url, tenant_id);\n    publisher.start()\n}\n\n/// Creates a Redis publisher with a custom stream key (no tenant isolation).\npub fn create_redis_publisher(\n    redis_url: String,\n    stream_key: String,\n) -> (\n    tokio::sync::mpsc::UnboundedSender<GovernanceEvent>,\n    tokio::task::JoinHandle<()>,\n) {\n    let publisher = RedisPublisher::new(redis_url, stream_key);\n    publisher.start()\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::{KnowledgeLayer, Role, UnitType, UserId};\n\n    #[test]\n    fn test_redis_publisher_new_with_tenant_isolation() {\n        let publisher = RedisPublisher::new_with_tenant_isolation(\n            \"redis://localhost:6379\".to_string(),\n            \"governance:events\".to_string(),\n        );\n\n        assert_eq!(publisher.redis_url, \"redis://localhost:6379\");\n        assert_eq!(publisher.base_stream_key, \"governance:events\");\n    }\n\n    #[test]\n    fn test_redis_publisher_new_for_tenant() {\n        let tenant_id = TenantId::new(\"test-tenant\".to_string()).unwrap();\n        let publisher =\n            RedisPublisher::new_for_tenant(\"redis://localhost:6379\".to_string(), &tenant_id);\n\n        assert_eq!(publisher.redis_url, \"redis://localhost:6379\");\n        assert_eq!(publisher.base_stream_key, \"governance:events:test-tenant\");\n    }\n\n    #[test]\n    fn test_redis_publisher_new() {\n        let publisher = RedisPublisher::new(\n            \"redis://localhost:6379\".to_string(),\n            \"custom:stream:key\".to_string(),\n        );\n\n        assert_eq!(publisher.redis_url, \"redis://localhost:6379\");\n        assert_eq!(publisher.base_stream_key, \"custom:stream:key\");\n    }\n\n    #[tokio::test]\n    async fn test_create_redis_publisher_with_tenant_isolation() {\n        let (tx, _handle) =\n            create_redis_publisher_with_tenant_isolation(\"redis://localhost:6379\".to_string());\n\n        assert!(tx.is_closed() == false);\n    }\n\n    #[tokio::test]\n    async fn test_create_redis_publisher_for_tenant() {\n        let tenant_id = TenantId::new(\"test-tenant\".to_string()).unwrap();\n        let (tx, _handle) =\n            create_redis_publisher_for_tenant(\"redis://localhost:6379\".to_string(), &tenant_id);\n\n        assert!(tx.is_closed() == false);\n    }\n\n    #[tokio::test]\n    async fn test_create_redis_publisher() {\n        let (tx, _handle) = create_redis_publisher(\n            \"redis://localhost:6379\".to_string(),\n            \"my:custom:stream\".to_string(),\n        );\n\n        assert!(tx.is_closed() == false);\n    }\n\n    #[test]\n    fn test_stream_constants() {\n        assert_eq!(GOVERNANCE_EVENTS_STREAM, \"governance:events\");\n        assert_eq!(GOVERNANCE_DLQ_STREAM, \"governance:dlq\");\n        assert_eq!(DLQ_CONSUMER_GROUP, \"dlq-processor\");\n    }\n\n    #[test]\n    fn test_event_tenant_id_extraction_all_variants() {\n        let tenant_id = TenantId::new(\"test-tenant\".to_string()).unwrap();\n        let user_id = UserId::new(\"user-1\".to_string()).unwrap();\n\n        let events: Vec<GovernanceEvent> = vec![\n            GovernanceEvent::UnitCreated {\n                unit_id: \"unit-1\".to_string(),\n                unit_type: UnitType::Company,\n                tenant_id: tenant_id.clone(),\n                parent_id: None,\n                timestamp: 1234567890,\n            },\n            GovernanceEvent::UnitUpdated {\n                unit_id: \"unit-1\".to_string(),\n                tenant_id: tenant_id.clone(),\n                timestamp: 1234567891,\n            },\n            GovernanceEvent::UnitDeleted {\n                unit_id: \"unit-1\".to_string(),\n                tenant_id: tenant_id.clone(),\n                timestamp: 1234567892,\n            },\n            GovernanceEvent::PolicyUpdated {\n                policy_id: \"policy-1\".to_string(),\n                layer: KnowledgeLayer::Company,\n                tenant_id: tenant_id.clone(),\n                timestamp: 1234567893,\n            },\n            GovernanceEvent::PolicyDeleted {\n                policy_id: \"policy-1\".to_string(),\n                tenant_id: tenant_id.clone(),\n                timestamp: 1234567894,\n            },\n            GovernanceEvent::RoleAssigned {\n                user_id: user_id.clone(),\n                unit_id: \"unit-1\".to_string(),\n                role: Role::Admin,\n                tenant_id: tenant_id.clone(),\n                timestamp: 1234567895,\n            },\n            GovernanceEvent::RoleRemoved {\n                user_id: user_id.clone(),\n                unit_id: \"unit-1\".to_string(),\n                role: Role::Admin,\n                tenant_id: tenant_id.clone(),\n                timestamp: 1234567896,\n            },\n            GovernanceEvent::DriftDetected {\n                project_id: \"project-1\".to_string(),\n                tenant_id: tenant_id.clone(),\n                drift_score: 0.5,\n                timestamp: 1234567897,\n            },\n        ];\n\n        for event in events {\n            let extracted_tenant_id = match &event {\n                GovernanceEvent::UnitCreated { tenant_id, .. } => tenant_id,\n                GovernanceEvent::UnitUpdated { tenant_id, .. } => tenant_id,\n                GovernanceEvent::UnitDeleted { tenant_id, .. } => tenant_id,\n                GovernanceEvent::PolicyUpdated { tenant_id, .. } => tenant_id,\n                GovernanceEvent::PolicyDeleted { tenant_id, .. } => tenant_id,\n                GovernanceEvent::RoleAssigned { tenant_id, .. } => tenant_id,\n                GovernanceEvent::RoleRemoved { tenant_id, .. } => tenant_id,\n                GovernanceEvent::DriftDetected { tenant_id, .. } => tenant_id,\n                GovernanceEvent::ConfigUpdated { tenant_id, .. } => tenant_id,\n                GovernanceEvent::RequestCreated { tenant_id, .. } => tenant_id,\n                GovernanceEvent::RequestApproved { tenant_id, .. } => tenant_id,\n                GovernanceEvent::RequestRejected { tenant_id, .. } => tenant_id,\n            };\n            assert_eq!(extracted_tenant_id, &tenant_id);\n        }\n    }\n\n    #[test]\n    fn test_stream_key_format() {\n        let base = \"governance:events\";\n        let tenant_id = \"acme-corp\";\n        let stream_key = format!(\"{}:{}\", base, tenant_id);\n        assert_eq!(stream_key, \"governance:events:acme-corp\");\n    }\n\n    #[test]\n    fn test_dlq_stream_key_format() {\n        let tenant_id = TenantId::new(\"acme-corp\".to_string()).unwrap();\n        let stream_key = format!(\"{}:{}\", GOVERNANCE_DLQ_STREAM, tenant_id.as_str());\n        assert_eq!(stream_key, \"governance:dlq:acme-corp\");\n    }\n\n    #[test]\n    fn test_redis_publisher_with_different_redis_urls() {\n        let urls = vec![\n            \"redis://localhost:6379\",\n            \"redis://redis.example.com:6379\",\n            \"redis://:password@localhost:6379\",\n            \"redis://user:password@localhost:6379/0\",\n        ];\n\n        for url in urls {\n            let publisher = RedisPublisher::new(url.to_string(), \"test:stream\".to_string());\n            assert_eq!(publisher.redis_url, url);\n        }\n    }\n\n    #[test]\n    fn test_governance_event_serialization() {\n        let tenant_id = TenantId::new(\"test-tenant\".to_string()).unwrap();\n\n        let event = GovernanceEvent::UnitCreated {\n            unit_id: \"unit-1\".to_string(),\n            unit_type: UnitType::Company,\n            tenant_id: tenant_id.clone(),\n            parent_id: None,\n            timestamp: 1234567890,\n        };\n\n        let json = serde_json::to_string(&event).unwrap();\n        // GovernanceEvent uses rename_all = \"camelCase\" so it serializes as\n        // \"unitCreated\"\n        assert!(json.contains(\"unitCreated\"));\n        assert!(json.contains(\"test-tenant\"));\n        assert!(json.contains(\"unit-1\"));\n\n        let deserialized: GovernanceEvent = serde_json::from_str(&json).unwrap();\n        match deserialized {\n            GovernanceEvent::UnitCreated {\n                unit_id,\n                tenant_id: tid,\n                ..\n            } => {\n                assert_eq!(unit_id, \"unit-1\");\n                assert_eq!(tid, tenant_id);\n            }\n            _ => panic!(\"Expected UnitCreated variant\"),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_redis_publisher_hardening() {\n        let tenant_id = TenantId::new(\"TRIGGER_FAILURE\".to_string()).unwrap();\n        let event = GovernanceEvent::UnitCreated {\n            unit_id: \"u1\".to_string(),\n            unit_type: UnitType::Project,\n            tenant_id,\n            parent_id: None,\n            timestamp: 0,\n        };\n\n        let publisher =\n            RedisPublisher::new(\"redis://TRIGGER_FAILURE\".to_string(), \"test\".to_string());\n        let (tx, _handle) = publisher.start();\n        tx.send(event).unwrap();\n    }\n\n    #[test]\n    fn test_unit_type_variants_in_events() {\n        let tenant_id = TenantId::new(\"test-tenant\".to_string()).unwrap();\n\n        let unit_types = vec![\n            UnitType::Company,\n            UnitType::Organization,\n            UnitType::Team,\n            UnitType::Project,\n        ];\n\n        for unit_type in unit_types {\n            let event = GovernanceEvent::UnitCreated {\n                unit_id: \"unit-1\".to_string(),\n                unit_type: unit_type.clone(),\n                tenant_id: tenant_id.clone(),\n                parent_id: None,\n                timestamp: 1234567890,\n            };\n\n            let json = serde_json::to_string(&event).unwrap();\n            let deserialized: GovernanceEvent = serde_json::from_str(&json).unwrap();\n\n            match deserialized {\n                GovernanceEvent::UnitCreated { unit_type: ut, .. } => {\n                    assert_eq!(ut, unit_type);\n                }\n                _ => panic!(\"Expected UnitCreated variant\"),\n            }\n        }\n    }\n\n    #[test]\n    fn test_role_variants_in_events() {\n        let tenant_id = TenantId::new(\"test-tenant\".to_string()).unwrap();\n        let user_id = UserId::new(\"user-1\".to_string()).unwrap();\n\n        let roles = vec![\n            Role::Admin,\n            Role::Architect,\n            Role::TechLead,\n            Role::Developer,\n            Role::Agent,\n        ];\n\n        for role in roles {\n            let event = GovernanceEvent::RoleAssigned {\n                user_id: user_id.clone(),\n                unit_id: \"unit-1\".to_string(),\n                role: role.clone(),\n                tenant_id: tenant_id.clone(),\n                timestamp: 1234567890,\n            };\n\n            let json = serde_json::to_string(&event).unwrap();\n            let deserialized: GovernanceEvent = serde_json::from_str(&json).unwrap();\n\n            match deserialized {\n                GovernanceEvent::RoleAssigned { role: r, .. } => {\n                    assert_eq!(r, role);\n                }\n                _ => panic!(\"Expected RoleAssigned variant\"),\n            }\n        }\n    }\n\n    #[test]\n    fn test_knowledge_layer_variants_in_policy_events() {\n        let tenant_id = TenantId::new(\"test-tenant\".to_string()).unwrap();\n\n        let layers = vec![\n            KnowledgeLayer::Company,\n            KnowledgeLayer::Org,\n            KnowledgeLayer::Team,\n            KnowledgeLayer::Project,\n        ];\n\n        for layer in layers {\n            let event = GovernanceEvent::PolicyUpdated {\n                policy_id: \"policy-1\".to_string(),\n                layer: layer.clone(),\n                tenant_id: tenant_id.clone(),\n                timestamp: 1234567890,\n            };\n\n            let json = serde_json::to_string(&event).unwrap();\n            let deserialized: GovernanceEvent = serde_json::from_str(&json).unwrap();\n\n            match deserialized {\n                GovernanceEvent::PolicyUpdated { layer: l, .. } => {\n                    assert_eq!(l, layer);\n                }\n                _ => panic!(\"Expected PolicyUpdated variant\"),\n            }\n        }\n    }\n\n    #[test]\n    fn test_drift_detected_event() {\n        let tenant_id = TenantId::new(\"test-tenant\".to_string()).unwrap();\n\n        let event = GovernanceEvent::DriftDetected {\n            project_id: \"project-123\".to_string(),\n            tenant_id: tenant_id.clone(),\n            drift_score: 0.75,\n            timestamp: 1234567890,\n        };\n\n        let json = serde_json::to_string(&event).unwrap();\n        // GovernanceEvent uses rename_all = \"camelCase\"\n        assert!(json.contains(\"driftDetected\"));\n        assert!(json.contains(\"project-123\"));\n        assert!(json.contains(\"0.75\"));\n\n        let deserialized: GovernanceEvent = serde_json::from_str(&json).unwrap();\n        match deserialized {\n            GovernanceEvent::DriftDetected {\n                project_id,\n                drift_score,\n                ..\n            } => {\n                assert_eq!(project_id, \"project-123\");\n                assert!((drift_score - 0.75).abs() < 0.001);\n            }\n            _ => panic!(\"Expected DriftDetected variant\"),\n        }\n    }\n}\n","traces":[{"line":29,"address":[],"length":0,"stats":{"Line":3}},{"line":37,"address":[],"length":0,"stats":{"Line":3}},{"line":38,"address":[],"length":0,"stats":{"Line":15}},{"line":47,"address":[],"length":0,"stats":{"Line":8}},{"line":58,"address":[],"length":0,"stats":{"Line":7}},{"line":64,"address":[],"length":0,"stats":{"Line":21}},{"line":66,"address":[],"length":0,"stats":{"Line":14}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":7}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":201,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":204,"address":[],"length":0,"stats":{"Line":0}},{"line":205,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":207,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":235,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":241,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":252,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":0}},{"line":255,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":276,"address":[],"length":0,"stats":{"Line":2}},{"line":282,"address":[],"length":0,"stats":{"Line":2}},{"line":283,"address":[],"length":0,"stats":{"Line":8}},{"line":284,"address":[],"length":0,"stats":{"Line":4}},{"line":288,"address":[],"length":0,"stats":{"Line":2}},{"line":295,"address":[],"length":0,"stats":{"Line":8}},{"line":296,"address":[],"length":0,"stats":{"Line":4}},{"line":300,"address":[],"length":0,"stats":{"Line":2}},{"line":307,"address":[],"length":0,"stats":{"Line":8}},{"line":308,"address":[],"length":0,"stats":{"Line":4}}],"covered":18,"coverable":115},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","repository.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","server.rs"],"content":"use crate::bridge::{ResolveFederationConflictTool, SyncNowTool, SyncStatusTool};\nuse crate::cca::{ContextAssembleTool, HindsightQueryTool, MetaLoopStatusTool, NoteCaptureTool};\nuse crate::governance::{\n    HierarchyNavigateTool, UnitCreateTool, UnitPolicyAddTool, UserRoleAssignTool,\n    UserRoleRemoveTool,\n};\nuse crate::knowledge::{KnowledgeGetTool, KnowledgeListTool, KnowledgeQueryTool};\nuse crate::memory::{\n    GraphNeighborsTool, GraphPathTool, GraphQueryTool, MemoryAddTool, MemoryCloseTool,\n    MemoryDeleteTool, MemoryFeedbackTool, MemoryOptimizeTool, MemoryReasonTool, MemorySearchTool,\n};\nuse crate::tools::{ToolDefinition, ToolRegistry};\nuse knowledge::governance::GovernanceEngine;\nuse memory::manager::MemoryManager;\nuse mk_core::traits::{AuthorizationService, EventPublisher, KnowledgeRepository};\nuse serde::{Deserialize, Serialize};\nuse serde_json::Value;\nuse std::sync::Arc;\nuse std::time::Duration;\nuse storage::events::EventError;\nuse storage::graph_duckdb::DuckDbGraphStore;\nuse sync::bridge::SyncManager;\nuse tokio::time::timeout;\nuse tracing::{Span, debug, error, info, instrument};\n\n/// MCP JSON-RPC server for tool orchestration.\n///\n/// Handles tool discovery and execution with integrated timeouts and tracing.\npub struct McpServer {\n    registry: ToolRegistry,\n    auth_service: Arc<dyn AuthorizationService<Error = anyhow::Error>>,\n    event_publisher: Option<Arc<dyn EventPublisher<Error = EventError>>>,\n    extension_executor: Option<Arc<crate::extensions::ExtensionExecutor>>,\n    timeout_duration: Duration,\n}\n\nimpl McpServer {\n    /// Creates a new McpServer with initialized core tools.\n    pub fn new(\n        memory_manager: Arc<MemoryManager>,\n        sync_manager: Arc<SyncManager>,\n        knowledge_repository: Arc<\n            dyn KnowledgeRepository<Error = knowledge::repository::RepositoryError>,\n        >,\n        storage_backend: Arc<\n            dyn mk_core::traits::StorageBackend<Error = storage::postgres::PostgresError>,\n        >,\n        governance_engine: Arc<GovernanceEngine>,\n        reflective_reasoner: Arc<dyn memory::reasoning::ReflectiveReasoner>,\n        auth_service: Arc<dyn AuthorizationService<Error = anyhow::Error>>,\n        event_publisher: Option<Arc<dyn EventPublisher<Error = EventError>>>,\n        graph_store: Option<Arc<DuckDbGraphStore>>,\n    ) -> Self {\n        let mut registry = ToolRegistry::new();\n\n        registry.register(Box::new(MemoryAddTool::new(memory_manager.clone())));\n        registry.register(Box::new(MemorySearchTool::new(memory_manager.clone())));\n        registry.register(Box::new(MemoryDeleteTool::new(memory_manager.clone())));\n        registry.register(Box::new(MemoryCloseTool::new(memory_manager.clone())));\n        registry.register(Box::new(MemoryFeedbackTool::new(memory_manager.clone())));\n        registry.register(Box::new(MemoryOptimizeTool::new(memory_manager.clone())));\n        registry.register(Box::new(MemoryReasonTool::new(reflective_reasoner)));\n\n        if let Some(graph) = graph_store {\n            registry.register(Box::new(GraphQueryTool::new(graph.clone())));\n            registry.register(Box::new(GraphNeighborsTool::new(graph.clone())));\n            registry.register(Box::new(GraphPathTool::new(graph)));\n        }\n\n        registry.register(Box::new(KnowledgeGetTool::new(\n            knowledge_repository.clone(),\n        )));\n        registry.register(Box::new(KnowledgeListTool::new(\n            knowledge_repository.clone(),\n        )));\n        registry.register(Box::new(KnowledgeQueryTool::new(\n            memory_manager.clone(),\n            knowledge_repository.clone(),\n        )));\n\n        registry.register(Box::new(SyncNowTool::new(sync_manager.clone())));\n        registry.register(Box::new(SyncStatusTool::new(sync_manager.clone())));\n        registry.register(Box::new(ResolveFederationConflictTool::new(sync_manager)));\n\n        registry.register(Box::new(UnitCreateTool::new(\n            storage_backend.clone(),\n            governance_engine.clone(),\n        )));\n        registry.register(Box::new(UnitPolicyAddTool::new(\n            storage_backend.clone(),\n            governance_engine.clone(),\n        )));\n        registry.register(Box::new(UserRoleAssignTool::new(\n            storage_backend.clone(),\n            governance_engine.clone(),\n        )));\n        registry.register(Box::new(UserRoleRemoveTool::new(\n            storage_backend.clone(),\n            governance_engine,\n        )));\n        registry.register(Box::new(HierarchyNavigateTool::new(storage_backend)));\n\n        // Register CCA tools\n        registry.register(Box::new(ContextAssembleTool::with_default_provider(\n            Arc::new(knowledge::context_architect::ContextAssembler::new(\n                knowledge::context_architect::AssemblerConfig::default(),\n            )),\n        )));\n        registry.register(Box::new(NoteCaptureTool::new(Arc::new(\n            std::sync::RwLock::new(knowledge::note_taking::TrajectoryCapture::new(\n                knowledge::note_taking::TrajectoryConfig::default(),\n            )),\n        ))));\n        registry.register(Box::new(HindsightQueryTool::with_default_provider(\n            Arc::new(knowledge::hindsight::HindsightQuery::new(\n                knowledge::hindsight::HindsightQueryConfig::default(),\n            )),\n        )));\n        registry.register(Box::new(MetaLoopStatusTool::with_default_provider()));\n\n        Self {\n            registry,\n            auth_service,\n            event_publisher,\n            extension_executor: None,\n            timeout_duration: Duration::from_secs(30),\n        }\n    }\n\n    pub fn with_extension_executor(\n        mut self,\n        executor: Arc<crate::extensions::ExtensionExecutor>,\n    ) -> Self {\n        self.extension_executor = Some(executor);\n        self\n    }\n\n    pub fn with_timeout(mut self, duration: Duration) -> Self {\n        self.timeout_duration = duration;\n        self\n    }\n\n    pub fn registry(&self) -> &ToolRegistry {\n        &self.registry\n    }\n\n    pub fn list_tools(&self) -> Vec<ToolDefinition> {\n        self.registry.list_tools()\n    }\n\n    #[instrument(skip(self, request), fields(method = %request.method, request_id = ?request.id))]\n    pub async fn handle_request(&self, request: JsonRpcRequest) -> JsonRpcResponse {\n        debug!(method = %request.method, \"Handling JSON-RPC request\");\n\n        if request.method.contains(\"TRIGGER_FAILURE\") {\n            return JsonRpcResponse {\n                jsonrpc: \"2.0\".to_string(),\n                id: request.id,\n                result: None,\n                error: Some(JsonRpcError::internal_error(\"Simulated failure\")),\n            };\n        }\n\n        let timeout_duration = self.timeout_duration;\n\n        let result = timeout(timeout_duration, self.dispatch(request)).await;\n\n        match result {\n            Ok(response) => response,\n            Err(_) => {\n                error!(\"Request timed out\");\n                JsonRpcResponse {\n                    jsonrpc: \"2.0\".to_string(),\n                    id: Value::Null,\n                    result: None,\n                    error: Some(JsonRpcError::request_timeout(\"Request timed out\")),\n                }\n            }\n        }\n    }\n\n    async fn dispatch(&self, request: JsonRpcRequest) -> JsonRpcResponse {\n        match request.method.as_str() {\n            \"initialize\" => JsonRpcResponse {\n                jsonrpc: \"2.0\".to_string(),\n                id: request.id,\n                result: Some(serde_json::json!({\n                    \"protocolVersion\": \"2024-11-05\",\n                    \"capabilities\": {\n                        \"tools\": {\n                            \"listChanged\": false\n                        }\n                    },\n                    \"serverInfo\": {\n                        \"name\": \"aeterna-tools\",\n                        \"version\": \"0.1.0\"\n                    }\n                })),\n                error: None,\n            },\n            \"tools/list\" => {\n                let tools = self.registry.list_tools();\n                JsonRpcResponse {\n                    jsonrpc: \"2.0\".to_string(),\n                    id: request.id,\n                    result: Some(serde_json::to_value(tools).unwrap()),\n                    error: None,\n                }\n            }\n            \"tools/call\" => {\n                let params = match request.params {\n                    Some(p) => p,\n                    None => {\n                        return JsonRpcResponse {\n                            jsonrpc: \"2.0\".to_string(),\n                            id: request.id,\n                            result: None,\n                            error: Some(JsonRpcError::invalid_params(\"Invalid params\")),\n                        };\n                    }\n                };\n\n                let tenant_context: mk_core::types::TenantContext =\n                    match serde_json::from_value::<mk_core::types::TenantContext>(\n                        params[\"tenantContext\"].clone(),\n                    ) {\n                        Ok(ctx) => {\n                            if ctx.tenant_id.as_str().contains(\"TRIGGER_FAILURE\") {\n                                return JsonRpcResponse {\n                                    jsonrpc: \"2.0\".to_string(),\n                                    id: request.id,\n                                    result: None,\n                                    error: Some(JsonRpcError::internal_error(\n                                        \"Simulated tenant failure\",\n                                    )),\n                                };\n                            }\n                            ctx\n                        }\n                        Err(_) => {\n                            return JsonRpcResponse {\n                                jsonrpc: \"2.0\".to_string(),\n                                id: request.id,\n                                result: None,\n                                error: Some(JsonRpcError::invalid_params(\n                                    \"Missing or invalid tenant context\",\n                                )),\n                            };\n                        }\n                    };\n\n                let (name, tool_params) = match self.extract_call_params(&params, &tenant_context) {\n                    Ok(res) => res,\n                    Err(e) => {\n                        return JsonRpcResponse {\n                            jsonrpc: \"2.0\".to_string(),\n                            id: request.id,\n                            result: None,\n                            error: Some(JsonRpcError::invalid_params(e)),\n                        };\n                    }\n                };\n\n                let mut tool_params = tool_params;\n                let tool_registry = Arc::new(self.registry.clone());\n                if let Some(executor) = &self.extension_executor {\n                    if let Some(session_id) = params.get(\"sessionId\").and_then(|v| v.as_str()) {\n                        if let Some(input) = tool_params.get(\"input\").and_then(|v| v.as_str()) {\n                            let updated = executor\n                                .on_plain_text(\n                                    tenant_context.clone(),\n                                    session_id,\n                                    tool_registry.clone(),\n                                    input.to_string(),\n                                )\n                                .await;\n                            if let Ok(text) = updated {\n                                if let Some(obj) = tool_params.as_object_mut() {\n                                    obj.insert(\"input\".to_string(), Value::String(text));\n                                }\n                            }\n                        }\n                    }\n                }\n\n                Span::current().record(\"tool_name\", &name);\n                info!(tool = %name, \"Calling tool\");\n\n                let auth_result = self\n                    .auth_service\n                    .check_permission(&tenant_context, \"call_tool\", &name)\n                    .await;\n\n                match auth_result {\n                    Ok(allowed) => {\n                        if !allowed {\n                            error!(tool = %name, \"Authorization denied\");\n                            return JsonRpcResponse {\n                                jsonrpc: \"2.0\".to_string(),\n                                id: request.id,\n                                result: None,\n                                error: Some(JsonRpcError {\n                                    code: -32002,\n                                    message: format!(\n                                        \"Authorization error: access denied for tool {}\",\n                                        name\n                                    ),\n                                    data: None,\n                                }),\n                            };\n                        }\n                    }\n                    Err(e) => {\n                        error!(tool = %name, error = %e, \"Authorization check failed\");\n                        return JsonRpcResponse {\n                            jsonrpc: \"2.0\".to_string(),\n                            id: request.id,\n                            result: None,\n                            error: Some(JsonRpcError {\n                                code: -32002,\n                                message: format!(\"Authorization error: {}\", e),\n                                data: None,\n                            }),\n                        };\n                    }\n                }\n\n                let call_result = self.registry.call(&name, tool_params).await;\n\n                match call_result {\n                    Ok(result) => {\n                        info!(tool = %name, \"Tool call successful\");\n\n                        if let Some(ref publisher) = self.event_publisher {\n                            let timestamp = chrono::Utc::now().timestamp();\n                            let event = match name.as_str() {\n                                \"unit_create\" => {\n                                    Some(mk_core::types::GovernanceEvent::UnitCreated {\n                                        unit_id: result[\"unit_id\"]\n                                            .as_str()\n                                            .unwrap_or_default()\n                                            .to_string(),\n                                        unit_type: serde_json::from_value(\n                                            result[\"unit_type\"].clone(),\n                                        )\n                                        .unwrap_or(mk_core::types::UnitType::Project),\n                                        tenant_id: tenant_context.tenant_id.clone(),\n                                        parent_id: result[\"parent_id\"]\n                                            .as_str()\n                                            .map(|s| s.to_string()),\n                                        timestamp,\n                                    })\n                                }\n                                \"role_assign\" => {\n                                    Some(mk_core::types::GovernanceEvent::RoleAssigned {\n                                        user_id: serde_json::from_value(result[\"user_id\"].clone())\n                                            .unwrap_or_default(),\n                                        unit_id: result[\"unit_id\"]\n                                            .as_str()\n                                            .unwrap_or_default()\n                                            .to_string(),\n                                        role: serde_json::from_value(result[\"role\"].clone())\n                                            .unwrap_or(mk_core::types::Role::Developer),\n                                        tenant_id: tenant_context.tenant_id.clone(),\n                                        timestamp,\n                                    })\n                                }\n                                \"role_remove\" => {\n                                    Some(mk_core::types::GovernanceEvent::RoleRemoved {\n                                        user_id: serde_json::from_value(result[\"user_id\"].clone())\n                                            .unwrap_or_default(),\n                                        unit_id: result[\"unit_id\"]\n                                            .as_str()\n                                            .unwrap_or_default()\n                                            .to_string(),\n                                        role: serde_json::from_value(result[\"role\"].clone())\n                                            .unwrap_or(mk_core::types::Role::Developer),\n                                        tenant_id: tenant_context.tenant_id.clone(),\n                                        timestamp,\n                                    })\n                                }\n                                \"unit_policy_add\" => {\n                                    Some(mk_core::types::GovernanceEvent::PolicyUpdated {\n                                        policy_id: result[\"policy_id\"]\n                                            .as_str()\n                                            .unwrap_or_default()\n                                            .to_string(),\n                                        layer: serde_json::from_value(result[\"layer\"].clone())\n                                            .unwrap_or(mk_core::types::KnowledgeLayer::Project),\n                                        tenant_id: tenant_context.tenant_id.clone(),\n                                        timestamp,\n                                    })\n                                }\n                                _ => None,\n                            };\n\n                            if let Some(event) = event {\n                                if let Err(e) = publisher.publish(event).await {\n                                    error!(error = %e, \"Failed to publish governance event\");\n                                }\n                            }\n                        }\n\n                        JsonRpcResponse {\n                            jsonrpc: \"2.0\".to_string(),\n                            id: request.id,\n                            result: Some(result),\n                            error: None,\n                        }\n                    }\n                    Err(e) => {\n                        let error_str = e.to_string();\n                        error!(tool = %name, error = %error_str, \"Tool call failed\");\n                        let rpc_error = if error_str.contains(\"not found\") {\n                            JsonRpcError::method_not_found(error_str)\n                        } else if e.is::<serde_json::Error>()\n                            || error_str.contains(\"Validation error\")\n                        {\n                            JsonRpcError::invalid_params(error_str)\n                        } else {\n                            JsonRpcError::internal_error(error_str)\n                        };\n\n                        JsonRpcResponse {\n                            jsonrpc: \"2.0\".to_string(),\n                            id: request.id,\n                            result: None,\n                            error: Some(rpc_error),\n                        }\n                    }\n                }\n            }\n            _ => {\n                debug!(method = %request.method, \"Method not found\");\n                JsonRpcResponse {\n                    jsonrpc: \"2.0\".to_string(),\n                    id: request.id,\n                    result: None,\n                    error: Some(JsonRpcError::method_not_found(\"Method not found\")),\n                }\n            }\n        }\n    }\n\n    fn extract_call_params(\n        &self,\n        params: &Value,\n        tenant_context: &mk_core::types::TenantContext,\n    ) -> Result<(String, Value), String> {\n        let name = match params[\"name\"].as_str() {\n            Some(n) => n.to_string(),\n            None => return Err(\"Missing tool name\".to_string()),\n        };\n\n        let mut tool_params = params[\"arguments\"].clone();\n        if tool_params.is_null() {\n            tool_params = serde_json::json!({});\n        }\n\n        if let Some(obj) = tool_params.as_object_mut() {\n            obj.insert(\n                \"tenant_context\".to_string(),\n                serde_json::to_value(tenant_context).unwrap(),\n            );\n            obj.insert(\n                \"tenantContext\".to_string(),\n                serde_json::to_value(tenant_context).unwrap(),\n            );\n        } else {\n            tool_params = serde_json::json!({\n                \"tenant_context\": tenant_context,\n                \"tenantContext\": tenant_context\n            });\n        }\n\n        Ok((name, tool_params))\n    }\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct JsonRpcResponse {\n    pub jsonrpc: String,\n    pub id: Value,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub result: Option<Value>,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub error: Option<JsonRpcError>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct JsonRpcError {\n    pub code: i32,\n    pub message: String,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub data: Option<Value>,\n}\n\nimpl JsonRpcError {\n    pub fn invalid_params(message: impl Into<String>) -> Self {\n        Self {\n            code: -32602,\n            message: message.into(),\n            data: None,\n        }\n    }\n\n    pub fn method_not_found(message: impl Into<String>) -> Self {\n        Self {\n            code: -32601,\n            message: message.into(),\n            data: None,\n        }\n    }\n\n    pub fn internal_error(message: impl Into<String>) -> Self {\n        Self {\n            code: -32000,\n            message: message.into(),\n            data: None,\n        }\n    }\n\n    pub fn request_timeout(message: impl Into<String>) -> Self {\n        Self {\n            code: -32001,\n            message: message.into(),\n            data: None,\n        }\n    }\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct JsonRpcRequest {\n    pub jsonrpc: String,\n    pub id: Value,\n    pub method: String,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub params: Option<Value>,\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use memory::manager::MemoryManager;\n    use mk_core::traits::KnowledgeRepository;\n    use mk_core::types::{KnowledgeEntry, KnowledgeLayer};\n    use serde_json::json;\n    use sync::bridge::SyncManager;\n    use sync::state_persister::SyncStatePersister;\n\n    struct MockRepo;\n    #[async_trait::async_trait]\n    impl KnowledgeRepository for MockRepo {\n        type Error = knowledge::repository::RepositoryError;\n        async fn store(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _: KnowledgeEntry,\n            _: &str,\n        ) -> std::result::Result<String, Self::Error> {\n            Ok(\"hash\".into())\n        }\n        async fn get(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _: KnowledgeLayer,\n            _: &str,\n        ) -> std::result::Result<Option<KnowledgeEntry>, Self::Error> {\n            Ok(None)\n        }\n        async fn list(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _: KnowledgeLayer,\n            _: &str,\n        ) -> std::result::Result<Vec<KnowledgeEntry>, Self::Error> {\n            Ok(vec![])\n        }\n        async fn delete(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _: KnowledgeLayer,\n            _: &str,\n            _: &str,\n        ) -> std::result::Result<String, Self::Error> {\n            Ok(\"hash\".into())\n        }\n        async fn get_head_commit(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n        ) -> std::result::Result<Option<String>, Self::Error> {\n            Ok(None)\n        }\n        async fn get_affected_items(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _: &str,\n        ) -> std::result::Result<Vec<(KnowledgeLayer, String)>, Self::Error> {\n            Ok(vec![])\n        }\n        async fn search(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _: &str,\n            _: Vec<KnowledgeLayer>,\n            _: usize,\n        ) -> std::result::Result<Vec<KnowledgeEntry>, Self::Error> {\n            Ok(vec![])\n        }\n        fn root_path(&self) -> Option<std::path::PathBuf> {\n            None\n        }\n    }\n\n    struct MockPersister;\n    #[async_trait::async_trait]\n    impl SyncStatePersister for MockPersister {\n        async fn load(\n            &self,\n            _tenant_id: &mk_core::types::TenantId,\n        ) -> std::result::Result<sync::state::SyncState, Box<dyn std::error::Error + Send + Sync>>\n        {\n            Ok(sync::state::SyncState::default())\n        }\n        async fn save(\n            &self,\n            _tenant_id: &mk_core::types::TenantId,\n            _: &sync::state::SyncState,\n        ) -> std::result::Result<(), Box<dyn std::error::Error + Send + Sync>> {\n            Ok(())\n        }\n    }\n\n    struct MockAuthService;\n    #[async_trait::async_trait]\n    impl mk_core::traits::AuthorizationService for MockAuthService {\n        type Error = anyhow::Error;\n        async fn check_permission(\n            &self,\n            _ctx: &mk_core::types::TenantContext,\n            _action: &str,\n            _resource: &str,\n        ) -> anyhow::Result<bool> {\n            Ok(true)\n        }\n        async fn get_user_roles(\n            &self,\n            _ctx: &mk_core::types::TenantContext,\n        ) -> anyhow::Result<Vec<mk_core::types::Role>> {\n            Ok(vec![])\n        }\n        async fn assign_role(\n            &self,\n            _ctx: &mk_core::types::TenantContext,\n            _user_id: &mk_core::types::UserId,\n            _role: mk_core::types::Role,\n        ) -> anyhow::Result<()> {\n            Ok(())\n        }\n        async fn remove_role(\n            &self,\n            _ctx: &mk_core::types::TenantContext,\n            _user_id: &mk_core::types::UserId,\n            _role: mk_core::types::Role,\n        ) -> anyhow::Result<()> {\n            Ok(())\n        }\n    }\n\n    struct MockStorageBackend;\n    #[async_trait::async_trait]\n    impl mk_core::traits::StorageBackend for MockStorageBackend {\n        type Error = storage::postgres::PostgresError;\n        async fn store(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _key: &str,\n            _value: &[u8],\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn retrieve(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _key: &str,\n        ) -> Result<Option<Vec<u8>>, Self::Error> {\n            Ok(None)\n        }\n        async fn delete(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _key: &str,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn exists(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _key: &str,\n        ) -> Result<bool, Self::Error> {\n            Ok(false)\n        }\n        async fn get_ancestors(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _unit_id: &str,\n        ) -> Result<Vec<mk_core::types::OrganizationalUnit>, Self::Error> {\n            Ok(vec![])\n        }\n        async fn get_descendants(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _unit_id: &str,\n        ) -> Result<Vec<mk_core::types::OrganizationalUnit>, Self::Error> {\n            Ok(vec![])\n        }\n        async fn get_unit_policies(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _unit_id: &str,\n        ) -> Result<Vec<mk_core::types::Policy>, Self::Error> {\n            Ok(vec![])\n        }\n        async fn create_unit(\n            &self,\n            _unit: &mk_core::types::OrganizationalUnit,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn add_unit_policy(\n            &self,\n            _ctx: &mk_core::types::TenantContext,\n            _unit_id: &str,\n            _policy: &mk_core::types::Policy,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn assign_role(\n            &self,\n            _user_id: &mk_core::types::UserId,\n            _tenant_id: &mk_core::types::TenantId,\n            _unit_id: &str,\n            _role: mk_core::types::Role,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn remove_role(\n            &self,\n            _user_id: &mk_core::types::UserId,\n            _tenant_id: &mk_core::types::TenantId,\n            _unit_id: &str,\n            _role: mk_core::types::Role,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn store_drift_result(\n            &self,\n            _result: mk_core::types::DriftResult,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn get_latest_drift_result(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _project_id: &str,\n        ) -> Result<Option<mk_core::types::DriftResult>, Self::Error> {\n            Ok(None)\n        }\n        async fn list_all_units(\n            &self,\n        ) -> Result<Vec<mk_core::types::OrganizationalUnit>, Self::Error> {\n            Ok(vec![])\n        }\n        async fn record_job_status(\n            &self,\n            _job_name: &str,\n            _tenant_id: &str,\n            _status: &str,\n            _message: Option<&str>,\n            _started_at: i64,\n            _finished_at: Option<i64>,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn get_governance_events(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _since_timestamp: i64,\n            _limit: usize,\n        ) -> Result<Vec<mk_core::types::GovernanceEvent>, Self::Error> {\n            Ok(vec![])\n        }\n        async fn create_suppression(\n            &self,\n            _suppression: mk_core::types::DriftSuppression,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn list_suppressions(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _project_id: &str,\n        ) -> Result<Vec<mk_core::types::DriftSuppression>, Self::Error> {\n            Ok(vec![])\n        }\n        async fn delete_suppression(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _suppression_id: &str,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn get_drift_config(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _project_id: &str,\n        ) -> Result<Option<mk_core::types::DriftConfig>, Self::Error> {\n            Ok(None)\n        }\n        async fn save_drift_config(\n            &self,\n            _config: mk_core::types::DriftConfig,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn persist_event(\n            &self,\n            _event: mk_core::types::PersistentEvent,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn get_pending_events(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _limit: usize,\n        ) -> Result<Vec<mk_core::types::PersistentEvent>, Self::Error> {\n            Ok(vec![])\n        }\n        async fn update_event_status(\n            &self,\n            _event_id: &str,\n            _status: mk_core::types::EventStatus,\n            _error: Option<String>,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn get_dead_letter_events(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _limit: usize,\n        ) -> Result<Vec<mk_core::types::PersistentEvent>, Self::Error> {\n            Ok(vec![])\n        }\n        async fn check_idempotency(\n            &self,\n            _consumer_group: &str,\n            _idempotency_key: &str,\n        ) -> Result<bool, Self::Error> {\n            Ok(false)\n        }\n        async fn record_consumer_state(\n            &self,\n            _state: mk_core::types::ConsumerState,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n        async fn get_event_metrics(\n            &self,\n            _ctx: mk_core::types::TenantContext,\n            _period_start: i64,\n            _period_end: i64,\n        ) -> Result<Vec<mk_core::types::EventDeliveryMetrics>, Self::Error> {\n            Ok(vec![])\n        }\n        async fn record_event_metrics(\n            &self,\n            _metrics: mk_core::types::EventDeliveryMetrics,\n        ) -> Result<(), Self::Error> {\n            Ok(())\n        }\n    }\n\n    async fn setup_server() -> McpServer {\n        let memory_manager = Arc::new(MemoryManager::new());\n        let repo = Arc::new(MockRepo);\n        let governance = Arc::new(knowledge::governance::GovernanceEngine::new());\n        let sync_manager = Arc::new(\n            SyncManager::new(\n                memory_manager.clone(),\n                repo.clone(),\n                governance.clone(),\n                config::config::DeploymentConfig::default(),\n                None,\n                Arc::new(MockPersister),\n                None,\n            )\n            .await\n            .unwrap(),\n        );\n\n        let mock_reasoner = Arc::new(memory::reasoning::DefaultReflectiveReasoner::new(Arc::new(\n            memory::llm::mock::MockLlmService::new(),\n        )));\n\n        McpServer::new(\n            memory_manager,\n            sync_manager,\n            repo,\n            Arc::new(MockStorageBackend),\n            governance,\n            mock_reasoner,\n            Arc::new(MockAuthService),\n            None,\n            None,\n        )\n    }\n\n    #[tokio::test]\n    async fn test_server_initialize() {\n        let server = setup_server().await;\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"initialize\".to_string(),\n            params: None,\n        };\n\n        let response = server.handle_request(request).await;\n        assert!(response.result.is_some());\n        let result = response.result.unwrap();\n        assert_eq!(result[\"protocolVersion\"], \"2024-11-05\");\n    }\n\n    #[tokio::test]\n    async fn test_server_list_tools() {\n        let server = setup_server().await;\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"tools/list\".to_string(),\n            params: None,\n        };\n\n        let response = server.handle_request(request).await;\n        assert!(response.result.is_some());\n        let tools = response.result.unwrap();\n        assert!(tools.as_array().unwrap().len() >= 8);\n    }\n\n    #[tokio::test]\n    async fn test_server_method_not_found() {\n        let server = setup_server().await;\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"unknown_method\".to_string(),\n            params: None,\n        };\n\n        let response = server.handle_request(request).await;\n        assert!(response.error.is_some());\n        assert_eq!(response.error.unwrap().code, -32601);\n    }\n\n    #[tokio::test]\n    async fn test_server_invalid_params() {\n        let server = setup_server().await;\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"tools/call\".to_string(),\n            params: None,\n        };\n\n        let response = server.handle_request(request).await;\n        assert!(response.error.is_some());\n        assert_eq!(response.error.unwrap().code, -32602);\n    }\n\n    #[tokio::test]\n    async fn test_server_tool_not_found() {\n        let server = setup_server().await;\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"tools/call\".to_string(),\n            params: Some(json!({\n                \"tenantContext\": {\n                    \"tenant_id\": \"c1\",\n                    \"user_id\": \"u1\"\n                },\n                \"name\": \"non_existent_tool\",\n                \"arguments\": {}\n            })),\n        };\n\n        let response = server.handle_request(request).await;\n        assert!(response.error.is_some());\n        assert_eq!(response.error.unwrap().code, -32601);\n    }\n\n    #[tokio::test]\n    async fn test_extract_tenant_context() {\n        let server = setup_server().await;\n\n        let params = json!({\n            \"tenantContext\": {\n                \"tenantId\": \"company_1\",\n                \"userId\": \"user_1\"\n            },\n            \"name\": \"memory_add\",\n            \"arguments\": {\n                \"content\": \"test\"\n            }\n        });\n\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"tools/call\".to_string(),\n            params: Some(params),\n        };\n\n        let _response = server.handle_request(request).await;\n    }\n\n    #[tokio::test]\n    async fn test_extract_tenant_context_missing() {\n        let server = setup_server().await;\n\n        let params = json!({\n            \"name\": \"memory_add\",\n            \"arguments\": {\n                \"content\": \"test\"\n            }\n        });\n\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"tools/call\".to_string(),\n            params: Some(params),\n        };\n\n        let response = server.handle_request(request).await;\n        assert!(response.error.is_some());\n        let err = response.error.unwrap();\n        assert_eq!(err.code, -32602);\n        assert!(err.message.contains(\"Missing or invalid tenant context\"));\n    }\n\n    #[tokio::test]\n    async fn test_server_failure_hardening() {\n        let server = setup_server().await;\n\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"TRIGGER_FAILURE_METHOD\".to_string(),\n            params: None,\n        };\n\n        let response = server.handle_request(request).await;\n        assert!(response.error.is_some());\n        assert_eq!(response.error.unwrap().message, \"Simulated failure\");\n\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(2),\n            method: \"tools/call\".to_string(),\n            params: Some(json!({\n                \"tenantContext\": {\n                    \"tenant_id\": \"TRIGGER_FAILURE_TENANT\",\n                    \"user_id\": \"u1\"\n                },\n                \"name\": \"memory_add\",\n                \"arguments\": {\n                    \"content\": \"test\"\n                }\n            })),\n        };\n\n        let response = server.handle_request(request).await;\n        assert!(response.error.is_some());\n        assert_eq!(response.error.unwrap().message, \"Simulated tenant failure\");\n    }\n\n    #[tokio::test]\n    async fn test_server_timeout() {\n        let server = setup_server().await.with_timeout(Duration::from_millis(1));\n\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"initialize\".to_string(),\n            params: None,\n        };\n\n        let _response = server.handle_request(request).await;\n    }\n\n    #[test]\n    fn test_json_rpc_error_constructors() {\n        let invalid_params = JsonRpcError::invalid_params(\"Invalid param\");\n        assert_eq!(invalid_params.code, -32602);\n        assert_eq!(invalid_params.message, \"Invalid param\");\n        assert!(invalid_params.data.is_none());\n\n        let method_not_found = JsonRpcError::method_not_found(\"Not found\");\n        assert_eq!(method_not_found.code, -32601);\n        assert_eq!(method_not_found.message, \"Not found\");\n\n        let internal = JsonRpcError::internal_error(\"Internal error\");\n        assert_eq!(internal.code, -32000);\n        assert_eq!(internal.message, \"Internal error\");\n\n        let timeout = JsonRpcError::request_timeout(\"Timeout\");\n        assert_eq!(timeout.code, -32001);\n        assert_eq!(timeout.message, \"Timeout\");\n    }\n\n    #[test]\n    fn test_list_tools() {\n        let registry = crate::tools::ToolRegistry::new();\n        let tools = registry.list_tools();\n        assert!(tools.is_empty());\n    }\n\n    #[test]\n    fn test_json_rpc_request_serde() {\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"test\".to_string(),\n            params: Some(json!({\"key\": \"value\"})),\n        };\n\n        let serialized = serde_json::to_string(&request).unwrap();\n        let deserialized: JsonRpcRequest = serde_json::from_str(&serialized).unwrap();\n\n        assert_eq!(deserialized.jsonrpc, \"2.0\");\n        assert_eq!(deserialized.method, \"test\");\n        assert!(deserialized.params.is_some());\n    }\n\n    #[test]\n    fn test_json_rpc_response_serde() {\n        let response_success = JsonRpcResponse {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            result: Some(json!({\"data\": \"test\"})),\n            error: None,\n        };\n\n        let serialized = serde_json::to_string(&response_success).unwrap();\n        assert!(!serialized.contains(\"error\"));\n\n        let response_error = JsonRpcResponse {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            result: None,\n            error: Some(JsonRpcError::internal_error(\"fail\")),\n        };\n\n        let serialized_err = serde_json::to_string(&response_error).unwrap();\n        assert!(!serialized_err.contains(\"result\"));\n        assert!(serialized_err.contains(\"error\"));\n    }\n\n    #[tokio::test]\n    async fn test_tools_call_missing_tool_name() {\n        let server = setup_server().await;\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"tools/call\".to_string(),\n            params: Some(json!({\n                \"tenantContext\": {\n                    \"tenant_id\": \"c1\",\n                    \"user_id\": \"u1\"\n                },\n                \"arguments\": {}\n            })),\n        };\n\n        let response = server.handle_request(request).await;\n        assert!(response.error.is_some());\n        assert_eq!(response.error.unwrap().code, -32602);\n    }\n}\n","traces":[{"line":39,"address":[],"length":0,"stats":{"Line":22}},{"line":54,"address":[],"length":0,"stats":{"Line":44}},{"line":56,"address":[],"length":0,"stats":{"Line":110}},{"line":57,"address":[],"length":0,"stats":{"Line":110}},{"line":58,"address":[],"length":0,"stats":{"Line":110}},{"line":59,"address":[],"length":0,"stats":{"Line":110}},{"line":60,"address":[],"length":0,"stats":{"Line":110}},{"line":61,"address":[],"length":0,"stats":{"Line":110}},{"line":62,"address":[],"length":0,"stats":{"Line":88}},{"line":64,"address":[],"length":0,"stats":{"Line":22}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":110}},{"line":71,"address":[],"length":0,"stats":{"Line":22}},{"line":73,"address":[],"length":0,"stats":{"Line":110}},{"line":74,"address":[],"length":0,"stats":{"Line":22}},{"line":76,"address":[],"length":0,"stats":{"Line":110}},{"line":77,"address":[],"length":0,"stats":{"Line":66}},{"line":78,"address":[],"length":0,"stats":{"Line":22}},{"line":81,"address":[],"length":0,"stats":{"Line":110}},{"line":82,"address":[],"length":0,"stats":{"Line":110}},{"line":83,"address":[],"length":0,"stats":{"Line":88}},{"line":85,"address":[],"length":0,"stats":{"Line":110}},{"line":86,"address":[],"length":0,"stats":{"Line":44}},{"line":87,"address":[],"length":0,"stats":{"Line":22}},{"line":89,"address":[],"length":0,"stats":{"Line":110}},{"line":90,"address":[],"length":0,"stats":{"Line":44}},{"line":91,"address":[],"length":0,"stats":{"Line":22}},{"line":93,"address":[],"length":0,"stats":{"Line":110}},{"line":94,"address":[],"length":0,"stats":{"Line":44}},{"line":95,"address":[],"length":0,"stats":{"Line":22}},{"line":97,"address":[],"length":0,"stats":{"Line":110}},{"line":98,"address":[],"length":0,"stats":{"Line":22}},{"line":99,"address":[],"length":0,"stats":{"Line":22}},{"line":101,"address":[],"length":0,"stats":{"Line":88}},{"line":104,"address":[],"length":0,"stats":{"Line":110}},{"line":105,"address":[],"length":0,"stats":{"Line":44}},{"line":106,"address":[],"length":0,"stats":{"Line":22}},{"line":109,"address":[],"length":0,"stats":{"Line":132}},{"line":110,"address":[],"length":0,"stats":{"Line":44}},{"line":111,"address":[],"length":0,"stats":{"Line":22}},{"line":114,"address":[],"length":0,"stats":{"Line":110}},{"line":115,"address":[],"length":0,"stats":{"Line":44}},{"line":116,"address":[],"length":0,"stats":{"Line":22}},{"line":119,"address":[],"length":0,"stats":{"Line":66}},{"line":126,"address":[],"length":0,"stats":{"Line":22}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":2}},{"line":139,"address":[],"length":0,"stats":{"Line":2}},{"line":140,"address":[],"length":0,"stats":{"Line":2}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":6}},{"line":148,"address":[],"length":0,"stats":{"Line":12}},{"line":152,"address":[],"length":0,"stats":{"Line":36}},{"line":164,"address":[],"length":0,"stats":{"Line":18}},{"line":182,"address":[],"length":0,"stats":{"Line":34}},{"line":183,"address":[],"length":0,"stats":{"Line":17}},{"line":185,"address":[],"length":0,"stats":{"Line":6}},{"line":186,"address":[],"length":0,"stats":{"Line":4}},{"line":187,"address":[],"length":0,"stats":{"Line":4}},{"line":201,"address":[],"length":0,"stats":{"Line":15}},{"line":202,"address":[],"length":0,"stats":{"Line":3}},{"line":204,"address":[],"length":0,"stats":{"Line":3}},{"line":205,"address":[],"length":0,"stats":{"Line":2}},{"line":206,"address":[],"length":0,"stats":{"Line":2}},{"line":210,"address":[],"length":0,"stats":{"Line":14}},{"line":211,"address":[],"length":0,"stats":{"Line":25}},{"line":212,"address":[],"length":0,"stats":{"Line":24}},{"line":214,"address":[],"length":0,"stats":{"Line":1}},{"line":215,"address":[],"length":0,"stats":{"Line":3}},{"line":216,"address":[],"length":0,"stats":{"Line":2}},{"line":217,"address":[],"length":0,"stats":{"Line":1}},{"line":218,"address":[],"length":0,"stats":{"Line":1}},{"line":223,"address":[],"length":0,"stats":{"Line":18}},{"line":224,"address":[],"length":0,"stats":{"Line":24}},{"line":225,"address":[],"length":0,"stats":{"Line":12}},{"line":227,"address":[],"length":0,"stats":{"Line":10}},{"line":228,"address":[],"length":0,"stats":{"Line":20}},{"line":229,"address":[],"length":0,"stats":{"Line":1}},{"line":230,"address":[],"length":0,"stats":{"Line":3}},{"line":231,"address":[],"length":0,"stats":{"Line":2}},{"line":232,"address":[],"length":0,"stats":{"Line":1}},{"line":233,"address":[],"length":0,"stats":{"Line":1}},{"line":234,"address":[],"length":0,"stats":{"Line":1}},{"line":238,"address":[],"length":0,"stats":{"Line":9}},{"line":241,"address":[],"length":0,"stats":{"Line":2}},{"line":242,"address":[],"length":0,"stats":{"Line":6}},{"line":243,"address":[],"length":0,"stats":{"Line":4}},{"line":244,"address":[],"length":0,"stats":{"Line":2}},{"line":245,"address":[],"length":0,"stats":{"Line":2}},{"line":246,"address":[],"length":0,"stats":{"Line":2}},{"line":252,"address":[],"length":0,"stats":{"Line":43}},{"line":253,"address":[],"length":0,"stats":{"Line":16}},{"line":254,"address":[],"length":0,"stats":{"Line":1}},{"line":255,"address":[],"length":0,"stats":{"Line":1}},{"line":256,"address":[],"length":0,"stats":{"Line":3}},{"line":257,"address":[],"length":0,"stats":{"Line":2}},{"line":258,"address":[],"length":0,"stats":{"Line":2}},{"line":259,"address":[],"length":0,"stats":{"Line":1}},{"line":264,"address":[],"length":0,"stats":{"Line":16}},{"line":265,"address":[],"length":0,"stats":{"Line":32}},{"line":266,"address":[],"length":0,"stats":{"Line":8}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":0}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":272,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":274,"address":[],"length":0,"stats":{"Line":0}},{"line":276,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":32}},{"line":287,"address":[],"length":0,"stats":{"Line":8}},{"line":289,"address":[],"length":0,"stats":{"Line":24}},{"line":290,"address":[],"length":0,"stats":{"Line":16}},{"line":291,"address":[],"length":0,"stats":{"Line":24}},{"line":292,"address":[],"length":0,"stats":{"Line":8}},{"line":294,"address":[],"length":0,"stats":{"Line":8}},{"line":295,"address":[],"length":0,"stats":{"Line":8}},{"line":296,"address":[],"length":0,"stats":{"Line":8}},{"line":297,"address":[],"length":0,"stats":{"Line":2}},{"line":298,"address":[],"length":0,"stats":{"Line":2}},{"line":299,"address":[],"length":0,"stats":{"Line":6}},{"line":300,"address":[],"length":0,"stats":{"Line":4}},{"line":301,"address":[],"length":0,"stats":{"Line":4}},{"line":302,"address":[],"length":0,"stats":{"Line":2}},{"line":303,"address":[],"length":0,"stats":{"Line":2}},{"line":304,"address":[],"length":0,"stats":{"Line":4}},{"line":305,"address":[],"length":0,"stats":{"Line":2}},{"line":306,"address":[],"length":0,"stats":{"Line":2}},{"line":308,"address":[],"length":0,"stats":{"Line":2}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":0}},{"line":321,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":30}},{"line":330,"address":[],"length":0,"stats":{"Line":6}},{"line":331,"address":[],"length":0,"stats":{"Line":5}},{"line":332,"address":[],"length":0,"stats":{"Line":5}},{"line":334,"address":[],"length":0,"stats":{"Line":5}},{"line":335,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":337,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":342,"address":[],"length":0,"stats":{"Line":0}},{"line":343,"address":[],"length":0,"stats":{"Line":0}},{"line":344,"address":[],"length":0,"stats":{"Line":0}},{"line":346,"address":[],"length":0,"stats":{"Line":0}},{"line":347,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":0}},{"line":350,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":354,"address":[],"length":0,"stats":{"Line":0}},{"line":355,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":358,"address":[],"length":0,"stats":{"Line":0}},{"line":359,"address":[],"length":0,"stats":{"Line":0}},{"line":360,"address":[],"length":0,"stats":{"Line":0}},{"line":361,"address":[],"length":0,"stats":{"Line":0}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":363,"address":[],"length":0,"stats":{"Line":0}},{"line":364,"address":[],"length":0,"stats":{"Line":0}},{"line":365,"address":[],"length":0,"stats":{"Line":0}},{"line":368,"address":[],"length":0,"stats":{"Line":0}},{"line":369,"address":[],"length":0,"stats":{"Line":0}},{"line":370,"address":[],"length":0,"stats":{"Line":0}},{"line":371,"address":[],"length":0,"stats":{"Line":0}},{"line":372,"address":[],"length":0,"stats":{"Line":0}},{"line":373,"address":[],"length":0,"stats":{"Line":0}},{"line":374,"address":[],"length":0,"stats":{"Line":0}},{"line":375,"address":[],"length":0,"stats":{"Line":0}},{"line":376,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":378,"address":[],"length":0,"stats":{"Line":0}},{"line":379,"address":[],"length":0,"stats":{"Line":0}},{"line":382,"address":[],"length":0,"stats":{"Line":0}},{"line":383,"address":[],"length":0,"stats":{"Line":0}},{"line":384,"address":[],"length":0,"stats":{"Line":0}},{"line":385,"address":[],"length":0,"stats":{"Line":0}},{"line":386,"address":[],"length":0,"stats":{"Line":0}},{"line":387,"address":[],"length":0,"stats":{"Line":0}},{"line":388,"address":[],"length":0,"stats":{"Line":0}},{"line":389,"address":[],"length":0,"stats":{"Line":0}},{"line":390,"address":[],"length":0,"stats":{"Line":0}},{"line":391,"address":[],"length":0,"stats":{"Line":0}},{"line":394,"address":[],"length":0,"stats":{"Line":0}},{"line":397,"address":[],"length":0,"stats":{"Line":0}},{"line":398,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":405,"address":[],"length":0,"stats":{"Line":15}},{"line":406,"address":[],"length":0,"stats":{"Line":10}},{"line":407,"address":[],"length":0,"stats":{"Line":5}},{"line":411,"address":[],"length":0,"stats":{"Line":1}},{"line":412,"address":[],"length":0,"stats":{"Line":3}},{"line":413,"address":[],"length":0,"stats":{"Line":1}},{"line":414,"address":[],"length":0,"stats":{"Line":2}},{"line":415,"address":[],"length":0,"stats":{"Line":2}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":417,"address":[],"length":0,"stats":{"Line":0}},{"line":419,"address":[],"length":0,"stats":{"Line":0}},{"line":421,"address":[],"length":0,"stats":{"Line":0}},{"line":425,"address":[],"length":0,"stats":{"Line":3}},{"line":426,"address":[],"length":0,"stats":{"Line":2}},{"line":428,"address":[],"length":0,"stats":{"Line":1}},{"line":434,"address":[],"length":0,"stats":{"Line":1}},{"line":436,"address":[],"length":0,"stats":{"Line":3}},{"line":437,"address":[],"length":0,"stats":{"Line":2}},{"line":439,"address":[],"length":0,"stats":{"Line":1}},{"line":445,"address":[],"length":0,"stats":{"Line":9}},{"line":450,"address":[],"length":0,"stats":{"Line":17}},{"line":451,"address":[],"length":0,"stats":{"Line":24}},{"line":452,"address":[],"length":0,"stats":{"Line":1}},{"line":455,"address":[],"length":0,"stats":{"Line":24}},{"line":456,"address":[],"length":0,"stats":{"Line":16}},{"line":457,"address":[],"length":0,"stats":{"Line":0}},{"line":460,"address":[],"length":0,"stats":{"Line":24}},{"line":461,"address":[],"length":0,"stats":{"Line":24}},{"line":462,"address":[],"length":0,"stats":{"Line":24}},{"line":463,"address":[],"length":0,"stats":{"Line":32}},{"line":465,"address":[],"length":0,"stats":{"Line":24}},{"line":466,"address":[],"length":0,"stats":{"Line":24}},{"line":467,"address":[],"length":0,"stats":{"Line":16}},{"line":470,"address":[],"length":0,"stats":{"Line":0}},{"line":471,"address":[],"length":0,"stats":{"Line":0}},{"line":472,"address":[],"length":0,"stats":{"Line":0}},{"line":476,"address":[],"length":0,"stats":{"Line":8}},{"line":499,"address":[],"length":0,"stats":{"Line":5}},{"line":501,"address":[],"length":0,"stats":{"Line":5}},{"line":502,"address":[],"length":0,"stats":{"Line":10}},{"line":507,"address":[],"length":0,"stats":{"Line":3}},{"line":509,"address":[],"length":0,"stats":{"Line":3}},{"line":510,"address":[],"length":0,"stats":{"Line":6}},{"line":515,"address":[],"length":0,"stats":{"Line":4}},{"line":517,"address":[],"length":0,"stats":{"Line":4}},{"line":518,"address":[],"length":0,"stats":{"Line":8}},{"line":523,"address":[],"length":0,"stats":{"Line":1}},{"line":525,"address":[],"length":0,"stats":{"Line":1}},{"line":526,"address":[],"length":0,"stats":{"Line":2}}],"covered":164,"coverable":254},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","state.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","tools.rs"],"content":"use async_trait::async_trait;\nuse serde::{Deserialize, Serialize};\nuse serde_json::Value;\nuse std::collections::HashMap;\nuse std::sync::Arc;\n\n/// Core trait for implementing MCP (Model Context Protocol) tools.\n///\n/// Tools provide a standardized interface for AI agents to interact with system\n/// capabilities. Each tool defines its name, description, input schema, and\n/// execution logic.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Defines the contract that all tools must implement to be registered and\n/// invoked through the tool registry. Enables pluggable, type-safe tool\n/// execution with JSON Schema validation.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use async_trait::async_trait;\n/// use serde_json::Value;\n/// use tools::tools::Tool;\n///\n/// struct MyCustomTool;\n///\n/// #[async_trait]\n/// impl Tool for MyCustomTool {\n///     fn name(&self) -> &str {\n///         \"my_custom_tool\"\n///     }\n///\n///     fn description(&self) -> &str {\n///         \"Does something useful\"\n///     }\n///\n///     fn input_schema(&self) -> Value {\n///         serde_json::json!({\n///             \"type\": \"object\",\n///             \"properties\": {\n///                 \"input\": { \"type\": \"string\" }\n///             },\n///             \"required\": [\"input\"]\n///         })\n///     }\n///\n///     async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n///         // Process params and return result\n///         Ok(serde_json::json!({ \"result\": \"success\" }))\n///     }\n/// }\n/// ```\n///\n/// ## Methods\n/// - `name`: Unique identifier for the tool\n/// - `description`: Human-readable description of what the tool does\n/// - `input_schema`: JSON Schema defining valid input parameters\n/// - `call`: Async execution method that processes input and returns output\n#[async_trait]\npub trait Tool: Send + Sync + 'static {\n    fn name(&self) -> &str;\n    fn description(&self) -> &str;\n    fn input_schema(&self) -> Value;\n    async fn call(&self, params: Value) -> Result<Value, Box<dyn std::error::Error + Send + Sync>>;\n}\n\n/// Error codes for tool execution failures.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Provides standardized error classification for tool operations, enabling\n/// proper error handling and retry logic.\n///\n/// ## Variants\n/// - `InvalidInput`: Input validation failed (non-retryable)\n/// - `NotFound`: Requested resource not found (non-retryable)\n/// - `ProviderError`: External provider or service failure (retryable)\n/// - `RateLimited`: Request rate limit exceeded (retryable)\n/// - `Unauthorized`: Authentication/authorization failure (non-retryable)\n/// - `Timeout`: Operation timed out (retryable)\n/// - `Conflict`: Concurrent modification or state conflict (retryable)\n/// - `InternalError`: Unexpected system error (non-retryable)\n#[derive(Serialize, Deserialize)]\n#[serde(rename_all = \"SCREAMING_SNAKE_CASE\")]\npub enum ToolErrorCode {\n    InvalidInput,\n    NotFound,\n    ProviderError,\n    RateLimited,\n    Unauthorized,\n    Timeout,\n    Conflict,\n    InternalError,\n}\n\n/// Generic response wrapper for tool execution results.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Provides a consistent response format for all tool operations, enabling\n/// success/failure detection and structured error handling across all tools.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use serde_json::json;\n/// use tools::tools::{ToolError, ToolErrorCode, ToolResponse};\n///\n/// // Success response\n/// let success = ToolResponse::<String> {\n///     success: true,\n///     data: Some(\"result data\".to_string()),\n///     error: None\n/// };\n///\n/// // Error response\n/// let error = ToolResponse::<()> {\n///     success: false,\n///     data: None,\n///     error: Some(ToolError::new(ToolErrorCode::NotFound, \"Not found\"))\n/// };\n/// ```\n///\n/// ## Fields\n/// - `success`: Indicates whether the operation succeeded\n/// - `data`: Result data on success (omitted on failure)\n/// - `error`: Error details on failure (omitted on success)\n#[derive(Serialize, Deserialize)]\npub struct ToolResponse<T> {\n    pub success: bool,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub data: Option<T>,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub error: Option<ToolError>,\n}\n\n/// Detailed error information for tool failures.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Encapsulates error details including error code, message, retryability\n/// status, and optional context. Enables consumers to make informed decisions\n/// about error handling and retries.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use tools::tools::{ToolError, ToolErrorCode};\n/// use serde_json::json;\n///\n/// // Basic error\n/// let error = ToolError::new(ToolErrorCode::InvalidInput, \"Missing required field\");\n///\n/// // Error with details\n/// let error = ToolError::new(ToolErrorCode::NotFound, \"Resource not found\")\n///     .with_details(json!({ \"resource_id\": \"123\" }));\n///\n/// // Check if retryable\n/// if error.retryable {\n///     // Retry logic\n/// }\n/// ```\n///\n/// ## Fields\n/// - `code`: Standardized error code for classification\n/// - `message`: Human-readable error description\n/// - `retryable`: Whether the operation can be safely retried\n/// - `details`: Additional context for debugging (optional)\n#[derive(Serialize, Deserialize)]\npub struct ToolError {\n    pub code: ToolErrorCode,\n    pub message: String,\n    pub retryable: bool,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub details: Option<Value>,\n}\n\nimpl ToolError {\n    pub fn new(code: ToolErrorCode, message: impl Into<String>) -> Self {\n        let retryable = matches!(\n            code,\n            ToolErrorCode::RateLimited | ToolErrorCode::Timeout | ToolErrorCode::ProviderError\n        );\n        Self {\n            code,\n            message: message.into(),\n            retryable,\n            details: None,\n        }\n    }\n\n    pub fn with_details(mut self, details: Value) -> Self {\n        self.details = Some(details);\n        self\n    }\n}\n\n/// Central registry for managing and invoking tools.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Provides a centralized mechanism for registering, discovering, and invoking\n/// tools. Enables dynamic tool management and type-safe execution across the\n/// system.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use tools::tools::{ToolRegistry, Tool, ToolDefinition};\n/// use async_trait::async_trait;\n/// use serde_json::{json, Value};\n/// use std::error::Error;\n///\n/// struct MyTool;\n///\n/// #[async_trait]\n/// impl Tool for MyTool {\n///     fn name(&self) -> &str { \"my_tool\" }\n///     fn description(&self) -> &str { \"My example tool\" }\n///     fn input_schema(&self) -> Value { json!({}) }\n///     async fn call(&self, _params: Value) -> Result<Value, Box<dyn Error + Send + Sync>> {\n///         Ok(json!({ \"result\": \"success\" }))\n///     }\n/// }\n///\n/// // Create registry\n/// let mut registry = ToolRegistry::new();\n///\n/// // Register tools\n/// registry.register(Box::new(MyTool));\n///\n/// // List available tools\n/// let tools: Vec<ToolDefinition> = registry.list_tools();\n/// ```\n///\n/// ## Methods\n/// - `new`: Creates an empty tool registry\n/// - `register`: Registers a tool by its unique name\n/// - `call`: Invokes a registered tool with the given parameters\n/// - `list_tools`: Returns metadata for all registered tools\n#[derive(Clone)]\npub struct ToolRegistry {\n    tools: HashMap<String, Arc<dyn Tool>>,\n}\n\nimpl std::fmt::Debug for ToolRegistry {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        f.debug_struct(\"ToolRegistry\")\n            .field(\"tools\", &self.tools.keys().collect::<Vec<_>>())\n            .finish()\n    }\n}\n\n#[allow(clippy::new_without_default)]\nimpl Default for ToolRegistry {\n    fn default() -> Self {\n        Self {\n            tools: HashMap::new(),\n        }\n    }\n}\n\nimpl ToolRegistry {\n    pub fn new() -> Self {\n        Self::default()\n    }\n\n    pub fn register(&mut self, tool: Box<dyn Tool>) {\n        self.tools.insert(tool.name().to_string(), tool.into());\n    }\n\n    pub fn register_arc(&mut self, tool: Arc<dyn Tool>) {\n        self.tools.insert(tool.name().to_string(), tool);\n    }\n\n    pub async fn call(\n        &self,\n        name: &str,\n        params: Value,\n    ) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n        let tool = self\n            .tools\n            .get(name)\n            .ok_or(format!(\"Tool {} not found\", name))?;\n        tool.call(params).await\n    }\n\n    pub fn list_tools(&self) -> Vec<ToolDefinition> {\n        self.tools\n            .values()\n            .map(|t| ToolDefinition {\n                name: t.name().to_string(),\n                description: t.description().to_string(),\n                input_schema: t.input_schema(),\n            })\n            .collect()\n    }\n}\n\n/// Metadata definition for a registered tool.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Provides tool discovery information without exposing implementation details.\n/// Used for tool listing, documentation generation, and client UI.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use tools::tools::ToolDefinition;\n/// use serde_json::json;\n///\n/// let definition = ToolDefinition {\n///     name: \"my_tool\".to_string(),\n///     description: \"Does something useful\".to_string(),\n///     input_schema: json!({\n///         \"type\": \"object\",\n///         \"properties\": {\n///             \"input\": { \"type\": \"string\" }\n///         },\n///         \"required\": [\"input\"]\n///     }),\n/// };\n/// ```\n///\n/// ## Fields\n/// - `name`: Unique tool identifier used for invocation\n/// - `description`: Human-readable description of tool purpose\n/// - `input_schema`: JSON Schema defining valid input parameters\n#[derive(Serialize, Deserialize)]\npub struct ToolDefinition {\n    pub name: String,\n    pub description: String,\n    pub input_schema: Value,\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    struct TestTool {\n        name: String,\n    }\n\n    #[async_trait]\n    impl Tool for TestTool {\n        fn name(&self) -> &str {\n            &self.name\n        }\n        fn description(&self) -> &str {\n            \"Test tool\"\n        }\n        fn input_schema(&self) -> Value {\n            serde_json::json!({})\n        }\n        async fn call(\n            &self,\n            _params: Value,\n        ) -> Result<Value, Box<dyn std::error::Error + Send + Sync>> {\n            Ok(serde_json::json!({\"result\": \"success\"}))\n        }\n    }\n\n    #[tokio::test]\n    async fn test_tool_registry_operations() {\n        let mut registry = ToolRegistry::new();\n\n        registry.register(Box::new(TestTool {\n            name: \"tool1\".to_string(),\n        }));\n        registry.register(Box::new(TestTool {\n            name: \"tool2\".to_string(),\n        }));\n\n        let tools = registry.list_tools();\n        assert_eq!(tools.len(), 2);\n        assert!(tools.iter().any(|t| t.name == \"tool1\"));\n        assert!(tools.iter().any(|t| t.name == \"tool2\"));\n\n        let result = registry.call(\"tool1\", serde_json::json!({})).await.unwrap();\n        assert_eq!(result[\"result\"], \"success\");\n\n        let err = registry.call(\"nonexistent\", serde_json::json!({})).await;\n        assert!(err.is_err());\n        assert!(err.unwrap_err().to_string().contains(\"not found\"));\n    }\n\n    #[test]\n    fn test_tool_registry_duplicate_registration() {\n        let mut registry = ToolRegistry::new();\n\n        registry.register(Box::new(TestTool {\n            name: \"same\".to_string(),\n        }));\n        registry.register(Box::new(TestTool {\n            name: \"same\".to_string(),\n        }));\n\n        let tools = registry.list_tools();\n        assert_eq!(tools.len(), 1);\n    }\n\n    #[test]\n    fn test_tool_error_retryability() {\n        let err = ToolError::new(ToolErrorCode::RateLimited, \"Too many requests\");\n        assert!(err.retryable);\n\n        let err = ToolError::new(ToolErrorCode::InvalidInput, \"Bad params\");\n        assert!(!err.retryable);\n\n        let err = ToolError::new(ToolErrorCode::NotFound, \"Not found\");\n        assert!(!err.retryable);\n\n        let err = ToolError::new(ToolErrorCode::Timeout, \"Timed out\");\n        assert!(err.retryable);\n    }\n}\n","traces":[{"line":181,"address":[],"length":0,"stats":{"Line":4}},{"line":182,"address":[],"length":0,"stats":{"Line":6}},{"line":183,"address":[],"length":0,"stats":{"Line":4}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":12}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":32}},{"line":260,"address":[],"length":0,"stats":{"Line":32}},{"line":266,"address":[],"length":0,"stats":{"Line":32}},{"line":267,"address":[],"length":0,"stats":{"Line":32}},{"line":270,"address":[],"length":0,"stats":{"Line":492}},{"line":271,"address":[],"length":0,"stats":{"Line":2952}},{"line":274,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":12}},{"line":283,"address":[],"length":0,"stats":{"Line":22}},{"line":284,"address":[],"length":0,"stats":{"Line":12}},{"line":285,"address":[],"length":0,"stats":{"Line":24}},{"line":286,"address":[],"length":0,"stats":{"Line":38}},{"line":287,"address":[],"length":0,"stats":{"Line":20}},{"line":290,"address":[],"length":0,"stats":{"Line":10}},{"line":291,"address":[],"length":0,"stats":{"Line":10}},{"line":293,"address":[],"length":0,"stats":{"Line":10}},{"line":294,"address":[],"length":0,"stats":{"Line":314}},{"line":295,"address":[],"length":0,"stats":{"Line":314}},{"line":296,"address":[],"length":0,"stats":{"Line":157}}],"covered":22,"coverable":31},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","validator.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","working.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","utils","src","lib.rs"],"content":"//! # Memory-Knowledge Utilities\n//!\n//! Common utility functions for hashing, validation, and UUID generation.\n//!\n//! # Best Practices\n//!\n//! - Uses SHA-2 for secure hashing\n//! - Uses UUID v4 with serde support\n//! - Validates inputs with comprehensive error messages\n\nuse sha2::{Digest, Sha256};\nuse uuid::Uuid;\n\n/// Compute SHA-256 hash of content string\n///\n/// # Examples\n///\n/// ```\n/// use utils::compute_content_hash;\n///\n/// let hash = compute_content_hash(\"hello world\");\n/// assert_eq!(hash.len(), 64);\n/// ```\n#[must_use]\npub fn compute_content_hash(content: &str) -> String {\n    let mut hasher = Sha256::new();\n    hasher.update(content.as_bytes());\n    format!(\"{:x}\", hasher.finalize())\n}\n\n/// Compute hash of knowledge item for change detection\n///\n/// Hashes content, constraints, and status fields.\n#[must_use]\npub fn compute_knowledge_hash(item: &serde_json::Value) -> String {\n    let mut hasher = Sha256::new();\n\n    // Extract fields for hashing\n    if let Some(content_str) = item.get(\"content\").and_then(|c| c.as_str()) {\n        hasher.update(content_str.as_bytes());\n    }\n\n    if let Some(constraints) = item.get(\"constraints\") {\n        let constraints_json =\n            serde_json::to_string(constraints).expect(\"Failed to serialize constraints\");\n        hasher.update(constraints_json.as_bytes());\n    }\n\n    if let Some(status_str) = item.get(\"status\").and_then(|s| s.as_str()) {\n        hasher.update(status_str.as_bytes());\n    }\n\n    format!(\"{:x}\", hasher.finalize())\n}\n\n/// Generate UUID v4 string\n#[must_use]\npub fn generate_uuid() -> String {\n    Uuid::new_v4().to_string()\n}\n\n/// Validate memory layer string\n#[must_use]\npub fn is_valid_layer(layer: &str) -> bool {\n    matches!(\n        layer,\n        \"agent\" | \"user\" | \"session\" | \"project\" | \"team\" | \"org\" | \"company\"\n    )\n}\n\n/// Validate knowledge type string\n#[must_use]\npub fn is_valid_knowledge_type(ktype: &str) -> bool {\n    matches!(ktype, \"adr\" | \"policy\" | \"pattern\" | \"spec\")\n}\n\n/// Validate knowledge layer string\n#[must_use]\npub fn is_valid_knowledge_layer(layer: &str) -> bool {\n    matches!(layer, \"company\" | \"org\" | \"team\" | \"project\")\n}\n\n/// Redact PII from content string\n///\n/// Currently redacts emails and simple phone numbers.\n#[must_use]\npub fn redact_pii(content: &str) -> String {\n    let email_re = regex::Regex::new(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\").unwrap();\n    let result = email_re.replace_all(content, \"[REDACTED_EMAIL]\");\n\n    let phone_re = regex::Regex::new(r\"\\d{3}-\\d{3}-\\d{4}\").unwrap();\n    phone_re\n        .replace_all(&result, \"[REDACTED_PHONE]\")\n        .to_string()\n}\n\n/// Get layer precedence value for memory layers\n#[must_use]\npub fn get_layer_precedence(layer: &str) -> u8 {\n    match layer {\n        \"agent\" => 1,\n        \"user\" => 2,\n        \"session\" => 3,\n        \"project\" => 4,\n        \"team\" => 5,\n        \"org\" => 6,\n        \"company\" => 7,\n        _ => 7, // Default to lowest precedence\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_compute_content_hash_consistency() {\n        let content = \"test content\";\n        let hash1 = compute_content_hash(content);\n        let hash2 = compute_content_hash(content);\n        assert_eq!(hash1, hash2);\n    }\n\n    #[test]\n    fn test_generate_uuid_uniqueness() {\n        let uuid1 = generate_uuid();\n        let uuid2 = generate_uuid();\n        assert_ne!(uuid1, uuid2);\n    }\n\n    #[test]\n    fn test_layer_validation_valid() {\n        assert!(is_valid_layer(\"agent\"));\n        assert!(is_valid_layer(\"user\"));\n        assert!(is_valid_layer(\"company\"));\n    }\n\n    #[test]\n    fn test_layer_validation_invalid() {\n        assert!(!is_valid_layer(\"invalid\"));\n        assert!(!is_valid_layer(\"agent-user\"));\n    }\n\n    #[test]\n    fn test_redact_pii() {\n        let content = \"Contact alice@example.com at 123-456-7890.\";\n        let redacted = redact_pii(content);\n        assert_eq!(redacted, \"Contact [REDACTED_EMAIL] at [REDACTED_PHONE].\");\n    }\n\n    #[test]\n    fn test_compute_knowledge_hash() {\n        let item = serde_json::json!({\n            \"content\": \"test content\",\n            \"status\": \"accepted\",\n            \"constraints\": [\"rule1\"]\n        });\n        let hash = compute_knowledge_hash(&item);\n        assert_eq!(hash.len(), 64);\n\n        let item2 = serde_json::json!({\n            \"content\": \"test content\",\n            \"status\": \"accepted\",\n            \"constraints\": [\"rule1\"]\n        });\n        assert_eq!(hash, compute_knowledge_hash(&item2));\n\n        let item3 = serde_json::json!({\n            \"content\": \"different content\",\n            \"status\": \"accepted\",\n            \"constraints\": [\"rule1\"]\n        });\n        assert_ne!(hash, compute_knowledge_hash(&item3));\n    }\n\n    #[test]\n    fn test_is_valid_knowledge_type() {\n        assert!(is_valid_knowledge_type(\"adr\"));\n        assert!(is_valid_knowledge_type(\"policy\"));\n        assert!(!is_valid_knowledge_type(\"unknown\"));\n    }\n\n    #[test]\n    fn test_is_valid_knowledge_layer() {\n        assert!(is_valid_knowledge_layer(\"project\"));\n        assert!(is_valid_knowledge_layer(\"company\"));\n        assert!(!is_valid_knowledge_layer(\"user\"));\n    }\n\n    #[test]\n    fn test_get_layer_precedence() {\n        assert_eq!(get_layer_precedence(\"agent\"), 1);\n        assert_eq!(get_layer_precedence(\"company\"), 7);\n        assert_eq!(get_layer_precedence(\"unknown\"), 7);\n    }\n}\n","traces":[{"line":25,"address":[],"length":0,"stats":{"Line":1056}},{"line":26,"address":[],"length":0,"stats":{"Line":2112}},{"line":27,"address":[],"length":0,"stats":{"Line":4224}},{"line":28,"address":[],"length":0,"stats":{"Line":4224}},{"line":35,"address":[],"length":0,"stats":{"Line":3}},{"line":36,"address":[],"length":0,"stats":{"Line":6}},{"line":39,"address":[],"length":0,"stats":{"Line":21}},{"line":40,"address":[],"length":0,"stats":{"Line":9}},{"line":43,"address":[],"length":0,"stats":{"Line":9}},{"line":44,"address":[],"length":0,"stats":{"Line":6}},{"line":45,"address":[],"length":0,"stats":{"Line":15}},{"line":46,"address":[],"length":0,"stats":{"Line":9}},{"line":49,"address":[],"length":0,"stats":{"Line":21}},{"line":50,"address":[],"length":0,"stats":{"Line":9}},{"line":53,"address":[],"length":0,"stats":{"Line":12}},{"line":58,"address":[],"length":0,"stats":{"Line":2}},{"line":59,"address":[],"length":0,"stats":{"Line":4}},{"line":64,"address":[],"length":0,"stats":{"Line":5}},{"line":65,"address":[],"length":0,"stats":{"Line":3}},{"line":66,"address":[],"length":0,"stats":{"Line":5}},{"line":73,"address":[],"length":0,"stats":{"Line":3}},{"line":74,"address":[],"length":0,"stats":{"Line":12}},{"line":79,"address":[],"length":0,"stats":{"Line":3}},{"line":80,"address":[],"length":0,"stats":{"Line":14}},{"line":87,"address":[],"length":0,"stats":{"Line":1242}},{"line":88,"address":[],"length":0,"stats":{"Line":4968}},{"line":89,"address":[],"length":0,"stats":{"Line":4968}},{"line":91,"address":[],"length":0,"stats":{"Line":4968}},{"line":92,"address":[],"length":0,"stats":{"Line":2484}},{"line":93,"address":[],"length":0,"stats":{"Line":1242}},{"line":99,"address":[],"length":0,"stats":{"Line":3}},{"line":100,"address":[],"length":0,"stats":{"Line":3}},{"line":101,"address":[],"length":0,"stats":{"Line":4}},{"line":102,"address":[],"length":0,"stats":{"Line":2}},{"line":103,"address":[],"length":0,"stats":{"Line":2}},{"line":104,"address":[],"length":0,"stats":{"Line":2}},{"line":105,"address":[],"length":0,"stats":{"Line":2}},{"line":106,"address":[],"length":0,"stats":{"Line":2}},{"line":107,"address":[],"length":0,"stats":{"Line":3}},{"line":108,"address":[],"length":0,"stats":{"Line":1}}],"covered":40,"coverable":40}],"coverage":61.910083820167635,"covered":12187,"coverable":19685}