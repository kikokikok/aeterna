"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[7168],{6738(e,n,r){r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>a,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"cca/migrations","title":"CCA Database Migrations","description":"This document describes the database migrations required for CCA (Confucius Code Agent) capabilities in Aeterna.","source":"@site/docs/cca/migrations.md","sourceDirName":"cca","slug":"/cca/migrations","permalink":"/aeterna/docs/cca/migrations","draft":false,"unlisted":false,"editUrl":"https://github.com/kikokikok/aeterna/tree/main/website/docs/cca/migrations.md","tags":[],"version":"current","frontMatter":{},"sidebar":"docs","previous":{"title":"CCA Redis Schema Documentation","permalink":"/aeterna/docs/cca/redis-schema"},"next":{"title":"MCP Server Integration Guide","permalink":"/aeterna/docs/integrations/mcp-server"}}');var s=r(4848),t=r(8453);const a={},o="CCA Database Migrations",l={},c=[{value:"Migration Overview",id:"migration-overview",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Migration 007: CCA Summary Schema",id:"migration-007-cca-summary-schema",level:2},{value:"Purpose",id:"purpose",level:3},{value:"Changes",id:"changes",level:3},{value:"Table Modifications",id:"table-modifications",level:4},{value:"New Tables",id:"new-tables",level:4},{value:"Indexes",id:"indexes",level:4},{value:"JSONB Schema: summaries",id:"jsonb-schema-summaries",level:3},{value:"Migration 008: Hindsight Learning Tables",id:"migration-008-hindsight-learning-tables",level:2},{value:"Purpose",id:"purpose-1",level:3},{value:"New Tables",id:"new-tables-1",level:3},{value:"error_signatures",id:"error_signatures",level:4},{value:"resolutions",id:"resolutions",level:4},{value:"hindsight_notes",id:"hindsight_notes",level:4},{value:"Indexes",id:"indexes-1",level:3},{value:"Row-Level Security (RLS)",id:"row-level-security-rls",level:3},{value:"Running Migrations",id:"running-migrations",level:2},{value:"Using sqlx-cli",id:"using-sqlx-cli",level:3},{value:"Manual Execution",id:"manual-execution",level:3},{value:"Post-Migration Verification",id:"post-migration-verification",level:2},{value:"Data Migration for Existing Deployments",id:"data-migration-for-existing-deployments",level:2},{value:"Pre-Migration Checklist",id:"pre-migration-checklist",level:3},{value:"Phase 1: Schema Migration",id:"phase-1-schema-migration",level:3},{value:"Phase 2: Memory Entry Summary Population",id:"phase-2-memory-entry-summary-population",level:3},{value:"Option A: Immediate Full Migration",id:"option-a-immediate-full-migration",level:4},{value:"Option B: Lazy Migration (Recommended for Large Deployments)",id:"option-b-lazy-migration-recommended-for-large-deployments",level:4},{value:"Option C: Prioritized Migration",id:"option-c-prioritized-migration",level:4},{value:"Phase 3: Context Vector Population",id:"phase-3-context-vector-population",level:3},{value:"Phase 4: Error Signature Migration",id:"phase-4-error-signature-migration",level:3},{value:"Phase 5: Redis Schema Population",id:"phase-5-redis-schema-population",level:3},{value:"Migration Monitoring",id:"migration-monitoring",level:3},{value:"Estimated Migration Times",id:"estimated-migration-times",level:3},{value:"LLM Token Cost Estimates",id:"llm-token-cost-estimates",level:3},{value:"Post-Migration Validation",id:"post-migration-validation",level:3},{value:"Rollback Procedure",id:"rollback-procedure",level:3},{value:"Performance Considerations",id:"performance-considerations",level:2},{value:"Index Maintenance",id:"index-maintenance",level:3},{value:"Storage Estimates",id:"storage-estimates",level:3},{value:"Cleanup Jobs",id:"cleanup-jobs",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Migration Fails: Vector Extension Missing",id:"migration-fails-vector-extension-missing",level:3},{value:"Migration Fails: Foreign Key Violation",id:"migration-fails-foreign-key-violation",level:3},{value:"RLS Blocking Access",id:"rls-blocking-access",level:3},{value:"Rollback Procedures",id:"rollback-procedures",level:2},{value:"Important: Rollback Order",id:"important-rollback-order",level:3},{value:"Pre-Rollback Checklist",id:"pre-rollback-checklist",level:3},{value:"Rollback Migration 008 (Hindsight Tables)",id:"rollback-migration-008-hindsight-tables",level:3},{value:"Step 1: Backup Hindsight Data (Optional)",id:"step-1-backup-hindsight-data-optional",level:4},{value:"Step 2: Drop RLS Policies",id:"step-2-drop-rls-policies",level:4},{value:"Step 3: Drop Indexes",id:"step-3-drop-indexes",level:4},{value:"Step 4: Drop Tables",id:"step-4-drop-tables",level:4},{value:"Step 5: Update Migration Tracking",id:"step-5-update-migration-tracking",level:4},{value:"Rollback Migration 007 (Summary Schema)",id:"rollback-migration-007-summary-schema",level:3},{value:"Step 1: Backup Summary Data (Optional)",id:"step-1-backup-summary-data-optional",level:4},{value:"Step 2: Drop Indexes",id:"step-2-drop-indexes",level:4},{value:"Step 3: Drop New Table",id:"step-3-drop-new-table",level:4},{value:"Step 4: Remove Columns from Existing Tables",id:"step-4-remove-columns-from-existing-tables",level:4},{value:"Step 5: Update Migration Tracking",id:"step-5-update-migration-tracking-1",level:4},{value:"Complete Rollback Script",id:"complete-rollback-script",level:3},{value:"Redis Cleanup After Rollback",id:"redis-cleanup-after-rollback",level:3},{value:"Post-Rollback Verification",id:"post-rollback-verification",level:3},{value:"Re-applying Migrations After Rollback",id:"re-applying-migrations-after-rollback",level:3},{value:"Emergency Rollback (Minimal Downtime)",id:"emergency-rollback-minimal-downtime",level:3},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"cca-database-migrations",children:"CCA Database Migrations"})}),"\n",(0,s.jsx)(n.p,{children:"This document describes the database migrations required for CCA (Confucius Code Agent) capabilities in Aeterna."}),"\n",(0,s.jsx)(n.h2,{id:"migration-overview",children:"Migration Overview"}),"\n",(0,s.jsx)(n.p,{children:"CCA introduces two PostgreSQL migrations and extends the Redis schema:"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Migration"}),(0,s.jsx)(n.th,{children:"File"}),(0,s.jsx)(n.th,{children:"Purpose"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"007"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"007_cca_summaries.sql"})}),(0,s.jsx)(n.td,{children:"Summary schema extensions for Context Architect"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"008"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"008_hindsight_tables.sql"})}),(0,s.jsx)(n.td,{children:"Error signatures, resolutions, and hindsight notes"})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsx)(n.p,{children:"Before running migrations:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"PostgreSQL 16+"})," with pgvector extension installed"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Existing Aeterna schema"})," (migrations 001-006 already applied)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Database backup"})," taken before migration"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# Verify pgvector is installed\npsql -c "SELECT * FROM pg_extension WHERE extname = \'vector\';"\n\n# Check current migration state\npsql -c "SELECT * FROM schema_migrations ORDER BY version;"\n\n# Create backup\npg_dump -Fc aeterna > backup_pre_cca_$(date +%Y%m%d).dump\n'})}),"\n",(0,s.jsx)(n.h2,{id:"migration-007-cca-summary-schema",children:"Migration 007: CCA Summary Schema"}),"\n",(0,s.jsx)(n.h3,{id:"purpose",children:"Purpose"}),"\n",(0,s.jsx)(n.p,{children:"Adds hierarchical summary storage to memory and knowledge entries for Context Architect compression."}),"\n",(0,s.jsx)(n.h3,{id:"changes",children:"Changes"}),"\n",(0,s.jsx)(n.h4,{id:"table-modifications",children:"Table Modifications"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"memory_entries"})," (existing table):"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- New columns added\nsummaries JSONB DEFAULT '{}'           -- Pre-computed summaries at multiple depths\ncontext_vector VECTOR(1536)            -- Semantic vector for relevance matching\nsummary_updated_at BIGINT              -- Timestamp of last summary update\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"knowledge_items"})," (existing table):"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- New column added\nsummaries JSONB DEFAULT '{}'           -- Pre-computed summaries\n"})}),"\n",(0,s.jsx)(n.h4,{id:"new-tables",children:"New Tables"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"layer_summary_cache"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE layer_summary_cache (\n    id TEXT PRIMARY KEY,\n    tenant_id TEXT NOT NULL,\n    memory_layer TEXT NOT NULL,         -- 'agent', 'user', 'session', etc.\n    entry_id TEXT NOT NULL,\n    depth TEXT NOT NULL,                -- 'sentence', 'paragraph', 'detailed'\n    content TEXT NOT NULL,\n    token_count INTEGER NOT NULL,\n    source_hash TEXT NOT NULL,          -- Hash of source content for staleness detection\n    personalized BOOLEAN DEFAULT FALSE,\n    personalization_context TEXT,\n    generated_at BIGINT NOT NULL,\n    expires_at BIGINT,\n    UNIQUE (tenant_id, entry_id, depth)\n);\n"})}),"\n",(0,s.jsx)(n.h4,{id:"indexes",children:"Indexes"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- Fast lookup by layer and update time\nCREATE INDEX idx_memory_entries_summary_updated \n    ON memory_entries(tenant_id, memory_layer, summary_updated_at)\n    WHERE summary_updated_at IS NOT NULL;\n\n-- Cache lookup\nCREATE INDEX idx_layer_summary_cache_lookup \n    ON layer_summary_cache(tenant_id, memory_layer, entry_id);\n\n-- Cache expiry cleanup\nCREATE INDEX idx_layer_summary_cache_expiry \n    ON layer_summary_cache(expires_at)\n    WHERE expires_at IS NOT NULL;\n"})}),"\n",(0,s.jsx)(n.h3,{id:"jsonb-schema-summaries",children:"JSONB Schema: summaries"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"summaries"})," JSONB column uses this structure:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\n  "sentence": {\n    "depth": "sentence",\n    "content": "One-line summary (~50 tokens)",\n    "token_count": 47,\n    "generated_at": 1705680000000,\n    "source_hash": "abc123",\n    "personalized": false,\n    "personalization_context": null\n  },\n  "paragraph": {\n    "depth": "paragraph",\n    "content": "Paragraph summary (~200 tokens)",\n    "token_count": 195,\n    "generated_at": 1705680000000,\n    "source_hash": "abc123",\n    "personalized": true,\n    "personalization_context": "user:alice:preferences"\n  },\n  "detailed": {\n    "depth": "detailed",\n    "content": "Detailed summary (~500 tokens)",\n    "token_count": 487,\n    "generated_at": 1705680000000,\n    "source_hash": "abc123",\n    "personalized": false,\n    "personalization_context": null\n  }\n}\n'})}),"\n",(0,s.jsx)(n.h2,{id:"migration-008-hindsight-learning-tables",children:"Migration 008: Hindsight Learning Tables"}),"\n",(0,s.jsx)(n.h3,{id:"purpose-1",children:"Purpose"}),"\n",(0,s.jsx)(n.p,{children:"Adds tables for error signature capture, resolution tracking, and hindsight notes for the Hindsight Learning component."}),"\n",(0,s.jsx)(n.h3,{id:"new-tables-1",children:"New Tables"}),"\n",(0,s.jsx)(n.h4,{id:"error_signatures",children:"error_signatures"}),"\n",(0,s.jsx)(n.p,{children:"Stores normalized error patterns for semantic matching:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE error_signatures (\n    id TEXT PRIMARY KEY,\n    tenant_id TEXT NOT NULL,\n    error_type TEXT NOT NULL,           -- e.g., 'TypeError', 'ConnectionError'\n    message_pattern TEXT NOT NULL,      -- Normalized error message pattern\n    stack_patterns JSONB DEFAULT '[]',  -- Array of stack trace patterns\n    context_patterns JSONB DEFAULT '[]',-- Array of context patterns\n    embedding JSONB,                    -- Semantic embedding for similarity search\n    occurrence_count INTEGER DEFAULT 1,\n    first_seen_at BIGINT NOT NULL,\n    last_seen_at BIGINT NOT NULL,\n    created_at BIGINT NOT NULL,\n    updated_at BIGINT NOT NULL,\n    FOREIGN KEY (tenant_id) REFERENCES organizational_units(id)\n);\n"})}),"\n",(0,s.jsx)(n.h4,{id:"resolutions",children:"resolutions"}),"\n",(0,s.jsx)(n.p,{children:"Stores successful fix patterns linked to error signatures:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE resolutions (\n    id TEXT PRIMARY KEY,\n    tenant_id TEXT NOT NULL,\n    error_signature_id TEXT NOT NULL,\n    description TEXT NOT NULL,          -- Human-readable resolution description\n    changes JSONB DEFAULT '[]',         -- Array of code changes that fixed the error\n    success_rate REAL DEFAULT 0.0,      -- 0.0 to 1.0\n    application_count INTEGER DEFAULT 0,\n    last_success_at BIGINT,\n    created_at BIGINT NOT NULL,\n    updated_at BIGINT NOT NULL,\n    FOREIGN KEY (error_signature_id) REFERENCES error_signatures(id) ON DELETE CASCADE\n);\n"})}),"\n",(0,s.jsx)(n.h4,{id:"hindsight_notes",children:"hindsight_notes"}),"\n",(0,s.jsx)(n.p,{children:"Stores distilled learnings from error/resolution pairs:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE hindsight_notes (\n    id TEXT PRIMARY KEY,\n    tenant_id TEXT NOT NULL,\n    error_signature_id TEXT NOT NULL,\n    content TEXT NOT NULL,              -- Markdown content of the note\n    tags JSONB DEFAULT '[]',            -- Array of tags for filtering\n    resolution_ids JSONB DEFAULT '[]',  -- Array of resolution IDs referenced\n    quality_score REAL,                 -- Quality score from distillation\n    promoted_to_layer TEXT,             -- Layer if promoted (e.g., 'team', 'org')\n    created_at BIGINT NOT NULL,\n    updated_at BIGINT NOT NULL,\n    FOREIGN KEY (error_signature_id) REFERENCES error_signatures(id) ON DELETE CASCADE\n);\n"})}),"\n",(0,s.jsx)(n.h3,{id:"indexes-1",children:"Indexes"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- Error signature lookups\nCREATE INDEX idx_error_signatures_tenant ON error_signatures(tenant_id);\nCREATE INDEX idx_error_signatures_type ON error_signatures(tenant_id, error_type);\nCREATE INDEX idx_error_signatures_last_seen ON error_signatures(tenant_id, last_seen_at DESC);\n\n-- Resolution lookups\nCREATE INDEX idx_resolutions_error_signature ON resolutions(error_signature_id);\nCREATE INDEX idx_resolutions_success_rate ON resolutions(tenant_id, success_rate DESC);\nCREATE INDEX idx_resolutions_application_count ON resolutions(tenant_id, application_count DESC);\n\n-- Hindsight note lookups\nCREATE INDEX idx_hindsight_notes_tenant ON hindsight_notes(tenant_id);\nCREATE INDEX idx_hindsight_notes_error_signature ON hindsight_notes(error_signature_id);\nCREATE INDEX idx_hindsight_notes_quality ON hindsight_notes(tenant_id, quality_score DESC) WHERE quality_score IS NOT NULL;\nCREATE INDEX idx_hindsight_notes_tags ON hindsight_notes USING GIN (tags);\n"})}),"\n",(0,s.jsx)(n.h3,{id:"row-level-security-rls",children:"Row-Level Security (RLS)"}),"\n",(0,s.jsx)(n.p,{children:"All new tables have RLS enabled with tenant isolation policies:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- Enable RLS\nALTER TABLE error_signatures ENABLE ROW LEVEL SECURITY;\nALTER TABLE resolutions ENABLE ROW LEVEL SECURITY;\nALTER TABLE hindsight_notes ENABLE ROW LEVEL SECURITY;\n\n-- Policies ensure tenant isolation via app.tenant_id session variable\nCREATE POLICY error_signatures_tenant_isolation ON error_signatures\n    USING (tenant_id = current_setting('app.tenant_id', true));\n"})}),"\n",(0,s.jsx)(n.h2,{id:"running-migrations",children:"Running Migrations"}),"\n",(0,s.jsx)(n.h3,{id:"using-sqlx-cli",children:"Using sqlx-cli"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Install sqlx-cli if needed\ncargo install sqlx-cli\n\n# Run pending migrations\nsqlx migrate run --source storage/migrations\n\n# Verify migration status\nsqlx migrate info --source storage/migrations\n"})}),"\n",(0,s.jsx)(n.h3,{id:"manual-execution",children:"Manual Execution"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# Migration 007\npsql -d aeterna -f storage/migrations/007_cca_summaries.sql\n\n# Migration 008\npsql -d aeterna -f storage/migrations/008_hindsight_tables.sql\n\n# Verify\npsql -d aeterna -c "\\dt *summary*"\npsql -d aeterna -c "\\dt *error*"\npsql -d aeterna -c "\\dt *resolution*"\npsql -d aeterna -c "\\dt *hindsight*"\n'})}),"\n",(0,s.jsx)(n.h2,{id:"post-migration-verification",children:"Post-Migration Verification"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- Verify new columns on memory_entries\nSELECT column_name, data_type, column_default \nFROM information_schema.columns \nWHERE table_name = 'memory_entries' \nAND column_name IN ('summaries', 'context_vector', 'summary_updated_at');\n\n-- Verify new tables exist\nSELECT table_name FROM information_schema.tables \nWHERE table_schema = 'public' \nAND table_name IN ('layer_summary_cache', 'error_signatures', 'resolutions', 'hindsight_notes');\n\n-- Verify RLS is enabled\nSELECT tablename, rowsecurity \nFROM pg_tables \nWHERE tablename IN ('error_signatures', 'resolutions', 'hindsight_notes');\n\n-- Verify indexes\nSELECT indexname FROM pg_indexes \nWHERE tablename IN ('memory_entries', 'layer_summary_cache', 'error_signatures', 'resolutions', 'hindsight_notes')\nORDER BY indexname;\n"})}),"\n",(0,s.jsx)(n.h2,{id:"data-migration-for-existing-deployments",children:"Data Migration for Existing Deployments"}),"\n",(0,s.jsx)(n.p,{children:"This section provides a comprehensive guide for migrating existing Aeterna deployments to include CCA capabilities."}),"\n",(0,s.jsx)(n.h3,{id:"pre-migration-checklist",children:"Pre-Migration Checklist"}),"\n",(0,s.jsx)(n.p,{children:"Before starting the data migration:"}),"\n",(0,s.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,s.jsx)(n.strong,{children:"Backup complete"}),": Full PostgreSQL and Redis backup taken"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,s.jsx)(n.strong,{children:"Downtime scheduled"}),": Plan 15-30 minutes for large deployments (>100K entries)"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,s.jsx)(n.strong,{children:"LLM budget allocated"}),": Summary generation requires LLM tokens (~750 tokens per entry)"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,s.jsx)(n.strong,{children:"Redis capacity verified"}),": Summary cache may increase Redis memory by 2-3x"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,s.jsx)(n.strong,{children:"Application stopped"}),": Stop all Aeterna instances to prevent race conditions"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"phase-1-schema-migration",children:"Phase 1: Schema Migration"}),"\n",(0,s.jsx)(n.p,{children:"Apply the database migrations first (see sections above):"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# Verify current state\nsqlx migrate info --source storage/migrations\n\n# Apply migrations\nsqlx migrate run --source storage/migrations\n\n# Verify\npsql -d aeterna -c "\\d memory_entries" | grep -E "(summaries|context_vector|summary_updated_at)"\n'})}),"\n",(0,s.jsx)(n.h3,{id:"phase-2-memory-entry-summary-population",children:"Phase 2: Memory Entry Summary Population"}),"\n",(0,s.jsx)(n.p,{children:"Existing memory entries need summaries generated. This should be done in batches to manage LLM costs."}),"\n",(0,s.jsx)(n.h4,{id:"option-a-immediate-full-migration",children:"Option A: Immediate Full Migration"}),"\n",(0,s.jsx)(n.p,{children:"For smaller deployments (<10K entries), populate all summaries immediately:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-rust",children:'use knowledge::context_architect::{SummaryGenerator, SummaryConfig};\nuse aeterna_storage::PostgresStorage;\n\nasync fn migrate_all_summaries(\n    storage: &PostgresStorage,\n    llm_client: &LlmClient,\n    tenant_id: &str,\n) -> Result<MigrationStats> {\n    let generator = SummaryGenerator::new(llm_client.clone());\n    let mut stats = MigrationStats::default();\n    \n    // Process in batches of 100\n    let mut offset = 0;\n    loop {\n        let entries = storage.query(\n            "SELECT id, content FROM memory_entries \n             WHERE tenant_id = $1 AND (summaries = \'{}\' OR summaries IS NULL)\n             ORDER BY created_at DESC\n             LIMIT 100 OFFSET $2",\n            &[tenant_id, &offset]\n        ).await?;\n        \n        if entries.is_empty() {\n            break;\n        }\n        \n        for entry in entries {\n            match generator.generate_all_depths(&entry.content, None).await {\n                Ok(summaries) => {\n                    storage.update_summaries(&entry.id, &summaries).await?;\n                    stats.migrated += 1;\n                }\n                Err(e) => {\n                    tracing::warn!("Failed to generate summary for {}: {}", entry.id, e);\n                    stats.failed += 1;\n                }\n            }\n        }\n        \n        offset += 100;\n        stats.processed += entries.len();\n        \n        // Rate limit to avoid LLM throttling\n        tokio::time::sleep(Duration::from_millis(100)).await;\n    }\n    \n    Ok(stats)\n}\n'})}),"\n",(0,s.jsx)(n.h4,{id:"option-b-lazy-migration-recommended-for-large-deployments",children:"Option B: Lazy Migration (Recommended for Large Deployments)"}),"\n",(0,s.jsx)(n.p,{children:"For larger deployments, generate summaries on-demand:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-rust",children:"// Configure lazy migration in config/aeterna.toml\n[cca.context_architect]\nlazy_migration = true\nlazy_migration_batch_size = 50\nlazy_migration_interval_seconds = 60\n"})}),"\n",(0,s.jsx)(n.p,{children:"With lazy migration enabled:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Summaries are generated when entries are accessed"}),"\n",(0,s.jsx)(n.li,{children:"A background job processes old entries during low-traffic periods"}),"\n",(0,s.jsx)(n.li,{children:"The system gracefully degrades (returns full content) when summaries don't exist"}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"option-c-prioritized-migration",children:"Option C: Prioritized Migration"}),"\n",(0,s.jsx)(n.p,{children:"Migrate high-value entries first:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- Create priority view for migration\nCREATE OR REPLACE VIEW migration_priority AS\nSELECT \n    id,\n    content,\n    memory_layer,\n    -- Priority score: recent + frequently accessed + higher layers\n    (CASE memory_layer \n        WHEN 'company' THEN 100\n        WHEN 'org' THEN 80\n        WHEN 'team' THEN 60\n        WHEN 'project' THEN 40\n        WHEN 'session' THEN 20\n        WHEN 'user' THEN 10\n        WHEN 'agent' THEN 5\n    END) +\n    (EXTRACT(EPOCH FROM NOW()) - created_at) / 86400 * -1 + -- Recency bonus\n    COALESCE(access_count, 0) * 2 -- Access frequency bonus\n    AS priority_score\nFROM memory_entries\nWHERE summaries = '{}' OR summaries IS NULL\nORDER BY priority_score DESC;\n\n-- Migrate top 1000 priority entries\nSELECT id, content FROM migration_priority LIMIT 1000;\n"})}),"\n",(0,s.jsx)(n.h3,{id:"phase-3-context-vector-population",children:"Phase 3: Context Vector Population"}),"\n",(0,s.jsx)(n.p,{children:"Context vectors enable semantic similarity matching. Generate them alongside summaries:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-rust",children:'use knowledge::context_architect::ContextVectorGenerator;\n\nasync fn populate_context_vectors(\n    storage: &PostgresStorage,\n    embedding_client: &EmbeddingClient,\n    tenant_id: &str,\n) -> Result<()> {\n    let generator = ContextVectorGenerator::new(embedding_client.clone());\n    \n    let entries = storage.query(\n        "SELECT id, content FROM memory_entries \n         WHERE tenant_id = $1 AND context_vector IS NULL\n         LIMIT 1000",\n        &[tenant_id]\n    ).await?;\n    \n    // Batch embedding for efficiency (up to 100 at a time)\n    for chunk in entries.chunks(100) {\n        let contents: Vec<_> = chunk.iter().map(|e| e.content.as_str()).collect();\n        let vectors = generator.generate_batch(&contents).await?;\n        \n        for (entry, vector) in chunk.iter().zip(vectors) {\n            storage.update_context_vector(&entry.id, &vector).await?;\n        }\n    }\n    \n    Ok(())\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"phase-4-error-signature-migration",children:"Phase 4: Error Signature Migration"}),"\n",(0,s.jsx)(n.p,{children:"If you have existing error logs, import them into the hindsight system:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-rust",children:'use knowledge::hindsight::{ErrorCapture, ErrorContext};\n\nasync fn import_existing_errors(\n    error_capture: &ErrorCapture,\n    error_logs: &[ExistingErrorLog],\n) -> Result<ImportStats> {\n    let mut stats = ImportStats::default();\n    \n    for log in error_logs {\n        let context = ErrorContext {\n            file_path: log.file_path.clone(),\n            function_name: log.function_name.clone(),\n            tool_name: log.tool_name.clone(),\n            timestamp: log.timestamp,\n        };\n        \n        match error_capture.capture_from_log(&log.message, &log.stack_trace, &context).await {\n            Ok(signature_id) => {\n                stats.imported += 1;\n                \n                // If there\'s a known resolution, import that too\n                if let Some(resolution) = &log.resolution {\n                    error_capture.record_resolution(&signature_id, resolution).await?;\n                    stats.resolutions += 1;\n                }\n            }\n            Err(e) => {\n                tracing::warn!("Failed to import error: {}", e);\n                stats.failed += 1;\n            }\n        }\n    }\n    \n    Ok(stats)\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"phase-5-redis-schema-population",children:"Phase 5: Redis Schema Population"}),"\n",(0,s.jsx)(n.p,{children:"Warm the Redis cache after PostgreSQL migration:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-rust",children:'use aeterna_storage::RedisStorage;\n\nasync fn warm_redis_cache(\n    postgres: &PostgresStorage,\n    redis: &RedisStorage,\n    tenant_id: &str,\n) -> Result<()> {\n    // Cache recently accessed summaries\n    let recent_entries = postgres.query(\n        "SELECT id, memory_layer, summaries FROM memory_entries\n         WHERE tenant_id = $1 AND summaries != \'{}\'\n         ORDER BY updated_at DESC\n         LIMIT 1000",\n        &[tenant_id]\n    ).await?;\n    \n    for entry in recent_entries {\n        for (depth, summary) in entry.summaries.iter() {\n            let key = format!("summary:{}:{}:{}:{}", tenant_id, entry.memory_layer, entry.id, depth);\n            redis.set_with_ttl(&key, &summary, Duration::from_secs(3600)).await?;\n        }\n    }\n    \n    Ok(())\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"migration-monitoring",children:"Migration Monitoring"}),"\n",(0,s.jsx)(n.p,{children:"Track migration progress with these queries:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- Overall migration progress\nSELECT \n    COUNT(*) FILTER (WHERE summaries != '{}') as migrated,\n    COUNT(*) FILTER (WHERE summaries = '{}' OR summaries IS NULL) as pending,\n    COUNT(*) as total,\n    ROUND(100.0 * COUNT(*) FILTER (WHERE summaries != '{}') / COUNT(*), 2) as percent_complete\nFROM memory_entries\nWHERE tenant_id = 'your-tenant';\n\n-- Migration progress by layer\nSELECT \n    memory_layer,\n    COUNT(*) FILTER (WHERE summaries != '{}') as migrated,\n    COUNT(*) FILTER (WHERE summaries = '{}') as pending\nFROM memory_entries\nWHERE tenant_id = 'your-tenant'\nGROUP BY memory_layer\nORDER BY memory_layer;\n\n-- Context vector population progress\nSELECT \n    COUNT(*) FILTER (WHERE context_vector IS NOT NULL) as with_vector,\n    COUNT(*) FILTER (WHERE context_vector IS NULL) as without_vector,\n    COUNT(*) as total\nFROM memory_entries\nWHERE tenant_id = 'your-tenant';\n\n-- Hindsight import progress\nSELECT \n    COUNT(*) as total_signatures,\n    SUM(occurrence_count) as total_occurrences,\n    COUNT(*) FILTER (WHERE (SELECT COUNT(*) FROM resolutions r WHERE r.error_signature_id = error_signatures.id) > 0) as with_resolutions\nFROM error_signatures\nWHERE tenant_id = 'your-tenant';\n"})}),"\n",(0,s.jsx)(n.h3,{id:"estimated-migration-times",children:"Estimated Migration Times"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Entries"}),(0,s.jsx)(n.th,{children:"Full Migration"}),(0,s.jsx)(n.th,{children:"Lazy Migration Warm-up"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"1,000"}),(0,s.jsx)(n.td,{children:"~5 minutes"}),(0,s.jsx)(n.td,{children:"Instant"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"10,000"}),(0,s.jsx)(n.td,{children:"~45 minutes"}),(0,s.jsx)(n.td,{children:"~2 hours background"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"100,000"}),(0,s.jsx)(n.td,{children:"~8 hours"}),(0,s.jsx)(n.td,{children:"~24 hours background"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"1,000,000"}),(0,s.jsx)(n.td,{children:"~80 hours"}),(0,s.jsx)(n.td,{children:"~7 days background"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"llm-token-cost-estimates",children:"LLM Token Cost Estimates"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Summary Type"}),(0,s.jsx)(n.th,{children:"Tokens/Entry"}),(0,s.jsx)(n.th,{children:"Cost (GPT-4o)"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Sentence"}),(0,s.jsx)(n.td,{children:"~100"}),(0,s.jsx)(n.td,{children:"~$0.0005"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Paragraph"}),(0,s.jsx)(n.td,{children:"~300"}),(0,s.jsx)(n.td,{children:"~$0.0015"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Detailed"}),(0,s.jsx)(n.td,{children:"~600"}),(0,s.jsx)(n.td,{children:"~$0.003"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"All depths"}),(0,s.jsx)(n.td,{children:"~1000"}),(0,s.jsx)(n.td,{children:"~$0.005"})]})]})]}),"\n",(0,s.jsx)(n.p,{children:"For 100K entries with all depths: ~$500 LLM cost."}),"\n",(0,s.jsx)(n.h3,{id:"post-migration-validation",children:"Post-Migration Validation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- Verify summary quality (check for empty or truncated summaries)\nSELECT id, memory_layer, \n       LENGTH(summaries::text) as summary_size,\n       jsonb_object_keys(summaries) as depths\nFROM memory_entries\nWHERE tenant_id = 'your-tenant' \n  AND summaries != '{}'\nLIMIT 10;\n\n-- Verify context vectors are correct dimension\nSELECT id, array_length(context_vector, 1) as vector_dim\nFROM memory_entries\nWHERE context_vector IS NOT NULL\nLIMIT 10;\n\n-- Verify hindsight relationships\nSELECT \n    e.id as error_id,\n    e.error_type,\n    COUNT(r.id) as resolution_count,\n    COUNT(h.id) as note_count\nFROM error_signatures e\nLEFT JOIN resolutions r ON r.error_signature_id = e.id\nLEFT JOIN hindsight_notes h ON h.error_signature_id = e.id\nWHERE e.tenant_id = 'your-tenant'\nGROUP BY e.id, e.error_type\nLIMIT 10;\n"})}),"\n",(0,s.jsx)(n.h3,{id:"rollback-procedure",children:"Rollback Procedure"}),"\n",(0,s.jsxs)(n.p,{children:["If migration fails or causes issues, see the ",(0,s.jsx)(n.a,{href:"#rollback-procedures",children:"Rollback Procedures"})," section below."]}),"\n",(0,s.jsx)(n.h2,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,s.jsx)(n.h3,{id:"index-maintenance",children:"Index Maintenance"}),"\n",(0,s.jsxs)(n.p,{children:["The new GIN index on ",(0,s.jsx)(n.code,{children:"hindsight_notes.tags"})," requires periodic maintenance:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- Reindex periodically for GIN indexes\nREINDEX INDEX CONCURRENTLY idx_hindsight_notes_tags;\n\n-- Analyze tables after bulk operations\nANALYZE memory_entries;\nANALYZE layer_summary_cache;\nANALYZE error_signatures;\nANALYZE resolutions;\nANALYZE hindsight_notes;\n"})}),"\n",(0,s.jsx)(n.h3,{id:"storage-estimates",children:"Storage Estimates"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Table"}),(0,s.jsx)(n.th,{children:"Row Size (avg)"}),(0,s.jsx)(n.th,{children:"Growth Rate"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"layer_summary_cache"}),(0,s.jsx)(n.td,{children:"~2KB"}),(0,s.jsx)(n.td,{children:"3x memory_entries"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"error_signatures"}),(0,s.jsx)(n.td,{children:"~1KB"}),(0,s.jsx)(n.td,{children:"Per unique error type"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"resolutions"}),(0,s.jsx)(n.td,{children:"~500B"}),(0,s.jsx)(n.td,{children:"Per successful fix"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"hindsight_notes"}),(0,s.jsx)(n.td,{children:"~2KB"}),(0,s.jsx)(n.td,{children:"Per distilled note"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"cleanup-jobs",children:"Cleanup Jobs"}),"\n",(0,s.jsx)(n.p,{children:"Configure periodic cleanup for expired cache entries:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- Delete expired summary cache entries (run daily)\nDELETE FROM layer_summary_cache \nWHERE expires_at IS NOT NULL \nAND expires_at < EXTRACT(EPOCH FROM NOW()) * 1000;\n"})}),"\n",(0,s.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,s.jsx)(n.h3,{id:"migration-fails-vector-extension-missing",children:"Migration Fails: Vector Extension Missing"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'ERROR: type "vector" does not exist\n'})}),"\n",(0,s.jsx)(n.p,{children:"Solution:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"CREATE EXTENSION IF NOT EXISTS vector;\n"})}),"\n",(0,s.jsx)(n.h3,{id:"migration-fails-foreign-key-violation",children:"Migration Fails: Foreign Key Violation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"ERROR: insert or update on table violates foreign key constraint\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Solution: Ensure ",(0,s.jsx)(n.code,{children:"organizational_units"})," table has all required tenant IDs before migration."]}),"\n",(0,s.jsx)(n.h3,{id:"rls-blocking-access",children:"RLS Blocking Access"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"ERROR: new row violates row-level security policy\n"})}),"\n",(0,s.jsx)(n.p,{children:"Solution: Set the tenant context before operations:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"SET app.tenant_id = 'your-tenant-id';\n"})}),"\n",(0,s.jsx)(n.h2,{id:"rollback-procedures",children:"Rollback Procedures"}),"\n",(0,s.jsx)(n.p,{children:"If CCA migrations cause issues, use these procedures to safely roll back."}),"\n",(0,s.jsx)(n.h3,{id:"important-rollback-order",children:"Important: Rollback Order"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Always rollback in reverse order"}),": 008 first, then 007."]}),"\n",(0,s.jsx)(n.p,{children:"Migration 008 has foreign keys to tables created in 007, so it must be removed first."}),"\n",(0,s.jsx)(n.h3,{id:"pre-rollback-checklist",children:"Pre-Rollback Checklist"}),"\n",(0,s.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,s.jsx)(n.strong,{children:"Stop all Aeterna instances"})," to prevent data corruption"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,s.jsx)(n.strong,{children:"Backup current state"})," including CCA data you may want to preserve"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,s.jsx)(n.strong,{children:"Document any manually-added data"})," in CCA tables"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,s.jsx)(n.strong,{children:"Notify dependent services"})," of temporary CCA unavailability"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"rollback-migration-008-hindsight-tables",children:"Rollback Migration 008 (Hindsight Tables)"}),"\n",(0,s.jsx)(n.h4,{id:"step-1-backup-hindsight-data-optional",children:"Step 1: Backup Hindsight Data (Optional)"}),"\n",(0,s.jsx)(n.p,{children:"If you want to preserve hindsight data for re-migration later:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- Export error signatures\nCOPY (SELECT * FROM error_signatures WHERE tenant_id = 'your-tenant')\nTO '/tmp/backup_error_signatures.csv' WITH CSV HEADER;\n\n-- Export resolutions\nCOPY (SELECT * FROM resolutions WHERE tenant_id = 'your-tenant')\nTO '/tmp/backup_resolutions.csv' WITH CSV HEADER;\n\n-- Export hindsight notes\nCOPY (SELECT * FROM hindsight_notes WHERE tenant_id = 'your-tenant')\nTO '/tmp/backup_hindsight_notes.csv' WITH CSV HEADER;\n"})}),"\n",(0,s.jsx)(n.h4,{id:"step-2-drop-rls-policies",children:"Step 2: Drop RLS Policies"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- Drop RLS policies for hindsight_notes\nDROP POLICY IF EXISTS hindsight_notes_delete_policy ON hindsight_notes;\nDROP POLICY IF EXISTS hindsight_notes_update_policy ON hindsight_notes;\nDROP POLICY IF EXISTS hindsight_notes_insert_policy ON hindsight_notes;\nDROP POLICY IF EXISTS hindsight_notes_tenant_isolation ON hindsight_notes;\n\n-- Drop RLS policies for resolutions\nDROP POLICY IF EXISTS resolutions_delete_policy ON resolutions;\nDROP POLICY IF EXISTS resolutions_update_policy ON resolutions;\nDROP POLICY IF EXISTS resolutions_insert_policy ON resolutions;\nDROP POLICY IF EXISTS resolutions_tenant_isolation ON resolutions;\n\n-- Drop RLS policies for error_signatures\nDROP POLICY IF EXISTS error_signatures_delete_policy ON error_signatures;\nDROP POLICY IF EXISTS error_signatures_update_policy ON error_signatures;\nDROP POLICY IF EXISTS error_signatures_insert_policy ON error_signatures;\nDROP POLICY IF EXISTS error_signatures_tenant_isolation ON error_signatures;\n"})}),"\n",(0,s.jsx)(n.h4,{id:"step-3-drop-indexes",children:"Step 3: Drop Indexes"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- Hindsight notes indexes\nDROP INDEX IF EXISTS idx_hindsight_notes_tags;\nDROP INDEX IF EXISTS idx_hindsight_notes_quality;\nDROP INDEX IF EXISTS idx_hindsight_notes_error_signature;\nDROP INDEX IF EXISTS idx_hindsight_notes_tenant;\n\n-- Resolutions indexes\nDROP INDEX IF EXISTS idx_resolutions_application_count;\nDROP INDEX IF EXISTS idx_resolutions_success_rate;\nDROP INDEX IF EXISTS idx_resolutions_error_signature;\n\n-- Error signatures indexes\nDROP INDEX IF EXISTS idx_error_signatures_last_seen;\nDROP INDEX IF EXISTS idx_error_signatures_type;\nDROP INDEX IF EXISTS idx_error_signatures_tenant;\n"})}),"\n",(0,s.jsx)(n.h4,{id:"step-4-drop-tables",children:"Step 4: Drop Tables"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- Drop in order respecting foreign keys\nDROP TABLE IF EXISTS hindsight_notes CASCADE;\nDROP TABLE IF EXISTS resolutions CASCADE;\nDROP TABLE IF EXISTS error_signatures CASCADE;\n"})}),"\n",(0,s.jsx)(n.h4,{id:"step-5-update-migration-tracking",children:"Step 5: Update Migration Tracking"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- Remove migration 008 from tracking (if using sqlx)\nDELETE FROM _sqlx_migrations WHERE version = 8;\n\n-- Or if using custom tracking table\nDELETE FROM schema_migrations WHERE version = '008';\n"})}),"\n",(0,s.jsx)(n.h3,{id:"rollback-migration-007-summary-schema",children:"Rollback Migration 007 (Summary Schema)"}),"\n",(0,s.jsx)(n.h4,{id:"step-1-backup-summary-data-optional",children:"Step 1: Backup Summary Data (Optional)"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- Export summaries\nCOPY (\n    SELECT id, summaries, context_vector, summary_updated_at \n    FROM memory_entries \n    WHERE summaries != '{}' AND tenant_id = 'your-tenant'\n) TO '/tmp/backup_memory_summaries.csv' WITH CSV HEADER;\n\n-- Export layer_summary_cache\nCOPY (SELECT * FROM layer_summary_cache WHERE tenant_id = 'your-tenant')\nTO '/tmp/backup_layer_summary_cache.csv' WITH CSV HEADER;\n\n-- Export knowledge_items summaries\nCOPY (\n    SELECT id, summaries \n    FROM knowledge_items \n    WHERE summaries != '{}' AND tenant_id = 'your-tenant'\n) TO '/tmp/backup_knowledge_summaries.csv' WITH CSV HEADER;\n"})}),"\n",(0,s.jsx)(n.h4,{id:"step-2-drop-indexes",children:"Step 2: Drop Indexes"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"DROP INDEX IF EXISTS idx_layer_summary_cache_expiry;\nDROP INDEX IF EXISTS idx_layer_summary_cache_lookup;\nDROP INDEX IF EXISTS idx_memory_entries_summary_updated;\n"})}),"\n",(0,s.jsx)(n.h4,{id:"step-3-drop-new-table",children:"Step 3: Drop New Table"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"DROP TABLE IF EXISTS layer_summary_cache CASCADE;\n"})}),"\n",(0,s.jsx)(n.h4,{id:"step-4-remove-columns-from-existing-tables",children:"Step 4: Remove Columns from Existing Tables"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- Remove summary columns from memory_entries\nALTER TABLE memory_entries DROP COLUMN IF EXISTS summaries;\nALTER TABLE memory_entries DROP COLUMN IF EXISTS context_vector;\nALTER TABLE memory_entries DROP COLUMN IF EXISTS summary_updated_at;\n\n-- Remove summary column from knowledge_items\nALTER TABLE knowledge_items DROP COLUMN IF EXISTS summaries;\n"})}),"\n",(0,s.jsx)(n.h4,{id:"step-5-update-migration-tracking-1",children:"Step 5: Update Migration Tracking"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- Remove migration 007 from tracking (if using sqlx)\nDELETE FROM _sqlx_migrations WHERE version = 7;\n\n-- Or if using custom tracking table\nDELETE FROM schema_migrations WHERE version = '007';\n"})}),"\n",(0,s.jsx)(n.h3,{id:"complete-rollback-script",children:"Complete Rollback Script"}),"\n",(0,s.jsx)(n.p,{children:"For convenience, here's a complete script to rollback both migrations:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- ============================================\n-- CCA COMPLETE ROLLBACK SCRIPT\n-- Run this to fully remove CCA schema changes\n-- ============================================\n\nBEGIN;\n\n-- === Migration 008 Rollback ===\n\n-- Drop RLS policies\nDROP POLICY IF EXISTS hindsight_notes_delete_policy ON hindsight_notes;\nDROP POLICY IF EXISTS hindsight_notes_update_policy ON hindsight_notes;\nDROP POLICY IF EXISTS hindsight_notes_insert_policy ON hindsight_notes;\nDROP POLICY IF EXISTS hindsight_notes_tenant_isolation ON hindsight_notes;\nDROP POLICY IF EXISTS resolutions_delete_policy ON resolutions;\nDROP POLICY IF EXISTS resolutions_update_policy ON resolutions;\nDROP POLICY IF EXISTS resolutions_insert_policy ON resolutions;\nDROP POLICY IF EXISTS resolutions_tenant_isolation ON resolutions;\nDROP POLICY IF EXISTS error_signatures_delete_policy ON error_signatures;\nDROP POLICY IF EXISTS error_signatures_update_policy ON error_signatures;\nDROP POLICY IF EXISTS error_signatures_insert_policy ON error_signatures;\nDROP POLICY IF EXISTS error_signatures_tenant_isolation ON error_signatures;\n\n-- Drop hindsight indexes\nDROP INDEX IF EXISTS idx_hindsight_notes_tags;\nDROP INDEX IF EXISTS idx_hindsight_notes_quality;\nDROP INDEX IF EXISTS idx_hindsight_notes_error_signature;\nDROP INDEX IF EXISTS idx_hindsight_notes_tenant;\nDROP INDEX IF EXISTS idx_resolutions_application_count;\nDROP INDEX IF EXISTS idx_resolutions_success_rate;\nDROP INDEX IF EXISTS idx_resolutions_error_signature;\nDROP INDEX IF EXISTS idx_error_signatures_last_seen;\nDROP INDEX IF EXISTS idx_error_signatures_type;\nDROP INDEX IF EXISTS idx_error_signatures_tenant;\n\n-- Drop hindsight tables\nDROP TABLE IF EXISTS hindsight_notes CASCADE;\nDROP TABLE IF EXISTS resolutions CASCADE;\nDROP TABLE IF EXISTS error_signatures CASCADE;\n\n-- === Migration 007 Rollback ===\n\n-- Drop summary indexes\nDROP INDEX IF EXISTS idx_layer_summary_cache_expiry;\nDROP INDEX IF EXISTS idx_layer_summary_cache_lookup;\nDROP INDEX IF EXISTS idx_memory_entries_summary_updated;\n\n-- Drop summary cache table\nDROP TABLE IF EXISTS layer_summary_cache CASCADE;\n\n-- Remove summary columns\nALTER TABLE memory_entries DROP COLUMN IF EXISTS summaries;\nALTER TABLE memory_entries DROP COLUMN IF EXISTS context_vector;\nALTER TABLE memory_entries DROP COLUMN IF EXISTS summary_updated_at;\nALTER TABLE knowledge_items DROP COLUMN IF EXISTS summaries;\n\n-- Update migration tracking\nDELETE FROM _sqlx_migrations WHERE version IN (7, 8);\n\nCOMMIT;\n\n-- Verify rollback\nSELECT column_name FROM information_schema.columns \nWHERE table_name = 'memory_entries' \nAND column_name IN ('summaries', 'context_vector', 'summary_updated_at');\n-- Should return 0 rows\n\nSELECT table_name FROM information_schema.tables \nWHERE table_name IN ('layer_summary_cache', 'error_signatures', 'resolutions', 'hindsight_notes');\n-- Should return 0 rows\n"})}),"\n",(0,s.jsx)(n.h3,{id:"redis-cleanup-after-rollback",children:"Redis Cleanup After Rollback"}),"\n",(0,s.jsx)(n.p,{children:"After rolling back PostgreSQL, clean up Redis CCA keys:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# Connect to Redis\nredis-cli\n\n# Delete all summary cache keys\nSCAN 0 MATCH "summary:*" COUNT 1000\n# Then DEL each key, or use redis-cli with pattern:\nredis-cli --scan --pattern "summary:*" | xargs redis-cli DEL\n\n# Delete extension state keys\nredis-cli --scan --pattern "ext_state:*" | xargs redis-cli DEL\n\n# Delete CCA-related lock keys\nredis-cli --scan --pattern "cca:*" | xargs redis-cli DEL\n\n# Delete summarization budget keys\nredis-cli --scan --pattern "budget:summarization:*" | xargs redis-cli DEL\n'})}),"\n",(0,s.jsx)(n.p,{children:"Or use this Lua script for atomic cleanup:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-lua",children:"-- cleanup_cca_redis.lua\nlocal patterns = {'summary:*', 'ext_state:*', 'cca:*', 'budget:summarization:*'}\nlocal deleted = 0\n\nfor _, pattern in ipairs(patterns) do\n    local cursor = '0'\n    repeat\n        local result = redis.call('SCAN', cursor, 'MATCH', pattern, 'COUNT', 1000)\n        cursor = result[1]\n        local keys = result[2]\n        if #keys > 0 then\n            redis.call('DEL', unpack(keys))\n            deleted = deleted + #keys\n        end\n    until cursor == '0'\nend\n\nreturn deleted\n"})}),"\n",(0,s.jsx)(n.p,{children:"Run with:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"redis-cli --eval cleanup_cca_redis.lua\n"})}),"\n",(0,s.jsx)(n.h3,{id:"post-rollback-verification",children:"Post-Rollback Verification"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- Verify no CCA tables remain\nSELECT table_name FROM information_schema.tables \nWHERE table_schema = 'public' \nAND table_name IN ('layer_summary_cache', 'error_signatures', 'resolutions', 'hindsight_notes');\n-- Expected: 0 rows\n\n-- Verify no CCA columns remain on memory_entries\nSELECT column_name FROM information_schema.columns \nWHERE table_name = 'memory_entries' \nAND column_name IN ('summaries', 'context_vector', 'summary_updated_at');\n-- Expected: 0 rows\n\n-- Verify no CCA columns remain on knowledge_items\nSELECT column_name FROM information_schema.columns \nWHERE table_name = 'knowledge_items' \nAND column_name = 'summaries';\n-- Expected: 0 rows\n\n-- Verify migrations removed from tracking\nSELECT * FROM _sqlx_migrations WHERE version IN (7, 8);\n-- Expected: 0 rows\n"})}),"\n",(0,s.jsx)(n.h3,{id:"re-applying-migrations-after-rollback",children:"Re-applying Migrations After Rollback"}),"\n",(0,s.jsx)(n.p,{children:"If you need to re-apply CCA migrations after fixing issues:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# Ensure migrations are in proper state\nsqlx migrate info --source storage/migrations\n\n# Re-run migrations\nsqlx migrate run --source storage/migrations\n\n# Verify\npsql -d aeterna -c "\\d+ memory_entries" | grep summaries\n'})}),"\n",(0,s.jsx)(n.h3,{id:"emergency-rollback-minimal-downtime",children:"Emergency Rollback (Minimal Downtime)"}),"\n",(0,s.jsx)(n.p,{children:"For production emergencies, use this faster approach:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"-- Disable CCA at application level first (via config)\n-- Then run minimal rollback:\n\nBEGIN;\n-- Just disable CCA functionality without data loss\nALTER TABLE memory_entries ALTER COLUMN summaries SET DEFAULT '{}';\nALTER TABLE memory_entries ALTER COLUMN context_vector DROP NOT NULL;\n\n-- Disable triggers if any\n-- ALTER TABLE memory_entries DISABLE TRIGGER cca_summary_trigger;\n\nCOMMIT;\n"})}),"\n",(0,s.jsx)(n.p,{children:"This preserves CCA data but disables functionality, allowing quick recovery while you investigate."}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsx)(n.p,{children:"After successful migration:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Configure CCA in ",(0,s.jsx)(n.code,{children:"config/aeterna.toml"})," (see ",(0,s.jsx)(n.a,{href:"/aeterna/docs/cca/configuration",children:"Configuration Guide"}),")"]}),"\n",(0,s.jsxs)(n.li,{children:["Verify Redis schema is configured (see ",(0,s.jsx)(n.a,{href:"/aeterna/docs/cca/redis-schema",children:"Redis Schema"}),")"]}),"\n",(0,s.jsxs)(n.li,{children:["Test CCA tools via MCP interface (see ",(0,s.jsx)(n.a,{href:"/aeterna/docs/cca/api-reference",children:"API Reference"}),")"]}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453(e,n,r){r.d(n,{R:()=>a,x:()=>o});var i=r(6540);const s={},t=i.createContext(s);function a(e){const n=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);