"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[9396],{6429(e,n,a){a.r(n),a.d(n,{assets:()=>s,contentTitle:()=>c,default:()=>p,frontMatter:()=>o,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"sequence-diagrams","title":"Aeterna: Complete Sequence Diagrams","description":"Detailed Flow Diagrams for All Key Interactions","source":"@site/docs/sequence-diagrams.md","sourceDirName":".","slug":"/sequence-diagrams","permalink":"/aeterna/docs/sequence-diagrams","draft":false,"unlisted":false,"editUrl":"https://github.com/kikokikok/aeterna/tree/main/website/docs/sequence-diagrams.md","tags":[],"version":"current","frontMatter":{},"sidebar":"docs","previous":{"title":"Architecture: Memory-Knowledge System","permalink":"/aeterna/docs/architecture-overview"},"next":{"title":"Aeterna: Comprehensive UX/DX Guide","permalink":"/aeterna/docs/comprehensive-ux-dx-guide"}}');var r=a(4848),i=a(8453);const o={},c="Aeterna: Complete Sequence Diagrams",s={},l=[{value:"Table of Contents",id:"table-of-contents",level:2},{value:"Memory Operations",id:"memory-operations",level:2},{value:"1.1 Memory Add with Embedding Generation",id:"11-memory-add-with-embedding-generation",level:3},{value:"1.2 Multi-Layer Memory Search",id:"12-multi-layer-memory-search",level:3},{value:"1.3 Memory Promotion (Working \u2192 Team)",id:"13-memory-promotion-working--team",level:3},{value:"Knowledge Repository Operations",id:"knowledge-repository-operations",level:2},{value:"2.1 Knowledge Query with Policy Check",id:"21-knowledge-query-with-policy-check",level:3},{value:"2.2 Policy Addition with Approval Workflow",id:"22-policy-addition-with-approval-workflow",level:3},{value:"Sync Bridge Operations",id:"sync-bridge-operations",level:2},{value:"3.1 Memory-to-Knowledge Sync (Bidirectional)",id:"31-memory-to-knowledge-sync-bidirectional",level:3},{value:"Governance &amp; Policy Enforcement",id:"governance--policy-enforcement",level:2},{value:"4.1 Real-Time Policy Validation",id:"41-real-time-policy-validation",level:3},{value:"4.2 Drift Detection Workflow",id:"42-drift-detection-workflow",level:3},{value:"Agent-to-Agent (A2A) Communication",id:"agent-to-agent-a2a-communication",level:2},{value:"5.1 A2A Memory Sharing Protocol",id:"51-a2a-memory-sharing-protocol",level:3},{value:"5.2 Multi-Agent Collaboration Flow",id:"52-multi-agent-collaboration-flow",level:3},{value:"Advanced Features (CCA)",id:"advanced-features-cca",level:2},{value:"6.1 Context Architect: Hierarchical Compression",id:"61-context-architect-hierarchical-compression",level:3},{value:"6.2 Hindsight Learning: Error Pattern Capture",id:"62-hindsight-learning-error-pattern-capture",level:3},{value:"Multi-Tenant Operations",id:"multi-tenant-operations",level:2},{value:"7.1 Tenant Isolation &amp; RBAC",id:"71-tenant-isolation--rbac",level:3},{value:"Error Handling &amp; Recovery",id:"error-handling--recovery",level:2},{value:"8.1 Graceful Degradation Flow",id:"81-graceful-degradation-flow",level:3},{value:"Summary",id:"summary",level:2}];function d(e){const n={a:"a",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",mermaid:"mermaid",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"aeterna-complete-sequence-diagrams",children:"Aeterna: Complete Sequence Diagrams"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Detailed Flow Diagrams for All Key Interactions"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"table-of-contents",children:"Table of Contents"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#memory-operations",children:"Memory Operations"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#knowledge-repository-operations",children:"Knowledge Repository Operations"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#sync-bridge-operations",children:"Sync Bridge Operations"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#governance--policy-enforcement",children:"Governance & Policy Enforcement"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#agent-to-agent-a2a-communication",children:"Agent-to-Agent (A2A) Communication"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#advanced-features-cca",children:"Advanced Features (CCA)"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#multi-tenant-operations",children:"Multi-Tenant Operations"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#error-handling--recovery",children:"Error Handling & Recovery"})}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"memory-operations",children:"Memory Operations"}),"\n",(0,r.jsx)(n.h3,{id:"11-memory-add-with-embedding-generation",children:"1.1 Memory Add with Embedding Generation"}),"\n",(0,r.jsx)(n.mermaid,{value:'sequenceDiagram\n    participant Client as Client/Agent\n    participant API as Aeterna API\n    participant MemManager as Memory Manager\n    participant Validator as Input Validator\n    participant Embedder as Embedding Service\n    participant VectorDB as Qdrant\n    participant Cache as Redis\n    participant Metrics as Metrics Collector\n\n    Client->>API: POST /api/v1/memory/add\n    activate API\n    \n    API->>Validator: Validate input\n    activate Validator\n    Validator--\x3e>API: \u2713 Valid\n    deactivate Validator\n    \n    API->>MemManager: add_memory(entry)\n    activate MemManager\n    \n    MemManager->>Metrics: increment(memory_add_total)\n    \n    par Parallel Processing\n        MemManager->>Embedder: generate_embedding(content)\n        activate Embedder\n        Embedder->>Embedder: Tokenize content\n        Embedder->>Embedder: Call OpenAI API\n        Embedder--\x3e>MemManager: embedding[1536]\n        deactivate Embedder\n    and\n        MemManager->>MemManager: Generate memory_id\n        MemManager->>MemManager: Add metadata (timestamps, layer)\n    end\n    \n    MemManager->>VectorDB: upsert_point(id, embedding, payload)\n    activate VectorDB\n    VectorDB--\x3e>MemManager: \u2713 Stored\n    deactivate VectorDB\n    \n    MemManager->>Cache: set(memory_id, metadata)\n    activate Cache\n    Cache--\x3e>MemManager: \u2713 Cached\n    deactivate Cache\n    \n    MemManager->>Metrics: observe(memory_add_duration_ms, 245)\n    \n    MemManager--\x3e>API: MemoryEntry{id, layer}\n    deactivate MemManager\n    \n    API--\x3e>Client: 201 Created {id: "mem_abc123"}\n    deactivate API'}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"12-multi-layer-memory-search",children:"1.2 Multi-Layer Memory Search"}),"\n",(0,r.jsx)(n.mermaid,{value:'sequenceDiagram\n    participant Client as Client/Agent\n    participant API as Aeterna API\n    participant MemManager as Memory Manager\n    participant Embedder as Embedding Service\n    participant Redis as Redis Cache\n    participant Qdrant as Qdrant\n    participant Postgres as PostgreSQL\n    participant Scorer as Relevance Scorer\n    participant Dedup as Deduplicator\n\n    Client->>API: POST /api/v1/memory/search\n    activate API\n    Note over Client,API: Query: "How to authenticate APIs?"<br/>Layers: [team, org, company]\n    \n    API->>MemManager: search(query, layers, limit)\n    activate MemManager\n    \n    MemManager->>Embedder: generate_embedding(query)\n    activate Embedder\n    Embedder--\x3e>MemManager: query_embedding[1536]\n    deactivate Embedder\n    \n    par Search Layer: Team (Redis)\n        MemManager->>Redis: search_by_embedding(team)\n        activate Redis\n        Redis--\x3e>MemManager: results_team[5]\n        deactivate Redis\n    and Search Layer: Org (Qdrant)\n        MemManager->>Qdrant: search_points(org_collection)\n        activate Qdrant\n        Qdrant--\x3e>MemManager: results_org[8]\n        deactivate Qdrant\n    and Search Layer: Company (PostgreSQL)\n        MemManager->>Postgres: SELECT with pgvector\n        activate Postgres\n        Postgres--\x3e>MemManager: results_company[3]\n        deactivate Postgres\n    end\n    \n    MemManager->>Scorer: rank_results(all_results)\n    activate Scorer\n    Scorer->>Scorer: Apply layer precedence (team > org > company)\n    Scorer->>Scorer: Calculate relevance scores\n    Scorer->>Scorer: Apply recency boost\n    Scorer--\x3e>MemManager: ranked_results[16]\n    deactivate Scorer\n    \n    MemManager->>Dedup: deduplicate(ranked_results)\n    activate Dedup\n    Dedup->>Dedup: Compare by content hash\n    Dedup->>Dedup: Keep highest-layer version\n    Dedup--\x3e>MemManager: unique_results[10]\n    deactivate Dedup\n    \n    MemManager--\x3e>API: SearchResults{results, total}\n    deactivate MemManager\n    \n    API--\x3e>Client: 200 OK {results: [...]}\n    deactivate API'}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"13-memory-promotion-working--team",children:"1.3 Memory Promotion (Working \u2192 Team)"}),"\n",(0,r.jsx)(n.mermaid,{value:'sequenceDiagram\n    participant Timer as Background Timer\n    participant PromotionEngine as Promotion Engine\n    participant MemManager as Memory Manager\n    participant Redis as Redis (Working)\n    participant Postgres as PostgreSQL (Team)\n    participant Metrics as Metrics Collector\n    participant Notifier as Event Notifier\n\n    loop Every 5 minutes\n        Timer->>PromotionEngine: check_promotion_candidates()\n        activate PromotionEngine\n        \n        PromotionEngine->>MemManager: get_layer_memories(working)\n        activate MemManager\n        MemManager->>Redis: scan_with_pattern("working:*")\n        activate Redis\n        Redis--\x3e>MemManager: memories[100]\n        deactivate Redis\n        MemManager--\x3e>PromotionEngine: candidate_memories\n        deactivate MemManager\n        \n        loop For each memory\n            PromotionEngine->>PromotionEngine: calculate_promotion_score()\n            Note over PromotionEngine: Score = (access_count * 0.4) +<br/>(confidence * 0.3) +<br/>(age_weight * 0.2) +<br/>(reward * 0.1)\n            \n            alt Score > threshold (0.75)\n                PromotionEngine->>MemManager: promote_memory(id, target_layer=session)\n                activate MemManager\n                \n                MemManager->>Redis: get(working:mem_id)\n                activate Redis\n                Redis--\x3e>MemManager: memory_data\n                deactivate Redis\n                \n                MemManager->>Postgres: INSERT INTO session_memories\n                activate Postgres\n                Postgres--\x3e>MemManager: \u2713 Inserted\n                deactivate Postgres\n                \n                MemManager->>Redis: setex(session:mem_id, ttl=3600)\n                activate Redis\n                Redis--\x3e>MemManager: \u2713 Cached\n                deactivate Redis\n                \n                MemManager->>Redis: del(working:mem_id)\n                activate Redis\n                Redis--\x3e>MemManager: \u2713 Deleted\n                deactivate Redis\n                \n                MemManager--\x3e>PromotionEngine: \u2713 Promoted\n                deactivate MemManager\n                \n                PromotionEngine->>Metrics: increment(memory_promotions_total, layer=session)\n                \n                PromotionEngine->>Notifier: emit_event(memory_promoted)\n                activate Notifier\n                Notifier->>Notifier: Publish to Redis pub/sub\n                Notifier--\x3e>PromotionEngine: \u2713 Notified\n                deactivate Notifier\n            end\n        end\n        \n        deactivate PromotionEngine\n    end'}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"knowledge-repository-operations",children:"Knowledge Repository Operations"}),"\n",(0,r.jsx)(n.h3,{id:"21-knowledge-query-with-policy-check",children:"2.1 Knowledge Query with Policy Check"}),"\n",(0,r.jsx)(n.mermaid,{value:'sequenceDiagram\n    participant Client as Client/Agent\n    participant API as Aeterna API\n    participant KnowledgeRepo as Knowledge Repository\n    participant GitBackend as Git Backend\n    participant Parser as Document Parser\n    participant Embedder as Embedding Service\n    participant Qdrant as Qdrant Search\n    participant Governance as Governance Engine\n    participant Cache as Redis Cache\n\n    Client->>API: POST /api/v1/knowledge/query\n    activate API\n    Note over Client,API: Query: "Database standards"\n    \n    API->>KnowledgeRepo: query(text, doc_types)\n    activate KnowledgeRepo\n    \n    KnowledgeRepo->>Cache: get_cached_query(hash)\n    activate Cache\n    Cache--\x3e>KnowledgeRepo: Cache miss\n    deactivate Cache\n    \n    KnowledgeRepo->>Embedder: generate_embedding(query)\n    activate Embedder\n    Embedder--\x3e>KnowledgeRepo: query_embedding[1536]\n    deactivate Embedder\n    \n    KnowledgeRepo->>Qdrant: search_knowledge_index()\n    activate Qdrant\n    Qdrant--\x3e>KnowledgeRepo: document_ids[10]\n    deactivate Qdrant\n    \n    loop For each document_id\n        KnowledgeRepo->>GitBackend: get_file(doc_id)\n        activate GitBackend\n        GitBackend->>GitBackend: git show HEAD:path\n        GitBackend--\x3e>KnowledgeRepo: raw_content\n        deactivate GitBackend\n        \n        KnowledgeRepo->>Parser: parse(raw_content, type)\n        activate Parser\n        Parser->>Parser: Extract frontmatter\n        Parser->>Parser: Parse markdown\n        Parser--\x3e>KnowledgeRepo: structured_doc\n        deactivate Parser\n        \n        KnowledgeRepo->>Governance: check_access(user, doc_id)\n        activate Governance\n        Governance->>Governance: Evaluate Cedar policy\n        Governance--\x3e>KnowledgeRepo: access_granted=true\n        deactivate Governance\n    end\n    \n    KnowledgeRepo->>KnowledgeRepo: Rank by relevance\n    KnowledgeRepo->>KnowledgeRepo: Apply access filters\n    \n    KnowledgeRepo->>Cache: set_cached_query(hash, results, ttl=300)\n    activate Cache\n    Cache--\x3e>KnowledgeRepo: \u2713 Cached\n    deactivate Cache\n    \n    KnowledgeRepo--\x3e>API: QueryResults{docs, total}\n    deactivate KnowledgeRepo\n    \n    API--\x3e>Client: 200 OK {results: [...]}\n    deactivate API'}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"22-policy-addition-with-approval-workflow",children:"2.2 Policy Addition with Approval Workflow"}),"\n",(0,r.jsx)(n.mermaid,{value:'sequenceDiagram\n    participant Sam as Sam (Architect)\n    participant CLI as Aeterna CLI\n    participant API as Aeterna API\n    participant KnowledgeRepo as Knowledge Repository\n    participant GitBackend as Git Backend\n    participant Governance as Governance Engine\n    participant Validator as Policy Validator\n    participant Approver as Approval Service\n    participant Notifier as Email/Slack Notifier\n\n    Sam->>CLI: aeterna policy add --file policy.yaml\n    activate CLI\n    \n    CLI->>Validator: validate_syntax(policy.yaml)\n    activate Validator\n    Validator->>Validator: Parse YAML\n    Validator->>Validator: Check constraint syntax\n    Validator->>Validator: Validate severity levels\n    Validator--\x3e>CLI: \u2713 Valid\n    deactivate Validator\n    \n    CLI->>API: POST /api/v1/knowledge/policy\n    activate API\n    \n    API->>Governance: check_permission(sam, "policy:create")\n    activate Governance\n    Governance->>Governance: Query Cedar policy\n    Governance--\x3e>API: Allowed (role=architect)\n    deactivate Governance\n    \n    API->>KnowledgeRepo: add_policy(policy_data)\n    activate KnowledgeRepo\n    \n    KnowledgeRepo->>GitBackend: create_branch(feature/policy-xyz)\n    activate GitBackend\n    GitBackend->>GitBackend: git checkout -b\n    GitBackend--\x3e>KnowledgeRepo: \u2713 Branch created\n    deactivate GitBackend\n    \n    KnowledgeRepo->>GitBackend: commit_file(policies/new-policy.yaml)\n    activate GitBackend\n    GitBackend->>GitBackend: git add && git commit\n    GitBackend--\x3e>KnowledgeRepo: commit_sha\n    deactivate GitBackend\n    \n    KnowledgeRepo->>Approver: create_approval_request()\n    activate Approver\n    Approver->>Approver: Determine required approvers\n    Approver->>Approver: Create approval record\n    Approver--\x3e>KnowledgeRepo: approval_id\n    deactivate Approver\n    \n    KnowledgeRepo->>Notifier: notify_approvers(approval_id)\n    activate Notifier\n    Notifier->>Notifier: Send emails to architects\n    Notifier--\x3e>KnowledgeRepo: \u2713 Notified\n    deactivate Notifier\n    \n    KnowledgeRepo--\x3e>API: PolicyPending{id, approval_id}\n    deactivate KnowledgeRepo\n    \n    API--\x3e>CLI: 202 Accepted (pending approval)\n    deactivate API\n    \n    CLI--\x3e>Sam: \u2713 Policy submitted, awaiting approval\n    deactivate CLI\n    \n    Note over Sam,Notifier: Later: Approval Process\n    \n    participant Approver2 as Other Architect\n    Approver2->>API: POST /api/v1/approvals/{id}/approve\n    activate API\n    \n    API->>Approver: record_approval(user, approval_id)\n    activate Approver\n    Approver->>Approver: Check approval threshold met\n    Approver--\x3e>API: Status=approved\n    deactivate Approver\n    \n    API->>GitBackend: merge_branch(feature/policy-xyz)\n    activate GitBackend\n    GitBackend->>GitBackend: git merge --ff\n    GitBackend--\x3e>API: \u2713 Merged to main\n    deactivate GitBackend\n    \n    API->>KnowledgeRepo: trigger_sync()\n    activate KnowledgeRepo\n    KnowledgeRepo->>KnowledgeRepo: Reindex policy\n    KnowledgeRepo--\x3e>API: \u2713 Policy active\n    deactivate KnowledgeRepo\n    \n    API--\x3e>Approver2: 200 OK\n    deactivate API\n    \n    API->>Notifier: notify_policy_active(sam)\n    activate Notifier\n    Notifier--\x3e>Sam: \ud83d\udce7 Your policy is now active\n    deactivate Notifier'}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"sync-bridge-operations",children:"Sync Bridge Operations"}),"\n",(0,r.jsx)(n.h3,{id:"31-memory-to-knowledge-sync-bidirectional",children:"3.1 Memory-to-Knowledge Sync (Bidirectional)"}),"\n",(0,r.jsx)(n.mermaid,{value:'sequenceDiagram\n    participant Timer as Sync Timer\n    participant SyncBridge as Sync Bridge\n    participant MemManager as Memory Manager\n    participant KnowledgeRepo as Knowledge Repo\n    participant DeltaDetector as Delta Detector\n    participant ConflictResolver as Conflict Resolver\n    participant GitBackend as Git Backend\n    participant EventBus as Redis Event Bus\n\n    loop Every 60 seconds\n        Timer->>SyncBridge: trigger_sync()\n        activate SyncBridge\n        \n        Note over SyncBridge: Phase 1: Memory \u2192 Knowledge\n        \n        SyncBridge->>MemManager: get_modified_since(last_sync)\n        activate MemManager\n        MemManager--\x3e>SyncBridge: modified_memories[12]\n        deactivate MemManager\n        \n        SyncBridge->>DeltaDetector: detect_deltas(memories)\n        activate DeltaDetector\n        \n        loop For each memory\n            DeltaDetector->>DeltaDetector: Calculate content hash\n            DeltaDetector->>DeltaDetector: Compare with last known state\n            \n            alt Content changed\n                DeltaDetector->>DeltaDetector: Mark as MODIFIED\n            else New memory\n                DeltaDetector->>DeltaDetector: Mark as ADDED\n            else Memory deleted\n                DeltaDetector->>DeltaDetector: Mark as REMOVED\n            end\n        end\n        \n        DeltaDetector--\x3e>SyncBridge: deltas[7]\n        deactivate DeltaDetector\n        \n        SyncBridge->>KnowledgeRepo: apply_deltas(deltas)\n        activate KnowledgeRepo\n        \n        loop For each delta\n            alt Delta type: ADDED\n                KnowledgeRepo->>GitBackend: create_file(path, content)\n                activate GitBackend\n                GitBackend--\x3e>KnowledgeRepo: \u2713 Created\n                deactivate GitBackend\n            else Delta type: MODIFIED\n                KnowledgeRepo->>ConflictResolver: check_conflict(file)\n                activate ConflictResolver\n                \n                alt Conflict detected\n                    ConflictResolver->>ConflictResolver: Apply merge strategy (last-write-wins)\n                    ConflictResolver--\x3e>KnowledgeRepo: resolved_content\n                else No conflict\n                    ConflictResolver--\x3e>KnowledgeRepo: proceed\n                end\n                deactivate ConflictResolver\n                \n                KnowledgeRepo->>GitBackend: update_file(path, content)\n                activate GitBackend\n                GitBackend--\x3e>KnowledgeRepo: \u2713 Updated\n                deactivate GitBackend\n            else Delta type: REMOVED\n                KnowledgeRepo->>GitBackend: delete_file(path)\n                activate GitBackend\n                GitBackend--\x3e>KnowledgeRepo: \u2713 Deleted\n                deactivate GitBackend\n            end\n        end\n        \n        KnowledgeRepo->>GitBackend: commit("Sync: M\u2192K batch")\n        activate GitBackend\n        GitBackend--\x3e>KnowledgeRepo: commit_sha\n        deactivate GitBackend\n        \n        KnowledgeRepo--\x3e>SyncBridge: sync_complete(7 deltas)\n        deactivate KnowledgeRepo\n        \n        Note over SyncBridge: Phase 2: Knowledge \u2192 Memory\n        \n        SyncBridge->>KnowledgeRepo: get_commits_since(last_sync)\n        activate KnowledgeRepo\n        KnowledgeRepo->>GitBackend: git log --since\n        activate GitBackend\n        GitBackend--\x3e>KnowledgeRepo: commits[3]\n        deactivate GitBackend\n        KnowledgeRepo--\x3e>SyncBridge: changed_files[5]\n        deactivate KnowledgeRepo\n        \n        SyncBridge->>MemManager: import_knowledge_updates(files)\n        activate MemManager\n        \n        loop For each file\n            MemManager->>MemManager: Parse document\n            MemManager->>MemManager: Extract key facts\n            MemManager->>MemManager: Store as procedural memory\n        end\n        \n        MemManager--\x3e>SyncBridge: imported[5]\n        deactivate MemManager\n        \n        SyncBridge->>EventBus: publish(sync_complete_event)\n        activate EventBus\n        EventBus--\x3e>SyncBridge: \u2713 Published\n        deactivate EventBus\n        \n        SyncBridge->>SyncBridge: Update last_sync_time\n        \n        deactivate SyncBridge\n    end'}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"governance--policy-enforcement",children:"Governance & Policy Enforcement"}),"\n",(0,r.jsx)(n.h3,{id:"41-real-time-policy-validation",children:"4.1 Real-Time Policy Validation"}),"\n",(0,r.jsx)(n.mermaid,{value:'sequenceDiagram\n    participant Agent as AI Agent\n    participant API as Aeterna API\n    participant KnowledgeRepo as Knowledge Repo\n    participant GovernanceEngine as Governance Engine\n    participant PolicyEngine as Cedar Policy Engine\n    participant ConstraintEvaluator as Constraint Evaluator\n    participant AuditLogger as Audit Logger\n    participant Notifier as Notifier\n\n    Agent->>API: POST /api/v1/knowledge/check\n    activate API\n    Note over Agent,API: Content: "Use MongoDB for user data"\n    \n    API->>KnowledgeRepo: validate_content(content)\n    activate KnowledgeRepo\n    \n    KnowledgeRepo->>GovernanceEngine: check_policies(content, context)\n    activate GovernanceEngine\n    \n    GovernanceEngine->>GovernanceEngine: Extract technology mentions\n    Note over GovernanceEngine: Detected: "MongoDB"\n    \n    GovernanceEngine->>PolicyEngine: query_policies(technology="mongodb")\n    activate PolicyEngine\n    \n    PolicyEngine->>PolicyEngine: Load relevant policies\n    Note over PolicyEngine: Found: db-standards policy\n    \n    PolicyEngine--\x3e>GovernanceEngine: applicable_policies[1]\n    deactivate PolicyEngine\n    \n    loop For each policy\n        GovernanceEngine->>ConstraintEvaluator: evaluate(constraint, context)\n        activate ConstraintEvaluator\n        \n        Note over ConstraintEvaluator: Constraint: MUST_USE postgresql FOR persistence\n        \n        ConstraintEvaluator->>ConstraintEvaluator: Check if MongoDB in approved list\n        ConstraintEvaluator->>ConstraintEvaluator: Result: \u274c VIOLATION\n        \n        ConstraintEvaluator--\x3e>GovernanceEngine: violation{policy, severity, message}\n        deactivate ConstraintEvaluator\n    end\n    \n    GovernanceEngine->>AuditLogger: log_violation(user, policy, content)\n    activate AuditLogger\n    AuditLogger->>AuditLogger: Record to audit trail\n    AuditLogger--\x3e>GovernanceEngine: \u2713 Logged\n    deactivate AuditLogger\n    \n    alt Severity: BLOCKING\n        GovernanceEngine->>Notifier: send_alert(violation)\n        activate Notifier\n        Notifier->>Notifier: Notify team lead\n        Notifier--\x3e>GovernanceEngine: \u2713 Notified\n        deactivate Notifier\n    end\n    \n    GovernanceEngine--\x3e>KnowledgeRepo: ValidationResult{valid=false, violations}\n    deactivate GovernanceEngine\n    \n    KnowledgeRepo--\x3e>API: ValidationResult\n    deactivate KnowledgeRepo\n    \n    API--\x3e>Agent: 200 OK {valid: false, violations: [...]}\n    deactivate API\n    \n    Note over Agent: Agent presents violation to user<br/>with alternative suggestions'}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"42-drift-detection-workflow",children:"4.2 Drift Detection Workflow"}),"\n",(0,r.jsx)(n.mermaid,{value:"sequenceDiagram\n    participant Timer as Scheduled Job\n    participant DriftDetector as Drift Detector\n    participant CodebaseScanner as Codebase Scanner\n    participant KnowledgeRepo as Knowledge Repo\n    participant Analyzer as Drift Analyzer\n    participant Reporter as Report Generator\n    participant Notifier as Notifier\n    participant Dashboard as Drift Dashboard\n\n    loop Every 6 hours\n        Timer->>DriftDetector: run_drift_detection()\n        activate DriftDetector\n        \n        DriftDetector->>KnowledgeRepo: get_active_policies()\n        activate KnowledgeRepo\n        KnowledgeRepo--\x3e>DriftDetector: policies[23]\n        deactivate KnowledgeRepo\n        \n        par Scan Codebase\n            DriftDetector->>CodebaseScanner: scan_codebase(patterns)\n            activate CodebaseScanner\n            \n            CodebaseScanner->>CodebaseScanner: Clone repositories\n            CodebaseScanner->>CodebaseScanner: Parse source files\n            CodebaseScanner->>CodebaseScanner: Extract technology usage\n            Note over CodebaseScanner: Found: PostgreSQL: 45 files<br/>MongoDB: 3 files<br/>MySQL: 1 file\n            \n            CodebaseScanner--\x3e>DriftDetector: usage_report\n            deactivate CodebaseScanner\n        and Load Policy Expectations\n            DriftDetector->>KnowledgeRepo: get_policy_constraints()\n            activate KnowledgeRepo\n            KnowledgeRepo--\x3e>DriftDetector: constraints[15]\n            deactivate KnowledgeRepo\n        end\n        \n        DriftDetector->>Analyzer: analyze_drift(usage, constraints)\n        activate Analyzer\n        \n        loop For each technology\n            Analyzer->>Analyzer: Compare actual vs expected\n            \n            alt Violation found\n                Analyzer->>Analyzer: Identify violating files\n                Analyzer->>Analyzer: Calculate drift score\n                \n                Note over Analyzer: MongoDB found in:<br/>- services/legacy-api/db.js<br/>- services/temp-service/store.js<br/>Policy: MUST_USE postgresql\n                \n                Analyzer->>Analyzer: Check if exception exists\n                \n                alt No exception\n                    Analyzer->>Analyzer: Mark as VIOLATION\n                else Exception approved\n                    Analyzer->>Analyzer: Mark as EXCEPTION (track)\n                end\n            end\n        end\n        \n        Analyzer--\x3e>DriftDetector: drift_report{violations, exceptions}\n        deactivate Analyzer\n        \n        DriftDetector->>Reporter: generate_report(drift_report)\n        activate Reporter\n        \n        Reporter->>Reporter: Format HTML report\n        Reporter->>Reporter: Calculate compliance score\n        Reporter->>Reporter: Identify trends\n        \n        Reporter--\x3e>DriftDetector: formatted_report\n        deactivate Reporter\n        \n        alt Violations found\n            DriftDetector->>Notifier: send_drift_alert(violations)\n            activate Notifier\n            \n            Notifier->>Notifier: Group by team\n            Notifier->>Notifier: Prioritize by severity\n            \n            loop For each team\n                Notifier->>Notifier: Send email to team lead\n                Notifier->>Notifier: Post to Slack channel\n            end\n            \n            Notifier--\x3e>DriftDetector: \u2713 Notifications sent\n            deactivate Notifier\n        end\n        \n        DriftDetector->>Dashboard: update_dashboard(report)\n        activate Dashboard\n        Dashboard->>Dashboard: Update compliance metrics\n        Dashboard->>Dashboard: Refresh violation trends\n        Dashboard--\x3e>DriftDetector: \u2713 Updated\n        deactivate Dashboard\n        \n        deactivate DriftDetector\n    end"}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"agent-to-agent-a2a-communication",children:"Agent-to-Agent (A2A) Communication"}),"\n",(0,r.jsx)(n.h3,{id:"51-a2a-memory-sharing-protocol",children:"5.1 A2A Memory Sharing Protocol"}),"\n",(0,r.jsx)(n.mermaid,{value:'sequenceDiagram\n    participant AgentA as Agent A (Frontend)\n    participant A2AClient as A2A Client\n    participant Gateway as A2A Gateway\n    participant AuthMiddleware as Auth Middleware\n    participant RateLimiter as Rate Limiter\n    participant SkillRouter as Skill Router\n    participant AgentB as Agent B (Backend)\n    participant Memory as Memory System\n    participant ThreadStore as Thread Store\n\n    AgentA->>A2AClient: query_agent(skill="memory:search", query="JWT errors")\n    activate A2AClient\n    \n    A2AClient->>A2AClient: Prepare JSONRPC 2.0 request\n    Note over A2AClient: {<br/>  "jsonrpc": "2.0",<br/>  "method": "skill.invoke",<br/>  "params": {...}<br/>}\n    \n    A2AClient->>Gateway: POST /a2a/query\n    activate Gateway\n    \n    Gateway->>AuthMiddleware: authenticate(request)\n    activate AuthMiddleware\n    \n    AuthMiddleware->>AuthMiddleware: Verify API key\n    AuthMiddleware->>AuthMiddleware: Validate JWT token\n    \n    AuthMiddleware--\x3e>Gateway: Principal{agent_id, permissions}\n    deactivate AuthMiddleware\n    \n    Gateway->>RateLimiter: check_rate_limit(agent_id)\n    activate RateLimiter\n    \n    RateLimiter->>RateLimiter: Check token bucket\n    Note over RateLimiter: Limit: 100 requests/minute\n    \n    RateLimiter--\x3e>Gateway: \u2713 Allowed\n    deactivate RateLimiter\n    \n    Gateway->>SkillRouter: route_request(skill, params)\n    activate SkillRouter\n    \n    SkillRouter->>SkillRouter: Parse skill identifier\n    Note over SkillRouter: Skill: memory:search<br/>Target: agents with memory skill\n    \n    SkillRouter->>SkillRouter: Discover agents with skill\n    Note over SkillRouter: Found: [AgentB, AgentC]\n    \n    SkillRouter->>SkillRouter: Select best agent (load, relevance)\n    \n    SkillRouter->>ThreadStore: get_or_create_thread(agent_a, agent_b)\n    activate ThreadStore\n    ThreadStore--\x3e>SkillRouter: thread_id="thread_xyz"\n    deactivate ThreadStore\n    \n    SkillRouter->>AgentB: invoke_skill(memory:search, params, thread_id)\n    deactivate SkillRouter\n    activate AgentB\n    \n    AgentB->>Memory: search(query="JWT errors", context={...})\n    activate Memory\n    \n    Memory->>Memory: Generate embedding\n    Memory->>Memory: Search across layers\n    Memory->>Memory: Rank results\n    \n    Memory--\x3e>AgentB: results[5]\n    deactivate Memory\n    \n    AgentB->>AgentB: Format response\n    Note over AgentB: Found solution:<br/>JWT key rotation yesterday<br/>Refresh from /.well-known/jwks.json\n    \n    AgentB->>ThreadStore: append_message(thread_id, response)\n    activate ThreadStore\n    ThreadStore--\x3e>AgentB: \u2713 Stored\n    deactivate ThreadStore\n    \n    AgentB--\x3e>Gateway: JSONRPC Response\n    deactivate AgentB\n    \n    Gateway--\x3e>A2AClient: 200 OK {result: {...}}\n    deactivate Gateway\n    \n    A2AClient--\x3e>AgentA: QueryResult{solution, confidence, source}\n    deactivate A2AClient\n    \n    Note over AgentA: Agent A uses solution<br/>to help its user'}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"52-multi-agent-collaboration-flow",children:"5.2 Multi-Agent Collaboration Flow"}),"\n",(0,r.jsx)(n.mermaid,{value:'sequenceDiagram\n    participant User as Customer\n    participant IntakeAgent as Intake Agent\n    participant A2AGateway as A2A Gateway\n    participant BillingAgent as Billing Agent\n    participant TechAgent as Technical Agent\n    participant Memory as Shared Memory\n    participant Orchestrator as Orchestrator\n\n    User->>IntakeAgent: "Payment failed during upgrade"\n    activate IntakeAgent\n    \n    IntakeAgent->>IntakeAgent: Classify issue: payment\n    \n    IntakeAgent->>A2AGateway: query(skill="billing:diagnose_payment")\n    activate A2AGateway\n    \n    A2AGateway->>BillingAgent: invoke_skill(diagnose_payment, context)\n    activate BillingAgent\n    \n    BillingAgent->>Memory: search("payment upgrade failures")\n    activate Memory\n    Memory--\x3e>BillingAgent: Common cause: expired cards\n    deactivate Memory\n    \n    BillingAgent--\x3e>A2AGateway: Diagnosis: Check card expiration\n    deactivate BillingAgent\n    \n    A2AGateway--\x3e>IntakeAgent: Result\n    deactivate A2AGateway\n    \n    IntakeAgent--\x3e>User: "Is your card expired?"\n    User->>IntakeAgent: "No, I updated it. Still failing."\n    \n    IntakeAgent->>A2AGateway: query(skill="technical:payment_gateway")\n    activate A2AGateway\n    \n    A2AGateway->>TechAgent: invoke_skill(diagnose_gateway, context)\n    activate TechAgent\n    \n    TechAgent->>Memory: search("payment gateway failures recent")\n    activate Memory\n    Memory--\x3e>TechAgent: Found incident from yesterday:<br/>Gateway timeout issue\n    deactivate Memory\n    \n    TechAgent->>TechAgent: Confirm gateway status\n    TechAgent->>TechAgent: Check workaround availability\n    \n    TechAgent--\x3e>A2AGateway: Known issue + manual workaround\n    deactivate TechAgent\n    \n    A2AGateway--\x3e>IntakeAgent: Result\n    deactivate A2AGateway\n    \n    IntakeAgent->>Orchestrator: request_action(manual_upgrade)\n    activate Orchestrator\n    \n    Orchestrator->>A2AGateway: query(skill="billing:manual_upgrade_approval")\n    activate A2AGateway\n    \n    A2AGateway->>BillingAgent: invoke_skill(approve_manual_upgrade)\n    activate BillingAgent\n    \n    BillingAgent->>BillingAgent: Verify user eligibility\n    BillingAgent->>BillingAgent: Check authorization\n    \n    BillingAgent--\x3e>A2AGateway: Approved\n    deactivate BillingAgent\n    \n    A2AGateway--\x3e>Orchestrator: Approval granted\n    deactivate A2AGateway\n    \n    Orchestrator->>Orchestrator: Execute manual upgrade\n    Orchestrator--\x3e>IntakeAgent: \u2713 Upgrade complete\n    deactivate Orchestrator\n    \n    IntakeAgent--\x3e>User: "Your upgrade is complete!"\n    \n    IntakeAgent->>Memory: store_resolution(interaction)\n    activate Memory\n    Note over Memory: Store: payment_gateway_timeout<br/>Resolution: manual_upgrade<br/>Collaboration: 3 agents\n    Memory--\x3e>IntakeAgent: \u2713 Stored for future\n    deactivate Memory\n    \n    deactivate IntakeAgent'}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"advanced-features-cca",children:"Advanced Features (CCA)"}),"\n",(0,r.jsx)(n.h3,{id:"61-context-architect-hierarchical-compression",children:"6.1 Context Architect: Hierarchical Compression"}),"\n",(0,r.jsx)(n.mermaid,{value:"sequenceDiagram\n    participant Agent as AI Agent\n    participant ContextArchitect as Context Architect\n    participant Memory as Memory System\n    participant Knowledge as Knowledge Repo\n    participant Compressor as Content Compressor\n    participant Assembler as Context Assembler\n    participant TokenCounter as Token Counter\n\n    Agent->>ContextArchitect: assemble_context(task, token_budget=4096)\n    activate ContextArchitect\n    \n    ContextArchitect->>Memory: retrieve_relevant(task)\n    activate Memory\n    \n    par Retrieve from layers\n        Memory->>Memory: Search working layer\n        Memory->>Memory: Search session layer\n        Memory->>Memory: Search team layer\n        Memory->>Memory: Search org layer\n    end\n    \n    Memory--\x3e>ContextArchitect: memories[50], total_tokens=12000\n    deactivate Memory\n    \n    ContextArchitect->>Knowledge: retrieve_relevant(task)\n    activate Knowledge\n    Knowledge--\x3e>ContextArchitect: docs[8], total_tokens=8000\n    deactivate Knowledge\n    \n    Note over ContextArchitect: Total: 20,000 tokens<br/>Budget: 4,096 tokens<br/>Compression needed!\n    \n    ContextArchitect->>Compressor: compress_hierarchically(content, budget)\n    activate Compressor\n    \n    loop For each content item\n        Compressor->>Compressor: Calculate relevance score\n        \n        Compressor->>Compressor: Generate multi-level summaries\n        Note over Compressor: Level 1: 1 sentence (50 tokens)<br/>Level 2: 1 paragraph (150 tokens)<br/>Level 3: Detailed (500 tokens)\n        \n        Compressor->>Compressor: Store with priority tier\n    end\n    \n    Compressor->>Assembler: assemble(summaries, budget)\n    activate Assembler\n    \n    Assembler->>Assembler: Sort by relevance + layer precedence\n    \n    loop Build context\n        Assembler->>TokenCounter: count_tokens(summary)\n        activate TokenCounter\n        TokenCounter--\x3e>Assembler: token_count\n        deactivate TokenCounter\n        \n        alt Tokens remaining\n            alt High relevance (>0.9)\n                Assembler->>Assembler: Add Level 3 (detailed)\n            else Medium relevance (0.7-0.9)\n                Assembler->>Assembler: Add Level 2 (paragraph)\n            else Low relevance (\\<0.7)\n                Assembler->>Assembler: Add Level 1 (sentence)\n            end\n        else Budget exhausted\n            Assembler->>Assembler: Skip remaining\n        end\n    end\n    \n    Assembler--\x3e>Compressor: assembled_context, used_tokens=4050\n    deactivate Assembler\n    \n    Compressor--\x3e>ContextArchitect: compressed_context\n    deactivate Compressor\n    \n    ContextArchitect->>ContextArchitect: Validate coherence\n    ContextArchitect->>ContextArchitect: Add cross-references\n    \n    ContextArchitect--\x3e>Agent: OptimizedContext{content, metadata}\n    deactivate ContextArchitect\n    \n    Note over Agent: Context assembled:<br/>4,050 tokens (99% of budget)<br/>15 memories (compressed from 50)<br/>6 docs (compressed from 8)<br/>Relevance-optimized!"}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"62-hindsight-learning-error-pattern-capture",children:"6.2 Hindsight Learning: Error Pattern Capture"}),"\n",(0,r.jsx)(n.mermaid,{value:'sequenceDiagram\n    participant Agent as AI Agent\n    participant ErrorDetector as Error Detector\n    participant HindsightLearner as Hindsight Learner\n    participant Analyzer as Pattern Analyzer\n    participant Memory as Memory System\n    participant KnowledgeRepo as Knowledge Repo\n    participant Recommender as Recommendation Engine\n\n    Agent->>Agent: Execute task\n    Agent->>Agent: \u274c Error occurred\n    \n    Agent->>ErrorDetector: report_error(error, context)\n    activate ErrorDetector\n    \n    ErrorDetector->>ErrorDetector: Extract error details\n    Note over ErrorDetector: Error: NullPointerException<br/>Context: user authentication flow<br/>Stack trace: [...]\n    \n    ErrorDetector->>HindsightLearner: analyze_error(error)\n    deactivate ErrorDetector\n    activate HindsightLearner\n    \n    HindsightLearner->>Analyzer: find_similar_errors(error)\n    activate Analyzer\n    \n    Analyzer->>Memory: search("NullPointerException authentication")\n    activate Memory\n    Memory--\x3e>Analyzer: similar_errors[3]\n    deactivate Memory\n    \n    loop For each similar error\n        Analyzer->>Analyzer: Compare stack traces\n        Analyzer->>Analyzer: Identify common patterns\n        \n        Note over Analyzer: Pattern identified:<br/>Missing null check after JWT decode<br/>Occurred 3 times in last month\n    end\n    \n    Analyzer--\x3e>HindsightLearner: patterns[1]\n    deactivate Analyzer\n    \n    HindsightLearner->>HindsightLearner: Generate resolution steps\n    Note over HindsightLearner: Resolution:<br/>1. Add null check after JWT decode<br/>2. Return 401 if decode fails<br/>3. Add test case for invalid JWT\n    \n    HindsightLearner->>Memory: store_error_pattern(pattern, resolution)\n    activate Memory\n    Memory->>Memory: Store in procedural layer\n    Memory->>Memory: Link to similar errors\n    Memory--\x3e>HindsightLearner: \u2713 Stored\n    deactivate Memory\n    \n    HindsightLearner->>Recommender: should_create_pattern?(frequency=3, impact=high)\n    activate Recommender\n    \n    alt Frequency > threshold\n        Recommender->>KnowledgeRepo: propose_pattern(error, resolution)\n        activate KnowledgeRepo\n        \n        KnowledgeRepo->>KnowledgeRepo: Create pattern document\n        Note over KnowledgeRepo: Pattern: JWT Null Handling<br/>When: Decoding JWT tokens<br/>Solution: Always null-check result<br/>Example: [code snippet]\n        \n        KnowledgeRepo->>KnowledgeRepo: Submit for approval\n        KnowledgeRepo--\x3e>Recommender: pattern_proposed\n        deactivate KnowledgeRepo\n    end\n    \n    Recommender--\x3e>HindsightLearner: \u2713 Pattern created\n    deactivate Recommender\n    \n    HindsightLearner--\x3e>Agent: LearningResult{resolution, pattern_id}\n    deactivate HindsightLearner\n    \n    Agent->>Agent: Apply resolution\n    Agent->>Agent: \u2713 Error fixed\n    \n    Agent->>Memory: reward(pattern_id, success=true)\n    activate Memory\n    Memory->>Memory: Increase confidence score\n    Memory->>Memory: Consider promotion to team layer\n    Memory--\x3e>Agent: \u2713 Learning reinforced\n    deactivate Memory'}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"multi-tenant-operations",children:"Multi-Tenant Operations"}),"\n",(0,r.jsx)(n.h3,{id:"71-tenant-isolation--rbac",children:"7.1 Tenant Isolation & RBAC"}),"\n",(0,r.jsx)(n.mermaid,{value:"sequenceDiagram\n    participant User as User (Alex)\n    participant API as Aeterna API\n    participant AuthService as Auth Service\n    participant TenantResolver as Tenant Resolver\n    participant CedarPDP as Cedar PDP\n    participant MemManager as Memory Manager\n    participant DataIsolation as Data Isolation Layer\n    participant Postgres as PostgreSQL\n\n    User->>API: GET /api/v1/memory/search (with JWT)\n    activate API\n    \n    API->>AuthService: validate_token(jwt)\n    activate AuthService\n    AuthService->>AuthService: Verify signature\n    AuthService->>AuthService: Check expiration\n    AuthService--\x3e>API: Principal{user_id, company_id, org_id, team_id, roles}\n    deactivate AuthService\n    \n    API->>TenantResolver: resolve_tenant_hierarchy(principal)\n    activate TenantResolver\n    \n    TenantResolver->>TenantResolver: Build tenant path\n    Note over TenantResolver: company: acme-corp<br/>org: engineering<br/>team: api-team<br/>user: alex@acme.com\n    \n    TenantResolver--\x3e>API: TenantContext{hierarchy, scopes}\n    deactivate TenantResolver\n    \n    API->>CedarPDP: authorize(principal, action=\"memory:read\", resource)\n    activate CedarPDP\n    \n    CedarPDP->>CedarPDP: Load applicable policies\n    Note over CedarPDP: Policy: team-member-read<br/>Condition: user in team.members\n    \n    CedarPDP->>CedarPDP: Evaluate policies\n    \n    CedarPDP--\x3e>API: Decision=ALLOW, constraints=[layers:team,user,session]\n    deactivate CedarPDP\n    \n    API->>MemManager: search(query, tenant_context, allowed_layers)\n    activate MemManager\n    \n    MemManager->>DataIsolation: apply_tenant_filter(tenant_context)\n    activate DataIsolation\n    \n    DataIsolation->>DataIsolation: Build WHERE clause\n    Note over DataIsolation: WHERE tenant_path LIKE 'acme-corp.engineering.api-team%'<br/>AND layer IN ('team', 'user', 'session')\n    \n    DataIsolation--\x3e>MemManager: filtered_query\n    deactivate DataIsolation\n    \n    MemManager->>Postgres: execute(filtered_query)\n    activate Postgres\n    \n    Postgres->>Postgres: Apply row-level security\n    Postgres->>Postgres: Execute with tenant filter\n    \n    Postgres--\x3e>MemManager: results[10]\n    deactivate Postgres\n    \n    MemManager->>MemManager: Verify no cross-tenant leakage\n    \n    loop For each result\n        MemManager->>MemManager: Check tenant_path matches\n        \n        alt Tenant mismatch\n            MemManager->>MemManager: \u26a0\ufe0f Security violation detected!\n            MemManager->>MemManager: Filter out result\n        end\n    end\n    \n    MemManager--\x3e>API: safe_results[9]\n    deactivate MemManager\n    \n    API--\x3e>User: 200 OK {results: [...]}\n    deactivate API"}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"error-handling--recovery",children:"Error Handling & Recovery"}),"\n",(0,r.jsx)(n.h3,{id:"81-graceful-degradation-flow",children:"8.1 Graceful Degradation Flow"}),"\n",(0,r.jsx)(n.mermaid,{value:"sequenceDiagram\n    participant Agent as AI Agent\n    participant API as Aeterna API\n    participant MemManager as Memory Manager\n    participant Qdrant as Qdrant (Primary)\n    participant Postgres as PostgreSQL (Fallback)\n    participant Redis as Redis (Cache)\n    participant CircuitBreaker as Circuit Breaker\n    participant Fallback as Fallback Logic\n    participant Metrics as Metrics\n\n    Agent->>API: POST /api/v1/memory/search\n    activate API\n    \n    API->>MemManager: search(query, layers=[semantic])\n    activate MemManager\n    \n    MemManager->>CircuitBreaker: check_state(qdrant)\n    activate CircuitBreaker\n    \n    alt Circuit CLOSED (healthy)\n        CircuitBreaker--\x3e>MemManager: \u2713 Proceed\n        deactivate CircuitBreaker\n        \n        MemManager->>Qdrant: search_vectors(query)\n        activate Qdrant\n        \n        alt Qdrant timeout\n            Qdrant--\x3e>MemManager: \u274c Timeout (5s)\n            deactivate Qdrant\n            \n            MemManager->>CircuitBreaker: record_failure(qdrant)\n            activate CircuitBreaker\n            CircuitBreaker->>CircuitBreaker: Increment failure count: 3/5\n            \n            alt Failure threshold reached\n                CircuitBreaker->>CircuitBreaker: Open circuit\n                Note over CircuitBreaker: Circuit OPEN<br/>Fast-fail for 30s\n            end\n            \n            CircuitBreaker--\x3e>MemManager: Circuit state updated\n            deactivate CircuitBreaker\n            \n            MemManager->>Metrics: increment(qdrant_failures)\n            \n            MemManager->>Fallback: execute_fallback(query)\n            activate Fallback\n            \n            Fallback->>Redis: try_cache_lookup(query)\n            activate Redis\n            \n            alt Cache hit\n                Redis--\x3e>Fallback: cached_results[5]\n                deactivate Redis\n                Fallback--\x3e>MemManager: results (from cache)\n            else Cache miss\n                Redis--\x3e>Fallback: Cache miss\n                deactivate Redis\n                \n                Fallback->>Postgres: search_with_pgvector(query)\n                activate Postgres\n                Postgres--\x3e>Fallback: results[8]\n                deactivate Postgres\n                \n                Fallback->>Fallback: Mark as degraded quality\n                Fallback--\x3e>MemManager: results (degraded)\n            end\n            deactivate Fallback\n            \n            MemManager->>MemManager: Add degradation warning\n            \n        else Qdrant success\n            Qdrant--\x3e>MemManager: results[10]\n            deactivate Qdrant\n            \n            MemManager->>CircuitBreaker: record_success(qdrant)\n            activate CircuitBreaker\n            CircuitBreaker->>CircuitBreaker: Reset failure count\n            CircuitBreaker--\x3e>MemManager: \u2713\n            deactivate CircuitBreaker\n        end\n        \n    else Circuit OPEN (unhealthy)\n        CircuitBreaker--\x3e>MemManager: \u274c Circuit open, fast-fail\n        deactivate CircuitBreaker\n        \n        Note over MemManager: Skip Qdrant, go directly to fallback\n        \n        MemManager->>Fallback: execute_fallback(query)\n        activate Fallback\n        Fallback->>Postgres: search_with_pgvector(query)\n        activate Postgres\n        Postgres--\x3e>Fallback: results[8]\n        deactivate Postgres\n        Fallback--\x3e>MemManager: results (degraded)\n        deactivate Fallback\n        \n    else Circuit HALF_OPEN (testing)\n        CircuitBreaker--\x3e>MemManager: \u26a0\ufe0f Test request\n        deactivate CircuitBreaker\n        \n        MemManager->>Qdrant: search_vectors(query) [test]\n        activate Qdrant\n        \n        alt Success\n            Qdrant--\x3e>MemManager: results[10]\n            deactivate Qdrant\n            \n            MemManager->>CircuitBreaker: record_success(qdrant)\n            activate CircuitBreaker\n            CircuitBreaker->>CircuitBreaker: Close circuit (recovered)\n            Note over CircuitBreaker: Circuit CLOSED<br/>Service recovered!\n            CircuitBreaker--\x3e>MemManager: \u2713 Circuit closed\n            deactivate CircuitBreaker\n            \n        else Failure\n            Qdrant--\x3e>MemManager: \u274c Still failing\n            deactivate Qdrant\n            \n            MemManager->>CircuitBreaker: record_failure(qdrant)\n            activate CircuitBreaker\n            CircuitBreaker->>CircuitBreaker: Re-open circuit\n            CircuitBreaker--\x3e>MemManager: Circuit re-opened\n            deactivate CircuitBreaker\n            \n            MemManager->>Fallback: execute_fallback(query)\n            activate Fallback\n            Fallback->>Postgres: search_with_pgvector(query)\n            activate Postgres\n            Postgres--\x3e>Fallback: results[8]\n            deactivate Postgres\n            Fallback--\x3e>MemManager: results (degraded)\n            deactivate Fallback\n        end\n    end\n    \n    MemManager--\x3e>API: SearchResults{results, quality_indicator}\n    deactivate MemManager\n    \n    API--\x3e>Agent: 200 OK (with degradation warning if applicable)\n    deactivate API\n    \n    Note over Agent: Agent receives results<br/>even when Qdrant is down<br/>(Graceful degradation!)"}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,r.jsxs)(n.p,{children:["This document provides ",(0,r.jsx)(n.strong,{children:"complete sequence diagrams"})," for all major Aeterna workflows:"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Memory Operations"})," - Add, search, promote with detailed timing"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Knowledge Repository"})," - Query, policy management, approval workflows"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sync Bridge"})," - Bidirectional synchronization with conflict resolution"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Governance"})," - Real-time validation, drift detection"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"A2A Communication"})," - Agent-to-agent protocol with skill routing"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"CCA Advanced"})," - Context compression, hindsight learning"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Multi-Tenant"})," - Isolation, RBAC, row-level security"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Error Handling"})," - Circuit breakers, fallback, graceful degradation"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"These diagrams demonstrate:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"System resilience"})," - Fallbacks and graceful degradation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Security"})," - Multi-layer authorization and tenant isolation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Performance"})," - Caching, parallel processing, token optimization"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Collaboration"})," - A2A protocol for multi-agent systems"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Learning"})," - Error pattern capture and memory promotion"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Each flow includes timing, error paths, and real-world scenarios."})]})}function p(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453(e,n,a){a.d(n,{R:()=>o,x:()=>c});var t=a(6540);const r={},i=t.createContext(r);function o(e){const n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);