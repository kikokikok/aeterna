<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <style>:root {
  --color: black;
  --bg: white;
  --head-bg: white;
  --link: #338;

  --blue: #ccf;
  --red: #fcc;
  --yellow: #ffc;
  --green: #cfc;
}

[data-theme='dark'] {
  --color: white;
  --bg: black;
  --head-bg: #333;
  --link: #aaf;

  --blue: #225;
  --red: #522;
  --yellow: #552;
  --green: #252;
}

html,
body {
  margin: 0;
  padding: 0;
  color: var(--color);
  background: var(--bg);
}

.app {
  margin: 10px;
  padding: 0;
}

.files-list {
  margin: 10px 0 0;
  width: 100%;
  border-collapse: collapse;
}
.files-list__head {
  border: 1px solid #999;
}
.files-list__head > tr > th {
  padding: 10px;
  border: 1px solid #999;
  text-align: left;
  font-weight: normal;
  background: var(--head-bg);
}
.files-list__body {
}
.files-list__file {
  cursor: pointer;
}
.files-list__file:hover {
  background: var(--blue);
}
.files-list__file > td {
  padding: 10px;
  border: 1px solid #999;
}
.files-list__file > td:first-child::before {
  content: '\01F4C4';
  margin-right: 1em;
}
.files-list__file_low {
  background: var(--red);
}
.files-list__file_medium {
  background: var(--yellow);
}
.files-list__file_high {
  background: var(--green);
}
.files-list__file_folder > td:first-child::before {
  content: '\01F4C1';
  margin-right: 1em;
}

.file-header {
  border: 1px solid #999;
  display: flex;
  justify-content: space-between;
  align-items: center;
  position: sticky;
  top: 0;
  background: var(--bg);
}

.file-header__back {
  margin: 10px;
  cursor: pointer;
  flex-shrink: 0;
  flex-grow: 0;
  text-decoration: underline;
  color: var(--link);
}

.file-header__name {
  margin: 10px;
  flex-shrink: 2;
  flex-grow: 2;
}

.file-header__stat {
  margin: 10px;
  flex-shrink: 0;
  flex-grow: 0;
}

.file-content {
  margin: 10px 0 0;
  border: 1px solid #999;
  padding: 10px;
  counter-reset: line;
  display: flex;
  flex-direction: column;
}

.code-line::before {
  content: counter(line);
  margin-right: 72px;
}
.code-line {
  margin: 0;
  height: 1em;
  counter-increment: line;

  position: absolute;
  padding: 0 0.3em 0.3em 0.3em;
  display: inherit;
  width: 100%;
}
.code-line_covered {
  background: var(--green);
}
.code-line_uncovered {
  background: var(--red);
}

.code-text-container {
  position: relative;
  height: 1em;
  padding: 0.3em 0;
}

.cover-indicator {
  display: flex;
  width: 100%;
  position: absolute;
  justify-content: end;
  height: 1em;
  align-items: center;
  padding: 0 0.3em 0.3em 0.3em;
}

.cover-indicator.check-cover::after {
  content: "\2713";
  font-weight: bold;
  background-color: var(--green);
  height: 1em;
}

.cover-indicator.no-cover::after {
  content: "\2716";
  font-weight: bold;
  background-color: var(--red);
  height: 1em;
}

.stat-line-hit {
  max-width: 48px;
  overflow: hidden;
  font-weight: bold;
  margin-right: 4px;
  background-color: var(--green);
  position: relative;
  top: 0.1em;
}

#theme-toggle-label {
  margin-left: 1ch;
}
</style>
</head>
<body>
    <div id="root"></div>
    <script>
        var data = {"files":[{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","auth","cedar.rs"],"content":"use async_trait::async_trait;\nuse cedar_policy::*;\nuse mk_core::traits::AuthorizationService;\nuse mk_core::types::{Role, TenantContext, UserId};\nuse std::str::FromStr;\nuse thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum CedarError {\n    #[error(\"Cedar evaluation error: {0}\")]\n    Evaluation(String),\n    #[error(\"Policy parsing error: {0}\")]\n    Parse(String),\n    #[error(\"Schema error: {0}\")]\n    Schema(String)\n}\n\npub struct CedarAuthorizer {\n    policies: PolicySet,\n    entities: Entities\n}\n\nimpl CedarAuthorizer {\n    pub fn new(policy_text: \u0026str, _schema_text: \u0026str) -\u003e Result\u003cSelf, CedarError\u003e {\n        let policies =\n            PolicySet::from_str(policy_text).map_err(|e| CedarError::Parse(e.to_string()))?;\n\n        Ok(Self {\n            policies,\n            entities: Entities::empty()\n        })\n    }\n}\n\n#[async_trait]\nimpl AuthorizationService for CedarAuthorizer {\n    type Error = CedarError;\n\n    async fn check_permission(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        action: \u0026str,\n        resource: \u0026str\n    ) -\u003e Result\u003cbool, Self::Error\u003e {\n        if let Some(agent_id) = \u0026ctx.agent_id {\n            let agent_principal = EntityUid::from_str(\u0026format!(\"User::\\\"{}\\\"\", agent_id))\n                .map_err(|e| CedarError::Evaluation(e.to_string()))?;\n            let delegate_action = EntityUid::from_str(\"Action::\\\"ActAs\\\"\")\n                .map_err(|e| CedarError::Evaluation(e.to_string()))?;\n            let user_resource = EntityUid::from_str(\u0026format!(\"User::\\\"{}\\\"\", ctx.user_id.as_str()))\n                .map_err(|e| CedarError::Evaluation(e.to_string()))?;\n\n            let delegation_request = Request::new(\n                agent_principal,\n                delegate_action,\n                user_resource,\n                Context::empty(),\n                None\n            )\n            .map_err(|e| CedarError::Evaluation(e.to_string()))?;\n\n            let authorizer = Authorizer::new();\n            let delegation_answer =\n                authorizer.is_authorized(\u0026delegation_request, \u0026self.policies, \u0026self.entities);\n\n            if delegation_answer.decision() != Decision::Allow {\n                return Ok(false);\n            }\n        }\n\n        let principal_str = format!(\"User::\\\"{}\\\"\", ctx.user_id.as_str());\n\n        let principal = EntityUid::from_str(\u0026principal_str)\n            .map_err(|e| CedarError::Evaluation(e.to_string()))?;\n        let action_uid = EntityUid::from_str(\u0026format!(\"Action::\\\"{}\\\"\", action))\n            .map_err(|e| CedarError::Evaluation(e.to_string()))?;\n        let resource_uid =\n            EntityUid::from_str(resource).map_err(|e| CedarError::Evaluation(e.to_string()))?;\n\n        let request = Request::new(principal, action_uid, resource_uid, Context::empty(), None)\n            .map_err(|e| CedarError::Evaluation(e.to_string()))?;\n\n        let authorizer = Authorizer::new();\n        let answer = authorizer.is_authorized(\u0026request, \u0026self.policies, \u0026self.entities);\n\n        Ok(answer.decision() == Decision::Allow)\n    }\n\n    async fn get_user_roles(\u0026self, _ctx: \u0026TenantContext) -\u003e Result\u003cVec\u003cRole\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n\n    async fn assign_role(\n        \u0026self,\n        _ctx: \u0026TenantContext,\n        _user_id: \u0026UserId,\n        _role: Role\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn remove_role(\n        \u0026self,\n        _ctx: \u0026TenantContext,\n        _user_id: \u0026UserId,\n        _role: Role\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::{TenantId, UserId};\n\n    #[tokio::test]\n    async fn test_cedar_authorization() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n        let schema = r#\"{\n            \"\": {\n                \"entityTypes\": {\n                    \"User\": {},\n                    \"Unit\": {}\n                },\n                \"actions\": {\n                    \"View\": {\n                        \"appliesTo\": {\n                            \"principalTypes\": [\"User\"],\n                            \"resourceTypes\": [\"Unit\"]\n                        }\n                    }\n                }\n            }\n        }\"#;\n\n        let policies = r#\"\n            permit(principal == User::\"u1\", action == Action::\"View\", resource == Unit::\"unit1\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, schema)?;\n\n        let ctx = TenantContext::new(\n            TenantId::new(\"t1\".into()).unwrap(),\n            UserId::new(\"u1\".into()).unwrap()\n        );\n\n        let allowed = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"unit1\\\"\")\n            .await?;\n        assert!(allowed);\n\n        let denied = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"unit2\\\"\")\n            .await?;\n        assert!(!denied);\n\n        Ok(())\n    }\n}\n","traces":[{"line":24,"address":[],"length":0,"stats":{"Line":38}},{"line":25,"address":[],"length":0,"stats":{"Line":36}},{"line":26,"address":[],"length":0,"stats":{"Line":120}},{"line":28,"address":[],"length":0,"stats":{"Line":36}},{"line":29,"address":[],"length":0,"stats":{"Line":36}},{"line":30,"address":[],"length":0,"stats":{"Line":36}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":2}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}}],"covered":7,"coverable":15},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","auth","mod.rs"],"content":"pub mod cedar;\npub mod permit;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","auth","permit.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::AuthorizationService;\nuse mk_core::types::{Role, TenantContext, UserId};\nuse serde::{Deserialize, Serialize};\nuse thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum PermitError {\n    #[error(\"Permit.io API error: {0}\")]\n    Api(String),\n    #[error(\"Authorization denied\")]\n    Denied,\n    #[error(\"Configuration error: {0}\")]\n    Config(String),\n    #[error(\"HTTP error: {0}\")]\n    Http(#[from] reqwest::Error)\n}\n\n#[derive(Debug, Serialize, Deserialize)]\nstruct PermitCheckRequest {\n    user: String,\n    action: String,\n    resource: String,\n    tenant: Option\u003cString\u003e\n}\n\n#[derive(Debug, Serialize, Deserialize)]\nstruct PermitCheckResponse {\n    allow: bool\n}\n\npub struct PermitAuthorizationService {\n    pdp_url: String,\n    api_key: String,\n    client: reqwest::Client\n}\n\nimpl PermitAuthorizationService {\n    pub fn new(api_key: \u0026str, pdp_url: \u0026str) -\u003e Self {\n        Self {\n            pdp_url: pdp_url.trim_end_matches('/').to_string(),\n            api_key: api_key.to_string(),\n            client: reqwest::Client::new()\n        }\n    }\n}\n\n#[async_trait]\nimpl AuthorizationService for PermitAuthorizationService {\n    type Error = PermitError;\n\n    async fn check_permission(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        action: \u0026str,\n        resource: \u0026str\n    ) -\u003e Result\u003cbool, Self::Error\u003e {\n        let user_id = if let Some(agent_id) = \u0026ctx.agent_id {\n            agent_id.as_str()\n        } else {\n            ctx.user_id.as_str()\n        };\n        let tenant_id = ctx.tenant_id.as_str();\n\n        let url = format!(\"{}/allowed\", self.pdp_url);\n        let request = PermitCheckRequest {\n            user: user_id.to_string(),\n            action: action.to_string(),\n            resource: resource.to_string(),\n            tenant: Some(tenant_id.to_string())\n        };\n\n        let response = self\n            .client\n            .post(\u0026url)\n            .header(\"Authorization\", format!(\"Bearer {}\", self.api_key))\n            .json(\u0026request)\n            .send()\n            .await?;\n\n        if !response.status().is_success() {\n            return Err(PermitError::Api(format!(\"Status: {}\", response.status())));\n        }\n\n        let result: PermitCheckResponse = response.json().await?;\n        Ok(result.allow)\n    }\n\n    async fn get_user_roles(\u0026self, ctx: \u0026TenantContext) -\u003e Result\u003cVec\u003cRole\u003e, Self::Error\u003e {\n        let user_id = ctx.user_id.as_str();\n        let tenant_id = ctx.tenant_id.as_str();\n\n        let url = format!(\n            \"{}/users/{}/roles?tenant={}\",\n            self.pdp_url, user_id, tenant_id\n        );\n        let response = self\n            .client\n            .get(\u0026url)\n            .header(\"Authorization\", format!(\"Bearer {}\", self.api_key))\n            .send()\n            .await?;\n\n        if !response.status().is_success() {\n            return Err(PermitError::Api(format!(\n                \"Failed to fetch roles: {}\",\n                response.status()\n            )));\n        }\n\n        let roles_str: Vec\u003cString\u003e = response.json().await?;\n        let mut roles = Vec::new();\n        for r in roles_str {\n            if let Ok(role) = r.parse::\u003cRole\u003e() {\n                roles.push(role);\n            }\n        }\n        Ok(roles)\n    }\n\n    async fn assign_role(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        user_id: \u0026UserId,\n        role: Role\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        let tenant_id = ctx.tenant_id.as_str();\n\n        let url = format!(\"{}/roles/assign\", self.pdp_url);\n        let request = serde_json::json!({\n            \"user\": user_id.as_str(),\n            \"role\": role.to_string().to_lowercase(),\n            \"tenant\": tenant_id\n        });\n\n        let response = self\n            .client\n            .post(\u0026url)\n            .header(\"Authorization\", format!(\"Bearer {}\", self.api_key))\n            .json(\u0026request)\n            .send()\n            .await?;\n\n        if !response.status().is_success() {\n            return Err(PermitError::Api(format!(\n                \"Role assignment failed: {}\",\n                response.status()\n            )));\n        }\n\n        Ok(())\n    }\n\n    async fn remove_role(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        user_id: \u0026UserId,\n        role: Role\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        let tenant_id = ctx.tenant_id.as_str();\n\n        let url = format!(\"{}/roles/unassign\", self.pdp_url);\n        let request = serde_json::json!({\n            \"user\": user_id.as_str(),\n            \"role\": role.to_string().to_lowercase(),\n            \"tenant\": tenant_id\n        });\n\n        let response = self\n            .client\n            .post(\u0026url)\n            .header(\"Authorization\", format!(\"Bearer {}\", self.api_key))\n            .json(\u0026request)\n            .send()\n            .await?;\n\n        if !response.status().is_success() {\n            return Err(PermitError::Api(format!(\n                \"Role removal failed: {}\",\n                response.status()\n            )));\n        }\n\n        Ok(())\n    }\n}\n","traces":[{"line":39,"address":[],"length":0,"stats":{"Line":3}},{"line":41,"address":[],"length":0,"stats":{"Line":9}},{"line":42,"address":[],"length":0,"stats":{"Line":6}},{"line":43,"address":[],"length":0,"stats":{"Line":3}},{"line":89,"address":[],"length":0,"stats":{"Line":0}}],"covered":4,"coverable":5},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","ecosystem.rs"],"content":"use async_trait::async_trait;\nuse serde_json::Value;\nuse std::sync::Arc;\nuse tools::server::JsonRpcRequest;\nuse tools::server::McpServer;\n\n#[async_trait]\npub trait EcosystemAdapter: Send + Sync {\n    fn name(\u0026self) -\u003e \u0026str;\n    async fn handle_mcp_request(\u0026self, request: Value) -\u003e anyhow::Result\u003cValue\u003e;\n}\n\npub struct OpenCodeAdapter {\n    server: Arc\u003cMcpServer\u003e\n}\n\nimpl OpenCodeAdapter {\n    pub fn new(server: Arc\u003cMcpServer\u003e) -\u003e Self {\n        Self { server }\n    }\n\n    pub fn get_memory_tools(\u0026self) -\u003e Vec\u003cValue\u003e {\n        self.server\n            .list_tools()\n            .into_iter()\n            .filter(|t| t.name.starts_with(\"memory_\"))\n            .map(|t| serde_json::to_value(t).unwrap())\n            .collect()\n    }\n\n    pub fn get_knowledge_tools(\u0026self) -\u003e Vec\u003cValue\u003e {\n        self.server\n            .list_tools()\n            .into_iter()\n            .filter(|t| t.name.starts_with(\"knowledge_\"))\n            .map(|t| serde_json::to_value(t).unwrap())\n            .collect()\n    }\n}\n\n#[async_trait]\nimpl EcosystemAdapter for OpenCodeAdapter {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"opencode\"\n    }\n\n    async fn handle_mcp_request(\u0026self, request: Value) -\u003e anyhow::Result\u003cValue\u003e {\n        let rpc_request: JsonRpcRequest = serde_json::from_value(request)?;\n        let response = self.server.handle_request(rpc_request).await;\n        Ok(serde_json::to_value(response)?)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_opencode_adapter_name() {\n        fn assert_ecosystem_adapter\u003cT: EcosystemAdapter\u003e() {}\n\n        assert_ecosystem_adapter::\u003cOpenCodeAdapter\u003e();\n    }\n\n    #[test]\n    fn test_ecosystem_adapter_trait_bounds() {\n        fn assert_send_sync\u003cT: Send + Sync\u003e() {}\n\n        assert_send_sync::\u003cOpenCodeAdapter\u003e();\n    }\n\n    #[test]\n    fn test_opencode_adapter_method_signatures() {\n        let _: fn(Arc\u003cMcpServer\u003e) -\u003e OpenCodeAdapter = OpenCodeAdapter::new;\n    }\n}\n","traces":[{"line":18,"address":[],"length":0,"stats":{"Line":1}},{"line":22,"address":[],"length":0,"stats":{"Line":1}},{"line":23,"address":[],"length":0,"stats":{"Line":1}},{"line":26,"address":[],"length":0,"stats":{"Line":31}},{"line":27,"address":[],"length":0,"stats":{"Line":13}},{"line":31,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}}],"covered":5,"coverable":12},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","hooks.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::ContextHooks;\n\npub struct MemoryContextHooks {}\n\nimpl MemoryContextHooks {\n    pub fn new() -\u003e Self {\n        Self {}\n    }\n}\n\n#[async_trait]\nimpl ContextHooks for MemoryContextHooks {\n    async fn on_session_start(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _session_id: \u0026str\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n\n    async fn on_session_end(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _session_id: \u0026str\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n\n    async fn on_message(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _session_id: \u0026str,\n        _message: \u0026str\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n\n    async fn on_tool_use(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _session_id: \u0026str,\n        _tool_name: \u0026str,\n        _params: serde_json::Value\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::TenantContext;\n    use serde_json::json;\n\n    #[test]\n    fn test_memory_context_hooks_new() {\n        let hooks = MemoryContextHooks::new();\n        let _ = hooks;\n    }\n\n    #[tokio::test]\n    async fn test_memory_context_hooks_methods() {\n        let hooks = MemoryContextHooks::new();\n        let ctx = TenantContext::default();\n\n        assert!(\n            hooks\n                .on_session_start(ctx.clone(), \"test-session\")\n                .await\n                .is_ok()\n        );\n        assert!(\n            hooks\n                .on_session_end(ctx.clone(), \"test-session\")\n                .await\n                .is_ok()\n        );\n        assert!(\n            hooks\n                .on_message(ctx.clone(), \"test-session\", \"test message\")\n                .await\n                .is_ok()\n        );\n        assert!(\n            hooks\n                .on_tool_use(ctx, \"test-session\", \"test_tool\", json!({}))\n                .await\n                .is_ok()\n        );\n    }\n\n    #[test]\n    fn test_context_hooks_trait_implementation() {\n        use mk_core::traits::ContextHooks;\n\n        fn assert_implements_context_hooks\u003cT: ContextHooks\u003e() {}\n\n        assert_implements_context_hooks::\u003cMemoryContextHooks\u003e();\n    }\n\n    #[test]\n    fn test_hooks_send_sync_bounds() {\n        fn assert_send_sync\u003cT: Send + Sync\u003e() {}\n\n        assert_send_sync::\u003cMemoryContextHooks\u003e();\n    }\n}\n","traces":[{"line":7,"address":[],"length":0,"stats":{"Line":2}}],"covered":1,"coverable":1},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","langchain.rs"],"content":"use crate::ecosystem::EcosystemAdapter;\nuse async_trait::async_trait;\nuse serde_json::{Value, json};\nuse std::sync::Arc;\nuse tools::server::McpServer;\n\npub struct LangChainAdapter {\n    server: Arc\u003cMcpServer\u003e,\n}\n\nimpl LangChainAdapter {\n    pub fn new(server: Arc\u003cMcpServer\u003e) -\u003e Self {\n        Self { server }\n    }\n\n    pub fn to_langchain_tools(\u0026self) -\u003e Vec\u003cValue\u003e {\n        self.server\n            .list_tools()\n            .into_iter()\n            .map(|tool| {\n                let mut schema = tool.input_schema.clone();\n                if let Some(obj) = schema.as_object_mut() {\n                    obj.insert(\n                        \"$schema\".to_string(),\n                        json!(\"http://json-schema.org/draft-07/schema#\"),\n                    );\n                    obj.insert(\"additionalProperties\".to_string(), json!(false));\n                }\n\n                json!({\n                    \"name\": tool.name,\n                    \"description\": tool.description,\n                    \"parameters\": schema,\n                })\n            })\n            .collect()\n    }\n}\n\n#[async_trait]\nimpl EcosystemAdapter for LangChainAdapter {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"langchain\"\n    }\n\n    async fn handle_mcp_request(\u0026self, request: Value) -\u003e anyhow::Result\u003cValue\u003e {\n        let name = request[\"name\"]\n            .as_str()\n            .ok_or_else(|| anyhow::anyhow!(\"Missing tool name\"))?;\n        let arguments = request[\"arguments\"].clone();\n        let tenant_context = request[\"tenantContext\"].clone();\n\n        let mcp_request = json!({\n            \"jsonrpc\": \"2.0\",\n            \"id\": 1,\n            \"method\": \"tools/call\",\n            \"params\": {\n                \"name\": name,\n                \"arguments\": arguments,\n                \"tenantContext\": tenant_context\n            }\n        });\n\n        let response = self\n            .server\n            .handle_request(serde_json::from_value(mcp_request)?)\n            .await;\n        Ok(serde_json::to_value(response)?)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use memory::manager::MemoryManager;\n    use sync::bridge::SyncManager;\n\n    async fn setup_server() -\u003e McpServer {\n        let memory_manager = Arc::new(MemoryManager::new());\n        let repo = Arc::new(MockRepo);\n        let governance = Arc::new(knowledge::governance::GovernanceEngine::new());\n        let auth_service = Arc::new(MockAuthService);\n        let deployment_config = config::config::DeploymentConfig::default();\n        let sync_manager = Arc::new(\n            SyncManager::new(\n                memory_manager.clone(),\n                repo.clone(),\n                governance.clone(),\n                deployment_config,\n                None,\n                Arc::new(MockPersister),\n            )\n            .await\n            .unwrap(),\n        );\n\n        McpServer::new(\n            memory_manager,\n            sync_manager,\n            repo,\n            Arc::new(MockStorageBackend),\n            governance,\n            auth_service,\n            None,\n        )\n    }\n\n    struct MockStorageBackend;\n    #[async_trait::async_trait]\n    impl mk_core::traits::StorageBackend for MockStorageBackend {\n        type Error = storage::postgres::PostgresError;\n        async fn store(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _key: \u0026str,\n            _value: \u0026[u8],\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n        async fn retrieve(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _key: \u0026str,\n        ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e {\n            Ok(None)\n        }\n        async fn delete(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _key: \u0026str,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n        async fn exists(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _key: \u0026str,\n        ) -\u003e Result\u003cbool, Self::Error\u003e {\n            Ok(false)\n        }\n        async fn get_ancestors(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _unit_id: \u0026str,\n        ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n        async fn get_descendants(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _unit_id: \u0026str,\n        ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n        async fn get_unit_policies(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _unit_id: \u0026str,\n        ) -\u003e Result\u003cVec\u003cmk_core::types::Policy\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n        async fn create_unit(\n            \u0026self,\n            _unit: \u0026mk_core::types::OrganizationalUnit,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n        async fn add_unit_policy(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n            _unit_id: \u0026str,\n            _policy: \u0026mk_core::types::Policy,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n        async fn assign_role(\n            \u0026self,\n            _user_id: \u0026mk_core::types::UserId,\n            _tenant_id: \u0026mk_core::types::TenantId,\n            _unit_id: \u0026str,\n            _role: mk_core::types::Role,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n        async fn remove_role(\n            \u0026self,\n            _user_id: \u0026mk_core::types::UserId,\n            _tenant_id: \u0026mk_core::types::TenantId,\n            _unit_id: \u0026str,\n            _role: mk_core::types::Role,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n        async fn store_drift_result(\n            \u0026self,\n            _result: mk_core::types::DriftResult,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n        async fn get_latest_drift_result(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _project_id: \u0026str,\n        ) -\u003e Result\u003cOption\u003cmk_core::types::DriftResult\u003e, Self::Error\u003e {\n            Ok(None)\n        }\n        async fn list_all_units(\n            \u0026self,\n        ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n        async fn record_job_status(\n            \u0026self,\n            _job_name: \u0026str,\n            _tenant_id: \u0026str,\n            _status: \u0026str,\n            _message: Option\u003c\u0026str\u003e,\n            _started_at: i64,\n            _finished_at: Option\u003ci64\u003e,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n        async fn get_governance_events(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _since_timestamp: i64,\n            _limit: usize,\n        ) -\u003e Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n    }\n\n    struct MockAuthService;\n\n    #[async_trait::async_trait]\n    impl mk_core::traits::AuthorizationService for MockAuthService {\n        type Error = anyhow::Error;\n        async fn check_permission(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n            _action: \u0026str,\n            _resource: \u0026str,\n        ) -\u003e anyhow::Result\u003cbool\u003e {\n            Ok(true)\n        }\n        async fn get_user_roles(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n        ) -\u003e anyhow::Result\u003cVec\u003cmk_core::types::Role\u003e\u003e {\n            Ok(vec![])\n        }\n        async fn assign_role(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n            _user_id: \u0026mk_core::types::UserId,\n            _role: mk_core::types::Role,\n        ) -\u003e anyhow::Result\u003c()\u003e {\n            Ok(())\n        }\n        async fn remove_role(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n            _user_id: \u0026mk_core::types::UserId,\n            _role: mk_core::types::Role,\n        ) -\u003e anyhow::Result\u003c()\u003e {\n            Ok(())\n        }\n    }\n\n    struct MockRepo;\n    #[async_trait::async_trait]\n    impl mk_core::traits::KnowledgeRepository for MockRepo {\n        type Error = knowledge::repository::RepositoryError;\n        async fn store(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: mk_core::types::KnowledgeEntry,\n            _: \u0026str,\n        ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n            Ok(\"hash\".into())\n        }\n        async fn get(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: mk_core::types::KnowledgeLayer,\n            _: \u0026str,\n        ) -\u003e std::result::Result\u003cOption\u003cmk_core::types::KnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(None)\n        }\n        async fn list(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: mk_core::types::KnowledgeLayer,\n            _: \u0026str,\n        ) -\u003e std::result::Result\u003cVec\u003cmk_core::types::KnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n        async fn delete(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: mk_core::types::KnowledgeLayer,\n            _: \u0026str,\n            _: \u0026str,\n        ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n            Ok(\"hash\".into())\n        }\n        async fn get_head_commit(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n        ) -\u003e std::result::Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n            Ok(None)\n        }\n        async fn get_affected_items(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: \u0026str,\n        ) -\u003e std::result::Result\u003cVec\u003c(mk_core::types::KnowledgeLayer, String)\u003e, Self::Error\u003e\n        {\n            Ok(vec![])\n        }\n        async fn search(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: \u0026str,\n            _: Vec\u003cmk_core::types::KnowledgeLayer\u003e,\n            _: usize,\n        ) -\u003e std::result::Result\u003cVec\u003cmk_core::types::KnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n        fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n            None\n        }\n    }\n\n    struct MockPersister;\n    #[async_trait::async_trait]\n    impl sync::state_persister::SyncStatePersister for MockPersister {\n        async fn load(\n            \u0026self,\n            _tenant_id: \u0026mk_core::types::TenantId,\n        ) -\u003e std::result::Result\u003csync::state::SyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e\n        {\n            Ok(sync::state::SyncState::default())\n        }\n        async fn save(\n            \u0026self,\n            _tenant_id: \u0026mk_core::types::TenantId,\n            _: \u0026sync::state::SyncState,\n        ) -\u003e std::result::Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n            Ok(())\n        }\n    }\n\n    #[tokio::test]\n    async fn test_langchain_adapter_name() {\n        let server = Arc::new(setup_server().await);\n        let adapter = LangChainAdapter::new(server);\n        assert_eq!(adapter.name(), \"langchain\");\n    }\n\n    #[tokio::test]\n    async fn test_langchain_handle_request_missing_name() {\n        let server = Arc::new(setup_server().await);\n        let adapter = LangChainAdapter::new(server);\n        let request = json!({\"arguments\": {}});\n        let result = adapter.handle_mcp_request(request).await;\n        assert!(result.is_err());\n        assert_eq!(result.unwrap_err().to_string(), \"Missing tool name\");\n    }\n\n    #[tokio::test]\n    async fn test_to_langchain_tools_empty() {\n        let server = Arc::new(setup_server().await);\n        let adapter = LangChainAdapter::new(server);\n        let tools = adapter.to_langchain_tools();\n        assert!(!tools.is_empty());\n    }\n}\n","traces":[{"line":12,"address":[],"length":0,"stats":{"Line":6}},{"line":16,"address":[],"length":0,"stats":{"Line":3}},{"line":17,"address":[],"length":0,"stats":{"Line":3}},{"line":20,"address":[],"length":0,"stats":{"Line":48}},{"line":21,"address":[],"length":0,"stats":{"Line":135}},{"line":22,"address":[],"length":0,"stats":{"Line":135}},{"line":23,"address":[],"length":0,"stats":{"Line":135}},{"line":24,"address":[],"length":0,"stats":{"Line":135}},{"line":25,"address":[],"length":0,"stats":{"Line":90}},{"line":27,"address":[],"length":0,"stats":{"Line":180}},{"line":30,"address":[],"length":0,"stats":{"Line":45}},{"line":31,"address":[],"length":0,"stats":{"Line":45}},{"line":32,"address":[],"length":0,"stats":{"Line":45}},{"line":33,"address":[],"length":0,"stats":{"Line":45}},{"line":42,"address":[],"length":0,"stats":{"Line":1}},{"line":43,"address":[],"length":0,"stats":{"Line":1}},{"line":46,"address":[],"length":0,"stats":{"Line":3}},{"line":49,"address":[],"length":0,"stats":{"Line":2}}],"covered":18,"coverable":18},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","lib.rs"],"content":"//! # Adapters\n//!\n//! Provider and ecosystem adapters.\n\npub mod auth;\npub mod ecosystem;\npub mod hooks;\npub mod langchain;\npub mod opencode;\npub mod providers;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","opencode.rs"],"content":"\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","providers.rs"],"content":"\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","tests","auth_integration.rs"],"content":"use adapters::auth::permit::PermitAuthorizationService;\nuse mk_core::traits::AuthorizationService;\nuse mk_core::types::{TenantContext, TenantId, UserId};\nuse serde_json::json;\nuse std::str::FromStr;\nuse wiremock::matchers::{header, method, path};\nuse wiremock::{Mock, MockServer, ResponseTemplate};\n\n#[tokio::test]\nasync fn test_permit_authorization_allow() {\n    let mock_server = MockServer::start().await;\n    let api_key = \"test_key\";\n    let service = PermitAuthorizationService::new(api_key, \u0026mock_server.uri());\n\n    let ctx = TenantContext {\n        tenant_id: TenantId::from_str(\"tenant-1\").unwrap(),\n        user_id: UserId::from_str(\"user-1\").unwrap(),\n        agent_id: None\n    };\n\n    Mock::given(method(\"POST\"))\n        .and(path(\"/allowed\"))\n        .and(header(\"Authorization\", \u0026format!(\"Bearer {}\", api_key)))\n        .respond_with(ResponseTemplate::new(200).set_body_json(json!({ \"allow\": true })))\n        .mount(\u0026mock_server)\n        .await;\n\n    let allowed = service\n        .check_permission(\u0026ctx, \"memory:read\", \"hierarchical\")\n        .await\n        .unwrap();\n    assert!(allowed);\n}\n\n#[tokio::test]\nasync fn test_permit_authorization_deny() {\n    let mock_server = MockServer::start().await;\n    let api_key = \"test_key\";\n    let service = PermitAuthorizationService::new(api_key, \u0026mock_server.uri());\n\n    let ctx = TenantContext {\n        tenant_id: TenantId::from_str(\"tenant-1\").unwrap(),\n        user_id: UserId::from_str(\"user-1\").unwrap(),\n        agent_id: None\n    };\n\n    Mock::given(method(\"POST\"))\n        .and(path(\"/allowed\"))\n        .respond_with(ResponseTemplate::new(200).set_body_json(json!({ \"allow\": false })))\n        .mount(\u0026mock_server)\n        .await;\n\n    let allowed = service\n        .check_permission(\u0026ctx, \"memory:read\", \"hierarchical\")\n        .await\n        .unwrap();\n    assert!(!allowed);\n}\n\n#[tokio::test]\nasync fn test_permit_api_error() {\n    let mock_server = MockServer::start().await;\n    let api_key = \"test_key\";\n    let service = PermitAuthorizationService::new(api_key, \u0026mock_server.uri());\n\n    let ctx = TenantContext {\n        tenant_id: TenantId::from_str(\"tenant-1\").unwrap(),\n        user_id: UserId::from_str(\"user-1\").unwrap(),\n        agent_id: None\n    };\n\n    Mock::given(method(\"POST\"))\n        .and(path(\"/allowed\"))\n        .respond_with(ResponseTemplate::new(500))\n        .mount(\u0026mock_server)\n        .await;\n\n    let result = service\n        .check_permission(\u0026ctx, \"memory:read\", \"hierarchical\")\n        .await;\n    assert!(result.is_err());\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","tests","cedar_integration.rs"],"content":"//! Cedar Authorization Integration Tests\n//!\n//! Comprehensive tests for Cedar policy evaluation including:\n//! - Multi-tenant authorization isolation\n//! - Agent delegation (ActAs) scenarios  \n//! - Role-based access control (RBAC)\n//! - Hierarchical unit inheritance\n//! - Policy evaluation edge cases\n//! - Error handling for invalid policies/requests\n\nuse adapters::auth::cedar::{CedarAuthorizer, CedarError};\nuse mk_core::traits::AuthorizationService;\nuse mk_core::types::{TenantContext, TenantId, UserId};\n\n// =============================================================================\n// Test Policies\n// =============================================================================\n\n/// Basic schema for Cedar tests\nconst TEST_SCHEMA: \u0026str = r#\"{\n    \"\": {\n        \"entityTypes\": {\n            \"User\": {},\n            \"Unit\": {},\n            \"Role\": {},\n            \"Memory\": {},\n            \"Knowledge\": {}\n        },\n        \"actions\": {\n            \"View\": {\n                \"appliesTo\": {\n                    \"principalTypes\": [\"User\"],\n                    \"resourceTypes\": [\"Unit\", \"Memory\", \"Knowledge\"]\n                }\n            },\n            \"Edit\": {\n                \"appliesTo\": {\n                    \"principalTypes\": [\"User\"],\n                    \"resourceTypes\": [\"Unit\", \"Memory\", \"Knowledge\"]\n                }\n            },\n            \"Delete\": {\n                \"appliesTo\": {\n                    \"principalTypes\": [\"User\"],\n                    \"resourceTypes\": [\"Unit\", \"Memory\", \"Knowledge\"]\n                }\n            },\n            \"Admin\": {\n                \"appliesTo\": {\n                    \"principalTypes\": [\"User\"],\n                    \"resourceTypes\": [\"Unit\"]\n                }\n            },\n            \"ActAs\": {\n                \"appliesTo\": {\n                    \"principalTypes\": [\"User\"],\n                    \"resourceTypes\": [\"User\"]\n                }\n            }\n        }\n    }\n}\"#;\n\n// =============================================================================\n// Helper Functions\n// =============================================================================\n\nfn create_tenant_context(tenant: \u0026str, user: \u0026str) -\u003e TenantContext {\n    TenantContext::new(\n        TenantId::new(tenant.into()).unwrap(),\n        UserId::new(user.into()).unwrap(),\n    )\n}\n\nfn create_agent_context(tenant: \u0026str, user: \u0026str, agent: \u0026str) -\u003e TenantContext {\n    let mut ctx = TenantContext::new(\n        TenantId::new(tenant.into()).unwrap(),\n        UserId::new(user.into()).unwrap(),\n    );\n    ctx.agent_id = Some(agent.to_string());\n    ctx\n}\n\n// =============================================================================\n// Multi-Tenant Isolation Tests\n// =============================================================================\n\nmod multi_tenant_isolation {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_user_can_access_own_tenant_resources() {\n        let policies = r#\"\n            permit(principal == User::\"tenant1-user1\", action == Action::\"View\", resource == Unit::\"tenant1-unit1\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"tenant1-user1\");\n\n        let allowed = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"tenant1-unit1\\\"\")\n            .await\n            .unwrap();\n        assert!(allowed, \"User should access resources in own tenant\");\n    }\n\n    #[tokio::test]\n    async fn test_user_cannot_access_other_tenant_resources() {\n        let policies = r#\"\n            permit(principal == User::\"tenant1-user1\", action == Action::\"View\", resource == Unit::\"tenant1-unit1\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"tenant1-user1\");\n\n        // Try to access tenant2's resource\n        let denied = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"tenant2-unit1\\\"\")\n            .await\n            .unwrap();\n        assert!(!denied, \"User should NOT access resources in other tenant\");\n    }\n\n    #[tokio::test]\n    async fn test_multiple_tenants_isolated() {\n        let policies = r#\"\n            permit(principal == User::\"alice\", action == Action::\"View\", resource == Unit::\"acme-data\");\n            permit(principal == User::\"bob\", action == Action::\"View\", resource == Unit::\"globex-data\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n\n        // Alice can access ACME data\n        let alice_ctx = create_tenant_context(\"acme\", \"alice\");\n        let alice_acme = authorizer\n            .check_permission(\u0026alice_ctx, \"View\", \"Unit::\\\"acme-data\\\"\")\n            .await\n            .unwrap();\n        assert!(alice_acme, \"Alice should access ACME data\");\n\n        // Alice cannot access Globex data\n        let alice_globex = authorizer\n            .check_permission(\u0026alice_ctx, \"View\", \"Unit::\\\"globex-data\\\"\")\n            .await\n            .unwrap();\n        assert!(!alice_globex, \"Alice should NOT access Globex data\");\n\n        // Bob can access Globex data\n        let bob_ctx = create_tenant_context(\"globex\", \"bob\");\n        let bob_globex = authorizer\n            .check_permission(\u0026bob_ctx, \"View\", \"Unit::\\\"globex-data\\\"\")\n            .await\n            .unwrap();\n        assert!(bob_globex, \"Bob should access Globex data\");\n\n        // Bob cannot access ACME data\n        let bob_acme = authorizer\n            .check_permission(\u0026bob_ctx, \"View\", \"Unit::\\\"acme-data\\\"\")\n            .await\n            .unwrap();\n        assert!(!bob_acme, \"Bob should NOT access ACME data\");\n    }\n\n    #[tokio::test]\n    async fn test_tenant_admin_scoped_to_tenant() {\n        let policies = r#\"\n            permit(principal == User::\"tenant1-admin\", action == Action::\"Admin\", resource == Unit::\"tenant1-unit1\");\n            permit(principal == User::\"tenant1-admin\", action == Action::\"Admin\", resource == Unit::\"tenant1-unit2\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"tenant1-admin\");\n\n        // Admin can manage tenant1 units\n        let can_admin_unit1 = authorizer\n            .check_permission(\u0026ctx, \"Admin\", \"Unit::\\\"tenant1-unit1\\\"\")\n            .await\n            .unwrap();\n        assert!(can_admin_unit1);\n\n        let can_admin_unit2 = authorizer\n            .check_permission(\u0026ctx, \"Admin\", \"Unit::\\\"tenant1-unit2\\\"\")\n            .await\n            .unwrap();\n        assert!(can_admin_unit2);\n\n        // Admin cannot manage tenant2 units\n        let cannot_admin_other = authorizer\n            .check_permission(\u0026ctx, \"Admin\", \"Unit::\\\"tenant2-unit1\\\"\")\n            .await\n            .unwrap();\n        assert!(!cannot_admin_other);\n    }\n}\n\n// =============================================================================\n// Agent Delegation (ActAs) Tests\n// =============================================================================\n\nmod agent_delegation {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_agent_with_valid_delegation_can_act() {\n        let policies = r#\"\n            permit(principal == User::\"agent-123\", action == Action::\"ActAs\", resource == User::\"user1\");\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data1\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_agent_context(\"tenant1\", \"user1\", \"agent-123\");\n\n        let allowed = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data1\\\"\")\n            .await\n            .unwrap();\n        assert!(\n            allowed,\n            \"Agent with delegation should act on behalf of user\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_agent_without_delegation_denied() {\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data1\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_agent_context(\"tenant1\", \"user1\", \"unauthorized-agent\");\n\n        let denied = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data1\\\"\")\n            .await\n            .unwrap();\n        assert!(!denied, \"Agent without ActAs delegation should be denied\");\n    }\n\n    #[tokio::test]\n    async fn test_agent_delegation_to_wrong_user_denied() {\n        let policies = r#\"\n            permit(principal == User::\"agent-123\", action == Action::\"ActAs\", resource == User::\"user2\");\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data1\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        // Agent has delegation to user2, but trying to act as user1\n        let ctx = create_agent_context(\"tenant1\", \"user1\", \"agent-123\");\n\n        let denied = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data1\\\"\")\n            .await\n            .unwrap();\n        assert!(\n            !denied,\n            \"Agent delegated to different user should be denied\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_multiple_agents_different_delegations() {\n        let policies = r#\"\n            permit(principal == User::\"agent-a\", action == Action::\"ActAs\", resource == User::\"alice\");\n            permit(principal == User::\"agent-b\", action == Action::\"ActAs\", resource == User::\"bob\");\n            permit(principal == User::\"alice\", action == Action::\"View\", resource == Unit::\"alice-data\");\n            permit(principal == User::\"bob\", action == Action::\"View\", resource == Unit::\"bob-data\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n\n        // Agent-A acting as Alice can access Alice's data\n        let ctx_a = create_agent_context(\"tenant1\", \"alice\", \"agent-a\");\n        let allowed_a = authorizer\n            .check_permission(\u0026ctx_a, \"View\", \"Unit::\\\"alice-data\\\"\")\n            .await\n            .unwrap();\n        assert!(allowed_a, \"Agent-A should access Alice's data\");\n\n        // Agent-A acting as Alice cannot access Bob's data\n        let denied_a = authorizer\n            .check_permission(\u0026ctx_a, \"View\", \"Unit::\\\"bob-data\\\"\")\n            .await\n            .unwrap();\n        assert!(!denied_a, \"Agent-A should NOT access Bob's data via Alice\");\n\n        // Agent-B acting as Bob can access Bob's data\n        let ctx_b = create_agent_context(\"tenant1\", \"bob\", \"agent-b\");\n        let allowed_b = authorizer\n            .check_permission(\u0026ctx_b, \"View\", \"Unit::\\\"bob-data\\\"\")\n            .await\n            .unwrap();\n        assert!(allowed_b, \"Agent-B should access Bob's data\");\n    }\n\n    #[tokio::test]\n    async fn test_direct_user_request_without_agent() {\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data1\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        // No agent_id - direct user request\n        let ctx = create_tenant_context(\"tenant1\", \"user1\");\n\n        let allowed = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data1\\\"\")\n            .await\n            .unwrap();\n        assert!(\n            allowed,\n            \"Direct user request should work without agent check\"\n        );\n    }\n}\n\n// =============================================================================\n// Role-Based Access Control Tests\n// =============================================================================\n\nmod rbac {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_viewer_can_only_view() {\n        let policies = r#\"\n            permit(principal == User::\"viewer\", action == Action::\"View\", resource == Unit::\"data\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"viewer\");\n\n        let can_view = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data\\\"\")\n            .await\n            .unwrap();\n        assert!(can_view, \"Viewer should be able to view\");\n\n        let cannot_edit = authorizer\n            .check_permission(\u0026ctx, \"Edit\", \"Unit::\\\"data\\\"\")\n            .await\n            .unwrap();\n        assert!(!cannot_edit, \"Viewer should NOT be able to edit\");\n\n        let cannot_delete = authorizer\n            .check_permission(\u0026ctx, \"Delete\", \"Unit::\\\"data\\\"\")\n            .await\n            .unwrap();\n        assert!(!cannot_delete, \"Viewer should NOT be able to delete\");\n    }\n\n    #[tokio::test]\n    async fn test_editor_can_view_and_edit() {\n        let policies = r#\"\n            permit(principal == User::\"editor\", action == Action::\"View\", resource == Unit::\"data\");\n            permit(principal == User::\"editor\", action == Action::\"Edit\", resource == Unit::\"data\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"editor\");\n\n        let can_view = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data\\\"\")\n            .await\n            .unwrap();\n        assert!(can_view, \"Editor should be able to view\");\n\n        let can_edit = authorizer\n            .check_permission(\u0026ctx, \"Edit\", \"Unit::\\\"data\\\"\")\n            .await\n            .unwrap();\n        assert!(can_edit, \"Editor should be able to edit\");\n\n        let cannot_delete = authorizer\n            .check_permission(\u0026ctx, \"Delete\", \"Unit::\\\"data\\\"\")\n            .await\n            .unwrap();\n        assert!(!cannot_delete, \"Editor should NOT be able to delete\");\n    }\n\n    #[tokio::test]\n    async fn test_admin_can_do_everything() {\n        let policies = r#\"\n            permit(principal == User::\"admin\", action == Action::\"View\", resource == Unit::\"data\");\n            permit(principal == User::\"admin\", action == Action::\"Edit\", resource == Unit::\"data\");\n            permit(principal == User::\"admin\", action == Action::\"Delete\", resource == Unit::\"data\");\n            permit(principal == User::\"admin\", action == Action::\"Admin\", resource == Unit::\"data\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"admin\");\n\n        for action in \u0026[\"View\", \"Edit\", \"Delete\", \"Admin\"] {\n            let allowed = authorizer\n                .check_permission(\u0026ctx, action, \"Unit::\\\"data\\\"\")\n                .await\n                .unwrap();\n            assert!(allowed, \"Admin should be able to {}\", action);\n        }\n    }\n\n    #[tokio::test]\n    async fn test_role_based_memory_access() {\n        let policies = r#\"\n            permit(principal == User::\"memory-reader\", action == Action::\"View\", resource == Memory::\"personal\");\n            permit(principal == User::\"memory-writer\", action == Action::\"View\", resource == Memory::\"personal\");\n            permit(principal == User::\"memory-writer\", action == Action::\"Edit\", resource == Memory::\"personal\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n\n        // Reader can only view\n        let reader_ctx = create_tenant_context(\"tenant1\", \"memory-reader\");\n        let reader_view = authorizer\n            .check_permission(\u0026reader_ctx, \"View\", \"Memory::\\\"personal\\\"\")\n            .await\n            .unwrap();\n        assert!(reader_view);\n\n        let reader_edit = authorizer\n            .check_permission(\u0026reader_ctx, \"Edit\", \"Memory::\\\"personal\\\"\")\n            .await\n            .unwrap();\n        assert!(!reader_edit);\n\n        // Writer can view and edit\n        let writer_ctx = create_tenant_context(\"tenant1\", \"memory-writer\");\n        let writer_view = authorizer\n            .check_permission(\u0026writer_ctx, \"View\", \"Memory::\\\"personal\\\"\")\n            .await\n            .unwrap();\n        assert!(writer_view);\n\n        let writer_edit = authorizer\n            .check_permission(\u0026writer_ctx, \"Edit\", \"Memory::\\\"personal\\\"\")\n            .await\n            .unwrap();\n        assert!(writer_edit);\n    }\n\n    #[tokio::test]\n    async fn test_knowledge_repository_roles() {\n        let policies = r#\"\n            permit(principal == User::\"knowledge-viewer\", action == Action::\"View\", resource == Knowledge::\"adr-001\");\n            permit(principal == User::\"knowledge-editor\", action == Action::\"View\", resource == Knowledge::\"adr-001\");\n            permit(principal == User::\"knowledge-editor\", action == Action::\"Edit\", resource == Knowledge::\"adr-001\");\n            permit(principal == User::\"knowledge-admin\", action == Action::\"View\", resource == Knowledge::\"adr-001\");\n            permit(principal == User::\"knowledge-admin\", action == Action::\"Edit\", resource == Knowledge::\"adr-001\");\n            permit(principal == User::\"knowledge-admin\", action == Action::\"Delete\", resource == Knowledge::\"adr-001\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n\n        // Viewer\n        let viewer_ctx = create_tenant_context(\"tenant1\", \"knowledge-viewer\");\n        assert!(\n            authorizer\n                .check_permission(\u0026viewer_ctx, \"View\", \"Knowledge::\\\"adr-001\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            !authorizer\n                .check_permission(\u0026viewer_ctx, \"Edit\", \"Knowledge::\\\"adr-001\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            !authorizer\n                .check_permission(\u0026viewer_ctx, \"Delete\", \"Knowledge::\\\"adr-001\\\"\")\n                .await\n                .unwrap()\n        );\n\n        // Editor\n        let editor_ctx = create_tenant_context(\"tenant1\", \"knowledge-editor\");\n        assert!(\n            authorizer\n                .check_permission(\u0026editor_ctx, \"View\", \"Knowledge::\\\"adr-001\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            authorizer\n                .check_permission(\u0026editor_ctx, \"Edit\", \"Knowledge::\\\"adr-001\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            !authorizer\n                .check_permission(\u0026editor_ctx, \"Delete\", \"Knowledge::\\\"adr-001\\\"\")\n                .await\n                .unwrap()\n        );\n\n        // Admin\n        let admin_ctx = create_tenant_context(\"tenant1\", \"knowledge-admin\");\n        assert!(\n            authorizer\n                .check_permission(\u0026admin_ctx, \"View\", \"Knowledge::\\\"adr-001\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            authorizer\n                .check_permission(\u0026admin_ctx, \"Edit\", \"Knowledge::\\\"adr-001\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            authorizer\n                .check_permission(\u0026admin_ctx, \"Delete\", \"Knowledge::\\\"adr-001\\\"\")\n                .await\n                .unwrap()\n        );\n    }\n}\n\n// =============================================================================\n// Hierarchical Unit Permission Tests\n// =============================================================================\n\nmod hierarchical_permissions {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_parent_unit_access_does_not_grant_child_access() {\n        // In this basic policy model, parent access doesn't automatically grant child access\n        let policies = r#\"\n            permit(principal == User::\"manager\", action == Action::\"View\", resource == Unit::\"org\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"manager\");\n\n        let can_view_org = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"org\\\"\")\n            .await\n            .unwrap();\n        assert!(can_view_org, \"Manager can view org unit\");\n\n        // Child unit not explicitly granted\n        let cannot_view_team = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"org-team1\\\"\")\n            .await\n            .unwrap();\n        assert!(\n            !cannot_view_team,\n            \"Without explicit policy, child access not granted\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_explicit_hierarchical_policy() {\n        let policies = r#\"\n            permit(principal == User::\"org-admin\", action == Action::\"View\", resource == Unit::\"org\");\n            permit(principal == User::\"org-admin\", action == Action::\"View\", resource == Unit::\"org-team1\");\n            permit(principal == User::\"org-admin\", action == Action::\"View\", resource == Unit::\"org-team2\");\n            permit(principal == User::\"team1-member\", action == Action::\"View\", resource == Unit::\"org-team1\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n\n        // Org admin can view all levels\n        let admin_ctx = create_tenant_context(\"tenant1\", \"org-admin\");\n        assert!(\n            authorizer\n                .check_permission(\u0026admin_ctx, \"View\", \"Unit::\\\"org\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            authorizer\n                .check_permission(\u0026admin_ctx, \"View\", \"Unit::\\\"org-team1\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            authorizer\n                .check_permission(\u0026admin_ctx, \"View\", \"Unit::\\\"org-team2\\\"\")\n                .await\n                .unwrap()\n        );\n\n        // Team member can only view their team\n        let member_ctx = create_tenant_context(\"tenant1\", \"team1-member\");\n        assert!(!member_ctx.agent_id.is_some()); // Sanity check - no agent\n        assert!(\n            !authorizer\n                .check_permission(\u0026member_ctx, \"View\", \"Unit::\\\"org\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            authorizer\n                .check_permission(\u0026member_ctx, \"View\", \"Unit::\\\"org-team1\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            !authorizer\n                .check_permission(\u0026member_ctx, \"View\", \"Unit::\\\"org-team2\\\"\")\n                .await\n                .unwrap()\n        );\n    }\n\n    #[tokio::test]\n    async fn test_memory_layer_hierarchy() {\n        // Memory layers: agent \u003c user \u003c session \u003c project \u003c team \u003c org \u003c company\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Memory::\"user-layer\");\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Memory::\"session-layer\");\n            permit(principal == User::\"team-member\", action == Action::\"View\", resource == Memory::\"team-layer\");\n            permit(principal == User::\"org-member\", action == Action::\"View\", resource == Memory::\"org-layer\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n\n        let user_ctx = create_tenant_context(\"tenant1\", \"user1\");\n        assert!(\n            authorizer\n                .check_permission(\u0026user_ctx, \"View\", \"Memory::\\\"user-layer\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            authorizer\n                .check_permission(\u0026user_ctx, \"View\", \"Memory::\\\"session-layer\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            !authorizer\n                .check_permission(\u0026user_ctx, \"View\", \"Memory::\\\"team-layer\\\"\")\n                .await\n                .unwrap()\n        );\n    }\n}\n\n// =============================================================================\n// Policy Evaluation Edge Cases\n// =============================================================================\n\nmod edge_cases {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_empty_policy_denies_all() {\n        let policies = \"\";\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"user1\");\n\n        let denied = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"anything\\\"\")\n            .await\n            .unwrap();\n        assert!(!denied, \"Empty policy should deny all requests\");\n    }\n\n    #[tokio::test]\n    async fn test_forbid_overrides_permit() {\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data\");\n            forbid(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"user1\");\n\n        let denied = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data\\\"\")\n            .await\n            .unwrap();\n        assert!(!denied, \"Forbid should override permit\");\n    }\n\n    #[tokio::test]\n    async fn test_specific_forbid_with_general_permit() {\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource);\n            forbid(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"secret\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"user1\");\n\n        // General permit works\n        let allowed = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"public\\\"\")\n            .await\n            .unwrap();\n        assert!(allowed, \"General permit should allow\");\n\n        // Specific forbid blocks\n        let denied = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"secret\\\"\")\n            .await\n            .unwrap();\n        assert!(!denied, \"Specific forbid should block\");\n    }\n\n    #[tokio::test]\n    async fn test_action_not_in_policy() {\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"user1\");\n\n        let denied = authorizer\n            .check_permission(\u0026ctx, \"NonExistentAction\", \"Unit::\\\"data\\\"\")\n            .await\n            .unwrap();\n        assert!(!denied, \"Unknown action should be denied\");\n    }\n\n    #[tokio::test]\n    async fn test_special_characters_in_ids() {\n        let policies = r#\"\n            permit(principal == User::\"user@example.com\", action == Action::\"View\", resource == Unit::\"data-with-dash\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"user@example.com\");\n\n        let allowed = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data-with-dash\\\"\")\n            .await\n            .unwrap();\n        assert!(allowed, \"Should handle special characters in IDs\");\n    }\n\n    #[tokio::test]\n    async fn test_uuid_style_ids() {\n        let policies = r#\"\n            permit(principal == User::\"550e8400-e29b-41d4-a716-446655440000\", action == Action::\"View\", resource == Unit::\"a3bb189e-8bf9-3888-9912-ace4e6543002\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"550e8400-e29b-41d4-a716-446655440000\");\n\n        let allowed = authorizer\n            .check_permission(\n                \u0026ctx,\n                \"View\",\n                \"Unit::\\\"a3bb189e-8bf9-3888-9912-ace4e6543002\\\"\",\n            )\n            .await\n            .unwrap();\n        assert!(allowed, \"Should handle UUID-style IDs\");\n    }\n\n    #[tokio::test]\n    async fn test_when_clause_always_false() {\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data\")\n            when { false };\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"user1\");\n\n        let denied = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data\\\"\")\n            .await\n            .unwrap();\n        assert!(!denied, \"when {{ false }} should always deny\");\n    }\n\n    #[tokio::test]\n    async fn test_unless_clause_always_true() {\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data\")\n            unless { true };\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"user1\");\n\n        let denied = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data\\\"\")\n            .await\n            .unwrap();\n        assert!(!denied, \"unless {{ true }} should always deny\");\n    }\n}\n\n// =============================================================================\n// Error Handling Tests\n// =============================================================================\n\nmod error_handling {\n    use super::*;\n\n    #[test]\n    fn test_invalid_policy_syntax() {\n        let invalid_policies = \"this is not valid cedar policy syntax!!!\";\n        let result = CedarAuthorizer::new(invalid_policies, TEST_SCHEMA);\n        assert!(result.is_err(), \"Invalid policy should return error\");\n\n        if let Err(CedarError::Parse(msg)) = result {\n            assert!(!msg.is_empty(), \"Error message should not be empty\");\n        } else {\n            panic!(\"Expected Parse error\");\n        }\n    }\n\n    #[test]\n    fn test_empty_schema_accepted() {\n        let policies = r#\"\n            permit(principal, action, resource);\n        \"#;\n        // Empty schema string should still work (schema validation is not strict in current impl)\n        let result = CedarAuthorizer::new(policies, \"\");\n        assert!(result.is_ok(), \"Empty schema should be accepted\");\n    }\n\n    #[tokio::test]\n    async fn test_malformed_resource_uid() {\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"user1\");\n\n        // Malformed resource string (missing quotes, wrong format)\n        let result = authorizer\n            .check_permission(\u0026ctx, \"View\", \"not-a-valid-resource-uid\")\n            .await;\n\n        assert!(\n            result.is_err(),\n            \"Malformed resource UID should return error\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_malformed_action_returns_deny() {\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"user1\");\n\n        // Action that doesn't match format (but still parseable)\n        let result = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data\\\"\")\n            .await;\n\n        assert!(result.is_ok(), \"Valid format should not error\");\n    }\n\n    #[test]\n    fn test_policy_with_syntax_error_in_condition() {\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource)\n            when { undefined_variable };\n        \"#;\n\n        let result = CedarAuthorizer::new(policies, TEST_SCHEMA);\n        // This should either fail at parse time or evaluation time\n        // Current implementation parses policies at construction\n        assert!(\n            result.is_err(),\n            \"Policy with undefined variable should fail\"\n        );\n    }\n\n    #[test]\n    fn test_duplicate_policy_ids_handled() {\n        // Multiple policies - Cedar handles this by evaluating all\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data\");\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data\");\n        \"#;\n\n        let result = CedarAuthorizer::new(policies, TEST_SCHEMA);\n        assert!(result.is_ok(), \"Duplicate policies should be accepted\");\n    }\n}\n\n// =============================================================================\n// Combined Authorization Scenarios\n// =============================================================================\n\nmod combined_scenarios {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_agent_delegation_with_rbac() {\n        let policies = r#\"\n            permit(principal == User::\"agent-1\", action == Action::\"ActAs\", resource == User::\"viewer\");\n            permit(principal == User::\"agent-2\", action == Action::\"ActAs\", resource == User::\"editor\");\n            permit(principal == User::\"viewer\", action == Action::\"View\", resource == Knowledge::\"doc1\");\n            permit(principal == User::\"editor\", action == Action::\"View\", resource == Knowledge::\"doc1\");\n            permit(principal == User::\"editor\", action == Action::\"Edit\", resource == Knowledge::\"doc1\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n\n        // Agent-1 acting as viewer can only view\n        let viewer_agent_ctx = create_agent_context(\"tenant1\", \"viewer\", \"agent-1\");\n        assert!(\n            authorizer\n                .check_permission(\u0026viewer_agent_ctx, \"View\", \"Knowledge::\\\"doc1\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            !authorizer\n                .check_permission(\u0026viewer_agent_ctx, \"Edit\", \"Knowledge::\\\"doc1\\\"\")\n                .await\n                .unwrap()\n        );\n\n        // Agent-2 acting as editor can view and edit\n        let editor_agent_ctx = create_agent_context(\"tenant1\", \"editor\", \"agent-2\");\n        assert!(\n            authorizer\n                .check_permission(\u0026editor_agent_ctx, \"View\", \"Knowledge::\\\"doc1\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            authorizer\n                .check_permission(\u0026editor_agent_ctx, \"Edit\", \"Knowledge::\\\"doc1\\\"\")\n                .await\n                .unwrap()\n        );\n    }\n\n    #[tokio::test]\n    async fn test_multi_tenant_with_agent_delegation() {\n        let policies = r#\"\n            permit(principal == User::\"agent-acme\", action == Action::\"ActAs\", resource == User::\"acme-user\");\n            permit(principal == User::\"agent-globex\", action == Action::\"ActAs\", resource == User::\"globex-user\");\n            permit(principal == User::\"acme-user\", action == Action::\"View\", resource == Unit::\"acme-data\");\n            permit(principal == User::\"globex-user\", action == Action::\"View\", resource == Unit::\"globex-data\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n\n        // ACME agent can only access ACME data\n        let acme_ctx = create_agent_context(\"acme\", \"acme-user\", \"agent-acme\");\n        assert!(\n            authorizer\n                .check_permission(\u0026acme_ctx, \"View\", \"Unit::\\\"acme-data\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            !authorizer\n                .check_permission(\u0026acme_ctx, \"View\", \"Unit::\\\"globex-data\\\"\")\n                .await\n                .unwrap()\n        );\n\n        // Globex agent can only access Globex data\n        let globex_ctx = create_agent_context(\"globex\", \"globex-user\", \"agent-globex\");\n        assert!(\n            authorizer\n                .check_permission(\u0026globex_ctx, \"View\", \"Unit::\\\"globex-data\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            !authorizer\n                .check_permission(\u0026globex_ctx, \"View\", \"Unit::\\\"acme-data\\\"\")\n                .await\n                .unwrap()\n        );\n\n        // Cross-tenant agent delegation doesn't work\n        let cross_ctx = create_agent_context(\"acme\", \"globex-user\", \"agent-acme\");\n        assert!(\n            !authorizer\n                .check_permission(\u0026cross_ctx, \"View\", \"Unit::\\\"globex-data\\\"\")\n                .await\n                .unwrap()\n        );\n    }\n\n    #[tokio::test]\n    async fn test_complete_governance_scenario() {\n        let policies = r#\"\n            // Company-level admin\n            permit(principal == User::\"company-admin\", action == Action::\"Admin\", resource == Unit::\"company\");\n            permit(principal == User::\"company-admin\", action == Action::\"View\", resource == Knowledge::\"company-policy\");\n            permit(principal == User::\"company-admin\", action == Action::\"Edit\", resource == Knowledge::\"company-policy\");\n            \n            // Org-level editor\n            permit(principal == User::\"org-editor\", action == Action::\"View\", resource == Knowledge::\"org-pattern\");\n            permit(principal == User::\"org-editor\", action == Action::\"Edit\", resource == Knowledge::\"org-pattern\");\n            \n            // Project-level viewer\n            permit(principal == User::\"project-viewer\", action == Action::\"View\", resource == Knowledge::\"project-spec\");\n            \n            // Agent delegation\n            permit(principal == User::\"automation-agent\", action == Action::\"ActAs\", resource == User::\"project-viewer\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n\n        // Company admin has full control\n        let admin_ctx = create_tenant_context(\"company1\", \"company-admin\");\n        assert!(\n            authorizer\n                .check_permission(\u0026admin_ctx, \"Admin\", \"Unit::\\\"company\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            authorizer\n                .check_permission(\u0026admin_ctx, \"Edit\", \"Knowledge::\\\"company-policy\\\"\")\n                .await\n                .unwrap()\n        );\n\n        // Org editor can edit org patterns but not company policies\n        let editor_ctx = create_tenant_context(\"company1\", \"org-editor\");\n        assert!(\n            authorizer\n                .check_permission(\u0026editor_ctx, \"Edit\", \"Knowledge::\\\"org-pattern\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            !authorizer\n                .check_permission(\u0026editor_ctx, \"Edit\", \"Knowledge::\\\"company-policy\\\"\")\n                .await\n                .unwrap()\n        );\n\n        // Project viewer can only view\n        let viewer_ctx = create_tenant_context(\"company1\", \"project-viewer\");\n        assert!(\n            authorizer\n                .check_permission(\u0026viewer_ctx, \"View\", \"Knowledge::\\\"project-spec\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            !authorizer\n                .check_permission(\u0026viewer_ctx, \"Edit\", \"Knowledge::\\\"project-spec\\\"\")\n                .await\n                .unwrap()\n        );\n\n        // Automation agent can view as project-viewer\n        let agent_ctx = create_agent_context(\"company1\", \"project-viewer\", \"automation-agent\");\n        assert!(\n            authorizer\n                .check_permission(\u0026agent_ctx, \"View\", \"Knowledge::\\\"project-spec\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            !authorizer\n                .check_permission(\u0026agent_ctx, \"Edit\", \"Knowledge::\\\"project-spec\\\"\")\n                .await\n                .unwrap()\n        );\n    }\n}\n\n// =============================================================================\n// Performance/Stress Tests\n// =============================================================================\n\nmod performance {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_large_policy_set() {\n        // Generate a policy with many rules\n        let mut policies = String::new();\n        for i in 0..100 {\n            policies.push_str(\u0026format!(\n                \"permit(principal == User::\\\"user{}\\\", action == Action::\\\"View\\\", resource == Unit::\\\"data{}\\\");\\n\",\n                i, i\n            ));\n        }\n\n        let authorizer = CedarAuthorizer::new(\u0026policies, TEST_SCHEMA).unwrap();\n\n        // Test access for various users\n        for i in [0, 50, 99].iter() {\n            let ctx = create_tenant_context(\"tenant1\", \u0026format!(\"user{}\", i));\n            let allowed = authorizer\n                .check_permission(\u0026ctx, \"View\", \u0026format!(\"Unit::\\\"data{}\\\"\", i))\n                .await\n                .unwrap();\n            assert!(allowed, \"User{} should access data{}\", i, i);\n        }\n    }\n\n    #[tokio::test]\n    async fn test_many_sequential_checks() {\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"user1\");\n\n        // Perform many checks\n        for _ in 0..100 {\n            let allowed = authorizer\n                .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data\\\"\")\n                .await\n                .unwrap();\n            assert!(allowed);\n        }\n    }\n}\n","traces":[{"line":68,"address":[],"length":0,"stats":{"Line":35}},{"line":70,"address":[],"length":0,"stats":{"Line":140}},{"line":71,"address":[],"length":0,"stats":{"Line":140}},{"line":75,"address":[],"length":0,"stats":{"Line":11}},{"line":77,"address":[],"length":0,"stats":{"Line":44}},{"line":78,"address":[],"length":0,"stats":{"Line":44}},{"line":80,"address":[],"length":0,"stats":{"Line":22}},{"line":81,"address":[],"length":0,"stats":{"Line":11}}],"covered":8,"coverable":8},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","tests","langchain_integration.rs"],"content":"use adapters::ecosystem::EcosystemAdapter;\nuse adapters::langchain::LangChainAdapter;\nuse memory::manager::MemoryManager;\nuse memory::providers::MockProvider;\nuse mk_core::traits::KnowledgeRepository;\nuse mk_core::types::{KnowledgeEntry, KnowledgeLayer, MemoryLayer, TenantContext};\nuse serde_json::json;\nuse std::sync::Arc;\nuse sync::bridge::SyncManager;\nuse sync::state::SyncState;\nuse tools::server::McpServer;\n\nstruct MockRepo;\n\n#[async_trait::async_trait]\nimpl KnowledgeRepository for MockRepo {\n    type Error = knowledge::repository::RepositoryError;\n\n    async fn get(\n        \u0026self,\n        _ctx: TenantContext,\n        _layer: KnowledgeLayer,\n        _path: \u0026str,\n    ) -\u003e Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n\n    async fn store(\n        \u0026self,\n        _ctx: TenantContext,\n        _entry: KnowledgeEntry,\n        _message: \u0026str,\n    ) -\u003e Result\u003cString, Self::Error\u003e {\n        Ok(\"hash\".to_string())\n    }\n\n    async fn list(\n        \u0026self,\n        _ctx: TenantContext,\n        _layer: KnowledgeLayer,\n        _prefix: \u0026str,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n\n    async fn delete(\n        \u0026self,\n        _ctx: TenantContext,\n        _layer: KnowledgeLayer,\n        _path: \u0026str,\n        _message: \u0026str,\n    ) -\u003e Result\u003cString, Self::Error\u003e {\n        Ok(\"hash\".to_string())\n    }\n\n    async fn get_head_commit(\u0026self, _ctx: TenantContext) -\u003e Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n        Ok(Some(\"head\".to_string()))\n    }\n\n    async fn get_affected_items(\n        \u0026self,\n        _ctx: TenantContext,\n        _since_commit: \u0026str,\n    ) -\u003e Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n\n    async fn search(\n        \u0026self,\n        _ctx: TenantContext,\n        _query: \u0026str,\n        _layers: Vec\u003cKnowledgeLayer\u003e,\n        _limit: usize,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n\n    fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n        None\n    }\n}\n\nstruct MockPersister;\n\n#[async_trait::async_trait]\nimpl sync::state_persister::SyncStatePersister for MockPersister {\n    async fn load(\n        \u0026self,\n        _tenant_id: \u0026mk_core::types::TenantId,\n    ) -\u003e Result\u003cSyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        Ok(SyncState::default())\n    }\n    async fn save(\n        \u0026self,\n        _tenant_id: \u0026mk_core::types::TenantId,\n        _state: \u0026SyncState,\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        Ok(())\n    }\n}\n\nasync fn setup_server() -\u003e Arc\u003cMcpServer\u003e {\n    let memory_manager = Arc::new(MemoryManager::new());\n    memory_manager\n        .register_provider(MemoryLayer::User, Box::new(MockProvider::new()))\n        .await;\n\n    let repo = Arc::new(MockRepo);\n    let governance = Arc::new(knowledge::governance::GovernanceEngine::new());\n    let deployment_config = config::config::DeploymentConfig::default();\n    let sync_manager = Arc::new(\n        SyncManager::new(\n            memory_manager.clone(),\n            repo.clone(),\n            governance.clone(),\n            deployment_config,\n            None,\n            Arc::new(MockPersister),\n        )\n        .await\n        .unwrap(),\n    );\n\n    let auth_service = Arc::new(MockAuthService);\n\n    Arc::new(McpServer::new(\n        memory_manager,\n        sync_manager,\n        repo,\n        Arc::new(MockStorageBackend),\n        governance,\n        auth_service,\n        None,\n    ))\n}\n\nstruct MockStorageBackend;\n#[async_trait::async_trait]\nimpl mk_core::traits::StorageBackend for MockStorageBackend {\n    type Error = storage::postgres::PostgresError;\n    async fn store(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _key: \u0026str,\n        _value: \u0026[u8],\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn retrieve(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _key: \u0026str,\n    ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n    async fn delete(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _key: \u0026str,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn exists(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _key: \u0026str,\n    ) -\u003e Result\u003cbool, Self::Error\u003e {\n        Ok(false)\n    }\n    async fn get_ancestors(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n    async fn get_descendants(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n    async fn get_unit_policies(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::Policy\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n    async fn create_unit(\n        \u0026self,\n        _unit: \u0026mk_core::types::OrganizationalUnit,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn add_unit_policy(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _unit_id: \u0026str,\n        _policy: \u0026mk_core::types::Policy,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn assign_role(\n        \u0026self,\n        _user_id: \u0026mk_core::types::UserId,\n        _tenant_id: \u0026mk_core::types::TenantId,\n        _unit_id: \u0026str,\n        _role: mk_core::types::Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn remove_role(\n        \u0026self,\n        _user_id: \u0026mk_core::types::UserId,\n        _tenant_id: \u0026mk_core::types::TenantId,\n        _unit_id: \u0026str,\n        _role: mk_core::types::Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn store_drift_result(\n        \u0026self,\n        _result: mk_core::types::DriftResult,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn get_latest_drift_result(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _project_id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cmk_core::types::DriftResult\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n    async fn list_all_units(\u0026self) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n    async fn record_job_status(\n        \u0026self,\n        _job_name: \u0026str,\n        _tenant_id: \u0026str,\n        _status: \u0026str,\n        _message: Option\u003c\u0026str\u003e,\n        _started_at: i64,\n        _finished_at: Option\u003ci64\u003e,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn get_governance_events(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _since_timestamp: i64,\n        _limit: usize,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n}\n\nstruct MockAuthService;\n#[async_trait::async_trait]\nimpl mk_core::traits::AuthorizationService for MockAuthService {\n    type Error = anyhow::Error;\n    async fn check_permission(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _action: \u0026str,\n        _resource: \u0026str,\n    ) -\u003e anyhow::Result\u003cbool\u003e {\n        Ok(true)\n    }\n    async fn get_user_roles(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n    ) -\u003e anyhow::Result\u003cVec\u003cmk_core::types::Role\u003e\u003e {\n        Ok(vec![])\n    }\n    async fn assign_role(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _user_id: \u0026mk_core::types::UserId,\n        _role: mk_core::types::Role,\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n    async fn remove_role(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _user_id: \u0026mk_core::types::UserId,\n        _role: mk_core::types::Role,\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n}\n\n#[tokio::test]\nasync fn test_langchain_adapter_tool_conversion() {\n    // GIVEN\n    let server = setup_server().await;\n    let adapter = LangChainAdapter::new(server);\n\n    // WHEN\n    let tools = adapter.to_langchain_tools();\n\n    // THEN\n    assert!(!tools.is_empty());\n    let memory_add = tools.iter().find(|t| t[\"name\"] == \"memory_add\").unwrap();\n    assert_eq!(\n        memory_add[\"description\"],\n        \"Store a piece of information in memory for future reference.\"\n    );\n    assert!(memory_add[\"parameters\"].is_object());\n    assert_eq!(memory_add[\"parameters\"][\"additionalProperties\"], false);\n    assert_eq!(\n        memory_add[\"parameters\"][\"$schema\"],\n        \"http://json-schema.org/draft-07/schema#\"\n    );\n}\n\n#[tokio::test]\nasync fn test_langchain_adapter_request_handling() {\n    // GIVEN\n    let server = setup_server().await;\n    let lc_adapter = LangChainAdapter::new(server);\n\n    let request = json!({\n        \"tenantContext\": {\n            \"tenant_id\": \"test_tenant\",\n            \"user_id\": \"test_user\"\n        },\n        \"name\": \"memory_add\",\n        \"arguments\": {\n            \"content\": \"test content\",\n            \"layer\": \"user\"\n        }\n    });\n\n    // WHEN\n    let response = lc_adapter.handle_mcp_request(request).await.unwrap();\n\n    // THEN\n    assert_eq!(response[\"jsonrpc\"], \"2.0\");\n    if let Some(err) = response.get(\"error\") {\n        panic!(\"Tool call failed: {}\", err);\n    }\n    assert!(response[\"result\"].is_object());\n    assert!(response[\"result\"][\"success\"].as_bool().unwrap());\n}\n","traces":[{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":4}},{"line":103,"address":[],"length":0,"stats":{"Line":6}},{"line":104,"address":[],"length":0,"stats":{"Line":4}},{"line":105,"address":[],"length":0,"stats":{"Line":6}},{"line":106,"address":[],"length":0,"stats":{"Line":2}},{"line":108,"address":[],"length":0,"stats":{"Line":6}},{"line":109,"address":[],"length":0,"stats":{"Line":6}},{"line":110,"address":[],"length":0,"stats":{"Line":4}},{"line":112,"address":[],"length":0,"stats":{"Line":4}},{"line":113,"address":[],"length":0,"stats":{"Line":6}},{"line":114,"address":[],"length":0,"stats":{"Line":4}},{"line":115,"address":[],"length":0,"stats":{"Line":6}},{"line":116,"address":[],"length":0,"stats":{"Line":4}},{"line":117,"address":[],"length":0,"stats":{"Line":4}},{"line":118,"address":[],"length":0,"stats":{"Line":2}},{"line":120,"address":[],"length":0,"stats":{"Line":2}},{"line":121,"address":[],"length":0,"stats":{"Line":2}},{"line":124,"address":[],"length":0,"stats":{"Line":6}},{"line":126,"address":[],"length":0,"stats":{"Line":4}},{"line":127,"address":[],"length":0,"stats":{"Line":2}},{"line":128,"address":[],"length":0,"stats":{"Line":2}},{"line":129,"address":[],"length":0,"stats":{"Line":2}},{"line":130,"address":[],"length":0,"stats":{"Line":2}},{"line":131,"address":[],"length":0,"stats":{"Line":2}},{"line":132,"address":[],"length":0,"stats":{"Line":2}},{"line":133,"address":[],"length":0,"stats":{"Line":2}},{"line":236,"address":[],"length":0,"stats":{"Line":0}}],"covered":26,"coverable":30},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","backend.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","bridge.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","config.rs"],"content":"//! # Configuration Structures\n//!\n//! This module defines all configuration structures for the Memory-Knowledge\n//! system.\n//!\n//! All configuration structures:\n//! - Use `serde` for serialization/deserialization\n//! - Use `validator` for input validation\n//! - Follow Microsoft Pragmatic Rust Guidelines\n//! - Include comprehensive M-CANONICAL-DOCS\n\nuse serde::{Deserialize, Serialize};\nuse validator::Validate;\n\n/// Main configuration structure for the Memory-Knowledge system.\n///\n/// This is the top-level configuration that aggregates all subsystem\n/// configurations.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Provides centralized configuration for the entire Memory-Knowledge system,\n/// including storage providers, sync behavior, MCP tools, and observability.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::Config;\n///\n/// let config = Config::default();\n/// println!(\"PostgreSQL host: {}\", config.providers.postgres.host);\n/// ```\n///\n/// ## Fields\n/// - `providers`: Configuration for storage backends (PostgreSQL, Qdrant,\n///   Redis)\n/// - `sync`: Configuration for memory-knowledge synchronization\n/// - `tools`: Configuration for MCP server tools\n/// - `observability`: Configuration for metrics and tracing\n///\n/// ## Validation\n/// All nested configurations must pass their own validation rules.\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, Default, PartialEq)]\npub struct Config {\n    /// Storage provider configurations (PostgreSQL, Qdrant, Redis)\n    #[serde(default)]\n    pub providers: ProviderConfig,\n\n    /// Memory-knowledge synchronization configuration\n    #[serde(default)]\n    pub sync: SyncConfig,\n\n    /// Memory system configuration\n    #[serde(default)]\n    pub memory: MemoryConfig,\n\n    /// MCP tool interface configuration\n    #[serde(default)]\n    pub tools: ToolConfig,\n\n    /// Observability configuration (metrics, tracing, logging)\n    #[serde(default)]\n    pub observability: ObservabilityConfig,\n\n    /// Deployment mode configuration (Local, Hybrid, Remote)\n    #[serde(default)]\n    pub deployment: DeploymentConfig,\n}\n\nimpl Config {\n    /// Detects environment settings for deployment mode.\n    ///\n    /// # M-CANONICAL-DOCS\n    ///\n    /// ## Purpose\n    /// Initializes configuration based on AETERNA_ environment variables.\n    pub fn detect_env() -\u003e Self {\n        let mut config = Self::default();\n\n        if let Ok(url) = std::env::var(\"AETERNA_REMOTE_GOVERNANCE_URL\") {\n            config.deployment.remote_url = Some(url);\n            config.deployment.mode =\n                std::env::var(\"AETERNA_DEPLOYMENT_MODE\").unwrap_or_else(|_| \"hybrid\".to_string());\n        }\n\n        if std::env::var(\"AETERNA_THIN_CLIENT\").is_ok() {\n            config.deployment.mode = \"remote\".to_string();\n            config.sync.enabled = false;\n        }\n\n        config\n    }\n}\n\n/// Deployment mode configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages the deployment mode of the system (Local, Hybrid, or Remote).\n///\n/// ## Fields\n/// - `mode`: Deployment mode (default: \"local\")\n/// - `remote_url`: URL of the remote governance server (required for\n///   Hybrid/Remote)\n/// - `sync_enabled`: Enable synchronization in Hybrid mode (default: true)\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct DeploymentConfig {\n    /// Deployment mode\n    #[serde(default = \"default_deployment_mode\")]\n    #[validate(custom(function = \"validate_deployment_mode\"))]\n    pub mode: String,\n\n    /// URL of the remote governance server\n    #[serde(default)]\n    pub remote_url: Option\u003cString\u003e,\n\n    /// Enable synchronization in Hybrid mode\n    #[serde(default = \"default_deployment_sync_enabled\")]\n    pub sync_enabled: bool,\n}\n\nfn default_deployment_mode() -\u003e String {\n    \"local\".to_string()\n}\n\nfn default_deployment_sync_enabled() -\u003e bool {\n    true\n}\n\nfn validate_deployment_mode(value: \u0026str) -\u003e Result\u003c(), validator::ValidationError\u003e {\n    match value {\n        \"local\" | \"hybrid\" | \"remote\" =\u003e Ok(()),\n        _ =\u003e Err(validator::ValidationError::new(\"Invalid deployment mode\")),\n    }\n}\n\nimpl Default for DeploymentConfig {\n    fn default() -\u003e Self {\n        Self {\n            mode: default_deployment_mode(),\n            remote_url: None,\n            sync_enabled: default_deployment_sync_enabled(),\n        }\n    }\n}\n\nimpl DeploymentConfig {\n    pub fn auto_detect() -\u003e Self {\n        let mut config = Self::default();\n\n        if let Ok(mode) = std::env::var(\"AETERNA_DEPLOYMENT_MODE\") {\n            config.mode = mode;\n        }\n\n        if let Ok(url) = std::env::var(\"AETERNA_REMOTE_GOVERNANCE_URL\") {\n            config.remote_url = Some(url);\n            if config.mode == \"local\" {\n                config.mode = \"hybrid\".to_string();\n            }\n        }\n\n        if std::env::var(\"AETERNA_THIN_CLIENT\").is_ok() {\n            config.mode = \"remote\".to_string();\n            config.sync_enabled = false;\n        }\n\n        if let Ok(sync) = std::env::var(\"AETERNA_SYNC_ENABLED\") {\n            config.sync_enabled = sync.to_lowercase() == \"true\" || sync == \"1\";\n        }\n\n        config\n    }\n\n    pub fn is_local(\u0026self) -\u003e bool {\n        self.mode == \"local\"\n    }\n\n    pub fn is_hybrid(\u0026self) -\u003e bool {\n        self.mode == \"hybrid\"\n    }\n\n    pub fn is_remote(\u0026self) -\u003e bool {\n        self.mode == \"remote\"\n    }\n\n    pub fn requires_remote_url(\u0026self) -\u003e bool {\n        self.is_hybrid() || self.is_remote()\n    }\n\n    pub fn requires_local_engine(\u0026self) -\u003e bool {\n        self.is_local() || self.is_hybrid()\n    }\n}\n\n/// Configuration for storage providers.\n///\n/// Manages connection settings for all storage backends.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Centralizes connection configuration for all storage backends:\n/// - PostgreSQL: Primary data storage with pgvector extension\n/// - Qdrant: Vector similarity search\n/// - Redis: Caching layer\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::ProviderConfig;\n///\n/// let providers = ProviderConfig::default();\n/// assert_eq!(providers.postgres.host, \"localhost\");\n/// ```\n///\n/// ## Fields\n/// - `postgres`: PostgreSQL connection configuration\n/// - `qdrant`: Qdrant vector database configuration\n/// - `redis`: Redis caching configuration\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, Default, PartialEq)]\npub struct ProviderConfig {\n    /// PostgreSQL connection configuration\n    #[serde(default)]\n    pub postgres: PostgresConfig,\n\n    /// Qdrant vector database configuration\n    #[serde(default)]\n    pub qdrant: QdrantConfig,\n\n    /// Redis caching configuration\n    #[serde(default)]\n    pub redis: RedisConfig,\n}\n\n/// PostgreSQL configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages connection settings for PostgreSQL, the primary data storage\n/// backend.\n///\n/// ## Fields\n/// - `host`: Database server hostname (default: \"localhost\")\n/// - `port`: Database server port (default: 5432)\n/// - `database`: Database name (required)\n/// - `username`: Database user (required)\n/// - `password`: Database password (required, should use environment variable)\n/// - `pool_size`: Maximum connections in pool (default: 10, range: 1-100)\n/// - `timeout_seconds`: Connection timeout (default: 30, range: 1-300)\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct PostgresConfig {\n    /// Database server hostname\n    #[serde(default = \"default_postgres_host\")]\n    #[validate(length(min = 1, max = 255))]\n    pub host: String,\n\n    /// Database server port\n    #[serde(default = \"default_postgres_port\")]\n    #[validate(range(min = 1, max = 65535))]\n    pub port: u16,\n\n    /// Database name\n    #[serde(default = \"default_postgres_database\")]\n    #[validate(length(min = 1, max = 63))]\n    pub database: String,\n\n    /// Database username\n    #[serde(default = \"default_postgres_username\")]\n    #[validate(length(min = 1, max = 63))]\n    pub username: String,\n\n    /// Database password\n    #[serde(default = \"default_postgres_password\")]\n    #[validate(length(min = 1))]\n    pub password: String,\n\n    /// Maximum connections in pool\n    #[serde(default = \"default_postgres_pool_size\")]\n    #[validate(range(min = 1, max = 100))]\n    pub pool_size: u32,\n\n    /// Connection timeout in seconds\n    #[serde(default = \"default_postgres_timeout\")]\n    #[validate(range(min = 1, max = 300))]\n    pub timeout_seconds: u64,\n}\n\nfn default_postgres_host() -\u003e String {\n    \"localhost\".to_string()\n}\n\nfn default_postgres_port() -\u003e u16 {\n    5432\n}\n\nfn default_postgres_database() -\u003e String {\n    \"memory_knowledge\".to_string()\n}\n\nfn default_postgres_username() -\u003e String {\n    \"postgres\".to_string()\n}\n\nfn default_postgres_password() -\u003e String {\n    \"\".to_string()\n}\n\nfn default_postgres_pool_size() -\u003e u32 {\n    10\n}\n\nfn default_postgres_timeout() -\u003e u64 {\n    30\n}\n\nimpl Default for PostgresConfig {\n    fn default() -\u003e Self {\n        Self {\n            host: default_postgres_host(),\n            port: default_postgres_port(),\n            database: default_postgres_database(),\n            username: default_postgres_username(),\n            password: default_postgres_password(),\n            pool_size: default_postgres_pool_size(),\n            timeout_seconds: default_postgres_timeout(),\n        }\n    }\n}\n\n/// Qdrant vector database configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages connection settings for Qdrant, used for vector similarity search.\n///\n/// ## Fields\n/// - `host`: Qdrant server hostname (default: \"localhost\")\n/// - `port`: Qdrant server port (default: 6333)\n/// - `collection`: Default collection name (required)\n/// - `timeout_seconds`: Request timeout (default: 30, range: 1-300)\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct QdrantConfig {\n    /// Qdrant server hostname\n    #[serde(default = \"default_qdrant_host\")]\n    #[validate(length(min = 1, max = 255))]\n    pub host: String,\n\n    /// Qdrant server port\n    #[serde(default = \"default_qdrant_port\")]\n    #[validate(range(min = 1, max = 65535))]\n    pub port: u16,\n\n    /// Default collection name\n    #[serde(default = \"default_qdrant_collection\")]\n    #[validate(length(min = 1, max = 255))]\n    pub collection: String,\n\n    /// Request timeout in seconds\n    #[serde(default = \"default_qdrant_timeout\")]\n    #[validate(range(min = 1, max = 300))]\n    pub timeout_seconds: u64,\n}\n\nfn default_qdrant_host() -\u003e String {\n    \"localhost\".to_string()\n}\n\nfn default_qdrant_port() -\u003e u16 {\n    6333\n}\n\nfn default_qdrant_collection() -\u003e String {\n    \"memory_embeddings\".to_string()\n}\n\nfn default_qdrant_timeout() -\u003e u64 {\n    30\n}\n\nimpl Default for QdrantConfig {\n    fn default() -\u003e Self {\n        Self {\n            host: default_qdrant_host(),\n            port: default_qdrant_port(),\n            collection: default_qdrant_collection(),\n            timeout_seconds: default_qdrant_timeout(),\n        }\n    }\n}\n\n/// Redis configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages connection settings for Redis, used as a caching layer.\n///\n/// ## Fields\n/// - `host`: Redis server hostname (default: \"localhost\")\n/// - `port`: Redis server port (default: 6379)\n/// - `db`: Redis database number (default: 0, range: 0-15)\n/// - `pool_size`: Maximum connections in pool (default: 10, range: 1-100)\n/// - `timeout_seconds`: Connection timeout (default: 30, range: 1-300)\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct RedisConfig {\n    /// Redis server hostname\n    #[serde(default = \"default_redis_host\")]\n    #[validate(length(min = 1, max = 255))]\n    pub host: String,\n\n    /// Redis server port\n    #[serde(default = \"default_redis_port\")]\n    #[validate(range(min = 1, max = 65535))]\n    pub port: u16,\n\n    /// Redis database number\n    #[serde(default = \"default_redis_db\")]\n    #[validate(range(min = 0, max = 15))]\n    pub db: u8,\n\n    /// Maximum connections in pool\n    #[serde(default = \"default_redis_pool_size\")]\n    #[validate(range(min = 1, max = 100))]\n    pub pool_size: u32,\n\n    /// Connection timeout in seconds\n    #[serde(default = \"default_redis_timeout\")]\n    #[validate(range(min = 1, max = 300))]\n    pub timeout_seconds: u64,\n}\n\nfn default_redis_host() -\u003e String {\n    \"localhost\".to_string()\n}\n\nfn default_redis_port() -\u003e u16 {\n    6379\n}\n\nfn default_redis_db() -\u003e u8 {\n    0\n}\n\nfn default_redis_pool_size() -\u003e u32 {\n    10\n}\n\nfn default_redis_timeout() -\u003e u64 {\n    30\n}\n\nimpl Default for RedisConfig {\n    fn default() -\u003e Self {\n        Self {\n            host: default_redis_host(),\n            port: default_redis_port(),\n            db: default_redis_db(),\n            pool_size: default_redis_pool_size(),\n            timeout_seconds: default_redis_timeout(),\n        }\n    }\n}\n\n/// Synchronization configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages synchronization behavior between memory and knowledge systems.\n///\n/// ## Fields\n/// - `enabled`: Enable/disable automatic sync (default: true)\n/// - `sync_interval_seconds`: Sync interval (default: 60, range: 10-3600)\n/// - `batch_size`: Number of items per sync batch (default: 100, range: 1-1000)\n/// - `checkpoint_enabled`: Enable checkpointing for rollback (default: true)\n/// - `conflict_resolution`: Strategy for conflict resolution (default:\n///   \"prefer_knowledge\")\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct SyncConfig {\n    /// Enable/disable automatic synchronization\n    #[serde(default = \"default_sync_enabled\")]\n    pub enabled: bool,\n\n    /// Sync interval in seconds\n    #[serde(default = \"default_sync_interval\")]\n    #[validate(range(min = 10, max = 3600))]\n    pub sync_interval_seconds: u64,\n\n    /// Number of items per sync batch\n    #[serde(default = \"default_sync_batch_size\")]\n    #[validate(range(min = 1, max = 1000))]\n    pub batch_size: u32,\n\n    /// Enable checkpointing for rollback\n    #[serde(default = \"default_sync_checkpoint\")]\n    pub checkpoint_enabled: bool,\n\n    /// Conflict resolution strategy\n    #[serde(default = \"default_sync_conflict_resolution\")]\n    #[validate(custom(function = \"validate_conflict_resolution\"))]\n    pub conflict_resolution: String,\n}\n\nfn default_sync_enabled() -\u003e bool {\n    true\n}\n\nfn default_sync_interval() -\u003e u64 {\n    60\n}\n\nfn default_sync_batch_size() -\u003e u32 {\n    100\n}\n\nfn default_sync_checkpoint() -\u003e bool {\n    true\n}\n\nfn default_sync_conflict_resolution() -\u003e String {\n    \"prefer_knowledge\".to_string()\n}\n\nfn validate_conflict_resolution(value: \u0026str) -\u003e Result\u003c(), validator::ValidationError\u003e {\n    match value {\n        \"prefer_knowledge\" | \"prefer_memory\" | \"manual\" =\u003e Ok(()),\n        _ =\u003e Err(validator::ValidationError::new(\n            \"Invalid conflict resolution strategy\",\n        )),\n    }\n}\n\nimpl Default for SyncConfig {\n    fn default() -\u003e Self {\n        Self {\n            enabled: default_sync_enabled(),\n            sync_interval_seconds: default_sync_interval(),\n            batch_size: default_sync_batch_size(),\n            checkpoint_enabled: default_sync_checkpoint(),\n            conflict_resolution: default_sync_conflict_resolution(),\n        }\n    }\n}\n\n/// MCP tool interface configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages configuration for the MCP (Model Context Protocol) server interface.\n///\n/// ## Fields\n/// - `enabled`: Enable/disable MCP server (default: true)\n/// - `host`: Server hostname (default: \"localhost\")\n/// - `port`: Server port (default: 8080)\n/// - `api_key`: API key for authentication (optional)\n/// - `rate_limit_requests_per_minute`: Rate limit (default: 60, range: 1-1000)\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct ToolConfig {\n    /// Enable/disable MCP server\n    #[serde(default = \"default_tools_enabled\")]\n    pub enabled: bool,\n\n    /// Server hostname\n    #[serde(default = \"default_tools_host\")]\n    #[validate(length(min = 1, max = 255))]\n    pub host: String,\n\n    /// Server port\n    #[serde(default = \"default_tools_port\")]\n    #[validate(range(min = 1, max = 65535))]\n    pub port: u16,\n\n    /// API key for authentication\n    #[serde(default)]\n    pub api_key: Option\u003cString\u003e,\n\n    /// Rate limit: requests per minute\n    #[serde(default = \"default_tools_rate_limit\")]\n    #[validate(range(min = 1, max = 1000))]\n    pub rate_limit_requests_per_minute: u32,\n}\n\nfn default_tools_enabled() -\u003e bool {\n    true\n}\n\nfn default_tools_host() -\u003e String {\n    \"localhost\".to_string()\n}\n\nfn default_tools_port() -\u003e u16 {\n    8080\n}\n\nfn default_tools_rate_limit() -\u003e u32 {\n    60\n}\n\nimpl Default for ToolConfig {\n    fn default() -\u003e Self {\n        Self {\n            enabled: default_tools_enabled(),\n            host: default_tools_host(),\n            port: default_tools_port(),\n            api_key: None,\n            rate_limit_requests_per_minute: default_tools_rate_limit(),\n        }\n    }\n}\n\n/// Observability configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages configuration for metrics, tracing, and logging.\n///\n/// ## Fields\n/// - `metrics_enabled`: Enable metrics collection (default: true)\n/// - `tracing_enabled`: Enable distributed tracing (default: true)\n/// - `logging_level`: Log level (default: \"info\")\n/// - `metrics_port`: Metrics server port (default: 9090)\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct ObservabilityConfig {\n    /// Enable metrics collection\n    #[serde(default = \"default_observability_metrics_enabled\")]\n    pub metrics_enabled: bool,\n\n    /// Enable distributed tracing\n    #[serde(default = \"default_observability_tracing_enabled\")]\n    pub tracing_enabled: bool,\n\n    /// Logging level\n    #[serde(default = \"default_observability_logging_level\")]\n    #[validate(custom(function = \"validate_logging_level\"))]\n    pub logging_level: String,\n\n    /// Metrics server port\n    #[serde(default = \"default_observability_metrics_port\")]\n    #[validate(range(min = 1, max = 65535))]\n    pub metrics_port: u16,\n}\n\nfn default_observability_metrics_enabled() -\u003e bool {\n    true\n}\n\nfn default_observability_tracing_enabled() -\u003e bool {\n    true\n}\n\nfn default_observability_logging_level() -\u003e String {\n    \"info\".to_string()\n}\n\nfn default_observability_metrics_port() -\u003e u16 {\n    9090\n}\n\nfn validate_logging_level(value: \u0026str) -\u003e Result\u003c(), validator::ValidationError\u003e {\n    match value {\n        \"trace\" | \"debug\" | \"info\" | \"warn\" | \"error\" =\u003e Ok(()),\n        _ =\u003e Err(validator::ValidationError::new(\"Invalid logging level\")),\n    }\n}\n\nimpl Default for ObservabilityConfig {\n    fn default() -\u003e Self {\n        Self {\n            metrics_enabled: default_observability_metrics_enabled(),\n            tracing_enabled: default_observability_tracing_enabled(),\n            logging_level: default_observability_logging_level(),\n            metrics_port: default_observability_metrics_port(),\n        }\n    }\n}\n\n/// Memory system configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages configuration for the memory system, including promotion thresholds.\n///\n/// ## Fields\n/// - `promotion_threshold`: Threshold for memory promotion (default: 0.8,\n///   range: 0.0-1.0)\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct MemoryConfig {\n    /// Threshold for memory promotion\n    #[serde(default = \"default_promotion_threshold\")]\n    #[validate(range(min = 0.0, max = 1.0))]\n    pub promotion_threshold: f32,\n}\n\nfn default_promotion_threshold() -\u003e f32 {\n    0.8\n}\n\nimpl Default for MemoryConfig {\n    fn default() -\u003e Self {\n        Self {\n            promotion_threshold: default_promotion_threshold(),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_config_default() {\n        let config = Config::default();\n        assert_eq!(config.providers.postgres.host, \"localhost\");\n        assert_eq!(config.sync.enabled, true);\n        assert_eq!(config.tools.port, 8080);\n        assert_eq!(config.observability.logging_level, \"info\");\n    }\n\n    #[test]\n    fn test_provider_config_default() {\n        let providers = ProviderConfig::default();\n        assert_eq!(providers.postgres.port, 5432);\n        assert_eq!(providers.qdrant.port, 6333);\n        assert_eq!(providers.redis.port, 6379);\n    }\n\n    #[test]\n    fn test_sync_config_default() {\n        let sync = SyncConfig::default();\n        assert_eq!(sync.enabled, true);\n        assert_eq!(sync.sync_interval_seconds, 60);\n        assert_eq!(sync.conflict_resolution, \"prefer_knowledge\");\n    }\n\n    #[test]\n    fn test_postgres_config_validation() {\n        let mut postgres = PostgresConfig::default();\n        postgres.host = \"\".to_string();\n        assert!(postgres.validate().is_err());\n    }\n\n    #[test]\n    fn test_qdrant_config_validation() {\n        let mut qdrant = QdrantConfig::default();\n        qdrant.port = 0;\n        assert!(qdrant.validate().is_err());\n    }\n\n    #[test]\n    fn test_redis_config_validation() {\n        let mut redis = RedisConfig::default();\n        redis.db = 16;\n        assert!(redis.validate().is_err());\n    }\n\n    #[test]\n    fn test_sync_config_conflict_resolution_validation() {\n        let mut sync = SyncConfig::default();\n        sync.conflict_resolution = \"invalid\".to_string();\n        assert!(sync.validate().is_err());\n\n        sync.conflict_resolution = \"prefer_memory\".to_string();\n        assert!(sync.validate().is_ok());\n    }\n\n    #[test]\n    fn test_observability_config_logging_level_validation() {\n        let mut obs = ObservabilityConfig::default();\n        obs.logging_level = \"invalid\".to_string();\n        assert!(obs.validate().is_err());\n\n        obs.logging_level = \"debug\".to_string();\n        assert!(obs.validate().is_ok());\n    }\n\n    #[test]\n    fn test_config_serialization() {\n        let config = Config::default();\n        let json = serde_json::to_string(\u0026config).unwrap();\n        let deserialized: Config = serde_json::from_str(\u0026json).unwrap();\n        assert_eq!(\n            config.providers.postgres.host,\n            deserialized.providers.postgres.host\n        );\n    }\n\n    #[test]\n    fn test_deployment_config_default() {\n        let config = DeploymentConfig::default();\n        assert_eq!(config.mode, \"local\");\n        assert!(config.remote_url.is_none());\n        assert!(config.sync_enabled);\n    }\n\n    #[test]\n    fn test_deployment_config_is_local() {\n        let config = DeploymentConfig {\n            mode: \"local\".to_string(),\n            remote_url: None,\n            sync_enabled: true,\n        };\n        assert!(config.is_local());\n        assert!(!config.is_hybrid());\n        assert!(!config.is_remote());\n    }\n\n    #[test]\n    fn test_deployment_config_is_hybrid() {\n        let config = DeploymentConfig {\n            mode: \"hybrid\".to_string(),\n            remote_url: Some(\"http://localhost:8080\".to_string()),\n            sync_enabled: true,\n        };\n        assert!(!config.is_local());\n        assert!(config.is_hybrid());\n        assert!(!config.is_remote());\n    }\n\n    #[test]\n    fn test_deployment_config_is_remote() {\n        let config = DeploymentConfig {\n            mode: \"remote\".to_string(),\n            remote_url: Some(\"http://localhost:8080\".to_string()),\n            sync_enabled: false,\n        };\n        assert!(!config.is_local());\n        assert!(!config.is_hybrid());\n        assert!(config.is_remote());\n    }\n\n    #[test]\n    fn test_deployment_config_requires_remote_url() {\n        let local = DeploymentConfig {\n            mode: \"local\".to_string(),\n            ..Default::default()\n        };\n        let hybrid = DeploymentConfig {\n            mode: \"hybrid\".to_string(),\n            ..Default::default()\n        };\n        let remote = DeploymentConfig {\n            mode: \"remote\".to_string(),\n            ..Default::default()\n        };\n\n        assert!(!local.requires_remote_url());\n        assert!(hybrid.requires_remote_url());\n        assert!(remote.requires_remote_url());\n    }\n\n    #[test]\n    fn test_deployment_config_requires_local_engine() {\n        let local = DeploymentConfig {\n            mode: \"local\".to_string(),\n            ..Default::default()\n        };\n        let hybrid = DeploymentConfig {\n            mode: \"hybrid\".to_string(),\n            ..Default::default()\n        };\n        let remote = DeploymentConfig {\n            mode: \"remote\".to_string(),\n            ..Default::default()\n        };\n\n        assert!(local.requires_local_engine());\n        assert!(hybrid.requires_local_engine());\n        assert!(!remote.requires_local_engine());\n    }\n\n    #[test]\n    fn test_deployment_mode_validation() {\n        assert!(validate_deployment_mode(\"local\").is_ok());\n        assert!(validate_deployment_mode(\"hybrid\").is_ok());\n        assert!(validate_deployment_mode(\"remote\").is_ok());\n        assert!(validate_deployment_mode(\"invalid\").is_err());\n    }\n}\n","traces":[{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":92}},{"line":124,"address":[],"length":0,"stats":{"Line":184}},{"line":127,"address":[],"length":0,"stats":{"Line":92}},{"line":128,"address":[],"length":0,"stats":{"Line":92}},{"line":131,"address":[],"length":0,"stats":{"Line":4}},{"line":132,"address":[],"length":0,"stats":{"Line":4}},{"line":133,"address":[],"length":0,"stats":{"Line":12}},{"line":134,"address":[],"length":0,"stats":{"Line":1}},{"line":139,"address":[],"length":0,"stats":{"Line":92}},{"line":141,"address":[],"length":0,"stats":{"Line":184}},{"line":143,"address":[],"length":0,"stats":{"Line":92}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":6}},{"line":176,"address":[],"length":0,"stats":{"Line":6}},{"line":179,"address":[],"length":0,"stats":{"Line":8}},{"line":180,"address":[],"length":0,"stats":{"Line":8}},{"line":183,"address":[],"length":0,"stats":{"Line":5}},{"line":184,"address":[],"length":0,"stats":{"Line":5}},{"line":187,"address":[],"length":0,"stats":{"Line":3}},{"line":188,"address":[],"length":0,"stats":{"Line":10}},{"line":191,"address":[],"length":0,"stats":{"Line":3}},{"line":192,"address":[],"length":0,"stats":{"Line":10}},{"line":289,"address":[],"length":0,"stats":{"Line":34}},{"line":290,"address":[],"length":0,"stats":{"Line":68}},{"line":293,"address":[],"length":0,"stats":{"Line":36}},{"line":294,"address":[],"length":0,"stats":{"Line":36}},{"line":297,"address":[],"length":0,"stats":{"Line":36}},{"line":298,"address":[],"length":0,"stats":{"Line":72}},{"line":301,"address":[],"length":0,"stats":{"Line":36}},{"line":302,"address":[],"length":0,"stats":{"Line":72}},{"line":305,"address":[],"length":0,"stats":{"Line":36}},{"line":306,"address":[],"length":0,"stats":{"Line":72}},{"line":309,"address":[],"length":0,"stats":{"Line":38}},{"line":310,"address":[],"length":0,"stats":{"Line":38}},{"line":313,"address":[],"length":0,"stats":{"Line":38}},{"line":314,"address":[],"length":0,"stats":{"Line":38}},{"line":318,"address":[],"length":0,"stats":{"Line":34}},{"line":320,"address":[],"length":0,"stats":{"Line":68}},{"line":321,"address":[],"length":0,"stats":{"Line":68}},{"line":322,"address":[],"length":0,"stats":{"Line":68}},{"line":323,"address":[],"length":0,"stats":{"Line":68}},{"line":324,"address":[],"length":0,"stats":{"Line":68}},{"line":325,"address":[],"length":0,"stats":{"Line":34}},{"line":326,"address":[],"length":0,"stats":{"Line":34}},{"line":366,"address":[],"length":0,"stats":{"Line":32}},{"line":367,"address":[],"length":0,"stats":{"Line":64}},{"line":370,"address":[],"length":0,"stats":{"Line":32}},{"line":371,"address":[],"length":0,"stats":{"Line":32}},{"line":374,"address":[],"length":0,"stats":{"Line":32}},{"line":375,"address":[],"length":0,"stats":{"Line":64}},{"line":378,"address":[],"length":0,"stats":{"Line":34}},{"line":379,"address":[],"length":0,"stats":{"Line":34}},{"line":383,"address":[],"length":0,"stats":{"Line":32}},{"line":385,"address":[],"length":0,"stats":{"Line":64}},{"line":386,"address":[],"length":0,"stats":{"Line":64}},{"line":387,"address":[],"length":0,"stats":{"Line":32}},{"line":388,"address":[],"length":0,"stats":{"Line":32}},{"line":434,"address":[],"length":0,"stats":{"Line":30}},{"line":435,"address":[],"length":0,"stats":{"Line":60}},{"line":438,"address":[],"length":0,"stats":{"Line":30}},{"line":439,"address":[],"length":0,"stats":{"Line":30}},{"line":442,"address":[],"length":0,"stats":{"Line":32}},{"line":443,"address":[],"length":0,"stats":{"Line":32}},{"line":446,"address":[],"length":0,"stats":{"Line":32}},{"line":447,"address":[],"length":0,"stats":{"Line":32}},{"line":450,"address":[],"length":0,"stats":{"Line":32}},{"line":451,"address":[],"length":0,"stats":{"Line":32}},{"line":455,"address":[],"length":0,"stats":{"Line":30}},{"line":457,"address":[],"length":0,"stats":{"Line":60}},{"line":458,"address":[],"length":0,"stats":{"Line":60}},{"line":459,"address":[],"length":0,"stats":{"Line":60}},{"line":460,"address":[],"length":0,"stats":{"Line":30}},{"line":461,"address":[],"length":0,"stats":{"Line":30}},{"line":506,"address":[],"length":0,"stats":{"Line":23}},{"line":507,"address":[],"length":0,"stats":{"Line":23}},{"line":510,"address":[],"length":0,"stats":{"Line":23}},{"line":511,"address":[],"length":0,"stats":{"Line":23}},{"line":514,"address":[],"length":0,"stats":{"Line":25}},{"line":515,"address":[],"length":0,"stats":{"Line":25}},{"line":518,"address":[],"length":0,"stats":{"Line":25}},{"line":519,"address":[],"length":0,"stats":{"Line":25}},{"line":522,"address":[],"length":0,"stats":{"Line":25}},{"line":523,"address":[],"length":0,"stats":{"Line":50}},{"line":526,"address":[],"length":0,"stats":{"Line":2}},{"line":527,"address":[],"length":0,"stats":{"Line":2}},{"line":528,"address":[],"length":0,"stats":{"Line":6}},{"line":529,"address":[],"length":0,"stats":{"Line":1}},{"line":530,"address":[],"length":0,"stats":{"Line":1}},{"line":536,"address":[],"length":0,"stats":{"Line":23}},{"line":538,"address":[],"length":0,"stats":{"Line":46}},{"line":539,"address":[],"length":0,"stats":{"Line":46}},{"line":540,"address":[],"length":0,"stats":{"Line":46}},{"line":541,"address":[],"length":0,"stats":{"Line":23}},{"line":542,"address":[],"length":0,"stats":{"Line":23}},{"line":586,"address":[],"length":0,"stats":{"Line":25}},{"line":587,"address":[],"length":0,"stats":{"Line":25}},{"line":590,"address":[],"length":0,"stats":{"Line":27}},{"line":591,"address":[],"length":0,"stats":{"Line":54}},{"line":594,"address":[],"length":0,"stats":{"Line":25}},{"line":595,"address":[],"length":0,"stats":{"Line":25}},{"line":598,"address":[],"length":0,"stats":{"Line":27}},{"line":599,"address":[],"length":0,"stats":{"Line":27}},{"line":603,"address":[],"length":0,"stats":{"Line":25}},{"line":605,"address":[],"length":0,"stats":{"Line":50}},{"line":606,"address":[],"length":0,"stats":{"Line":50}},{"line":607,"address":[],"length":0,"stats":{"Line":50}},{"line":609,"address":[],"length":0,"stats":{"Line":25}},{"line":647,"address":[],"length":0,"stats":{"Line":22}},{"line":648,"address":[],"length":0,"stats":{"Line":22}},{"line":651,"address":[],"length":0,"stats":{"Line":22}},{"line":652,"address":[],"length":0,"stats":{"Line":22}},{"line":655,"address":[],"length":0,"stats":{"Line":20}},{"line":656,"address":[],"length":0,"stats":{"Line":40}},{"line":659,"address":[],"length":0,"stats":{"Line":22}},{"line":660,"address":[],"length":0,"stats":{"Line":22}},{"line":663,"address":[],"length":0,"stats":{"Line":2}},{"line":664,"address":[],"length":0,"stats":{"Line":2}},{"line":665,"address":[],"length":0,"stats":{"Line":8}},{"line":666,"address":[],"length":0,"stats":{"Line":1}},{"line":671,"address":[],"length":0,"stats":{"Line":20}},{"line":673,"address":[],"length":0,"stats":{"Line":40}},{"line":674,"address":[],"length":0,"stats":{"Line":40}},{"line":675,"address":[],"length":0,"stats":{"Line":20}},{"line":676,"address":[],"length":0,"stats":{"Line":20}},{"line":699,"address":[],"length":0,"stats":{"Line":111}},{"line":700,"address":[],"length":0,"stats":{"Line":111}},{"line":704,"address":[],"length":0,"stats":{"Line":111}},{"line":706,"address":[],"length":0,"stats":{"Line":111}}],"covered":127,"coverable":151},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","ecosystem.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","episodic.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","file_loader.rs"],"content":"//! # Configuration File Loading\n//!\n//! Loads configuration from TOML or YAML files.\n//!\n//! Supports automatic format detection based on file extension.\n\nuse crate::config::Config;\nuse std::path::Path;\n\n/// Configuration file loading error.\n#[derive(Debug, thiserror::Error)]\npub enum ConfigFileError {\n    #[error(\"File not found: {0}\")]\n    FileNotFound(String),\n\n    #[error(\"IO error: {0}\")]\n    Io(#[from] std::io::Error),\n\n    #[error(\"Failed to parse TOML: {0}\")]\n    TomlParse(String),\n\n    #[error(\"Failed to parse YAML: {0}\")]\n    YamlParse(String),\n\n    #[error(\"Config file has no extension\")]\n    NoExtension,\n\n    #[error(\"Unsupported config file format: {0}\")]\n    UnsupportedFormat(String),\n}\n\n/// Load configuration from TOML file.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Loads complete configuration from a TOML format file.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::load_from_toml;\n/// use std::path::Path;\n///\n/// fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n///     let config = load_from_toml(Path::new(\"config.toml\"))?;\n///     println!(\"PostgreSQL host: {}\", config.providers.postgres.host);\n///     Ok(())\n/// }\n/// ```\n///\n/// ## Error Handling\n/// Returns `ConfigFileError` for:\n/// - File not found\n/// - Invalid TOML syntax\n/// - Missing required fields\npub fn load_from_toml(path: \u0026Path) -\u003e Result\u003cConfig, ConfigFileError\u003e {\n    let contents = std::fs::read_to_string(path)\n        .map_err(|_e| ConfigFileError::FileNotFound(path.display().to_string()))?;\n\n    let config: Config =\n        toml::from_str(\u0026contents).map_err(|e| ConfigFileError::TomlParse(e.to_string()))?;\n\n    Ok(config)\n}\n\n/// Load configuration from YAML file.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Loads complete configuration from a YAML format file.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::load_from_yaml;\n/// use std::path::Path;\n///\n/// fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n///     let config = load_from_yaml(Path::new(\"config.yaml\"))?;\n///     println!(\"PostgreSQL host: {}\", config.providers.postgres.host);\n///     Ok(())\n/// }\n/// ```\n///\n/// ## Error Handling\n/// Returns `ConfigFileError` for:\n/// - File not found\n/// - Invalid YAML syntax\n/// - Missing required fields\npub fn load_from_yaml(path: \u0026Path) -\u003e Result\u003cConfig, ConfigFileError\u003e {\n    let contents = std::fs::read_to_string(path)\n        .map_err(|_e| ConfigFileError::FileNotFound(path.display().to_string()))?;\n\n    let config: Config =\n        serde_yaml::from_str(\u0026contents).map_err(|e| ConfigFileError::YamlParse(e.to_string()))?;\n\n    Ok(config)\n}\n\n/// Load configuration from file with auto-detection.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Loads configuration from file, automatically detecting format from\n/// extension.\n///\n/// ## Supported Formats\n/// - `.toml`: TOML format\n/// - `.yaml`: YAML format\n/// - `.yml`: YAML format\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::load_from_file;\n/// use std::path::Path;\n///\n/// fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n///     let config = load_from_file(Path::new(\"config.yaml\"))?;\n///     Ok(())\n/// }\n/// ```\n///\n/// ## Error Handling\n/// Returns `ConfigFileError` for:\n/// - File not found\n/// - Invalid file extension\n/// - Parse errors for detected format\npub fn load_from_file(path: \u0026Path) -\u003e Result\u003cConfig, ConfigFileError\u003e {\n    let extension = path\n        .extension()\n        .and_then(|s| s.to_str())\n        .ok_or(ConfigFileError::NoExtension)?;\n\n    match extension.to_lowercase().as_str() {\n        \"toml\" =\u003e load_from_toml(path),\n        \"yaml\" | \"yml\" =\u003e load_from_yaml(path),\n        other =\u003e Err(ConfigFileError::UnsupportedFormat(other.to_string())),\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::fs;\n    use tempfile::NamedTempFile;\n\n    #[test]\n    fn test_load_from_toml() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"toml\");\n\n        let toml_content = r#\"\n[providers.postgres]\nhost = \"testhost\"\nport = 5433\ndatabase = \"testdb\"\nusername = \"testuser\"\npassword = \"testpass\"\n\n[providers.qdrant]\nhost = \"qdranthost\"\nport = 7333\ncollection = \"test_collection\"\n\n[providers.redis]\nhost = \"redishost\"\nport = 6380\n\n[sync]\nenabled = false\nsync_interval_seconds = 120\n\n[tools]\nenabled = false\nport = 9090\n\n[observability]\nlogging_level = \"debug\"\n\"#;\n        fs::write(\u0026path, toml_content).unwrap();\n\n        let config = load_from_toml(\u0026path).unwrap();\n        assert_eq!(config.providers.postgres.host, \"testhost\");\n        assert_eq!(config.providers.postgres.port, 5433);\n        assert_eq!(config.providers.postgres.database, \"testdb\");\n        assert_eq!(config.providers.qdrant.host, \"qdranthost\");\n        assert_eq!(config.providers.qdrant.port, 7333);\n        assert_eq!(config.providers.redis.host, \"redishost\");\n        assert_eq!(config.sync.enabled, false);\n        assert_eq!(config.sync.sync_interval_seconds, 120);\n        assert_eq!(config.tools.port, 9090);\n        assert_eq!(config.observability.logging_level, \"debug\");\n    }\n\n    #[test]\n    fn test_load_from_yaml() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"yaml\");\n\n        let yaml_content = r#\"\nproviders:\n  postgres:\n    host: testhost\n    port: 5433\n    database: testdb\n    username: testuser\n    password: testpass\n  qdrant:\n    host: qdranthost\n    port: 7333\n    collection: test_collection\n  redis:\n    host: redishost\n    port: 6380\n\nsync:\n  enabled: false\n  sync_interval_seconds: 120\n\ntools:\n  enabled: false\n  port: 9090\n\nobservability:\n  logging_level: debug\n\"#;\n        fs::write(\u0026path, yaml_content).unwrap();\n\n        let config = load_from_yaml(\u0026path).unwrap();\n        assert_eq!(config.providers.postgres.host, \"testhost\");\n        assert_eq!(config.providers.postgres.port, 5433);\n        assert_eq!(config.providers.qdrant.host, \"qdranthost\");\n        assert_eq!(config.sync.enabled, false);\n        assert_eq!(config.tools.port, 9090);\n        assert_eq!(config.observability.logging_level, \"debug\");\n    }\n\n    #[test]\n    fn test_load_from_file_unsupported() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"json\");\n        fs::write(\u0026path, \"{}\").unwrap();\n\n        let result = load_from_file(\u0026path);\n        assert!(matches!(result, Err(ConfigFileError::UnsupportedFormat(_))));\n    }\n\n    #[test]\n    fn test_load_from_file_no_extension() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"\");\n        fs::write(\u0026path, \"\").unwrap();\n\n        let result = load_from_file(\u0026path);\n        assert!(matches!(result, Err(ConfigFileError::NoExtension)));\n    }\n\n    #[test]\n    fn test_load_from_file_auto_detect_toml() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"toml\");\n        let toml_content = r#\"\n[providers.postgres]\nhost = \"autohost\"\n\"#;\n        fs::write(\u0026path, toml_content).unwrap();\n\n        let config = load_from_file(\u0026path).unwrap();\n        assert_eq!(config.providers.postgres.host, \"autohost\");\n    }\n\n    #[test]\n    fn test_load_from_file_auto_detect_yaml() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"yaml\");\n        let yaml_content = r#\"\nproviders:\n  postgres:\n    host: autohost\n\"#;\n        fs::write(\u0026path, yaml_content).unwrap();\n\n        let config = load_from_file(\u0026path).unwrap();\n        assert_eq!(config.providers.postgres.host, \"autohost\");\n    }\n\n    #[test]\n    fn test_load_from_toml_invalid() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"toml\");\n        let invalid_toml = r#\"\n[invalid\n\"#;\n        fs::write(\u0026path, invalid_toml).unwrap();\n\n        let result = load_from_toml(\u0026path);\n        assert!(matches!(result, Err(ConfigFileError::TomlParse(_))));\n    }\n\n    #[test]\n    fn test_load_from_yaml_invalid() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"yaml\");\n        let invalid_yaml = r#\"\ninvalid: [unmatched\n\"#;\n        fs::write(\u0026path, invalid_yaml).unwrap();\n\n        let result = load_from_yaml(\u0026path);\n        assert!(matches!(result, Err(ConfigFileError::YamlParse(_))));\n    }\n\n    #[test]\n    fn test_load_from_toml_not_found() {\n        let path = Path::new(\"/nonexistent/path/config.toml\");\n        let result = load_from_toml(path);\n        assert!(matches!(result, Err(ConfigFileError::FileNotFound(_))));\n    }\n}\n","traces":[{"line":56,"address":[],"length":0,"stats":{"Line":4}},{"line":57,"address":[],"length":0,"stats":{"Line":11}},{"line":58,"address":[],"length":0,"stats":{"Line":7}},{"line":60,"address":[],"length":0,"stats":{"Line":4}},{"line":61,"address":[],"length":0,"stats":{"Line":12}},{"line":63,"address":[],"length":0,"stats":{"Line":2}},{"line":90,"address":[],"length":0,"stats":{"Line":3}},{"line":91,"address":[],"length":0,"stats":{"Line":9}},{"line":92,"address":[],"length":0,"stats":{"Line":3}},{"line":94,"address":[],"length":0,"stats":{"Line":4}},{"line":95,"address":[],"length":0,"stats":{"Line":12}},{"line":97,"address":[],"length":0,"stats":{"Line":2}},{"line":129,"address":[],"length":0,"stats":{"Line":4}},{"line":130,"address":[],"length":0,"stats":{"Line":7}},{"line":132,"address":[],"length":0,"stats":{"Line":10}},{"line":133,"address":[],"length":0,"stats":{"Line":9}},{"line":135,"address":[],"length":0,"stats":{"Line":3}},{"line":136,"address":[],"length":0,"stats":{"Line":5}},{"line":137,"address":[],"length":0,"stats":{"Line":5}},{"line":138,"address":[],"length":0,"stats":{"Line":2}}],"covered":20,"coverable":20},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","governance.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","hot_reload.rs"],"content":"//! # Configuration Hot Reload\n//!\n//! Watches configuration files for changes and reloads configuration\n//! automatically.\n\nuse notify::{EventKind, RecommendedWatcher, RecursiveMode, Watcher};\nuse std::path::{Path, PathBuf};\nuse tracing::debug;\nuse tracing::{error, info, warn};\n\n/// Configuration reload event.\n#[derive(Debug, Clone, PartialEq)]\npub enum ConfigReloadEvent {\n    Ready,\n\n    /// Configuration file changed\n    Changed(PathBuf),\n\n    /// Configuration file was removed\n    Removed(PathBuf),\n\n    /// Configuration file was created\n    Created(PathBuf),\n\n    /// Configuration reload error\n    Error {\n        path: PathBuf,\n        error: String,\n    },\n}\n\n/// Watch a configuration file for changes and emit reload events.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Monitors configuration file for changes and automatically reloads\n/// configuration. Uses `notify` crate for cross-platform file system watching.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::{hot_reload::ConfigReloadEvent, watch_config};\n/// use tokio::signal;\n///\n/// #[tokio::main]\n/// async fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n///     let config_path = std::path::Path::new(\"config.toml\");\n///     let (_tx, mut rx) = watch_config(\u0026config_path).await?;\n///\n///     loop {\n///         tokio::select! {\n///             _ = signal::ctrl_c() =\u003e break,\n///             Some(event) = rx.recv() =\u003e {\n///                 match event {\n///                     ConfigReloadEvent::Changed(path) =\u003e {\n///                         println!(\"Config changed: {:?}\", path);\n///                     }\n///                     ConfigReloadEvent::Error { path, error } =\u003e {\n///                         eprintln!(\"Error reloading {:?}: {}\", path, error);\n///                     }\n///                     _ =\u003e {}\n///                 }\n///             }\n///         }\n///     }\n///\n///     Ok(())\n/// }\n/// ```\n///\n/// ## Event Types\n/// - `Changed`: File content modified\n/// - `Created`: New file created\n/// - `Removed`: File deleted\n/// - `Error`: Failed to reload configuration\n///\n/// ## Performance\n/// Uses debouncing to avoid multiple reload events for single file change.\npub async fn watch_config(\n    config_path: \u0026Path,\n) -\u003e Result\u003c\n    (\n        tokio::sync::mpsc::Sender\u003cConfigReloadEvent\u003e,\n        tokio::sync::mpsc::Receiver\u003cConfigReloadEvent\u003e,\n    ),\n    Box\u003cdyn std::error::Error\u003e,\n\u003e {\n    let config_path = config_path.to_path_buf();\n\n    if !config_path.exists() {\n        return Err(Box::new(std::io::Error::new(\n            std::io::ErrorKind::NotFound,\n            format!(\"Config file not found: {:?}\", config_path),\n        )));\n    }\n\n    let (tx, rx) = tokio::sync::mpsc::channel(100);\n    let tx_task = tx.clone();\n    let path_task = config_path.clone();\n\n    tokio::spawn(async move {\n        let (event_tx, mut event_rx) = tokio::sync::mpsc::channel(100);\n        let mut watcher = match RecommendedWatcher::new(\n            move |res| {\n                let _ = event_tx.blocking_send(res);\n            },\n            notify::Config::default(),\n        ) {\n            Ok(w) =\u003e w,\n            Err(e) =\u003e {\n                let error_msg = format!(\"Failed to create file watcher: {}\", e);\n                error!(\"{}\", error_msg);\n\n                let _ = tx_task\n                    .send(ConfigReloadEvent::Error {\n                        path: path_task,\n                        error: error_msg,\n                    })\n                    .await;\n\n                return;\n            }\n        };\n\n        if let Err(e) = watcher.watch(\u0026config_path, RecursiveMode::NonRecursive) {\n            let error_msg = format!(\"Failed to watch config file: {}\", e);\n            error!(\"{}\", error_msg);\n\n            let _ = tx_task\n                .send(ConfigReloadEvent::Error {\n                    path: path_task,\n                    error: error_msg,\n                })\n                .await;\n\n            return;\n        }\n\n        info!(\"Watching config file: {:?}\", config_path);\n\n        let _ = tx_task.send(ConfigReloadEvent::Ready).await;\n\n        loop {\n            tokio::select! {\n                _ = tx_task.closed() =\u003e {\n                    debug!(\"Receiver dropped, stopping watcher for {:?}\", config_path);\n                    break;\n                }\n                event_result = event_rx.recv() =\u003e {\n                    let Some(event_result) = event_result else {\n                        break;\n                    };\n\n                    match event_result {\n                        Ok(event) =\u003e {\n                            if !event.paths.is_empty() {\n                                let path = event.paths[0].clone();\n                                let reload_event = match event.kind {\n                                    EventKind::Create(_) | EventKind::Modify(_) =\u003e {\n                                        info!(\"Config file updated: {:?}\", path);\n                                        ConfigReloadEvent::Changed(path)\n                                    }\n                                    EventKind::Remove(_) =\u003e {\n                                        warn!(\"Config file removed: {:?}\", path);\n                                        ConfigReloadEvent::Removed(path)\n                                    }\n                                    _ =\u003e {\n                                        debug!(\"Ignoring event: {:?}\", event.kind);\n                                        continue;\n                                    }\n                                };\n\n                                if let Err(e) = tx_task.send(reload_event).await {\n                                    error!(\"Failed to send config reload event: {}\", e);\n                                    break;\n                                }\n                            }\n                        }\n                        Err(e) =\u003e {\n                            warn!(\"Watch error: {}\", e);\n                        }\n                    }\n                }\n            }\n        }\n    });\n\n    Ok((tx, rx))\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::fs;\n    use tempfile::NamedTempFile;\n    use tokio::time::Duration;\n\n    #[test]\n    fn test_config_reload_event_created() {\n        let path = PathBuf::from(\"/test/config.toml\");\n        let event = ConfigReloadEvent::Created(path.clone());\n        assert!(matches!(event, ConfigReloadEvent::Created(_)));\n        assert_eq!(event, ConfigReloadEvent::Created(path));\n    }\n\n    #[test]\n    fn test_config_reload_event_removed() {\n        let path = PathBuf::from(\"/test/config.toml\");\n        let event = ConfigReloadEvent::Removed(path.clone());\n        assert!(matches!(event, ConfigReloadEvent::Removed(_)));\n        assert_eq!(event, ConfigReloadEvent::Removed(path));\n    }\n\n    #[test]\n    fn test_config_reload_event_changed() {\n        let path = PathBuf::from(\"/test/config.toml\");\n        let event = ConfigReloadEvent::Changed(path.clone());\n        assert!(matches!(event, ConfigReloadEvent::Changed(_)));\n        assert_eq!(event, ConfigReloadEvent::Changed(path));\n    }\n\n    #[test]\n    fn test_config_reload_event_error() {\n        let path = PathBuf::from(\"/test/config.toml\");\n        let event = ConfigReloadEvent::Error {\n            path: path.clone(),\n            error: \"Test error\".to_string(),\n        };\n        assert!(matches!(event, ConfigReloadEvent::Error { .. }));\n        assert_eq!(\n            event,\n            ConfigReloadEvent::Error {\n                path,\n                error: \"Test error\".to_string()\n            }\n        );\n    }\n\n    #[tokio::test]\n    async fn test_tokio_config_reload_event_created() {\n        let path = PathBuf::from(\"/test/config.toml\");\n        let event = ConfigReloadEvent::Created(path.clone());\n        assert!(matches!(event, ConfigReloadEvent::Created(_)));\n        assert_eq!(event, ConfigReloadEvent::Created(path));\n    }\n\n    #[tokio::test]\n    async fn test_tokio_config_reload_event_removed() {\n        let path = PathBuf::from(\"/test/config.toml\");\n        let event = ConfigReloadEvent::Removed(path.clone());\n        assert!(matches!(event, ConfigReloadEvent::Removed(_)));\n        assert_eq!(event, ConfigReloadEvent::Removed(path));\n    }\n\n    #[tokio::test]\n    async fn test_tokio_config_reload_event_error() {\n        let path = PathBuf::from(\"/test/config.toml\");\n        let event = ConfigReloadEvent::Error {\n            path: path.clone(),\n            error: \"Test error\".to_string(),\n        };\n        assert!(matches!(event, ConfigReloadEvent::Error { .. }));\n        assert_eq!(\n            event,\n            ConfigReloadEvent::Error {\n                path,\n                error: \"Test error\".to_string()\n            }\n        );\n    }\n\n    #[tokio::test]\n    async fn test_watch_config_emits_events() {\n        let temp_file = NamedTempFile::new().unwrap();\n        let config_content = r#\"\n[providers.postgres]\nhost = \"testhost\"\n\"#;\n        fs::write(temp_file.path(), config_content).unwrap();\n\n        let (_tx, mut rx) = watch_config(temp_file.path()).await.unwrap();\n\n        let ready_event = tokio::time::timeout(Duration::from_secs(5), rx.recv())\n            .await\n            .expect(\"Timeout waiting for Ready event\")\n            .expect(\"No event received\");\n        assert_eq!(ready_event, ConfigReloadEvent::Ready);\n\n        fs::write(temp_file.path(), \"[providers.postgres]\\nhost = \\\"updated\\\"\").unwrap();\n\n        let event = tokio::time::timeout(Duration::from_secs(5), rx.recv())\n            .await\n            .expect(\"Timeout waiting for config change event\")\n            .expect(\"No event received\");\n\n        match event {\n            ConfigReloadEvent::Changed(path) =\u003e {\n                assert_eq!(\n                    path.canonicalize().unwrap(),\n                    temp_file.path().canonicalize().unwrap()\n                );\n            }\n            _ =\u003e panic!(\"Expected Changed event, got {:?}\", event),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_watch_config_handles_create() {\n        let temp_dir = tempfile::tempdir().unwrap();\n        let config_path = temp_dir.path().join(\"config.toml\");\n\n        fs::write(\u0026config_path, \"initial\").unwrap();\n\n        let (_tx, mut rx) = watch_config(\u0026config_path).await.unwrap();\n\n        let ready_event = tokio::time::timeout(Duration::from_secs(5), rx.recv())\n            .await\n            .expect(\"Timeout waiting for Ready event\")\n            .expect(\"No event received\");\n        assert_eq!(ready_event, ConfigReloadEvent::Ready);\n\n        fs::write(\u0026config_path, \"updated\").unwrap();\n\n        let event = tokio::time::timeout(Duration::from_secs(5), rx.recv())\n            .await\n            .expect(\"Timeout waiting for config change event\")\n            .expect(\"No event received\");\n\n        match event {\n            ConfigReloadEvent::Changed(path) =\u003e {\n                assert_eq!(\n                    path.canonicalize().unwrap(),\n                    config_path.canonicalize().unwrap()\n                );\n            }\n            _ =\u003e panic!(\"Expected Changed event, got {:?}\", event),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_watch_config_nonexistent_file() {\n        let temp_dir = tempfile::tempdir().unwrap();\n        let config_path = temp_dir.path().join(\"nonexistent.toml\");\n\n        let result = watch_config(\u0026config_path).await;\n        assert!(result.is_err());\n\n        let error = result.unwrap_err();\n        let error_str = error.to_string();\n        assert!(error_str.contains(\"not found\") || error_str.contains(\"NotFound\"));\n    }\n\n    #[tokio::test]\n    async fn test_watch_config_error_handling() {\n        let temp_file = NamedTempFile::new().unwrap();\n        fs::write(temp_file.path(), \"test\").unwrap();\n\n        let (_tx, mut rx) = watch_config(temp_file.path()).await.unwrap();\n\n        let _ = tokio::time::timeout(Duration::from_secs(5), rx.recv())\n            .await\n            .expect(\"Timeout waiting for Ready event\");\n\n        drop(rx);\n        tokio::time::sleep(Duration::from_millis(100)).await;\n    }\n\n    #[tokio::test]\n    async fn test_watch_config_removed_file() {\n        let temp_dir = tempfile::tempdir().unwrap();\n        let config_path = temp_dir.path().join(\"config.toml\");\n\n        fs::write(\u0026config_path, \"initial\").unwrap();\n\n        let (_tx, mut rx) = watch_config(\u0026config_path).await.unwrap();\n\n        let ready_event = tokio::time::timeout(Duration::from_secs(5), rx.recv())\n            .await\n            .expect(\"Timeout waiting for Ready event\")\n            .expect(\"No event received\");\n        assert_eq!(ready_event, ConfigReloadEvent::Ready);\n\n        fs::remove_file(\u0026config_path).unwrap();\n\n        let event = tokio::time::timeout(Duration::from_secs(5), rx.recv()).await;\n\n        if let Ok(Some(event)) = event {\n            match event {\n                ConfigReloadEvent::Removed(path) =\u003e {\n                    assert_eq!(\n                        path.canonicalize().unwrap(),\n                        config_path.canonicalize().unwrap()\n                    );\n                }\n                ConfigReloadEvent::Error { path, error } =\u003e {\n                    assert_eq!(\n                        path.canonicalize().unwrap(),\n                        config_path.canonicalize().unwrap()\n                    );\n                    assert!(!error.is_empty());\n                }\n                _ =\u003e {}\n            }\n        }\n    }\n\n    #[test]\n    fn test_config_reload_event_ready() {\n        let event = ConfigReloadEvent::Ready;\n        assert!(matches!(event, ConfigReloadEvent::Ready));\n        assert_eq!(event, ConfigReloadEvent::Ready);\n    }\n\n    #[test]\n    fn test_config_reload_event_partial_eq() {\n        let path1 = PathBuf::from(\"/test/config.toml\");\n        let path2 = PathBuf::from(\"/test/config.toml\");\n        let path3 = PathBuf::from(\"/other/config.toml\");\n\n        // Test equality\n        assert_eq!(\n            ConfigReloadEvent::Changed(path1.clone()),\n            ConfigReloadEvent::Changed(path2.clone())\n        );\n\n        assert_eq!(\n            ConfigReloadEvent::Created(path1.clone()),\n            ConfigReloadEvent::Created(path2.clone())\n        );\n\n        assert_eq!(\n            ConfigReloadEvent::Removed(path1.clone()),\n            ConfigReloadEvent::Removed(path2.clone())\n        );\n\n        assert_eq!(\n            ConfigReloadEvent::Error {\n                path: path1.clone(),\n                error: \"test\".to_string()\n            },\n            ConfigReloadEvent::Error {\n                path: path2.clone(),\n                error: \"test\".to_string()\n            }\n        );\n\n        // Test inequality\n        assert_ne!(\n            ConfigReloadEvent::Changed(path1.clone()),\n            ConfigReloadEvent::Changed(path3.clone())\n        );\n\n        assert_ne!(\n            ConfigReloadEvent::Changed(path1.clone()),\n            ConfigReloadEvent::Created(path1.clone())\n        );\n\n        assert_ne!(\n            ConfigReloadEvent::Error {\n                path: path1.clone(),\n                error: \"error1\".to_string()\n            },\n            ConfigReloadEvent::Error {\n                path: path1.clone(),\n                error: \"error2\".to_string()\n            }\n        );\n    }\n}\n","traces":[{"line":79,"address":[],"length":0,"stats":{"Line":5}},{"line":88,"address":[],"length":0,"stats":{"Line":15}},{"line":90,"address":[],"length":0,"stats":{"Line":5}},{"line":91,"address":[],"length":0,"stats":{"Line":3}},{"line":92,"address":[],"length":0,"stats":{"Line":2}},{"line":93,"address":[],"length":0,"stats":{"Line":1}},{"line":97,"address":[],"length":0,"stats":{"Line":12}},{"line":98,"address":[],"length":0,"stats":{"Line":12}},{"line":99,"address":[],"length":0,"stats":{"Line":12}},{"line":101,"address":[],"length":0,"stats":{"Line":8}},{"line":102,"address":[],"length":0,"stats":{"Line":12}},{"line":103,"address":[],"length":0,"stats":{"Line":8}},{"line":104,"address":[],"length":0,"stats":{"Line":12}},{"line":105,"address":[],"length":0,"stats":{"Line":24}},{"line":107,"address":[],"length":0,"stats":{"Line":4}},{"line":109,"address":[],"length":0,"stats":{"Line":8}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":12}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":4}},{"line":141,"address":[],"length":0,"stats":{"Line":16}},{"line":144,"address":[],"length":0,"stats":{"Line":16}},{"line":145,"address":[],"length":0,"stats":{"Line":32}},{"line":146,"address":[],"length":0,"stats":{"Line":1}},{"line":147,"address":[],"length":0,"stats":{"Line":1}},{"line":149,"address":[],"length":0,"stats":{"Line":44}},{"line":150,"address":[],"length":0,"stats":{"Line":24}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":12}},{"line":155,"address":[],"length":0,"stats":{"Line":12}},{"line":156,"address":[],"length":0,"stats":{"Line":12}},{"line":157,"address":[],"length":0,"stats":{"Line":36}},{"line":158,"address":[],"length":0,"stats":{"Line":24}},{"line":160,"address":[],"length":0,"stats":{"Line":11}},{"line":161,"address":[],"length":0,"stats":{"Line":11}},{"line":164,"address":[],"length":0,"stats":{"Line":1}},{"line":165,"address":[],"length":0,"stats":{"Line":1}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":48}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":4}}],"covered":36,"coverable":60},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","lib.rs"],"content":"//! # Configuration System\n//!\n//! Centralized configuration management for the Memory-Knowledge system.\n//!\n//! This crate provides:\n//! - Configuration structures for all system components\n//! - Environment variable loading (12-factor app principles)\n//! - Configuration file loading (TOML/YAML)\n//! - Configuration precedence (CLI \u003e env \u003e file \u003e defaults)\n//! - Configuration validation\n//! - Hot reload functionality\n//!\n//! # Best Practices\n//!\n//! - Uses `validator` crate for input validation\n//! - Follows 12-factor app configuration principles\n//! - Provides clear error messages for invalid configuration\n//! - Thread-safe configuration access\n\npub mod config;\npub mod file_loader;\npub mod hot_reload;\npub mod loader;\npub mod precedence;\n\npub use config::{\n    Config, DeploymentConfig, MemoryConfig, ObservabilityConfig, ProviderConfig, SyncConfig,\n    ToolConfig,\n};\npub use file_loader::{load_from_file, load_from_toml, load_from_yaml};\npub use hot_reload::watch_config;\npub use loader::load_from_env;\npub use precedence::merge_configs;\npub use validator::Validate;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","loader.rs"],"content":"//! # Environment Variable Loader\n//!\n//! Loads configuration from environment variables following 12-factor app\n//! principles.\n//!\n//! # Naming Convention\n//! - `MK_*`: Memory-related settings\n//! - `KK_*`: Knowledge-related settings\n//! - `SY_*`: Sync-related settings\n//! - `TL_*`: Tool-related settings\n//! - `PG_*`: PostgreSQL settings\n//! - `QD_*`: Qdrant settings\n//! - `RD_*`: Redis settings\n//! - `OB_*`: Observability settings\n\nuse crate::config::{\n    Config, MemoryConfig, ObservabilityConfig, PostgresConfig, ProviderConfig, QdrantConfig,\n    RedisConfig, SyncConfig, ToolConfig,\n};\nuse std::env;\n\n/// Load configuration from environment variables.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Loads configuration from environment variables following 12-factor app\n/// principles. Environment variables override default values but can be\n/// overridden by CLI arguments.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::load_from_env;\n///\n/// fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n///     let config = load_from_env()?;\n///     println!(\"PostgreSQL host: {}\", config.providers.postgres.host);\n///     Ok(())\n/// }\n/// ```\n///\n/// ## Environment Variables\n/// ### General Settings\n/// - `MK_LOG_LEVEL`: Logging level (trace/debug/info/warn/error)\n///\n/// ### PostgreSQL Settings (`PG_*`)\n/// - `PG_HOST`: Database host (default: \"localhost\")\n/// - `PG_PORT`: Database port (default: 5432)\n/// - `PG_DATABASE`: Database name (default: \"memory_knowledge\")\n/// - `PG_USERNAME`: Database user (default: \"postgres\")\n/// - `PG_PASSWORD`: Database password (default: \"\")\n/// - `PG_POOL_SIZE`: Connection pool size (default: 10)\n/// - `PG_TIMEOUT_SECONDS`: Connection timeout in seconds (default: 30)\n///\n/// ### Qdrant Settings (`QD_*`)\n/// - `QD_HOST`: Qdrant host (default: \"localhost\")\n/// - `QD_PORT`: Qdrant port (default: 6333)\n/// - `QD_COLLECTION`: Collection name (default: \"memory_embeddings\")\n/// - `QD_TIMEOUT_SECONDS`: Request timeout in seconds (default: 30)\n///\n/// ### Redis Settings (`RD_*`)\n/// - `RD_HOST`: Redis host (default: \"localhost\")\n/// - `RD_PORT`: Redis port (default: 6379)\n/// - `RD_DB`: Redis database number (default: 0)\n/// - `RD_POOL_SIZE`: Connection pool size (default: 10)\n/// - `RD_TIMEOUT_SECONDS`: Connection timeout in seconds (default: 30)\n///\n/// ### Sync Settings (`SY_*`)\n/// - `SY_ENABLED`: Enable sync (true/false, default: true)\n/// - `SY_SYNC_INTERVAL_SECONDS`: Sync interval (default: 60)\n/// - `SY_BATCH_SIZE`: Batch size (default: 100)\n/// - `SY_CHECKPOINT_ENABLED`: Enable checkpointing (true/false, default: true)\n/// - `SY_CONFLICT_RESOLUTION`: Conflict resolution\n///   (prefer_knowledge/prefer_memory/manual, default: prefer_knowledge)\n///\n/// ### Tools Settings (`TL_*`)\n/// - `TL_ENABLED`: Enable MCP server (true/false, default: true)\n/// - `TL_HOST`: Server host (default: \"localhost\")\n/// - `TL_PORT`: Server port (default: 8080)\n/// - `TL_API_KEY`: API key for authentication (optional)\n/// - `TL_RATE_LIMIT_REQUESTS_PER_MINUTE`: Rate limit (default: 60)\n///\n/// ### Observability Settings (`OB_*`)\n/// - `OB_METRICS_ENABLED`: Enable metrics (true/false, default: true)\n/// - `OB_TRACING_ENABLED`: Enable tracing (true/false, default: true)\n/// - `OB_LOGGING_LEVEL`: Logging level (trace/debug/info/warn/error, default:\n///   \"info\")\n/// - `OB_METRICS_PORT`: Metrics server port (default: 9090)\npub fn load_from_env() -\u003e Result\u003cConfig, Box\u003cdyn std::error::Error\u003e\u003e {\n    let config = Config {\n        providers: load_provider_from_env()?,\n        sync: load_sync_from_env()?,\n        memory: load_memory_from_env()?,\n        tools: load_tools_from_env()?,\n        observability: load_observability_from_env()?,\n        deployment: load_deployment_from_env()?,\n    };\n\n    Ok(config)\n}\n\nfn load_deployment_from_env() -\u003e Result\u003ccrate::config::DeploymentConfig, Box\u003cdyn std::error::Error\u003e\u003e\n{\n    Ok(crate::config::DeploymentConfig {\n        mode: env::var(\"AETERNA_DEPLOYMENT_MODE\").unwrap_or_else(|_| \"local\".to_string()),\n        remote_url: env::var(\"AETERNA_REMOTE_GOVERNANCE_URL\").ok(),\n        sync_enabled: parse_env(\"AETERNA_SYNC_ENABLED\").unwrap_or(true),\n    })\n}\n\nfn load_provider_from_env() -\u003e Result\u003cProviderConfig, Box\u003cdyn std::error::Error\u003e\u003e {\n    Ok(ProviderConfig {\n        postgres: load_postgres_from_env()?,\n        qdrant: load_qdrant_from_env()?,\n        redis: load_redis_from_env()?,\n    })\n}\n\nfn load_postgres_from_env() -\u003e Result\u003cPostgresConfig, Box\u003cdyn std::error::Error\u003e\u003e {\n    Ok(PostgresConfig {\n        host: env::var(\"PG_HOST\").unwrap_or_else(|_| \"localhost\".to_string()),\n        port: parse_env(\"PG_PORT\").unwrap_or(5432),\n        database: env::var(\"PG_DATABASE\").unwrap_or_else(|_| \"memory_knowledge\".to_string()),\n        username: env::var(\"PG_USERNAME\").unwrap_or_else(|_| \"postgres\".to_string()),\n        password: env::var(\"PG_PASSWORD\").unwrap_or_default(),\n        pool_size: parse_env(\"PG_POOL_SIZE\").unwrap_or(10),\n        timeout_seconds: parse_env(\"PG_TIMEOUT_SECONDS\").unwrap_or(30),\n    })\n}\n\nfn load_qdrant_from_env() -\u003e Result\u003cQdrantConfig, Box\u003cdyn std::error::Error\u003e\u003e {\n    Ok(QdrantConfig {\n        host: env::var(\"QD_HOST\").unwrap_or_else(|_| \"localhost\".to_string()),\n        port: parse_env(\"QD_PORT\").unwrap_or(6333),\n        collection: env::var(\"QD_COLLECTION\").unwrap_or_else(|_| \"memory_embeddings\".to_string()),\n        timeout_seconds: parse_env(\"QD_TIMEOUT_SECONDS\").unwrap_or(30),\n    })\n}\n\nfn load_redis_from_env() -\u003e Result\u003cRedisConfig, Box\u003cdyn std::error::Error\u003e\u003e {\n    Ok(RedisConfig {\n        host: env::var(\"RD_HOST\").unwrap_or_else(|_| \"localhost\".to_string()),\n        port: parse_env(\"RD_PORT\").unwrap_or(6379),\n        db: parse_env(\"RD_DB\").unwrap_or(0),\n        pool_size: parse_env(\"RD_POOL_SIZE\").unwrap_or(10),\n        timeout_seconds: parse_env(\"RD_TIMEOUT_SECONDS\").unwrap_or(30),\n    })\n}\n\nfn load_sync_from_env() -\u003e Result\u003cSyncConfig, Box\u003cdyn std::error::Error\u003e\u003e {\n    Ok(SyncConfig {\n        enabled: parse_env(\"SY_ENABLED\").unwrap_or(true),\n        sync_interval_seconds: parse_env(\"SY_SYNC_INTERVAL_SECONDS\").unwrap_or(60),\n        batch_size: parse_env(\"SY_BATCH_SIZE\").unwrap_or(100),\n        checkpoint_enabled: parse_env(\"SY_CHECKPOINT_ENABLED\").unwrap_or(true),\n        conflict_resolution: env::var(\"SY_CONFLICT_RESOLUTION\")\n            .unwrap_or_else(|_| \"prefer_knowledge\".to_string()),\n    })\n}\n\nfn load_memory_from_env() -\u003e Result\u003cMemoryConfig, Box\u003cdyn std::error::Error\u003e\u003e {\n    Ok(MemoryConfig {\n        promotion_threshold: parse_env(\"MK_PROMOTION_THRESHOLD\").unwrap_or(0.8),\n    })\n}\n\nfn load_tools_from_env() -\u003e Result\u003cToolConfig, Box\u003cdyn std::error::Error\u003e\u003e {\n    Ok(ToolConfig {\n        enabled: parse_env(\"TL_ENABLED\").unwrap_or(true),\n        host: env::var(\"TL_HOST\").unwrap_or_else(|_| \"localhost\".to_string()),\n        port: parse_env(\"TL_PORT\").unwrap_or(8080),\n        api_key: env::var(\"TL_API_KEY\").ok(),\n        rate_limit_requests_per_minute: parse_env(\"TL_RATE_LIMIT_REQUESTS_PER_MINUTE\")\n            .unwrap_or(60),\n    })\n}\n\nfn load_observability_from_env() -\u003e Result\u003cObservabilityConfig, Box\u003cdyn std::error::Error\u003e\u003e {\n    Ok(ObservabilityConfig {\n        metrics_enabled: parse_env(\"OB_METRICS_ENABLED\").unwrap_or(true),\n        tracing_enabled: parse_env(\"OB_TRACING_ENABLED\").unwrap_or(true),\n        logging_level: env::var(\"OB_LOGGING_LEVEL\").unwrap_or_else(|_| \"info\".to_string()),\n        metrics_port: parse_env(\"OB_METRICS_PORT\").unwrap_or(9090),\n    })\n}\n\nfn parse_env\u003cT\u003e(key: \u0026str) -\u003e Result\u003cT, Box\u003cdyn std::error::Error\u003e\u003e\nwhere\n    T: std::str::FromStr,\n    T::Err: std::error::Error + Send + Sync + 'static,\n{\n    match env::var(key) {\n        Ok(s) =\u003e s\n            .parse::\u003cT\u003e()\n            .map_err(|e| Box::new(e) as Box\u003cdyn std::error::Error\u003e),\n        Err(e) =\u003e Err(Box::new(e) as Box\u003cdyn std::error::Error\u003e),\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use serial_test::serial;\n\n    #[test]\n    #[serial]\n    fn test_load_from_env_defaults() {\n        unsafe {\n            env::remove_var(\"PG_HOST\");\n            env::remove_var(\"QD_HOST\");\n            env::remove_var(\"RD_HOST\");\n            env::remove_var(\"SY_ENABLED\");\n            env::remove_var(\"TL_PORT\");\n            env::remove_var(\"OB_LOGGING_LEVEL\");\n        }\n        let config = load_from_env().unwrap();\n        assert_eq!(config.providers.postgres.host, \"localhost\");\n        assert_eq!(config.providers.qdrant.host, \"localhost\");\n        assert_eq!(config.providers.redis.host, \"localhost\");\n        assert_eq!(config.sync.enabled, true);\n        assert_eq!(config.tools.port, 8080);\n        assert_eq!(config.observability.logging_level, \"info\");\n    }\n\n    #[test]\n    #[serial]\n    fn test_load_from_env_overrides() {\n        unsafe {\n            env::set_var(\"PG_HOST\", \"testhost\");\n            env::set_var(\"PG_PORT\", \"9999\");\n            env::set_var(\"SY_ENABLED\", \"false\");\n        }\n\n        let config = load_from_env().unwrap();\n        assert_eq!(config.providers.postgres.host, \"testhost\");\n        assert_eq!(config.providers.postgres.port, 9999);\n        assert_eq!(config.sync.enabled, false);\n\n        unsafe {\n            env::remove_var(\"PG_HOST\");\n            env::remove_var(\"PG_PORT\");\n            env::remove_var(\"SY_ENABLED\");\n        }\n    }\n\n    #[test]\n    fn test_parse_env_missing() {\n        let result: Result\u003cu32, _\u003e = parse_env(\"NONEXISTENT_VAR\");\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_parse_env_valid_string() {\n        unsafe {\n            env::set_var(\"TEST_VAR\", \"test_value\");\n        }\n        let result: Result\u003cString, _\u003e = parse_env(\"TEST_VAR\");\n        assert_eq!(result.unwrap(), \"test_value\");\n        unsafe {\n            env::remove_var(\"TEST_VAR\");\n        }\n    }\n\n    #[test]\n    fn test_parse_env_valid_number() {\n        unsafe {\n            env::set_var(\"TEST_VAR\", \"123\");\n        }\n        let result: Result\u003cu32, _\u003e = parse_env(\"TEST_VAR\");\n        assert_eq!(result.unwrap(), 123);\n        unsafe {\n            env::remove_var(\"TEST_VAR\");\n        }\n    }\n\n    #[test]\n    fn test_parse_env_valid_number_with_parse_env() {\n        unsafe {\n            env::set_var(\"TEST_VAR\", \"123\");\n        }\n        let result: Result\u003cu32, _\u003e = parse_env(\"TEST_VAR\");\n        assert_eq!(result.unwrap(), 123);\n        unsafe {\n            env::remove_var(\"TEST_VAR\");\n        }\n    }\n\n    #[test]\n    fn test_parse_env_invalid_number() {\n        unsafe {\n            env::set_var(\"TEST_VAR\", \"not_a_number\");\n        }\n        let result: Result\u003cu32, _\u003e = parse_env(\"TEST_VAR\");\n        assert!(result.is_err());\n        unsafe {\n            env::remove_var(\"TEST_VAR\");\n        }\n    }\n\n    #[test]\n    #[serial]\n    fn test_load_postgres_from_env() {\n        unsafe {\n            env::set_var(\"PG_HOST\", \"customhost\");\n            env::set_var(\"PG_PORT\", \"5433\");\n            env::set_var(\"PG_DATABASE\", \"testdb\");\n            env::set_var(\"PG_USERNAME\", \"testuser\");\n            env::set_var(\"PG_PASSWORD\", \"testpass\");\n            env::set_var(\"PG_POOL_SIZE\", \"20\");\n            env::set_var(\"PG_TIMEOUT_SECONDS\", \"60\");\n        }\n\n        let postgres = load_postgres_from_env().unwrap();\n\n        unsafe {\n            env::remove_var(\"PG_HOST\");\n            env::remove_var(\"PG_PORT\");\n            env::remove_var(\"PG_DATABASE\");\n            env::remove_var(\"PG_USERNAME\");\n            env::remove_var(\"PG_PASSWORD\");\n            env::remove_var(\"PG_POOL_SIZE\");\n            env::remove_var(\"PG_TIMEOUT_SECONDS\");\n        }\n\n        assert_eq!(postgres.host, \"customhost\");\n        assert_eq!(postgres.port, 5433);\n        assert_eq!(postgres.database, \"testdb\");\n        assert_eq!(postgres.username, \"testuser\");\n        assert_eq!(postgres.password, \"testpass\");\n        assert_eq!(postgres.pool_size, 20);\n        assert_eq!(postgres.timeout_seconds, 60);\n    }\n\n    #[test]\n    #[serial]\n    fn test_load_qdrant_from_env() {\n        unsafe {\n            env::set_var(\"QD_HOST\", \"qdranthost\");\n            env::set_var(\"QD_PORT\", \"7333\");\n            env::set_var(\"QD_COLLECTION\", \"test_collection\");\n            env::set_var(\"QD_TIMEOUT_SECONDS\", \"45\");\n        }\n\n        let qdrant = load_qdrant_from_env().unwrap();\n        assert_eq!(qdrant.host, \"qdranthost\");\n        assert_eq!(qdrant.port, 7333);\n        assert_eq!(qdrant.collection, \"test_collection\");\n        assert_eq!(qdrant.timeout_seconds, 45);\n\n        unsafe {\n            env::remove_var(\"QD_HOST\");\n            env::remove_var(\"QD_PORT\");\n            env::remove_var(\"QD_COLLECTION\");\n            env::remove_var(\"QD_TIMEOUT_SECONDS\");\n        }\n    }\n\n    #[test]\n    #[serial]\n    fn test_load_redis_from_env() {\n        unsafe {\n            env::set_var(\"RD_HOST\", \"redishost\");\n            env::set_var(\"RD_PORT\", \"6380\");\n            env::set_var(\"RD_DB\", \"1\");\n            env::set_var(\"RD_POOL_SIZE\", \"15\");\n            env::set_var(\"RD_TIMEOUT_SECONDS\", \"45\");\n        }\n\n        let redis = load_redis_from_env().unwrap();\n        assert_eq!(redis.host, \"redishost\");\n        assert_eq!(redis.port, 6380);\n        assert_eq!(redis.db, 1);\n        assert_eq!(redis.pool_size, 15);\n        assert_eq!(redis.timeout_seconds, 45);\n\n        unsafe {\n            env::remove_var(\"RD_HOST\");\n            env::remove_var(\"RD_PORT\");\n            env::remove_var(\"RD_DB\");\n            env::remove_var(\"RD_POOL_SIZE\");\n            env::remove_var(\"RD_TIMEOUT_SECONDS\");\n        }\n    }\n}\n","traces":[{"line":89,"address":[],"length":0,"stats":{"Line":2}},{"line":91,"address":[],"length":0,"stats":{"Line":2}},{"line":92,"address":[],"length":0,"stats":{"Line":2}},{"line":93,"address":[],"length":0,"stats":{"Line":2}},{"line":94,"address":[],"length":0,"stats":{"Line":2}},{"line":95,"address":[],"length":0,"stats":{"Line":2}},{"line":96,"address":[],"length":0,"stats":{"Line":2}},{"line":99,"address":[],"length":0,"stats":{"Line":2}},{"line":102,"address":[],"length":0,"stats":{"Line":2}},{"line":105,"address":[],"length":0,"stats":{"Line":8}},{"line":106,"address":[],"length":0,"stats":{"Line":4}},{"line":107,"address":[],"length":0,"stats":{"Line":6}},{"line":111,"address":[],"length":0,"stats":{"Line":2}},{"line":113,"address":[],"length":0,"stats":{"Line":2}},{"line":114,"address":[],"length":0,"stats":{"Line":2}},{"line":115,"address":[],"length":0,"stats":{"Line":2}},{"line":119,"address":[],"length":0,"stats":{"Line":3}},{"line":121,"address":[],"length":0,"stats":{"Line":8}},{"line":122,"address":[],"length":0,"stats":{"Line":9}},{"line":123,"address":[],"length":0,"stats":{"Line":10}},{"line":124,"address":[],"length":0,"stats":{"Line":10}},{"line":125,"address":[],"length":0,"stats":{"Line":6}},{"line":126,"address":[],"length":0,"stats":{"Line":9}},{"line":127,"address":[],"length":0,"stats":{"Line":9}},{"line":131,"address":[],"length":0,"stats":{"Line":3}},{"line":133,"address":[],"length":0,"stats":{"Line":10}},{"line":134,"address":[],"length":0,"stats":{"Line":9}},{"line":135,"address":[],"length":0,"stats":{"Line":10}},{"line":136,"address":[],"length":0,"stats":{"Line":9}},{"line":140,"address":[],"length":0,"stats":{"Line":3}},{"line":142,"address":[],"length":0,"stats":{"Line":10}},{"line":143,"address":[],"length":0,"stats":{"Line":9}},{"line":144,"address":[],"length":0,"stats":{"Line":9}},{"line":145,"address":[],"length":0,"stats":{"Line":9}},{"line":146,"address":[],"length":0,"stats":{"Line":9}},{"line":150,"address":[],"length":0,"stats":{"Line":2}},{"line":152,"address":[],"length":0,"stats":{"Line":6}},{"line":153,"address":[],"length":0,"stats":{"Line":6}},{"line":154,"address":[],"length":0,"stats":{"Line":6}},{"line":155,"address":[],"length":0,"stats":{"Line":6}},{"line":156,"address":[],"length":0,"stats":{"Line":2}},{"line":157,"address":[],"length":0,"stats":{"Line":6}},{"line":161,"address":[],"length":0,"stats":{"Line":2}},{"line":162,"address":[],"length":0,"stats":{"Line":2}},{"line":163,"address":[],"length":0,"stats":{"Line":4}},{"line":167,"address":[],"length":0,"stats":{"Line":2}},{"line":169,"address":[],"length":0,"stats":{"Line":6}},{"line":170,"address":[],"length":0,"stats":{"Line":8}},{"line":171,"address":[],"length":0,"stats":{"Line":6}},{"line":172,"address":[],"length":0,"stats":{"Line":4}},{"line":173,"address":[],"length":0,"stats":{"Line":4}},{"line":174,"address":[],"length":0,"stats":{"Line":2}},{"line":178,"address":[],"length":0,"stats":{"Line":2}},{"line":180,"address":[],"length":0,"stats":{"Line":6}},{"line":181,"address":[],"length":0,"stats":{"Line":6}},{"line":182,"address":[],"length":0,"stats":{"Line":8}},{"line":183,"address":[],"length":0,"stats":{"Line":6}},{"line":187,"address":[],"length":0,"stats":{"Line":56}},{"line":192,"address":[],"length":0,"stats":{"Line":56}},{"line":193,"address":[],"length":0,"stats":{"Line":30}},{"line":195,"address":[],"length":0,"stats":{"Line":18}},{"line":196,"address":[],"length":0,"stats":{"Line":123}}],"covered":62,"coverable":62},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","opencode.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","pointer.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","pool.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","postgres.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","precedence.rs"],"content":"//! # Configuration Precedence\n//!\n//! Merges configuration from multiple sources with precedence rules.\n//!\n//! # Precedence Order\n//! 1. CLI arguments (highest priority)\n//! 2. Environment variables\n//! 3. Configuration file\n//! 4. Default values (lowest priority)\n\nuse crate::config::{\n    Config, ObservabilityConfig, PostgresConfig, QdrantConfig, RedisConfig, SyncConfig, ToolConfig,\n};\n\n/// Merge multiple configuration sources with precedence.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Merges configuration from multiple sources following precedence rules:\n/// CLI arguments \u003e environment variables \u003e config file \u003e defaults.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::{Config, load_from_env, load_from_file, merge_configs};\n/// use std::path::Path;\n///\n/// fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n///     let defaults = Config::default();\n///     let from_file = load_from_file(Path::new(\"config.toml\"))?;\n///     let from_env = load_from_env()?;\n///\n///     let _config = merge_configs(defaults, from_file, \"file\", from_env, \"env\", None, \"cli\");\n///     Ok(())\n/// }\n/// ```\n///\n/// ## Deep Merge\n/// Performs deep merge on nested structures (providers, sync, tools,\n/// observability). String fields are overridden, not concatenated.\npub fn merge_configs(\n    defaults: Config,\n    file_config: Config,\n    file_source_name: \u0026str,\n    env_config: Config,\n    env_source_name: \u0026str,\n    cli_config: Option\u003cConfig\u003e,\n    cli_source_name: \u0026str,\n) -\u003e Config {\n    let mut config = defaults;\n\n    config = merge_with_logging(config, file_config, file_source_name);\n    config = merge_with_logging(config, env_config, env_source_name);\n\n    if let Some(cli) = cli_config {\n        config = merge_with_logging(config, cli, cli_source_name);\n    }\n\n    config\n}\n\nfn merge_with_logging(mut base: Config, override_config: Config, source_name: \u0026str) -\u003e Config {\n    let mut changes = Vec::new();\n\n    let mut temp_postgres = base.providers.postgres.clone();\n    merge_postgres(\n        \u0026mut temp_postgres,\n        \u0026override_config.providers.postgres,\n        source_name,\n        \u0026mut changes,\n    );\n    if !changes.is_empty() {\n        base.providers.postgres = temp_postgres;\n    }\n\n    let mut qdrant_changes = Vec::new();\n    let mut temp_qdrant = base.providers.qdrant.clone();\n    merge_qdrant(\n        \u0026mut temp_qdrant,\n        \u0026override_config.providers.qdrant,\n        source_name,\n        \u0026mut qdrant_changes,\n    );\n    if !qdrant_changes.is_empty() {\n        base.providers.qdrant = temp_qdrant;\n        changes.extend(qdrant_changes);\n    }\n\n    let mut redis_changes = Vec::new();\n    let mut temp_redis = base.providers.redis.clone();\n    merge_redis(\n        \u0026mut temp_redis,\n        \u0026override_config.providers.redis,\n        source_name,\n        \u0026mut redis_changes,\n    );\n    if !redis_changes.is_empty() {\n        base.providers.redis = temp_redis;\n        changes.extend(redis_changes);\n    }\n\n    let mut sync_changes = Vec::new();\n    let mut temp_sync = base.sync.clone();\n    merge_sync(\n        \u0026mut temp_sync,\n        \u0026override_config.sync,\n        source_name,\n        \u0026mut sync_changes,\n    );\n    if !sync_changes.is_empty() {\n        base.sync = temp_sync;\n        changes.extend(sync_changes);\n    }\n\n    let mut tool_changes = Vec::new();\n    let mut temp_tools = base.tools.clone();\n    merge_tools(\n        \u0026mut temp_tools,\n        \u0026override_config.tools,\n        source_name,\n        \u0026mut tool_changes,\n    );\n    if !tool_changes.is_empty() {\n        base.tools = temp_tools;\n        changes.extend(tool_changes);\n    }\n\n    let mut obs_changes = Vec::new();\n    let mut temp_obs = base.observability.clone();\n    merge_observability(\n        \u0026mut temp_obs,\n        \u0026override_config.observability,\n        source_name,\n        \u0026mut obs_changes,\n    );\n    if !obs_changes.is_empty() {\n        base.observability = temp_obs;\n        changes.extend(obs_changes);\n    }\n\n    if !changes.is_empty() {\n        tracing::info!(\"Configuration from {}: {:?}\", source_name, changes);\n    }\n\n    base\n}\n\nfn merge_postgres(\n    base: \u0026mut PostgresConfig,\n    override_config: \u0026PostgresConfig,\n    _source: \u0026str,\n    changes: \u0026mut Vec\u003cString\u003e,\n) {\n    if override_config.host != \"localhost\" \u0026\u0026 override_config.host != base.host {\n        changes.push(format!(\n            \"providers.postgres.host = {}\",\n            override_config.host\n        ));\n        base.host.clone_from(\u0026override_config.host);\n    }\n    if override_config.port != 5432 \u0026\u0026 override_config.port != base.port {\n        changes.push(format!(\n            \"providers.postgres.port = {}\",\n            override_config.port\n        ));\n        base.port = override_config.port;\n    }\n    if override_config.database != \"memory_knowledge\" \u0026\u0026 override_config.database != base.database {\n        changes.push(format!(\n            \"providers.postgres.database = {}\",\n            override_config.database\n        ));\n        base.database.clone_from(\u0026override_config.database);\n    }\n    if override_config.username != \"postgres\" \u0026\u0026 override_config.username != base.username {\n        changes.push(format!(\n            \"providers.postgres.username = {}\",\n            override_config.username\n        ));\n        base.username.clone_from(\u0026override_config.username);\n    }\n    if !override_config.password.is_empty() \u0026\u0026 override_config.password != base.password {\n        changes.push(\"providers.postgres.password = ***\".to_string());\n        base.password.clone_from(\u0026override_config.password);\n    }\n    if override_config.pool_size != 10 \u0026\u0026 override_config.pool_size != base.pool_size {\n        changes.push(format!(\n            \"providers.postgres.pool_size = {}\",\n            override_config.pool_size\n        ));\n        base.pool_size = override_config.pool_size;\n    }\n    if override_config.timeout_seconds != 30\n        \u0026\u0026 override_config.timeout_seconds != base.timeout_seconds\n    {\n        changes.push(format!(\n            \"providers.postgres.timeout_seconds = {}\",\n            override_config.timeout_seconds\n        ));\n        base.timeout_seconds = override_config.timeout_seconds;\n    }\n}\n\nfn merge_qdrant(\n    base: \u0026mut QdrantConfig,\n    override_config: \u0026QdrantConfig,\n    _source: \u0026str,\n    changes: \u0026mut Vec\u003cString\u003e,\n) {\n    if override_config.host != \"localhost\" \u0026\u0026 override_config.host != base.host {\n        changes.push(format!(\"providers.qdrant.host = {}\", override_config.host));\n        base.host.clone_from(\u0026override_config.host);\n    }\n    if override_config.port != 6333 \u0026\u0026 override_config.port != base.port {\n        changes.push(format!(\"providers.qdrant.port = {}\", override_config.port));\n        base.port = override_config.port;\n    }\n    if override_config.collection != \"memory_embeddings\"\n        \u0026\u0026 override_config.collection != base.collection\n    {\n        changes.push(format!(\n            \"providers.qdrant.collection = {}\",\n            override_config.collection\n        ));\n        base.collection.clone_from(\u0026override_config.collection);\n    }\n    if override_config.timeout_seconds != 30\n        \u0026\u0026 override_config.timeout_seconds != base.timeout_seconds\n    {\n        changes.push(format!(\n            \"providers.qdrant.timeout_seconds = {}\",\n            override_config.timeout_seconds\n        ));\n        base.timeout_seconds = override_config.timeout_seconds;\n    }\n}\n\nfn merge_redis(\n    base: \u0026mut RedisConfig,\n    override_config: \u0026RedisConfig,\n    _source: \u0026str,\n    changes: \u0026mut Vec\u003cString\u003e,\n) {\n    if override_config.host != \"localhost\" \u0026\u0026 override_config.host != base.host {\n        changes.push(format!(\"providers.redis.host = {}\", override_config.host));\n        base.host.clone_from(\u0026override_config.host);\n    }\n    if override_config.port != 6379 \u0026\u0026 override_config.port != base.port {\n        changes.push(format!(\"providers.redis.port = {}\", override_config.port));\n        base.port = override_config.port;\n    }\n    if override_config.db != 0 \u0026\u0026 override_config.db != base.db {\n        changes.push(format!(\"providers.redis.db = {}\", override_config.db));\n        base.db = override_config.db;\n    }\n    if override_config.pool_size != 10 \u0026\u0026 override_config.pool_size != base.pool_size {\n        changes.push(format!(\n            \"providers.redis.pool_size = {}\",\n            override_config.pool_size\n        ));\n        base.pool_size = override_config.pool_size;\n    }\n    if override_config.timeout_seconds != 30\n        \u0026\u0026 override_config.timeout_seconds != base.timeout_seconds\n    {\n        changes.push(format!(\n            \"providers.redis.timeout_seconds = {}\",\n            override_config.timeout_seconds\n        ));\n        base.timeout_seconds = override_config.timeout_seconds;\n    }\n}\n\nfn merge_sync(\n    base: \u0026mut SyncConfig,\n    override_config: \u0026SyncConfig,\n    _source: \u0026str,\n    changes: \u0026mut Vec\u003cString\u003e,\n) {\n    if override_config.enabled != base.enabled {\n        changes.push(format!(\"sync.enabled = {}\", override_config.enabled));\n        base.enabled = override_config.enabled;\n    }\n    if override_config.sync_interval_seconds != 60\n        \u0026\u0026 override_config.sync_interval_seconds != base.sync_interval_seconds\n    {\n        changes.push(format!(\n            \"sync.sync_interval_seconds = {}\",\n            override_config.sync_interval_seconds\n        ));\n        base.sync_interval_seconds = override_config.sync_interval_seconds;\n    }\n    if override_config.batch_size != 100 \u0026\u0026 override_config.batch_size != base.batch_size {\n        changes.push(format!(\"sync.batch_size = {}\", override_config.batch_size));\n        base.batch_size = override_config.batch_size;\n    }\n    if override_config.checkpoint_enabled != base.checkpoint_enabled {\n        changes.push(format!(\n            \"sync.checkpoint_enabled = {}\",\n            override_config.checkpoint_enabled\n        ));\n        base.checkpoint_enabled = override_config.checkpoint_enabled;\n    }\n    if override_config.conflict_resolution != \"prefer_knowledge\"\n        \u0026\u0026 override_config.conflict_resolution != base.conflict_resolution\n    {\n        changes.push(format!(\n            \"sync.conflict_resolution = {}\",\n            override_config.conflict_resolution\n        ));\n        base.conflict_resolution\n            .clone_from(\u0026override_config.conflict_resolution);\n    }\n}\n\nfn merge_tools(\n    base: \u0026mut ToolConfig,\n    override_config: \u0026ToolConfig,\n    _source: \u0026str,\n    changes: \u0026mut Vec\u003cString\u003e,\n) {\n    if override_config.enabled != base.enabled {\n        changes.push(format!(\"tools.enabled = {}\", override_config.enabled));\n        base.enabled = override_config.enabled;\n    }\n    if override_config.host != \"localhost\" \u0026\u0026 override_config.host != base.host {\n        changes.push(format!(\"tools.host = {}\", override_config.host));\n        base.host.clone_from(\u0026override_config.host);\n    }\n    if override_config.port != 8080 \u0026\u0026 override_config.port != base.port {\n        changes.push(format!(\"tools.port = {}\", override_config.port));\n        base.port = override_config.port;\n    }\n    if override_config.api_key != base.api_key {\n        match (\u0026override_config.api_key, \u0026base.api_key) {\n            (Some(_), None) =\u003e changes.push(\"tools.api_key = ***\".to_string()),\n            (None, Some(_)) =\u003e changes.push(\"tools.api_key = (none)\".to_string()),\n            (Some(new_key), Some(old_key)) if new_key != old_key =\u003e {\n                changes.push(\"tools.api_key = ***\".to_string())\n            }\n            _ =\u003e {}\n        }\n        base.api_key.clone_from(\u0026override_config.api_key);\n    }\n    if override_config.rate_limit_requests_per_minute != 60\n        \u0026\u0026 override_config.rate_limit_requests_per_minute != base.rate_limit_requests_per_minute\n    {\n        changes.push(format!(\n            \"tools.rate_limit_requests_per_minute = {}\",\n            override_config.rate_limit_requests_per_minute\n        ));\n        base.rate_limit_requests_per_minute = override_config.rate_limit_requests_per_minute;\n    }\n}\n\nfn merge_observability(\n    base: \u0026mut ObservabilityConfig,\n    override_config: \u0026ObservabilityConfig,\n    _source: \u0026str,\n    changes: \u0026mut Vec\u003cString\u003e,\n) {\n    if override_config.metrics_enabled != base.metrics_enabled {\n        changes.push(format!(\n            \"observability.metrics_enabled = {}\",\n            override_config.metrics_enabled\n        ));\n        base.metrics_enabled = override_config.metrics_enabled;\n    }\n    if override_config.tracing_enabled != base.tracing_enabled {\n        changes.push(format!(\n            \"observability.tracing_enabled = {}\",\n            override_config.tracing_enabled\n        ));\n        base.tracing_enabled = override_config.tracing_enabled;\n    }\n    if override_config.logging_level != \"info\"\n        \u0026\u0026 override_config.logging_level != base.logging_level\n    {\n        changes.push(format!(\n            \"observability.logging_level = {}\",\n            override_config.logging_level\n        ));\n        base.logging_level\n            .clone_from(\u0026override_config.logging_level);\n    }\n    if override_config.metrics_port != 9090 \u0026\u0026 override_config.metrics_port != base.metrics_port {\n        changes.push(format!(\n            \"observability.metrics_port = {}\",\n            override_config.metrics_port\n        ));\n        base.metrics_port = override_config.metrics_port;\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::config::ProviderConfig;\n\n    #[test]\n    fn test_merge_configs_precedence() {\n        let defaults = Config {\n            providers: ProviderConfig {\n                postgres: PostgresConfig {\n                    host: \"default_host\".to_string(),\n                    ..Default::default()\n                },\n                ..Default::default()\n            },\n            ..Default::default()\n        };\n\n        let file_config = Config {\n            providers: ProviderConfig {\n                postgres: PostgresConfig {\n                    host: \"file_host\".to_string(),\n                    ..Default::default()\n                },\n                ..Default::default()\n            },\n            ..Default::default()\n        };\n\n        let env_config = Config {\n            providers: ProviderConfig {\n                postgres: PostgresConfig {\n                    port: 9999,\n                    ..Default::default()\n                },\n                ..Default::default()\n            },\n            ..Default::default()\n        };\n\n        let merged = merge_configs(\n            defaults,\n            file_config,\n            \"file\",\n            env_config,\n            \"env\",\n            None,\n            \"cli\",\n        );\n\n        assert_eq!(merged.providers.postgres.host, \"file_host\");\n        assert_eq!(merged.providers.postgres.port, 9999);\n    }\n\n    #[test]\n    fn test_merge_postgres() {\n        let mut base = PostgresConfig {\n            host: \"base_host\".to_string(),\n            port: 5432,\n            database: \"base_db\".to_string(),\n            ..Default::default()\n        };\n\n        let override_config = PostgresConfig {\n            host: \"override_host\".to_string(),\n            port: 9999,\n            database: \"override_db\".to_string(),\n            ..Default::default()\n        };\n\n        let mut changes = Vec::new();\n        merge_postgres(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(base.host, \"override_host\");\n        assert_eq!(base.port, 9999);\n        assert_eq!(base.database, \"override_db\");\n        assert_eq!(changes.len(), 3);\n    }\n\n    #[test]\n    fn test_merge_sync() {\n        let mut base = SyncConfig {\n            enabled: true,\n            sync_interval_seconds: 60,\n            ..Default::default()\n        };\n\n        let override_config = SyncConfig {\n            enabled: false,\n            sync_interval_seconds: 120,\n            ..Default::default()\n        };\n\n        let mut changes = Vec::new();\n        merge_sync(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(base.enabled, false);\n        assert_eq!(base.sync_interval_seconds, 120);\n        assert_eq!(changes.len(), 2);\n    }\n\n    #[test]\n    fn test_merge_tools_with_api_key() {\n        let mut base = ToolConfig {\n            api_key: Some(\"old_key\".to_string()),\n            ..Default::default()\n        };\n\n        let override_config = ToolConfig {\n            api_key: Some(\"new_key\".to_string()),\n            ..Default::default()\n        };\n\n        let mut changes = Vec::new();\n        merge_tools(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(base.api_key, Some(\"new_key\".to_string()));\n        assert_eq!(changes.len(), 1);\n        assert!(changes[0].contains(\"api_key = ***\"));\n    }\n\n    #[test]\n    fn test_merge_cli_overrides_all() {\n        let defaults = Config::default();\n        let file_config = defaults.clone();\n        let env_config = defaults.clone();\n        let cli_config = Config {\n            providers: ProviderConfig {\n                postgres: PostgresConfig {\n                    host: \"cli_host\".to_string(),\n                    ..Default::default()\n                },\n                ..Default::default()\n            },\n            ..Default::default()\n        };\n\n        let merged = merge_configs(\n            defaults,\n            file_config,\n            \"file\",\n            env_config,\n            \"env\",\n            Some(cli_config),\n            \"cli\",\n        );\n\n        assert_eq!(merged.providers.postgres.host, \"cli_host\");\n    }\n\n    #[test]\n    fn test_merge_qdrant() {\n        let mut base = QdrantConfig {\n            host: \"base_host\".to_string(),\n            port: 6333,\n            collection: \"base_collection\".to_string(),\n            ..Default::default()\n        };\n\n        let override_config = QdrantConfig {\n            host: \"override_host\".to_string(),\n            port: 9999,\n            collection: \"override_collection\".to_string(),\n            ..Default::default()\n        };\n\n        let mut changes = Vec::new();\n        merge_qdrant(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(base.host, \"override_host\");\n        assert_eq!(base.port, 9999);\n        assert_eq!(base.collection, \"override_collection\");\n        assert_eq!(changes.len(), 3);\n    }\n\n    #[test]\n    fn test_merge_redis() {\n        let mut base = RedisConfig {\n            host: \"base_host\".to_string(),\n            port: 6379,\n            db: 0,\n            ..Default::default()\n        };\n\n        let override_config = RedisConfig {\n            host: \"override_host\".to_string(),\n            port: 9999,\n            db: 1,\n            ..Default::default()\n        };\n\n        let mut changes = Vec::new();\n        merge_redis(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(base.host, \"override_host\");\n        assert_eq!(base.port, 9999);\n        assert_eq!(base.db, 1);\n        assert_eq!(changes.len(), 3);\n    }\n\n    #[test]\n    fn test_merge_observability() {\n        let mut base = ObservabilityConfig {\n            metrics_enabled: true,\n            tracing_enabled: true,\n            logging_level: \"info\".to_string(),\n            metrics_port: 9090,\n        };\n\n        let override_config = ObservabilityConfig {\n            metrics_enabled: false,\n            tracing_enabled: false,\n            logging_level: \"debug\".to_string(),\n            metrics_port: 9999,\n        };\n\n        let mut changes = Vec::new();\n        merge_observability(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(base.metrics_enabled, false);\n        assert_eq!(base.tracing_enabled, false);\n        assert_eq!(base.logging_level, \"debug\");\n        assert_eq!(base.metrics_port, 9999);\n        assert_eq!(changes.len(), 4);\n    }\n\n    #[test]\n    fn test_merge_with_default_values() {\n        let mut base = PostgresConfig {\n            host: \"localhost\".to_string(),\n            port: 5432,\n            database: \"memory_knowledge\".to_string(),\n            username: \"postgres\".to_string(),\n            password: \"\".to_string(),\n            pool_size: 10,\n            timeout_seconds: 30,\n        };\n\n        let override_config = PostgresConfig {\n            host: \"localhost\".to_string(),\n            port: 5432,\n            database: \"memory_knowledge\".to_string(),\n            username: \"postgres\".to_string(),\n            password: \"\".to_string(),\n            pool_size: 10,\n            timeout_seconds: 30,\n        };\n\n        let mut changes = Vec::new();\n        merge_postgres(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(changes.len(), 0);\n    }\n\n    #[test]\n    fn test_merge_tools_without_api_key() {\n        let mut base = ToolConfig {\n            api_key: None,\n            ..Default::default()\n        };\n\n        let override_config = ToolConfig {\n            api_key: None,\n            ..Default::default()\n        };\n\n        let mut changes = Vec::new();\n        merge_tools(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(base.api_key, None);\n        assert_eq!(changes.len(), 0);\n    }\n\n    #[test]\n    fn test_merge_tools_remove_api_key() {\n        let mut base = ToolConfig {\n            api_key: Some(\"old_key\".to_string()),\n            ..Default::default()\n        };\n\n        let override_config = ToolConfig {\n            api_key: None,\n            ..Default::default()\n        };\n\n        let mut changes = Vec::new();\n        merge_tools(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(base.api_key, None);\n        assert_eq!(changes.len(), 1);\n        assert!(changes[0].contains(\"api_key = (none)\"));\n    }\n\n    #[test]\n    fn test_merge_configs_no_changes() {\n        let defaults = Config::default();\n        let file_config = Config::default();\n        let env_config = Config::default();\n\n        let merged = merge_configs(\n            defaults,\n            file_config,\n            \"file\",\n            env_config,\n            \"env\",\n            None,\n            \"cli\",\n        );\n\n        assert_eq!(merged, Config::default());\n    }\n\n    #[test]\n    fn test_merge_configs_partial_changes() {\n        let defaults = Config {\n            providers: ProviderConfig {\n                postgres: PostgresConfig {\n                    host: \"default_host\".to_string(),\n                    port: 5432,\n                    ..Default::default()\n                },\n                qdrant: QdrantConfig {\n                    host: \"default_qdrant\".to_string(),\n                    ..Default::default()\n                },\n                ..Default::default()\n            },\n            ..Default::default()\n        };\n\n        let file_config = Config {\n            providers: ProviderConfig {\n                postgres: PostgresConfig {\n                    host: \"file_host\".to_string(),\n                    ..Default::default()\n                },\n                ..Default::default()\n            },\n            ..Default::default()\n        };\n\n        let env_config = Config {\n            providers: ProviderConfig {\n                qdrant: QdrantConfig {\n                    host: \"env_qdrant\".to_string(),\n                    ..Default::default()\n                },\n                ..Default::default()\n            },\n            ..Default::default()\n        };\n\n        let merged = merge_configs(\n            defaults,\n            file_config,\n            \"file\",\n            env_config,\n            \"env\",\n            None,\n            \"cli\",\n        );\n\n        assert_eq!(merged.providers.postgres.host, \"file_host\");\n        assert_eq!(merged.providers.postgres.port, 5432);\n        assert_eq!(merged.providers.qdrant.host, \"env_qdrant\");\n    }\n\n    #[test]\n    fn test_merge_postgres_no_changes() {\n        let mut base = PostgresConfig::default();\n        let override_config = PostgresConfig::default();\n        let mut changes = Vec::new();\n\n        merge_postgres(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(changes.len(), 0);\n        assert_eq!(base, PostgresConfig::default());\n    }\n\n    #[test]\n    fn test_merge_qdrant_no_changes() {\n        let mut base = QdrantConfig::default();\n        let override_config = QdrantConfig::default();\n        let mut changes = Vec::new();\n\n        merge_qdrant(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(changes.len(), 0);\n        assert_eq!(base, QdrantConfig::default());\n    }\n\n    #[test]\n    fn test_merge_redis_no_changes() {\n        let mut base = RedisConfig::default();\n        let override_config = RedisConfig::default();\n        let mut changes = Vec::new();\n\n        merge_redis(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(changes.len(), 0);\n        assert_eq!(base, RedisConfig::default());\n    }\n\n    #[test]\n    fn test_merge_sync_no_changes() {\n        let mut base = SyncConfig::default();\n        let override_config = SyncConfig::default();\n        let mut changes = Vec::new();\n\n        merge_sync(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(changes.len(), 0);\n        assert_eq!(base, SyncConfig::default());\n    }\n\n    #[test]\n    fn test_merge_tools_no_changes() {\n        let mut base = ToolConfig::default();\n        let override_config = ToolConfig::default();\n        let mut changes = Vec::new();\n\n        merge_tools(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(changes.len(), 0);\n        assert_eq!(base, ToolConfig::default());\n    }\n\n    #[test]\n    fn test_merge_observability_no_changes() {\n        let mut base = ObservabilityConfig::default();\n        let override_config = ObservabilityConfig::default();\n        let mut changes = Vec::new();\n\n        merge_observability(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(changes.len(), 0);\n        assert_eq!(base, ObservabilityConfig::default());\n    }\n}\n","traces":[{"line":41,"address":[],"length":0,"stats":{"Line":4}},{"line":50,"address":[],"length":0,"stats":{"Line":8}},{"line":52,"address":[],"length":0,"stats":{"Line":20}},{"line":53,"address":[],"length":0,"stats":{"Line":20}},{"line":55,"address":[],"length":0,"stats":{"Line":6}},{"line":56,"address":[],"length":0,"stats":{"Line":4}},{"line":59,"address":[],"length":0,"stats":{"Line":4}},{"line":62,"address":[],"length":0,"stats":{"Line":9}},{"line":63,"address":[],"length":0,"stats":{"Line":18}},{"line":65,"address":[],"length":0,"stats":{"Line":27}},{"line":67,"address":[],"length":0,"stats":{"Line":9}},{"line":68,"address":[],"length":0,"stats":{"Line":9}},{"line":69,"address":[],"length":0,"stats":{"Line":9}},{"line":70,"address":[],"length":0,"stats":{"Line":9}},{"line":72,"address":[],"length":0,"stats":{"Line":13}},{"line":73,"address":[],"length":0,"stats":{"Line":4}},{"line":76,"address":[],"length":0,"stats":{"Line":18}},{"line":77,"address":[],"length":0,"stats":{"Line":27}},{"line":79,"address":[],"length":0,"stats":{"Line":9}},{"line":80,"address":[],"length":0,"stats":{"Line":9}},{"line":81,"address":[],"length":0,"stats":{"Line":9}},{"line":82,"address":[],"length":0,"stats":{"Line":9}},{"line":84,"address":[],"length":0,"stats":{"Line":10}},{"line":85,"address":[],"length":0,"stats":{"Line":3}},{"line":86,"address":[],"length":0,"stats":{"Line":2}},{"line":89,"address":[],"length":0,"stats":{"Line":18}},{"line":90,"address":[],"length":0,"stats":{"Line":27}},{"line":92,"address":[],"length":0,"stats":{"Line":9}},{"line":93,"address":[],"length":0,"stats":{"Line":9}},{"line":94,"address":[],"length":0,"stats":{"Line":9}},{"line":95,"address":[],"length":0,"stats":{"Line":9}},{"line":97,"address":[],"length":0,"stats":{"Line":9}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":18}},{"line":103,"address":[],"length":0,"stats":{"Line":27}},{"line":105,"address":[],"length":0,"stats":{"Line":9}},{"line":106,"address":[],"length":0,"stats":{"Line":9}},{"line":107,"address":[],"length":0,"stats":{"Line":9}},{"line":108,"address":[],"length":0,"stats":{"Line":9}},{"line":110,"address":[],"length":0,"stats":{"Line":9}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":18}},{"line":116,"address":[],"length":0,"stats":{"Line":27}},{"line":118,"address":[],"length":0,"stats":{"Line":9}},{"line":119,"address":[],"length":0,"stats":{"Line":9}},{"line":120,"address":[],"length":0,"stats":{"Line":9}},{"line":121,"address":[],"length":0,"stats":{"Line":9}},{"line":123,"address":[],"length":0,"stats":{"Line":9}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":18}},{"line":129,"address":[],"length":0,"stats":{"Line":27}},{"line":131,"address":[],"length":0,"stats":{"Line":9}},{"line":132,"address":[],"length":0,"stats":{"Line":9}},{"line":133,"address":[],"length":0,"stats":{"Line":9}},{"line":134,"address":[],"length":0,"stats":{"Line":9}},{"line":136,"address":[],"length":0,"stats":{"Line":9}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":9}},{"line":142,"address":[],"length":0,"stats":{"Line":5}},{"line":145,"address":[],"length":0,"stats":{"Line":9}},{"line":148,"address":[],"length":0,"stats":{"Line":12}},{"line":154,"address":[],"length":0,"stats":{"Line":20}},{"line":155,"address":[],"length":0,"stats":{"Line":16}},{"line":156,"address":[],"length":0,"stats":{"Line":8}},{"line":157,"address":[],"length":0,"stats":{"Line":4}},{"line":159,"address":[],"length":0,"stats":{"Line":8}},{"line":161,"address":[],"length":0,"stats":{"Line":16}},{"line":162,"address":[],"length":0,"stats":{"Line":8}},{"line":163,"address":[],"length":0,"stats":{"Line":2}},{"line":164,"address":[],"length":0,"stats":{"Line":2}},{"line":166,"address":[],"length":0,"stats":{"Line":2}},{"line":168,"address":[],"length":0,"stats":{"Line":14}},{"line":169,"address":[],"length":0,"stats":{"Line":4}},{"line":170,"address":[],"length":0,"stats":{"Line":2}},{"line":171,"address":[],"length":0,"stats":{"Line":1}},{"line":173,"address":[],"length":0,"stats":{"Line":2}},{"line":175,"address":[],"length":0,"stats":{"Line":12}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":12}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":12}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":12}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":204,"address":[],"length":0,"stats":{"Line":11}},{"line":210,"address":[],"length":0,"stats":{"Line":15}},{"line":211,"address":[],"length":0,"stats":{"Line":10}},{"line":212,"address":[],"length":0,"stats":{"Line":4}},{"line":214,"address":[],"length":0,"stats":{"Line":13}},{"line":215,"address":[],"length":0,"stats":{"Line":4}},{"line":216,"address":[],"length":0,"stats":{"Line":1}},{"line":218,"address":[],"length":0,"stats":{"Line":11}},{"line":219,"address":[],"length":0,"stats":{"Line":1}},{"line":221,"address":[],"length":0,"stats":{"Line":4}},{"line":222,"address":[],"length":0,"stats":{"Line":2}},{"line":223,"address":[],"length":0,"stats":{"Line":1}},{"line":225,"address":[],"length":0,"stats":{"Line":2}},{"line":227,"address":[],"length":0,"stats":{"Line":11}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":231,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":11}},{"line":244,"address":[],"length":0,"stats":{"Line":13}},{"line":245,"address":[],"length":0,"stats":{"Line":5}},{"line":246,"address":[],"length":0,"stats":{"Line":2}},{"line":248,"address":[],"length":0,"stats":{"Line":13}},{"line":249,"address":[],"length":0,"stats":{"Line":4}},{"line":250,"address":[],"length":0,"stats":{"Line":1}},{"line":252,"address":[],"length":0,"stats":{"Line":13}},{"line":253,"address":[],"length":0,"stats":{"Line":4}},{"line":254,"address":[],"length":0,"stats":{"Line":1}},{"line":256,"address":[],"length":0,"stats":{"Line":11}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":11}},{"line":264,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":0}},{"line":270,"address":[],"length":0,"stats":{"Line":0}},{"line":274,"address":[],"length":0,"stats":{"Line":11}},{"line":280,"address":[],"length":0,"stats":{"Line":12}},{"line":281,"address":[],"length":0,"stats":{"Line":4}},{"line":282,"address":[],"length":0,"stats":{"Line":1}},{"line":284,"address":[],"length":0,"stats":{"Line":11}},{"line":285,"address":[],"length":0,"stats":{"Line":1}},{"line":287,"address":[],"length":0,"stats":{"Line":4}},{"line":288,"address":[],"length":0,"stats":{"Line":1}},{"line":289,"address":[],"length":0,"stats":{"Line":1}},{"line":291,"address":[],"length":0,"stats":{"Line":1}},{"line":293,"address":[],"length":0,"stats":{"Line":11}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":11}},{"line":298,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":11}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":13}},{"line":322,"address":[],"length":0,"stats":{"Line":13}},{"line":323,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":13}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":13}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":334,"address":[],"length":0,"stats":{"Line":13}},{"line":335,"address":[],"length":0,"stats":{"Line":4}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":337,"address":[],"length":0,"stats":{"Line":4}},{"line":338,"address":[],"length":0,"stats":{"Line":4}},{"line":339,"address":[],"length":0,"stats":{"Line":4}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":343,"address":[],"length":0,"stats":{"Line":6}},{"line":345,"address":[],"length":0,"stats":{"Line":13}},{"line":346,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":0}},{"line":350,"address":[],"length":0,"stats":{"Line":0}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":11}},{"line":362,"address":[],"length":0,"stats":{"Line":12}},{"line":363,"address":[],"length":0,"stats":{"Line":4}},{"line":364,"address":[],"length":0,"stats":{"Line":1}},{"line":365,"address":[],"length":0,"stats":{"Line":1}},{"line":367,"address":[],"length":0,"stats":{"Line":1}},{"line":369,"address":[],"length":0,"stats":{"Line":12}},{"line":370,"address":[],"length":0,"stats":{"Line":4}},{"line":371,"address":[],"length":0,"stats":{"Line":1}},{"line":372,"address":[],"length":0,"stats":{"Line":1}},{"line":374,"address":[],"length":0,"stats":{"Line":1}},{"line":376,"address":[],"length":0,"stats":{"Line":11}},{"line":377,"address":[],"length":0,"stats":{"Line":1}},{"line":379,"address":[],"length":0,"stats":{"Line":4}},{"line":380,"address":[],"length":0,"stats":{"Line":2}},{"line":381,"address":[],"length":0,"stats":{"Line":1}},{"line":383,"address":[],"length":0,"stats":{"Line":2}},{"line":384,"address":[],"length":0,"stats":{"Line":1}},{"line":386,"address":[],"length":0,"stats":{"Line":13}},{"line":387,"address":[],"length":0,"stats":{"Line":4}},{"line":388,"address":[],"length":0,"stats":{"Line":1}},{"line":389,"address":[],"length":0,"stats":{"Line":1}},{"line":391,"address":[],"length":0,"stats":{"Line":1}}],"covered":149,"coverable":211},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","procedural.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","providers.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","qdrant.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","redis.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","repository.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","state.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","tools.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","validator.rs"],"content":"//! # Configuration Validation\n//!\n//! Provides validation for all configuration structures using the `validator` crate.\n\nuse crate::config::{\n    Config, ObservabilityConfig, PostgresConfig, ProviderConfig, QdrantConfig, RedisConfig,\n    SyncConfig, ToolConfig,\n};\nuse validator::Validate;\n\n/// Validate configuration structure.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Validates all configuration fields using the `validator` crate.\n/// Ensures all required fields are present and within valid ranges.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use memory_knowledge_config::{Config, validate};\n///\n/// let config = Config::default();\n/// match validate(\u0026config) {\n///     Ok(()) =\u003e println!(\"Configuration is valid\"),\n///     Err(errors) =\u003e println!(\"Validation errors: {:?}\", errors),\n/// }\n/// ```\n///\n/// ## Validation Rules\n/// ### General\n/// - All string fields: minimum length 1, maximum length varies\n///\n/// ### PostgreSQL\n/// - `host`: 1-255 characters\n/// - `port`: 1-65535\n/// - `database`: 1-63 characters\n/// - `username`: 1-63 characters\n/// - `password`: 1+ characters\n/// - `pool_size`: 1-100\n/// - `timeout_seconds`: 1-300\n///\n/// ### Qdrant\n/// - `host`: 1-255 characters\n/// - `port`: 1-65535\n/// - `collection`: 1-255 characters\n/// - `timeout_seconds`: 1-300\n///\n/// ### Redis\n/// - `host`: 1-255 characters\n/// - `port`: 1-65535\n/// - `db`: 0-15\n/// - `pool_size`: 1-100\n/// - `timeout_seconds`: 1-300\n///\n/// ### Sync\n/// - `sync_interval_seconds`: 10-3600\n/// - `batch_size`: 1-1000\n/// - `conflict_resolution`: must be \"prefer_knowledge\", \"prefer_memory\", or \"manual\"\n///\n/// ### Tools\n/// - `host`: 1-255 characters\n/// - `port`: 1-65535\n/// - `rate_limit_requests_per_minute`: 1-1000\n///\n/// ### Observability\n/// - `logging_level`: must be \"trace\", \"debug\", \"info\", \"warn\", or \"error\"\n/// - `metrics_port`: 1-65535\npub fn validate(config: \u0026Config) -\u003e Result\u003c(), validator::ValidationErrors\u003e {\n    config.validate()\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_validate_valid_config() {\n        let config = Config::default();\n        assert!(validate(\u0026config).is_ok());\n    }\n\n    #[test]\n    fn test_validate_invalid_postgres_host() {\n        let mut config = Config::default();\n        config.providers.postgres.host = \"\".to_string();\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_invalid_postgres_port() {\n        let mut config = Config::default();\n        config.providers.postgres.port = 0;\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_invalid_qdrant_port() {\n        let mut config = Config::default();\n        config.providers.qdrant.port = 0;\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_invalid_redis_db() {\n        let mut config = Config::default();\n        config.providers.redis.db = 16;\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_invalid_sync_interval() {\n        let mut config = Config::default();\n        config.sync.sync_interval_seconds = 5;\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_invalid_sync_interval_high() {\n        let mut config = Config::default();\n        config.sync.sync_interval_seconds = 4000;\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_invalid_batch_size() {\n        let mut config = Config::default();\n        config.sync.batch_size = 0;\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_invalid_conflict_resolution() {\n        let mut config = Config::default();\n        config.sync.conflict_resolution = \"invalid\".to_string();\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_valid_conflict_resolution() {\n        let mut config = Config::default();\n        config.sync.conflict_resolution = \"prefer_memory\".to_string();\n        assert!(validate(\u0026config).is_ok());\n    }\n\n    #[test]\n    fn test_validate_invalid_logging_level() {\n        let mut config = Config::default();\n        config.observability.logging_level = \"invalid\".to_string();\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_valid_logging_levels() {\n        for level in [\"trace\", \"debug\", \"info\", \"warn\", \"error\"] {\n            let mut config = Config::default();\n            config.observability.logging_level = level.to_string();\n            assert!(validate(\u0026config).is_ok());\n        }\n    }\n\n    #[test]\n    fn test_validate_invalid_tools_rate_limit() {\n        let mut config = Config::default();\n        config.tools.rate_limit_requests_per_minute = 0;\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_postgres_pool_size_out_of_range() {\n        let mut config = Config::default();\n        config.providers.postgres.pool_size = 101;\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_postgres_timeout_out_of_range() {\n        let mut config = Config::default();\n        config.providers.postgres.timeout_seconds = 301;\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_qdrant_collection_empty() {\n        let mut config = Config::default();\n        config.providers.qdrant.collection = \"\".to_string();\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_redis_host_empty() {\n        let mut config = Config::default();\n        config.providers.redis.host = \"\".to_string();\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_tools_port_zero() {\n        let mut config = Config::default();\n        config.tools.port = 0;\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_observability_metrics_port_zero() {\n        let mut config = Config::default();\n        config.observability.metrics_port = 0;\n        assert!(validate(\u0026config).is_err());\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","working.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","errors","src","lib.rs"],"content":"//! # Memory-Knowledge Errors\n//!\n//! Comprehensive error handling for Memory-Knowledge system.\n//!\n//! Follows Microsoft Pragmatic Rust Guidelines:\n//! - Uses `thiserror` for structured error definitions\n//! - Provides `Display` and `Error` trait implementations\n//! - Includes error context for debugging\n\nuse thiserror::Error;\n\n/// Memory-specific errors\n#[derive(Debug, Error)]\npub enum MemoryError {\n    // FIX: Use named field {layer} instead of positional {0}\n    #[error(\"Invalid memory layer: {layer}\")]\n    InvalidLayer { layer: String },\n\n    // FIX: Use named field {identifier} instead of positional {0}\n    #[error(\"Missing required identifier: {identifier}\")]\n    MissingIdentifier { identifier: String },\n\n    // FIX: Use named field {id} instead of positional {0}\n    #[error(\"Memory not found: {id}\")]\n    MemoryNotFound { id: String },\n\n    // FIX: Use named fields {length} and {max} instead of positional {0} and {1}\n    #[error(\"Content too long: {length} characters max {max}\")]\n    ContentTooLong { length: usize, max: usize },\n\n    // FIX: Use named fields {length} and {max} instead of positional {0} and {1}\n    #[error(\"Query too long: {length} characters max {max}\")]\n    QueryTooLong { length: usize, max: usize },\n\n    // FIX: Use named field {reason} instead of positional {0}\n    #[error(\"Embedding generation failed: {reason}\")]\n    EmbeddingFailed { reason: String },\n\n    // FIX: Use named fields {source_name} and {reason} to match the struct\n    #[error(\"Provider error: {source_name} - {reason}\")]\n    ProviderError { source_name: String, reason: String },\n\n    // FIX: Use named field {retry_after} instead of positional {0}\n    #[error(\"Rate limited: retry after {retry_after}s\")]\n    RateLimited { retry_after: u64 },\n\n    // FIX: Use named field {reason} instead of positional {0}\n    #[error(\"Unauthorized access: {reason}\")]\n    Unauthorized { reason: String },\n\n    // FIX: Use named field {message} instead of positional {0}\n    #[error(\"Configuration error: {message}\")]\n    ConfigurationError { message: String }\n}\n\n/// Knowledge repository errors\n#[derive(Debug, Error)]\npub enum KnowledgeError {\n    // FIX: Use named field {id} instead of positional {0}\n    #[error(\"Knowledge item not found: {id}\")]\n    ItemNotFound { id: String },\n\n    // FIX: Use named field {type_} instead of positional {0}\n    #[error(\"Invalid knowledge type: {type_}\")]\n    InvalidType { type_: String },\n\n    // FIX: Use named field {layer} instead of positional {0}\n    #[error(\"Invalid knowledge layer: {layer}\")]\n    InvalidLayer { layer: String },\n\n    // FIX: Use named fields {from} and {to} instead of positional {0} and {1}\n    #[error(\"Invalid status transition: {from} to {to}\")]\n    InvalidStatusTransition { from: String, to: String },\n\n    // FIX: Use named fields {operation} and {reason} instead of positional {0} and {1}\n    #[error(\"Git operation: {operation} failed: {reason}\")]\n    GitError { operation: String, reason: String },\n\n    // FIX: Use named field {reason} instead of positional {0}\n    #[error(\"Manifest corrupted: {reason}\")]\n    ManifestCorrupted { reason: String },\n\n    // FIX: Use named field {constraint_id} instead of positional {0}\n    #[error(\"Constraint violation: {constraint_id}\")]\n    ConstraintViolation { constraint_id: String }\n}\n\n/// Sync bridge errors\n#[derive(Debug, Error)]\npub enum SyncError {\n    // FIX: Use named field {reason} instead of positional {0}\n    #[error(\"Knowledge unavailable: {reason}\")]\n    KnowledgeUnavailable { reason: String },\n\n    // FIX: Use named field {reason} instead of positional {0}\n    #[error(\"Memory unavailable: {reason}\")]\n    MemoryUnavailable { reason: String },\n\n    // FIX: Use named field {reason} instead of positional {0}\n    #[error(\"State corrupted: {reason}\")]\n    StateCorrupted { reason: String },\n\n    // FIX: Use named field {checkpoint_id} instead of positional {0}\n    #[error(\"Checkpoint failed: {checkpoint_id}\")]\n    CheckpointFailed { checkpoint_id: String },\n\n    // FIX: Use named fields {checkpoint_id} and {reason} instead of positional {0} and {1}\n    #[error(\"Rollback of {checkpoint_id} failed: {reason}\")]\n    RollbackFailed {\n        checkpoint_id: String,\n        reason: String\n    },\n\n    // FIX: Use named field {conflict_id} instead of positional {0}\n    #[error(\"Conflict unresolvable: {conflict_id}\")]\n    ConflictUnresolvable { conflict_id: String },\n\n    // FIX: Use named field {failed_items} instead of positional {0}\n    #[error(\"Partial failure: {failed_items:?} items failed\")]\n    PartialFailure { failed_items: Vec\u003cString\u003e }\n}\n\n/// Tool interface errors\n#[derive(Debug, Error)]\npub enum ToolError {\n    // FIX: Use named fields {field} and {reason} instead of positional {0}\n    #[error(\"Invalid input: {field} reason: {reason}\")]\n    InvalidInput { field: String, reason: String },\n\n    // FIX: Use named fields {resource} and {id} instead of positional {0} and {1}\n    #[error(\"Resource not found: {resource}:{id}\")]\n    NotFound { resource: String, id: String },\n\n    // FIX: Use named fields {source_name} and {reason} to match the struct\n    #[error(\"Provider error: {source_name} - {reason}\")]\n    ProviderError { source_name: String, reason: String },\n\n    // FIX: Use named field {retry_after} instead of positional {0}\n    #[error(\"Rate limited: retry after {retry_after}s\")]\n    RateLimited { retry_after: u64 },\n\n    // FIX: Use named field {reason} instead of positional {0}\n    #[error(\"Unauthorized access: {reason}\")]\n    Unauthorized { reason: String },\n\n    // FIX: Use named field {timeout_ms} instead of positional {0}\n    #[error(\"Timeout: operation took longer than {timeout_ms}ms\")]\n    Timeout { timeout_ms: u64 },\n\n    // FIX: Use named fields {conflict_id} and {details} instead of positional {0} and {1}\n    #[error(\"Conflict: {conflict_id}: {details}\")]\n    Conflict {\n        conflict_id: String,\n        details: String\n    }\n}\n\n/// Storage layer errors\n#[derive(Debug, Error)]\npub enum StorageError {\n    // FIX: Use named fields {backend} and {reason} instead of positional {0} and {1}\n    #[error(\"Connection to {backend} failed: {reason}\")]\n    ConnectionError { backend: String, reason: String },\n\n    // FIX: Use named fields {backend} and {reason} instead of positional {0} and {1}\n    #[error(\"Query on {backend} failed: {reason}\")]\n    QueryError { backend: String, reason: String },\n\n    // FIX: Use named fields {error_type} and {reason} instead of positional {0} and {1}\n    #[error(\"Serialization error: {error_type} - {reason}\")]\n    SerializationError { error_type: String, reason: String },\n\n    // FIX: Use named fields {backend} and {id} instead of positional {0} and {1}\n    #[error(\"Not found on {backend}:{id}\")]\n    NotFound { backend: String, id: String },\n\n    // FIX: Use named fields {backend} and {reason} instead of positional {0} and {1}\n    #[error(\"Transaction on {backend} failed: {reason}\")]\n    TransactionError { backend: String, reason: String }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","expanded_qdrant.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","api.rs"],"content":"use crate::governance::GovernanceEngine;\nuse crate::governance_client::{GovernanceClient, RemoteGovernanceClient};\nuse config::config::DeploymentConfig;\nuse mk_core::traits::StorageBackend;\nuse mk_core::types::{DriftResult, GovernanceEvent, KnowledgeLayer, TenantContext};\nuse std::sync::Arc;\nuse storage::postgres::PostgresBackend;\nuse utoipa::OpenApi;\n\n#[derive(OpenApi)]\n#[openapi(\n    paths(\n        get_drift_status,\n        get_org_report,\n        approve_proposal,\n        reject_proposal,\n        get_job_status,\n        replay_events\n    ),\n    components(\n        schemas(mk_core::types::DriftResult, mk_core::types::PolicyViolation, mk_core::types::GovernanceEvent)\n    ),\n    tags(\n        (name = \"governance\", description = \"Governance Dashboard API\")\n    )\n)]\npub struct GovernanceApiDoc;\n\npub struct GovernanceDashboardApi {\n    engine: Arc\u003cGovernanceEngine\u003e,\n    storage: Arc\u003cPostgresBackend\u003e,\n    governance_client: Option\u003cArc\u003cdyn GovernanceClient\u003e\u003e,\n    deployment_config: DeploymentConfig\n}\n\n#[utoipa::path(\n    get,\n    path = \"/api/v1/governance/drift/{project_id}\",\n    responses(\n        (status = 200, description = \"Drift status fetched successfully\", body = Option\u003cDriftResult\u003e),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"project_id\" = String, Path, description = \"Project ID\")\n    ),\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn get_drift_status(\n    api: Arc\u003cGovernanceDashboardApi\u003e,\n    ctx: \u0026TenantContext,\n    project_id: \u0026str\n) -\u003e anyhow::Result\u003cOption\u003cDriftResult\u003e\u003e {\n    if api.deployment_config.mode == \"remote\" {\n        if let Some(client) = \u0026api.governance_client {\n            return client\n                .get_drift_status(ctx, project_id)\n                .await\n                .map_err(|e| anyhow::anyhow!(\"Remote drift status failed: {}\", e));\n        }\n    }\n\n    let result =\n        StorageBackend::get_latest_drift_result(api.storage.as_ref(), ctx.clone(), project_id)\n            .await\n            .map_err(|e| anyhow::anyhow!(\"Failed to fetch drift result: {:?}\", e))?;\n\n    Ok(result)\n}\n\n#[utoipa::path(\n    get,\n    path = \"/api/v1/governance/reports/{org_id}\",\n    responses(\n        (status = 200, description = \"Organization report fetched successfully\", body = serde_json::Value),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"org_id\" = String, Path, description = \"Organization ID\")\n    ),\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn get_org_report(\n    api: Arc\u003cGovernanceDashboardApi\u003e,\n    ctx: \u0026TenantContext,\n    org_id: \u0026str\n) -\u003e anyhow::Result\u003cserde_json::Value\u003e {\n    let descendants = StorageBackend::get_descendants(api.storage.as_ref(), ctx.clone(), org_id)\n        .await\n        .map_err(|e| anyhow::anyhow!(\"Failed to fetch descendants: {:?}\", e))?;\n\n    let mut project_drifts = Vec::new();\n    for unit in descendants {\n        if unit.unit_type == mk_core::types::UnitType::Project {\n            if let Some(drift) = get_drift_status(api.clone(), ctx, \u0026unit.id).await? {\n                project_drifts.push(drift);\n            }\n        }\n    }\n\n    let avg_drift = if project_drifts.is_empty() {\n        0.0\n    } else {\n        project_drifts.iter().map(|d| d.drift_score).sum::\u003cf32\u003e() / project_drifts.len() as f32\n    };\n\n    Ok(serde_json::json!({\n        \"orgId\": org_id,\n        \"averageDrift\": avg_drift,\n        \"projectCount\": project_drifts.len(),\n        \"projects\": project_drifts,\n        \"timestamp\": chrono::Utc::now().timestamp()\n    }))\n}\n\n#[utoipa::path(\n    post,\n    path = \"/api/v1/governance/proposals/{proposal_id}/approve\",\n    responses(\n        (status = 200, description = \"Proposal approved successfully\"),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 404, description = \"Proposal not found\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"proposal_id\" = String, Path, description = \"Proposal ID\")\n    ),\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn approve_proposal(\n    api: Arc\u003cGovernanceDashboardApi\u003e,\n    ctx: \u0026TenantContext,\n    proposal_id: \u0026str\n) -\u003e anyhow::Result\u003c()\u003e {\n    let repo = api\n        .engine\n        .repository()\n        .ok_or_else(|| anyhow::anyhow!(\"Repository not configured\"))?;\n\n    let entry = repo\n        .get(\n            ctx.clone(),\n            mk_core::types::KnowledgeLayer::Project,\n            proposal_id\n        )\n        .await\n        .map_err(|e| anyhow::anyhow!(\"Failed to fetch proposal: {:?}\", e))?\n        .ok_or_else(|| anyhow::anyhow!(\"Proposal not found\"))?;\n\n    let mut accepted_entry = entry.clone();\n    accepted_entry.status = mk_core::types::KnowledgeStatus::Accepted;\n\n    repo.store(ctx.clone(), accepted_entry, \"Proposal approved\")\n        .await\n        .map_err(|e| anyhow::anyhow!(\"Failed to approve proposal: {:?}\", e))?;\n\n    Ok(())\n}\n\n#[utoipa::path(\n    post,\n    path = \"/api/v1/governance/proposals/{proposal_id}/reject\",\n    responses(\n        (status = 200, description = \"Proposal rejected successfully\"),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 404, description = \"Proposal not found\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"proposal_id\" = String, Path, description = \"Proposal ID\"),\n        (\"reason\" = String, Query, description = \"Rejection reason\")\n    ),\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn reject_proposal(\n    api: Arc\u003cGovernanceDashboardApi\u003e,\n    ctx: \u0026TenantContext,\n    proposal_id: \u0026str,\n    reason: \u0026str\n) -\u003e anyhow::Result\u003c()\u003e {\n    let repo = api\n        .engine\n        .repository()\n        .ok_or_else(|| anyhow::anyhow!(\"Repository not configured\"))?;\n\n    let entry = repo\n        .get(\n            ctx.clone(),\n            mk_core::types::KnowledgeLayer::Project,\n            proposal_id\n        )\n        .await\n        .map_err(|e| anyhow::anyhow!(\"Failed to fetch proposal: {:?}\", e))?\n        .ok_or_else(|| anyhow::anyhow!(\"Proposal not found\"))?;\n\n    let mut rejected_entry = entry.clone();\n    rejected_entry.status = mk_core::types::KnowledgeStatus::Draft;\n    rejected_entry\n        .metadata\n        .insert(\"rejection_reason\".to_string(), serde_json::json!(reason));\n\n    repo.store(\n        ctx.clone(),\n        rejected_entry,\n        \u0026format!(\"Proposal rejected: {}\", reason)\n    )\n    .await\n    .map_err(|e| anyhow::anyhow!(\"Failed to reject proposal: {:?}\", e))?;\n\n    Ok(())\n}\n\n#[utoipa::path(\n    get,\n    path = \"/api/v1/governance/jobs\",\n    responses(\n        (status = 200, description = \"Job status fetched successfully\", body = serde_json::Value),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"job_name\" = Option\u003cString\u003e, Query, description = \"Filter by job name\")\n    ),\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn get_job_status(\n    api: Arc\u003cGovernanceDashboardApi\u003e,\n    ctx: \u0026TenantContext,\n    job_name: Option\u003c\u0026str\u003e\n) -\u003e anyhow::Result\u003cserde_json::Value\u003e {\n    let rows = sqlx::query(\n        \"SELECT id, job_name, status, message, started_at, finished_at, duration_ms \n         FROM job_status \n         WHERE tenant_id = $1 OR tenant_id = 'all' \n         ORDER BY started_at DESC LIMIT 50\"\n    )\n    .bind(ctx.tenant_id.as_str())\n    .fetch_all(api.storage.pool())\n    .await\n    .map_err(|e| anyhow::anyhow!(\"Failed to fetch job status: {:?}\", e))?;\n\n    let mut jobs = Vec::new();\n    for row in rows {\n        use sqlx::Row;\n        let name: String = row.get(\"job_name\");\n        if let Some(filter) = job_name {\n            if name != filter {\n                continue;\n            }\n        }\n\n        jobs.push(serde_json::json!({\n            \"id\": row.get::\u003cuuid::Uuid, _\u003e(\"id\"),\n            \"jobName\": name,\n            \"status\": row.get::\u003cString, _\u003e(\"status\"),\n            \"message\": row.get::\u003cOption\u003cString\u003e, _\u003e(\"message\"),\n            \"startedAt\": row.get::\u003ci64, _\u003e(\"started_at\"),\n            \"finishedAt\": row.get::\u003cOption\u003ci64\u003e, _\u003e(\"finished_at\"),\n            \"durationMs\": row.get::\u003cOption\u003ci64\u003e, _\u003e(\"duration_ms\"),\n        }));\n    }\n\n    Ok(serde_json::json!(jobs))\n}\n\n#[utoipa::path(\n    get,\n    path = \"/api/v1/governance/events/replay\",\n    responses(\n        (status = 200, description = \"Events replayed successfully\", body = Vec\u003cGovernanceEvent\u003e),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"since_timestamp\" = i64, Query, description = \"Replay events after this timestamp\"),\n        (\"limit\" = usize, Query, description = \"Maximum number of events to return\")\n    ),\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn replay_events(\n    api: Arc\u003cGovernanceDashboardApi\u003e,\n    ctx: \u0026TenantContext,\n    since_timestamp: i64,\n    limit: usize\n) -\u003e anyhow::Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e\u003e {\n    if api.deployment_config.mode == \"remote\" {\n        if let Some(client) = \u0026api.governance_client {\n            return client\n                .replay_events(ctx, since_timestamp, limit)\n                .await\n                .map_err(|e| anyhow::anyhow!(\"Remote replay events failed: {}\", e));\n        }\n    }\n\n    let events = StorageBackend::get_governance_events(\n        api.storage.as_ref(),\n        ctx.clone(),\n        since_timestamp,\n        limit\n    )\n    .await\n    .map_err(|e| anyhow::anyhow!(\"Failed to replay governance events: {:?}\", e))?;\n\n    Ok(events)\n}\n\nimpl GovernanceDashboardApi {\n    pub fn new(\n        engine: Arc\u003cGovernanceEngine\u003e,\n        storage: Arc\u003cPostgresBackend\u003e,\n        deployment_config: DeploymentConfig\n    ) -\u003e Self {\n        let governance_client = if deployment_config.mode == \"remote\" {\n            deployment_config.remote_url.as_ref().map(|url: \u0026String| {\n                Arc::new(RemoteGovernanceClient::new(url.clone())) as Arc\u003cdyn GovernanceClient\u003e\n            })\n        } else {\n            None\n        };\n\n        Self {\n            engine,\n            storage,\n            governance_client,\n            deployment_config\n        }\n    }\n\n    pub async fn list_proposals(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        layer: Option\u003cKnowledgeLayer\u003e\n    ) -\u003e anyhow::Result\u003cVec\u003cmk_core::types::KnowledgeEntry\u003e\u003e {\n        if self.deployment_config.mode == \"remote\" {\n            if let Some(client) = \u0026self.governance_client {\n                return client\n                    .list_proposals(ctx, layer)\n                    .await\n                    .map_err(|e| anyhow::anyhow!(\"Remote list proposals failed: {}\", e));\n            }\n        }\n\n        let repo = self\n            .engine\n            .repository()\n            .ok_or_else(|| anyhow::anyhow!(\"Repository not configured\"))?;\n\n        let layers = if let Some(l) = layer {\n            vec![l]\n        } else {\n            vec![\n                KnowledgeLayer::Project,\n                KnowledgeLayer::Team,\n                KnowledgeLayer::Org,\n                KnowledgeLayer::Company,\n            ]\n        };\n\n        let mut proposals = Vec::new();\n        for l in layers {\n            let entries: Vec\u003cmk_core::types::KnowledgeEntry\u003e = repo\n                .list(ctx.clone(), l, \"\")\n                .await\n                .map_err(|e| anyhow::anyhow!(\"Failed to list entries in layer {:?}: {:?}\", l, e))?;\n\n            for entry in entries {\n                if entry.status == mk_core::types::KnowledgeStatus::Proposed {\n                    proposals.push(entry);\n                }\n            }\n        }\n\n        Ok(proposals)\n    }\n}\n","traces":[{"line":51,"address":[],"length":0,"stats":{"Line":4}},{"line":56,"address":[],"length":0,"stats":{"Line":4}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":4}},{"line":66,"address":[],"length":0,"stats":{"Line":20}},{"line":67,"address":[],"length":0,"stats":{"Line":4}},{"line":68,"address":[],"length":0,"stats":{"Line":4}},{"line":70,"address":[],"length":0,"stats":{"Line":4}},{"line":88,"address":[],"length":0,"stats":{"Line":1}},{"line":93,"address":[],"length":0,"stats":{"Line":6}},{"line":94,"address":[],"length":0,"stats":{"Line":1}},{"line":95,"address":[],"length":0,"stats":{"Line":1}},{"line":97,"address":[],"length":0,"stats":{"Line":2}},{"line":98,"address":[],"length":0,"stats":{"Line":7}},{"line":99,"address":[],"length":0,"stats":{"Line":3}},{"line":100,"address":[],"length":0,"stats":{"Line":7}},{"line":101,"address":[],"length":0,"stats":{"Line":2}},{"line":106,"address":[],"length":0,"stats":{"Line":3}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":4}},{"line":112,"address":[],"length":0,"stats":{"Line":2}},{"line":113,"address":[],"length":0,"stats":{"Line":2}},{"line":114,"address":[],"length":0,"stats":{"Line":2}},{"line":115,"address":[],"length":0,"stats":{"Line":4}},{"line":116,"address":[],"length":0,"stats":{"Line":2}},{"line":117,"address":[],"length":0,"stats":{"Line":2}},{"line":137,"address":[],"length":0,"stats":{"Line":1}},{"line":142,"address":[],"length":0,"stats":{"Line":2}},{"line":143,"address":[],"length":0,"stats":{"Line":1}},{"line":145,"address":[],"length":0,"stats":{"Line":1}},{"line":147,"address":[],"length":0,"stats":{"Line":3}},{"line":149,"address":[],"length":0,"stats":{"Line":3}},{"line":150,"address":[],"length":0,"stats":{"Line":1}},{"line":151,"address":[],"length":0,"stats":{"Line":1}},{"line":153,"address":[],"length":0,"stats":{"Line":1}},{"line":154,"address":[],"length":0,"stats":{"Line":1}},{"line":155,"address":[],"length":0,"stats":{"Line":1}},{"line":157,"address":[],"length":0,"stats":{"Line":3}},{"line":158,"address":[],"length":0,"stats":{"Line":1}},{"line":160,"address":[],"length":0,"stats":{"Line":5}},{"line":161,"address":[],"length":0,"stats":{"Line":1}},{"line":162,"address":[],"length":0,"stats":{"Line":1}},{"line":164,"address":[],"length":0,"stats":{"Line":1}},{"line":184,"address":[],"length":0,"stats":{"Line":1}},{"line":190,"address":[],"length":0,"stats":{"Line":2}},{"line":191,"address":[],"length":0,"stats":{"Line":1}},{"line":193,"address":[],"length":0,"stats":{"Line":1}},{"line":195,"address":[],"length":0,"stats":{"Line":3}},{"line":197,"address":[],"length":0,"stats":{"Line":3}},{"line":198,"address":[],"length":0,"stats":{"Line":1}},{"line":199,"address":[],"length":0,"stats":{"Line":1}},{"line":201,"address":[],"length":0,"stats":{"Line":1}},{"line":202,"address":[],"length":0,"stats":{"Line":1}},{"line":203,"address":[],"length":0,"stats":{"Line":1}},{"line":205,"address":[],"length":0,"stats":{"Line":3}},{"line":206,"address":[],"length":0,"stats":{"Line":1}},{"line":207,"address":[],"length":0,"stats":{"Line":1}},{"line":208,"address":[],"length":0,"stats":{"Line":1}},{"line":209,"address":[],"length":0,"stats":{"Line":4}},{"line":211,"address":[],"length":0,"stats":{"Line":3}},{"line":212,"address":[],"length":0,"stats":{"Line":3}},{"line":213,"address":[],"length":0,"stats":{"Line":2}},{"line":214,"address":[],"length":0,"stats":{"Line":1}},{"line":216,"address":[],"length":0,"stats":{"Line":1}},{"line":217,"address":[],"length":0,"stats":{"Line":1}},{"line":219,"address":[],"length":0,"stats":{"Line":1}},{"line":237,"address":[],"length":0,"stats":{"Line":3}},{"line":248,"address":[],"length":0,"stats":{"Line":12}},{"line":249,"address":[],"length":0,"stats":{"Line":6}},{"line":250,"address":[],"length":0,"stats":{"Line":3}},{"line":251,"address":[],"length":0,"stats":{"Line":3}},{"line":253,"address":[],"length":0,"stats":{"Line":6}},{"line":254,"address":[],"length":0,"stats":{"Line":17}},{"line":256,"address":[],"length":0,"stats":{"Line":28}},{"line":257,"address":[],"length":0,"stats":{"Line":11}},{"line":258,"address":[],"length":0,"stats":{"Line":4}},{"line":259,"address":[],"length":0,"stats":{"Line":2}},{"line":263,"address":[],"length":0,"stats":{"Line":15}},{"line":264,"address":[],"length":0,"stats":{"Line":15}},{"line":265,"address":[],"length":0,"stats":{"Line":5}},{"line":266,"address":[],"length":0,"stats":{"Line":15}},{"line":267,"address":[],"length":0,"stats":{"Line":15}},{"line":268,"address":[],"length":0,"stats":{"Line":15}},{"line":269,"address":[],"length":0,"stats":{"Line":15}},{"line":270,"address":[],"length":0,"stats":{"Line":15}},{"line":274,"address":[],"length":0,"stats":{"Line":3}},{"line":293,"address":[],"length":0,"stats":{"Line":2}},{"line":299,"address":[],"length":0,"stats":{"Line":2}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":4}},{"line":310,"address":[],"length":0,"stats":{"Line":6}},{"line":311,"address":[],"length":0,"stats":{"Line":4}},{"line":312,"address":[],"length":0,"stats":{"Line":2}},{"line":314,"address":[],"length":0,"stats":{"Line":2}},{"line":315,"address":[],"length":0,"stats":{"Line":2}},{"line":317,"address":[],"length":0,"stats":{"Line":2}},{"line":321,"address":[],"length":0,"stats":{"Line":6}},{"line":326,"address":[],"length":0,"stats":{"Line":12}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":331,"address":[],"length":0,"stats":{"Line":6}},{"line":342,"address":[],"length":0,"stats":{"Line":1}},{"line":347,"address":[],"length":0,"stats":{"Line":1}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":0}},{"line":350,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":2}},{"line":357,"address":[],"length":0,"stats":{"Line":1}},{"line":359,"address":[],"length":0,"stats":{"Line":1}},{"line":361,"address":[],"length":0,"stats":{"Line":2}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":364,"address":[],"length":0,"stats":{"Line":1}},{"line":365,"address":[],"length":0,"stats":{"Line":1}},{"line":366,"address":[],"length":0,"stats":{"Line":1}},{"line":367,"address":[],"length":0,"stats":{"Line":1}},{"line":368,"address":[],"length":0,"stats":{"Line":1}},{"line":372,"address":[],"length":0,"stats":{"Line":2}},{"line":373,"address":[],"length":0,"stats":{"Line":9}},{"line":374,"address":[],"length":0,"stats":{"Line":16}},{"line":375,"address":[],"length":0,"stats":{"Line":16}},{"line":376,"address":[],"length":0,"stats":{"Line":4}},{"line":377,"address":[],"length":0,"stats":{"Line":4}},{"line":379,"address":[],"length":0,"stats":{"Line":6}},{"line":380,"address":[],"length":0,"stats":{"Line":2}},{"line":381,"address":[],"length":0,"stats":{"Line":2}},{"line":386,"address":[],"length":0,"stats":{"Line":1}}],"covered":117,"coverable":136},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","backend.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","bridge.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","config.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","ecosystem.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","episodic.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","federation.rs"],"content":"use crate::repository::RepositoryError;\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct UpstreamConfig {\n    pub id: String,\n    pub url: String,\n    pub branch: String,\n    pub auth_token: Option\u003cString\u003e\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct FederationConfig {\n    pub upstreams: Vec\u003cUpstreamConfig\u003e,\n    pub sync_interval_secs: u64\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct KnowledgeManifest {\n    pub version: String,\n    pub items: HashMap\u003cString, String\u003e\n}\n\n#[async_trait::async_trait]\npub trait FederationProvider: Send + Sync {\n    fn config(\u0026self) -\u003e \u0026FederationConfig;\n    async fn fetch_upstream_manifest(\n        \u0026self,\n        upstream_id: \u0026str\n    ) -\u003e Result\u003cKnowledgeManifest, RepositoryError\u003e;\n    async fn sync_upstream(\n        \u0026self,\n        upstream_id: \u0026str,\n        target_path: \u0026std::path::Path\n    ) -\u003e Result\u003c(), RepositoryError\u003e;\n}\n\npub struct FederationManager {\n    config: FederationConfig\n}\n\n#[async_trait::async_trait]\nimpl FederationProvider for FederationManager {\n    fn config(\u0026self) -\u003e \u0026FederationConfig {\n        \u0026self.config\n    }\n\n    async fn fetch_upstream_manifest(\n        \u0026self,\n        upstream_id: \u0026str\n    ) -\u003e Result\u003cKnowledgeManifest, RepositoryError\u003e {\n        let _upstream = self\n            .config\n            .upstreams\n            .iter()\n            .find(|u| u.id == upstream_id)\n            .ok_or_else(|| {\n                RepositoryError::InvalidPath(format!(\"Upstream not found: {}\", upstream_id))\n            })?;\n\n        Ok(KnowledgeManifest {\n            version: \"1.0\".to_string(),\n            items: HashMap::new()\n        })\n    }\n\n    async fn sync_upstream(\n        \u0026self,\n        upstream_id: \u0026str,\n        target_path: \u0026std::path::Path\n    ) -\u003e Result\u003c(), RepositoryError\u003e {\n        let upstream = self\n            .config\n            .upstreams\n            .iter()\n            .find(|u| u.id == upstream_id)\n            .ok_or_else(|| {\n                RepositoryError::InvalidPath(format!(\"Upstream not found: {}\", upstream_id))\n            })?;\n\n        if target_path.exists() {\n            let repo = git2::Repository::open(target_path)?;\n            let mut remote = repo.find_remote(\"origin\")?;\n            remote.fetch(\u0026[\u0026upstream.branch], None, None)?;\n\n            let head = repo.head()?.peel_to_commit()?;\n            let remote_ref =\n                repo.find_reference(\u0026format!(\"refs/remotes/origin/{}\", upstream.branch))?;\n            let remote_commit = remote_ref.peel_to_commit()?;\n\n            if repo.merge_base(head.id(), remote_commit.id())? != remote_commit.id() {\n                return Err(RepositoryError::InvalidPath(\n                    \"Local changes conflict with upstream\".to_string()\n                ));\n            }\n        } else {\n            git2::Repository::clone(\u0026upstream.url, target_path)?;\n        }\n\n        Ok(())\n    }\n}\n\nimpl FederationManager {\n    pub fn new(config: FederationConfig) -\u003e Self {\n        Self { config }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_federation_config_serialization() {\n        let config = FederationConfig {\n            upstreams: vec![UpstreamConfig {\n                id: \"test\".to_string(),\n                url: \"https://github.com/test/repo\".to_string(),\n                branch: \"main\".to_string(),\n                auth_token: Some(\"secret\".to_string())\n            }],\n            sync_interval_secs: 3600\n        };\n\n        let json = serde_json::to_string(\u0026config).unwrap();\n        let decoded: FederationConfig = serde_json::from_str(\u0026json).unwrap();\n\n        assert_eq!(decoded.upstreams.len(), 1);\n        assert_eq!(decoded.upstreams[0].id, \"test\");\n        assert_eq!(decoded.sync_interval_secs, 3600);\n    }\n\n    #[tokio::test]\n    async fn test_fetch_upstream_manifest_not_found() {\n        let manager = FederationManager::new(FederationConfig {\n            upstreams: vec![],\n            sync_interval_secs: 60\n        });\n\n        let result = manager.fetch_upstream_manifest(\"nonexistent\").await;\n        assert!(result.is_err());\n        match result {\n            Err(RepositoryError::InvalidPath(msg)) =\u003e assert!(msg.contains(\"Upstream not found\")),\n            _ =\u003e panic!(\"Expected InvalidPath error\")\n        }\n    }\n\n    #[tokio::test]\n    async fn test_sync_upstream_not_found() {\n        let manager = FederationManager::new(FederationConfig {\n            upstreams: vec![],\n            sync_interval_secs: 60\n        });\n\n        let result = manager\n            .sync_upstream(\"nonexistent\", std::path::Path::new(\"/tmp\"))\n            .await;\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_knowledge_manifest_serialization() {\n        let mut items = HashMap::new();\n        items.insert(\"key1\".to_string(), \"hash1\".to_string());\n\n        let manifest = KnowledgeManifest {\n            version: \"1.0\".to_string(),\n            items\n        };\n\n        let json = serde_json::to_string(\u0026manifest).unwrap();\n        let decoded: KnowledgeManifest = serde_json::from_str(\u0026json).unwrap();\n\n        assert_eq!(decoded.version, \"1.0\");\n        assert_eq!(decoded.items.get(\"key1\").unwrap(), \"hash1\");\n    }\n}\n","traces":[{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":1}},{"line":59,"address":[],"length":0,"stats":{"Line":1}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":1}},{"line":79,"address":[],"length":0,"stats":{"Line":1}},{"line":106,"address":[],"length":0,"stats":{"Line":2}}],"covered":5,"coverable":9},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","governance.rs"],"content":"use crate::telemetry::KnowledgeTelemetry;\nuse mk_core::traits::{EmbeddingService, EventPublisher, LlmService};\nuse mk_core::types::{\n    ConstraintSeverity, GovernanceEvent, KnowledgeLayer, Policy, PolicyViolation, TenantContext,\n    ValidationResult,\n};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse storage::events::EventError;\n\npub struct GovernanceEngine {\n    policies: HashMap\u003cKnowledgeLayer, Vec\u003cPolicy\u003e\u003e,\n    telemetry: KnowledgeTelemetry,\n    storage:\n        Option\u003cArc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e\u003e,\n    event_publisher: Option\u003cArc\u003cdyn EventPublisher\u003cError = EventError\u003e\u003e\u003e,\n    embedding_service: Option\u003cArc\u003cdyn EmbeddingService\u003cError = anyhow::Error\u003e\u003e\u003e,\n    llm_service: Option\u003cArc\u003cdyn LlmService\u003cError = anyhow::Error\u003e\u003e\u003e,\n    knowledge_repository: Option\u003c\n        Arc\u003cdyn mk_core::traits::KnowledgeRepository\u003cError = crate::repository::RepositoryError\u003e\u003e,\n    \u003e,\n}\n\nimpl GovernanceEngine {\n    pub fn new() -\u003e Self {\n        Self {\n            policies: HashMap::new(),\n            telemetry: KnowledgeTelemetry,\n            storage: None,\n            event_publisher: None,\n            embedding_service: None,\n            llm_service: None,\n            knowledge_repository: None,\n        }\n    }\n\n    pub fn with_storage(\n        mut self,\n        storage: Arc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e,\n    ) -\u003e Self {\n        self.storage = Some(storage);\n        self\n    }\n\n    pub fn with_event_publisher(\n        mut self,\n        publisher: Arc\u003cdyn EventPublisher\u003cError = EventError\u003e\u003e,\n    ) -\u003e Self {\n        self.event_publisher = Some(publisher);\n        self\n    }\n\n    pub fn with_embedding_service(\n        mut self,\n        embedding_service: Arc\u003cdyn EmbeddingService\u003cError = anyhow::Error\u003e\u003e,\n    ) -\u003e Self {\n        self.embedding_service = Some(embedding_service);\n        self\n    }\n\n    pub fn with_llm_service(\n        mut self,\n        llm_service: Arc\u003cdyn LlmService\u003cError = anyhow::Error\u003e\u003e,\n    ) -\u003e Self {\n        self.llm_service = Some(llm_service);\n        self\n    }\n\n    pub fn with_repository(\n        mut self,\n        repository: Arc\u003c\n            dyn mk_core::traits::KnowledgeRepository\u003cError = crate::repository::RepositoryError\u003e,\n        \u003e,\n    ) -\u003e Self {\n        self.knowledge_repository = Some(repository);\n        self\n    }\n\n    pub fn storage(\n        \u0026self,\n    ) -\u003e Option\u003cArc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e\u003e\n    {\n        self.storage.clone()\n    }\n\n    pub fn llm_service(\u0026self) -\u003e Option\u003cArc\u003cdyn LlmService\u003cError = anyhow::Error\u003e\u003e\u003e {\n        self.llm_service.clone()\n    }\n\n    pub fn repository(\n        \u0026self,\n    ) -\u003e Option\u003c\n        Arc\u003cdyn mk_core::traits::KnowledgeRepository\u003cError = crate::repository::RepositoryError\u003e\u003e,\n    \u003e {\n        self.knowledge_repository.clone()\n    }\n    pub async fn publish_event(\u0026self, event: GovernanceEvent) -\u003e Result\u003c(), EventError\u003e {\n        if let Some(publisher) = \u0026self.event_publisher {\n            publisher.publish(event).await\n        } else {\n            Ok(())\n        }\n    }\n}\n\nimpl Default for GovernanceEngine {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\nimpl GovernanceEngine {\n    pub fn add_policy(\u0026mut self, policy: Policy) {\n        self.policies.entry(policy.layer).or_default().push(policy);\n    }\n\n    pub fn event_publisher(\u0026self) -\u003e Option\u003cArc\u003cdyn EventPublisher\u003cError = EventError\u003e\u003e\u003e {\n        self.event_publisher.clone()\n    }\n\n    pub fn validate(\n        \u0026self,\n        target_layer: KnowledgeLayer,\n        context: \u0026HashMap\u003cString, serde_json::Value\u003e,\n    ) -\u003e ValidationResult {\n        let mut resolved_map: HashMap\u003cString, Policy\u003e = HashMap::new();\n        let mut mandatory_policies: HashMap\u003cString, KnowledgeLayer\u003e = HashMap::new();\n\n        let layers = [\n            KnowledgeLayer::Company,\n            KnowledgeLayer::Org,\n            KnowledgeLayer::Team,\n            KnowledgeLayer::Project,\n        ];\n\n        for layer in \u0026layers {\n            if let Some(layer_policies) = self.policies.get(layer) {\n                for policy in layer_policies {\n                    let mut p = policy.clone();\n                    p.layer = *layer;\n                    self.merge_policy(\u0026mut resolved_map, \u0026mut mandatory_policies, p);\n                }\n            }\n            if layer == \u0026target_layer {\n                break;\n            }\n        }\n\n        let mut violations = Vec::new();\n        let mut resolved_vec: Vec\u003cPolicy\u003e = resolved_map.into_values().collect();\n        resolved_vec.sort_by_key(|p| p.layer);\n\n        for policy in resolved_vec {\n            for rule in \u0026policy.rules {\n                if let Some(violation) = self.evaluate_rule(\u0026policy, rule, context) {\n                    self.telemetry.record_violation(\n                        \u0026format!(\"{:?}\", policy.layer),\n                        \u0026format!(\"{:?}\", rule.severity),\n                    );\n                    violations.push(violation);\n                }\n            }\n        }\n\n        ValidationResult {\n            is_valid: violations.is_empty(),\n            violations,\n        }\n    }\n\n    pub async fn validate_with_context(\n        \u0026self,\n        target_layer: KnowledgeLayer,\n        context: \u0026HashMap\u003cString, serde_json::Value\u003e,\n        tenant_ctx: Option\u003c\u0026TenantContext\u003e,\n    ) -\u003e ValidationResult {\n        let mut violations = Vec::new();\n\n        let active_policies = self\n            .resolve_active_policies(target_layer, context, tenant_ctx)\n            .await;\n\n        for policy in active_policies {\n            for rule in \u0026policy.rules {\n                if let Some(violation) = self.evaluate_rule(\u0026policy, rule, context) {\n                    self.telemetry.record_violation(\n                        \u0026format!(\"{:?}\", policy.layer),\n                        \u0026format!(\"{:?}\", rule.severity),\n                    );\n                    violations.push(violation);\n                }\n            }\n        }\n\n        if !violations.is_empty() {\n            self.emit_drift_event(context, tenant_ctx, \u0026violations)\n                .await;\n        }\n\n        ValidationResult {\n            is_valid: violations.is_empty(),\n            violations,\n        }\n    }\n\n    async fn resolve_active_policies(\n        \u0026self,\n        target_layer: KnowledgeLayer,\n        context: \u0026HashMap\u003cString, serde_json::Value\u003e,\n        tenant_ctx: Option\u003c\u0026TenantContext\u003e,\n    ) -\u003e Vec\u003cPolicy\u003e {\n        let mut resolved_map: HashMap\u003cString, Policy\u003e = HashMap::new();\n        let mut mandatory_policies: HashMap\u003cString, KnowledgeLayer\u003e = HashMap::new();\n\n        let layers = [\n            KnowledgeLayer::Company,\n            KnowledgeLayer::Org,\n            KnowledgeLayer::Team,\n            KnowledgeLayer::Project,\n        ];\n\n        for layer in \u0026layers {\n            if let Some(layer_policies) = self.policies.get(layer) {\n                for policy in layer_policies {\n                    self.merge_policy(\u0026mut resolved_map, \u0026mut mandatory_policies, policy.clone());\n                }\n            }\n            if layer == \u0026target_layer {\n                break;\n            }\n        }\n\n        if let Some(storage) = \u0026self.storage {\n            let unit_id = context\n                .get(\"unitId\")\n                .or_else(|| context.get(\"projectId\"))\n                .and_then(|v| v.as_str());\n\n            if let Some(uid) = unit_id {\n                let ctx = tenant_ctx.cloned().unwrap_or_default();\n\n                let mut units = Vec::new();\n                if let Ok(mut ancestors) = storage.get_ancestors(ctx.clone(), uid).await {\n                    units.append(\u0026mut ancestors);\n                }\n\n                units.reverse();\n\n                for unit in units {\n                    if let Ok(unit_policies) =\n                        storage.get_unit_policies(ctx.clone(), \u0026unit.id).await\n                    {\n                        for policy in unit_policies {\n                            self.merge_policy(\u0026mut resolved_map, \u0026mut mandatory_policies, policy);\n                        }\n                    }\n                }\n\n                if let Ok(unit_policies) = storage.get_unit_policies(ctx, uid).await {\n                    for policy in unit_policies {\n                        self.merge_policy(\u0026mut resolved_map, \u0026mut mandatory_policies, policy);\n                    }\n                }\n            }\n        }\n\n        resolved_map.into_values().collect()\n    }\n\n    fn merge_policy(\n        \u0026self,\n        resolved: \u0026mut HashMap\u003cString, Policy\u003e,\n        mandatory_policies: \u0026mut HashMap\u003cString, KnowledgeLayer\u003e,\n        incoming: Policy,\n    ) {\n        use mk_core::types::{PolicyMode, RuleMergeStrategy};\n\n        let policy_id = incoming.id.clone();\n\n        if let Some(mandatory_layer) = mandatory_policies.get(\u0026policy_id) {\n            if incoming.layer != *mandatory_layer\n                \u0026\u0026 incoming.merge_strategy != RuleMergeStrategy::Override\n            {\n                return;\n            }\n        }\n\n        if incoming.mode == PolicyMode::Mandatory {\n            mandatory_policies.insert(policy_id.clone(), incoming.layer);\n        }\n\n        if let Some(existing) = resolved.get_mut(\u0026policy_id) {\n            match incoming.merge_strategy {\n                RuleMergeStrategy::Override =\u003e {\n                    *existing = incoming;\n                }\n                RuleMergeStrategy::Merge =\u003e {\n                    for rule in incoming.rules {\n                        if !existing.rules.iter().any(|r| r.id == rule.id) {\n                            existing.rules.push(rule);\n                        }\n                    }\n                    for (k, v) in incoming.metadata {\n                        existing.metadata.insert(k, v);\n                    }\n                    existing.layer = incoming.layer;\n                }\n                RuleMergeStrategy::Intersect =\u003e {\n                    existing\n                        .rules\n                        .retain(|r| incoming.rules.iter().any(|ir| ir.id == r.id));\n                    existing.layer = incoming.layer;\n                }\n            }\n        } else {\n            resolved.insert(policy_id, incoming);\n        }\n    }\n\n    pub async fn check_drift(\n        \u0026self,\n        tenant_ctx: \u0026TenantContext,\n        _project_id: \u0026str,\n        context: \u0026HashMap\u003cString, serde_json::Value\u003e,\n    ) -\u003e Result\u003cf32, anyhow::Error\u003e {\n        let mut violations = Vec::new();\n\n        let content = context.get(\"content\").and_then(|v| v.as_str());\n        if let Some(c) = content {\n            if self.embedding_service.is_some() {\n                let mut semantic_violations = self.check_contradictions(tenant_ctx, c, 0.8).await?;\n                violations.append(\u0026mut semantic_violations);\n            }\n        }\n\n        let active_policies = self\n            .resolve_active_policies(KnowledgeLayer::Project, context, Some(tenant_ctx))\n            .await;\n\n        for policy in \u0026active_policies {\n            for rule in \u0026policy.rules {\n                if let Some(violation) = self.evaluate_rule(policy, rule, context) {\n                    violations.push(violation);\n                }\n            }\n        }\n\n        let mandatory_policies_count = active_policies\n            .iter()\n            .filter(|p| p.mode == mk_core::types::PolicyMode::Mandatory)\n            .count();\n\n        if mandatory_policies_count == 0 {\n            violations.push(PolicyViolation {\n                rule_id: \"missing_mandatory_policies\".to_string(),\n                policy_id: \"governance_requirement\".to_string(),\n                severity: ConstraintSeverity::Warn,\n                message: \"No mandatory policies detected for this project layer\".to_string(),\n                context: context.clone(),\n            });\n        }\n\n        for policy in \u0026active_policies {\n            if let Some(expected_hash) =\n                policy.metadata.get(\"version_hash\").and_then(|v| v.as_str())\n            {\n                let actual_hash = context.get(\"version_hash\").and_then(|v| v.as_str());\n                if let Some(actual) = actual_hash {\n                    if actual != expected_hash {\n                        violations.push(PolicyViolation {\n                            rule_id: \"stale_policy_reference\".to_string(),\n                            policy_id: policy.id.clone(),\n                            severity: ConstraintSeverity::Warn,\n                            message: format!(\n                                \"Project uses stale policy version (expected: {}, actual: {})\",\n                                expected_hash, actual\n                            ),\n                            context: context.clone(),\n                        });\n                    }\n                }\n            }\n        }\n\n        if let Some(c) = content {\n            if let Some(llm_violations) = self\n                .analyze_drift_with_llm(c, \u0026active_policies, context)\n                .await\n            {\n                for v in llm_violations {\n                    if !violations\n                        .iter()\n                        .any(|existing| existing.rule_id == v.rule_id)\n                    {\n                        violations.push(v);\n                    }\n                }\n            }\n        }\n\n        let drift_score = self.calculate_drift_score(\u0026violations);\n\n        if drift_score \u003e 0.0 {\n            self.emit_drift_event(context, Some(tenant_ctx), \u0026violations)\n                .await;\n        }\n\n        if let Some(storage) = \u0026self.storage {\n            let _ = storage\n                .store_drift_result(mk_core::types::DriftResult {\n                    project_id: _project_id.to_string(),\n                    tenant_id: tenant_ctx.tenant_id.clone(),\n                    drift_score,\n                    violations: violations.clone(),\n                    timestamp: chrono::Utc::now().timestamp(),\n                })\n                .await;\n        }\n\n        Ok(drift_score)\n    }\n\n    async fn analyze_drift_with_llm(\n        \u0026self,\n        content: \u0026str,\n        policies: \u0026[Policy],\n        context: \u0026HashMap\u003cString, serde_json::Value\u003e,\n    ) -\u003e Option\u003cVec\u003cPolicyViolation\u003e\u003e {\n        let llm = self.llm_service.as_ref()?;\n\n        if policies.is_empty() {\n            return None;\n        }\n\n        match llm.analyze_drift(content, policies).await {\n            Ok(result) =\u003e {\n                if result.is_valid {\n                    return None;\n                }\n\n                let violations = result\n                    .violations\n                    .into_iter()\n                    .map(|v| PolicyViolation {\n                        rule_id: format!(\"llm_{}\", v.rule_id),\n                        policy_id: v.policy_id,\n                        severity: v.severity,\n                        message: format!(\"[LLM Analysis] {}\", v.message),\n                        context: context.clone(),\n                    })\n                    .collect();\n\n                Some(violations)\n            }\n            Err(e) =\u003e {\n                tracing::warn!(\"LLM drift analysis failed: {}\", e);\n                None\n            }\n        }\n    }\n\n    fn calculate_drift_score(\u0026self, violations: \u0026[PolicyViolation]) -\u003e f32 {\n        if violations.is_empty() {\n            return 0.0;\n        }\n\n        let score = violations\n            .iter()\n            .map(|v| match v.severity {\n                ConstraintSeverity::Block =\u003e 1.0,\n                ConstraintSeverity::Warn =\u003e 0.5,\n                ConstraintSeverity::Info =\u003e 0.1,\n            })\n            .sum::\u003cf32\u003e();\n\n        score.min(1.0)\n    }\n\n    async fn emit_drift_event(\n        \u0026self,\n        context: \u0026HashMap\u003cString, serde_json::Value\u003e,\n        tenant_ctx: Option\u003c\u0026TenantContext\u003e,\n        violations: \u0026[PolicyViolation],\n    ) {\n        if let Some(publisher) = \u0026self.event_publisher {\n            let project_id = context\n                .get(\"projectId\")\n                .and_then(|v| v.as_str())\n                .or_else(|| context.get(\"unitId\").and_then(|v| v.as_str()));\n\n            if let Some(pid) = project_id {\n                let drift_score = violations\n                    .iter()\n                    .map(|v| match v.severity {\n                        mk_core::types::ConstraintSeverity::Block =\u003e 1.0,\n                        mk_core::types::ConstraintSeverity::Warn =\u003e 0.5,\n                        mk_core::types::ConstraintSeverity::Info =\u003e 0.1,\n                    })\n                    .sum::\u003cf32\u003e();\n\n                let _ = publisher\n                    .publish(GovernanceEvent::DriftDetected {\n                        project_id: pid.to_string(),\n                        tenant_id: tenant_ctx.map(|c| c.tenant_id.clone()).unwrap_or_default(),\n                        drift_score: drift_score.min(1.0),\n                        timestamp: chrono::Utc::now().timestamp(),\n                    })\n                    .await;\n            }\n        }\n    }\n\n    fn evaluate_rule(\n        \u0026self,\n        policy: \u0026Policy,\n        rule: \u0026mk_core::types::PolicyRule,\n        context: \u0026HashMap\u003cString, serde_json::Value\u003e,\n    ) -\u003e Option\u003cPolicyViolation\u003e {\n        use mk_core::types::{ConstraintOperator, RuleType};\n\n        let target_key = match rule.target {\n            mk_core::types::ConstraintTarget::File =\u003e \"path\",\n            mk_core::types::ConstraintTarget::Code =\u003e \"content\",\n            mk_core::types::ConstraintTarget::Dependency =\u003e \"dependencies\",\n            mk_core::types::ConstraintTarget::Import =\u003e \"imports\",\n            mk_core::types::ConstraintTarget::Config =\u003e \"config\",\n        };\n\n        let value = context.get(target_key);\n\n        let is_condition_met = match rule.operator {\n            ConstraintOperator::MustExist =\u003e value.is_some(),\n            ConstraintOperator::MustNotExist =\u003e value.is_none(),\n            ConstraintOperator::MustUse =\u003e {\n                if let Some(v) = value {\n                    if let Some(arr) = v.as_array() {\n                        arr.contains(\u0026rule.value)\n                    } else {\n                        v == \u0026rule.value\n                    }\n                } else {\n                    false\n                }\n            }\n            ConstraintOperator::MustNotUse =\u003e {\n                if let Some(v) = value {\n                    if let Some(arr) = v.as_array() {\n                        !arr.contains(\u0026rule.value)\n                    } else {\n                        v != \u0026rule.value\n                    }\n                } else {\n                    true\n                }\n            }\n            ConstraintOperator::MustMatch =\u003e {\n                if let Some(v) = value {\n                    if let Some(s) = v.as_str() {\n                        if let Some(re_str) = rule.value.as_str() {\n                            if let Ok(re) = regex::Regex::new(re_str) {\n                                re.is_match(s)\n                            } else {\n                                false\n                            }\n                        } else {\n                            false\n                        }\n                    } else {\n                        false\n                    }\n                } else {\n                    false\n                }\n            }\n            ConstraintOperator::MustNotMatch =\u003e {\n                if let Some(v) = value {\n                    if let Some(s) = v.as_str() {\n                        if let Some(re_str) = rule.value.as_str() {\n                            if let Ok(re) = regex::Regex::new(re_str) {\n                                !re.is_match(s)\n                            } else {\n                                true\n                            }\n                        } else {\n                            true\n                        }\n                    } else {\n                        true\n                    }\n                } else {\n                    true\n                }\n            }\n        };\n\n        let is_violated = match rule.rule_type {\n            RuleType::Allow =\u003e !is_condition_met,\n            RuleType::Deny =\u003e is_condition_met,\n        };\n\n        if is_violated {\n            Some(PolicyViolation {\n                rule_id: rule.id.clone(),\n                policy_id: policy.id.clone(),\n                severity: rule.severity,\n                message: rule.message.clone(),\n                context: context.clone(),\n            })\n        } else {\n            None\n        }\n    }\n\n    pub async fn check_contradictions(\n        \u0026self,\n        tenant_ctx: \u0026TenantContext,\n        content: \u0026str,\n        threshold: f32,\n    ) -\u003e Result\u003cVec\u003cPolicyViolation\u003e, anyhow::Error\u003e {\n        let embedding_service = self\n            .embedding_service\n            .as_ref()\n            .ok_or_else(|| anyhow::anyhow!(\"Embedding service not configured\"))?;\n\n        let content_embedding = embedding_service.embed(content).await?;\n\n        let mut violations = Vec::new();\n\n        let mut context = HashMap::new();\n        context.insert(\"content\".to_string(), serde_json::json!(content));\n\n        let active_policies = self\n            .resolve_active_policies(KnowledgeLayer::Project, \u0026context, Some(tenant_ctx))\n            .await;\n\n        for policy in active_policies {\n            for rule in \u0026policy.rules {\n                if let Some(rule_embedding_val) =\n                    policy.metadata.get(\u0026format!(\"rule_{}_embedding\", rule.id))\n                {\n                    if let Ok(rule_embedding) =\n                        serde_json::from_value::\u003cVec\u003cf32\u003e\u003e(rule_embedding_val.clone())\n                    {\n                        let similarity =\n                            self.cosine_similarity(\u0026content_embedding, \u0026rule_embedding);\n                        if similarity \u003e threshold {\n                            violations.push(PolicyViolation {\n                                rule_id: rule.id.clone(),\n                                policy_id: policy.id.clone(),\n                                severity: rule.severity,\n                                message: format!(\n                                    \"Semantic contradiction detected (similarity: {:.2}): {}\",\n                                    similarity, rule.message\n                                ),\n                                context: context.clone(),\n                            });\n                        }\n                    }\n                }\n            }\n        }\n\n        Ok(violations)\n    }\n\n    fn cosine_similarity(\u0026self, v1: \u0026[f32], v2: \u0026[f32]) -\u003e f32 {\n        if v1.len() != v2.len() || v1.is_empty() {\n            return 0.0;\n        }\n        let dot_product: f32 = v1.iter().zip(v2.iter()).map(|(a, b)| a * b).sum();\n        let norm1: f32 = v1.iter().map(|a| a * a).sum::\u003cf32\u003e().sqrt();\n        let norm2: f32 = v2.iter().map(|a| a * a).sum::\u003cf32\u003e().sqrt();\n\n        if norm1 == 0.0 || norm2 == 0.0 {\n            0.0\n        } else {\n            dot_product / (norm1 * norm2)\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::{ConstraintOperator, ConstraintSeverity, ConstraintTarget, PolicyRule};\n\n    #[test]\n    fn test_governance_engine_evaluation() {\n        let mut engine = GovernanceEngine::new();\n\n        let company_policy = Policy {\n            id: \"p1\".to_string(),\n            name: \"Security Standards\".to_string(),\n            description: None,\n            layer: KnowledgeLayer::Company,\n            rules: vec![\n                PolicyRule {\n                    id: \"r1\".to_string(),\n                    target: ConstraintTarget::Dependency,\n                    operator: ConstraintOperator::MustNotUse,\n                    value: serde_json::json!(\"unsafe-lib\"),\n                    severity: ConstraintSeverity::Block,\n                    message: \"unsafe-lib is banned\".to_string(),\n                    rule_type: mk_core::types::RuleType::Allow,\n                },\n                PolicyRule {\n                    id: \"r2\".to_string(),\n                    target: ConstraintTarget::Code,\n                    operator: ConstraintOperator::MustMatch,\n                    value: serde_json::json!(\"^# ADR\"),\n                    severity: ConstraintSeverity::Warn,\n                    message: \"ADRs must start with # ADR\".to_string(),\n                    rule_type: mk_core::types::RuleType::Allow,\n                },\n            ],\n            metadata: HashMap::new(),\n            mode: mk_core::types::PolicyMode::Optional,\n            merge_strategy: mk_core::types::RuleMergeStrategy::Merge,\n        };\n\n        engine.add_policy(company_policy);\n\n        let mut context = HashMap::new();\n        context.insert(\n            \"dependencies\".to_string(),\n            serde_json::json!([\"safe-lib\", \"unsafe-lib\"]),\n        );\n        context.insert(\"content\".to_string(), serde_json::json!(\"# ADR 001\\n...\"));\n\n        let result = engine.validate(KnowledgeLayer::Project, \u0026context);\n        assert!(!result.is_valid);\n        assert_eq!(result.violations.len(), 1);\n        assert_eq!(result.violations[0].rule_id, \"r1\");\n\n        let mut context = HashMap::new();\n        context.insert(\"dependencies\".to_string(), serde_json::json!([\"safe-lib\"]));\n        context.insert(\"content\".to_string(), serde_json::json!(\"ADR 001\\n...\"));\n\n        let result = engine.validate(KnowledgeLayer::Project, \u0026context);\n        assert!(!result.is_valid);\n        assert_eq!(result.violations.len(), 1);\n        assert_eq!(result.violations[0].rule_id, \"r2\");\n\n        let mut context = HashMap::new();\n        context.insert(\"dependencies\".to_string(), serde_json::json!([\"safe-lib\"]));\n        context.insert(\"content\".to_string(), serde_json::json!(\"# ADR 001\\n...\"));\n\n        let result = engine.validate(KnowledgeLayer::Project, \u0026context);\n        assert!(result.is_valid);\n    }\n}\n","traces":[{"line":25,"address":[],"length":0,"stats":{"Line":139}},{"line":27,"address":[],"length":0,"stats":{"Line":278}},{"line":37,"address":[],"length":0,"stats":{"Line":9}},{"line":41,"address":[],"length":0,"stats":{"Line":18}},{"line":42,"address":[],"length":0,"stats":{"Line":9}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":5}},{"line":65,"address":[],"length":0,"stats":{"Line":10}},{"line":66,"address":[],"length":0,"stats":{"Line":5}},{"line":69,"address":[],"length":0,"stats":{"Line":1}},{"line":75,"address":[],"length":0,"stats":{"Line":2}},{"line":76,"address":[],"length":0,"stats":{"Line":1}},{"line":79,"address":[],"length":0,"stats":{"Line":3}},{"line":83,"address":[],"length":0,"stats":{"Line":6}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":6}},{"line":95,"address":[],"length":0,"stats":{"Line":12}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":49}},{"line":114,"address":[],"length":0,"stats":{"Line":245}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":1063}},{"line":126,"address":[],"length":0,"stats":{"Line":3189}},{"line":127,"address":[],"length":0,"stats":{"Line":3189}},{"line":129,"address":[],"length":0,"stats":{"Line":2126}},{"line":130,"address":[],"length":0,"stats":{"Line":2126}},{"line":131,"address":[],"length":0,"stats":{"Line":2126}},{"line":132,"address":[],"length":0,"stats":{"Line":1063}},{"line":133,"address":[],"length":0,"stats":{"Line":1063}},{"line":136,"address":[],"length":0,"stats":{"Line":8458}},{"line":137,"address":[],"length":0,"stats":{"Line":8502}},{"line":138,"address":[],"length":0,"stats":{"Line":182}},{"line":139,"address":[],"length":0,"stats":{"Line":184}},{"line":140,"address":[],"length":0,"stats":{"Line":92}},{"line":141,"address":[],"length":0,"stats":{"Line":184}},{"line":144,"address":[],"length":0,"stats":{"Line":4229}},{"line":145,"address":[],"length":0,"stats":{"Line":1063}},{"line":149,"address":[],"length":0,"stats":{"Line":2126}},{"line":150,"address":[],"length":0,"stats":{"Line":5315}},{"line":151,"address":[],"length":0,"stats":{"Line":2126}},{"line":153,"address":[],"length":0,"stats":{"Line":1137}},{"line":154,"address":[],"length":0,"stats":{"Line":135}},{"line":155,"address":[],"length":0,"stats":{"Line":246}},{"line":156,"address":[],"length":0,"stats":{"Line":75}},{"line":157,"address":[],"length":0,"stats":{"Line":50}},{"line":158,"address":[],"length":0,"stats":{"Line":50}},{"line":160,"address":[],"length":0,"stats":{"Line":50}},{"line":166,"address":[],"length":0,"stats":{"Line":2126}},{"line":171,"address":[],"length":0,"stats":{"Line":3}},{"line":177,"address":[],"length":0,"stats":{"Line":6}},{"line":179,"address":[],"length":0,"stats":{"Line":9}},{"line":180,"address":[],"length":0,"stats":{"Line":12}},{"line":181,"address":[],"length":0,"stats":{"Line":3}},{"line":183,"address":[],"length":0,"stats":{"Line":3}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":3}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":201,"address":[],"length":0,"stats":{"Line":6}},{"line":206,"address":[],"length":0,"stats":{"Line":42}},{"line":212,"address":[],"length":0,"stats":{"Line":126}},{"line":213,"address":[],"length":0,"stats":{"Line":126}},{"line":215,"address":[],"length":0,"stats":{"Line":84}},{"line":216,"address":[],"length":0,"stats":{"Line":84}},{"line":217,"address":[],"length":0,"stats":{"Line":84}},{"line":218,"address":[],"length":0,"stats":{"Line":42}},{"line":219,"address":[],"length":0,"stats":{"Line":42}},{"line":222,"address":[],"length":0,"stats":{"Line":336}},{"line":223,"address":[],"length":0,"stats":{"Line":362}},{"line":224,"address":[],"length":0,"stats":{"Line":107}},{"line":225,"address":[],"length":0,"stats":{"Line":135}},{"line":228,"address":[],"length":0,"stats":{"Line":168}},{"line":229,"address":[],"length":0,"stats":{"Line":42}},{"line":233,"address":[],"length":0,"stats":{"Line":52}},{"line":234,"address":[],"length":0,"stats":{"Line":20}},{"line":236,"address":[],"length":0,"stats":{"Line":10}},{"line":237,"address":[],"length":0,"stats":{"Line":30}},{"line":239,"address":[],"length":0,"stats":{"Line":20}},{"line":240,"address":[],"length":0,"stats":{"Line":40}},{"line":242,"address":[],"length":0,"stats":{"Line":20}},{"line":243,"address":[],"length":0,"stats":{"Line":70}},{"line":244,"address":[],"length":0,"stats":{"Line":20}},{"line":247,"address":[],"length":0,"stats":{"Line":10}},{"line":249,"address":[],"length":0,"stats":{"Line":36}},{"line":250,"address":[],"length":0,"stats":{"Line":13}},{"line":251,"address":[],"length":0,"stats":{"Line":65}},{"line":253,"address":[],"length":0,"stats":{"Line":46}},{"line":254,"address":[],"length":0,"stats":{"Line":44}},{"line":259,"address":[],"length":0,"stats":{"Line":50}},{"line":260,"address":[],"length":0,"stats":{"Line":25}},{"line":261,"address":[],"length":0,"stats":{"Line":20}},{"line":267,"address":[],"length":0,"stats":{"Line":126}},{"line":270,"address":[],"length":0,"stats":{"Line":89}},{"line":278,"address":[],"length":0,"stats":{"Line":267}},{"line":280,"address":[],"length":0,"stats":{"Line":182}},{"line":281,"address":[],"length":0,"stats":{"Line":4}},{"line":282,"address":[],"length":0,"stats":{"Line":4}},{"line":284,"address":[],"length":0,"stats":{"Line":2}},{"line":288,"address":[],"length":0,"stats":{"Line":145}},{"line":289,"address":[],"length":0,"stats":{"Line":232}},{"line":292,"address":[],"length":0,"stats":{"Line":182}},{"line":293,"address":[],"length":0,"stats":{"Line":8}},{"line":294,"address":[],"length":0,"stats":{"Line":5}},{"line":295,"address":[],"length":0,"stats":{"Line":5}},{"line":298,"address":[],"length":0,"stats":{"Line":9}},{"line":299,"address":[],"length":0,"stats":{"Line":15}},{"line":300,"address":[],"length":0,"stats":{"Line":6}},{"line":303,"address":[],"length":0,"stats":{"Line":3}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":306,"address":[],"length":0,"stats":{"Line":3}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":237}},{"line":320,"address":[],"length":0,"stats":{"Line":39}},{"line":326,"address":[],"length":0,"stats":{"Line":78}},{"line":328,"address":[],"length":0,"stats":{"Line":211}},{"line":329,"address":[],"length":0,"stats":{"Line":47}},{"line":330,"address":[],"length":0,"stats":{"Line":16}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":117}},{"line":337,"address":[],"length":0,"stats":{"Line":156}},{"line":338,"address":[],"length":0,"stats":{"Line":39}},{"line":340,"address":[],"length":0,"stats":{"Line":123}},{"line":341,"address":[],"length":0,"stats":{"Line":130}},{"line":342,"address":[],"length":0,"stats":{"Line":228}},{"line":343,"address":[],"length":0,"stats":{"Line":52}},{"line":348,"address":[],"length":0,"stats":{"Line":78}},{"line":350,"address":[],"length":0,"stats":{"Line":123}},{"line":353,"address":[],"length":0,"stats":{"Line":45}},{"line":354,"address":[],"length":0,"stats":{"Line":18}},{"line":355,"address":[],"length":0,"stats":{"Line":18}},{"line":356,"address":[],"length":0,"stats":{"Line":18}},{"line":357,"address":[],"length":0,"stats":{"Line":12}},{"line":358,"address":[],"length":0,"stats":{"Line":18}},{"line":359,"address":[],"length":0,"stats":{"Line":6}},{"line":363,"address":[],"length":0,"stats":{"Line":123}},{"line":364,"address":[],"length":0,"stats":{"Line":2}},{"line":365,"address":[],"length":0,"stats":{"Line":172}},{"line":367,"address":[],"length":0,"stats":{"Line":14}},{"line":368,"address":[],"length":0,"stats":{"Line":4}},{"line":369,"address":[],"length":0,"stats":{"Line":3}},{"line":370,"address":[],"length":0,"stats":{"Line":3}},{"line":371,"address":[],"length":0,"stats":{"Line":3}},{"line":372,"address":[],"length":0,"stats":{"Line":3}},{"line":373,"address":[],"length":0,"stats":{"Line":2}},{"line":374,"address":[],"length":0,"stats":{"Line":2}},{"line":375,"address":[],"length":0,"stats":{"Line":2}},{"line":376,"address":[],"length":0,"stats":{"Line":1}},{"line":378,"address":[],"length":0,"stats":{"Line":1}},{"line":385,"address":[],"length":0,"stats":{"Line":47}},{"line":386,"address":[],"length":0,"stats":{"Line":11}},{"line":387,"address":[],"length":0,"stats":{"Line":32}},{"line":388,"address":[],"length":0,"stats":{"Line":8}},{"line":390,"address":[],"length":0,"stats":{"Line":9}},{"line":391,"address":[],"length":0,"stats":{"Line":3}},{"line":392,"address":[],"length":0,"stats":{"Line":3}},{"line":393,"address":[],"length":0,"stats":{"Line":7}},{"line":395,"address":[],"length":0,"stats":{"Line":6}},{"line":401,"address":[],"length":0,"stats":{"Line":156}},{"line":403,"address":[],"length":0,"stats":{"Line":39}},{"line":404,"address":[],"length":0,"stats":{"Line":145}},{"line":405,"address":[],"length":0,"stats":{"Line":29}},{"line":408,"address":[],"length":0,"stats":{"Line":49}},{"line":409,"address":[],"length":0,"stats":{"Line":20}},{"line":410,"address":[],"length":0,"stats":{"Line":20}},{"line":411,"address":[],"length":0,"stats":{"Line":30}},{"line":412,"address":[],"length":0,"stats":{"Line":30}},{"line":413,"address":[],"length":0,"stats":{"Line":20}},{"line":414,"address":[],"length":0,"stats":{"Line":30}},{"line":415,"address":[],"length":0,"stats":{"Line":10}},{"line":417,"address":[],"length":0,"stats":{"Line":10}},{"line":420,"address":[],"length":0,"stats":{"Line":39}},{"line":423,"address":[],"length":0,"stats":{"Line":8}},{"line":429,"address":[],"length":0,"stats":{"Line":24}},{"line":431,"address":[],"length":0,"stats":{"Line":10}},{"line":432,"address":[],"length":0,"stats":{"Line":2}},{"line":435,"address":[],"length":0,"stats":{"Line":12}},{"line":436,"address":[],"length":0,"stats":{"Line":3}},{"line":437,"address":[],"length":0,"stats":{"Line":3}},{"line":438,"address":[],"length":0,"stats":{"Line":0}},{"line":441,"address":[],"length":0,"stats":{"Line":6}},{"line":442,"address":[],"length":0,"stats":{"Line":3}},{"line":444,"address":[],"length":0,"stats":{"Line":3}},{"line":445,"address":[],"length":0,"stats":{"Line":6}},{"line":446,"address":[],"length":0,"stats":{"Line":3}},{"line":447,"address":[],"length":0,"stats":{"Line":3}},{"line":448,"address":[],"length":0,"stats":{"Line":6}},{"line":449,"address":[],"length":0,"stats":{"Line":6}},{"line":453,"address":[],"length":0,"stats":{"Line":3}},{"line":455,"address":[],"length":0,"stats":{"Line":0}},{"line":456,"address":[],"length":0,"stats":{"Line":0}},{"line":457,"address":[],"length":0,"stats":{"Line":0}},{"line":462,"address":[],"length":0,"stats":{"Line":39}},{"line":463,"address":[],"length":0,"stats":{"Line":78}},{"line":464,"address":[],"length":0,"stats":{"Line":10}},{"line":467,"address":[],"length":0,"stats":{"Line":58}},{"line":469,"address":[],"length":0,"stats":{"Line":65}},{"line":470,"address":[],"length":0,"stats":{"Line":13}},{"line":471,"address":[],"length":0,"stats":{"Line":17}},{"line":472,"address":[],"length":0,"stats":{"Line":6}},{"line":476,"address":[],"length":0,"stats":{"Line":58}},{"line":479,"address":[],"length":0,"stats":{"Line":29}},{"line":485,"address":[],"length":0,"stats":{"Line":29}},{"line":486,"address":[],"length":0,"stats":{"Line":0}},{"line":488,"address":[],"length":0,"stats":{"Line":0}},{"line":489,"address":[],"length":0,"stats":{"Line":0}},{"line":491,"address":[],"length":0,"stats":{"Line":0}},{"line":492,"address":[],"length":0,"stats":{"Line":0}},{"line":494,"address":[],"length":0,"stats":{"Line":0}},{"line":495,"address":[],"length":0,"stats":{"Line":0}},{"line":496,"address":[],"length":0,"stats":{"Line":0}},{"line":497,"address":[],"length":0,"stats":{"Line":0}},{"line":501,"address":[],"length":0,"stats":{"Line":0}},{"line":502,"address":[],"length":0,"stats":{"Line":0}},{"line":503,"address":[],"length":0,"stats":{"Line":0}},{"line":504,"address":[],"length":0,"stats":{"Line":0}},{"line":505,"address":[],"length":0,"stats":{"Line":0}},{"line":506,"address":[],"length":0,"stats":{"Line":0}},{"line":508,"address":[],"length":0,"stats":{"Line":0}},{"line":513,"address":[],"length":0,"stats":{"Line":93}},{"line":521,"address":[],"length":0,"stats":{"Line":186}},{"line":522,"address":[],"length":0,"stats":{"Line":6}},{"line":523,"address":[],"length":0,"stats":{"Line":41}},{"line":524,"address":[],"length":0,"stats":{"Line":42}},{"line":525,"address":[],"length":0,"stats":{"Line":0}},{"line":526,"address":[],"length":0,"stats":{"Line":4}},{"line":529,"address":[],"length":0,"stats":{"Line":372}},{"line":531,"address":[],"length":0,"stats":{"Line":186}},{"line":532,"address":[],"length":0,"stats":{"Line":10}},{"line":533,"address":[],"length":0,"stats":{"Line":4}},{"line":535,"address":[],"length":0,"stats":{"Line":72}},{"line":536,"address":[],"length":0,"stats":{"Line":72}},{"line":537,"address":[],"length":0,"stats":{"Line":72}},{"line":539,"address":[],"length":0,"stats":{"Line":0}},{"line":542,"address":[],"length":0,"stats":{"Line":0}},{"line":546,"address":[],"length":0,"stats":{"Line":10}},{"line":547,"address":[],"length":0,"stats":{"Line":10}},{"line":548,"address":[],"length":0,"stats":{"Line":10}},{"line":550,"address":[],"length":0,"stats":{"Line":0}},{"line":553,"address":[],"length":0,"stats":{"Line":0}},{"line":557,"address":[],"length":0,"stats":{"Line":36}},{"line":558,"address":[],"length":0,"stats":{"Line":36}},{"line":559,"address":[],"length":0,"stats":{"Line":36}},{"line":560,"address":[],"length":0,"stats":{"Line":36}},{"line":561,"address":[],"length":0,"stats":{"Line":54}},{"line":563,"address":[],"length":0,"stats":{"Line":0}},{"line":566,"address":[],"length":0,"stats":{"Line":0}},{"line":569,"address":[],"length":0,"stats":{"Line":0}},{"line":572,"address":[],"length":0,"stats":{"Line":0}},{"line":576,"address":[],"length":0,"stats":{"Line":54}},{"line":577,"address":[],"length":0,"stats":{"Line":54}},{"line":578,"address":[],"length":0,"stats":{"Line":54}},{"line":579,"address":[],"length":0,"stats":{"Line":54}},{"line":580,"address":[],"length":0,"stats":{"Line":54}},{"line":582,"address":[],"length":0,"stats":{"Line":0}},{"line":585,"address":[],"length":0,"stats":{"Line":0}},{"line":588,"address":[],"length":0,"stats":{"Line":0}},{"line":591,"address":[],"length":0,"stats":{"Line":0}},{"line":596,"address":[],"length":0,"stats":{"Line":186}},{"line":597,"address":[],"length":0,"stats":{"Line":89}},{"line":598,"address":[],"length":0,"stats":{"Line":4}},{"line":601,"address":[],"length":0,"stats":{"Line":93}},{"line":602,"address":[],"length":0,"stats":{"Line":51}},{"line":603,"address":[],"length":0,"stats":{"Line":153}},{"line":604,"address":[],"length":0,"stats":{"Line":153}},{"line":605,"address":[],"length":0,"stats":{"Line":102}},{"line":606,"address":[],"length":0,"stats":{"Line":153}},{"line":607,"address":[],"length":0,"stats":{"Line":51}},{"line":610,"address":[],"length":0,"stats":{"Line":42}},{"line":614,"address":[],"length":0,"stats":{"Line":0}},{"line":620,"address":[],"length":0,"stats":{"Line":0}},{"line":621,"address":[],"length":0,"stats":{"Line":0}},{"line":623,"address":[],"length":0,"stats":{"Line":0}},{"line":625,"address":[],"length":0,"stats":{"Line":0}},{"line":627,"address":[],"length":0,"stats":{"Line":0}},{"line":629,"address":[],"length":0,"stats":{"Line":0}},{"line":630,"address":[],"length":0,"stats":{"Line":0}},{"line":632,"address":[],"length":0,"stats":{"Line":0}},{"line":633,"address":[],"length":0,"stats":{"Line":0}},{"line":634,"address":[],"length":0,"stats":{"Line":0}},{"line":636,"address":[],"length":0,"stats":{"Line":0}},{"line":637,"address":[],"length":0,"stats":{"Line":0}},{"line":638,"address":[],"length":0,"stats":{"Line":0}},{"line":639,"address":[],"length":0,"stats":{"Line":0}},{"line":641,"address":[],"length":0,"stats":{"Line":0}},{"line":642,"address":[],"length":0,"stats":{"Line":0}},{"line":644,"address":[],"length":0,"stats":{"Line":0}},{"line":645,"address":[],"length":0,"stats":{"Line":0}},{"line":646,"address":[],"length":0,"stats":{"Line":0}},{"line":647,"address":[],"length":0,"stats":{"Line":0}},{"line":648,"address":[],"length":0,"stats":{"Line":0}},{"line":649,"address":[],"length":0,"stats":{"Line":0}},{"line":650,"address":[],"length":0,"stats":{"Line":0}},{"line":651,"address":[],"length":0,"stats":{"Line":0}},{"line":652,"address":[],"length":0,"stats":{"Line":0}},{"line":653,"address":[],"length":0,"stats":{"Line":0}},{"line":655,"address":[],"length":0,"stats":{"Line":0}},{"line":663,"address":[],"length":0,"stats":{"Line":0}},{"line":666,"address":[],"length":0,"stats":{"Line":0}},{"line":667,"address":[],"length":0,"stats":{"Line":0}},{"line":668,"address":[],"length":0,"stats":{"Line":0}},{"line":670,"address":[],"length":0,"stats":{"Line":0}},{"line":671,"address":[],"length":0,"stats":{"Line":0}},{"line":672,"address":[],"length":0,"stats":{"Line":0}},{"line":674,"address":[],"length":0,"stats":{"Line":0}},{"line":675,"address":[],"length":0,"stats":{"Line":0}},{"line":677,"address":[],"length":0,"stats":{"Line":0}}],"covered":225,"coverable":327},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","governance_client.rs"],"content":"use async_trait::async_trait;\nuse mk_core::types::{\n    DriftResult, GovernanceEvent, KnowledgeEntry, KnowledgeLayer, TenantContext, ValidationResult,\n};\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse std::time::{Duration, Instant};\nuse tokio::sync::RwLock;\n\n#[derive(Debug, thiserror::Error)]\npub enum GovernanceClientError {\n    #[error(\"Network error: {0}\")]\n    Network(#[from] reqwest::Error),\n    #[error(\"API error: {0}\")]\n    Api(String),\n    #[error(\"Serialization error: {0}\")]\n    Serialization(#[from] serde_json::Error),\n    #[error(\"Internal error: {0}\")]\n    Internal(String),\n    #[error(\"Remote unavailable, using cached data\")]\n    RemoteUnavailable,\n    #[error(\"Sync conflict: {0}\")]\n    SyncConflict(String),\n}\n\npub type Result\u003cT\u003e = std::result::Result\u003cT, GovernanceClientError\u003e;\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct SyncState {\n    pub last_sync_timestamp: i64,\n    pub local_version: u64,\n    pub remote_version: u64,\n    pub pending_changes: Vec\u003cPendingChange\u003e,\n}\n\nimpl Default for SyncState {\n    fn default() -\u003e Self {\n        Self {\n            last_sync_timestamp: 0,\n            local_version: 0,\n            remote_version: 0,\n            pending_changes: Vec::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PendingChange {\n    pub id: String,\n    pub change_type: ChangeType,\n    pub data: serde_json::Value,\n    pub created_at: i64,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\npub enum ChangeType {\n    PolicyUpdate,\n    DriftResult,\n    ProposalAction,\n}\n\n#[derive(Debug, Clone)]\nstruct CacheEntry\u003cT\u003e {\n    data: T,\n    inserted_at: Instant,\n    ttl: Duration,\n}\n\nimpl\u003cT: Clone\u003e CacheEntry\u003cT\u003e {\n    fn new(data: T, ttl: Duration) -\u003e Self {\n        Self {\n            data,\n            inserted_at: Instant::now(),\n            ttl,\n        }\n    }\n\n    fn is_expired(\u0026self) -\u003e bool {\n        self.inserted_at.elapsed() \u003e self.ttl\n    }\n}\n\n#[async_trait]\npub trait GovernanceClient: Send + Sync {\n    async fn validate(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        layer: KnowledgeLayer,\n        context: \u0026std::collections::HashMap\u003cString, serde_json::Value\u003e,\n    ) -\u003e Result\u003cValidationResult\u003e;\n\n    async fn get_drift_status(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        project_id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cDriftResult\u003e\u003e;\n\n    async fn list_proposals(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        layer: Option\u003cKnowledgeLayer\u003e,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e\u003e;\n\n    async fn replay_events(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        since_timestamp: i64,\n        limit: usize,\n    ) -\u003e Result\u003cVec\u003cGovernanceEvent\u003e\u003e;\n}\n\npub struct RemoteGovernanceClient {\n    client: reqwest::Client,\n    base_url: String,\n}\n\nimpl RemoteGovernanceClient {\n    pub fn new(base_url: String) -\u003e Self {\n        Self {\n            client: reqwest::Client::new(),\n            base_url,\n        }\n    }\n}\n\npub struct HybridGovernanceClient {\n    remote_client: RemoteGovernanceClient,\n    local_engine: Arc\u003ccrate::governance::GovernanceEngine\u003e,\n    cache: Arc\u003cRwLock\u003cHybridCache\u003e\u003e,\n    sync_state: Arc\u003cRwLock\u003cSyncState\u003e\u003e,\n    cache_ttl: Duration,\n    sync_interval: Duration,\n}\n\nstruct HybridCache {\n    drift_results: HashMap\u003cString, CacheEntry\u003cDriftResult\u003e\u003e,\n    proposals: Option\u003cCacheEntry\u003cVec\u003cKnowledgeEntry\u003e\u003e\u003e,\n}\n\nimpl Default for HybridCache {\n    fn default() -\u003e Self {\n        Self {\n            drift_results: HashMap::new(),\n            proposals: None,\n        }\n    }\n}\n\nimpl HybridGovernanceClient {\n    pub fn new(remote_url: String, local_engine: Arc\u003ccrate::governance::GovernanceEngine\u003e) -\u003e Self {\n        Self {\n            remote_client: RemoteGovernanceClient::new(remote_url),\n            local_engine,\n            cache: Arc::new(RwLock::new(HybridCache::default())),\n            sync_state: Arc::new(RwLock::new(SyncState::default())),\n            cache_ttl: Duration::from_secs(300),\n            sync_interval: Duration::from_secs(60),\n        }\n    }\n\n    pub fn with_cache_ttl(mut self, ttl: Duration) -\u003e Self {\n        self.cache_ttl = ttl;\n        self\n    }\n\n    pub fn with_sync_interval(mut self, interval: Duration) -\u003e Self {\n        self.sync_interval = interval;\n        self\n    }\n\n    fn cache_key(ctx: \u0026TenantContext, suffix: \u0026str) -\u003e String {\n        format!(\n            \"{}:{}:{}\",\n            ctx.tenant_id.as_str(),\n            ctx.user_id.as_str(),\n            suffix\n        )\n    }\n\n    pub async fn sync_pending_changes(\u0026self, ctx: \u0026TenantContext) -\u003e Result\u003cusize\u003e {\n        let mut state = self.sync_state.write().await;\n        let pending = std::mem::take(\u0026mut state.pending_changes);\n        let mut synced = 0;\n\n        for change in pending {\n            match self.push_change_to_remote(ctx, \u0026change).await {\n                Ok(_) =\u003e {\n                    synced += 1;\n                    state.local_version += 1;\n                }\n                Err(e) =\u003e {\n                    tracing::error!(\"Failed to sync change {}: {:?}\", change.id, e);\n                    state.pending_changes.push(change);\n                }\n            }\n        }\n\n        if synced \u003e 0 {\n            state.last_sync_timestamp = chrono::Utc::now().timestamp();\n        }\n\n        Ok(synced)\n    }\n\n    async fn push_change_to_remote(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        change: \u0026PendingChange,\n    ) -\u003e Result\u003c()\u003e {\n        let url = match change.change_type {\n            ChangeType::PolicyUpdate =\u003e {\n                format!(\n                    \"{}/api/v1/governance/policies/sync\",\n                    self.remote_client.base_url\n                )\n            }\n            ChangeType::DriftResult =\u003e {\n                format!(\n                    \"{}/api/v1/governance/drift/sync\",\n                    self.remote_client.base_url\n                )\n            }\n            ChangeType::ProposalAction =\u003e {\n                format!(\n                    \"{}/api/v1/governance/proposals/sync\",\n                    self.remote_client.base_url\n                )\n            }\n        };\n\n        let response = self\n            .remote_client\n            .client\n            .post(\u0026url)\n            .header(\"X-Tenant-Id\", ctx.tenant_id.as_str())\n            .header(\"X-User-Id\", ctx.user_id.as_str())\n            .json(\u0026change.data)\n            .send()\n            .await?;\n\n        if response.status().is_success() {\n            Ok(())\n        } else {\n            Err(GovernanceClientError::Api(response.text().await?))\n        }\n    }\n\n    pub async fn queue_local_change(\u0026self, change: PendingChange) {\n        let mut state = self.sync_state.write().await;\n        state.pending_changes.push(change);\n    }\n\n    pub async fn get_sync_state(\u0026self) -\u003e SyncState {\n        self.sync_state.read().await.clone()\n    }\n}\n\n#[async_trait]\nimpl GovernanceClient for HybridGovernanceClient {\n    async fn validate(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        layer: KnowledgeLayer,\n        context: \u0026std::collections::HashMap\u003cString, serde_json::Value\u003e,\n    ) -\u003e Result\u003cValidationResult\u003e {\n        let local_result = self\n            .local_engine\n            .validate_with_context(layer, context, Some(ctx))\n            .await;\n\n        self.queue_local_change(PendingChange {\n            id: uuid::Uuid::new_v4().to_string(),\n            change_type: ChangeType::PolicyUpdate,\n            data: serde_json::json!({\n                \"layer\": layer,\n                \"context\": context,\n                \"result\": local_result\n            }),\n            created_at: chrono::Utc::now().timestamp(),\n        })\n        .await;\n\n        Ok(local_result)\n    }\n\n    async fn get_drift_status(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        project_id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cDriftResult\u003e\u003e {\n        let cache_key = Self::cache_key(ctx, \u0026format!(\"drift:{}\", project_id));\n\n        {\n            let cache = self.cache.read().await;\n            if let Some(entry) = cache.drift_results.get(\u0026cache_key) {\n                if !entry.is_expired() {\n                    return Ok(Some(entry.data.clone()));\n                }\n            }\n        }\n\n        match self.remote_client.get_drift_status(ctx, project_id).await {\n            Ok(result) =\u003e {\n                if let Some(ref drift) = result {\n                    let mut cache = self.cache.write().await;\n                    cache\n                        .drift_results\n                        .insert(cache_key, CacheEntry::new(drift.clone(), self.cache_ttl));\n                }\n                Ok(result)\n            }\n            Err(_) =\u003e {\n                if let Some(storage) = self.local_engine.storage() {\n                    match storage\n                        .get_latest_drift_result(ctx.clone(), project_id)\n                        .await\n                    {\n                        Ok(result) =\u003e Ok(result),\n                        Err(e) =\u003e Err(GovernanceClientError::Internal(format!(\"{:?}\", e))),\n                    }\n                } else {\n                    Ok(None)\n                }\n            }\n        }\n    }\n\n    async fn list_proposals(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        layer: Option\u003cKnowledgeLayer\u003e,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e\u003e {\n        {\n            let cache = self.cache.read().await;\n            if let Some(ref entry) = cache.proposals {\n                if !entry.is_expired() {\n                    let filtered: Vec\u003c_\u003e = entry\n                        .data\n                        .iter()\n                        .filter(|e| layer.is_none() || Some(e.layer) == layer)\n                        .cloned()\n                        .collect();\n                    return Ok(filtered);\n                }\n            }\n        }\n\n        match self.remote_client.list_proposals(ctx, layer).await {\n            Ok(proposals) =\u003e {\n                let mut cache = self.cache.write().await;\n                cache.proposals = Some(CacheEntry::new(proposals.clone(), self.cache_ttl));\n                Ok(proposals)\n            }\n            Err(_) =\u003e {\n                if let Some(repo) = self.local_engine.repository() {\n                    let target_layer = layer.unwrap_or(KnowledgeLayer::Project);\n                    match repo.list(ctx.clone(), target_layer, \"proposals/\").await {\n                        Ok(entries) =\u003e Ok(entries),\n                        Err(e) =\u003e Err(GovernanceClientError::Internal(format!(\"{:?}\", e))),\n                    }\n                } else {\n                    Ok(vec![])\n                }\n            }\n        }\n    }\n\n    async fn replay_events(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        since_timestamp: i64,\n        limit: usize,\n    ) -\u003e Result\u003cVec\u003cGovernanceEvent\u003e\u003e {\n        self.remote_client\n            .replay_events(ctx, since_timestamp, limit)\n            .await\n    }\n}\n\npub enum GovernanceClientKind {\n    Local(LocalGovernanceClient),\n    Hybrid(HybridGovernanceClient),\n    Remote(RemoteGovernanceClient),\n}\n\nimpl std::fmt::Debug for GovernanceClientKind {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        match self {\n            GovernanceClientKind::Local(_) =\u003e f.debug_tuple(\"Local\").finish(),\n            GovernanceClientKind::Hybrid(_) =\u003e f.debug_tuple(\"Hybrid\").finish(),\n            GovernanceClientKind::Remote(_) =\u003e f.debug_tuple(\"Remote\").finish(),\n        }\n    }\n}\n\nimpl GovernanceClientKind {\n    pub fn as_client(\u0026self) -\u003e \u0026dyn GovernanceClient {\n        match self {\n            GovernanceClientKind::Local(c) =\u003e c,\n            GovernanceClientKind::Hybrid(c) =\u003e c,\n            GovernanceClientKind::Remote(c) =\u003e c,\n        }\n    }\n}\n\npub fn create_governance_client(\n    config: \u0026config::DeploymentConfig,\n    engine: Option\u003cArc\u003ccrate::governance::GovernanceEngine\u003e\u003e,\n) -\u003e Result\u003cGovernanceClientKind\u003e {\n    match config.mode.as_str() {\n        \"local\" =\u003e {\n            let engine = engine.ok_or_else(|| {\n                GovernanceClientError::Internal(\n                    \"Local mode requires a GovernanceEngine instance\".to_string(),\n                )\n            })?;\n            Ok(GovernanceClientKind::Local(LocalGovernanceClient::new(\n                engine,\n            )))\n        }\n        \"hybrid\" =\u003e {\n            let engine = engine.ok_or_else(|| {\n                GovernanceClientError::Internal(\n                    \"Hybrid mode requires a GovernanceEngine instance\".to_string(),\n                )\n            })?;\n            let remote_url = config.remote_url.clone().ok_or_else(|| {\n                GovernanceClientError::Internal(\n                    \"Hybrid mode requires a remote_url configuration\".to_string(),\n                )\n            })?;\n            Ok(GovernanceClientKind::Hybrid(HybridGovernanceClient::new(\n                remote_url, engine,\n            )))\n        }\n        \"remote\" =\u003e {\n            let remote_url = config.remote_url.clone().ok_or_else(|| {\n                GovernanceClientError::Internal(\n                    \"Remote mode requires a remote_url configuration\".to_string(),\n                )\n            })?;\n            Ok(GovernanceClientKind::Remote(RemoteGovernanceClient::new(\n                remote_url,\n            )))\n        }\n        other =\u003e Err(GovernanceClientError::Internal(format!(\n            \"Invalid deployment mode: {}\",\n            other\n        ))),\n    }\n}\n\n/// Local governance client that wraps the `GovernanceEngine` directly.\n///\n/// Used in \"local\" deployment mode where all governance operations are\n/// performed locally without any remote communication.\npub struct LocalGovernanceClient {\n    engine: Arc\u003ccrate::governance::GovernanceEngine\u003e,\n}\n\nimpl LocalGovernanceClient {\n    pub fn new(engine: Arc\u003ccrate::governance::GovernanceEngine\u003e) -\u003e Self {\n        Self { engine }\n    }\n}\n\n#[async_trait]\nimpl GovernanceClient for LocalGovernanceClient {\n    async fn validate(\n        \u0026self,\n        _ctx: \u0026TenantContext,\n        layer: KnowledgeLayer,\n        context: \u0026std::collections::HashMap\u003cString, serde_json::Value\u003e,\n    ) -\u003e Result\u003cValidationResult\u003e {\n        Ok(self\n            .engine\n            .validate_with_context(layer, context, None)\n            .await)\n    }\n\n    async fn get_drift_status(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        project_id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cDriftResult\u003e\u003e {\n        if let Some(storage) = self.engine.storage() {\n            match storage\n                .get_latest_drift_result(ctx.clone(), project_id)\n                .await\n            {\n                Ok(result) =\u003e Ok(result),\n                Err(e) =\u003e Err(GovernanceClientError::Internal(format!(\"{:?}\", e))),\n            }\n        } else {\n            Ok(None)\n        }\n    }\n\n    async fn list_proposals(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        layer: Option\u003cKnowledgeLayer\u003e,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e\u003e {\n        if let Some(repo) = self.engine.repository() {\n            let target_layer = layer.unwrap_or(KnowledgeLayer::Project);\n            match repo.list(ctx.clone(), target_layer, \"proposals/\").await {\n                Ok(entries) =\u003e Ok(entries),\n                Err(e) =\u003e Err(GovernanceClientError::Internal(format!(\"{:?}\", e))),\n            }\n        } else {\n            Ok(vec![])\n        }\n    }\n\n    async fn replay_events(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        since_timestamp: i64,\n        limit: usize,\n    ) -\u003e Result\u003cVec\u003cGovernanceEvent\u003e\u003e {\n        if let Some(storage) = self.engine.storage() {\n            match storage\n                .get_governance_events(ctx.clone(), since_timestamp, limit)\n                .await\n            {\n                Ok(events) =\u003e Ok(events),\n                Err(e) =\u003e Err(GovernanceClientError::Internal(format!(\"{:?}\", e))),\n            }\n        } else {\n            Ok(vec![])\n        }\n    }\n}\n\n#[async_trait]\nimpl GovernanceClient for RemoteGovernanceClient {\n    async fn validate(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        layer: KnowledgeLayer,\n        context: \u0026std::collections::HashMap\u003cString, serde_json::Value\u003e,\n    ) -\u003e Result\u003cValidationResult\u003e {\n        let url = format!(\"{}/api/v1/governance/validate\", self.base_url);\n        let response = self\n            .client\n            .post(\u0026url)\n            .header(\"X-Tenant-Id\", ctx.tenant_id.as_str())\n            .header(\"X-User-Id\", ctx.user_id.as_str())\n            .json(\u0026serde_json::json!({\n                \"layer\": layer,\n                \"context\": context\n            }))\n            .send()\n            .await?;\n\n        if response.status().is_success() {\n            Ok(response.json().await?)\n        } else {\n            Err(GovernanceClientError::Api(response.text().await?))\n        }\n    }\n\n    async fn get_drift_status(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        project_id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cDriftResult\u003e\u003e {\n        let url = format!(\"{}/api/v1/governance/drift/{}\", self.base_url, project_id);\n        let response = self\n            .client\n            .get(\u0026url)\n            .header(\"X-Tenant-Id\", ctx.tenant_id.as_str())\n            .header(\"X-User-Id\", ctx.user_id.as_str())\n            .send()\n            .await?;\n\n        if response.status().is_success() {\n            Ok(response.json().await?)\n        } else {\n            Err(GovernanceClientError::Api(response.text().await?))\n        }\n    }\n\n    async fn list_proposals(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        layer: Option\u003cKnowledgeLayer\u003e,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e\u003e {\n        let mut url = format!(\"{}/api/v1/governance/proposals\", self.base_url);\n        if let Some(l) = layer {\n            url.push_str(\u0026format!(\"?layer={:?}\", l));\n        }\n\n        let response = self\n            .client\n            .get(\u0026url)\n            .header(\"X-Tenant-Id\", ctx.tenant_id.as_str())\n            .header(\"X-User-Id\", ctx.user_id.as_str())\n            .send()\n            .await?;\n\n        if response.status().is_success() {\n            Ok(response.json().await?)\n        } else {\n            Err(GovernanceClientError::Api(response.text().await?))\n        }\n    }\n\n    async fn replay_events(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        since_timestamp: i64,\n        limit: usize,\n    ) -\u003e Result\u003cVec\u003cGovernanceEvent\u003e\u003e {\n        let url = format!(\n            \"{}/api/v1/governance/events/replay?since_timestamp={}\u0026limit={}\",\n            self.base_url, since_timestamp, limit\n        );\n\n        let response = self\n            .client\n            .get(\u0026url)\n            .header(\"X-Tenant-Id\", ctx.tenant_id.as_str())\n            .header(\"X-User-Id\", ctx.user_id.as_str())\n            .send()\n            .await?;\n\n        if response.status().is_success() {\n            Ok(response.json().await?)\n        } else {\n            Err(GovernanceClientError::Api(response.text().await?))\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::{TenantId, UserId};\n\n    fn test_tenant_context() -\u003e TenantContext {\n        TenantContext::new(TenantId::default(), UserId::default())\n    }\n\n    #[test]\n    fn test_sync_state_default() {\n        let state = SyncState::default();\n        assert_eq!(state.last_sync_timestamp, 0);\n        assert_eq!(state.local_version, 0);\n        assert_eq!(state.remote_version, 0);\n        assert!(state.pending_changes.is_empty());\n    }\n\n    #[test]\n    fn test_pending_change_serialization() {\n        let change = PendingChange {\n            id: \"change-1\".to_string(),\n            change_type: ChangeType::PolicyUpdate,\n            data: serde_json::json!({\"key\": \"value\"}),\n            created_at: 1234567890,\n        };\n\n        let json = serde_json::to_string(\u0026change).unwrap();\n        let deserialized: PendingChange = serde_json::from_str(\u0026json).unwrap();\n\n        assert_eq!(deserialized.id, \"change-1\");\n        assert_eq!(deserialized.change_type, ChangeType::PolicyUpdate);\n        assert_eq!(deserialized.created_at, 1234567890);\n    }\n\n    #[test]\n    fn test_change_type_variants() {\n        assert_eq!(ChangeType::PolicyUpdate, ChangeType::PolicyUpdate);\n        assert_eq!(ChangeType::DriftResult, ChangeType::DriftResult);\n        assert_eq!(ChangeType::ProposalAction, ChangeType::ProposalAction);\n        assert_ne!(ChangeType::PolicyUpdate, ChangeType::DriftResult);\n    }\n\n    #[test]\n    fn test_cache_entry_expiration() {\n        let entry = CacheEntry::new(\"test data\".to_string(), Duration::from_millis(10));\n        assert!(!entry.is_expired());\n\n        std::thread::sleep(Duration::from_millis(15));\n        assert!(entry.is_expired());\n    }\n\n    #[test]\n    fn test_cache_entry_not_expired() {\n        let entry = CacheEntry::new(42i32, Duration::from_secs(60));\n        assert!(!entry.is_expired());\n    }\n\n    #[test]\n    fn test_hybrid_cache_default() {\n        let cache = HybridCache::default();\n        assert!(cache.drift_results.is_empty());\n        assert!(cache.proposals.is_none());\n    }\n\n    #[test]\n    fn test_cache_key_generation() {\n        let ctx = test_tenant_context();\n        let key = HybridGovernanceClient::cache_key(\u0026ctx, \"drift:proj-1\");\n        assert_eq!(key, \"default:default:drift:proj-1\");\n    }\n\n    #[test]\n    fn test_remote_client_construction() {\n        let client = RemoteGovernanceClient::new(\"http://localhost:8080\".to_string());\n        assert_eq!(client.base_url, \"http://localhost:8080\");\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_client_construction() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client =\n            HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine.clone());\n\n        assert_eq!(client.cache_ttl, Duration::from_secs(300));\n        assert_eq!(client.sync_interval, Duration::from_secs(60));\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_client_with_custom_ttl() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine)\n            .with_cache_ttl(Duration::from_secs(120));\n\n        assert_eq!(client.cache_ttl, Duration::from_secs(120));\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_client_with_custom_sync_interval() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine)\n            .with_sync_interval(Duration::from_secs(30));\n\n        assert_eq!(client.sync_interval, Duration::from_secs(30));\n    }\n\n    #[tokio::test]\n    async fn test_queue_local_change() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine);\n\n        let change = PendingChange {\n            id: \"test-change\".to_string(),\n            change_type: ChangeType::PolicyUpdate,\n            data: serde_json::json!({\"test\": true}),\n            created_at: chrono::Utc::now().timestamp(),\n        };\n\n        client.queue_local_change(change).await;\n\n        let state = client.get_sync_state().await;\n        assert_eq!(state.pending_changes.len(), 1);\n        assert_eq!(state.pending_changes[0].id, \"test-change\");\n    }\n\n    #[tokio::test]\n    async fn test_get_sync_state_initial() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine);\n\n        let state = client.get_sync_state().await;\n        assert_eq!(state.last_sync_timestamp, 0);\n        assert_eq!(state.local_version, 0);\n        assert_eq!(state.remote_version, 0);\n        assert!(state.pending_changes.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_validate_queues_change() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine);\n\n        let ctx = test_tenant_context();\n        let context = HashMap::new();\n\n        let result = client\n            .validate(\u0026ctx, KnowledgeLayer::Project, \u0026context)\n            .await;\n        assert!(result.is_ok());\n\n        let state = client.get_sync_state().await;\n        assert_eq!(state.pending_changes.len(), 1);\n        assert_eq!(\n            state.pending_changes[0].change_type,\n            ChangeType::PolicyUpdate\n        );\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_get_drift_status_no_storage() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://invalid-host:9999\".to_string(), engine);\n\n        let ctx = test_tenant_context();\n        let result = client.get_drift_status(\u0026ctx, \"proj-1\").await;\n\n        assert!(result.is_ok());\n        assert!(result.unwrap().is_none());\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_list_proposals_no_repo() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://invalid-host:9999\".to_string(), engine);\n\n        let ctx = test_tenant_context();\n        let result = client.list_proposals(\u0026ctx, None).await;\n\n        assert!(result.is_ok());\n        assert!(result.unwrap().is_empty());\n    }\n\n    #[test]\n    fn test_governance_client_error_display() {\n        let err = GovernanceClientError::Api(\"Not found\".to_string());\n        assert_eq!(err.to_string(), \"API error: Not found\");\n\n        let err = GovernanceClientError::Internal(\"Something went wrong\".to_string());\n        assert_eq!(err.to_string(), \"Internal error: Something went wrong\");\n\n        let err = GovernanceClientError::RemoteUnavailable;\n        assert_eq!(err.to_string(), \"Remote unavailable, using cached data\");\n\n        let err = GovernanceClientError::SyncConflict(\"Version mismatch\".to_string());\n        assert_eq!(err.to_string(), \"Sync conflict: Version mismatch\");\n    }\n\n    #[test]\n    fn test_sync_state_serialization() {\n        let state = SyncState {\n            last_sync_timestamp: 1234567890,\n            local_version: 5,\n            remote_version: 3,\n            pending_changes: vec![PendingChange {\n                id: \"change-1\".to_string(),\n                change_type: ChangeType::DriftResult,\n                data: serde_json::json!({}),\n                created_at: 1234567890,\n            }],\n        };\n\n        let json = serde_json::to_string(\u0026state).unwrap();\n        let deserialized: SyncState = serde_json::from_str(\u0026json).unwrap();\n\n        assert_eq!(deserialized.last_sync_timestamp, 1234567890);\n        assert_eq!(deserialized.local_version, 5);\n        assert_eq!(deserialized.remote_version, 3);\n        assert_eq!(deserialized.pending_changes.len(), 1);\n    }\n\n    #[tokio::test]\n    async fn test_multiple_queued_changes() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine);\n\n        for i in 0..5 {\n            client\n                .queue_local_change(PendingChange {\n                    id: format!(\"change-{}\", i),\n                    change_type: ChangeType::PolicyUpdate,\n                    data: serde_json::json!({\"index\": i}),\n                    created_at: chrono::Utc::now().timestamp(),\n                })\n                .await;\n        }\n\n        let state = client.get_sync_state().await;\n        assert_eq!(state.pending_changes.len(), 5);\n    }\n\n    #[tokio::test]\n    async fn test_sync_pending_changes_empty() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine);\n\n        let ctx = test_tenant_context();\n        let synced = client.sync_pending_changes(\u0026ctx).await.unwrap();\n\n        assert_eq!(synced, 0);\n    }\n\n    #[tokio::test]\n    async fn test_cache_key_with_custom_context() {\n        let tenant_id = TenantId::new(\"acme-corp\".to_string()).unwrap();\n        let user_id = UserId::new(\"john-doe\".to_string()).unwrap();\n        let ctx = TenantContext::new(tenant_id, user_id);\n\n        let key = HybridGovernanceClient::cache_key(\u0026ctx, \"proposals\");\n        assert_eq!(key, \"acme-corp:john-doe:proposals\");\n    }\n\n    #[test]\n    fn test_change_type_serialization() {\n        let policy = ChangeType::PolicyUpdate;\n        let drift = ChangeType::DriftResult;\n        let proposal = ChangeType::ProposalAction;\n\n        let policy_json = serde_json::to_string(\u0026policy).unwrap();\n        let drift_json = serde_json::to_string(\u0026drift).unwrap();\n        let proposal_json = serde_json::to_string(\u0026proposal).unwrap();\n\n        assert_eq!(policy_json, \"\\\"PolicyUpdate\\\"\");\n        assert_eq!(drift_json, \"\\\"DriftResult\\\"\");\n        assert_eq!(proposal_json, \"\\\"ProposalAction\\\"\");\n\n        let deserialized: ChangeType = serde_json::from_str(\u0026policy_json).unwrap();\n        assert_eq!(deserialized, ChangeType::PolicyUpdate);\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_client_builder_chain() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine)\n            .with_cache_ttl(Duration::from_secs(600))\n            .with_sync_interval(Duration::from_secs(120));\n\n        assert_eq!(client.cache_ttl, Duration::from_secs(600));\n        assert_eq!(client.sync_interval, Duration::from_secs(120));\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_validate_returns_valid_result() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine);\n\n        let ctx = test_tenant_context();\n        let context = HashMap::new();\n\n        let result = client\n            .validate(\u0026ctx, KnowledgeLayer::Project, \u0026context)\n            .await\n            .unwrap();\n\n        assert!(result.is_valid);\n        assert!(result.violations.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_list_proposals_with_layer_filter() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://invalid-host:9999\".to_string(), engine);\n\n        let ctx = test_tenant_context();\n        let result = client\n            .list_proposals(\u0026ctx, Some(KnowledgeLayer::Company))\n            .await;\n\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_local_client_construction() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let _client = LocalGovernanceClient::new(engine);\n    }\n\n    #[tokio::test]\n    async fn test_local_client_validate() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = LocalGovernanceClient::new(engine);\n\n        let ctx = test_tenant_context();\n        let context = HashMap::new();\n\n        let result = client\n            .validate(\u0026ctx, KnowledgeLayer::Project, \u0026context)\n            .await;\n        assert!(result.is_ok());\n        assert!(result.unwrap().is_valid);\n    }\n\n    #[tokio::test]\n    async fn test_local_client_get_drift_status_no_storage() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = LocalGovernanceClient::new(engine);\n\n        let ctx = test_tenant_context();\n        let result = client.get_drift_status(\u0026ctx, \"proj-1\").await;\n\n        assert!(result.is_ok());\n        assert!(result.unwrap().is_none());\n    }\n\n    #[tokio::test]\n    async fn test_local_client_list_proposals_no_repo() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = LocalGovernanceClient::new(engine);\n\n        let ctx = test_tenant_context();\n        let result = client.list_proposals(\u0026ctx, None).await;\n\n        assert!(result.is_ok());\n        assert!(result.unwrap().is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_local_client_replay_events_no_storage() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = LocalGovernanceClient::new(engine);\n\n        let ctx = test_tenant_context();\n        let result = client.replay_events(\u0026ctx, 0, 100).await;\n\n        assert!(result.is_ok());\n        assert!(result.unwrap().is_empty());\n    }\n\n    #[test]\n    fn test_create_governance_client_local_mode() {\n        let config = config::DeploymentConfig {\n            mode: \"local\".to_string(),\n            remote_url: None,\n            sync_enabled: true,\n        };\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n\n        let result = create_governance_client(\u0026config, Some(engine));\n        assert!(result.is_ok());\n        assert!(matches!(result.unwrap(), GovernanceClientKind::Local(_)));\n    }\n\n    #[test]\n    fn test_create_governance_client_local_mode_requires_engine() {\n        let config = config::DeploymentConfig {\n            mode: \"local\".to_string(),\n            remote_url: None,\n            sync_enabled: true,\n        };\n\n        let result = create_governance_client(\u0026config, None);\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Local mode requires\")\n        );\n    }\n\n    #[test]\n    fn test_create_governance_client_hybrid_mode() {\n        let config = config::DeploymentConfig {\n            mode: \"hybrid\".to_string(),\n            remote_url: Some(\"http://localhost:8080\".to_string()),\n            sync_enabled: true,\n        };\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n\n        let result = create_governance_client(\u0026config, Some(engine));\n        assert!(result.is_ok());\n        assert!(matches!(result.unwrap(), GovernanceClientKind::Hybrid(_)));\n    }\n\n    #[test]\n    fn test_create_governance_client_hybrid_mode_requires_engine() {\n        let config = config::DeploymentConfig {\n            mode: \"hybrid\".to_string(),\n            remote_url: Some(\"http://localhost:8080\".to_string()),\n            sync_enabled: true,\n        };\n\n        let result = create_governance_client(\u0026config, None);\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Hybrid mode requires a GovernanceEngine\")\n        );\n    }\n\n    #[test]\n    fn test_create_governance_client_hybrid_mode_requires_url() {\n        let config = config::DeploymentConfig {\n            mode: \"hybrid\".to_string(),\n            remote_url: None,\n            sync_enabled: true,\n        };\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n\n        let result = create_governance_client(\u0026config, Some(engine));\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Hybrid mode requires a remote_url\")\n        );\n    }\n\n    #[test]\n    fn test_create_governance_client_remote_mode() {\n        let config = config::DeploymentConfig {\n            mode: \"remote\".to_string(),\n            remote_url: Some(\"http://localhost:8080\".to_string()),\n            sync_enabled: false,\n        };\n\n        let result = create_governance_client(\u0026config, None);\n        assert!(result.is_ok());\n        assert!(matches!(result.unwrap(), GovernanceClientKind::Remote(_)));\n    }\n\n    #[test]\n    fn test_create_governance_client_remote_mode_requires_url() {\n        let config = config::DeploymentConfig {\n            mode: \"remote\".to_string(),\n            remote_url: None,\n            sync_enabled: false,\n        };\n\n        let result = create_governance_client(\u0026config, None);\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Remote mode requires a remote_url\")\n        );\n    }\n\n    #[test]\n    fn test_create_governance_client_invalid_mode() {\n        let config = config::DeploymentConfig {\n            mode: \"invalid\".to_string(),\n            remote_url: None,\n            sync_enabled: true,\n        };\n\n        let result = create_governance_client(\u0026config, None);\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Invalid deployment mode\")\n        );\n    }\n\n    #[test]\n    fn test_governance_client_kind_as_client_local() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client_kind = GovernanceClientKind::Local(LocalGovernanceClient::new(engine));\n        let _client: \u0026dyn GovernanceClient = client_kind.as_client();\n    }\n\n    #[test]\n    fn test_governance_client_kind_as_client_hybrid() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client_kind = GovernanceClientKind::Hybrid(HybridGovernanceClient::new(\n            \"http://localhost:8080\".to_string(),\n            engine,\n        ));\n        let _client: \u0026dyn GovernanceClient = client_kind.as_client();\n    }\n\n    #[test]\n    fn test_governance_client_kind_as_client_remote() {\n        let client_kind = GovernanceClientKind::Remote(RemoteGovernanceClient::new(\n            \"http://localhost:8080\".to_string(),\n        ));\n        let _client: \u0026dyn GovernanceClient = client_kind.as_client();\n    }\n}\n","traces":[{"line":38,"address":[],"length":0,"stats":{"Line":16}},{"line":43,"address":[],"length":0,"stats":{"Line":16}},{"line":71,"address":[],"length":0,"stats":{"Line":2}},{"line":74,"address":[],"length":0,"stats":{"Line":2}},{"line":79,"address":[],"length":0,"stats":{"Line":3}},{"line":80,"address":[],"length":0,"stats":{"Line":3}},{"line":119,"address":[],"length":0,"stats":{"Line":18}},{"line":121,"address":[],"length":0,"stats":{"Line":18}},{"line":142,"address":[],"length":0,"stats":{"Line":16}},{"line":144,"address":[],"length":0,"stats":{"Line":16}},{"line":151,"address":[],"length":0,"stats":{"Line":15}},{"line":153,"address":[],"length":0,"stats":{"Line":45}},{"line":155,"address":[],"length":0,"stats":{"Line":60}},{"line":156,"address":[],"length":0,"stats":{"Line":60}},{"line":157,"address":[],"length":0,"stats":{"Line":15}},{"line":158,"address":[],"length":0,"stats":{"Line":15}},{"line":162,"address":[],"length":0,"stats":{"Line":2}},{"line":163,"address":[],"length":0,"stats":{"Line":2}},{"line":164,"address":[],"length":0,"stats":{"Line":2}},{"line":167,"address":[],"length":0,"stats":{"Line":2}},{"line":168,"address":[],"length":0,"stats":{"Line":2}},{"line":169,"address":[],"length":0,"stats":{"Line":2}},{"line":172,"address":[],"length":0,"stats":{"Line":3}},{"line":173,"address":[],"length":0,"stats":{"Line":3}},{"line":175,"address":[],"length":0,"stats":{"Line":6}},{"line":176,"address":[],"length":0,"stats":{"Line":6}},{"line":181,"address":[],"length":0,"stats":{"Line":2}},{"line":182,"address":[],"length":0,"stats":{"Line":2}},{"line":183,"address":[],"length":0,"stats":{"Line":3}},{"line":184,"address":[],"length":0,"stats":{"Line":2}},{"line":186,"address":[],"length":0,"stats":{"Line":1}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":1}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":1}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":225,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":235,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":240,"address":[],"length":0,"stats":{"Line":0}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":16}},{"line":250,"address":[],"length":0,"stats":{"Line":16}},{"line":251,"address":[],"length":0,"stats":{"Line":24}},{"line":254,"address":[],"length":0,"stats":{"Line":8}},{"line":255,"address":[],"length":0,"stats":{"Line":12}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":388,"address":[],"length":0,"stats":{"Line":0}},{"line":389,"address":[],"length":0,"stats":{"Line":0}},{"line":390,"address":[],"length":0,"stats":{"Line":0}},{"line":391,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":0}},{"line":398,"address":[],"length":0,"stats":{"Line":3}},{"line":399,"address":[],"length":0,"stats":{"Line":3}},{"line":400,"address":[],"length":0,"stats":{"Line":2}},{"line":401,"address":[],"length":0,"stats":{"Line":2}},{"line":402,"address":[],"length":0,"stats":{"Line":2}},{"line":407,"address":[],"length":0,"stats":{"Line":8}},{"line":411,"address":[],"length":0,"stats":{"Line":8}},{"line":412,"address":[],"length":0,"stats":{"Line":8}},{"line":413,"address":[],"length":0,"stats":{"Line":6}},{"line":414,"address":[],"length":0,"stats":{"Line":1}},{"line":415,"address":[],"length":0,"stats":{"Line":1}},{"line":418,"address":[],"length":0,"stats":{"Line":1}},{"line":419,"address":[],"length":0,"stats":{"Line":1}},{"line":422,"address":[],"length":0,"stats":{"Line":6}},{"line":423,"address":[],"length":0,"stats":{"Line":9}},{"line":424,"address":[],"length":0,"stats":{"Line":1}},{"line":425,"address":[],"length":0,"stats":{"Line":1}},{"line":428,"address":[],"length":0,"stats":{"Line":8}},{"line":429,"address":[],"length":0,"stats":{"Line":1}},{"line":430,"address":[],"length":0,"stats":{"Line":1}},{"line":433,"address":[],"length":0,"stats":{"Line":2}},{"line":434,"address":[],"length":0,"stats":{"Line":1}},{"line":437,"address":[],"length":0,"stats":{"Line":3}},{"line":438,"address":[],"length":0,"stats":{"Line":8}},{"line":439,"address":[],"length":0,"stats":{"Line":1}},{"line":440,"address":[],"length":0,"stats":{"Line":1}},{"line":443,"address":[],"length":0,"stats":{"Line":1}},{"line":444,"address":[],"length":0,"stats":{"Line":1}},{"line":447,"address":[],"length":0,"stats":{"Line":2}},{"line":448,"address":[],"length":0,"stats":{"Line":1}},{"line":449,"address":[],"length":0,"stats":{"Line":1}},{"line":463,"address":[],"length":0,"stats":{"Line":7}}],"covered":70,"coverable":100},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","hot_reload.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","lib.rs"],"content":"//! # Knowledge Repository\n//!\n//! Git-based knowledge management with governance.\n\npub mod api;\npub mod federation;\npub mod governance;\npub mod governance_client;\npub mod repository;\npub mod scheduler;\npub mod telemetry;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","loader.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","opencode.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","pointer.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","pool.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","postgres.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","procedural.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","providers.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","qdrant.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","redis.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","repository.rs"],"content":"use async_trait::async_trait;\nuse git2::{Repository, Signature};\nuse mk_core::traits::KnowledgeRepository;\nuse mk_core::types::{KnowledgeEntry, KnowledgeLayer, KnowledgeType};\nuse std::path::PathBuf;\nuse thiserror::Error;\nuse walkdir::WalkDir;\n\n#[derive(Error, Debug)]\npub enum RepositoryError {\n    #[error(\"Git error: {0}\")]\n    Git(#[from] git2::Error),\n    #[error(\"IO error: {0}\")]\n    Io(#[from] std::io::Error),\n    #[error(\"Invalid path: {0}\")]\n    InvalidPath(String),\n    #[error(\"Serialization error: {0}\")]\n    Serialization(#[from] serde_json::Error),\n}\n\npub struct GitRepository {\n    root_path: PathBuf,\n}\n\nimpl GitRepository {\n    pub fn new(root_path: impl Into\u003cPathBuf\u003e) -\u003e Result\u003cSelf, RepositoryError\u003e {\n        let root_path = root_path.into();\n        if !root_path.exists() {\n            std::fs::create_dir_all(\u0026root_path)?;\n        }\n\n        if Repository::open(\u0026root_path).is_err() {\n            Repository::init(\u0026root_path)?;\n        }\n\n        Ok(Self { root_path })\n    }\n\n    fn resolve_path(\n        \u0026self,\n        ctx: \u0026mk_core::types::TenantContext,\n        layer: KnowledgeLayer,\n        path: \u0026str,\n    ) -\u003e PathBuf {\n        let layer_dir = match layer {\n            KnowledgeLayer::Company =\u003e \"company\",\n            KnowledgeLayer::Org =\u003e \"org\",\n            KnowledgeLayer::Team =\u003e \"team\",\n            KnowledgeLayer::Project =\u003e \"project\",\n        };\n        self.root_path\n            .join(ctx.tenant_id.as_str())\n            .join(layer_dir)\n            .join(path)\n    }\n\n    pub fn commit(\u0026self, message: \u0026str) -\u003e Result\u003cString, RepositoryError\u003e {\n        let span = tracing::info_span!(\"knowledge_commit\", message = %message);\n        let _enter = span.enter();\n\n        let repo = Repository::open(\u0026self.root_path)?;\n        let mut index = repo.index()?;\n        index.add_all([\"*\"].iter(), git2::IndexAddOption::DEFAULT, None)?;\n        index.write()?;\n\n        let tree_id = index.write_tree()?;\n        let tree = repo.find_tree(tree_id)?;\n\n        let sig = repo\n            .signature()\n            .or_else(|_| Signature::now(\"Aeterna\", \"system@aeterna.ai\"))?;\n\n        let parent_commit = match repo.head() {\n            Ok(head) =\u003e Some(head.peel_to_commit()?),\n            Err(_) =\u003e None,\n        };\n\n        let parents = match \u0026parent_commit {\n            Some(c) =\u003e vec![c],\n            None =\u003e vec![],\n        };\n\n        let commit_id = repo.commit(Some(\"HEAD\"), \u0026sig, \u0026sig, message, \u0026tree, \u0026parents)?;\n\n        Ok(commit_id.to_string())\n    }\n\n    pub fn get_head_commit_sync(\u0026self) -\u003e Result\u003cOption\u003cString\u003e, RepositoryError\u003e {\n        let repo = Repository::open(\u0026self.root_path)?;\n        match repo.head() {\n            Ok(head) =\u003e Ok(Some(head.peel_to_commit()?.id().to_string())),\n            Err(_) =\u003e Ok(None),\n        }\n    }\n\n    pub fn root_path(\u0026self) -\u003e \u0026std::path::Path {\n        \u0026self.root_path\n    }\n\n    pub async fn get_by_path(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        path: \u0026str,\n    ) -\u003e Result\u003cOption\u003cKnowledgeEntry\u003e, RepositoryError\u003e {\n        for layer in [\n            KnowledgeLayer::Company,\n            KnowledgeLayer::Org,\n            KnowledgeLayer::Team,\n            KnowledgeLayer::Project,\n        ] {\n            if let Some(entry) = self.get(ctx.clone(), layer, path).await? {\n                return Ok(Some(entry));\n            }\n        }\n        Ok(None)\n    }\n}\n\n#[async_trait]\nimpl KnowledgeRepository for GitRepository {\n    type Error = RepositoryError;\n\n    async fn get_head_commit(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n    ) -\u003e Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n        self.get_head_commit_sync()\n    }\n\n    async fn get_affected_items(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        since_commit: \u0026str,\n    ) -\u003e Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n        let repo = Repository::open(\u0026self.root_path)?;\n        let from_obj = repo.revparse_single(since_commit)?;\n        let from_commit = from_obj.peel_to_commit()?;\n        let from_tree = from_commit.tree()?;\n\n        let head = repo.head()?.peel_to_commit()?;\n        let head_tree = head.tree()?;\n\n        let diff = repo.diff_tree_to_tree(Some(\u0026from_tree), Some(\u0026head_tree), None)?;\n        let mut affected = Vec::new();\n\n        diff.foreach(\n            \u0026mut |delta, _| {\n                if let Some(path) = delta.new_file().path().and_then(|p| p.to_str()) {\n                    let parts: Vec\u003c\u0026str\u003e = path.split('/').collect();\n                    if parts.len() \u003e= 2 {\n                        let layer = match parts[0] {\n                            \"company\" =\u003e KnowledgeLayer::Company,\n                            \"org\" =\u003e KnowledgeLayer::Org,\n                            \"team\" =\u003e KnowledgeLayer::Team,\n                            \"project\" =\u003e KnowledgeLayer::Project,\n                            _ =\u003e return true,\n                        };\n                        let inner_path = parts[1..].join(\"/\");\n                        affected.push((layer, inner_path));\n                    }\n                }\n                true\n            },\n            None,\n            None,\n            None,\n        )?;\n\n        Ok(affected)\n    }\n\n    async fn get(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        layer: KnowledgeLayer,\n        path: \u0026str,\n    ) -\u003e Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        let full_path = self.resolve_path(\u0026ctx, layer, path);\n        if !full_path.exists() {\n            return Ok(None);\n        }\n\n        let metadata_path = full_path.with_extension(\"metadata.json\");\n\n        let content = tokio::fs::read_to_string(\u0026full_path).await?;\n\n        let commit_hash = {\n            let repo = Repository::open(\u0026self.root_path)?;\n            let mut revwalk = repo.revwalk()?;\n            revwalk.push_head().ok();\n            revwalk.next().transpose()?.map(|id| id.to_string())\n        };\n\n        let (kind, status, metadata, author, updated_at) = if metadata_path.exists() {\n            let meta_content = tokio::fs::read_to_string(\u0026metadata_path).await?;\n            let meta: serde_json::Value = serde_json::from_str(\u0026meta_content)?;\n            (\n                serde_json::from_value(meta[\"kind\"].clone()).unwrap_or(KnowledgeType::Spec),\n                serde_json::from_value(meta[\"status\"].clone())\n                    .unwrap_or(mk_core::types::KnowledgeStatus::Accepted),\n                serde_json::from_value(meta[\"metadata\"].clone()).unwrap_or_default(),\n                serde_json::from_value(meta[\"author\"].clone()).unwrap_or_default(),\n                meta[\"updated_at\"]\n                    .as_i64()\n                    .unwrap_or_else(|| chrono::Utc::now().timestamp()),\n            )\n        } else {\n            (\n                KnowledgeType::Spec,\n                mk_core::types::KnowledgeStatus::Accepted,\n                std::collections::HashMap::new(),\n                None,\n                chrono::Utc::now().timestamp(),\n            )\n        };\n\n        Ok(Some(KnowledgeEntry {\n            path: path.to_string(),\n            content,\n            layer,\n            kind,\n            status,\n            metadata,\n            commit_hash,\n            author,\n            updated_at,\n        }))\n    }\n\n    async fn store(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        entry: KnowledgeEntry,\n        message: \u0026str,\n    ) -\u003e Result\u003cString, Self::Error\u003e {\n        let full_path = self.resolve_path(\u0026ctx, entry.layer, \u0026entry.path);\n        let metadata_path = full_path.with_extension(\"metadata.json\");\n\n        if let Some(parent) = full_path.parent() {\n            tokio::fs::create_dir_all(parent).await?;\n        }\n\n        tokio::fs::write(\u0026full_path, entry.content).await?;\n\n        let meta = serde_json::json!({\n            \"kind\": entry.kind,\n            \"status\": entry.status,\n            \"metadata\": entry.metadata,\n            \"author\": entry.author,\n            \"updated_at\": entry.updated_at,\n        });\n        tokio::fs::write(\u0026metadata_path, serde_json::to_string(\u0026meta)?).await?;\n\n        self.commit(message)\n    }\n\n    async fn list(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        layer: KnowledgeLayer,\n        prefix: \u0026str,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        let tenant_path = self.root_path.join(ctx.tenant_id.as_str());\n        let layer_path = match layer {\n            KnowledgeLayer::Company =\u003e tenant_path.join(\"company\"),\n            KnowledgeLayer::Org =\u003e tenant_path.join(\"org\"),\n            KnowledgeLayer::Team =\u003e tenant_path.join(\"team\"),\n            KnowledgeLayer::Project =\u003e tenant_path.join(\"project\"),\n        };\n\n        if !layer_path.exists() {\n            return Ok(vec![]);\n        }\n\n        let mut entries = Vec::new();\n        for entry in WalkDir::new(\u0026layer_path)\n            .into_iter()\n            .filter_map(|e| e.ok())\n            .filter(|e| {\n                e.file_type().is_file() \u0026\u0026 !e.path().to_string_lossy().ends_with(\".metadata.json\")\n            })\n        {\n            let path = entry.path();\n            let relative_path = path\n                .strip_prefix(\u0026layer_path)\n                .map_err(|_| RepositoryError::InvalidPath(path.to_string_lossy().into_owned()))?;\n\n            if relative_path.to_string_lossy().starts_with(prefix) {\n                if let Some(ke) = self\n                    .get(ctx.clone(), layer, \u0026relative_path.to_string_lossy())\n                    .await?\n                {\n                    entries.push(ke);\n                }\n            }\n        }\n\n        Ok(entries)\n    }\n\n    async fn delete(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        layer: KnowledgeLayer,\n        path: \u0026str,\n        message: \u0026str,\n    ) -\u003e Result\u003cString, Self::Error\u003e {\n        let full_path = self.resolve_path(\u0026ctx, layer, path);\n        let metadata_path = full_path.with_extension(\"metadata.json\");\n\n        if full_path.exists() {\n            tokio::fs::remove_file(full_path).await?;\n            if metadata_path.exists() {\n                tokio::fs::remove_file(metadata_path).await?;\n            }\n            self.commit(message)\n        } else {\n            Ok(String::new())\n        }\n    }\n\n    async fn search(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        query: \u0026str,\n        layers: Vec\u003cKnowledgeLayer\u003e,\n        limit: usize,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        let mut results = Vec::new();\n        for layer in layers {\n            let entries = self.list(ctx.clone(), layer, \"\").await?;\n            for entry in entries {\n                if entry.content.contains(query) || entry.path.contains(query) {\n                    results.push(entry);\n                }\n                if results.len() \u003e= limit {\n                    return Ok(results);\n                }\n            }\n        }\n        Ok(results)\n    }\n\n    fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n        Some(self.root_path.clone())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use tempfile::tempdir;\n\n    #[tokio::test]\n    async fn test_git_repository_lifecycle() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n        let dir = tempdir()?;\n        let repo = GitRepository::new(dir.path())?;\n        let tenant_id = mk_core::types::TenantId::new(\"c1\".into()).unwrap();\n        let user_id = mk_core::types::UserId::new(\"u1\".into()).unwrap();\n        let ctx = mk_core::types::TenantContext::new(tenant_id, user_id);\n\n        let entry = KnowledgeEntry {\n            path: \"test.md\".to_string(),\n            content: \"hello world\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: mk_core::types::KnowledgeStatus::Draft,\n            metadata: std::collections::HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: chrono::Utc::now().timestamp(),\n        };\n\n        repo.store(ctx.clone(), entry.clone(), \"initial commit\")\n            .await?;\n\n        let retrieved = repo\n            .get(ctx.clone(), KnowledgeLayer::Project, \"test.md\")\n            .await?;\n        assert!(retrieved.is_some());\n        let retrieved = retrieved.unwrap();\n        assert_eq!(retrieved.content, \"hello world\");\n        assert_eq!(retrieved.status, mk_core::types::KnowledgeStatus::Draft);\n\n        let list = repo.list(ctx.clone(), KnowledgeLayer::Project, \"\").await?;\n        assert_eq!(list.len(), 1);\n\n        repo.delete(\n            ctx.clone(),\n            KnowledgeLayer::Project,\n            \"test.md\",\n            \"delete file\",\n        )\n        .await?;\n        let after_delete = repo.get(ctx, KnowledgeLayer::Project, \"test.md\").await?;\n        assert!(after_delete.is_none());\n\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_git_repository_isolation() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n        let dir = tempdir()?;\n        let repo = GitRepository::new(dir.path())?;\n\n        let tenant_a = mk_core::types::TenantId::new(\"tenant_a\".into()).unwrap();\n        let user_a = mk_core::types::UserId::new(\"user_a\".into()).unwrap();\n        let ctx_a = mk_core::types::TenantContext::new(tenant_a, user_a);\n\n        let tenant_b = mk_core::types::TenantId::new(\"tenant_b\".into()).unwrap();\n        let user_b = mk_core::types::UserId::new(\"user_b\".into()).unwrap();\n        let ctx_b = mk_core::types::TenantContext::new(tenant_b, user_b);\n\n        let entry = KnowledgeEntry {\n            path: \"secret.md\".to_string(),\n            content: \"tenant a secret\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: mk_core::types::KnowledgeStatus::Accepted,\n            metadata: std::collections::HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: chrono::Utc::now().timestamp(),\n        };\n\n        repo.store(ctx_a.clone(), entry, \"tenant a commit\").await?;\n\n        let retrieved_b = repo\n            .get(ctx_b.clone(), KnowledgeLayer::Project, \"secret.md\")\n            .await?;\n        assert!(\n            retrieved_b.is_none(),\n            \"Tenant B should not see Tenant A data\"\n        );\n\n        let retrieved_a = repo\n            .get(ctx_a.clone(), KnowledgeLayer::Project, \"secret.md\")\n            .await?;\n        assert!(retrieved_a.is_some());\n        assert_eq!(retrieved_a.unwrap().content, \"tenant a secret\");\n\n        let list_b = repo.list(ctx_b, KnowledgeLayer::Project, \"\").await?;\n        assert!(list_b.is_empty(), \"Tenant B list should be empty\");\n\n        let list_a = repo.list(ctx_a, KnowledgeLayer::Project, \"\").await?;\n        assert_eq!(list_a.len(), 1, \"Tenant A should see its entry\");\n\n        Ok(())\n    }\n}\n","traces":[{"line":26,"address":[],"length":0,"stats":{"Line":10}},{"line":27,"address":[],"length":0,"stats":{"Line":30}},{"line":28,"address":[],"length":0,"stats":{"Line":10}},{"line":29,"address":[],"length":0,"stats":{"Line":2}},{"line":32,"address":[],"length":0,"stats":{"Line":20}},{"line":33,"address":[],"length":0,"stats":{"Line":20}},{"line":36,"address":[],"length":0,"stats":{"Line":10}},{"line":39,"address":[],"length":0,"stats":{"Line":41}},{"line":45,"address":[],"length":0,"stats":{"Line":82}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":48,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":41}},{"line":51,"address":[],"length":0,"stats":{"Line":164}},{"line":52,"address":[],"length":0,"stats":{"Line":164}},{"line":53,"address":[],"length":0,"stats":{"Line":82}},{"line":54,"address":[],"length":0,"stats":{"Line":41}},{"line":57,"address":[],"length":0,"stats":{"Line":14}},{"line":58,"address":[],"length":0,"stats":{"Line":28}},{"line":59,"address":[],"length":0,"stats":{"Line":42}},{"line":61,"address":[],"length":0,"stats":{"Line":42}},{"line":62,"address":[],"length":0,"stats":{"Line":42}},{"line":63,"address":[],"length":0,"stats":{"Line":70}},{"line":64,"address":[],"length":0,"stats":{"Line":28}},{"line":66,"address":[],"length":0,"stats":{"Line":42}},{"line":67,"address":[],"length":0,"stats":{"Line":56}},{"line":69,"address":[],"length":0,"stats":{"Line":28}},{"line":71,"address":[],"length":0,"stats":{"Line":14}},{"line":73,"address":[],"length":0,"stats":{"Line":28}},{"line":74,"address":[],"length":0,"stats":{"Line":15}},{"line":75,"address":[],"length":0,"stats":{"Line":9}},{"line":78,"address":[],"length":0,"stats":{"Line":28}},{"line":79,"address":[],"length":0,"stats":{"Line":15}},{"line":80,"address":[],"length":0,"stats":{"Line":9}},{"line":83,"address":[],"length":0,"stats":{"Line":126}},{"line":85,"address":[],"length":0,"stats":{"Line":14}},{"line":88,"address":[],"length":0,"stats":{"Line":8}},{"line":89,"address":[],"length":0,"stats":{"Line":24}},{"line":90,"address":[],"length":0,"stats":{"Line":8}},{"line":91,"address":[],"length":0,"stats":{"Line":40}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":1}},{"line":148,"address":[],"length":0,"stats":{"Line":6}},{"line":149,"address":[],"length":0,"stats":{"Line":5}},{"line":150,"address":[],"length":0,"stats":{"Line":1}},{"line":151,"address":[],"length":0,"stats":{"Line":1}},{"line":152,"address":[],"length":0,"stats":{"Line":1}},{"line":153,"address":[],"length":0,"stats":{"Line":1}},{"line":154,"address":[],"length":0,"stats":{"Line":1}},{"line":155,"address":[],"length":0,"stats":{"Line":1}},{"line":156,"address":[],"length":0,"stats":{"Line":1}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":50}},{"line":205,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":58}},{"line":279,"address":[],"length":0,"stats":{"Line":29}},{"line":280,"address":[],"length":0,"stats":{"Line":76}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":344,"address":[],"length":0,"stats":{"Line":0}},{"line":345,"address":[],"length":0,"stats":{"Line":0}}],"covered":51,"coverable":73},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","scheduler.rs"],"content":"use crate::governance::GovernanceEngine;\nuse config::config::DeploymentConfig;\nuse mk_core::traits::KnowledgeRepository;\nuse mk_core::types::{DriftResult, KnowledgeLayer, TenantContext, UnitType, UserId};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse std::time::Duration;\nuse tokio::time;\n\npub struct GovernanceScheduler {\n    engine: Arc\u003cGovernanceEngine\u003e,\n    repository: Arc\u003cdyn KnowledgeRepository\u003cError = crate::repository::RepositoryError\u003e\u003e,\n    deployment_config: DeploymentConfig,\n    quick_scan_interval: Duration,\n    semantic_scan_interval: Duration,\n    report_interval: Duration,\n}\n\nimpl GovernanceScheduler {\n    pub fn new(\n        engine: Arc\u003cGovernanceEngine\u003e,\n        repository: Arc\u003cdyn KnowledgeRepository\u003cError = crate::repository::RepositoryError\u003e\u003e,\n        deployment_config: DeploymentConfig,\n        quick_scan_interval: Duration,\n        semantic_scan_interval: Duration,\n        report_interval: Duration,\n    ) -\u003e Self {\n        Self {\n            engine,\n            repository,\n            deployment_config,\n            quick_scan_interval,\n            semantic_scan_interval,\n            report_interval,\n        }\n    }\n\n    pub async fn start(\u0026self) {\n        if self.deployment_config.mode == \"remote\" {\n            tracing::info!(\"Governance scheduler disabled in Remote mode\");\n            return;\n        }\n\n        let mut quick_interval = time::interval(self.quick_scan_interval);\n        let mut semantic_interval = time::interval(self.semantic_scan_interval);\n        let mut report_interval = time::interval(self.report_interval);\n\n        loop {\n            tokio::select! {\n                _ = quick_interval.tick() =\u003e {\n                    let _ = self.run_job(\"quick_drift_scan\", \"all\", self.run_batch_drift_scan()).await;\n                }\n                _ = semantic_interval.tick() =\u003e {\n                    if self.deployment_config.mode != \"hybrid\" {\n                        let _ = self.run_job(\"semantic_analysis\", \"all\", self.run_semantic_analysis_job()).await;\n                    } else {\n                        tracing::debug!(\"Skipping local semantic analysis in Hybrid mode (relying on remote)\");\n                    }\n                }\n                _ = report_interval.tick() =\u003e {\n                    if self.deployment_config.mode == \"local\" {\n                        let _ = self.run_job(\"weekly_report\", \"all\", self.run_weekly_report_job()).await;\n                    }\n                }\n            }\n        }\n    }\n\n    async fn run_job\u003cF\u003e(\u0026self, name: \u0026str, tenant_id: \u0026str, job_future: F) -\u003e anyhow::Result\u003c()\u003e\n    where\n        F: std::future::Future\u003cOutput = anyhow::Result\u003c()\u003e\u003e,\n    {\n        let started_at = chrono::Utc::now().timestamp();\n        tracing::info!(\"Starting job: {}\", name);\n\n        let storage = self\n            .engine\n            .storage()\n            .ok_or_else(|| anyhow::anyhow!(\"Storage not configured\"))?;\n\n        let _ = storage\n            .record_job_status(name, tenant_id, \"running\", None, started_at, None)\n            .await;\n\n        match job_future.await {\n            Ok(_) =\u003e {\n                let finished_at = chrono::Utc::now().timestamp();\n                let _ = storage\n                    .record_job_status(\n                        name,\n                        tenant_id,\n                        \"completed\",\n                        None,\n                        started_at,\n                        Some(finished_at),\n                    )\n                    .await;\n                Ok(())\n            }\n            Err(e) =\u003e {\n                let finished_at = chrono::Utc::now().timestamp();\n                let message = format!(\"{:?}\", e);\n                let _ = storage\n                    .record_job_status(\n                        name,\n                        tenant_id,\n                        \"failed\",\n                        Some(\u0026message),\n                        started_at,\n                        Some(finished_at),\n                    )\n                    .await;\n                Err(e)\n            }\n        }\n    }\n\n    async fn run_batch_drift_scan(\u0026self) -\u003e anyhow::Result\u003c()\u003e {\n        tracing::info!(\"Starting batch drift scan\");\n\n        let storage = self\n            .engine\n            .storage()\n            .ok_or_else(|| anyhow::anyhow!(\"Storage not configured\"))?;\n        let units = storage\n            .list_all_units()\n            .await\n            .map_err(|e| anyhow::anyhow!(\"Failed to list units: {:?}\", e))?;\n\n        for unit in units {\n            if unit.unit_type == UnitType::Project {\n                let tenant_ctx =\n                    TenantContext::new(unit.tenant_id.clone(), mk_core::types::UserId::default());\n                let mut context = HashMap::new();\n                context.insert(\"projectId\".to_string(), serde_json::json!(unit.id));\n                context.insert(\"content\".to_string(), serde_json::json!(\"\"));\n\n                let _ = self\n                    .engine\n                    .check_drift(\u0026tenant_ctx, \u0026unit.id, \u0026context)\n                    .await;\n            }\n        }\n\n        Ok(())\n    }\n\n    async fn run_semantic_analysis_job(\u0026self) -\u003e anyhow::Result\u003c()\u003e {\n        tracing::info!(\"Starting daily semantic analysis job\");\n\n        let llm = self\n            .engine\n            .llm_service()\n            .ok_or_else(|| anyhow::anyhow!(\"LLM service not configured\"))?;\n\n        let storage = self\n            .engine\n            .storage()\n            .ok_or_else(|| anyhow::anyhow!(\"Storage not configured\"))?;\n\n        let units = storage\n            .list_all_units()\n            .await\n            .map_err(|e| anyhow::anyhow!(\"Failed to list units: {:?}\", e))?;\n\n        for unit in units {\n            if unit.unit_type == UnitType::Project {\n                let ctx = TenantContext::new(unit.tenant_id.clone(), UserId::default());\n\n                let policies = storage\n                    .get_unit_policies(ctx.clone(), \u0026unit.id)\n                    .await\n                    .map_err(|e| anyhow::anyhow!(\"Failed to fetch policies: {:?}\", e))?;\n\n                if policies.is_empty() {\n                    continue;\n                }\n\n                let entries = self\n                    .repository\n                    .list(ctx.clone(), KnowledgeLayer::Project, \"\")\n                    .await\n                    .map_err(|e| anyhow::anyhow!(\"Failed to list project files: {:?}\", e))?;\n\n                let content = entries\n                    .into_iter()\n                    .map(|e| format!(\"File: {}\\n---\\n{}\\n---\", e.path, e.content))\n                    .collect::\u003cVec\u003c_\u003e\u003e()\n                    .join(\"\\n\\n\");\n\n                if content.is_empty() {\n                    continue;\n                }\n\n                match llm.analyze_drift(\u0026content, \u0026policies).await {\n                    Ok(result) =\u003e {\n                        let drift_score = if result.is_valid { 0.0 } else { 1.0 };\n                        let _ = storage\n                            .store_drift_result(DriftResult {\n                                project_id: unit.id.clone(),\n                                tenant_id: unit.tenant_id.clone(),\n                                drift_score,\n                                violations: result.violations,\n                                timestamp: chrono::Utc::now().timestamp(),\n                            })\n                            .await;\n                    }\n                    Err(e) =\u003e {\n                        tracing::error!(\n                            \"Semantic analysis failed for project {}: {:?}\",\n                            unit.id,\n                            e\n                        );\n                    }\n                }\n            }\n        }\n\n        Ok(())\n    }\n\n    async fn run_weekly_report_job(\u0026self) -\u003e anyhow::Result\u003c()\u003e {\n        tracing::info!(\"Starting weekly governance report job\");\n\n        let storage = self\n            .engine\n            .storage()\n            .ok_or_else(|| anyhow::anyhow!(\"Storage not configured\"))?;\n\n        let units = storage\n            .list_all_units()\n            .await\n            .map_err(|e| anyhow::anyhow!(\"Failed to list units: {:?}\", e))?;\n\n        let now = chrono::Utc::now().timestamp();\n        let one_week_ago = now - (7 * 24 * 60 * 60);\n\n        for unit in units {\n            if unit.unit_type == UnitType::Organization {\n                let mut report_data = HashMap::new();\n                let children = storage\n                    .get_descendants(\n                        TenantContext::new(unit.tenant_id.clone(), UserId::default()),\n                        \u0026unit.id,\n                    )\n                    .await\n                    .map_err(|e| anyhow::anyhow!(\"Failed to list projects: {:?}\", e))?;\n\n                let mut total_drift = 0.0;\n                let mut project_count = 0;\n                let mut all_violations = Vec::new();\n\n                for child in children {\n                    if child.unit_type == UnitType::Project {\n                        if let Some(result) = storage\n                            .get_latest_drift_result(\n                                TenantContext::new(child.tenant_id.clone(), UserId::default()),\n                                \u0026child.id,\n                            )\n                            .await\n                            .map_err(|e| anyhow::anyhow!(\"Failed to fetch drift: {:?}\", e))?\n                        {\n                            if result.timestamp \u003e= one_week_ago {\n                                total_drift += result.drift_score;\n                                project_count += 1;\n                                all_violations.extend(result.violations);\n                            }\n                        }\n                    }\n                }\n\n                let avg_drift = if project_count \u003e 0 {\n                    total_drift / project_count as f32\n                } else {\n                    0.0\n                };\n\n                report_data.insert(\"average_drift\".to_string(), serde_json::json!(avg_drift));\n                report_data.insert(\n                    \"project_count\".to_string(),\n                    serde_json::json!(project_count),\n                );\n                report_data.insert(\n                    \"violation_count\".to_string(),\n                    serde_json::json!(all_violations.len()),\n                );\n\n                tracing::info!(\n                    \"Weekly report for Org {}: Avg Drift: {}, Projects: {}, Violations: {}\",\n                    unit.id,\n                    avg_drift,\n                    project_count,\n                    all_violations.len()\n                );\n            }\n        }\n\n        Ok(())\n    }\n}\n","traces":[{"line":20,"address":[],"length":0,"stats":{"Line":5}},{"line":38,"address":[],"length":0,"stats":{"Line":2}},{"line":39,"address":[],"length":0,"stats":{"Line":1}},{"line":40,"address":[],"length":0,"stats":{"Line":1}},{"line":41,"address":[],"length":0,"stats":{"Line":1}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":201,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":204,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":223,"address":[],"length":0,"stats":{"Line":0}},{"line":225,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":235,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":240,"address":[],"length":0,"stats":{"Line":0}},{"line":241,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":0}},{"line":254,"address":[],"length":0,"stats":{"Line":0}},{"line":255,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":264,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":272,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":284,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":298,"address":[],"length":0,"stats":{"Line":0}}],"covered":5,"coverable":159},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","state.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","telemetry.rs"],"content":"use metrics::increment_counter;\n\npub struct KnowledgeTelemetry;\n\nimpl KnowledgeTelemetry {\n    pub fn record_operation(\u0026self, operation: \u0026str, status: \u0026str) {\n        // GIVEN an operation and status\n        // WHEN recording metrics\n        // THEN increment the operation counter with status label\n\n        increment_counter!(\"knowledge_operations_total\", \"operation\" =\u003e operation.to_string(), \"status\" =\u003e status.to_string());\n    }\n\n    pub fn record_violation(\u0026self, layer: \u0026str, severity: \u0026str) {\n        // GIVEN a layer and severity\n        // WHEN recording metrics\n        // THEN increment the violation counter with layer and severity labels\n\n        increment_counter!(\"knowledge_violations_total\", \"layer\" =\u003e layer.to_string(), \"severity\" =\u003e severity.to_string());\n    }\n}\n","traces":[{"line":6,"address":[],"length":0,"stats":{"Line":0}},{"line":11,"address":[],"length":0,"stats":{"Line":0}},{"line":14,"address":[],"length":0,"stats":{"Line":25}},{"line":19,"address":[],"length":0,"stats":{"Line":25}}],"covered":2,"coverable":4},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","tools.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","validator.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","working.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","tests","api_test.rs"],"content":"use knowledge::api::{\n    GovernanceDashboardApi, approve_proposal, get_drift_status, get_job_status, get_org_report,\n    reject_proposal, replay_events,\n};\nuse knowledge::governance::GovernanceEngine;\nuse mk_core::traits::{EventPublisher, KnowledgeRepository, StorageBackend};\nuse mk_core::types::{\n    GovernanceEvent, KnowledgeEntry, KnowledgeLayer, KnowledgeStatus, KnowledgeType,\n    OrganizationalUnit, TenantContext, TenantId, UnitType,\n};\nuse std::sync::Arc;\nuse storage::postgres::PostgresBackend;\nuse testcontainers::runners::AsyncRunner;\nuse testcontainers_modules::postgres::Postgres;\n\n#[tokio::test]\nasync fn test_governance_dashboard_api_get_drift_status() {\n    let container = match Postgres::default().start().await {\n        Ok(c) =\u003e c,\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Postgres test: Docker not available\");\n            return;\n        }\n    };\n\n    let host = container.get_host().await.unwrap();\n    let port = container.get_host_port_ipv4(5432).await.unwrap();\n    let conn_str = format!(\n        \"postgres://postgres:postgres@{}:{}/postgres?sslmode=disable\",\n        host, port\n    );\n\n    let storage = Arc::new(PostgresBackend::new(\u0026conn_str).await.unwrap());\n    storage.initialize_schema().await.unwrap();\n\n    let engine = Arc::new(GovernanceEngine::new());\n    let deployment_config = config::config::DeploymentConfig {\n        mode: \"local\".to_string(),\n        remote_url: None,\n        ..Default::default()\n    };\n\n    let api = Arc::new(GovernanceDashboardApi::new(\n        engine.clone(),\n        storage.clone(),\n        deployment_config,\n    ));\n\n    let tenant_id = TenantId::new(\"t1\".to_string()).unwrap();\n    let ctx = TenantContext {\n        tenant_id: tenant_id.clone(),\n        user_id: mk_core::types::UserId::new(\"u1\".to_string()).unwrap(),\n        agent_id: Some(\"a1\".to_string()),\n    };\n\n    let res = get_drift_status(api.clone(), \u0026ctx, \"p1\").await.unwrap();\n    assert!(res.is_none());\n\n    let drift = mk_core::types::DriftResult {\n        project_id: \"p1\".to_string(),\n        tenant_id: tenant_id.clone(),\n        drift_score: 0.75,\n        violations: vec![],\n        timestamp: 123456789,\n    };\n    storage.store_drift_result(drift).await.unwrap();\n\n    let res = get_drift_status(api.clone(), \u0026ctx, \"p1\").await.unwrap();\n    assert!(res.is_some());\n    assert_eq!(res.unwrap().drift_score, 0.75);\n}\n\n#[tokio::test]\nasync fn test_governance_dashboard_api_get_org_report() {\n    let container = match Postgres::default().start().await {\n        Ok(c) =\u003e c,\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Postgres test: Docker not available\");\n            return;\n        }\n    };\n\n    let host = container.get_host().await.unwrap();\n    let port = container.get_host_port_ipv4(5432).await.unwrap();\n    let conn_str = format!(\n        \"postgres://postgres:postgres@{}:{}/postgres?sslmode=disable\",\n        host, port\n    );\n\n    let storage = Arc::new(PostgresBackend::new(\u0026conn_str).await.unwrap());\n    storage.initialize_schema().await.unwrap();\n\n    let engine = Arc::new(GovernanceEngine::new());\n    let deployment_config = config::config::DeploymentConfig {\n        mode: \"local\".to_string(),\n        remote_url: None,\n        ..Default::default()\n    };\n\n    let api = Arc::new(GovernanceDashboardApi::new(\n        engine.clone(),\n        storage.clone(),\n        deployment_config,\n    ));\n\n    let tenant_id = TenantId::new(\"t1\".to_string()).unwrap();\n    let ctx = TenantContext {\n        tenant_id: tenant_id.clone(),\n        user_id: mk_core::types::UserId::new(\"u1\".to_string()).unwrap(),\n        agent_id: Some(\"a1\".to_string()),\n    };\n\n    let company_unit = OrganizationalUnit {\n        id: \"c1\".to_string(),\n        name: \"Company 1\".to_string(),\n        unit_type: UnitType::Company,\n        tenant_id: tenant_id.clone(),\n        parent_id: None,\n        metadata: std::collections::HashMap::new(),\n        created_at: 1000,\n        updated_at: 1000,\n    };\n    storage.create_unit(\u0026company_unit).await.unwrap();\n\n    let org_unit = OrganizationalUnit {\n        id: \"org1\".to_string(),\n        name: \"Org 1\".to_string(),\n        unit_type: UnitType::Organization,\n        tenant_id: tenant_id.clone(),\n        parent_id: Some(\"c1\".to_string()),\n        metadata: std::collections::HashMap::new(),\n        created_at: 1000,\n        updated_at: 1000,\n    };\n    storage.create_unit(\u0026org_unit).await.unwrap();\n\n    let team_unit = OrganizationalUnit {\n        id: \"t1_unit\".to_string(),\n        name: \"Team 1\".to_string(),\n        unit_type: UnitType::Team,\n        tenant_id: tenant_id.clone(),\n        parent_id: Some(\"org1\".to_string()),\n        metadata: std::collections::HashMap::new(),\n        created_at: 1000,\n        updated_at: 1000,\n    };\n    storage.create_unit(\u0026team_unit).await.unwrap();\n\n    let project_unit = OrganizationalUnit {\n        id: \"p1\".to_string(),\n        name: \"Project 1\".to_string(),\n        unit_type: UnitType::Project,\n        tenant_id: tenant_id.clone(),\n        parent_id: Some(\"t1_unit\".to_string()),\n        metadata: std::collections::HashMap::new(),\n        created_at: 1000,\n        updated_at: 1000,\n    };\n    storage.create_unit(\u0026project_unit).await.unwrap();\n\n    let drift = mk_core::types::DriftResult {\n        project_id: \"p1\".to_string(),\n        tenant_id: tenant_id.clone(),\n        drift_score: 0.5,\n        violations: vec![],\n        timestamp: 123456789,\n    };\n    storage.store_drift_result(drift).await.unwrap();\n\n    let report = get_org_report(api.clone(), \u0026ctx, \"c1\").await.unwrap();\n    assert_eq!(report[\"orgId\"], \"c1\");\n    assert_eq!(report[\"averageDrift\"], 0.5);\n    assert_eq!(report[\"projectCount\"], 1);\n}\n\n#[tokio::test]\nasync fn test_governance_dashboard_api_proposals() {\n    let container = match Postgres::default().start().await {\n        Ok(c) =\u003e c,\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Postgres test: Docker not available\");\n            return;\n        }\n    };\n\n    let host = container.get_host().await.unwrap();\n    let port = container.get_host_port_ipv4(5432).await.unwrap();\n    let conn_str = format!(\n        \"postgres://postgres:postgres@{}:{}/postgres?sslmode=disable\",\n        host, port\n    );\n\n    let storage = Arc::new(PostgresBackend::new(\u0026conn_str).await.unwrap());\n    storage.initialize_schema().await.unwrap();\n\n    let temp_dir = tempfile::tempdir().unwrap();\n    let repo = Arc::new(\n        knowledge::repository::GitRepository::new(temp_dir.path().to_str().unwrap()).unwrap(),\n    );\n\n    let engine = Arc::new(GovernanceEngine::new().with_repository(repo.clone()));\n    let deployment_config = config::config::DeploymentConfig {\n        mode: \"local\".to_string(),\n        remote_url: None,\n        ..Default::default()\n    };\n\n    let api = Arc::new(GovernanceDashboardApi::new(\n        engine.clone(),\n        storage.clone(),\n        deployment_config,\n    ));\n\n    let tenant_id = TenantId::new(\"t1\".to_string()).unwrap();\n    let ctx = TenantContext {\n        tenant_id: tenant_id.clone(),\n        user_id: mk_core::types::UserId::new(\"u1\".to_string()).unwrap(),\n        agent_id: Some(\"a1\".to_string()),\n    };\n\n    let entry = KnowledgeEntry {\n        path: \"prop1\".to_string(),\n        content: \"Content\".to_string(),\n        layer: KnowledgeLayer::Project,\n        kind: KnowledgeType::Adr,\n        status: KnowledgeStatus::Proposed,\n        metadata: std::collections::HashMap::new(),\n        commit_hash: None,\n        author: Some(\"u1\".to_string()),\n        updated_at: 1000,\n    };\n    repo.store(ctx.clone(), entry, \"Initial proposal\")\n        .await\n        .unwrap();\n\n    let proposals = api.list_proposals(\u0026ctx, None).await.unwrap();\n    assert_eq!(proposals.len(), 1);\n    assert_eq!(proposals[0].path, \"prop1\");\n\n    approve_proposal(api.clone(), \u0026ctx, \"prop1\").await.unwrap();\n    let approved = repo\n        .get(ctx.clone(), KnowledgeLayer::Project, \"prop1\")\n        .await\n        .unwrap()\n        .unwrap();\n    assert_eq!(approved.status, KnowledgeStatus::Accepted);\n\n    let entry2 = KnowledgeEntry {\n        path: \"prop2\".to_string(),\n        content: \"Content\".to_string(),\n        layer: KnowledgeLayer::Project,\n        kind: KnowledgeType::Adr,\n        status: KnowledgeStatus::Proposed,\n        metadata: std::collections::HashMap::new(),\n        commit_hash: None,\n        author: Some(\"u1\".to_string()),\n        updated_at: 1000,\n    };\n    repo.store(ctx.clone(), entry2, \"Initial proposal\")\n        .await\n        .unwrap();\n\n    reject_proposal(api.clone(), \u0026ctx, \"prop2\", \"Too complex\")\n        .await\n        .unwrap();\n    let rejected = repo\n        .get(ctx.clone(), KnowledgeLayer::Project, \"prop2\")\n        .await\n        .unwrap()\n        .unwrap();\n    assert_eq!(rejected.status, KnowledgeStatus::Draft);\n    assert_eq!(\n        rejected.metadata.get(\"rejection_reason\").unwrap(),\n        \u0026serde_json::json!(\"Too complex\")\n    );\n}\n\n#[tokio::test]\nasync fn test_governance_dashboard_api_get_job_status() {\n    let container = match Postgres::default().start().await {\n        Ok(c) =\u003e c,\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Postgres test: Docker not available\");\n            return;\n        }\n    };\n\n    let host = container.get_host().await.unwrap();\n    let port = container.get_host_port_ipv4(5432).await.unwrap();\n    let conn_str = format!(\n        \"postgres://postgres:postgres@{}:{}/postgres?sslmode=disable\",\n        host, port\n    );\n\n    let storage = Arc::new(PostgresBackend::new(\u0026conn_str).await.unwrap());\n    storage.initialize_schema().await.unwrap();\n\n    let engine = Arc::new(GovernanceEngine::new());\n    let api = Arc::new(GovernanceDashboardApi::new(\n        engine,\n        storage.clone(),\n        config::config::DeploymentConfig::default(),\n    ));\n\n    let tenant_id = TenantId::new(\"t1\".to_string()).unwrap();\n    let ctx = TenantContext {\n        tenant_id: tenant_id.clone(),\n        user_id: mk_core::types::UserId::new(\"u1\".to_string()).unwrap(),\n        agent_id: Some(\"a1\".to_string()),\n    };\n\n    storage\n        .record_job_status(\n            \"test-job\",\n            \"t1\",\n            \"completed\",\n            Some(\"Done\"),\n            1000,\n            Some(1001),\n        )\n        .await\n        .unwrap();\n    storage\n        .record_job_status(\"other-job\", \"t1\", \"running\", None, 1002, None)\n        .await\n        .unwrap();\n    storage\n        .record_job_status(\"global-job\", \"all\", \"completed\", None, 1003, Some(1004))\n        .await\n        .unwrap();\n\n    let all_jobs = get_job_status(api.clone(), \u0026ctx, None).await.unwrap();\n    assert_eq!(all_jobs.as_array().unwrap().len(), 3);\n\n    let filtered_jobs = get_job_status(api.clone(), \u0026ctx, Some(\"test-job\"))\n        .await\n        .unwrap();\n    assert_eq!(filtered_jobs.as_array().unwrap().len(), 1);\n    assert_eq!(filtered_jobs[0][\"jobName\"], \"test-job\");\n    assert_eq!(filtered_jobs[0][\"status\"], \"completed\");\n}\n\n#[tokio::test]\nasync fn test_governance_dashboard_api_replay_events() {\n    let container = match Postgres::default().start().await {\n        Ok(c) =\u003e c,\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Postgres test: Docker not available\");\n            return;\n        }\n    };\n\n    let host = container.get_host().await.unwrap();\n    let port = container.get_host_port_ipv4(5432).await.unwrap();\n    let conn_str = format!(\n        \"postgres://postgres:postgres@{}:{}/postgres?sslmode=disable\",\n        host, port\n    );\n\n    let storage = Arc::new(PostgresBackend::new(\u0026conn_str).await.unwrap());\n    storage.initialize_schema().await.unwrap();\n\n    let engine = Arc::new(GovernanceEngine::new());\n    let api = Arc::new(GovernanceDashboardApi::new(\n        engine,\n        storage.clone(),\n        config::config::DeploymentConfig::default(),\n    ));\n\n    let tenant_id = TenantId::new(\"t1\".to_string()).unwrap();\n    let ctx = TenantContext {\n        tenant_id: tenant_id.clone(),\n        user_id: mk_core::types::UserId::new(\"u1\".to_string()).unwrap(),\n        agent_id: Some(\"a1\".to_string()),\n    };\n\n    let event1 = GovernanceEvent::UnitCreated {\n        unit_id: \"u1\".into(),\n        unit_type: UnitType::Project,\n        tenant_id: tenant_id.clone(),\n        parent_id: None,\n        timestamp: 1000,\n    };\n    let event2 = GovernanceEvent::UnitCreated {\n        unit_id: \"u2\".into(),\n        unit_type: UnitType::Project,\n        tenant_id: tenant_id.clone(),\n        parent_id: None,\n        timestamp: 2000,\n    };\n\n    storage.publish(event1).await.unwrap();\n    storage.publish(event2).await.unwrap();\n\n    let all_replayed = replay_events(api.clone(), \u0026ctx, 500, 10).await.unwrap();\n    assert_eq!(all_replayed.len(), 2);\n\n    let partial_replayed = replay_events(api.clone(), \u0026ctx, 1500, 10).await.unwrap();\n    assert_eq!(partial_replayed.len(), 1);\n    if let GovernanceEvent::UnitCreated { unit_id, .. } = \u0026partial_replayed[0] {\n        assert_eq!(unit_id, \"u2\");\n    } else {\n        panic!(\"Expected UnitCreated event\");\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","tests","drift_detection_test.rs"],"content":"//! Tests for drift detection accuracy in the GovernanceEngine.\n//!\n//! These tests verify:\n//! - Drift score calculation based on violation severity\n//! - Missing mandatory policies detection\n//! - Stale policy version detection\n//! - Semantic contradiction detection\n//! - Edge cases and boundary conditions\n\nuse knowledge::governance::GovernanceEngine;\nuse mk_core::types::{\n    ConstraintOperator, ConstraintSeverity, ConstraintTarget, KnowledgeLayer, Policy, PolicyMode,\n    PolicyRule, RuleMergeStrategy, RuleType, TenantContext, TenantId, UserId,\n};\nuse std::collections::HashMap;\nuse std::sync::Arc;\n\nfn create_test_context() -\u003e TenantContext {\n    TenantContext::new(\n        TenantId::new(\"test-tenant\".to_string()).unwrap(),\n        UserId::new(\"test-user\".to_string()).unwrap(),\n    )\n}\n\nfn create_mandatory_policy(id: \u0026str, rules: Vec\u003cPolicyRule\u003e) -\u003e Policy {\n    Policy {\n        id: id.to_string(),\n        name: format!(\"Policy {}\", id),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules,\n        metadata: HashMap::new(),\n    }\n}\n\nfn create_advisory_policy(id: \u0026str, rules: Vec\u003cPolicyRule\u003e) -\u003e Policy {\n    Policy {\n        id: id.to_string(),\n        name: format!(\"Policy {}\", id),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules,\n        metadata: HashMap::new(),\n    }\n}\n\n#[tokio::test]\nasync fn test_drift_score_zero_when_no_violations() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"valid-policy\",\n        vec![PolicyRule {\n            id: \"rule-1\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::File,\n            operator: ConstraintOperator::MustExist,\n            value: serde_json::json!(null),\n            severity: ConstraintSeverity::Block,\n            message: \"File must exist\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"path\".to_string(), serde_json::json!(\"/src/main.rs\"));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(\n        drift_score, 0.0,\n        \"No violations should yield drift score of 0.0\"\n    );\n}\n\n#[tokio::test]\nasync fn test_drift_score_block_severity_yields_one() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"blocking-policy\",\n        vec![PolicyRule {\n            id: \"block-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"required-lib\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Required library missing\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([\"other-lib\"]));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(\n        drift_score, 1.0,\n        \"Block severity violation should yield drift score of 1.0\"\n    );\n}\n\n#[tokio::test]\nasync fn test_drift_score_warn_severity_yields_half() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"warning-policy\",\n        vec![PolicyRule {\n            id: \"warn-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"recommended-lib\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Recommended library missing\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([\"other-lib\"]));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(\n        drift_score, 0.5,\n        \"Warn severity violation should yield drift score of 0.5\"\n    );\n}\n\n#[tokio::test]\nasync fn test_drift_score_info_severity_yields_point_one() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"info-policy\",\n        vec![PolicyRule {\n            id: \"info-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"optional-lib\"),\n            severity: ConstraintSeverity::Info,\n            message: \"Optional library missing\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([\"other-lib\"]));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert!(\n        (drift_score - 0.1).abs() \u003c 0.01,\n        \"Info severity violation should yield drift score of ~0.1\"\n    );\n}\n\n#[tokio::test]\nasync fn test_drift_score_capped_at_one() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"multi-violation-policy\",\n        vec![\n            PolicyRule {\n                id: \"block-1\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Dependency,\n                operator: ConstraintOperator::MustUse,\n                value: serde_json::json!(\"lib-1\"),\n                severity: ConstraintSeverity::Block,\n                message: \"Missing lib-1\".to_string(),\n            },\n            PolicyRule {\n                id: \"block-2\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Dependency,\n                operator: ConstraintOperator::MustUse,\n                value: serde_json::json!(\"lib-2\"),\n                severity: ConstraintSeverity::Block,\n                message: \"Missing lib-2\".to_string(),\n            },\n            PolicyRule {\n                id: \"block-3\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Dependency,\n                operator: ConstraintOperator::MustUse,\n                value: serde_json::json!(\"lib-3\"),\n                severity: ConstraintSeverity::Block,\n                message: \"Missing lib-3\".to_string(),\n            },\n        ],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([]));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(\n        drift_score, 1.0,\n        \"Drift score should be capped at 1.0 even with multiple Block violations\"\n    );\n}\n\n#[tokio::test]\nasync fn test_drift_score_mixed_severities() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"mixed-policy\",\n        vec![\n            PolicyRule {\n                id: \"warn-rule\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Dependency,\n                operator: ConstraintOperator::MustUse,\n                value: serde_json::json!(\"warn-lib\"),\n                severity: ConstraintSeverity::Warn,\n                message: \"Missing warn-lib\".to_string(),\n            },\n            PolicyRule {\n                id: \"info-rule\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Dependency,\n                operator: ConstraintOperator::MustUse,\n                value: serde_json::json!(\"info-lib\"),\n                severity: ConstraintSeverity::Info,\n                message: \"Missing info-lib\".to_string(),\n            },\n        ],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([]));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert!(\n        (drift_score - 0.6).abs() \u003c 0.01,\n        \"Warn (0.5) + Info (0.1) should yield ~0.6\"\n    );\n}\n\n#[tokio::test]\nasync fn test_missing_mandatory_policies_detection() {\n    let engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let context: HashMap\u003cString, serde_json::Value\u003e = HashMap::new();\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n\n    assert!(\n        drift_score \u003e 0.0,\n        \"Missing mandatory policies should trigger drift\"\n    );\n    assert!(\n        drift_score \u003c= 0.5,\n        \"Missing mandatory policies is a Warn severity (0.5)\"\n    );\n}\n\n#[tokio::test]\nasync fn test_stale_policy_version_detection() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let mut metadata = HashMap::new();\n    metadata.insert(\"version_hash\".to_string(), serde_json::json!(\"v2.0.0\"));\n\n    let policy = Policy {\n        id: \"versioned-policy\".to_string(),\n        name: \"Versioned Policy\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Project,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![],\n        metadata,\n    };\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"version_hash\".to_string(), serde_json::json!(\"v1.0.0\"));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert!(\n        drift_score \u003e 0.0,\n        \"Stale policy version should trigger drift\"\n    );\n}\n\n#[tokio::test]\nasync fn test_no_stale_policy_when_versions_match() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let mut metadata = HashMap::new();\n    metadata.insert(\"version_hash\".to_string(), serde_json::json!(\"v2.0.0\"));\n\n    let policy = Policy {\n        id: \"versioned-policy\".to_string(),\n        name: \"Versioned Policy\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Project,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![],\n        metadata,\n    };\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"version_hash\".to_string(), serde_json::json!(\"v2.0.0\"));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(\n        drift_score, 0.0,\n        \"Matching versions should not trigger drift\"\n    );\n}\n\n#[tokio::test]\nasync fn test_advisory_policies_dont_count_as_mandatory() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_advisory_policy(\n        \"advisory-only\",\n        vec![PolicyRule {\n            id: \"advisory-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::File,\n            operator: ConstraintOperator::MustExist,\n            value: serde_json::json!(null),\n            severity: ConstraintSeverity::Info,\n            message: \"Advisory check\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"path\".to_string(), serde_json::json!(\"/src/main.rs\"));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert!(\n        drift_score \u003e 0.0,\n        \"Only advisory policies should still trigger missing mandatory drift\"\n    );\n}\n\n#[tokio::test]\nasync fn test_multiple_policies_accumulate_violations() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy1 = create_mandatory_policy(\n        \"policy-1\",\n        vec![PolicyRule {\n            id: \"rule-1\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"lib-a\"),\n            severity: ConstraintSeverity::Info,\n            message: \"Missing lib-a\".to_string(),\n        }],\n    );\n\n    let policy2 = create_mandatory_policy(\n        \"policy-2\",\n        vec![PolicyRule {\n            id: \"rule-2\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"lib-b\"),\n            severity: ConstraintSeverity::Info,\n            message: \"Missing lib-b\".to_string(),\n        }],\n    );\n\n    engine.add_policy(policy1);\n    engine.add_policy(policy2);\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([]));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert!(\n        (drift_score - 0.2).abs() \u003c 0.01,\n        \"Two Info violations should yield ~0.2\"\n    );\n}\n\n#[tokio::test]\nasync fn test_deny_rule_violation_detection() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"deny-policy\",\n        vec![PolicyRule {\n            id: \"deny-rule\".to_string(),\n            rule_type: RuleType::Deny,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"forbidden-lib\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Forbidden library detected\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\n        \"dependencies\".to_string(),\n        serde_json::json!([\"forbidden-lib\", \"good-lib\"]),\n    );\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(\n        drift_score, 1.0,\n        \"Using forbidden dependency should yield max drift\"\n    );\n}\n\n#[tokio::test]\nasync fn test_empty_context_with_mandatory_policies() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"requires-deps\",\n        vec![PolicyRule {\n            id: \"check-deps\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustExist,\n            value: serde_json::json!(null),\n            severity: ConstraintSeverity::Block,\n            message: \"Dependencies must be declared\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let context: HashMap\u003cString, serde_json::Value\u003e = HashMap::new();\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(\n        drift_score, 1.0,\n        \"Missing required dependency key should yield max drift\"\n    );\n}\n\n#[tokio::test]\nasync fn test_drift_with_must_not_use_satisfied() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"no-bad-libs\",\n        vec![PolicyRule {\n            id: \"no-bad\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustNotUse,\n            value: serde_json::json!(\"bad-lib\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Bad library forbidden\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([\"good-lib\"]));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(\n        drift_score, 0.0,\n        \"Not using forbidden lib should yield zero drift\"\n    );\n}\n\n#[tokio::test]\nasync fn test_drift_with_must_not_use_violated() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"no-bad-libs\",\n        vec![PolicyRule {\n            id: \"no-bad\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustNotUse,\n            value: serde_json::json!(\"bad-lib\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Bad library forbidden\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\n        \"dependencies\".to_string(),\n        serde_json::json!([\"good-lib\", \"bad-lib\"]),\n    );\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(\n        drift_score, 1.0,\n        \"Using forbidden lib should yield max drift\"\n    );\n}\n\n#[tokio::test]\nasync fn test_drift_with_regex_match_satisfied() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"naming-policy\",\n        vec![PolicyRule {\n            id: \"name-pattern\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::File,\n            operator: ConstraintOperator::MustMatch,\n            value: serde_json::json!(r\"^[a-z_]+\\.rs$\"),\n            severity: ConstraintSeverity::Block,\n            message: \"File must match naming convention\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"path\".to_string(), serde_json::json!(\"my_module.rs\"));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(drift_score, 0.0, \"Matching pattern should yield zero drift\");\n}\n\n#[tokio::test]\nasync fn test_drift_with_regex_match_violated() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"naming-policy\",\n        vec![PolicyRule {\n            id: \"name-pattern\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::File,\n            operator: ConstraintOperator::MustMatch,\n            value: serde_json::json!(r\"^[a-z_]+\\.rs$\"),\n            severity: ConstraintSeverity::Block,\n            message: \"File must match naming convention\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"path\".to_string(), serde_json::json!(\"MyModule.rs\"));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(\n        drift_score, 1.0,\n        \"Non-matching pattern should yield max drift\"\n    );\n}\n\n#[tokio::test]\nasync fn test_drift_with_must_not_match_satisfied() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"no-test-files\",\n        vec![PolicyRule {\n            id: \"no-test\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::File,\n            operator: ConstraintOperator::MustNotMatch,\n            value: serde_json::json!(r\"_test\\.rs$\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Test files not allowed in src\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"path\".to_string(), serde_json::json!(\"main.rs\"));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(drift_score, 0.0, \"Non-test file should yield zero drift\");\n}\n\n#[tokio::test]\nasync fn test_drift_with_must_not_match_violated() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"no-test-files\",\n        vec![PolicyRule {\n            id: \"no-test\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::File,\n            operator: ConstraintOperator::MustNotMatch,\n            value: serde_json::json!(r\"_test\\.rs$\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Test files not allowed in src\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"path\".to_string(), serde_json::json!(\"main_test.rs\"));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(drift_score, 1.0, \"Test file in src should yield max drift\");\n}\n\n#[tokio::test]\nasync fn test_drift_layer_filtering() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let company_policy = Policy {\n        id: \"company-policy\".to_string(),\n        name: \"Company Policy\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![PolicyRule {\n            id: \"company-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"company-lib\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Company lib required\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    let project_policy = Policy {\n        id: \"project-policy\".to_string(),\n        name: \"Project Policy\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Project,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![PolicyRule {\n            id: \"project-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"project-lib\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Project lib required\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(company_policy);\n    engine.add_policy(project_policy);\n\n    let mut context = HashMap::new();\n    context.insert(\n        \"dependencies\".to_string(),\n        serde_json::json!([\"company-lib\"]),\n    );\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert!(\n        drift_score \u003e 0.0,\n        \"Missing project-lib should trigger drift\"\n    );\n    assert!(\n        drift_score \u003c= 0.5,\n        \"Only project-lib missing (Warn) should yield \u003c= 0.5\"\n    );\n}\n\n#[tokio::test]\nasync fn test_drift_idempotent_check() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"idempotent-test\",\n        vec![PolicyRule {\n            id: \"rule-1\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"required-lib\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Required lib missing\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([\"other-lib\"]));\n\n    let score1 = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    let score2 = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    let score3 = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n\n    assert_eq!(score1, score2, \"Drift check should be idempotent\");\n    assert_eq!(score2, score3, \"Drift check should be idempotent\");\n}\n\n#[tokio::test]\nasync fn test_llm_enhanced_drift_detects_semantic_violations() {\n    let mock_llm = Arc::new(memory::llm::mock::MockLlmService::new());\n\n    let engine = GovernanceEngine::new().with_llm_service(mock_llm);\n    let ctx = create_test_context();\n\n    let mut context = HashMap::new();\n    context.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"This code violate:security-rule violates security practices\"),\n    );\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n\n    assert!(\n        drift_score \u003e 0.0,\n        \"LLM should detect semantic violations when rule marker present\"\n    );\n}\n\n#[tokio::test]\nasync fn test_llm_enhanced_drift_no_false_positives() {\n    let mock_llm = Arc::new(memory::llm::mock::MockLlmService::new());\n\n    let engine = GovernanceEngine::new().with_llm_service(mock_llm);\n    let ctx = create_test_context();\n\n    let mut context = HashMap::new();\n    context.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"This is perfectly compliant code with no issues\"),\n    );\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n\n    assert!(\n        drift_score \u003c= 0.5,\n        \"LLM should not create false positives for compliant content\"\n    );\n}\n\n#[tokio::test]\nasync fn test_llm_violations_prefixed_with_llm_marker() {\n    let mock_llm = Arc::new(memory::llm::mock::MockLlmService::new());\n\n    let mut engine = GovernanceEngine::new().with_llm_service(mock_llm);\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"semantic-policy\",\n        vec![PolicyRule {\n            id: \"semantic-check\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustMatch,\n            value: serde_json::json!(\".*\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Semantic policy\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"Code that violate:semantic-check triggers LLM analysis\"),\n    );\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert!(drift_score \u003e 0.0, \"Should detect LLM violation\");\n}\n\n#[tokio::test]\nasync fn test_llm_graceful_degradation_without_service() {\n    let engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let mut context = HashMap::new();\n    context.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"Content that would trigger LLM analysis if available\"),\n    );\n\n    let result = engine.check_drift(\u0026ctx, \"project-1\", \u0026context).await;\n    assert!(result.is_ok(), \"Should work without LLM service configured\");\n}\n\n#[tokio::test]\nasync fn test_llm_combined_with_rule_based_violations() {\n    let mock_llm = Arc::new(memory::llm::mock::MockLlmService::new());\n\n    let mut engine = GovernanceEngine::new().with_llm_service(mock_llm);\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"combined-policy\",\n        vec![\n            PolicyRule {\n                id: \"rule-based\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Dependency,\n                operator: ConstraintOperator::MustUse,\n                value: serde_json::json!(\"required-lib\"),\n                severity: ConstraintSeverity::Warn,\n                message: \"Required lib missing\".to_string(),\n            },\n            PolicyRule {\n                id: \"llm-checked\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Code,\n                operator: ConstraintOperator::MustMatch,\n                value: serde_json::json!(\".*\"),\n                severity: ConstraintSeverity::Info,\n                message: \"LLM semantic check\".to_string(),\n            },\n        ],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([\"other-lib\"]));\n    context.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"Code that violate:llm-checked\"),\n    );\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert!(\n        drift_score \u003e= 0.6,\n        \"Should combine rule-based (0.5) + LLM (0.1) violations\"\n    );\n}\n\n#[tokio::test]\nasync fn test_llm_does_not_duplicate_existing_violations() {\n    let mock_llm = Arc::new(memory::llm::mock::MockLlmService::new());\n\n    let mut engine = GovernanceEngine::new().with_llm_service(mock_llm);\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"dup-test-policy\",\n        vec![PolicyRule {\n            id: \"shared-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"must-have-lib\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Must have lib\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([]));\n    context.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"Content that triggers violate:shared-rule\"),\n    );\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(\n        drift_score, 1.0,\n        \"Score should be capped at 1.0, not doubled\"\n    );\n}\n","traces":[{"line":18,"address":[],"length":0,"stats":{"Line":27}},{"line":20,"address":[],"length":0,"stats":{"Line":108}},{"line":21,"address":[],"length":0,"stats":{"Line":108}},{"line":25,"address":[],"length":0,"stats":{"Line":20}},{"line":27,"address":[],"length":0,"stats":{"Line":60}},{"line":28,"address":[],"length":0,"stats":{"Line":60}},{"line":34,"address":[],"length":0,"stats":{"Line":20}},{"line":38,"address":[],"length":0,"stats":{"Line":1}},{"line":40,"address":[],"length":0,"stats":{"Line":3}},{"line":41,"address":[],"length":0,"stats":{"Line":3}},{"line":47,"address":[],"length":0,"stats":{"Line":1}}],"covered":11,"coverable":11},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","tests","governance_inheritance_test.rs"],"content":"use knowledge::governance::GovernanceEngine;\nuse mk_core::types::{\n    ConstraintOperator, ConstraintSeverity, ConstraintTarget, KnowledgeLayer, Policy, PolicyMode,\n    PolicyRule, RuleMergeStrategy, RuleType,\n};\nuse std::collections::HashMap;\n\n#[tokio::test]\nasync fn test_policy_shadowing_and_inheritance() {\n    let mut engine = GovernanceEngine::new();\n\n    let company_policy = Policy {\n        id: \"security\".to_string(),\n        name: \"Security\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"no-secrets\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustNotMatch,\n            value: serde_json::json!(\"SECRET_.*\"),\n            severity: ConstraintSeverity::Block,\n            message: \"No secrets allowed\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    let org_policy = Policy {\n        id: \"coding-style\".to_string(),\n        name: \"Style\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Org,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![PolicyRule {\n            id: \"indentation\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustMatch,\n            value: serde_json::json!(r\"^  \\S\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Use 2 spaces\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(company_policy);\n    engine.add_policy(org_policy);\n\n    let project_id = \"proj-1\";\n    let mut context = HashMap::new();\n    context.insert(\"projectId\".to_string(), serde_json::json!(project_id));\n    context.insert(\"content\".to_string(), serde_json::json!(\"    fn main() {}\"));\n\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context);\n    assert!(!result.is_valid);\n\n    let project_policy = Policy {\n        id: \"coding-style\".to_string(),\n        name: \"Project Style\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Project,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![PolicyRule {\n            id: \"indentation\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustMatch,\n            value: serde_json::json!(r\"^    \\S\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Use 4 spaces\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(project_policy);\n\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context);\n    assert!(\n        result.is_valid,\n        \"Project policy should have overridden Org policy\"\n    );\n\n    let project_security_override = Policy {\n        id: \"security\".to_string(),\n        name: \"Insecure Project\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Project,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(project_security_override);\n\n    let mut context_with_secret = HashMap::new();\n    context_with_secret.insert(\"projectId\".to_string(), serde_json::json!(project_id));\n    context_with_secret.insert(\"content\".to_string(), serde_json::json!(\"SECRET_KEY=123\"));\n\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context_with_secret);\n    assert!(\n        !result.is_valid,\n        \"Company mandatory policy should NOT be overridable\"\n    );\n}\n\n#[tokio::test]\nasync fn test_rule_type_deny_precedence() {\n    let mut engine = GovernanceEngine::new();\n\n    let company_policy = Policy {\n        id: \"lib-checks\".to_string(),\n        name: \"Lib Checks\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"deny-jquery\".to_string(),\n            rule_type: RuleType::Deny,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"jquery\"),\n            severity: ConstraintSeverity::Block,\n            message: \"JQuery is forbidden\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(company_policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([\"jquery\"]));\n\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context);\n    assert!(!result.is_valid);\n    assert_eq!(result.violations[0].rule_id, \"deny-jquery\");\n}\n\n#[tokio::test]\nasync fn test_layer_hierarchy_order() {\n    let mut engine = GovernanceEngine::new();\n\n    let company_policy = Policy {\n        id: \"layer-test\".to_string(),\n        name: \"Company Layer Test\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![PolicyRule {\n            id: \"layer-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustMatch,\n            value: serde_json::json!(\"company\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Must contain company\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    let org_policy = Policy {\n        id: \"layer-test\".to_string(),\n        name: \"Org Layer Test\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Org,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![PolicyRule {\n            id: \"layer-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustMatch,\n            value: serde_json::json!(\"org\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Must contain org\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(company_policy);\n    engine.add_policy(org_policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"content\".to_string(), serde_json::json!(\"org content here\"));\n\n    let result = engine.validate(KnowledgeLayer::Org, \u0026context);\n    assert!(\n        result.is_valid,\n        \"Org policy should override company for Org layer validation\"\n    );\n\n    let mut context_company = HashMap::new();\n    context_company.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"company content here\"),\n    );\n    let result_company = engine.validate(KnowledgeLayer::Company, \u0026context_company);\n    assert!(\n        result_company.is_valid,\n        \"Company layer validation should only use company policies\"\n    );\n}\n\n#[tokio::test]\nasync fn test_team_layer_inheritance() {\n    let mut engine = GovernanceEngine::new();\n\n    let company_policy = Policy {\n        id: \"company-rule\".to_string(),\n        name: \"Company Rule\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"company-check\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustNotMatch,\n            value: serde_json::json!(\"FORBIDDEN\"),\n            severity: ConstraintSeverity::Block,\n            message: \"FORBIDDEN not allowed\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    let team_policy = Policy {\n        id: \"team-rule\".to_string(),\n        name: \"Team Rule\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Team,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"team-check\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustMatch,\n            value: serde_json::json!(\"team_approved\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Team approval marker needed\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(company_policy);\n    engine.add_policy(team_policy);\n\n    let mut valid_context = HashMap::new();\n    valid_context.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"team_approved content\"),\n    );\n    let result = engine.validate(KnowledgeLayer::Team, \u0026valid_context);\n    assert!(\n        result.is_valid,\n        \"Content meeting both company and team requirements should pass\"\n    );\n\n    let mut forbidden_context = HashMap::new();\n    forbidden_context.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"team_approved FORBIDDEN content\"),\n    );\n    let result = engine.validate(KnowledgeLayer::Team, \u0026forbidden_context);\n    assert!(\n        !result.is_valid,\n        \"Company mandatory policy should still apply at team layer\"\n    );\n\n    let mut missing_marker_context = HashMap::new();\n    missing_marker_context.insert(\"content\".to_string(), serde_json::json!(\"no marker here\"));\n    let result = engine.validate(KnowledgeLayer::Team, \u0026missing_marker_context);\n    assert!(\n        !result.is_valid,\n        \"Team policy should be enforced at team layer\"\n    );\n}\n\n#[tokio::test]\nasync fn test_merge_strategy_merge_accumulates_rules() {\n    let mut engine = GovernanceEngine::new();\n\n    let company_policy = Policy {\n        id: \"multi-rule\".to_string(),\n        name: \"Multi Rule\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"rule-1\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustNotMatch,\n            value: serde_json::json!(\"RULE1_VIOLATION\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Rule 1 violated\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    let org_policy = Policy {\n        id: \"multi-rule\".to_string(),\n        name: \"Multi Rule Org\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Org,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"rule-2\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustNotMatch,\n            value: serde_json::json!(\"RULE2_VIOLATION\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Rule 2 violated\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(company_policy);\n    engine.add_policy(org_policy);\n\n    let mut context_rule1 = HashMap::new();\n    context_rule1.insert(\"content\".to_string(), serde_json::json!(\"RULE1_VIOLATION\"));\n    let result = engine.validate(KnowledgeLayer::Org, \u0026context_rule1);\n    assert!(\n        !result.is_valid,\n        \"Rule 1 from company should still apply after merge\"\n    );\n\n    let mut context_rule2 = HashMap::new();\n    context_rule2.insert(\"content\".to_string(), serde_json::json!(\"RULE2_VIOLATION\"));\n    let result = engine.validate(KnowledgeLayer::Org, \u0026context_rule2);\n    assert!(\n        !result.is_valid,\n        \"Rule 2 from org should be added via merge\"\n    );\n\n    let mut context_both = HashMap::new();\n    context_both.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"RULE1_VIOLATION RULE2_VIOLATION\"),\n    );\n    let result = engine.validate(KnowledgeLayer::Org, \u0026context_both);\n    assert!(!result.is_valid);\n    assert!(\n        result.violations.len() \u003e= 1,\n        \"Both rules should be evaluated\"\n    );\n}\n\n#[tokio::test]\nasync fn test_severity_levels_in_hierarchy() {\n    let mut engine = GovernanceEngine::new();\n\n    let block_policy = Policy {\n        id: \"severity-test\".to_string(),\n        name: \"Severity Test\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![\n            PolicyRule {\n                id: \"block-rule\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Code,\n                operator: ConstraintOperator::MustNotMatch,\n                value: serde_json::json!(\"CRITICAL_ERROR\"),\n                severity: ConstraintSeverity::Block,\n                message: \"Critical error found\".to_string(),\n            },\n            PolicyRule {\n                id: \"warn-rule\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Code,\n                operator: ConstraintOperator::MustNotMatch,\n                value: serde_json::json!(\"MINOR_ISSUE\"),\n                severity: ConstraintSeverity::Warn,\n                message: \"Minor issue found\".to_string(),\n            },\n            PolicyRule {\n                id: \"info-rule\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Code,\n                operator: ConstraintOperator::MustNotMatch,\n                value: serde_json::json!(\"NOTE_THIS\"),\n                severity: ConstraintSeverity::Info,\n                message: \"Note for review\".to_string(),\n            },\n        ],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(block_policy);\n\n    let mut context_block = HashMap::new();\n    context_block.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"CRITICAL_ERROR here\"),\n    );\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context_block);\n    assert!(!result.is_valid);\n    assert_eq!(result.violations[0].severity, ConstraintSeverity::Block);\n\n    let mut context_warn = HashMap::new();\n    context_warn.insert(\"content\".to_string(), serde_json::json!(\"MINOR_ISSUE here\"));\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context_warn);\n    assert!(!result.is_valid);\n    assert_eq!(result.violations[0].severity, ConstraintSeverity::Warn);\n\n    let mut context_info = HashMap::new();\n    context_info.insert(\"content\".to_string(), serde_json::json!(\"NOTE_THIS here\"));\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context_info);\n    assert!(!result.is_valid);\n    assert_eq!(result.violations[0].severity, ConstraintSeverity::Info);\n}\n\n#[tokio::test]\nasync fn test_empty_policy_layers_are_skipped() {\n    let mut engine = GovernanceEngine::new();\n\n    let project_policy = Policy {\n        id: \"project-only\".to_string(),\n        name: \"Project Only\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Project,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"project-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustMatch,\n            value: serde_json::json!(\"project_marker\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Project marker needed\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(project_policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"content\".to_string(), serde_json::json!(\"no marker\"));\n    let result = engine.validate(KnowledgeLayer::Org, \u0026context);\n    assert!(\n        result.is_valid,\n        \"Project policy should not apply at Org layer\"\n    );\n\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context);\n    assert!(\n        !result.is_valid,\n        \"Project policy should apply at Project layer\"\n    );\n}\n\n#[tokio::test]\nasync fn test_multiple_policies_same_layer() {\n    let mut engine = GovernanceEngine::new();\n\n    let policy_a = Policy {\n        id: \"policy-a\".to_string(),\n        name: \"Policy A\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"rule-a\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustNotMatch,\n            value: serde_json::json!(\"VIOLATION_A\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Violation A\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    let policy_b = Policy {\n        id: \"policy-b\".to_string(),\n        name: \"Policy B\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"rule-b\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustNotMatch,\n            value: serde_json::json!(\"VIOLATION_B\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Violation B\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(policy_a);\n    engine.add_policy(policy_b);\n\n    let mut context = HashMap::new();\n    context.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"VIOLATION_A VIOLATION_B\"),\n    );\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context);\n    assert!(!result.is_valid);\n    assert_eq!(\n        result.violations.len(),\n        2,\n        \"Both policies should generate violations\"\n    );\n}\n\n#[tokio::test]\nasync fn test_dependency_constraint_inheritance() {\n    let mut engine = GovernanceEngine::new();\n\n    let company_policy = Policy {\n        id: \"dependency-policy\".to_string(),\n        name: \"Dependency Policy\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"require-security-lib\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"security-lib\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Security library required\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    let org_policy = Policy {\n        id: \"dependency-policy\".to_string(),\n        name: \"Org Dependency Policy\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Org,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"require-logging-lib\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"logging-lib\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Logging library recommended\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(company_policy);\n    engine.add_policy(org_policy);\n\n    let mut context_missing_security = HashMap::new();\n    context_missing_security.insert(\n        \"dependencies\".to_string(),\n        serde_json::json!([\"logging-lib\", \"other-lib\"]),\n    );\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context_missing_security);\n    assert!(\n        !result.is_valid,\n        \"Missing mandatory security-lib should fail\"\n    );\n\n    let mut context_has_both = HashMap::new();\n    context_has_both.insert(\n        \"dependencies\".to_string(),\n        serde_json::json!([\"security-lib\", \"logging-lib\"]),\n    );\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context_has_both);\n    assert!(result.is_valid, \"Having both libs should pass\");\n}\n\n#[tokio::test]\nasync fn test_config_constraint_target() {\n    let mut engine = GovernanceEngine::new();\n\n    // Test MustExist: config key must exist in context\n    let config_policy = Policy {\n        id: \"config-policy\".to_string(),\n        name: \"Config Policy\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"require-config\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Config,\n            operator: ConstraintOperator::MustExist,\n            value: serde_json::json!(null), // MustExist checks key presence, value not used\n            severity: ConstraintSeverity::Block,\n            message: \"Config section required\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(config_policy);\n\n    // Context without \"config\" key should fail\n    let context_without_config: HashMap\u003cString, serde_json::Value\u003e = HashMap::new();\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context_without_config);\n    assert!(!result.is_valid, \"Missing config key should fail\");\n\n    // Context with \"config\" key should pass\n    let mut context_with_config = HashMap::new();\n    context_with_config.insert(\"config\".to_string(), serde_json::json!({\"any\": \"value\"}));\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context_with_config);\n    assert!(result.is_valid, \"Config key present should pass\");\n\n    // Test MustNotExist: config key must NOT exist\n    let mut engine2 = GovernanceEngine::new();\n    let no_config_policy = Policy {\n        id: \"no-config-policy\".to_string(),\n        name: \"No Config Policy\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"forbid-config\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Config,\n            operator: ConstraintOperator::MustNotExist,\n            value: serde_json::json!(null),\n            severity: ConstraintSeverity::Block,\n            message: \"Config section forbidden\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine2.add_policy(no_config_policy);\n\n    // Context with \"config\" key should fail for MustNotExist\n    let result = engine2.validate(KnowledgeLayer::Project, \u0026context_with_config);\n    assert!(\n        !result.is_valid,\n        \"Config key present should fail with MustNotExist\"\n    );\n\n    // Context without \"config\" key should pass for MustNotExist\n    let result = engine2.validate(KnowledgeLayer::Project, \u0026context_without_config);\n    assert!(\n        result.is_valid,\n        \"Missing config key should pass with MustNotExist\"\n    );\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","tests","scheduler_test.rs"],"content":"//! Tests for the GovernanceScheduler.\n//!\n//! The scheduler runs background jobs for governance checks.\n//! These tests verify the individual job methods work correctly.\n\nuse async_trait::async_trait;\nuse config::config::DeploymentConfig;\nuse knowledge::governance::GovernanceEngine;\nuse knowledge::scheduler::GovernanceScheduler;\nuse mk_core::traits::{KnowledgeRepository, StorageBackend};\nuse mk_core::types::{\n    DriftResult, GovernanceEvent, KnowledgeEntry, KnowledgeLayer, KnowledgeStatus, KnowledgeType,\n    OrganizationalUnit, Policy, Role, TenantContext, TenantId, UnitType, UserId,\n};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse std::sync::atomic::{AtomicUsize, Ordering};\nuse std::time::Duration;\nuse tokio::sync::RwLock;\n\n// Mock storage backend for testing\nstruct MockStorage {\n    units: RwLock\u003cVec\u003cOrganizationalUnit\u003e\u003e,\n    drift_results: RwLock\u003cVec\u003cDriftResult\u003e\u003e,\n    job_records: Arc\u003cAtomicUsize\u003e,\n}\n\nimpl MockStorage {\n    fn new() -\u003e Self {\n        Self {\n            units: RwLock::new(Vec::new()),\n            drift_results: RwLock::new(Vec::new()),\n            job_records: Arc::new(AtomicUsize::new(0)),\n        }\n    }\n\n    fn with_units(units: Vec\u003cOrganizationalUnit\u003e) -\u003e Self {\n        Self {\n            units: RwLock::new(units),\n            drift_results: RwLock::new(Vec::new()),\n            job_records: Arc::new(AtomicUsize::new(0)),\n        }\n    }\n}\n\n#[derive(Debug)]\nstruct MockStorageError(String);\n\nimpl std::fmt::Display for MockStorageError {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        write!(f, \"{}\", self.0)\n    }\n}\n\nimpl std::error::Error for MockStorageError {}\n\n#[async_trait]\nimpl StorageBackend for MockStorage {\n    type Error = storage::postgres::PostgresError;\n\n    async fn store(\n        \u0026self,\n        _ctx: TenantContext,\n        _key: \u0026str,\n        _value: \u0026[u8],\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn retrieve(\n        \u0026self,\n        _ctx: TenantContext,\n        _key: \u0026str,\n    ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n\n    async fn delete(\u0026self, _ctx: TenantContext, _key: \u0026str) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn exists(\u0026self, _ctx: TenantContext, _key: \u0026str) -\u003e Result\u003cbool, Self::Error\u003e {\n        Ok(false)\n    }\n\n    async fn get_ancestors(\n        \u0026self,\n        _ctx: TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn get_descendants(\n        \u0026self,\n        _ctx: TenantContext,\n        unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, Self::Error\u003e {\n        let units = self.units.read().await;\n        let children: Vec\u003c_\u003e = units\n            .iter()\n            .filter(|u| u.parent_id.as_deref() == Some(unit_id))\n            .cloned()\n            .collect();\n        Ok(children)\n    }\n\n    async fn get_unit_policies(\n        \u0026self,\n        _ctx: TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cPolicy\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn create_unit(\u0026self, _unit: \u0026OrganizationalUnit) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn add_unit_policy(\n        \u0026self,\n        _ctx: \u0026TenantContext,\n        _unit_id: \u0026str,\n        _policy: \u0026Policy,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn assign_role(\n        \u0026self,\n        _user_id: \u0026UserId,\n        _tenant_id: \u0026TenantId,\n        _unit_id: \u0026str,\n        _role: Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn remove_role(\n        \u0026self,\n        _user_id: \u0026UserId,\n        _tenant_id: \u0026TenantId,\n        _unit_id: \u0026str,\n        _role: Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn store_drift_result(\u0026self, result: DriftResult) -\u003e Result\u003c(), Self::Error\u003e {\n        self.drift_results.write().await.push(result);\n        Ok(())\n    }\n\n    async fn get_latest_drift_result(\n        \u0026self,\n        _ctx: TenantContext,\n        project_id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cDriftResult\u003e, Self::Error\u003e {\n        let results = self.drift_results.read().await;\n        let result = results.iter().find(|r| r.project_id == project_id).cloned();\n        Ok(result)\n    }\n\n    async fn list_all_units(\u0026self) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(self.units.read().await.clone())\n    }\n\n    async fn record_job_status(\n        \u0026self,\n        _job_name: \u0026str,\n        _tenant_id: \u0026str,\n        _status: \u0026str,\n        _message: Option\u003c\u0026str\u003e,\n        _started_at: i64,\n        _finished_at: Option\u003ci64\u003e,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        self.job_records.fetch_add(1, Ordering::SeqCst);\n        Ok(())\n    }\n\n    async fn get_governance_events(\n        \u0026self,\n        _ctx: TenantContext,\n        _since_timestamp: i64,\n        _limit: usize,\n    ) -\u003e Result\u003cVec\u003cGovernanceEvent\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n}\n\n// Mock repository for testing\nstruct MockRepository {\n    entries: RwLock\u003cVec\u003cKnowledgeEntry\u003e\u003e,\n}\n\nimpl MockRepository {\n    fn new() -\u003e Self {\n        Self {\n            entries: RwLock::new(Vec::new()),\n        }\n    }\n\n    fn with_entries(entries: Vec\u003cKnowledgeEntry\u003e) -\u003e Self {\n        Self {\n            entries: RwLock::new(entries),\n        }\n    }\n}\n\n#[async_trait]\nimpl KnowledgeRepository for MockRepository {\n    type Error = knowledge::repository::RepositoryError;\n\n    async fn get(\n        \u0026self,\n        _ctx: TenantContext,\n        _layer: KnowledgeLayer,\n        path: \u0026str,\n    ) -\u003e Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        let entries = self.entries.read().await;\n        Ok(entries.iter().find(|e| e.path == path).cloned())\n    }\n\n    async fn store(\n        \u0026self,\n        _ctx: TenantContext,\n        entry: KnowledgeEntry,\n        _message: \u0026str,\n    ) -\u003e Result\u003cString, Self::Error\u003e {\n        self.entries.write().await.push(entry);\n        Ok(\"hash123\".to_string())\n    }\n\n    async fn list(\n        \u0026self,\n        _ctx: TenantContext,\n        layer: KnowledgeLayer,\n        _prefix: \u0026str,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        let entries = self.entries.read().await;\n        Ok(entries\n            .iter()\n            .filter(|e| e.layer == layer)\n            .cloned()\n            .collect())\n    }\n\n    async fn delete(\n        \u0026self,\n        _ctx: TenantContext,\n        _layer: KnowledgeLayer,\n        _path: \u0026str,\n        _message: \u0026str,\n    ) -\u003e Result\u003cString, Self::Error\u003e {\n        Ok(\"hash123\".to_string())\n    }\n\n    async fn get_head_commit(\u0026self, _ctx: TenantContext) -\u003e Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n        Ok(Some(\"head123\".to_string()))\n    }\n\n    async fn get_affected_items(\n        \u0026self,\n        _ctx: TenantContext,\n        _since_commit: \u0026str,\n    ) -\u003e Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn search(\n        \u0026self,\n        _ctx: TenantContext,\n        _query: \u0026str,\n        _layers: Vec\u003cKnowledgeLayer\u003e,\n        _limit: usize,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n        None\n    }\n}\n\nfn create_test_tenant() -\u003e TenantId {\n    TenantId::new(\"test-tenant\".to_string()).unwrap()\n}\n\nfn create_test_project_unit(id: \u0026str, tenant_id: TenantId) -\u003e OrganizationalUnit {\n    OrganizationalUnit {\n        id: id.to_string(),\n        name: format!(\"Project {}\", id),\n        unit_type: UnitType::Project,\n        tenant_id,\n        parent_id: Some(\"org-1\".to_string()),\n        metadata: HashMap::new(),\n        created_at: chrono::Utc::now().timestamp(),\n        updated_at: chrono::Utc::now().timestamp(),\n    }\n}\n\nfn create_test_org_unit(id: \u0026str, tenant_id: TenantId) -\u003e OrganizationalUnit {\n    OrganizationalUnit {\n        id: id.to_string(),\n        name: format!(\"Org {}\", id),\n        unit_type: UnitType::Organization,\n        tenant_id,\n        parent_id: None,\n        metadata: HashMap::new(),\n        created_at: chrono::Utc::now().timestamp(),\n        updated_at: chrono::Utc::now().timestamp(),\n    }\n}\n\n#[tokio::test]\nasync fn test_scheduler_new() {\n    let engine = Arc::new(GovernanceEngine::new());\n    let repo: Arc\u003cdyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e\u003e =\n        Arc::new(MockRepository::new());\n    let config = DeploymentConfig::default();\n\n    let _scheduler = GovernanceScheduler::new(\n        engine,\n        repo,\n        config,\n        Duration::from_secs(300),\n        Duration::from_secs(3600),\n        Duration::from_secs(86400),\n    );\n\n    // Just verify it constructs without panicking\n    assert!(true);\n}\n\n#[tokio::test]\nasync fn test_scheduler_remote_mode_does_not_run() {\n    let storage = Arc::new(MockStorage::new());\n    let engine = Arc::new(GovernanceEngine::new().with_storage(storage.clone()));\n    let repo: Arc\u003cdyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e\u003e =\n        Arc::new(MockRepository::new());\n\n    let mut config = DeploymentConfig::default();\n    config.mode = \"remote\".to_string();\n\n    let scheduler = GovernanceScheduler::new(\n        engine,\n        repo,\n        config,\n        Duration::from_millis(10),\n        Duration::from_millis(10),\n        Duration::from_millis(10),\n    );\n\n    // Run in background with timeout\n    let handle = tokio::spawn(async move {\n        scheduler.start().await;\n    });\n\n    // Give it a moment to check mode and return\n    tokio::time::sleep(Duration::from_millis(50)).await;\n\n    // In remote mode, start() should return immediately\n    // The handle should be completed\n    assert!(!handle.is_finished() || storage.job_records.load(Ordering::SeqCst) == 0);\n    handle.abort();\n}\n\n#[tokio::test]\nasync fn test_scheduler_with_storage_configured() {\n    let tenant_id = create_test_tenant();\n    let units = vec![\n        create_test_org_unit(\"org-1\", tenant_id.clone()),\n        create_test_project_unit(\"proj-1\", tenant_id.clone()),\n        create_test_project_unit(\"proj-2\", tenant_id.clone()),\n    ];\n\n    let storage = Arc::new(MockStorage::with_units(units));\n    let engine = Arc::new(GovernanceEngine::new().with_storage(storage.clone()));\n    let repo: Arc\u003cdyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e\u003e =\n        Arc::new(MockRepository::new());\n\n    let config = DeploymentConfig::default();\n\n    let _scheduler = GovernanceScheduler::new(\n        engine,\n        repo,\n        config,\n        Duration::from_secs(300),\n        Duration::from_secs(3600),\n        Duration::from_secs(86400),\n    );\n\n    // Verify storage has units\n    let all_units = storage.list_all_units().await.unwrap();\n    assert_eq!(all_units.len(), 3);\n}\n\n#[tokio::test]\nasync fn test_storage_list_all_units() {\n    let tenant_id = create_test_tenant();\n    let units = vec![\n        create_test_org_unit(\"org-1\", tenant_id.clone()),\n        create_test_project_unit(\"proj-1\", tenant_id.clone()),\n    ];\n\n    let storage = MockStorage::with_units(units);\n    let all_units = storage.list_all_units().await.unwrap();\n\n    assert_eq!(all_units.len(), 2);\n    assert!(all_units.iter().any(|u| u.id == \"org-1\"));\n    assert!(all_units.iter().any(|u| u.id == \"proj-1\"));\n}\n\n#[tokio::test]\nasync fn test_storage_get_descendants() {\n    let tenant_id = create_test_tenant();\n    let units = vec![\n        create_test_org_unit(\"org-1\", tenant_id.clone()),\n        create_test_project_unit(\"proj-1\", tenant_id.clone()),\n        create_test_project_unit(\"proj-2\", tenant_id.clone()),\n    ];\n\n    let storage = MockStorage::with_units(units);\n    let ctx = TenantContext::new(tenant_id, UserId::default());\n\n    let descendants = storage.get_descendants(ctx, \"org-1\").await.unwrap();\n    assert_eq!(descendants.len(), 2);\n}\n\n#[tokio::test]\nasync fn test_storage_store_drift_result() {\n    let storage = MockStorage::new();\n\n    let result = DriftResult {\n        project_id: \"proj-1\".to_string(),\n        tenant_id: create_test_tenant(),\n        drift_score: 0.5,\n        violations: vec![],\n        timestamp: chrono::Utc::now().timestamp(),\n    };\n\n    storage.store_drift_result(result).await.unwrap();\n\n    let results = storage.drift_results.read().await;\n    assert_eq!(results.len(), 1);\n    assert_eq!(results[0].project_id, \"proj-1\");\n}\n\n#[tokio::test]\nasync fn test_storage_get_latest_drift_result() {\n    let storage = MockStorage::new();\n    let tenant_id = create_test_tenant();\n\n    let result1 = DriftResult {\n        project_id: \"proj-1\".to_string(),\n        tenant_id: tenant_id.clone(),\n        drift_score: 0.3,\n        violations: vec![],\n        timestamp: 1000,\n    };\n\n    let result2 = DriftResult {\n        project_id: \"proj-2\".to_string(),\n        tenant_id: tenant_id.clone(),\n        drift_score: 0.7,\n        violations: vec![],\n        timestamp: 2000,\n    };\n\n    storage.store_drift_result(result1).await.unwrap();\n    storage.store_drift_result(result2).await.unwrap();\n\n    let ctx = TenantContext::new(tenant_id, UserId::default());\n    let latest = storage\n        .get_latest_drift_result(ctx.clone(), \"proj-1\")\n        .await\n        .unwrap();\n    assert!(latest.is_some());\n    assert_eq!(latest.unwrap().drift_score, 0.3);\n\n    let latest2 = storage\n        .get_latest_drift_result(ctx, \"proj-2\")\n        .await\n        .unwrap();\n    assert!(latest2.is_some());\n    assert_eq!(latest2.unwrap().drift_score, 0.7);\n}\n\n#[tokio::test]\nasync fn test_storage_record_job_status() {\n    let storage = MockStorage::new();\n\n    storage\n        .record_job_status(\n            \"test_job\",\n            \"tenant-1\",\n            \"running\",\n            None,\n            chrono::Utc::now().timestamp(),\n            None,\n        )\n        .await\n        .unwrap();\n\n    assert_eq!(storage.job_records.load(Ordering::SeqCst), 1);\n\n    storage\n        .record_job_status(\n            \"test_job\",\n            \"tenant-1\",\n            \"completed\",\n            None,\n            chrono::Utc::now().timestamp(),\n            Some(chrono::Utc::now().timestamp()),\n        )\n        .await\n        .unwrap();\n\n    assert_eq!(storage.job_records.load(Ordering::SeqCst), 2);\n}\n\n#[tokio::test]\nasync fn test_mock_repository_list_by_layer() {\n    let entries = vec![\n        KnowledgeEntry {\n            path: \"project/spec.md\".to_string(),\n            content: \"Project spec\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            metadata: HashMap::new(),\n            status: KnowledgeStatus::Accepted,\n            commit_hash: None,\n            author: None,\n            updated_at: chrono::Utc::now().timestamp(),\n        },\n        KnowledgeEntry {\n            path: \"company/policy.md\".to_string(),\n            content: \"Company policy\".to_string(),\n            layer: KnowledgeLayer::Company,\n            kind: KnowledgeType::Policy,\n            metadata: HashMap::new(),\n            status: KnowledgeStatus::Accepted,\n            commit_hash: None,\n            author: None,\n            updated_at: chrono::Utc::now().timestamp(),\n        },\n    ];\n\n    let repo = MockRepository::with_entries(entries);\n    let ctx = TenantContext::new(create_test_tenant(), UserId::default());\n\n    let project_entries = repo\n        .list(ctx.clone(), KnowledgeLayer::Project, \"\")\n        .await\n        .unwrap();\n    assert_eq!(project_entries.len(), 1);\n    assert_eq!(project_entries[0].path, \"project/spec.md\");\n\n    let company_entries = repo.list(ctx, KnowledgeLayer::Company, \"\").await.unwrap();\n    assert_eq!(company_entries.len(), 1);\n    assert_eq!(company_entries[0].path, \"company/policy.md\");\n}\n\n#[tokio::test]\nasync fn test_deployment_config_modes() {\n    let mut config = DeploymentConfig::default();\n\n    // Default is local\n    assert_eq!(config.mode, \"local\");\n\n    // Test remote mode\n    config.mode = \"remote\".to_string();\n    assert_eq!(config.mode, \"remote\");\n\n    // Test hybrid mode\n    config.mode = \"hybrid\".to_string();\n    assert_eq!(config.mode, \"hybrid\");\n}\n\n#[tokio::test]\nasync fn test_scheduler_intervals() {\n    let engine = Arc::new(GovernanceEngine::new());\n    let repo: Arc\u003cdyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e\u003e =\n        Arc::new(MockRepository::new());\n    let config = DeploymentConfig::default();\n\n    // Test with various intervals\n    let _scheduler1 = GovernanceScheduler::new(\n        engine.clone(),\n        repo.clone(),\n        config.clone(),\n        Duration::from_secs(60),\n        Duration::from_secs(3600),\n        Duration::from_secs(604800), // 1 week\n    );\n\n    let _scheduler2 = GovernanceScheduler::new(\n        engine.clone(),\n        repo.clone(),\n        config.clone(),\n        Duration::from_millis(100),\n        Duration::from_millis(500),\n        Duration::from_millis(1000),\n    );\n\n    // Just verify construction succeeds with different intervals\n    assert!(true);\n}\n","traces":[{"line":29,"address":[],"length":0,"stats":{"Line":4}},{"line":31,"address":[],"length":0,"stats":{"Line":12}},{"line":32,"address":[],"length":0,"stats":{"Line":12}},{"line":33,"address":[],"length":0,"stats":{"Line":4}},{"line":37,"address":[],"length":0,"stats":{"Line":3}},{"line":39,"address":[],"length":0,"stats":{"Line":9}},{"line":40,"address":[],"length":0,"stats":{"Line":9}},{"line":41,"address":[],"length":0,"stats":{"Line":3}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":6}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":3}},{"line":160,"address":[],"length":0,"stats":{"Line":6}},{"line":164,"address":[],"length":0,"stats":{"Line":2}},{"line":197,"address":[],"length":0,"stats":{"Line":4}},{"line":199,"address":[],"length":0,"stats":{"Line":4}},{"line":203,"address":[],"length":0,"stats":{"Line":1}},{"line":205,"address":[],"length":0,"stats":{"Line":1}},{"line":221,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":8}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":6}},{"line":286,"address":[],"length":0,"stats":{"Line":24}},{"line":289,"address":[],"length":0,"stats":{"Line":5}},{"line":291,"address":[],"length":0,"stats":{"Line":15}},{"line":292,"address":[],"length":0,"stats":{"Line":15}},{"line":295,"address":[],"length":0,"stats":{"Line":10}},{"line":296,"address":[],"length":0,"stats":{"Line":10}},{"line":297,"address":[],"length":0,"stats":{"Line":15}},{"line":298,"address":[],"length":0,"stats":{"Line":5}},{"line":302,"address":[],"length":0,"stats":{"Line":3}},{"line":304,"address":[],"length":0,"stats":{"Line":9}},{"line":305,"address":[],"length":0,"stats":{"Line":9}},{"line":309,"address":[],"length":0,"stats":{"Line":6}},{"line":310,"address":[],"length":0,"stats":{"Line":9}},{"line":311,"address":[],"length":0,"stats":{"Line":3}}],"covered":32,"coverable":41},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","backend.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","bridge.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","config.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","ecosystem.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","embedding","mock.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::EmbeddingService;\n\npub struct MockEmbeddingService {\n    dimension: usize\n}\n\nimpl MockEmbeddingService {\n    pub fn new(dimension: usize) -\u003e Self {\n        Self { dimension }\n    }\n\n    fn generate_mock_embedding(text: \u0026str) -\u003e Vec\u003cf32\u003e {\n        let mut embedding = vec![0.0; 384];\n        let text_lower = text.to_lowercase();\n\n        if text_lower.contains(\"rust\") {\n            embedding[0] = 0.8;\n            embedding[1] = 0.6;\n        }\n        if text_lower.contains(\"typescript\") || text_lower.contains(\"javascript\") {\n            embedding[2] = 0.7;\n            embedding[3] = 0.5;\n        }\n        if text_lower.contains(\"python\") {\n            embedding[4] = 0.9;\n            embedding[5] = 0.4;\n        }\n        if text_lower.contains(\"database\") {\n            embedding[6] = 0.6;\n            embedding[7] = 0.7;\n        }\n        if text_lower.contains(\"api\") {\n            embedding[8] = 0.5;\n            embedding[9] = 0.8;\n        }\n\n        let length_factor = (text.len() as f32).min(1000.0) / 1000.0;\n        embedding[10] = length_factor;\n\n        embedding\n    }\n}\n\n#[async_trait]\nimpl EmbeddingService for MockEmbeddingService {\n    type Error = Box\u003cdyn std::error::Error + Send + Sync\u003e;\n\n    async fn embed(\u0026self, text: \u0026str) -\u003e Result\u003cVec\u003cf32\u003e, Self::Error\u003e {\n        Ok(Self::generate_mock_embedding(text))\n    }\n\n    fn dimension(\u0026self) -\u003e usize {\n        self.dimension\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_mock_embedding_service() {\n        let service = MockEmbeddingService::new(384);\n\n        let embedding1 = service.embed(\"Rust programming language\").await.unwrap();\n        assert_eq!(embedding1.len(), 384);\n        assert!(embedding1[0] \u003e 0.0);\n        assert!(embedding1[1] \u003e 0.0);\n\n        let embedding2 = service.embed(\"Python data science\").await.unwrap();\n        assert_eq!(embedding2.len(), 384);\n        assert!(embedding2[4] \u003e 0.0);\n        assert!(embedding2[5] \u003e 0.0);\n\n        assert_ne!(embedding1, embedding2);\n    }\n\n    #[tokio::test]\n    async fn test_mock_embedding_service_batch() {\n        let service = MockEmbeddingService::new(384);\n\n        let texts = vec![\n            \"Rust programming\".to_string(),\n            \"Python scripting\".to_string(),\n            \"Database management\".to_string(),\n        ];\n\n        let embeddings = service.embed_batch(\u0026texts).await.unwrap();\n        assert_eq!(embeddings.len(), 3);\n        for embedding in embeddings {\n            assert_eq!(embedding.len(), 384);\n        }\n    }\n}\n","traces":[{"line":9,"address":[],"length":0,"stats":{"Line":4}},{"line":13,"address":[],"length":0,"stats":{"Line":8}},{"line":14,"address":[],"length":0,"stats":{"Line":16}},{"line":15,"address":[],"length":0,"stats":{"Line":24}},{"line":17,"address":[],"length":0,"stats":{"Line":12}},{"line":18,"address":[],"length":0,"stats":{"Line":8}},{"line":19,"address":[],"length":0,"stats":{"Line":4}},{"line":21,"address":[],"length":0,"stats":{"Line":16}},{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":23,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":10}},{"line":26,"address":[],"length":0,"stats":{"Line":4}},{"line":27,"address":[],"length":0,"stats":{"Line":2}},{"line":29,"address":[],"length":0,"stats":{"Line":9}},{"line":30,"address":[],"length":0,"stats":{"Line":2}},{"line":31,"address":[],"length":0,"stats":{"Line":1}},{"line":33,"address":[],"length":0,"stats":{"Line":8}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[],"length":0,"stats":{"Line":16}},{"line":39,"address":[],"length":0,"stats":{"Line":8}},{"line":41,"address":[],"length":0,"stats":{"Line":8}},{"line":49,"address":[],"length":0,"stats":{"Line":8}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}}],"covered":19,"coverable":25},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","embedding","mod.rs"],"content":"pub mod mock;\npub mod openai;\n\npub use mock::MockEmbeddingService;\npub use openai::OpenAIEmbeddingService;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","embedding","openai.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::EmbeddingService;\nuse std::sync::Arc;\nuse storage::redis::RedisStorage;\nuse tokio::sync::RwLock;\n\npub struct OpenAIEmbeddingService {\n    client: async_openai::Client\u003casync_openai::config::OpenAIConfig\u003e,\n    model: String,\n    dimension: usize,\n    cache: Arc\u003cRwLock\u003clru::LruCache\u003cString, Vec\u003cf32\u003e\u003e\u003e\u003e,\n    redis: Option\u003cArc\u003cRwLock\u003cRedisStorage\u003e\u003e\u003e\n}\n\nimpl OpenAIEmbeddingService {\n    pub fn new(api_key: String, model: \u0026str) -\u003e Self {\n        let config = async_openai::config::OpenAIConfig::new().with_api_key(api_key);\n        let client = async_openai::Client::with_config(config);\n\n        let dimension = match model {\n            \"text-embedding-ada-002\" =\u003e 1536,\n            \"text-embedding-3-small\" =\u003e 1536,\n            \"text-embedding-3-large\" =\u003e 3072,\n            _ =\u003e 1536\n        };\n\n        Self {\n            client,\n            model: model.to_string(),\n            dimension,\n            cache: Arc::new(RwLock::new(lru::LruCache::new(\n                std::num::NonZeroUsize::new(1000).unwrap()\n            ))),\n            redis: None\n        }\n    }\n\n    pub fn with_redis(mut self, redis: Arc\u003cRwLock\u003cRedisStorage\u003e\u003e) -\u003e Self {\n        self.redis = Some(redis);\n        self\n    }\n\n    pub fn with_cache_size(api_key: String, model: \u0026str, cache_size: usize) -\u003e Self {\n        let config = async_openai::config::OpenAIConfig::new().with_api_key(api_key);\n        let client = async_openai::Client::with_config(config);\n\n        let dimension = match model {\n            \"text-embedding-ada-002\" =\u003e 1536,\n            \"text-embedding-3-small\" =\u003e 1536,\n            \"text-embedding-3-large\" =\u003e 3072,\n            _ =\u003e 1536\n        };\n\n        Self {\n            client,\n            model: model.to_string(),\n            dimension,\n            cache: Arc::new(RwLock::new(lru::LruCache::new(\n                std::num::NonZeroUsize::new(cache_size).unwrap()\n            ))),\n            redis: None\n        }\n    }\n\n    pub fn with_default_model(api_key: String) -\u003e Self {\n        Self::new(api_key, \"text-embedding-ada-002\")\n    }\n}\n\n#[async_trait]\nimpl EmbeddingService for OpenAIEmbeddingService {\n    type Error = Box\u003cdyn std::error::Error + Send + Sync\u003e;\n\n    async fn embed(\u0026self, text: \u0026str) -\u003e Result\u003cVec\u003cf32\u003e, Self::Error\u003e {\n        {\n            let mut cache = self.cache.write().await;\n            if let Some(cached) = cache.get(text) {\n                return Ok(cached.clone());\n            }\n        }\n\n        if let Some(redis) = \u0026self.redis {\n            let redis = redis.write().await;\n            let key = format!(\"emb:{}:{}\", self.model, text);\n            if let Ok(Some(cached_json)) = redis.get(\u0026key).await {\n                if let Ok(embedding) = serde_json::from_str::\u003cVec\u003cf32\u003e\u003e(\u0026cached_json) {\n                    let mut cache = self.cache.write().await;\n                    cache.put(text.to_string(), embedding.clone());\n                    return Ok(embedding);\n                }\n            }\n        }\n\n        let request = async_openai::types::CreateEmbeddingRequestArgs::default()\n            .model(\u0026self.model)\n            .input(text)\n            .build()?;\n\n        let response = self.client.embeddings().create(request).await?;\n\n        let embedding = response\n            .data\n            .first()\n            .ok_or(\"No embedding returned\")?\n            .embedding\n            .clone();\n\n        {\n            let mut cache = self.cache.write().await;\n            cache.put(text.to_string(), embedding.clone());\n        }\n\n        if let Some(redis) = \u0026self.redis {\n            let redis = redis.write().await;\n            let key = format!(\"emb:{}:{}\", self.model, text);\n            if let Ok(json) = serde_json::to_string(\u0026embedding) {\n                let _ = redis.set(\u0026key, \u0026json, Some(86400)).await;\n            }\n        }\n\n        Ok(embedding)\n    }\n\n    fn dimension(\u0026self) -\u003e usize {\n        self.dimension\n    }\n\n    async fn embed_batch(\u0026self, texts: \u0026[String]) -\u003e Result\u003cVec\u003cVec\u003cf32\u003e\u003e, Self::Error\u003e {\n        let mut results = Vec::with_capacity(texts.len());\n        let mut uncached_texts = Vec::new();\n        let mut uncached_indices = Vec::new();\n\n        let mut cache = self.cache.write().await;\n\n        for (i, text) in texts.iter().enumerate() {\n            if let Some(cached) = cache.get(text) {\n                results.push(cached.clone());\n            } else {\n                results.push(Vec::new());\n                uncached_texts.push(text.clone());\n                uncached_indices.push(i);\n            }\n        }\n\n        if !uncached_texts.is_empty() {\n            let request = async_openai::types::CreateEmbeddingRequestArgs::default()\n                .model(\u0026self.model)\n                .input(uncached_texts.clone())\n                .build()?;\n\n            let response = self.client.embeddings().create(request).await?;\n\n            for (i, embedding_data) in response.data.into_iter().enumerate() {\n                let idx = uncached_indices[i];\n                let text: \u0026String = \u0026uncached_texts[i];\n                let embedding = embedding_data.embedding;\n\n                cache.put(text.clone(), embedding.clone());\n                results[idx] = embedding;\n            }\n        }\n\n        Ok(results)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[tokio::test]\n    #[ignore = \"Requires OpenAI API key\"]\n    async fn test_openai_embedding_service() {\n        let api_key = std::env::var(\"OPENAI_API_KEY\").unwrap_or_default();\n        if api_key.is_empty() {\n            return;\n        }\n\n        let service = OpenAIEmbeddingService::with_default_model(api_key);\n\n        let embedding = service.embed(\"Test text\").await.unwrap();\n        assert_eq!(embedding.len(), 1536);\n        assert!(service.dimension() == 1536);\n\n        let texts = vec![\"First text\".to_string(), \"Second text\".to_string()];\n        let embeddings = service.embed_batch(\u0026texts).await.unwrap();\n        assert_eq!(embeddings.len(), 2);\n        for embedding in embeddings {\n            assert_eq!(embedding.len(), 1536);\n        }\n    }\n\n    #[tokio::test]\n    async fn test_lru_cache_hit() {\n        let service = OpenAIEmbeddingService::with_cache_size(\n            \"sk-fake-key\".to_string(),\n            \"text-embedding-ada-002\",\n            10\n        );\n\n        let mut cache = service.cache.write().await;\n\n        let test_vector = vec![0.1; 1536];\n        cache.put(\"test_text\".to_string(), test_vector.clone());\n\n        let cached = cache.get(\"test_text\");\n        assert!(cached.is_some(), \"Cached value should be found\");\n        assert_eq!(*cached.unwrap(), *test_vector, \"Cached vector should match\");\n    }\n\n    #[tokio::test]\n    async fn test_lru_cache_miss() {\n        let service = OpenAIEmbeddingService::with_cache_size(\n            \"sk-fake-key\".to_string(),\n            \"text-embedding-ada-002\",\n            10\n        );\n\n        let mut cache = service.cache.write().await;\n\n        let cached = cache.get(\"nonexistent_text\");\n        assert!(cached.is_none(), \"Should return None for nonexistent key\");\n    }\n\n    #[test]\n    fn test_dimension_configuration() {\n        let service = OpenAIEmbeddingService::new(\"sk-test\".to_string(), \"text-embedding-ada-002\");\n        assert_eq!(\n            service.dimension(),\n            1536,\n            \"ada-002 should have 1536 dimensions\"\n        );\n\n        let service = OpenAIEmbeddingService::new(\"sk-test\".to_string(), \"text-embedding-3-small\");\n        assert_eq!(\n            service.dimension(),\n            1536,\n            \"3-small should have 1536 dimensions\"\n        );\n\n        let service = OpenAIEmbeddingService::new(\"sk-test\".to_string(), \"text-embedding-3-large\");\n        assert_eq!(\n            service.dimension(),\n            3072,\n            \"3-large should have 3072 dimensions\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_custom_cache_size() {\n        let service = OpenAIEmbeddingService::with_cache_size(\n            \"sk-test\".to_string(),\n            \"text-embedding-ada-002\",\n            500\n        );\n\n        let cache = service.cache.read().await;\n        assert_eq!(cache.cap().get(), 500, \"Cache capacity should be 500\");\n    }\n}\n","traces":[{"line":16,"address":[],"length":0,"stats":{"Line":3}},{"line":17,"address":[],"length":0,"stats":{"Line":12}},{"line":18,"address":[],"length":0,"stats":{"Line":9}},{"line":20,"address":[],"length":0,"stats":{"Line":6}},{"line":21,"address":[],"length":0,"stats":{"Line":4}},{"line":22,"address":[],"length":0,"stats":{"Line":3}},{"line":23,"address":[],"length":0,"stats":{"Line":2}},{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":29,"address":[],"length":0,"stats":{"Line":9}},{"line":31,"address":[],"length":0,"stats":{"Line":12}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":3}},{"line":44,"address":[],"length":0,"stats":{"Line":12}},{"line":45,"address":[],"length":0,"stats":{"Line":9}},{"line":47,"address":[],"length":0,"stats":{"Line":6}},{"line":48,"address":[],"length":0,"stats":{"Line":6}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":9}},{"line":58,"address":[],"length":0,"stats":{"Line":12}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":3}},{"line":125,"address":[],"length":0,"stats":{"Line":3}},{"line":128,"address":[],"length":0,"stats":{"Line":0}}],"covered":18,"coverable":29},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","episodic.rs"],"content":"\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","error.rs"],"content":"use thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum MemoryError {\n    #[error(\"Provider error: {0}\")]\n    ProviderError(String),\n\n    #[error(\"Embedding error: {0}\")]\n    EmbeddingError(String),\n\n    #[error(\"Validation error: {0}\")]\n    ValidationError(String),\n\n    #[error(\"Storage error: {0}\")]\n    StorageError(String),\n\n    #[error(\"Network error: {0}\")]\n    NetworkError(String),\n\n    #[error(\"Timeout error: {0}\")]\n    TimeoutError(String),\n\n    #[error(\"Configuration error: {0}\")]\n    ConfigError(String),\n\n    #[error(\"Serialization error: {0}\")]\n    SerializationError(String),\n\n    #[error(\"Resource not found: {0}\")]\n    NotFound(String),\n\n    #[error(\"Unauthorized access: {0}\")]\n    Unauthorized(String),\n\n    #[error(\"Rate limited: {0}\")]\n    RateLimited(String),\n\n    #[error(\"Internal error: {0}\")]\n    InternalError(String)\n}\n\nimpl MemoryError {\n    pub fn is_retryable(\u0026self) -\u003e bool {\n        match self {\n            MemoryError::NetworkError(_)\n            | MemoryError::TimeoutError(_)\n            | MemoryError::RateLimited(_)\n            | MemoryError::ProviderError(_) =\u003e true,\n            _ =\u003e false\n        }\n    }\n\n    pub fn should_backoff(\u0026self) -\u003e bool {\n        match self {\n            MemoryError::RateLimited(_) =\u003e true,\n            _ =\u003e false\n        }\n    }\n\n    pub fn backoff_duration(\u0026self) -\u003e Option\u003cstd::time::Duration\u003e {\n        match self {\n            MemoryError::RateLimited(_) =\u003e Some(std::time::Duration::from_secs(5)),\n            MemoryError::NetworkError(_) =\u003e Some(std::time::Duration::from_secs(1)),\n            _ =\u003e None\n        }\n    }\n}\n\npub type MemoryResult\u003cT\u003e = Result\u003cT, MemoryError\u003e;\n\n#[allow(async_fn_in_trait)]\npub trait WithRetry {\n    type Output;\n\n    async fn with_retry\u003cF, Fut\u003e(operation: F) -\u003e MemoryResult\u003cSelf::Output\u003e\n    where\n        F: Fn() -\u003e Fut,\n        Fut: std::future::Future\u003cOutput = MemoryResult\u003cSelf::Output\u003e\u003e;\n}\n\npub struct RetryConfig {\n    pub max_retries: usize,\n    pub initial_backoff: std::time::Duration,\n    pub max_backoff: std::time::Duration,\n    pub backoff_multiplier: f32,\n    pub jitter: bool\n}\n\nimpl Default for RetryConfig {\n    fn default() -\u003e Self {\n        Self {\n            max_retries: 3,\n            initial_backoff: std::time::Duration::from_millis(100),\n            max_backoff: std::time::Duration::from_secs(10),\n            backoff_multiplier: 2.0,\n            jitter: true\n        }\n    }\n}\n\npub async fn with_retry\u003cF, Fut, T\u003e(operation: F, config: RetryConfig) -\u003e MemoryResult\u003cT\u003e\nwhere\n    F: Fn() -\u003e Fut,\n    Fut: std::future::Future\u003cOutput = MemoryResult\u003cT\u003e\u003e\n{\n    let mut last_error = None;\n    let mut backoff = config.initial_backoff;\n\n    for attempt in 0..=config.max_retries {\n        match operation().await {\n            Ok(result) =\u003e return Ok(result),\n            Err(err) =\u003e {\n                last_error = Some(err);\n\n                if attempt == config.max_retries {\n                    break;\n                }\n\n                let current_error = last_error.as_ref().unwrap();\n\n                if !current_error.is_retryable() {\n                    break;\n                }\n\n                if let Some(error_backoff) = current_error.backoff_duration() {\n                    tokio::time::sleep(error_backoff).await;\n                } else {\n                    let mut actual_backoff = backoff;\n\n                    if config.jitter {\n                        let jitter = rand::random::\u003cf32\u003e() * 0.3 + 0.85;\n                        actual_backoff = std::time::Duration::from_millis(\n                            (actual_backoff.as_millis() as f32 * jitter) as u64\n                        );\n                    }\n\n                    tokio::time::sleep(actual_backoff).await;\n\n                    backoff = std::time::Duration::from_millis(\n                        (backoff.as_millis() as f32 * config.backoff_multiplier) as u64\n                    )\n                    .min(config.max_backoff);\n                }\n            }\n        }\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        MemoryError::InternalError(\"Operation failed after retries\".to_string())\n    }))\n}\n\npub async fn with_exponential_backoff\u003cF, Fut, T\u003e(\n    operation: F,\n    max_retries: usize\n) -\u003e MemoryResult\u003cT\u003e\nwhere\n    F: Fn() -\u003e Fut,\n    Fut: std::future::Future\u003cOutput = MemoryResult\u003cT\u003e\u003e\n{\n    with_retry(\n        operation,\n        RetryConfig {\n            max_retries,\n            ..Default::default()\n        }\n    )\n    .await\n}\n\npub struct CircuitBreaker {\n    state: std::sync::Arc\u003ctokio::sync::RwLock\u003cCircuitState\u003e\u003e,\n    failure_threshold: usize,\n    reset_timeout: std::time::Duration,\n    _half_open_timeout: std::time::Duration\n}\n\nenum CircuitState {\n    Closed { failure_count: usize },\n    Open { opened_at: std::time::Instant },\n    HalfOpen\n}\n\nimpl CircuitBreaker {\n    pub fn new(failure_threshold: usize, reset_timeout: std::time::Duration) -\u003e Self {\n        Self {\n            state: std::sync::Arc::new(tokio::sync::RwLock::new(CircuitState::Closed {\n                failure_count: 0\n            })),\n            failure_threshold,\n            reset_timeout,\n            _half_open_timeout: reset_timeout / 2\n        }\n    }\n\n    pub async fn execute\u003cF, Fut, T\u003e(\u0026self, operation: F) -\u003e MemoryResult\u003cT\u003e\n    where\n        F: Fn() -\u003e Fut,\n        Fut: std::future::Future\u003cOutput = MemoryResult\u003cT\u003e\u003e\n    {\n        let state = self.state.read().await;\n\n        match *state {\n            CircuitState::Open { opened_at } =\u003e {\n                if opened_at.elapsed() \u003e= self.reset_timeout {\n                    drop(state);\n                    let mut state = self.state.write().await;\n                    *state = CircuitState::HalfOpen;\n                } else {\n                    return Err(MemoryError::NetworkError(\n                        \"Circuit breaker is open\".to_string()\n                    ));\n                }\n            }\n            CircuitState::HalfOpen =\u003e {\n                drop(state);\n            }\n            CircuitState::Closed { .. } =\u003e {\n                drop(state);\n            }\n        }\n\n        let result = operation().await;\n\n        let mut state = self.state.write().await;\n        match *state {\n            CircuitState::HalfOpen =\u003e {\n                if result.is_ok() {\n                    *state = CircuitState::Closed { failure_count: 0 };\n                } else {\n                    *state = CircuitState::Open {\n                        opened_at: std::time::Instant::now()\n                    };\n                }\n            }\n            CircuitState::Closed {\n                ref mut failure_count\n            } =\u003e {\n                if result.is_ok() {\n                    *failure_count = 0;\n                } else {\n                    *failure_count += 1;\n                    if *failure_count \u003e= self.failure_threshold {\n                        *state = CircuitState::Open {\n                            opened_at: std::time::Instant::now()\n                        };\n                    }\n                }\n            }\n            _ =\u003e {}\n        }\n\n        result\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::sync::atomic::{AtomicUsize, Ordering};\n\n    #[tokio::test]\n    async fn test_retry_success() {\n        let counter = AtomicUsize::new(0);\n\n        let result = with_retry(\n            || async {\n                let count = counter.fetch_add(1, Ordering::SeqCst);\n                if count \u003c 2 {\n                    Err(MemoryError::NetworkError(\"Temporary failure\".to_string()))\n                } else {\n                    Ok(\"success\")\n                }\n            },\n            RetryConfig::default()\n        )\n        .await;\n\n        assert_eq!(result.unwrap(), \"success\");\n        assert_eq!(counter.load(Ordering::SeqCst), 3);\n    }\n\n    #[tokio::test]\n    async fn test_retry_non_retryable_error() {\n        let counter = AtomicUsize::new(0);\n\n        let result: Result\u003c\u0026str, _\u003e = with_retry(\n            || async {\n                counter.fetch_add(1, Ordering::SeqCst);\n                Err(MemoryError::ValidationError(\n                    \"Permanent failure\".to_string()\n                ))\n            },\n            RetryConfig::default()\n        )\n        .await;\n\n        assert!(result.is_err());\n        assert_eq!(counter.load(Ordering::SeqCst), 1);\n    }\n\n    #[test]\n    fn test_memory_error_retryable() {\n        assert!(MemoryError::NetworkError(\"\".into()).is_retryable());\n        assert!(MemoryError::TimeoutError(\"\".into()).is_retryable());\n        assert!(MemoryError::RateLimited(\"\".into()).is_retryable());\n        assert!(MemoryError::ProviderError(\"\".into()).is_retryable());\n        assert!(!MemoryError::ValidationError(\"\".into()).is_retryable());\n    }\n\n    #[test]\n    fn test_memory_error_backoff() {\n        assert!(MemoryError::RateLimited(\"\".into()).should_backoff());\n        assert!(!MemoryError::NetworkError(\"\".into()).should_backoff());\n\n        assert!(\n            MemoryError::RateLimited(\"\".into())\n                .backoff_duration()\n                .is_some()\n        );\n        assert!(\n            MemoryError::NetworkError(\"\".into())\n                .backoff_duration()\n                .is_some()\n        );\n        assert!(\n            MemoryError::InternalError(\"\".into())\n                .backoff_duration()\n                .is_none()\n        );\n    }\n\n    #[tokio::test]\n    async fn test_with_exponential_backoff() {\n        let counter = AtomicUsize::new(0);\n        let result = with_exponential_backoff(\n            || async {\n                let c = counter.fetch_add(1, Ordering::SeqCst);\n                if c \u003c 1 {\n                    Err(MemoryError::NetworkError(\"\".into()))\n                } else {\n                    Ok(\"ok\")\n                }\n            },\n            2\n        )\n        .await;\n        assert_eq!(result.unwrap(), \"ok\");\n        assert_eq!(counter.load(Ordering::SeqCst), 2);\n    }\n\n    #[tokio::test]\n    async fn test_circuit_breaker_half_open_failure() {\n        let breaker = CircuitBreaker::new(1, std::time::Duration::from_millis(50));\n\n        // Open it\n        let _: Result\u003c(), _\u003e = breaker\n            .execute(|| async { Err(MemoryError::NetworkError(\"\".into())) })\n            .await;\n\n        // Wait for reset timeout\n        tokio::time::sleep(std::time::Duration::from_millis(60)).await;\n\n        // Half-open attempt fails -\u003e goes back to Open\n        let _: Result\u003c(), _\u003e = breaker\n            .execute(|| async { Err(MemoryError::InternalError(\"\".into())) })\n            .await;\n\n        // Next call should be blocked immediately\n        let result = breaker.execute(|| async { Ok(\"should be blocked\") }).await;\n        assert!(\n            matches!(result, Err(MemoryError::NetworkError(msg)) if msg.contains(\"Circuit breaker is open\"))\n        );\n    }\n\n    #[tokio::test]\n    async fn test_circuit_breaker_half_open_success() {\n        let breaker = CircuitBreaker::new(2, std::time::Duration::from_millis(50));\n\n        // Open it with 2 failures\n        let _: Result\u003c(), _\u003e = breaker\n            .execute(|| async { Err(MemoryError::NetworkError(\"\".into())) })\n            .await;\n        let _: Result\u003c(), _\u003e = breaker\n            .execute(|| async { Err(MemoryError::NetworkError(\"\".into())) })\n            .await;\n\n        // Wait for reset timeout\n        tokio::time::sleep(std::time::Duration::from_millis(60)).await;\n\n        // Half-open attempt succeeds -\u003e goes back to Closed\n        let result = breaker.execute(|| async { Ok(\"success\") }).await;\n        assert_eq!(result.unwrap(), \"success\");\n\n        // Should be closed now, can make another successful call\n        let result = breaker.execute(|| async { Ok(\"another success\") }).await;\n        assert_eq!(result.unwrap(), \"another success\");\n    }\n\n    #[tokio::test]\n    async fn test_circuit_breaker_closed_state_reset_on_success() {\n        let breaker = CircuitBreaker::new(3, std::time::Duration::from_millis(100));\n\n        // Fail once\n        let _: Result\u003c(), _\u003e = breaker\n            .execute(|| async { Err(MemoryError::NetworkError(\"\".into())) })\n            .await;\n\n        // Success should reset failure count\n        let result = breaker.execute(|| async { Ok(\"reset\") }).await;\n        assert_eq!(result.unwrap(), \"reset\");\n\n        // Should still be closed, not open\n        let result = breaker.execute(|| async { Ok(\"still working\") }).await;\n        assert_eq!(result.unwrap(), \"still working\");\n    }\n\n    #[test]\n    fn test_all_error_variants_display() {\n        // Test that all error variants can be formatted\n        let errors = vec![\n            MemoryError::ProviderError(\"test\".to_string()),\n            MemoryError::EmbeddingError(\"test\".to_string()),\n            MemoryError::ValidationError(\"test\".to_string()),\n            MemoryError::StorageError(\"test\".to_string()),\n            MemoryError::NetworkError(\"test\".to_string()),\n            MemoryError::TimeoutError(\"test\".to_string()),\n            MemoryError::ConfigError(\"test\".to_string()),\n            MemoryError::SerializationError(\"test\".to_string()),\n            MemoryError::NotFound(\"test\".to_string()),\n            MemoryError::Unauthorized(\"test\".to_string()),\n            MemoryError::RateLimited(\"test\".to_string()),\n            MemoryError::InternalError(\"test\".to_string()),\n        ];\n\n        for error in errors {\n            let display = error.to_string();\n            assert!(!display.is_empty());\n            assert!(display.contains(\"test\"));\n        }\n    }\n\n    #[tokio::test]\n    async fn test_with_retry_jitter_calculation() {\n        let counter = AtomicUsize::new(0);\n\n        let config = RetryConfig {\n            max_retries: 2,\n            initial_backoff: std::time::Duration::from_millis(100),\n            max_backoff: std::time::Duration::from_secs(1),\n            backoff_multiplier: 2.0,\n            jitter: true\n        };\n\n        let result = with_retry(\n            || async {\n                let count = counter.fetch_add(1, Ordering::SeqCst);\n                if count \u003c 2 {\n                    Err(MemoryError::NetworkError(\"Temporary\".to_string()))\n                } else {\n                    Ok(\"success with jitter\")\n                }\n            },\n            config\n        )\n        .await;\n\n        assert_eq!(result.unwrap(), \"success with jitter\");\n        assert_eq!(counter.load(Ordering::SeqCst), 3);\n    }\n\n    #[tokio::test]\n    async fn test_with_retry_error_backoff_takes_precedence() {\n        let counter = AtomicUsize::new(0);\n\n        let result: Result\u003c\u0026str, _\u003e = with_retry(\n            || async {\n                let count = counter.fetch_add(1, Ordering::SeqCst);\n                // RateLimited has its own backoff duration (5 seconds)\n                Err(MemoryError::RateLimited(format!(\"Attempt {}\", count)))\n            },\n            RetryConfig::default()\n        )\n        .await;\n\n        assert!(result.is_err());\n        // Should fail immediately after max retries since RateLimited has\n        // error-specific backoff\n        assert!(counter.load(Ordering::SeqCst) \u003e 0);\n    }\n\n    // Test implementation of WithRetry trait\n    struct TestRetryable;\n\n    impl WithRetry for TestRetryable {\n        type Output = String;\n\n        async fn with_retry\u003cF, Fut\u003e(operation: F) -\u003e MemoryResult\u003cSelf::Output\u003e\n        where\n            F: Fn() -\u003e Fut,\n            Fut: std::future::Future\u003cOutput = MemoryResult\u003cSelf::Output\u003e\u003e\n        {\n            with_retry(operation, RetryConfig::default()).await\n        }\n    }\n\n    #[tokio::test]\n    async fn test_with_retry_trait_implementation() {\n        let counter = AtomicUsize::new(0);\n\n        let result = TestRetryable::with_retry(|| async {\n            let count = counter.fetch_add(1, Ordering::SeqCst);\n            if count \u003c 1 {\n                Err(MemoryError::NetworkError(\"Temporary\".to_string()))\n            } else {\n                Ok(\"trait success\".to_string())\n            }\n        })\n        .await;\n\n        assert_eq!(result.unwrap(), \"trait success\");\n        assert_eq!(counter.load(Ordering::SeqCst), 2);\n    }\n}\n","traces":[{"line":43,"address":[],"length":0,"stats":{"Line":15}},{"line":44,"address":[],"length":0,"stats":{"Line":15}},{"line":48,"address":[],"length":0,"stats":{"Line":13}},{"line":49,"address":[],"length":0,"stats":{"Line":2}},{"line":53,"address":[],"length":0,"stats":{"Line":2}},{"line":54,"address":[],"length":0,"stats":{"Line":2}},{"line":55,"address":[],"length":0,"stats":{"Line":1}},{"line":56,"address":[],"length":0,"stats":{"Line":1}},{"line":60,"address":[],"length":0,"stats":{"Line":12}},{"line":61,"address":[],"length":0,"stats":{"Line":12}},{"line":62,"address":[],"length":0,"stats":{"Line":4}},{"line":63,"address":[],"length":0,"stats":{"Line":7}},{"line":64,"address":[],"length":0,"stats":{"Line":1}},{"line":90,"address":[],"length":0,"stats":{"Line":5}},{"line":93,"address":[],"length":0,"stats":{"Line":5}},{"line":94,"address":[],"length":0,"stats":{"Line":5}},{"line":101,"address":[],"length":0,"stats":{"Line":6}},{"line":106,"address":[],"length":0,"stats":{"Line":12}},{"line":107,"address":[],"length":0,"stats":{"Line":12}},{"line":109,"address":[],"length":0,"stats":{"Line":21}},{"line":110,"address":[],"length":0,"stats":{"Line":30}},{"line":111,"address":[],"length":0,"stats":{"Line":8}},{"line":112,"address":[],"length":0,"stats":{"Line":11}},{"line":113,"address":[],"length":0,"stats":{"Line":22}},{"line":115,"address":[],"length":0,"stats":{"Line":11}},{"line":116,"address":[],"length":0,"stats":{"Line":1}},{"line":119,"address":[],"length":0,"stats":{"Line":40}},{"line":121,"address":[],"length":0,"stats":{"Line":10}},{"line":122,"address":[],"length":0,"stats":{"Line":1}},{"line":125,"address":[],"length":0,"stats":{"Line":18}},{"line":126,"address":[],"length":0,"stats":{"Line":18}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":4}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":1}},{"line":162,"address":[],"length":0,"stats":{"Line":2}},{"line":163,"address":[],"length":0,"stats":{"Line":1}},{"line":164,"address":[],"length":0,"stats":{"Line":1}},{"line":165,"address":[],"length":0,"stats":{"Line":1}},{"line":168,"address":[],"length":0,"stats":{"Line":1}},{"line":185,"address":[],"length":0,"stats":{"Line":3}},{"line":187,"address":[],"length":0,"stats":{"Line":12}},{"line":192,"address":[],"length":0,"stats":{"Line":3}},{"line":196,"address":[],"length":0,"stats":{"Line":10}},{"line":201,"address":[],"length":0,"stats":{"Line":20}},{"line":203,"address":[],"length":0,"stats":{"Line":10}},{"line":204,"address":[],"length":0,"stats":{"Line":3}},{"line":205,"address":[],"length":0,"stats":{"Line":3}},{"line":206,"address":[],"length":0,"stats":{"Line":4}},{"line":207,"address":[],"length":0,"stats":{"Line":4}},{"line":208,"address":[],"length":0,"stats":{"Line":2}},{"line":210,"address":[],"length":0,"stats":{"Line":1}},{"line":211,"address":[],"length":0,"stats":{"Line":1}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":7}},{"line":219,"address":[],"length":0,"stats":{"Line":7}},{"line":223,"address":[],"length":0,"stats":{"Line":18}},{"line":225,"address":[],"length":0,"stats":{"Line":18}},{"line":226,"address":[],"length":0,"stats":{"Line":9}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":5}},{"line":229,"address":[],"length":0,"stats":{"Line":1}},{"line":231,"address":[],"length":0,"stats":{"Line":1}},{"line":232,"address":[],"length":0,"stats":{"Line":1}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":7}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":17}},{"line":240,"address":[],"length":0,"stats":{"Line":3}},{"line":242,"address":[],"length":0,"stats":{"Line":4}},{"line":243,"address":[],"length":0,"stats":{"Line":6}},{"line":244,"address":[],"length":0,"stats":{"Line":2}},{"line":245,"address":[],"length":0,"stats":{"Line":2}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":9}}],"covered":68,"coverable":84},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","governance.rs"],"content":"use serde_json::Value;\n\npub struct GovernanceService {}\n\nimpl GovernanceService {\n    pub fn new() -\u003e Self {\n        Self {}\n    }\n\n    pub fn redact_pii(\u0026self, content: \u0026str) -\u003e String {\n        utils::redact_pii(content)\n    }\n\n    pub fn is_sensitive(\u0026self, metadata: \u0026Value) -\u003e bool {\n        if let Some(obj) = metadata.as_object() {\n            if let Some(sensitive) = obj.get(\"sensitive\") {\n                if let Some(b) = sensitive.as_bool() {\n                    if b {\n                        return true;\n                    }\n                }\n            }\n            if let Some(private) = obj.get(\"private\") {\n                if let Some(b) = private.as_bool() {\n                    if b {\n                        return true;\n                    }\n                }\n            }\n        }\n        false\n    }\n\n    pub fn can_promote(\u0026self, _content: \u0026str, metadata: \u0026Value) -\u003e bool {\n        if self.is_sensitive(metadata) {\n            return false;\n        }\n        true\n    }\n}\n\nimpl Default for GovernanceService {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use serde_json::json;\n\n    #[test]\n    fn test_pii_redaction() {\n        let service = GovernanceService::new();\n        let content = \"Contact me at user@example.com for details.\";\n        let redacted = service.redact_pii(content);\n        assert_eq!(redacted, \"Contact me at [REDACTED_EMAIL] for details.\");\n    }\n\n    #[test]\n    fn test_sensitivity_check() {\n        let service = GovernanceService::new();\n\n        let metadata_sensitive = json!({ \"sensitive\": true });\n        assert!(service.is_sensitive(\u0026metadata_sensitive));\n\n        let metadata_private = json!({ \"private\": true });\n        assert!(service.is_sensitive(\u0026metadata_private));\n\n        let metadata_safe = json!({ \"tags\": [\"rust\"] });\n        assert!(!service.is_sensitive(\u0026metadata_safe));\n    }\n\n    #[test]\n    fn test_can_promote() {\n        let service = GovernanceService::new();\n        let content = \"Safe content\";\n        let metadata = json!({ \"sensitive\": false });\n        assert!(service.can_promote(content, \u0026metadata));\n\n        let metadata_sensitive = json!({ \"sensitive\": true });\n        assert!(!service.can_promote(content, \u0026metadata_sensitive));\n    }\n\n    #[test]\n    fn test_governance_default() {\n        let _ = GovernanceService::default();\n    }\n\n    #[test]\n    fn test_is_sensitive_non_object() {\n        let service = GovernanceService::new();\n        assert!(!service.is_sensitive(\u0026json!(\"not an object\")));\n        assert!(!service.is_sensitive(\u0026json!(null)));\n    }\n\n    #[test]\n    fn test_is_sensitive_mixed_types() {\n        let service = GovernanceService::new();\n        assert!(!service.is_sensitive(\u0026json!({ \"sensitive\": \"true\" })));\n        assert!(!service.is_sensitive(\u0026json!({ \"private\": 123 })));\n    }\n}\n","traces":[{"line":6,"address":[],"length":0,"stats":{"Line":98}},{"line":10,"address":[],"length":0,"stats":{"Line":1050}},{"line":11,"address":[],"length":0,"stats":{"Line":2100}},{"line":14,"address":[],"length":0,"stats":{"Line":17}},{"line":15,"address":[],"length":0,"stats":{"Line":32}},{"line":16,"address":[],"length":0,"stats":{"Line":35}},{"line":17,"address":[],"length":0,"stats":{"Line":9}},{"line":18,"address":[],"length":0,"stats":{"Line":4}},{"line":19,"address":[],"length":0,"stats":{"Line":3}},{"line":23,"address":[],"length":0,"stats":{"Line":26}},{"line":24,"address":[],"length":0,"stats":{"Line":3}},{"line":25,"address":[],"length":0,"stats":{"Line":1}},{"line":26,"address":[],"length":0,"stats":{"Line":1}},{"line":31,"address":[],"length":0,"stats":{"Line":13}},{"line":34,"address":[],"length":0,"stats":{"Line":10}},{"line":35,"address":[],"length":0,"stats":{"Line":30}},{"line":36,"address":[],"length":0,"stats":{"Line":2}},{"line":38,"address":[],"length":0,"stats":{"Line":8}},{"line":43,"address":[],"length":0,"stats":{"Line":1}},{"line":44,"address":[],"length":0,"stats":{"Line":1}}],"covered":20,"coverable":20},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","hot_reload.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","lib.rs"],"content":"//! # Memory System\n//!\n//! Implementation of hierarchical memory storage and retrieval.\n\npub mod embedding;\npub mod episodic;\npub mod error;\npub mod governance;\npub mod llm;\npub mod manager;\npub mod procedural;\npub mod promotion;\npub mod providers;\npub mod telemetry;\npub mod working;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","llm","mock.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::LlmService;\nuse mk_core::types::{Policy, ValidationResult};\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\npub struct MockLlmService {\n    responses: Arc\u003cRwLock\u003cstd::collections::HashMap\u003cString, String\u003e\u003e\u003e\n}\n\nimpl MockLlmService {\n    pub fn new() -\u003e Self {\n        Self {\n            responses: Arc::new(RwLock::new(std::collections::HashMap::new()))\n        }\n    }\n\n    pub async fn add_response(\u0026self, prompt: String, response: String) {\n        let mut responses = self.responses.write().await;\n        responses.insert(prompt, response);\n    }\n}\n\n#[async_trait]\nimpl LlmService for MockLlmService {\n    type Error = anyhow::Error;\n\n    async fn generate(\u0026self, prompt: \u0026str) -\u003e Result\u003cString, Self::Error\u003e {\n        let responses = self.responses.read().await;\n        if let Some(response) = responses.get(prompt) {\n            Ok(response.clone())\n        } else {\n            Ok(format!(\"Mock response for: {}\", prompt))\n        }\n    }\n\n    async fn analyze_drift(\n        \u0026self,\n        content: \u0026str,\n        policies: \u0026[Policy]\n    ) -\u003e Result\u003cValidationResult, Self::Error\u003e {\n        let mut is_valid = true;\n        let mut violations = Vec::new();\n\n        for policy in policies {\n            for rule in \u0026policy.rules {\n                if content.contains(\u0026format!(\"violate:{}\", rule.id)) {\n                    is_valid = false;\n                    violations.push(mk_core::types::PolicyViolation {\n                        rule_id: rule.id.clone(),\n                        policy_id: policy.id.clone(),\n                        severity: rule.severity,\n                        message: format!(\n                            \"Semantic violation of rule {}: {}\",\n                            rule.id, rule.message\n                        ),\n                        context: std::collections::HashMap::new()\n                    });\n                }\n            }\n        }\n\n        Ok(ValidationResult {\n            is_valid,\n            violations\n        })\n    }\n}\n","traces":[{"line":12,"address":[],"length":0,"stats":{"Line":5}},{"line":14,"address":[],"length":0,"stats":{"Line":10}},{"line":18,"address":[],"length":0,"stats":{"Line":0}},{"line":19,"address":[],"length":0,"stats":{"Line":0}},{"line":20,"address":[],"length":0,"stats":{"Line":0}},{"line":28,"address":[],"length":0,"stats":{"Line":0}}],"covered":2,"coverable":6},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","llm","mod.rs"],"content":"pub mod mock;\npub mod openai;\n\npub use mock::MockLlmService;\npub use openai::OpenAILlmService;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","llm","openai.rs"],"content":"use async_openai::types::{\n    ChatCompletionRequestSystemMessageArgs, ChatCompletionRequestUserMessageArgs,\n    CreateChatCompletionRequestArgs\n};\nuse async_trait::async_trait;\nuse mk_core::traits::LlmService;\nuse mk_core::types::{Policy, ValidationResult};\nuse std::num::NonZeroUsize;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\npub struct OpenAILlmService {\n    client: async_openai::Client\u003casync_openai::config::OpenAIConfig\u003e,\n    model: String,\n    cache: Arc\u003cRwLock\u003clru::LruCache\u003cString, String\u003e\u003e\u003e\n}\n\nimpl OpenAILlmService {\n    pub fn new(api_key: String, model: String) -\u003e Self {\n        let config = async_openai::config::OpenAIConfig::new().with_api_key(api_key);\n        let client = async_openai::Client::with_config(config);\n        let cache = lru::LruCache::new(NonZeroUsize::new(100).unwrap());\n\n        Self {\n            client,\n            model,\n            cache: Arc::new(RwLock::new(cache))\n        }\n    }\n}\n\n#[async_trait]\nimpl LlmService for OpenAILlmService {\n    type Error = anyhow::Error;\n\n    async fn generate(\u0026self, prompt: \u0026str) -\u003e Result\u003cString, Self::Error\u003e {\n        {\n            let mut cache = self.cache.write().await;\n            if let Some(cached) = cache.get(prompt) {\n                return Ok(cached.clone());\n            }\n        }\n\n        let request = CreateChatCompletionRequestArgs::default()\n            .model(\u0026self.model)\n            .messages([ChatCompletionRequestUserMessageArgs::default()\n                .content(prompt)\n                .build()?\n                .into()])\n            .build()?;\n\n        let response = self.client.chat().create(request).await?;\n        let content = response\n            .choices\n            .first()\n            .and_then(|choice| choice.message.content.clone())\n            .unwrap_or_default();\n\n        {\n            let mut cache = self.cache.write().await;\n            cache.put(prompt.to_string(), content.clone());\n        }\n\n        Ok(content)\n    }\n\n    async fn analyze_drift(\n        \u0026self,\n        content: \u0026str,\n        policies: \u0026[Policy]\n    ) -\u003e Result\u003cValidationResult, Self::Error\u003e {\n        let policies_json = serde_json::to_string_pretty(policies)?;\n        let prompt = format!(\n            \"Analyze the following content against the provided governance policies.\\nReturn a \\\n             JSON object with 'isValid' (boolean) and 'violations' (array of PolicyViolation \\\n             objects).\\nPolicyViolation schema: {{ 'ruleId': string, 'policyId': string, \\\n             'severity': 'info'|'warn'|'block', 'message': string, 'context': object \\\n             }}\\n\\nContent:\\n{}\\n\\nPolicies:\\n{}\",\n            content, policies_json\n        );\n\n        let system_prompt = \"You are a governance analysis engine. You strictly evaluate content \\\n                             against policies and return structured JSON results.\";\n\n        let request = CreateChatCompletionRequestArgs::default()\n            .model(\u0026self.model)\n            .messages([\n                ChatCompletionRequestSystemMessageArgs::default()\n                    .content(system_prompt)\n                    .build()?\n                    .into(),\n                ChatCompletionRequestUserMessageArgs::default()\n                    .content(\u0026*prompt)\n                    .build()?\n                    .into()\n            ])\n            .response_format(async_openai::types::ResponseFormat::JsonObject)\n            .build()?;\n\n        let response = self.client.chat().create(request).await?;\n        let result_json = response\n            .choices\n            .first()\n            .and_then(|choice| choice.message.content.clone())\n            .ok_or_else(|| anyhow::anyhow!(\"Empty response from OpenAI\"))?;\n\n        let result: ValidationResult = serde_json::from_str(\u0026result_json)?;\n        Ok(result)\n    }\n}\n","traces":[{"line":19,"address":[],"length":0,"stats":{"Line":0}},{"line":20,"address":[],"length":0,"stats":{"Line":0}},{"line":21,"address":[],"length":0,"stats":{"Line":0}},{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":9},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","loader.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","manager.rs"],"content":"use crate::governance::GovernanceService;\nuse crate::telemetry::MemoryTelemetry;\nuse mk_core::traits::MemoryProviderAdapter;\nuse mk_core::traits::{AuthorizationService, EmbeddingService};\nuse mk_core::types::{MemoryEntry, MemoryLayer};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\npub type ProviderMap = HashMap\u003c\n    MemoryLayer,\n    Box\u003cdyn MemoryProviderAdapter\u003cError = Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e + Send + Sync\u003e\n\u003e;\n\npub struct MemoryManager {\n    providers: Arc\u003cRwLock\u003cProviderMap\u003e\u003e,\n    embedding_service: Option\u003c\n        Arc\u003cdyn EmbeddingService\u003cError = Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e + Send + Sync\u003e\n    \u003e,\n    governance_service: Arc\u003cGovernanceService\u003e,\n    auth_service: Option\u003c\n        Arc\u003c\n            dyn AuthorizationService\u003cError = Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e\n                + Send\n                + Sync\n        \u003e\n    \u003e,\n    telemetry: Arc\u003cMemoryTelemetry\u003e,\n    config: config::MemoryConfig\n}\n\nimpl MemoryManager {\n    pub fn new() -\u003e Self {\n        Self {\n            providers: Arc::new(RwLock::new(HashMap::new())),\n            embedding_service: None,\n            governance_service: Arc::new(GovernanceService::new()),\n            auth_service: None,\n            telemetry: Arc::new(MemoryTelemetry::new()),\n            config: config::MemoryConfig::default()\n        }\n    }\n\n    pub fn with_config(mut self, config: config::MemoryConfig) -\u003e Self {\n        self.config = config;\n        self\n    }\n\n    pub fn with_embedding_service(\n        mut self,\n        embedding_service: Arc\u003c\n            dyn EmbeddingService\u003cError = Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e + Send + Sync\n        \u003e\n    ) -\u003e Self {\n        self.embedding_service = Some(embedding_service);\n        self\n    }\n\n    pub fn with_auth_service(\n        mut self,\n        auth_service: Arc\u003c\n            dyn AuthorizationService\u003cError = Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e\n                + Send\n                + Sync\n        \u003e\n    ) -\u003e Self {\n        self.auth_service = Some(auth_service);\n        self\n    }\n\n    pub fn with_telemetry(mut self, telemetry: Arc\u003cMemoryTelemetry\u003e) -\u003e Self {\n        self.telemetry = telemetry;\n        self\n    }\n}\n\nimpl Default for MemoryManager {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\nimpl MemoryManager {\n    pub async fn register_provider(\n        \u0026self,\n        layer: MemoryLayer,\n        provider: Box\u003c\n            dyn MemoryProviderAdapter\u003cError = Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e\n                + Send\n                + Sync\n        \u003e\n    ) {\n        let mut providers = self.providers.write().await;\n        providers.insert(layer, provider);\n    }\n\n    pub async fn search_hierarchical(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        query_vector: Vec\u003cf32\u003e,\n        limit: usize,\n        filters: HashMap\u003cString, serde_json::Value\u003e\n    ) -\u003e Result\u003cVec\u003cMemoryEntry\u003e, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        if let Some(auth) = \u0026self.auth_service {\n            if !auth\n                .check_permission(\u0026ctx, \"memory:read\", \"hierarchical\")\n                .await?\n            {\n                return Err(\"Unauthorized to search hierarchical memory\".into());\n            }\n        }\n\n        let start = std::time::Instant::now();\n        let providers = self.providers.read().await;\n        let mut all_results = Vec::new();\n\n        for (layer, provider) in providers.iter() {\n            let layer_str = format!(\"{:?}\", layer);\n            let _span = self.telemetry.record_operation_start(\"search\", \u0026layer_str);\n            match provider\n                .search(ctx.clone(), query_vector.clone(), limit, filters.clone())\n                .await\n            {\n                Ok(results) =\u003e {\n                    self.telemetry.record_operation_success(\n                        \"search\",\n                        \u0026layer_str,\n                        start.elapsed().as_millis() as f64\n                    );\n                    for mut entry in results {\n                        entry.layer = *layer;\n                        all_results.push(entry);\n                    }\n                }\n                Err(e) =\u003e {\n                    self.telemetry\n                        .record_operation_failure(\"search\", \u0026layer_str, \u0026e.to_string());\n                    tracing::error!(\"Error searching layer {:?}: {}\", layer, e)\n                }\n            }\n        }\n\n        all_results.sort_by(|a, b| a.layer.precedence().cmp(\u0026b.layer.precedence()));\n\n        let final_results: Vec\u003cMemoryEntry\u003e = all_results.into_iter().take(limit).collect();\n        self.telemetry\n            .record_search_operation(final_results.len(), query_vector.len());\n        Ok(final_results)\n    }\n\n    pub async fn search_with_threshold(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        query_vector: Vec\u003cf32\u003e,\n        limit: usize,\n        threshold: f32,\n        filters: HashMap\u003cString, serde_json::Value\u003e\n    ) -\u003e Result\u003cVec\u003cMemoryEntry\u003e, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let providers = self.providers.read().await;\n        let mut all_results = Vec::new();\n\n        for (layer, provider) in providers.iter() {\n            match provider\n                .search(ctx.clone(), query_vector.clone(), limit, filters.clone())\n                .await\n            {\n                Ok(results) =\u003e {\n                    for mut entry in results {\n                        let score = entry\n                            .metadata\n                            .get(\"score\")\n                            .and_then(|s| s.as_f64())\n                            .map(|s| s as f32)\n                            .unwrap_or(1.0);\n\n                        if score \u003e= threshold {\n                            entry.layer = *layer;\n                            all_results.push(entry);\n                        }\n                    }\n                }\n                Err(e) =\u003e tracing::error!(\"Error searching layer {:?}: {}\", layer, e)\n            }\n        }\n\n        all_results.sort_by(|a, b| a.layer.precedence().cmp(\u0026b.layer.precedence()));\n\n        Ok(all_results.into_iter().take(limit).collect())\n    }\n\n    pub async fn search_text_with_threshold(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        query_text: \u0026str,\n        limit: usize,\n        threshold: f32,\n        filters: HashMap\u003cString, serde_json::Value\u003e\n    ) -\u003e Result\u003cVec\u003cMemoryEntry\u003e, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let embedding_service = self\n            .embedding_service\n            .as_ref()\n            .ok_or(\"Embedding service not configured\")?;\n\n        let query_vector = embedding_service.embed(query_text).await?;\n\n        self.search_with_threshold(ctx, query_vector, limit, threshold, filters)\n            .await\n    }\n\n    pub async fn add_to_layer(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer,\n        mut entry: MemoryEntry\n    ) -\u003e Result\u003cString, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        if let Some(auth) = \u0026self.auth_service {\n            if !auth\n                .check_permission(\u0026ctx, \"memory:write\", \u0026format!(\"layer:{:?}\", layer))\n                .await?\n            {\n                return Err(\"Unauthorized to write to this memory layer\".into());\n            }\n        }\n\n        let start = std::time::Instant::now();\n        let layer_str = format!(\"{:?}\", layer);\n        let _span = self.telemetry.record_operation_start(\"add\", \u0026layer_str);\n\n        let original_content = entry.content.clone();\n        entry.content = self.governance_service.redact_pii(\u0026entry.content);\n        if entry.content != original_content {\n            self.telemetry.record_governance_redaction(\u0026layer_str);\n        }\n\n        let providers = self.providers.read().await;\n        let provider = providers\n            .get(\u0026layer)\n            .ok_or(\"No provider registered for layer\")?;\n\n        match provider.add(ctx, entry).await {\n            Ok(id) =\u003e {\n                self.telemetry.record_operation_success(\n                    \"add\",\n                    \u0026layer_str,\n                    start.elapsed().as_millis() as f64\n                );\n                Ok(id)\n            }\n            Err(e) =\u003e {\n                self.telemetry\n                    .record_operation_failure(\"add\", \u0026layer_str, \u0026e.to_string());\n                Err(e)\n            }\n        }\n    }\n\n    pub async fn delete_from_layer(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer,\n        id: \u0026str\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let providers = self.providers.read().await;\n        let provider = providers\n            .get(\u0026layer)\n            .ok_or(\"No provider registered for layer\")?;\n        provider.delete(ctx, id).await\n    }\n\n    pub async fn get_from_layer(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer,\n        id: \u0026str\n    ) -\u003e Result\u003cOption\u003cMemoryEntry\u003e, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let providers = self.providers.read().await;\n        let provider = providers\n            .get(\u0026layer)\n            .ok_or(\"No provider registered for layer\")?;\n\n        let entry = provider.get(ctx.clone(), id).await?;\n\n        if let Some(mut entry) = entry {\n            let now = chrono::Utc::now().timestamp();\n            let count = entry\n                .metadata\n                .get(\"access_count\")\n                .and_then(|v| v.as_u64())\n                .unwrap_or(0)\n                + 1;\n\n            entry\n                .metadata\n                .insert(\"access_count\".to_string(), serde_json::json!(count));\n            entry\n                .metadata\n                .insert(\"last_accessed_at\".to_string(), serde_json::json!(now));\n            entry.updated_at = now;\n\n            provider.update(ctx, entry.clone()).await?;\n            Ok(Some(entry))\n        } else {\n            Ok(None)\n        }\n    }\n\n    pub async fn list_all_from_layer(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer\n    ) -\u003e Result\u003cVec\u003cMemoryEntry\u003e, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let providers = self.providers.read().await;\n        let provider = providers\n            .get(\u0026layer)\n            .ok_or(\"No provider registered for layer\")?;\n\n        let (result, _) = provider.list(ctx, layer, 1000, None).await?;\n        Ok(result)\n    }\n\n    pub async fn promote_memory(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        id: \u0026str,\n        source_layer: MemoryLayer,\n        target_layer: MemoryLayer\n    ) -\u003e Result\u003cString, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let entry = self\n            .get_from_layer(ctx.clone(), source_layer, id)\n            .await?\n            .ok_or_else(|| format!(\"Memory {} not found in layer {:?}\", id, source_layer))?;\n\n        let mut promoted_entry = entry.clone();\n        promoted_entry.id = format!(\"{}_promoted\", entry.id);\n        promoted_entry.layer = target_layer;\n\n        let now = chrono::Utc::now().timestamp();\n        promoted_entry.metadata.insert(\n            \"original_memory_id\".to_string(),\n            serde_json::json!(entry.id)\n        );\n        promoted_entry\n            .metadata\n            .insert(\"promoted_at\".to_string(), serde_json::json!(now));\n\n        self.add_to_layer(ctx, target_layer, promoted_entry).await\n    }\n\n    pub async fn promote_important_memories(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer\n    ) -\u003e Result\u003cVec\u003cString\u003e, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        use crate::promotion::PromotionService;\n        let promotion_service = PromotionService::new(Arc::new(MemoryManager {\n            providers: self.providers.clone(),\n            embedding_service: self.embedding_service.clone(),\n            governance_service: self.governance_service.clone(),\n            auth_service: self.auth_service.clone(),\n            telemetry: self.telemetry.clone(),\n            config: self.config.clone()\n        }))\n        .with_config(self.config.clone())\n        .with_telemetry(self.telemetry.clone());\n\n        promotion_service\n            .promote_layer_memories(ctx, layer, \u0026mk_core::types::LayerIdentifiers::default())\n            .await\n            .map_err(|e| {\n                Box::new(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    e.to_string()\n                )) as Box\u003cdyn std::error::Error + Send + Sync\u003e\n            })\n    }\n\n    pub async fn close_session(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        session_id: \u0026str\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        tracing::info!(\"Closing session: {}\", session_id);\n\n        self.promote_important_memories(ctx.clone(), MemoryLayer::Session)\n            .await?;\n\n        self.delete_from_layer(ctx, MemoryLayer::Session, session_id)\n            .await?;\n\n        Ok(())\n    }\n\n    pub async fn close_agent(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        agent_id: \u0026str\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        tracing::info!(\"Closing agent: {}\", agent_id);\n\n        self.promote_important_memories(ctx.clone(), MemoryLayer::Agent)\n            .await?;\n\n        self.delete_from_layer(ctx, MemoryLayer::Agent, agent_id)\n            .await?;\n\n        Ok(())\n    }\n}\n\n#[cfg(test)]\npub(crate) mod tests {\n    use super::*;\n    use crate::providers::MockProvider;\n    use mk_core::types::TenantContext;\n\n    pub(crate) fn test_ctx() -\u003e TenantContext {\n        use std::str::FromStr;\n        TenantContext {\n            tenant_id: mk_core::types::TenantId::from_str(\"test-tenant\").unwrap(),\n            user_id: mk_core::types::UserId::from_str(\"test-user\").unwrap(),\n            agent_id: None\n        }\n    }\n\n    #[tokio::test]\n    async fn test_hierarchical_search() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let agent_provider = Box::new(MockProvider::new());\n        let session_provider = Box::new(MockProvider::new());\n\n        manager\n            .register_provider(MemoryLayer::Agent, agent_provider)\n            .await;\n        manager\n            .register_provider(MemoryLayer::Session, session_provider)\n            .await;\n\n        let agent_entry = MemoryEntry {\n            id: \"agent_1\".to_string(),\n            content: \"agent content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        let session_entry = MemoryEntry {\n            id: \"session_1\".to_string(),\n            content: \"session content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Agent, agent_entry)\n            .await\n            .unwrap();\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Session, session_entry)\n            .await\n            .unwrap();\n\n        let results = manager\n            .search_hierarchical(ctx, vec![], 10, HashMap::new())\n            .await\n            .unwrap();\n\n        assert_eq!(results.len(), 2);\n        assert_eq!(results[0].id, \"agent_1\");\n        assert_eq!(results[1].id, \"session_1\");\n    }\n\n    #[tokio::test]\n    async fn test_search_with_threshold() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let provider = Box::new(MockProvider::new());\n\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let entry_high_score = MemoryEntry {\n            id: \"high_score\".to_string(),\n            content: \"high score content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: {\n                let mut map = HashMap::new();\n                map.insert(\"score\".to_string(), serde_json::json!(0.9));\n                map\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n\n        let entry_low_score = MemoryEntry {\n            id: \"low_score\".to_string(),\n            content: \"low score content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: {\n                let mut map = HashMap::new();\n                map.insert(\"score\".to_string(), serde_json::json!(0.5));\n                map\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry_high_score)\n            .await\n            .unwrap();\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry_low_score)\n            .await\n            .unwrap();\n\n        let results = manager\n            .search_with_threshold(ctx.clone(), vec![], 10, 0.7, HashMap::new())\n            .await\n            .unwrap();\n\n        assert_eq!(results.len(), 1);\n        assert_eq!(results[0].id, \"high_score\");\n\n        let results = manager\n            .search_with_threshold(ctx, vec![], 10, 0.3, HashMap::new())\n            .await\n            .unwrap();\n\n        assert_eq!(results.len(), 2);\n    }\n\n    #[tokio::test]\n    async fn test_search_with_threshold_no_score_in_metadata() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let provider = Box::new(MockProvider::new());\n\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let entry = MemoryEntry {\n            id: \"no_score\".to_string(),\n            content: \"no score content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n            .await\n            .unwrap();\n\n        let results = manager\n            .search_with_threshold(ctx, vec![], 10, 0.8, HashMap::new())\n            .await\n            .unwrap();\n\n        assert_eq!(results.len(), 1);\n        assert_eq!(results[0].id, \"no_score\");\n    }\n\n    #[tokio::test]\n    async fn test_add_to_layer_with_governance() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let provider = Box::new(MockProvider::new());\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let entry = MemoryEntry {\n            id: \"mem_1\".to_string(),\n            content: \"Contact user@example.com\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n            .await\n            .unwrap();\n\n        let retrieved = manager\n            .get_from_layer(ctx, MemoryLayer::User, \"mem_1\")\n            .await\n            .unwrap()\n            .unwrap();\n        assert_eq!(retrieved.content, \"Contact [REDACTED_EMAIL]\");\n    }\n\n    #[tokio::test]\n    async fn test_delete_from_layer() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let provider = Box::new(MockProvider::new());\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let entry = MemoryEntry {\n            id: \"mem_1\".to_string(),\n            content: \"test\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n            .await\n            .unwrap();\n        manager\n            .delete_from_layer(ctx.clone(), MemoryLayer::User, \"mem_1\")\n            .await\n            .unwrap();\n\n        let retrieved = manager\n            .get_from_layer(ctx, MemoryLayer::User, \"mem_1\")\n            .await\n            .unwrap();\n        assert!(retrieved.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_promote_memory_manual() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let mock_session = Box::new(MockProvider::new());\n        let mock_project = Box::new(MockProvider::new());\n        manager\n            .register_provider(MemoryLayer::Session, mock_session)\n            .await;\n        manager\n            .register_provider(MemoryLayer::Project, mock_project)\n            .await;\n\n        let entry = MemoryEntry {\n            id: \"session_mem\".to_string(),\n            content: \"to be promoted\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Session, entry)\n            .await\n            .unwrap();\n        manager\n            .promote_memory(\n                ctx.clone(),\n                \"session_mem\",\n                MemoryLayer::Session,\n                MemoryLayer::Project\n            )\n            .await\n            .unwrap();\n\n        let promoted = manager\n            .get_from_layer(ctx, MemoryLayer::Project, \"session_mem_promoted\")\n            .await\n            .unwrap();\n        assert!(promoted.is_some());\n    }\n\n    #[tokio::test]\n    async fn test_search_precedence_ordering() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let agent_provider = Box::new(MockProvider::new());\n        let user_provider = Box::new(MockProvider::new());\n\n        manager\n            .register_provider(MemoryLayer::Agent, agent_provider)\n            .await;\n        manager\n            .register_provider(MemoryLayer::User, user_provider)\n            .await;\n\n        let agent_entry = MemoryEntry {\n            id: \"agent_high_priority\".to_string(),\n            content: \"agent content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: {\n                let mut map = HashMap::new();\n                map.insert(\"score\".to_string(), serde_json::json!(0.5));\n                map\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n\n        let user_entry = MemoryEntry {\n            id: \"user_high_similarity\".to_string(),\n            content: \"user content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: {\n                let mut map = HashMap::new();\n                map.insert(\"score\".to_string(), serde_json::json!(0.9));\n                map\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Agent, agent_entry)\n            .await\n            .unwrap();\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, user_entry)\n            .await\n            .unwrap();\n\n        let results = manager\n            .search_hierarchical(ctx, vec![], 10, HashMap::new())\n            .await\n            .unwrap();\n\n        assert_eq!(results.len(), 2);\n        assert_eq!(results[0].id, \"agent_high_priority\");\n        assert_eq!(results[1].id, \"user_high_similarity\");\n    }\n\n    #[tokio::test]\n    async fn test_close_session_triggers_promotion() {\n        let manager = MemoryManager::new().with_config(config::MemoryConfig {\n            promotion_threshold: 0.5\n        });\n        let ctx = test_ctx();\n        let mock_session = Box::new(MockProvider::new());\n        let mock_project = Box::new(MockProvider::new());\n        manager\n            .register_provider(MemoryLayer::Session, mock_session)\n            .await;\n        manager\n            .register_provider(MemoryLayer::Project, mock_project)\n            .await;\n\n        let entry = MemoryEntry {\n            id: \"important\".to_string(),\n            content: \"highly important\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(1.0));\n                m\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Session, entry)\n            .await\n            .unwrap();\n        manager.close_session(ctx.clone(), \"some_id\").await.unwrap();\n\n        let promoted = manager\n            .list_all_from_layer(ctx, MemoryLayer::Project)\n            .await\n            .unwrap();\n        assert!(!promoted.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_search_text_with_threshold_requires_embedding_service() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let provider = Box::new(MockProvider::new());\n\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let result = manager\n            .search_text_with_threshold(ctx, \"test query\", 10, 0.7, HashMap::new())\n            .await;\n\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Embedding service not configured\")\n        );\n    }\n\n    #[tokio::test]\n    async fn test_hierarchical_search_provider_error() {\n        struct FailingProvider;\n        #[async_trait::async_trait]\n        impl mk_core::traits::MemoryProviderAdapter for FailingProvider {\n            type Error = Box\u003cdyn std::error::Error + Send + Sync\u003e;\n            async fn add(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry\n            ) -\u003e Result\u003cString, Self::Error\u003e {\n                Ok(\"id\".to_string())\n            }\n            async fn get(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _id: \u0026str\n            ) -\u003e Result\u003cOption\u003cMemoryEntry\u003e, Self::Error\u003e {\n                Ok(None)\n            }\n            async fn search(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _v: Vec\u003cf32\u003e,\n                _l: usize,\n                _f: HashMap\u003cString, serde_json::Value\u003e\n            ) -\u003e Result\u003cVec\u003cMemoryEntry\u003e, Self::Error\u003e {\n                Err(\"search failed\".into())\n            }\n            async fn update(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Ok(())\n            }\n            async fn delete(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _id: \u0026str\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Ok(())\n            }\n            async fn list(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _l: MemoryLayer,\n                _lim: usize,\n                _c: Option\u003cString\u003e\n            ) -\u003e Result\u003c(Vec\u003cMemoryEntry\u003e, Option\u003cString\u003e), Self::Error\u003e {\n                Ok((vec![], None))\n            }\n        }\n\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        manager\n            .register_provider(MemoryLayer::Agent, Box::new(FailingProvider))\n            .await;\n\n        let results = manager\n            .search_hierarchical(ctx, vec![0.0], 10, HashMap::new())\n            .await\n            .unwrap();\n        assert!(results.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_close_agent_triggers_promotion() {\n        let manager = MemoryManager::new().with_config(config::MemoryConfig {\n            promotion_threshold: 0.5,\n            ..Default::default()\n        });\n        let ctx = test_ctx();\n        let mock_agent = Box::new(MockProvider::new());\n        let mock_user = Box::new(MockProvider::new());\n        manager\n            .register_provider(MemoryLayer::Agent, mock_agent)\n            .await;\n        manager\n            .register_provider(MemoryLayer::User, mock_user)\n            .await;\n\n        let entry = MemoryEntry {\n            id: \"agent_mem\".to_string(),\n            content: \"agent memory content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(1.0));\n                m\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Agent, entry)\n            .await\n            .unwrap();\n        manager.close_agent(ctx.clone(), \"agent_id\").await.unwrap();\n\n        let promoted = manager\n            .list_all_from_layer(ctx, MemoryLayer::User)\n            .await\n            .unwrap();\n        assert!(!promoted.is_empty());\n        assert_eq!(\n            promoted[0].metadata.get(\"original_memory_id\").unwrap(),\n            \"agent_mem\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_search_text_with_threshold_success() {\n        use crate::embedding::mock::MockEmbeddingService;\n        let manager =\n            MemoryManager::new().with_embedding_service(Arc::new(MockEmbeddingService::new(1536)));\n        let ctx = test_ctx();\n\n        let provider = Box::new(MockProvider::new());\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let entry = MemoryEntry {\n            id: \"text_mem\".to_string(),\n            content: \"some text content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(0.9));\n                m\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n            .await\n            .unwrap();\n\n        let results = manager\n            .search_text_with_threshold(ctx, \"query\", 10, 0.5, HashMap::new())\n            .await\n            .unwrap();\n        assert_eq!(results.len(), 1);\n        assert_eq!(results[0].id, \"text_mem\");\n    }\n\n    #[tokio::test]\n    async fn test_with_telemetry_and_default() {\n        let telemetry = Arc::new(MemoryTelemetry::new());\n        let manager = MemoryManager::default().with_telemetry(telemetry);\n        assert!(manager.embedding_service.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_add_to_layer_no_provider() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let entry = MemoryEntry {\n            id: \"test\".to_string(),\n            content: \"test\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        let result = manager.add_to_layer(ctx, MemoryLayer::User, entry).await;\n        assert!(result.is_err());\n        assert_eq!(\n            result.unwrap_err().to_string(),\n            \"No provider registered for layer\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_search_with_threshold_provider_error() {\n        struct FailingProvider;\n        #[async_trait::async_trait]\n        impl mk_core::traits::MemoryProviderAdapter for FailingProvider {\n            type Error = Box\u003cdyn std::error::Error + Send + Sync\u003e;\n            async fn add(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry\n            ) -\u003e Result\u003cString, Self::Error\u003e {\n                Ok(\"id\".into())\n            }\n            async fn get(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _id: \u0026str\n            ) -\u003e Result\u003cOption\u003cMemoryEntry\u003e, Self::Error\u003e {\n                Ok(None)\n            }\n            async fn search(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _v: Vec\u003cf32\u003e,\n                _l: usize,\n                _f: HashMap\u003cString, serde_json::Value\u003e\n            ) -\u003e Result\u003cVec\u003cMemoryEntry\u003e, Self::Error\u003e {\n                Err(\"search failed\".into())\n            }\n            async fn update(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Ok(())\n            }\n            async fn delete(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _id: \u0026str\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Ok(())\n            }\n            async fn list(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _l: MemoryLayer,\n                _lim: usize,\n                _c: Option\u003cString\u003e\n            ) -\u003e Result\u003c(Vec\u003cMemoryEntry\u003e, Option\u003cString\u003e), Self::Error\u003e {\n                Ok((vec![], None))\n            }\n        }\n\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        manager\n            .register_provider(MemoryLayer::User, Box::new(FailingProvider))\n            .await;\n\n        let results = manager\n            .search_with_threshold(ctx, vec![0.0], 10, 0.5, HashMap::new())\n            .await\n            .unwrap();\n        assert!(results.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_promote_important_memories_error_mapping() {\n        struct ErrorProvider;\n        #[async_trait::async_trait]\n        impl mk_core::traits::MemoryProviderAdapter for ErrorProvider {\n            type Error = Box\u003cdyn std::error::Error + Send + Sync\u003e;\n            async fn add(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry\n            ) -\u003e Result\u003cString, Self::Error\u003e {\n                Ok(\"id\".into())\n            }\n            async fn get(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _id: \u0026str\n            ) -\u003e Result\u003cOption\u003cMemoryEntry\u003e, Self::Error\u003e {\n                Ok(None)\n            }\n            async fn search(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _v: Vec\u003cf32\u003e,\n                _l: usize,\n                _f: HashMap\u003cString, serde_json::Value\u003e\n            ) -\u003e Result\u003cVec\u003cMemoryEntry\u003e, Self::Error\u003e {\n                Err(\"list failed\".into())\n            }\n            async fn update(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Ok(())\n            }\n            async fn delete(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _id: \u0026str\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Ok(())\n            }\n            async fn list(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _l: MemoryLayer,\n                _lim: usize,\n                _c: Option\u003cString\u003e\n            ) -\u003e Result\u003c(Vec\u003cMemoryEntry\u003e, Option\u003cString\u003e), Self::Error\u003e {\n                Err(\"list failed\".into())\n            }\n        }\n\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        manager\n            .register_provider(MemoryLayer::Session, Box::new(ErrorProvider))\n            .await;\n\n        let result = manager\n            .promote_important_memories(ctx, MemoryLayer::Session)\n            .await;\n        assert!(result.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_add_to_layer_provider_error() {\n        struct FailingAddProvider;\n        #[async_trait::async_trait]\n        impl mk_core::traits::MemoryProviderAdapter for FailingAddProvider {\n            type Error = Box\u003cdyn std::error::Error + Send + Sync\u003e;\n            async fn add(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry\n            ) -\u003e Result\u003cString, Self::Error\u003e {\n                Err(\"add failed\".into())\n            }\n            async fn get(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _id: \u0026str\n            ) -\u003e Result\u003cOption\u003cMemoryEntry\u003e, Self::Error\u003e {\n                Ok(None)\n            }\n            async fn search(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _v: Vec\u003cf32\u003e,\n                _l: usize,\n                _f: HashMap\u003cString, serde_json::Value\u003e\n            ) -\u003e Result\u003cVec\u003cMemoryEntry\u003e, Self::Error\u003e {\n                Ok(vec![])\n            }\n            async fn update(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Ok(())\n            }\n            async fn delete(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _id: \u0026str\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Ok(())\n            }\n            async fn list(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _l: MemoryLayer,\n                _lim: usize,\n                _c: Option\u003cString\u003e\n            ) -\u003e Result\u003c(Vec\u003cMemoryEntry\u003e, Option\u003cString\u003e), Self::Error\u003e {\n                Ok((vec![], None))\n            }\n        }\n\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        manager\n            .register_provider(MemoryLayer::User, Box::new(FailingAddProvider))\n            .await;\n\n        let entry = MemoryEntry {\n            id: \"test\".to_string(),\n            content: \"test\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        let result = manager.add_to_layer(ctx, MemoryLayer::User, entry).await;\n        assert!(result.is_err());\n        assert_eq!(result.unwrap_err().to_string(), \"add failed\");\n    }\n}\n","traces":[{"line":33,"address":[],"length":0,"stats":{"Line":82}},{"line":35,"address":[],"length":0,"stats":{"Line":328}},{"line":37,"address":[],"length":0,"stats":{"Line":246}},{"line":39,"address":[],"length":0,"stats":{"Line":164}},{"line":40,"address":[],"length":0,"stats":{"Line":82}},{"line":44,"address":[],"length":0,"stats":{"Line":2}},{"line":45,"address":[],"length":0,"stats":{"Line":2}},{"line":46,"address":[],"length":0,"stats":{"Line":2}},{"line":49,"address":[],"length":0,"stats":{"Line":2}},{"line":55,"address":[],"length":0,"stats":{"Line":4}},{"line":56,"address":[],"length":0,"stats":{"Line":2}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":1}},{"line":72,"address":[],"length":0,"stats":{"Line":2}},{"line":73,"address":[],"length":0,"stats":{"Line":1}},{"line":78,"address":[],"length":0,"stats":{"Line":1}},{"line":79,"address":[],"length":0,"stats":{"Line":1}},{"line":84,"address":[],"length":0,"stats":{"Line":50}},{"line":93,"address":[],"length":0,"stats":{"Line":100}},{"line":94,"address":[],"length":0,"stats":{"Line":150}},{"line":97,"address":[],"length":0,"stats":{"Line":3}},{"line":104,"address":[],"length":0,"stats":{"Line":3}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":6}},{"line":114,"address":[],"length":0,"stats":{"Line":6}},{"line":115,"address":[],"length":0,"stats":{"Line":6}},{"line":117,"address":[],"length":0,"stats":{"Line":16}},{"line":118,"address":[],"length":0,"stats":{"Line":15}},{"line":119,"address":[],"length":0,"stats":{"Line":20}},{"line":120,"address":[],"length":0,"stats":{"Line":5}},{"line":121,"address":[],"length":0,"stats":{"Line":40}},{"line":122,"address":[],"length":0,"stats":{"Line":5}},{"line":124,"address":[],"length":0,"stats":{"Line":4}},{"line":125,"address":[],"length":0,"stats":{"Line":12}},{"line":127,"address":[],"length":0,"stats":{"Line":8}},{"line":128,"address":[],"length":0,"stats":{"Line":4}},{"line":130,"address":[],"length":0,"stats":{"Line":16}},{"line":131,"address":[],"length":0,"stats":{"Line":8}},{"line":132,"address":[],"length":0,"stats":{"Line":8}},{"line":135,"address":[],"length":0,"stats":{"Line":1}},{"line":136,"address":[],"length":0,"stats":{"Line":2}},{"line":137,"address":[],"length":0,"stats":{"Line":4}},{"line":138,"address":[],"length":0,"stats":{"Line":1}},{"line":143,"address":[],"length":0,"stats":{"Line":12}},{"line":145,"address":[],"length":0,"stats":{"Line":21}},{"line":146,"address":[],"length":0,"stats":{"Line":6}},{"line":147,"address":[],"length":0,"stats":{"Line":12}},{"line":148,"address":[],"length":0,"stats":{"Line":3}},{"line":151,"address":[],"length":0,"stats":{"Line":7}},{"line":159,"address":[],"length":0,"stats":{"Line":14}},{"line":160,"address":[],"length":0,"stats":{"Line":14}},{"line":162,"address":[],"length":0,"stats":{"Line":28}},{"line":163,"address":[],"length":0,"stats":{"Line":7}},{"line":164,"address":[],"length":0,"stats":{"Line":56}},{"line":165,"address":[],"length":0,"stats":{"Line":7}},{"line":167,"address":[],"length":0,"stats":{"Line":6}},{"line":168,"address":[],"length":0,"stats":{"Line":20}},{"line":169,"address":[],"length":0,"stats":{"Line":14}},{"line":170,"address":[],"length":0,"stats":{"Line":7}},{"line":172,"address":[],"length":0,"stats":{"Line":17}},{"line":173,"address":[],"length":0,"stats":{"Line":12}},{"line":176,"address":[],"length":0,"stats":{"Line":13}},{"line":177,"address":[],"length":0,"stats":{"Line":12}},{"line":178,"address":[],"length":0,"stats":{"Line":12}},{"line":182,"address":[],"length":0,"stats":{"Line":2}},{"line":186,"address":[],"length":0,"stats":{"Line":17}},{"line":188,"address":[],"length":0,"stats":{"Line":28}},{"line":191,"address":[],"length":0,"stats":{"Line":6}},{"line":199,"address":[],"length":0,"stats":{"Line":9}},{"line":200,"address":[],"length":0,"stats":{"Line":6}},{"line":204,"address":[],"length":0,"stats":{"Line":9}},{"line":206,"address":[],"length":0,"stats":{"Line":21}},{"line":207,"address":[],"length":0,"stats":{"Line":3}},{"line":210,"address":[],"length":0,"stats":{"Line":1044}},{"line":216,"address":[],"length":0,"stats":{"Line":1044}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":221,"address":[],"length":0,"stats":{"Line":0}},{"line":225,"address":[],"length":0,"stats":{"Line":2088}},{"line":226,"address":[],"length":0,"stats":{"Line":3132}},{"line":227,"address":[],"length":0,"stats":{"Line":4176}},{"line":229,"address":[],"length":0,"stats":{"Line":3132}},{"line":230,"address":[],"length":0,"stats":{"Line":3132}},{"line":231,"address":[],"length":0,"stats":{"Line":1045}},{"line":232,"address":[],"length":0,"stats":{"Line":2}},{"line":235,"address":[],"length":0,"stats":{"Line":2088}},{"line":236,"address":[],"length":0,"stats":{"Line":3131}},{"line":237,"address":[],"length":0,"stats":{"Line":1044}},{"line":240,"address":[],"length":0,"stats":{"Line":5215}},{"line":241,"address":[],"length":0,"stats":{"Line":1042}},{"line":242,"address":[],"length":0,"stats":{"Line":3126}},{"line":244,"address":[],"length":0,"stats":{"Line":2084}},{"line":245,"address":[],"length":0,"stats":{"Line":1042}},{"line":247,"address":[],"length":0,"stats":{"Line":1042}},{"line":249,"address":[],"length":0,"stats":{"Line":1}},{"line":250,"address":[],"length":0,"stats":{"Line":2}},{"line":251,"address":[],"length":0,"stats":{"Line":4}},{"line":252,"address":[],"length":0,"stats":{"Line":1}},{"line":257,"address":[],"length":0,"stats":{"Line":16}},{"line":263,"address":[],"length":0,"stats":{"Line":32}},{"line":264,"address":[],"length":0,"stats":{"Line":42}},{"line":265,"address":[],"length":0,"stats":{"Line":16}},{"line":267,"address":[],"length":0,"stats":{"Line":40}},{"line":270,"address":[],"length":0,"stats":{"Line":1016}},{"line":276,"address":[],"length":0,"stats":{"Line":2032}},{"line":277,"address":[],"length":0,"stats":{"Line":3048}},{"line":278,"address":[],"length":0,"stats":{"Line":1016}},{"line":281,"address":[],"length":0,"stats":{"Line":6096}},{"line":283,"address":[],"length":0,"stats":{"Line":2028}},{"line":284,"address":[],"length":0,"stats":{"Line":3036}},{"line":285,"address":[],"length":0,"stats":{"Line":2024}},{"line":286,"address":[],"length":0,"stats":{"Line":1012}},{"line":287,"address":[],"length":0,"stats":{"Line":2024}},{"line":288,"address":[],"length":0,"stats":{"Line":1016}},{"line":289,"address":[],"length":0,"stats":{"Line":1012}},{"line":292,"address":[],"length":0,"stats":{"Line":1012}},{"line":293,"address":[],"length":0,"stats":{"Line":1012}},{"line":294,"address":[],"length":0,"stats":{"Line":4048}},{"line":295,"address":[],"length":0,"stats":{"Line":1012}},{"line":296,"address":[],"length":0,"stats":{"Line":1012}},{"line":297,"address":[],"length":0,"stats":{"Line":4048}},{"line":298,"address":[],"length":0,"stats":{"Line":1012}},{"line":300,"address":[],"length":0,"stats":{"Line":5060}},{"line":301,"address":[],"length":0,"stats":{"Line":1012}},{"line":303,"address":[],"length":0,"stats":{"Line":4}},{"line":307,"address":[],"length":0,"stats":{"Line":5}},{"line":312,"address":[],"length":0,"stats":{"Line":10}},{"line":313,"address":[],"length":0,"stats":{"Line":15}},{"line":314,"address":[],"length":0,"stats":{"Line":5}},{"line":317,"address":[],"length":0,"stats":{"Line":30}},{"line":318,"address":[],"length":0,"stats":{"Line":4}},{"line":321,"address":[],"length":0,"stats":{"Line":1}},{"line":328,"address":[],"length":0,"stats":{"Line":3}},{"line":329,"address":[],"length":0,"stats":{"Line":5}},{"line":330,"address":[],"length":0,"stats":{"Line":1}},{"line":331,"address":[],"length":0,"stats":{"Line":1}},{"line":333,"address":[],"length":0,"stats":{"Line":3}},{"line":334,"address":[],"length":0,"stats":{"Line":3}},{"line":335,"address":[],"length":0,"stats":{"Line":1}},{"line":337,"address":[],"length":0,"stats":{"Line":3}},{"line":338,"address":[],"length":0,"stats":{"Line":2}},{"line":339,"address":[],"length":0,"stats":{"Line":2}},{"line":340,"address":[],"length":0,"stats":{"Line":1}},{"line":342,"address":[],"length":0,"stats":{"Line":1}},{"line":343,"address":[],"length":0,"stats":{"Line":1}},{"line":344,"address":[],"length":0,"stats":{"Line":4}},{"line":346,"address":[],"length":0,"stats":{"Line":5}},{"line":349,"address":[],"length":0,"stats":{"Line":3}},{"line":355,"address":[],"length":0,"stats":{"Line":12}},{"line":356,"address":[],"length":0,"stats":{"Line":9}},{"line":357,"address":[],"length":0,"stats":{"Line":9}},{"line":358,"address":[],"length":0,"stats":{"Line":9}},{"line":359,"address":[],"length":0,"stats":{"Line":9}},{"line":360,"address":[],"length":0,"stats":{"Line":9}},{"line":361,"address":[],"length":0,"stats":{"Line":3}},{"line":363,"address":[],"length":0,"stats":{"Line":9}},{"line":364,"address":[],"length":0,"stats":{"Line":9}},{"line":366,"address":[],"length":0,"stats":{"Line":6}},{"line":367,"address":[],"length":0,"stats":{"Line":12}},{"line":368,"address":[],"length":0,"stats":{"Line":3}},{"line":369,"address":[],"length":0,"stats":{"Line":4}},{"line":370,"address":[],"length":0,"stats":{"Line":3}},{"line":371,"address":[],"length":0,"stats":{"Line":2}},{"line":372,"address":[],"length":0,"stats":{"Line":2}},{"line":373,"address":[],"length":0,"stats":{"Line":1}},{"line":377,"address":[],"length":0,"stats":{"Line":1}},{"line":382,"address":[],"length":0,"stats":{"Line":1}},{"line":384,"address":[],"length":0,"stats":{"Line":5}},{"line":385,"address":[],"length":0,"stats":{"Line":1}},{"line":387,"address":[],"length":0,"stats":{"Line":5}},{"line":388,"address":[],"length":0,"stats":{"Line":1}},{"line":390,"address":[],"length":0,"stats":{"Line":1}},{"line":393,"address":[],"length":0,"stats":{"Line":1}},{"line":398,"address":[],"length":0,"stats":{"Line":1}},{"line":400,"address":[],"length":0,"stats":{"Line":5}},{"line":401,"address":[],"length":0,"stats":{"Line":1}},{"line":403,"address":[],"length":0,"stats":{"Line":5}},{"line":404,"address":[],"length":0,"stats":{"Line":1}},{"line":406,"address":[],"length":0,"stats":{"Line":1}}],"covered":174,"coverable":185},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","opencode.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","pointer.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","pool.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","postgres.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","procedural.rs"],"content":"\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","promotion","mod.rs"],"content":"use crate::governance::GovernanceService;\nuse crate::manager::MemoryManager;\nuse crate::telemetry::MemoryTelemetry;\nuse anyhow::{Context, Result};\nuse mk_core::types::{MemoryEntry, MemoryLayer};\nuse std::sync::Arc;\n\npub struct PromotionService {\n    memory_manager: Arc\u003cMemoryManager\u003e,\n    governance_service: Arc\u003cGovernanceService\u003e,\n    telemetry: Arc\u003cMemoryTelemetry\u003e,\n    config: config::MemoryConfig,\n    promote_important: bool,\n    cleanup_after_promotion: bool\n}\n\nimpl PromotionService {\n    pub fn new(memory_manager: Arc\u003cMemoryManager\u003e) -\u003e Self {\n        Self {\n            memory_manager,\n            governance_service: Arc::new(GovernanceService::new()),\n            telemetry: Arc::new(MemoryTelemetry::new()),\n            config: config::MemoryConfig::default(),\n            promote_important: true,\n            cleanup_after_promotion: false\n        }\n    }\n\n    pub fn with_config(mut self, config: config::MemoryConfig) -\u003e Self {\n        self.config = config;\n        self\n    }\n\n    pub fn with_telemetry(mut self, telemetry: Arc\u003cMemoryTelemetry\u003e) -\u003e Self {\n        self.telemetry = telemetry;\n        self\n    }\n\n    pub fn with_promote_important(mut self, promote: bool) -\u003e Self {\n        self.promote_important = promote;\n        self\n    }\n\n    pub fn with_cleanup(mut self, cleanup: bool) -\u003e Self {\n        self.cleanup_after_promotion = cleanup;\n        self\n    }\n\n    pub async fn evaluate_and_promote(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        entry: \u0026MemoryEntry\n    ) -\u003e Result\u003cOption\u003cString\u003e\u003e {\n        if !self.promote_important {\n            return Ok(None);\n        }\n\n        let metadata_value = serde_json::to_value(\u0026entry.metadata).unwrap_or(serde_json::json!({}));\n        if !self\n            .governance_service\n            .can_promote(\u0026entry.content, \u0026metadata_value)\n        {\n            tracing::info!(\"Memory {} promotion blocked by governance\", entry.id);\n            self.telemetry\n                .record_promotion_blocked(\u0026format!(\"{:?}\", entry.layer), \"governance\");\n            return Ok(None);\n        }\n\n        let score = self.calculate_importance_score(entry);\n\n        if score \u003e= self.config.promotion_threshold {\n            if let Some(target) = self.determine_target_layer(entry.layer) {\n                self.telemetry.record_promotion_attempt(\n                    \u0026format!(\"{:?}\", entry.layer),\n                    \u0026format!(\"{:?}\", target)\n                );\n                tracing::info!(\n                    \"Promoting memory {} from {:?} to {:?} (score: {:.2})\",\n                    entry.id,\n                    entry.layer,\n                    target,\n                    score\n                );\n\n                let mut promoted_entry = entry.clone();\n                promoted_entry.id = format!(\"{}_promoted\", entry.id);\n                promoted_entry.layer = target;\n                let original_content = entry.content.clone();\n                promoted_entry.content = self.governance_service.redact_pii(\u0026entry.content);\n\n                if promoted_entry.content != original_content {\n                    self.telemetry\n                        .record_governance_redaction(\u0026format!(\"{:?}\", target));\n                }\n\n                promoted_entry.metadata.insert(\n                    \"original_memory_id\".to_string(),\n                    serde_json::json!(entry.id)\n                );\n                promoted_entry.metadata.insert(\n                    \"promoted_at\".to_string(),\n                    serde_json::json!(chrono::Utc::now().timestamp())\n                );\n                promoted_entry\n                    .metadata\n                    .insert(\"promotion_score\".to_string(), serde_json::json!(score));\n\n                let new_id = self\n                    .memory_manager\n                    .add_to_layer(ctx.clone(), target, promoted_entry)\n                    .await\n                    .map_err(|e| anyhow::anyhow!(e))\n                    .context(\"Failed to add promoted memory to target layer\")?;\n\n                if self.cleanup_after_promotion {\n                    self.memory_manager\n                        .delete_from_layer(ctx, entry.layer, \u0026entry.id)\n                        .await\n                        .map_err(|e| anyhow::anyhow!(e))\n                        .context(\"Failed to cleanup source memory after promotion\")?;\n                    tracing::info!(\n                        \"Cleaned up source memory {} from {:?}\",\n                        entry.id,\n                        entry.layer\n                    );\n                }\n\n                self.telemetry.record_promotion_success(\n                    \u0026format!(\"{:?}\", entry.layer),\n                    \u0026format!(\"{:?}\", target)\n                );\n                return Ok(Some(new_id));\n            }\n        }\n\n        Ok(None)\n    }\n\n    fn calculate_importance_score(\u0026self, entry: \u0026MemoryEntry) -\u003e f32 {\n        let explicit_score = entry\n            .metadata\n            .get(\"score\")\n            .and_then(|v| v.as_f64())\n            .map(|v| v as f32)\n            .unwrap_or(0.0);\n\n        let access_count = entry\n            .metadata\n            .get(\"access_count\")\n            .and_then(|v| v.as_u64())\n            .unwrap_or(1) as f32;\n\n        let last_accessed = entry\n            .metadata\n            .get(\"last_accessed_at\")\n            .and_then(|v| v.as_i64())\n            .unwrap_or_else(|| chrono::Utc::now().timestamp()) as f32;\n\n        let now_ts = chrono::Utc::now().timestamp() as f32;\n        let days_since_last_access = (now_ts - last_accessed).max(0.0) / 86400.0;\n        let recency_score = (1.0f32 - days_since_last_access).max(0.0f32);\n\n        let frequency_score = (access_count / 10.0).min(1.0);\n\n        (explicit_score * 0.6) + (frequency_score * 0.3) + (recency_score * 0.1)\n    }\n\n    pub async fn promote_layer_memories(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer,\n        _identifiers: \u0026mk_core::types::LayerIdentifiers\n    ) -\u003e Result\u003cVec\u003cString\u003e\u003e {\n        let entries = self\n            .memory_manager\n            .list_all_from_layer(ctx.clone(), layer)\n            .await\n            .map_err(|e| anyhow::anyhow!(e))?;\n\n        let mut promoted_ids = Vec::new();\n        for entry in entries {\n            if let Some(new_id) = self.evaluate_and_promote(ctx.clone(), \u0026entry).await? {\n                promoted_ids.push(new_id);\n            }\n        }\n        Ok(promoted_ids)\n    }\n\n    fn determine_target_layer(\u0026self, current_layer: MemoryLayer) -\u003e Option\u003cMemoryLayer\u003e {\n        match current_layer {\n            MemoryLayer::Agent =\u003e Some(MemoryLayer::User),\n            MemoryLayer::Session =\u003e Some(MemoryLayer::Project),\n            _ =\u003e None\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::manager::tests::test_ctx;\n    use crate::providers::MockProvider;\n    use mk_core::types::MemoryEntry;\n    use std::collections::HashMap;\n\n    #[tokio::test]\n    async fn test_evaluate_and_promote_high_score() {\n        let manager = Arc::new(MemoryManager::new());\n        let ctx = test_ctx();\n        let mock_session = Box::new(MockProvider::new());\n        let mock_project = Box::new(MockProvider::new());\n\n        manager\n            .register_provider(MemoryLayer::Session, mock_session)\n            .await;\n        manager\n            .register_provider(MemoryLayer::Project, mock_project)\n            .await;\n\n        let service = PromotionService::new(manager.clone()).with_config(config::MemoryConfig {\n            promotion_threshold: 0.7\n        });\n\n        let entry = MemoryEntry {\n            id: \"mem_1\".to_string(),\n            content: \"important stuff\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(1.0));\n                m.insert(\"access_count\".to_string(), serde_json::json!(10));\n                m.insert(\n                    \"last_accessed_at\".to_string(),\n                    serde_json::json!(chrono::Utc::now().timestamp())\n                );\n                m\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n\n        let result = service\n            .evaluate_and_promote(ctx.clone(), \u0026entry)\n            .await\n            .unwrap();\n        assert!(result.is_some());\n        assert!(result.unwrap().contains(\"mem_1_promoted\"));\n\n        let promoted = manager\n            .get_from_layer(ctx.clone(), MemoryLayer::Project, \"mem_1_promoted\")\n            .await\n            .unwrap();\n        assert!(promoted.is_some());\n        assert_eq!(\n            promoted\n                .unwrap()\n                .metadata\n                .get(\"original_memory_id\")\n                .unwrap(),\n            \"mem_1\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_evaluate_and_promote_low_score() {\n        let manager = Arc::new(MemoryManager::new());\n        let ctx = test_ctx();\n        let service = PromotionService::new(manager).with_config(config::MemoryConfig {\n            promotion_threshold: 0.8\n        });\n\n        let entry = MemoryEntry {\n            id: \"mem_low\".to_string(),\n            content: \"boring stuff\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(0.2));\n                m\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n\n        let result = service.evaluate_and_promote(ctx, \u0026entry).await.unwrap();\n        assert!(result.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_promotion_blocked_by_governance() {\n        let manager = Arc::new(MemoryManager::new());\n        let ctx = test_ctx();\n        let service = PromotionService::new(manager);\n\n        let entry = MemoryEntry {\n            id: \"mem_sensitive\".to_string(),\n            content: \"secret stuff\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(1.0));\n                m.insert(\"sensitive\".to_string(), serde_json::json!(true));\n                m\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n\n        let result = service.evaluate_and_promote(ctx, \u0026entry).await.unwrap();\n        assert!(result.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_promotion_redacts_pii() {\n        let manager = Arc::new(MemoryManager::new());\n        let ctx = test_ctx();\n        let mock_session = Box::new(MockProvider::new());\n        let mock_project = Box::new(MockProvider::new());\n        manager\n            .register_provider(MemoryLayer::Session, mock_session)\n            .await;\n        manager\n            .register_provider(MemoryLayer::Project, mock_project)\n            .await;\n\n        let service = PromotionService::new(manager.clone()).with_config(config::MemoryConfig {\n            promotion_threshold: 0.0\n        });\n\n        let entry = MemoryEntry {\n            id: \"mem_pii\".to_string(),\n            content: \"Contact user@example.com\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        let result = service\n            .evaluate_and_promote(ctx.clone(), \u0026entry)\n            .await\n            .unwrap();\n        assert!(result.is_some());\n\n        let promoted = manager\n            .get_from_layer(ctx, MemoryLayer::Project, result.unwrap().as_str())\n            .await\n            .unwrap()\n            .unwrap();\n        assert_eq!(promoted.content, \"Contact [REDACTED_EMAIL]\");\n    }\n\n    #[tokio::test]\n    async fn test_promotion_cleanup() {\n        let manager = Arc::new(MemoryManager::new());\n        let ctx = test_ctx();\n        let mock_session = Box::new(MockProvider::new());\n        let mock_project = Box::new(MockProvider::new());\n        manager\n            .register_provider(MemoryLayer::Session, mock_session)\n            .await;\n        manager\n            .register_provider(MemoryLayer::Project, mock_project)\n            .await;\n\n        let service = PromotionService::new(manager.clone())\n            .with_config(config::MemoryConfig {\n                promotion_threshold: 0.0\n            })\n            .with_cleanup(true);\n\n        let entry = MemoryEntry {\n            id: \"mem_cleanup\".to_string(),\n            content: \"cleanup test\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Session, entry.clone())\n            .await\n            .unwrap();\n\n        let result = service\n            .evaluate_and_promote(ctx.clone(), \u0026entry)\n            .await\n            .unwrap();\n        assert!(result.is_some());\n\n        let promoted = manager\n            .get_from_layer(ctx.clone(), MemoryLayer::Project, result.unwrap().as_str())\n            .await\n            .unwrap();\n        assert!(promoted.is_some());\n\n        let original = manager\n            .get_from_layer(ctx, MemoryLayer::Session, \"mem_cleanup\")\n            .await\n            .unwrap();\n        assert!(original.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_with_promote_important_false() {\n        let manager = Arc::new(MemoryManager::new());\n        let ctx = test_ctx();\n        let service = PromotionService::new(manager).with_promote_important(false);\n\n        let entry = MemoryEntry {\n            id: \"test\".to_string(),\n            content: \"test\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        let result = service.evaluate_and_promote(ctx, \u0026entry).await.unwrap();\n        assert!(result.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_determine_target_layer_none() {\n        let manager = Arc::new(MemoryManager::new());\n        let ctx = test_ctx();\n        let service = PromotionService::new(manager);\n\n        let entry = MemoryEntry {\n            id: \"test\".to_string(),\n            content: \"test\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        let result = service.evaluate_and_promote(ctx, \u0026entry).await.unwrap();\n        assert!(result.is_none());\n    }\n}\n","traces":[{"line":18,"address":[],"length":0,"stats":{"Line":10}},{"line":21,"address":[],"length":0,"stats":{"Line":30}},{"line":22,"address":[],"length":0,"stats":{"Line":20}},{"line":23,"address":[],"length":0,"stats":{"Line":10}},{"line":29,"address":[],"length":0,"stats":{"Line":7}},{"line":30,"address":[],"length":0,"stats":{"Line":7}},{"line":31,"address":[],"length":0,"stats":{"Line":7}},{"line":34,"address":[],"length":0,"stats":{"Line":3}},{"line":35,"address":[],"length":0,"stats":{"Line":6}},{"line":36,"address":[],"length":0,"stats":{"Line":3}},{"line":39,"address":[],"length":0,"stats":{"Line":1}},{"line":40,"address":[],"length":0,"stats":{"Line":1}},{"line":41,"address":[],"length":0,"stats":{"Line":1}},{"line":44,"address":[],"length":0,"stats":{"Line":1}},{"line":45,"address":[],"length":0,"stats":{"Line":1}},{"line":46,"address":[],"length":0,"stats":{"Line":1}},{"line":49,"address":[],"length":0,"stats":{"Line":9}},{"line":54,"address":[],"length":0,"stats":{"Line":9}},{"line":55,"address":[],"length":0,"stats":{"Line":1}},{"line":58,"address":[],"length":0,"stats":{"Line":40}},{"line":59,"address":[],"length":0,"stats":{"Line":16}},{"line":60,"address":[],"length":0,"stats":{"Line":16}},{"line":61,"address":[],"length":0,"stats":{"Line":16}},{"line":63,"address":[],"length":0,"stats":{"Line":1}},{"line":64,"address":[],"length":0,"stats":{"Line":2}},{"line":65,"address":[],"length":0,"stats":{"Line":2}},{"line":66,"address":[],"length":0,"stats":{"Line":1}},{"line":69,"address":[],"length":0,"stats":{"Line":28}},{"line":71,"address":[],"length":0,"stats":{"Line":7}},{"line":72,"address":[],"length":0,"stats":{"Line":15}},{"line":73,"address":[],"length":0,"stats":{"Line":15}},{"line":74,"address":[],"length":0,"stats":{"Line":10}},{"line":75,"address":[],"length":0,"stats":{"Line":5}},{"line":77,"address":[],"length":0,"stats":{"Line":5}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":15}},{"line":86,"address":[],"length":0,"stats":{"Line":15}},{"line":87,"address":[],"length":0,"stats":{"Line":5}},{"line":88,"address":[],"length":0,"stats":{"Line":15}},{"line":89,"address":[],"length":0,"stats":{"Line":15}},{"line":91,"address":[],"length":0,"stats":{"Line":6}},{"line":92,"address":[],"length":0,"stats":{"Line":2}},{"line":93,"address":[],"length":0,"stats":{"Line":2}},{"line":96,"address":[],"length":0,"stats":{"Line":10}},{"line":97,"address":[],"length":0,"stats":{"Line":10}},{"line":98,"address":[],"length":0,"stats":{"Line":5}},{"line":100,"address":[],"length":0,"stats":{"Line":10}},{"line":101,"address":[],"length":0,"stats":{"Line":10}},{"line":102,"address":[],"length":0,"stats":{"Line":15}},{"line":104,"address":[],"length":0,"stats":{"Line":5}},{"line":105,"address":[],"length":0,"stats":{"Line":5}},{"line":106,"address":[],"length":0,"stats":{"Line":20}},{"line":108,"address":[],"length":0,"stats":{"Line":15}},{"line":109,"address":[],"length":0,"stats":{"Line":10}},{"line":110,"address":[],"length":0,"stats":{"Line":20}},{"line":111,"address":[],"length":0,"stats":{"Line":5}},{"line":112,"address":[],"length":0,"stats":{"Line":5}},{"line":115,"address":[],"length":0,"stats":{"Line":5}},{"line":116,"address":[],"length":0,"stats":{"Line":2}},{"line":117,"address":[],"length":0,"stats":{"Line":3}},{"line":118,"address":[],"length":0,"stats":{"Line":1}},{"line":119,"address":[],"length":0,"stats":{"Line":1}},{"line":121,"address":[],"length":0,"stats":{"Line":1}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":15}},{"line":129,"address":[],"length":0,"stats":{"Line":10}},{"line":130,"address":[],"length":0,"stats":{"Line":5}},{"line":132,"address":[],"length":0,"stats":{"Line":5}},{"line":136,"address":[],"length":0,"stats":{"Line":2}},{"line":139,"address":[],"length":0,"stats":{"Line":7}},{"line":140,"address":[],"length":0,"stats":{"Line":14}},{"line":141,"address":[],"length":0,"stats":{"Line":7}},{"line":143,"address":[],"length":0,"stats":{"Line":15}},{"line":144,"address":[],"length":0,"stats":{"Line":11}},{"line":147,"address":[],"length":0,"stats":{"Line":14}},{"line":148,"address":[],"length":0,"stats":{"Line":7}},{"line":149,"address":[],"length":0,"stats":{"Line":14}},{"line":150,"address":[],"length":0,"stats":{"Line":9}},{"line":151,"address":[],"length":0,"stats":{"Line":7}},{"line":153,"address":[],"length":0,"stats":{"Line":14}},{"line":154,"address":[],"length":0,"stats":{"Line":7}},{"line":155,"address":[],"length":0,"stats":{"Line":14}},{"line":156,"address":[],"length":0,"stats":{"Line":9}},{"line":157,"address":[],"length":0,"stats":{"Line":19}},{"line":159,"address":[],"length":0,"stats":{"Line":14}},{"line":160,"address":[],"length":0,"stats":{"Line":14}},{"line":161,"address":[],"length":0,"stats":{"Line":21}},{"line":163,"address":[],"length":0,"stats":{"Line":21}},{"line":165,"address":[],"length":0,"stats":{"Line":7}},{"line":168,"address":[],"length":0,"stats":{"Line":3}},{"line":174,"address":[],"length":0,"stats":{"Line":8}},{"line":175,"address":[],"length":0,"stats":{"Line":6}},{"line":176,"address":[],"length":0,"stats":{"Line":9}},{"line":177,"address":[],"length":0,"stats":{"Line":3}},{"line":178,"address":[],"length":0,"stats":{"Line":6}},{"line":180,"address":[],"length":0,"stats":{"Line":4}},{"line":181,"address":[],"length":0,"stats":{"Line":6}},{"line":182,"address":[],"length":0,"stats":{"Line":14}},{"line":183,"address":[],"length":0,"stats":{"Line":4}},{"line":186,"address":[],"length":0,"stats":{"Line":2}},{"line":189,"address":[],"length":0,"stats":{"Line":5}},{"line":190,"address":[],"length":0,"stats":{"Line":5}},{"line":191,"address":[],"length":0,"stats":{"Line":1}},{"line":192,"address":[],"length":0,"stats":{"Line":4}},{"line":193,"address":[],"length":0,"stats":{"Line":0}}],"covered":102,"coverable":105},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","providers","mod.rs"],"content":"pub mod qdrant;\n\nuse async_trait::async_trait;\nuse mk_core::traits::MemoryProviderAdapter;\nuse mk_core::types::{MemoryEntry, MemoryLayer};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\npub struct MockProvider {\n    entries: Arc\u003cRwLock\u003cHashMap\u003cString, MemoryEntry\u003e\u003e\u003e\n}\n\nimpl MockProvider {\n    pub fn new() -\u003e Self {\n        Self {\n            entries: Arc::new(RwLock::new(HashMap::new()))\n        }\n    }\n}\n\nimpl Default for MockProvider {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\n#[async_trait]\nimpl MemoryProviderAdapter for MockProvider {\n    type Error = Box\u003cdyn std::error::Error + Send + Sync\u003e;\n\n    async fn add(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        entry: MemoryEntry\n    ) -\u003e Result\u003cString, Self::Error\u003e {\n        let mut entries = self.entries.write().await;\n        let id = entry.id.clone();\n        let mut entry = entry;\n        entry\n            .metadata\n            .insert(\"tenant_id\".to_string(), serde_json::json!(ctx.tenant_id));\n        entries.insert(id.clone(), entry);\n        Ok(id)\n    }\n\n    async fn search(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        _query_vector: Vec\u003cf32\u003e,\n        limit: usize,\n        filters: HashMap\u003cString, serde_json::Value\u003e\n    ) -\u003e Result\u003cVec\u003cMemoryEntry\u003e, Self::Error\u003e {\n        let entries = self.entries.read().await;\n        let results: Vec\u003cMemoryEntry\u003e = entries\n            .values()\n            .filter(|entry| {\n                // Ensure tenant isolation in mock search\n                if entry.metadata.get(\"tenant_id\") != Some(\u0026serde_json::json!(ctx.tenant_id)) {\n                    return false;\n                }\n                for (key, val) in \u0026filters {\n                    if entry.metadata.get(key) != Some(val) {\n                        return false;\n                    }\n                }\n                true\n            })\n            .take(limit)\n            .cloned()\n            .collect();\n        Ok(results)\n    }\n\n    async fn get(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        id: \u0026str\n    ) -\u003e Result\u003cOption\u003cMemoryEntry\u003e, Self::Error\u003e {\n        let entries = self.entries.read().await;\n        if let Some(entry) = entries.get(id) {\n            if entry.metadata.get(\"tenant_id\") == Some(\u0026serde_json::json!(ctx.tenant_id)) {\n                return Ok(Some(entry.clone()));\n            }\n        }\n        Ok(None)\n    }\n\n    async fn update(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        entry: MemoryEntry\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        let mut entries = self.entries.write().await;\n        if let Some(existing) = entries.get(\u0026entry.id) {\n            if existing.metadata.get(\"tenant_id\") == Some(\u0026serde_json::json!(ctx.tenant_id)) {\n                let mut entry = entry;\n                entry\n                    .metadata\n                    .insert(\"tenant_id\".to_string(), serde_json::json!(ctx.tenant_id));\n                entries.insert(entry.id.clone(), entry);\n                return Ok(());\n            }\n        }\n        Err(\"Entry not found or access denied\".into())\n    }\n\n    async fn delete(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        id: \u0026str\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        let mut entries = self.entries.write().await;\n        if let Some(existing) = entries.get(id) {\n            if existing.metadata.get(\"tenant_id\") == Some(\u0026serde_json::json!(ctx.tenant_id)) {\n                entries.remove(id);\n            }\n        }\n        Ok(())\n    }\n\n    async fn list(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer,\n        limit: usize,\n        cursor: Option\u003cString\u003e\n    ) -\u003e Result\u003c(Vec\u003cMemoryEntry\u003e, Option\u003cString\u003e), Self::Error\u003e {\n        let entries = self.entries.read().await;\n        let mut results: Vec\u003cMemoryEntry\u003e = entries\n            .values()\n            .filter(|e| {\n                e.layer == layer\n                    \u0026\u0026 e.metadata.get(\"tenant_id\") == Some(\u0026serde_json::json!(ctx.tenant_id))\n            })\n            .collect::\u003cVec\u003c_\u003e\u003e()\n            .into_iter()\n            .cloned()\n            .collect();\n\n        results.sort_by(|a, b| a.id.cmp(\u0026b.id));\n\n        let start_index = if let Some(c) = cursor {\n            results\n                .iter()\n                .position(|e| e.id == c)\n                .map(|p| p + 1)\n                .unwrap_or(0)\n        } else {\n            0\n        };\n\n        let page = results\n            .iter()\n            .skip(start_index)\n            .take(limit)\n            .cloned()\n            .collect::\u003cVec\u003c_\u003e\u003e();\n        let next_cursor = if page.len() == limit \u0026\u0026 results.len() \u003e start_index + limit {\n            page.last().map(|e| e.id.clone())\n        } else {\n            None\n        };\n\n        Ok((page, next_cursor))\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::{MemoryLayer, TenantContext};\n\n    fn test_ctx() -\u003e TenantContext {\n        use std::str::FromStr;\n        TenantContext {\n            tenant_id: mk_core::types::TenantId::from_str(\"test-tenant\").unwrap(),\n            user_id: mk_core::types::UserId::from_str(\"test-user\").unwrap(),\n            agent_id: None\n        }\n    }\n\n    #[tokio::test]\n    async fn test_mock_provider_basic_ops() {\n        let provider = MockProvider::new();\n        let ctx = test_ctx();\n        let entry = MemoryEntry {\n            id: \"test1\".to_string(),\n            content: \"hello world\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        provider.add(ctx.clone(), entry.clone()).await.unwrap();\n\n        let retrieved = provider.get(ctx.clone(), \"test1\").await.unwrap().unwrap();\n        assert_eq!(retrieved.content, \"hello world\");\n\n        let mut updated = entry.clone();\n        updated.content = \"updated\".to_string();\n        provider.update(ctx.clone(), updated).await.unwrap();\n        assert_eq!(\n            provider\n                .get(ctx.clone(), \"test1\")\n                .await\n                .unwrap()\n                .unwrap()\n                .content,\n            \"updated\"\n        );\n\n        let (list, _) = provider\n            .list(ctx.clone(), MemoryLayer::Agent, 10, None)\n            .await\n            .unwrap();\n        assert_eq!(list.len(), 1);\n\n        provider.delete(ctx.clone(), \"test1\").await.unwrap();\n        assert!(provider.get(ctx.clone(), \"test1\").await.unwrap().is_none());\n    }\n\n    #[tokio::test]\n    async fn test_mock_provider_update_nonexistent() {\n        let provider = MockProvider::new();\n        let ctx = test_ctx();\n        let entry = MemoryEntry {\n            id: \"ghost\".to_string(),\n            content: \"ghost\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n        assert!(provider.update(ctx, entry).await.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_mock_provider_search() {\n        let provider = MockProvider::new();\n        let ctx = test_ctx();\n        let entry1 = MemoryEntry {\n            id: \"1\".to_string(),\n            content: \"one\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"type\".to_string(), serde_json::json!(\"a\"));\n                m\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n        let entry2 = MemoryEntry {\n            id: \"2\".to_string(),\n            content: \"two\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"type\".to_string(), serde_json::json!(\"b\"));\n                m\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n\n        provider.add(ctx.clone(), entry1).await.unwrap();\n        provider.add(ctx.clone(), entry2).await.unwrap();\n\n        let mut filters = HashMap::new();\n        filters.insert(\"type\".to_string(), serde_json::json!(\"a\"));\n\n        let results = provider.search(ctx, vec![], 10, filters).await.unwrap();\n        assert_eq!(results.len(), 1);\n        assert_eq!(results[0].id, \"1\");\n    }\n\n    #[tokio::test]\n    async fn test_mock_provider_list_pagination() {\n        let provider = MockProvider::new();\n        let ctx = test_ctx();\n        for i in 0..5 {\n            let entry = MemoryEntry {\n                id: format!(\"{}\", i),\n                content: format!(\"content {}\", i),\n                embedding: None,\n                layer: MemoryLayer::Agent,\n                metadata: HashMap::new(),\n                created_at: 0,\n                updated_at: 0\n            };\n            provider.add(ctx.clone(), entry).await.unwrap();\n        }\n\n        let (page1, cursor) = provider\n            .list(ctx.clone(), MemoryLayer::Agent, 2, None)\n            .await\n            .unwrap();\n        assert_eq!(page1.len(), 2);\n        assert!(cursor.is_some());\n\n        let (page2, cursor2) = provider\n            .list(ctx.clone(), MemoryLayer::Agent, 2, cursor)\n            .await\n            .unwrap();\n        assert_eq!(page2.len(), 2);\n        assert!(cursor2.is_some());\n\n        let (page3, cursor3) = provider\n            .list(ctx.clone(), MemoryLayer::Agent, 2, cursor2)\n            .await\n            .unwrap();\n        assert_eq!(page3.len(), 1);\n        assert!(cursor3.is_none());\n    }\n}\n","traces":[{"line":15,"address":[],"length":0,"stats":{"Line":50}},{"line":17,"address":[],"length":0,"stats":{"Line":100}},{"line":23,"address":[],"length":0,"stats":{"Line":0}},{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":13}},{"line":59,"address":[],"length":0,"stats":{"Line":26}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":18}},{"line":63,"address":[],"length":0,"stats":{"Line":4}},{"line":64,"address":[],"length":0,"stats":{"Line":1}},{"line":67,"address":[],"length":0,"stats":{"Line":12}},{"line":132,"address":[],"length":0,"stats":{"Line":20}},{"line":133,"address":[],"length":0,"stats":{"Line":20}},{"line":134,"address":[],"length":0,"stats":{"Line":40}},{"line":141,"address":[],"length":0,"stats":{"Line":63}},{"line":146,"address":[],"length":0,"stats":{"Line":12}},{"line":147,"address":[],"length":0,"stats":{"Line":2}},{"line":160,"address":[],"length":0,"stats":{"Line":4}}],"covered":15,"coverable":18},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","providers","qdrant.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::MemoryProviderAdapter;\nuse mk_core::types::{MemoryEntry, MemoryLayer};\nuse qdrant_client::{\n    Qdrant,\n    qdrant::{\n        Distance, PointId, PointStruct, ScoredPoint, Value as QdrantValue, VectorParams,\n        VectorsConfig, point_id::PointIdOptions, vectors_config::Config\n    }\n};\nuse serde_json::{Value, json};\n\nuse std::collections::HashMap;\nuse std::sync::Arc;\n\npub struct QdrantProvider {\n    client: Arc\u003cQdrant\u003e,\n    collection_name: String,\n    embedding_dimension: usize\n}\n\nimpl QdrantProvider {\n    pub fn new(client: Qdrant, collection_name: String, embedding_dimension: usize) -\u003e Self {\n        Self {\n            client: Arc::new(client),\n            collection_name,\n            embedding_dimension\n        }\n    }\n\n    pub async fn ensure_collection(\u0026self) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let collections_list = self.client.list_collections().await?;\n        let collection_exists = collections_list\n            .collections\n            .iter()\n            .any(|c| c.name == self.collection_name);\n\n        if !collection_exists {\n            use qdrant_client::qdrant::CreateCollectionBuilder;\n            let request = CreateCollectionBuilder::new(self.collection_name.clone())\n                .vectors_config(VectorsConfig {\n                    config: Some(Config::Params(VectorParams {\n                        size: self.embedding_dimension as u64,\n                        distance: Distance::Cosine.into(),\n                        ..Default::default()\n                    }))\n                });\n\n            self.client.create_collection(request).await?;\n        }\n\n        Ok(())\n    }\n\n    fn entry_to_point(\n        \u0026self,\n        entry: \u0026MemoryEntry\n    ) -\u003e Result\u003cPointStruct, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let embedding = entry.embedding.as_ref().ok_or(\"Entry missing embedding\")?;\n\n        let mut payload: HashMap\u003cString, QdrantValue\u003e = HashMap::from([\n            (\"id\".to_string(), entry.id.clone().into()),\n            (\"content\".to_string(), entry.content.clone().into()),\n            (\n                \"layer\".to_string(),\n                serde_json::to_string(\u0026entry.layer)?.into()\n            ),\n            (\"created_at\".to_string(), entry.created_at.into()),\n            (\"updated_at\".to_string(), entry.updated_at.into())\n        ]);\n\n        payload.insert(\n            \"metadata\".to_string(),\n            serde_json::to_string(\u0026entry.metadata)?.into()\n        );\n\n        Ok(PointStruct {\n            id: Some(PointId::from(entry.id.clone())),\n            vectors: Some(embedding.clone().into()),\n            payload\n        })\n    }\n\n    fn point_to_entry(\n        \u0026self,\n        point: ScoredPoint\n    ) -\u003e Result\u003cMemoryEntry, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let payload = point.payload;\n\n        let metadata_str = payload\n            .get(\"metadata\")\n            .and_then(|v| {\n                let v: Value = v.clone().into();\n                if v.is_string() {\n                    v.as_str().map(|s| s.to_string())\n                } else {\n                    None\n                }\n            })\n            .ok_or(\"Missing metadata in payload\")?;\n\n        let mut metadata: HashMap\u003cString, Value\u003e = serde_json::from_str(\u0026metadata_str)?;\n        metadata.insert(\"score\".to_string(), json!(point.score));\n\n        let vector = match point.vectors {\n            Some(v) =\u003e v\n                .get_vector()\n                .and_then(|vec| match vec {\n                    qdrant_client::qdrant::vector_output::Vector::Dense(dense) =\u003e Some(dense.data),\n                    _ =\u003e None\n                })\n                .ok_or(\"Unsupported or missing vector format\")?,\n            None =\u003e return Err(\"Point missing vector\".into())\n        };\n\n        let layer_str = payload\n            .get(\"layer\")\n            .and_then(|v| {\n                let v: Value = v.clone().into();\n                if v.is_string() {\n                    v.as_str().map(|s| s.to_string())\n                } else {\n                    None\n                }\n            })\n            .ok_or(\"Missing layer\")?;\n        let layer: MemoryLayer = serde_json::from_str(\u0026layer_str)?;\n\n        let id = payload\n            .get(\"id\")\n            .and_then(|v| {\n                let v: Value = v.clone().into();\n                v.as_str().map(|s| s.to_string())\n            })\n            .ok_or(\"Missing id\")?;\n\n        let content = payload\n            .get(\"content\")\n            .and_then(|v| {\n                let v: Value = v.clone().into();\n                v.as_str().map(|s| s.to_string())\n            })\n            .ok_or(\"Missing content\")?;\n\n        let created_at = payload\n            .get(\"created_at\")\n            .and_then(|v| {\n                let v: Value = v.clone().into();\n                v.as_i64()\n            })\n            .ok_or(\"Missing created_at\")?;\n\n        let updated_at = payload\n            .get(\"updated_at\")\n            .and_then(|v| {\n                let v: Value = v.clone().into();\n                v.as_i64()\n            })\n            .ok_or(\"Missing updated_at\")?;\n\n        Ok(MemoryEntry {\n            id,\n            content,\n            embedding: Some(vector),\n            layer,\n            metadata,\n            created_at,\n            updated_at\n        })\n    }\n}\n\n#[async_trait]\nimpl MemoryProviderAdapter for QdrantProvider {\n    type Error = Box\u003cdyn std::error::Error + Send + Sync\u003e;\n\n    async fn add(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        entry: MemoryEntry\n    ) -\u003e Result\u003cString, Self::Error\u003e {\n        self.ensure_collection().await?;\n        let mut entry = entry;\n\n        entry\n            .metadata\n            .insert(\"tenant_id\".to_string(), json!(ctx.tenant_id.as_str()));\n        entry\n            .metadata\n            .insert(\"user_id\".to_string(), json!(ctx.user_id.as_str()));\n\n        if let Some(agent_id) = \u0026ctx.agent_id {\n            entry\n                .metadata\n                .insert(\"agent_id\".to_string(), json!(agent_id));\n        }\n\n        let point = self.entry_to_point(\u0026entry)?;\n        use qdrant_client::qdrant::UpsertPointsBuilder;\n        let request = UpsertPointsBuilder::new(self.collection_name.clone(), vec![point]);\n        self.client.upsert_points(request).await?;\n        Ok(entry.id)\n    }\n\n    async fn search(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        query_vector: Vec\u003cf32\u003e,\n        limit: usize,\n        _filters: HashMap\u003cString, Value\u003e\n    ) -\u003e Result\u003cVec\u003cMemoryEntry\u003e, Self::Error\u003e {\n        self.ensure_collection().await?;\n        use qdrant_client::qdrant::{Condition, Filter, SearchPointsBuilder};\n\n        let filter = Filter::all(vec![Condition::matches(\n            \"tenant_id\",\n            ctx.tenant_id.as_str().to_string()\n        )]);\n\n        let request =\n            SearchPointsBuilder::new(self.collection_name.clone(), query_vector, limit as u64)\n                .with_payload(true)\n                .with_vectors(true)\n                .filter(filter);\n\n        let result = self.client.search_points(request).await?;\n        result\n            .result\n            .into_iter()\n            .map(|p| self.point_to_entry(p))\n            .collect()\n    }\n\n    async fn get(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        id: \u0026str\n    ) -\u003e Result\u003cOption\u003cMemoryEntry\u003e, Self::Error\u003e {\n        self.ensure_collection().await?;\n        use qdrant_client::qdrant::GetPointsBuilder;\n\n        tracing::debug!(tenant_id = %ctx.tenant_id, \"Qdrant get point\");\n\n        let request = GetPointsBuilder::new(\n            self.collection_name.clone(),\n            vec![PointId::from(id.to_string())]\n        )\n        .with_payload(true)\n        .with_vectors(true);\n\n        let result = self.client.get_points(request).await?;\n        if let Some(point) = result.result.into_iter().next() {\n            let entry = self.point_to_entry(ScoredPoint {\n                id: point.id,\n                version: 0,\n                score: 1.0,\n                payload: point.payload,\n                vectors: point.vectors,\n                order_value: None,\n                shard_key: None\n            })?;\n\n            if entry.metadata.get(\"tenant_id\").and_then(|t| t.as_str())\n                != Some(ctx.tenant_id.as_str())\n            {\n                return Ok(None);\n            }\n\n            Ok(Some(entry))\n        } else {\n            Ok(None)\n        }\n    }\n\n    async fn update(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        entry: MemoryEntry\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        self.add(ctx, entry).await?;\n        Ok(())\n    }\n\n    async fn delete(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        id: \u0026str\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        self.ensure_collection().await?;\n\n        if self.get(ctx.clone(), id).await?.is_none() {\n            return Ok(());\n        }\n\n        tracing::debug!(tenant_id = %ctx.tenant_id, \"Qdrant delete point\");\n\n        use qdrant_client::qdrant::DeletePointsBuilder;\n        let request = DeletePointsBuilder::new(self.collection_name.clone())\n            .points(vec![PointId::from(id.to_string())]);\n        self.client.delete_points(request).await?;\n        Ok(())\n    }\n\n    async fn list(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        _layer: MemoryLayer,\n        limit: usize,\n        cursor: Option\u003cString\u003e\n    ) -\u003e Result\u003c(Vec\u003cMemoryEntry\u003e, Option\u003cString\u003e), Self::Error\u003e {\n        self.ensure_collection().await?;\n\n        tracing::debug!(tenant_id = %ctx.tenant_id, \"Qdrant list points\");\n\n        use qdrant_client::qdrant::{Condition, Filter};\n        let filter = Filter::all(vec![Condition::matches(\n            \"tenant_id\",\n            ctx.tenant_id.as_str().to_string()\n        )]);\n\n        let scroll_request = qdrant_client::qdrant::ScrollPoints {\n            collection_name: self.collection_name.clone(),\n            limit: Some(limit as u32),\n            with_payload: Some(true.into()),\n            with_vectors: Some(true.into()),\n            offset: cursor.map(|c| PointId::from(c)),\n            filter: Some(filter),\n            ..Default::default()\n        };\n\n        let result = self.client.scroll(scroll_request).await?;\n        let entries: Result\u003cVec\u003cMemoryEntry\u003e, _\u003e = result\n            .result\n            .into_iter()\n            .map(|p| {\n                self.point_to_entry(ScoredPoint {\n                    id: p.id,\n                    version: 0,\n                    score: 1.0,\n                    payload: p.payload,\n                    vectors: p.vectors,\n                    order_value: None,\n                    shard_key: None\n                })\n            })\n            .collect();\n\n        let next_cursor = result.next_page_offset.map(|id| match id.point_id_options {\n            Some(PointIdOptions::Uuid(u)) =\u003e u,\n            Some(PointIdOptions::Num(n)) =\u003e n.to_string(),\n            None =\u003e String::new()\n        });\n        Ok((entries?, next_cursor))\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::MemoryLayer;\n\n    use qdrant_client::qdrant::vectors_output::VectorsOptions;\n    use qdrant_client::qdrant::{VectorOutput, VectorsOutput};\n\n    fn setup_provider() -\u003e QdrantProvider {\n        let client = Qdrant::from_url(\"http://localhost:6334\").build().unwrap();\n        QdrantProvider::new(client, \"test_collection\".to_string(), 3)\n    }\n\n    #[test]\n    fn test_point_to_entry_conversion() {\n        let provider = setup_provider();\n        let mut payload = HashMap::new();\n        payload.insert(\"id\".to_string(), \"test-id\".to_string().into());\n        payload.insert(\"content\".to_string(), \"test content\".to_string().into());\n        payload.insert(\n            \"layer\".to_string(),\n            serde_json::to_string(\u0026MemoryLayer::Agent).unwrap().into()\n        );\n        payload.insert(\n            \"metadata\".to_string(),\n            serde_json::to_string(\u0026HashMap::\u003cString, Value\u003e::new())\n                .unwrap()\n                .into()\n        );\n        payload.insert(\"created_at\".to_string(), 1000.into());\n        payload.insert(\"updated_at\".to_string(), 2000.into());\n\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload,\n            vectors: Some(VectorsOutput {\n                vectors_options: Some(VectorsOptions::Vector(VectorOutput {\n                    vector: Some(qdrant_client::qdrant::vector_output::Vector::Dense(\n                        qdrant_client::qdrant::DenseVector {\n                            data: vec![0.1, 0.2, 0.3]\n                        }\n                    )),\n                    ..Default::default()\n                }))\n            }),\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None\n        };\n\n        let entry = provider.point_to_entry(point).unwrap();\n\n        assert_eq!(entry.id, \"test-id\");\n        assert_eq!(entry.content, \"test content\");\n        assert_eq!(entry.layer, MemoryLayer::Agent);\n        assert_eq!(entry.created_at, 1000);\n        assert_eq!(entry.updated_at, 2000);\n        assert_eq!(entry.embedding, Some(vec![0.1, 0.2, 0.3]));\n    }\n\n    #[test]\n    fn test_point_to_entry_with_metadata() {\n        let provider = setup_provider();\n        let mut payload = HashMap::new();\n        payload.insert(\"id\".to_string(), \"test-id\".to_string().into());\n        payload.insert(\"content\".to_string(), \"test content\".to_string().into());\n        payload.insert(\n            \"layer\".to_string(),\n            serde_json::to_string(\u0026MemoryLayer::Agent).unwrap().into()\n        );\n        payload.insert(\n            \"metadata\".to_string(),\n            serde_json::to_string(\u0026HashMap::from([(\"key\".to_string(), json!(\"value\"))]))\n                .unwrap()\n                .into()\n        );\n        payload.insert(\"created_at\".to_string(), 1000.into());\n        payload.insert(\"updated_at\".to_string(), 2000.into());\n\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload,\n            vectors: Some(VectorsOutput {\n                vectors_options: Some(VectorsOptions::Vector(VectorOutput {\n                    vector: Some(qdrant_client::qdrant::vector_output::Vector::Dense(\n                        qdrant_client::qdrant::DenseVector {\n                            data: vec![0.1, 0.2, 0.3]\n                        }\n                    )),\n                    ..Default::default()\n                }))\n            }),\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None\n        };\n\n        let entry = provider.point_to_entry(point).unwrap();\n\n        assert_eq!(entry.id, \"test-id\");\n        assert_eq!(entry.content, \"test content\");\n        assert_eq!(entry.embedding.unwrap(), vec![0.1, 0.2, 0.3]);\n        assert_eq!(entry.layer, MemoryLayer::Agent);\n        assert_eq!(entry.metadata.get(\"key\").unwrap(), \u0026json!(\"value\"));\n        // Use approx comparison for floating point\n        let score_value = entry.metadata.get(\"score\").unwrap().as_f64().unwrap();\n        assert!((score_value - 0.95).abs() \u003c 0.0001);\n        assert_eq!(entry.created_at, 1000);\n        assert_eq!(entry.updated_at, 2000);\n    }\n\n    #[test]\n    fn test_entry_to_point_missing_embedding() {\n        let provider = setup_provider();\n        let entry = MemoryEntry {\n            id: \"test-id\".to_string(),\n            content: \"test content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: HashMap::new(),\n            created_at: 1000,\n            updated_at: 2000\n        };\n\n        let result = provider.entry_to_point(\u0026entry);\n        assert!(result.is_err());\n        assert_eq!(result.unwrap_err().to_string(), \"Entry missing embedding\");\n    }\n\n    #[test]\n    fn test_point_to_entry_missing_payload_fields() {\n        let provider = setup_provider();\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload: HashMap::new(),\n            vectors: Some(VectorsOutput {\n                vectors_options: Some(VectorsOptions::Vector(VectorOutput {\n                    vector: Some(qdrant_client::qdrant::vector_output::Vector::Dense(\n                        qdrant_client::qdrant::DenseVector {\n                            data: vec![0.1, 0.2, 0.3]\n                        }\n                    )),\n                    ..Default::default()\n                }))\n            }),\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None\n        };\n\n        let result = provider.point_to_entry(point);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_point_to_entry_invalid_layer() {\n        let provider = setup_provider();\n        let mut payload = HashMap::new();\n        payload.insert(\"id\".to_string(), \"test-id\".to_string().into());\n        payload.insert(\"content\".to_string(), \"test content\".to_string().into());\n        payload.insert(\"layer\".to_string(), \"\\\"InvalidLayer\\\"\".to_string().into());\n        payload.insert(\"metadata\".to_string(), \"{}\".to_string().into());\n        payload.insert(\"created_at\".to_string(), 1000.into());\n        payload.insert(\"updated_at\".to_string(), 2000.into());\n\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload,\n            vectors: Some(VectorsOutput {\n                vectors_options: Some(VectorsOptions::Vector(VectorOutput {\n                    vector: Some(qdrant_client::qdrant::vector_output::Vector::Dense(\n                        qdrant_client::qdrant::DenseVector {\n                            data: vec![0.1, 0.2, 0.3]\n                        }\n                    )),\n                    ..Default::default()\n                }))\n            }),\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None\n        };\n\n        let result = provider.point_to_entry(point);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_point_to_entry_missing_metadata() {\n        let provider = setup_provider();\n        let mut payload = HashMap::new();\n        payload.insert(\"id\".to_string(), \"test-id\".to_string().into());\n        payload.insert(\"content\".to_string(), \"test content\".to_string().into());\n        payload.insert(\n            \"layer\".to_string(),\n            serde_json::to_string(\u0026MemoryLayer::Agent).unwrap().into()\n        );\n        payload.insert(\"created_at\".to_string(), 1000.into());\n        payload.insert(\"updated_at\".to_string(), 2000.into());\n\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload,\n            vectors: Some(VectorsOutput {\n                vectors_options: Some(VectorsOptions::Vector(VectorOutput {\n                    vector: Some(qdrant_client::qdrant::vector_output::Vector::Dense(\n                        qdrant_client::qdrant::DenseVector {\n                            data: vec![0.1, 0.2, 0.3]\n                        }\n                    )),\n                    ..Default::default()\n                }))\n            }),\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None\n        };\n\n        let result = provider.point_to_entry(point);\n        assert!(result.is_err());\n        assert_eq!(\n            result.unwrap_err().to_string(),\n            \"Missing metadata in payload\"\n        );\n    }\n\n    #[test]\n    fn test_point_to_entry_unsupported_vector() {\n        let provider = setup_provider();\n        let mut payload = HashMap::new();\n        payload.insert(\"id\".to_string(), \"test-id\".to_string().into());\n        payload.insert(\"content\".to_string(), \"test content\".to_string().into());\n        payload.insert(\n            \"layer\".to_string(),\n            serde_json::to_string(\u0026MemoryLayer::Agent).unwrap().into()\n        );\n        payload.insert(\"metadata\".to_string(), \"{}\".to_string().into());\n        payload.insert(\"created_at\".to_string(), 1000.into());\n        payload.insert(\"updated_at\".to_string(), 2000.into());\n\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload,\n            vectors: Some(VectorsOutput {\n                vectors_options: None\n            }),\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None\n        };\n\n        let result = provider.point_to_entry(point);\n        assert!(result.is_err());\n        assert_eq!(\n            result.unwrap_err().to_string(),\n            \"Unsupported or missing vector format\"\n        );\n    }\n\n    #[test]\n    fn test_point_to_entry_invalid_metadata_json() {\n        let provider = setup_provider();\n        let mut payload = HashMap::new();\n        payload.insert(\"id\".to_string(), \"test-id\".to_string().into());\n        payload.insert(\"content\".to_string(), \"test content\".to_string().into());\n        payload.insert(\n            \"layer\".to_string(),\n            serde_json::to_string(\u0026MemoryLayer::Agent).unwrap().into()\n        );\n        payload.insert(\"metadata\".to_string(), \"invalid-json\".to_string().into());\n        payload.insert(\"created_at\".to_string(), 1000.into());\n        payload.insert(\"updated_at\".to_string(), 2000.into());\n\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload,\n            vectors: Some(VectorsOutput {\n                vectors_options: Some(VectorsOptions::Vector(VectorOutput {\n                    vector: Some(qdrant_client::qdrant::vector_output::Vector::Dense(\n                        qdrant_client::qdrant::DenseVector {\n                            data: vec![0.1, 0.2, 0.3]\n                        }\n                    )),\n                    ..Default::default()\n                }))\n            }),\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None\n        };\n\n        let result = provider.point_to_entry(point);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_point_to_entry_missing_vector() {\n        let provider = setup_provider();\n        let mut payload = HashMap::new();\n        payload.insert(\"id\".to_string(), \"test-id\".to_string().into());\n        payload.insert(\"content\".to_string(), \"test content\".to_string().into());\n        payload.insert(\n            \"layer\".to_string(),\n            serde_json::to_string(\u0026MemoryLayer::Agent).unwrap().into()\n        );\n        payload.insert(\"metadata\".to_string(), \"{}\".to_string().into());\n        payload.insert(\"created_at\".to_string(), 1000.into());\n        payload.insert(\"updated_at\".to_string(), 2000.into());\n\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload,\n            vectors: None,\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None\n        };\n\n        let result = provider.point_to_entry(point);\n        assert!(result.is_err());\n        assert_eq!(result.unwrap_err().to_string(), \"Point missing vector\");\n    }\n}\n","traces":[{"line":23,"address":[],"length":0,"stats":{"Line":9}},{"line":25,"address":[],"length":0,"stats":{"Line":27}},{"line":31,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":42,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":1}},{"line":59,"address":[],"length":0,"stats":{"Line":4}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":8}},{"line":88,"address":[],"length":0,"stats":{"Line":16}},{"line":90,"address":[],"length":0,"stats":{"Line":14}},{"line":92,"address":[],"length":0,"stats":{"Line":14}},{"line":93,"address":[],"length":0,"stats":{"Line":30}},{"line":94,"address":[],"length":0,"stats":{"Line":12}},{"line":95,"address":[],"length":0,"stats":{"Line":30}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":23}},{"line":103,"address":[],"length":0,"stats":{"Line":25}},{"line":105,"address":[],"length":0,"stats":{"Line":8}},{"line":106,"address":[],"length":0,"stats":{"Line":8}},{"line":108,"address":[],"length":0,"stats":{"Line":7}},{"line":109,"address":[],"length":0,"stats":{"Line":6}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":1}},{"line":116,"address":[],"length":0,"stats":{"Line":6}},{"line":118,"address":[],"length":0,"stats":{"Line":6}},{"line":119,"address":[],"length":0,"stats":{"Line":15}},{"line":120,"address":[],"length":0,"stats":{"Line":6}},{"line":121,"address":[],"length":0,"stats":{"Line":15}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":11}},{"line":129,"address":[],"length":0,"stats":{"Line":4}},{"line":131,"address":[],"length":0,"stats":{"Line":4}},{"line":132,"address":[],"length":0,"stats":{"Line":10}},{"line":133,"address":[],"length":0,"stats":{"Line":10}},{"line":137,"address":[],"length":0,"stats":{"Line":4}},{"line":139,"address":[],"length":0,"stats":{"Line":4}},{"line":140,"address":[],"length":0,"stats":{"Line":10}},{"line":141,"address":[],"length":0,"stats":{"Line":10}},{"line":145,"address":[],"length":0,"stats":{"Line":4}},{"line":147,"address":[],"length":0,"stats":{"Line":4}},{"line":148,"address":[],"length":0,"stats":{"Line":10}},{"line":149,"address":[],"length":0,"stats":{"Line":4}},{"line":153,"address":[],"length":0,"stats":{"Line":4}},{"line":155,"address":[],"length":0,"stats":{"Line":4}},{"line":156,"address":[],"length":0,"stats":{"Line":10}},{"line":157,"address":[],"length":0,"stats":{"Line":4}},{"line":161,"address":[],"length":0,"stats":{"Line":2}},{"line":162,"address":[],"length":0,"stats":{"Line":4}},{"line":163,"address":[],"length":0,"stats":{"Line":4}},{"line":164,"address":[],"length":0,"stats":{"Line":4}},{"line":165,"address":[],"length":0,"stats":{"Line":4}},{"line":166,"address":[],"length":0,"stats":{"Line":4}},{"line":167,"address":[],"length":0,"stats":{"Line":2}},{"line":168,"address":[],"length":0,"stats":{"Line":2}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":335,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":337,"address":[],"length":0,"stats":{"Line":0}},{"line":338,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":342,"address":[],"length":0,"stats":{"Line":0}},{"line":343,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":0}},{"line":350,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}}],"covered":48,"coverable":95},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","redis.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","repository.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","state.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","telemetry.rs"],"content":"use metrics::{counter, gauge, histogram};\nuse opentelemetry::global;\nuse opentelemetry::global::{BoxedSpan, BoxedTracer};\nuse opentelemetry::metrics::Meter;\nuse opentelemetry::trace::Tracer;\n\n#[derive(Debug)]\npub struct MemoryTelemetry {\n    tracer: BoxedTracer\n}\n\nimpl MemoryTelemetry {\n    pub fn new() -\u003e Self {\n        let tracer = global::tracer(\"memory_system\");\n\n        Self { tracer }\n    }\n\n    pub fn with_tracer(tracer: BoxedTracer) -\u003e Self {\n        Self { tracer }\n    }\n\n    pub fn with_meter(_meter: Meter) -\u003e Self {\n        let tracer = global::tracer(\"memory_system\");\n\n        Self { tracer }\n    }\n\n    pub fn record_operation_start(\u0026self, operation: \u0026str, layer: \u0026str) -\u003e BoxedSpan {\n        self.tracer\n            .span_builder(format!(\"memory.{}\", operation))\n            .with_attributes(vec![\n                opentelemetry::KeyValue::new(\"layer\", layer.to_string()),\n                opentelemetry::KeyValue::new(\"operation\", operation.to_string()),\n            ])\n            .start(\u0026self.tracer)\n    }\n\n    pub fn record_operation_success(\u0026self, operation: \u0026str, layer: \u0026str, duration_ms: f64) {\n        counter!(\"memory_operations_total\", 1,\n            \"operation\" =\u003e operation.to_string(),\n            \"layer\" =\u003e layer.to_string(),\n            \"status\" =\u003e \"success\"\n        );\n\n        histogram!(\"memory_operation_duration_seconds\", duration_ms / 1000.0,\n            \"operation\" =\u003e operation.to_string(),\n            \"layer\" =\u003e layer.to_string()\n        );\n    }\n\n    pub fn record_operation_failure(\u0026self, operation: \u0026str, layer: \u0026str, error: \u0026str) {\n        counter!(\"memory_operations_total\", 1,\n            \"operation\" =\u003e operation.to_string(),\n            \"layer\" =\u003e layer.to_string(),\n            \"status\" =\u003e \"failure\",\n            \"error\" =\u003e error.to_string()\n        );\n\n        counter!(\"memory_operation_errors_total\", 1,\n            \"operation\" =\u003e operation.to_string(),\n            \"layer\" =\u003e layer.to_string(),\n            \"error_type\" =\u003e error.to_string()\n        );\n    }\n\n    pub fn record_embedding_generation(\u0026self, dimension: usize, duration_ms: f64) {\n        counter!(\"memory_embeddings_generated_total\", 1,\n            \"dimension\" =\u003e dimension.to_string()\n        );\n\n        histogram!(\"memory_embedding_generation_duration_seconds\", duration_ms / 1000.0,\n            \"dimension\" =\u003e dimension.to_string()\n        );\n\n        gauge!(\"memory_embedding_dimension\", dimension as f64);\n    }\n\n    pub fn record_search_operation(\u0026self, results_count: usize, query_dimension: usize) {\n        counter!(\"memory_searches_total\", 1);\n        histogram!(\"memory_search_results_count\", results_count as f64);\n        gauge!(\"memory_search_query_dimension\", query_dimension as f64);\n    }\n\n    pub fn record_storage_metrics(\u0026self, entries_count: usize, total_size_bytes: usize) {\n        gauge!(\"memory_entries_total\", entries_count as f64);\n        gauge!(\"memory_storage_size_bytes\", total_size_bytes as f64);\n    }\n\n    pub fn record_cache_metrics(\u0026self, hit_count: usize, miss_count: usize, cache_size: usize) {\n        counter!(\"memory_cache_hits_total\", hit_count as u64);\n        counter!(\"memory_cache_misses_total\", miss_count as u64);\n        gauge!(\"memory_cache_size\", cache_size as f64);\n\n        let total = hit_count + miss_count;\n        if total \u003e 0 {\n            let hit_rate = (hit_count as f64) / (total as f64);\n            gauge!(\"memory_cache_hit_rate\", hit_rate);\n        }\n    }\n\n    pub fn record_promotion_attempt(\u0026self, from_layer: \u0026str, target_layer: \u0026str) {\n        counter!(\"memory_promotion_attempts_total\", 1,\n            \"from_layer\" =\u003e from_layer.to_string(),\n            \"target_layer\" =\u003e target_layer.to_string()\n        );\n    }\n\n    pub fn record_promotion_success(\u0026self, from_layer: \u0026str, target_layer: \u0026str) {\n        counter!(\"memory_promotion_success_total\", 1,\n            \"from_layer\" =\u003e from_layer.to_string(),\n            \"target_layer\" =\u003e target_layer.to_string()\n        );\n    }\n\n    pub fn record_promotion_blocked(\u0026self, from_layer: \u0026str, reason: \u0026str) {\n        counter!(\"memory_promotion_blocked_total\", 1,\n            \"from_layer\" =\u003e from_layer.to_string(),\n            \"reason\" =\u003e reason.to_string()\n        );\n    }\n\n    pub fn record_governance_redaction(\u0026self, layer: \u0026str) {\n        counter!(\"memory_governance_redactions_total\", 1,\n            \"layer\" =\u003e layer.to_string()\n        );\n    }\n}\n\npub fn init_telemetry() -\u003e Result\u003cMemoryTelemetry, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    let telemetry = MemoryTelemetry::new();\n\n    metrics_exporter_prometheus::PrometheusBuilder::new()\n        .with_http_listener(([0, 0, 0, 0], 9090))\n        .install()?;\n\n    Ok(telemetry)\n}\n\npub fn init_telemetry_with_endpoint(\n    endpoint: std::net::SocketAddr\n) -\u003e Result\u003cMemoryTelemetry, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    let telemetry = MemoryTelemetry::new();\n\n    metrics_exporter_prometheus::PrometheusBuilder::new()\n        .with_http_listener(endpoint)\n        .install()?;\n\n    Ok(telemetry)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use metrics_util::debugging::DebuggingRecorder;\n\n    #[test]\n    fn test_telemetry_creation() {\n        use opentelemetry::trace::Span as _;\n        use opentelemetry::trace::TracerProvider as _;\n        use opentelemetry_sdk::trace::TracerProvider;\n\n        let provider = TracerProvider::default();\n        let tracer = provider.tracer(\"test\");\n        let telemetry =\n            MemoryTelemetry::with_tracer(opentelemetry::global::BoxedTracer::new(Box::new(tracer)));\n\n        let mut span = telemetry.record_operation_start(\"add\", \"agent\");\n        assert!(span.span_context().is_valid());\n        span.end();\n    }\n\n    #[test]\n    fn test_metrics_recording() {\n        let recorder = DebuggingRecorder::new();\n        let static_recorder: \u0026'static DebuggingRecorder = Box::leak(Box::new(recorder));\n        metrics::set_recorder(static_recorder).ok();\n\n        let telemetry = MemoryTelemetry::new();\n\n        telemetry.record_operation_success(\"add\", \"agent\", 150.0);\n        telemetry.record_operation_failure(\"search\", \"session\", \"not_found\");\n        telemetry.record_embedding_generation(1536, 250.0);\n        telemetry.record_search_operation(5, 1536);\n        telemetry.record_storage_metrics(100, 1024000);\n        telemetry.record_cache_metrics(75, 25, 100);\n        telemetry.record_promotion_attempt(\"agent\", \"user\");\n        telemetry.record_promotion_success(\"agent\", \"user\");\n        telemetry.record_promotion_blocked(\"agent\", \"governance\");\n        telemetry.record_governance_redaction(\"user\");\n    }\n\n    #[test]\n    fn test_with_meter() {\n        use opentelemetry::metrics::MeterProvider;\n        use opentelemetry_sdk::metrics::MeterProvider as SdkMeterProvider;\n\n        let provider = SdkMeterProvider::default();\n        let meter = provider.meter(\"test\");\n\n        // Test that with_meter creates telemetry instance\n        let telemetry = MemoryTelemetry::with_meter(meter);\n\n        // Verify telemetry instance was created\n        // The meter parameter is ignored in the implementation, but we test the method\n        // exists\n        assert!(std::mem::size_of_val(\u0026telemetry) \u003e 0);\n    }\n\n    #[test]\n    fn test_init_telemetry() {\n        // Test that init_telemetry returns a Result\n        // The function might succeed or fail depending on port availability\n        let result = init_telemetry();\n\n        // Verify it returns a Result (either Ok or Err)\n        // We can't guarantee it will fail because port 9090 might be available\n        match result {\n            Ok(telemetry) =\u003e {\n                // If it succeeds, verify we got a telemetry instance\n                assert!(std::mem::size_of_val(\u0026telemetry) \u003e 0);\n            }\n            Err(e) =\u003e {\n                // If it fails, verify the error is related to binding\n                let error_str = e.to_string();\n                assert!(\n                    error_str.contains(\"address already in use\")\n                        || error_str.contains(\"bind\")\n                        || error_str.contains(\"port\")\n                        || error_str.contains(\"Permission denied\")\n                );\n            }\n        }\n    }\n\n    #[test]\n    fn test_init_telemetry_with_endpoint() {\n        use std::net::{IpAddr, Ipv4Addr, SocketAddr};\n\n        // Create a test endpoint (port 0 means OS will assign a free port)\n        let endpoint = SocketAddr::new(IpAddr::V4(Ipv4Addr::new(127, 0, 0, 1)), 0);\n\n        // Test that init_telemetry_with_endpoint returns a Result\n        let result = init_telemetry_with_endpoint(endpoint);\n\n        // The function should work with port 0 (OS-assigned port)\n        // But metrics initialization might still fail for other reasons\n        // We just verify it returns a Result\n        assert!(result.is_err() || result.is_ok());\n\n        // If it fails, verify it's not a bind error\n        if let Err(e) = result {\n            let error_str = e.to_string();\n            // Should not be a bind error with port 0\n            assert!(!error_str.contains(\"address already in use\"));\n        }\n    }\n}\n","traces":[{"line":13,"address":[],"length":0,"stats":{"Line":96}},{"line":14,"address":[],"length":0,"stats":{"Line":192}},{"line":19,"address":[],"length":0,"stats":{"Line":1}},{"line":23,"address":[],"length":0,"stats":{"Line":1}},{"line":24,"address":[],"length":0,"stats":{"Line":2}},{"line":29,"address":[],"length":0,"stats":{"Line":1050}},{"line":30,"address":[],"length":0,"stats":{"Line":1050}},{"line":31,"address":[],"length":0,"stats":{"Line":3150}},{"line":32,"address":[],"length":0,"stats":{"Line":2100}},{"line":33,"address":[],"length":0,"stats":{"Line":3150}},{"line":34,"address":[],"length":0,"stats":{"Line":3150}},{"line":36,"address":[],"length":0,"stats":{"Line":2100}},{"line":39,"address":[],"length":0,"stats":{"Line":1047}},{"line":40,"address":[],"length":0,"stats":{"Line":1047}},{"line":41,"address":[],"length":0,"stats":{"Line":2}},{"line":42,"address":[],"length":0,"stats":{"Line":2}},{"line":46,"address":[],"length":0,"stats":{"Line":1048}},{"line":47,"address":[],"length":0,"stats":{"Line":2}},{"line":48,"address":[],"length":0,"stats":{"Line":2}},{"line":52,"address":[],"length":0,"stats":{"Line":3}},{"line":53,"address":[],"length":0,"stats":{"Line":3}},{"line":54,"address":[],"length":0,"stats":{"Line":2}},{"line":55,"address":[],"length":0,"stats":{"Line":2}},{"line":57,"address":[],"length":0,"stats":{"Line":2}},{"line":60,"address":[],"length":0,"stats":{"Line":3}},{"line":61,"address":[],"length":0,"stats":{"Line":2}},{"line":62,"address":[],"length":0,"stats":{"Line":2}},{"line":63,"address":[],"length":0,"stats":{"Line":2}},{"line":67,"address":[],"length":0,"stats":{"Line":1}},{"line":68,"address":[],"length":0,"stats":{"Line":1}},{"line":69,"address":[],"length":0,"stats":{"Line":2}},{"line":72,"address":[],"length":0,"stats":{"Line":2}},{"line":73,"address":[],"length":0,"stats":{"Line":2}},{"line":76,"address":[],"length":0,"stats":{"Line":2}},{"line":79,"address":[],"length":0,"stats":{"Line":4}},{"line":80,"address":[],"length":0,"stats":{"Line":4}},{"line":81,"address":[],"length":0,"stats":{"Line":5}},{"line":82,"address":[],"length":0,"stats":{"Line":5}},{"line":85,"address":[],"length":0,"stats":{"Line":1}},{"line":86,"address":[],"length":0,"stats":{"Line":2}},{"line":87,"address":[],"length":0,"stats":{"Line":2}},{"line":90,"address":[],"length":0,"stats":{"Line":1}},{"line":91,"address":[],"length":0,"stats":{"Line":2}},{"line":92,"address":[],"length":0,"stats":{"Line":2}},{"line":93,"address":[],"length":0,"stats":{"Line":2}},{"line":95,"address":[],"length":0,"stats":{"Line":2}},{"line":96,"address":[],"length":0,"stats":{"Line":1}},{"line":97,"address":[],"length":0,"stats":{"Line":2}},{"line":98,"address":[],"length":0,"stats":{"Line":2}},{"line":102,"address":[],"length":0,"stats":{"Line":6}},{"line":103,"address":[],"length":0,"stats":{"Line":6}},{"line":104,"address":[],"length":0,"stats":{"Line":2}},{"line":105,"address":[],"length":0,"stats":{"Line":2}},{"line":109,"address":[],"length":0,"stats":{"Line":6}},{"line":110,"address":[],"length":0,"stats":{"Line":6}},{"line":111,"address":[],"length":0,"stats":{"Line":2}},{"line":112,"address":[],"length":0,"stats":{"Line":2}},{"line":116,"address":[],"length":0,"stats":{"Line":2}},{"line":117,"address":[],"length":0,"stats":{"Line":2}},{"line":118,"address":[],"length":0,"stats":{"Line":2}},{"line":119,"address":[],"length":0,"stats":{"Line":2}},{"line":123,"address":[],"length":0,"stats":{"Line":3}},{"line":124,"address":[],"length":0,"stats":{"Line":3}},{"line":125,"address":[],"length":0,"stats":{"Line":2}},{"line":130,"address":[],"length":0,"stats":{"Line":1}},{"line":131,"address":[],"length":0,"stats":{"Line":2}},{"line":133,"address":[],"length":0,"stats":{"Line":1}},{"line":134,"address":[],"length":0,"stats":{"Line":2}},{"line":137,"address":[],"length":0,"stats":{"Line":1}},{"line":140,"address":[],"length":0,"stats":{"Line":1}},{"line":143,"address":[],"length":0,"stats":{"Line":2}},{"line":145,"address":[],"length":0,"stats":{"Line":1}},{"line":146,"address":[],"length":0,"stats":{"Line":2}},{"line":149,"address":[],"length":0,"stats":{"Line":0}}],"covered":73,"coverable":74},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","tools.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","validator.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","working.rs"],"content":"\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","tests","qdrant_testcontainers.rs"],"content":"//! Integration tests for Qdrant provider using testcontainers\n\nuse memory::providers::qdrant::QdrantProvider;\nuse mk_core::traits::MemoryProviderAdapter;\nuse mk_core::types::{MemoryEntry, MemoryLayer, TenantContext};\nuse qdrant_client::{Qdrant, config::QdrantConfig};\nuse std::collections::HashMap;\nuse testcontainers::{\n    GenericImage,\n    core::{ContainerPort, WaitFor},\n    runners::AsyncRunner\n};\n\nfn test_ctx() -\u003e TenantContext {\n    TenantContext::default()\n}\n\n#[tokio::test]\nasync fn test_qdrant_full_lifecycle() {\n    let container = match GenericImage::new(\"qdrant/qdrant\", \"latest\")\n        .with_exposed_port(ContainerPort::Tcp(6334))\n        .with_wait_for(WaitFor::message_on_stdout(\n            \"Qdrant is ready to accept connections\"\n        ))\n        .start()\n        .await\n    {\n        Ok(c) =\u003e c,\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Qdrant test: Docker not available\");\n            return;\n        }\n    };\n\n    let host = container.get_host().await.unwrap();\n    let port = container.get_host_port_ipv4(6334).await.unwrap();\n    let connection_url = format!(\"http://{}:{}\", host, port);\n\n    let client = Qdrant::new(QdrantConfig::from_url(\u0026connection_url))\n        .expect(\"Failed to create Qdrant client\");\n\n    let provider = QdrantProvider::new(client, \"lifecycle_test\".to_string(), 128);\n\n    provider\n        .ensure_collection()\n        .await\n        .expect(\"Failed to create collection\");\n\n    let ctx = test_ctx();\n\n    for i in 0..5 {\n        let entry = MemoryEntry {\n            id: format!(\"id_{}\", i),\n            content: format!(\"Content {}\", i),\n            embedding: Some(vec![i as f32 * 0.1; 128]),\n            layer: MemoryLayer::User,\n            metadata: HashMap::new(),\n            created_at: 1000 + i as i64,\n            updated_at: 1000 + i as i64\n        };\n        provider\n            .add(ctx.clone(), entry)\n            .await\n            .expect(\"Failed to add entry\");\n    }\n\n    let query = vec![0.25; 128];\n    let search_results = provider\n        .search(ctx.clone(), query, 10, HashMap::new())\n        .await\n        .expect(\"Search failed\");\n    assert!(search_results.len() \u003e= 2);\n\n    let first_id = \u0026search_results[0].id;\n    assert!(first_id == \"id_2\" || first_id == \"id_3\");\n\n    let entry = provider\n        .get(ctx.clone(), \"id_0\")\n        .await\n        .expect(\"Get failed\")\n        .expect(\"Entry not found\");\n    assert_eq!(entry.content, \"Content 0\");\n\n    let mut entry_to_update = entry;\n    entry_to_update.content = \"Updated content\".to_string();\n    provider\n        .update(ctx.clone(), entry_to_update)\n        .await\n        .expect(\"Update failed\");\n\n    let updated = provider\n        .get(ctx.clone(), \"id_0\")\n        .await\n        .expect(\"Get failed\")\n        .expect(\"Entry not found\");\n    assert_eq!(updated.content, \"Updated content\");\n\n    let (list, next_cursor) = provider\n        .list(ctx.clone(), MemoryLayer::User, 2, None)\n        .await\n        .expect(\"List failed\");\n    assert_eq!(list.len(), 2);\n    assert!(next_cursor.is_some());\n\n    provider\n        .delete(ctx.clone(), \"id_0\")\n        .await\n        .expect(\"Delete failed\");\n    let deleted = provider.get(ctx, \"id_0\").await.expect(\"Get failed\");\n    assert!(deleted.is_none());\n}\n\n#[tokio::test]\nasync fn test_qdrant_error_conditions() {\n    let container = match GenericImage::new(\"qdrant/qdrant\", \"latest\")\n        .with_exposed_port(ContainerPort::Tcp(6334))\n        .with_wait_for(WaitFor::message_on_stdout(\n            \"Qdrant is ready to accept connections\"\n        ))\n        .start()\n        .await\n    {\n        Ok(c) =\u003e c,\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Qdrant test: Docker not available\");\n            return;\n        }\n    };\n\n    let host = container.get_host().await.unwrap();\n    let port = container.get_host_port_ipv4(6334).await.unwrap();\n    let connection_url = format!(\"http://{}:{}\", host, port);\n\n    let client = Qdrant::new(QdrantConfig::from_url(\u0026connection_url))\n        .expect(\"Failed to create Qdrant client\");\n\n    let provider = QdrantProvider::new(client, \"error_test\".to_string(), 128);\n\n    let entry_no_emb = MemoryEntry {\n        id: \"no_emb\".to_string(),\n        content: \"No embedding\".to_string(),\n        embedding: None,\n        layer: MemoryLayer::User,\n        metadata: HashMap::new(),\n        created_at: 0,\n        updated_at: 0\n    };\n    let ctx = test_ctx();\n    let result = provider.add(ctx, entry_no_emb).await;\n    assert!(result.is_err());\n    assert!(\n        result\n            .unwrap_err()\n            .to_string()\n            .contains(\"missing embedding\")\n    );\n\n    provider.ensure_collection().await.unwrap();\n    let ctx = test_ctx();\n    let wrong_dim_query = vec![1.0; 64];\n    let result = provider\n        .search(ctx, wrong_dim_query, 10, HashMap::new())\n        .await;\n    assert!(result.is_err());\n}\n\n#[tokio::test]\nasync fn test_qdrant_complex_metadata() {\n    let container = match GenericImage::new(\"qdrant/qdrant\", \"latest\")\n        .with_exposed_port(ContainerPort::Tcp(6334))\n        .with_wait_for(WaitFor::message_on_stdout(\n            \"Qdrant is ready to accept connections\"\n        ))\n        .start()\n        .await\n    {\n        Ok(c) =\u003e c,\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Qdrant test: Docker not available\");\n            return;\n        }\n    };\n\n    let host = container.get_host().await.unwrap();\n    let port = container.get_host_port_ipv4(6334).await.unwrap();\n    let connection_url = format!(\"http://{}:{}\", host, port);\n\n    let client = Qdrant::new(QdrantConfig::from_url(\u0026connection_url))\n        .expect(\"Failed to create Qdrant client\");\n\n    let provider = QdrantProvider::new(client, \"metadata_test\".to_string(), 128);\n\n    let mut metadata = HashMap::new();\n    metadata.insert(\"tags\".to_string(), serde_json::json!([\"rust\", \"ai\"]));\n    metadata.insert(\"nested\".to_string(), serde_json::json!({\"key\": \"value\"}));\n    metadata.insert(\"priority\".to_string(), serde_json::json!(5));\n\n    let entry = MemoryEntry {\n        id: \"meta_1\".to_string(),\n        content: \"Metadata test\".to_string(),\n        embedding: Some(vec![0.1; 128]),\n        layer: MemoryLayer::Session,\n        metadata,\n        created_at: 123456789,\n        updated_at: 123456789\n    };\n\n    let ctx = test_ctx();\n    provider\n        .add(ctx.clone(), entry.clone())\n        .await\n        .expect(\"Failed to add entry with metadata\");\n\n    let retrieved = provider\n        .get(ctx, \"meta_1\")\n        .await\n        .expect(\"Get failed\")\n        .unwrap();\n    assert_eq!(\n        retrieved\n            .metadata\n            .get(\"priority\")\n            .unwrap()\n            .as_i64()\n            .unwrap(),\n        5\n    );\n    assert_eq!(\n        retrieved\n            .metadata\n            .get(\"tags\")\n            .unwrap()\n            .as_array()\n            .unwrap()\n            .len(),\n        2\n    );\n    assert_eq!(\n        retrieved\n            .metadata\n            .get(\"nested\")\n            .unwrap()\n            .as_object()\n            .unwrap()\n            .get(\"key\")\n            .unwrap()\n            .as_str()\n            .unwrap(),\n        \"value\"\n    );\n\n    if let MemoryLayer::Session = retrieved.layer {\n        assert!(true);\n    } else {\n        panic!(\"Layer was not preserved correctly\");\n    }\n}\n\n#[tokio::test]\nasync fn test_qdrant_collection_management() {\n    let container = match GenericImage::new(\"qdrant/qdrant\", \"latest\")\n        .with_exposed_port(ContainerPort::Tcp(6334))\n        .with_wait_for(WaitFor::message_on_stdout(\n            \"Qdrant is ready to accept connections\"\n        ))\n        .start()\n        .await\n    {\n        Ok(c) =\u003e c,\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Qdrant test: Docker not available\");\n            return;\n        }\n    };\n\n    let host = container.get_host().await.unwrap();\n    let port = container.get_host_port_ipv4(6334).await.unwrap();\n    let connection_url = format!(\"http://{}:{}\", host, port);\n\n    let client = Qdrant::new(QdrantConfig::from_url(\u0026connection_url))\n        .expect(\"Failed to create Qdrant client\");\n\n    let provider = QdrantProvider::new(client, \"mgmt_test\".to_string(), 384);\n\n    provider\n        .ensure_collection()\n        .await\n        .expect(\"First creation failed\");\n    provider\n        .ensure_collection()\n        .await\n        .expect(\"Idempotent creation failed\");\n}\n","traces":[{"line":14,"address":[],"length":0,"stats":{"Line":0}},{"line":15,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":2},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","tests","system_integration.rs"],"content":"//! System Integration Test for Aeterna Memory System\n//!\n//! Coordinates PostgreSQL, Redis, and Qdrant using testcontainers\n//! to verify the full memory lifecycle across different storage layers.\n\nuse memory::manager::MemoryManager;\nuse memory::providers::qdrant::QdrantProvider;\nuse mk_core::types::{MemoryEntry, MemoryLayer, TenantContext};\nuse qdrant_client::{Qdrant, config::QdrantConfig};\nuse std::collections::HashMap;\nuse storage::postgres::PostgresBackend;\nuse storage::redis::RedisStorage;\nuse testcontainers::{\n    ContainerAsync, GenericImage,\n    core::{ContainerPort, WaitFor},\n    runners::AsyncRunner,\n};\nuse testcontainers_modules::postgres::Postgres;\nuse testcontainers_modules::redis::Redis;\n\nfn test_ctx() -\u003e TenantContext {\n    TenantContext::default()\n}\n\nasync fn setup_postgres() -\u003e Result\u003c(ContainerAsync\u003cPostgres\u003e, String), Box\u003cdyn std::error::Error\u003e\u003e\n{\n    let container = Postgres::default()\n        .with_db_name(\"aeterna_test\")\n        .with_user(\"aeterna\")\n        .with_password(\"aeterna\")\n        .start()\n        .await?;\n    let port = container.get_host_port_ipv4(5432).await?;\n    let url = format!(\"postgres://aeterna:aeterna@localhost:{}/aeterna_test\", port);\n    Ok((container, url))\n}\n\nasync fn setup_redis() -\u003e Result\u003c(ContainerAsync\u003cRedis\u003e, String), Box\u003cdyn std::error::Error\u003e\u003e {\n    let container = Redis::default().start().await?;\n    let port = container.get_host_port_ipv4(6379).await?;\n    let url = format!(\"redis://localhost:{}\", port);\n    Ok((container, url))\n}\n\nasync fn setup_qdrant() -\u003e Result\u003c(ContainerAsync\u003cGenericImage\u003e, String), Box\u003cdyn std::error::Error\u003e\u003e\n{\n    let container = GenericImage::new(\"qdrant/qdrant\", \"latest\")\n        .with_exposed_port(ContainerPort::Tcp(6334))\n        .with_wait_for(WaitFor::message_on_stdout(\n            \"Qdrant is ready to accept connections\",\n        ))\n        .start()\n        .await?;\n    let port = container.get_host_port_ipv4(6334).await?;\n    let url = format!(\"http://localhost:{}\", port);\n    Ok((container, url))\n}\n\n#[tokio::test]\n#[ignore = \"requires Docker with PostgreSQL, Redis, and Qdrant containers\"]\nasync fn test_system_wide_memory_flow() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n    let postgres_setup = setup_postgres().await;\n    let redis_setup = setup_redis().await;\n    let qdrant_setup = setup_qdrant().await;\n\n    let (_pg_container, pg_url) = match postgres_setup {\n        Ok(res) =\u003e res,\n        Err(_) =\u003e {\n            eprintln!(\"Skipping system test: Docker not available\");\n            return Ok(());\n        }\n    };\n    let (_redis_container, redis_url) = redis_setup?;\n    let (_qdrant_container, qdrant_url) = qdrant_setup?;\n\n    let pg_backend = PostgresBackend::new(\u0026pg_url).await?;\n    pg_backend.initialize_schema().await?;\n\n    let _redis_storage = RedisStorage::new(\u0026redis_url).await?;\n\n    let qdrant_client = Qdrant::new(QdrantConfig::from_url(\u0026qdrant_url))?;\n    let qdrant_provider = QdrantProvider::new(qdrant_client, \"system_test\".to_string(), 128);\n    qdrant_provider\n        .ensure_collection()\n        .await\n        .map_err(|e| e.to_string())?;\n\n    let manager = MemoryManager::new();\n    manager\n        .register_provider(MemoryLayer::User, Box::new(qdrant_provider))\n        .await;\n\n    let entry = MemoryEntry {\n        id: \"system_msg_1\".to_string(),\n        content: \"System integration test content\".to_string(),\n        embedding: Some(vec![0.1; 128]),\n        layer: MemoryLayer::User,\n        metadata: HashMap::new(),\n        created_at: 1736400000,\n        updated_at: 1736400000,\n    };\n\n    let ctx = test_ctx();\n\n    manager\n        .add_to_layer(ctx.clone(), MemoryLayer::User, entry.clone())\n        .await\n        .map_err(|e| e.to_string())?;\n\n    let retrieved = manager\n        .get_from_layer(ctx.clone(), MemoryLayer::User, \"system_msg_1\")\n        .await\n        .map_err(|e| e.to_string())?;\n    assert!(retrieved.is_some());\n    let retrieved = retrieved.unwrap();\n    assert_eq!(retrieved.content, entry.content);\n\n    let search_results = manager\n        .search_hierarchical(ctx.clone(), vec![0.1; 128], 1, HashMap::new())\n        .await\n        .map_err(|e| e.to_string())?;\n    assert_eq!(search_results.len(), 1);\n    assert_eq!(search_results[0].id, \"system_msg_1\");\n\n    let session_entry = MemoryEntry {\n        id: \"session_important\".to_string(),\n        content: \"Important session content for promotion\".to_string(),\n        embedding: Some(vec![0.2; 128]),\n        layer: MemoryLayer::Session,\n        metadata: {\n            let mut m = HashMap::new();\n            m.insert(\"score\".to_string(), serde_json::json!(1.0));\n            m.insert(\"access_count\".to_string(), serde_json::json!(10));\n            m.insert(\n                \"last_accessed_at\".to_string(),\n                serde_json::json!(chrono::Utc::now().timestamp()),\n            );\n            m\n        },\n        created_at: 1736400000,\n        updated_at: 1736400000,\n    };\n\n    let session_qdrant_client = Qdrant::new(QdrantConfig::from_url(\u0026qdrant_url))?;\n    let session_provider =\n        QdrantProvider::new(session_qdrant_client, \"session_test\".to_string(), 128);\n    session_provider\n        .ensure_collection()\n        .await\n        .map_err(|e| e.to_string())?;\n\n    let project_qdrant_client = Qdrant::new(QdrantConfig::from_url(\u0026qdrant_url))?;\n    let project_provider =\n        QdrantProvider::new(project_qdrant_client, \"project_test\".to_string(), 128);\n    project_provider\n        .ensure_collection()\n        .await\n        .map_err(|e| e.to_string())?;\n\n    manager\n        .register_provider(MemoryLayer::Session, Box::new(session_provider))\n        .await;\n    manager\n        .register_provider(MemoryLayer::Project, Box::new(project_provider))\n        .await;\n\n    manager\n        .add_to_layer(ctx.clone(), MemoryLayer::Session, session_entry)\n        .await\n        .map_err(|e| e.to_string())?;\n\n    let promoted_ids = manager\n        .promote_important_memories(ctx.clone(), MemoryLayer::Session)\n        .await\n        .map_err(|e| e.to_string())?;\n    assert_eq!(promoted_ids.len(), 1);\n    assert!(promoted_ids[0].contains(\"session_important_promoted\"));\n\n    let promoted_entry = manager\n        .get_from_layer(ctx, MemoryLayer::Project, \u0026promoted_ids[0])\n        .await\n        .map_err(|e| e.to_string())?;\n    assert!(promoted_entry.is_some());\n    assert_eq!(\n        promoted_entry.unwrap().content,\n        \"Important session content for promotion\"\n    );\n\n    Ok(())\n}\n","traces":[{"line":21,"address":[],"length":0,"stats":{"Line":0}},{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":42,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":48,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":22},{"path":["/","Users","christian.klat","dev","git","aeterna","mk_core","src","lib.rs"],"content":"//! # Memory-Knowledge System Core\n//!\n//! Shared types, traits, and utilities for the Memory-Knowledge system.\n//!\n//! This crate provides:\n//! - Type definitions for memory and knowledge systems\n//! - Core traits for adapters and providers\n//! - Error types with proper handling\n//! - Validation utilities\n//!\n//! # Best Practices\n//!\n//! - Follows Microsoft Pragmatic Rust Guidelines\n//! - Uses Rust Edition 2024 (never back)\n//! - Comprehensive error handling with `thiserror`\n//! - M-CANONICAL-DOCS documentation format\n\npub mod traits;\npub mod types;\n\n// Re-export commonly used types for convenience\npub use types::{\n    ConstraintOperator, ConstraintSeverity, ConstraintTarget, HierarchyPath, KnowledgeLayer,\n    KnowledgeType, MemoryLayer, TenantContext, TenantId, UserId\n};\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","mk_core","src","traits.rs"],"content":"//! Core traits for memory-knowledge system\n\nuse async_trait::async_trait;\nuse serde::{Deserialize, Serialize};\n\n/// Storage backend trait for extensible storage implementations\n#[async_trait]\npub trait StorageBackend: Send + Sync {\n    type Error;\n\n    async fn store(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        key: \u0026str,\n        value: \u0026[u8]\n    ) -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn retrieve(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        key: \u0026str\n    ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e;\n\n    async fn delete(\u0026self, ctx: crate::types::TenantContext, key: \u0026str) -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn exists(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        key: \u0026str\n    ) -\u003e Result\u003cbool, Self::Error\u003e;\n\n    async fn get_ancestors(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        unit_id: \u0026str\n    ) -\u003e Result\u003cVec\u003ccrate::types::OrganizationalUnit\u003e, Self::Error\u003e;\n\n    async fn get_descendants(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        unit_id: \u0026str\n    ) -\u003e Result\u003cVec\u003ccrate::types::OrganizationalUnit\u003e, Self::Error\u003e;\n\n    async fn get_unit_policies(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        unit_id: \u0026str\n    ) -\u003e Result\u003cVec\u003ccrate::types::Policy\u003e, Self::Error\u003e;\n\n    async fn create_unit(\u0026self, unit: \u0026crate::types::OrganizationalUnit)\n    -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn add_unit_policy(\n        \u0026self,\n        ctx: \u0026crate::types::TenantContext,\n        unit_id: \u0026str,\n        policy: \u0026crate::types::Policy\n    ) -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn assign_role(\n        \u0026self,\n        user_id: \u0026crate::types::UserId,\n        tenant_id: \u0026crate::types::TenantId,\n        unit_id: \u0026str,\n        role: crate::types::Role\n    ) -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn remove_role(\n        \u0026self,\n        user_id: \u0026crate::types::UserId,\n        tenant_id: \u0026crate::types::TenantId,\n        unit_id: \u0026str,\n        role: crate::types::Role\n    ) -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn store_drift_result(\n        \u0026self,\n        result: crate::types::DriftResult\n    ) -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn get_latest_drift_result(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        project_id: \u0026str\n    ) -\u003e Result\u003cOption\u003ccrate::types::DriftResult\u003e, Self::Error\u003e;\n\n    async fn list_all_units(\u0026self) -\u003e Result\u003cVec\u003ccrate::types::OrganizationalUnit\u003e, Self::Error\u003e;\n    async fn record_job_status(\n        \u0026self,\n        job_name: \u0026str,\n        tenant_id: \u0026str,\n        status: \u0026str,\n        message: Option\u003c\u0026str\u003e,\n        started_at: i64,\n        finished_at: Option\u003ci64\u003e\n    ) -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn get_governance_events(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        since_timestamp: i64,\n        limit: usize\n    ) -\u003e Result\u003cVec\u003ccrate::types::GovernanceEvent\u003e, Self::Error\u003e;\n}\n\n/// Health check capability for service monitoring\npub trait HealthCheck: Send + Sync {\n    fn health_check(\u0026self) -\u003e Result\u003cHealthStatus, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e;\n}\n\n/// Health status for service monitoring\n#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]\npub enum HealthStatus {\n    Healthy,\n    Degraded,\n    Unhealthy\n}\n\n#[async_trait]\npub trait MemoryProviderAdapter: Send + Sync {\n    type Error;\n\n    async fn add(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        entry: crate::types::MemoryEntry\n    ) -\u003e Result\u003cString, Self::Error\u003e;\n\n    async fn search(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        query_vector: Vec\u003cf32\u003e,\n        limit: usize,\n        filters: std::collections::HashMap\u003cString, serde_json::Value\u003e\n    ) -\u003e Result\u003cVec\u003ccrate::types::MemoryEntry\u003e, Self::Error\u003e;\n\n    async fn get(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        id: \u0026str\n    ) -\u003e Result\u003cOption\u003ccrate::types::MemoryEntry\u003e, Self::Error\u003e;\n\n    async fn update(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        entry: crate::types::MemoryEntry\n    ) -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn delete(\u0026self, ctx: crate::types::TenantContext, id: \u0026str) -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn list(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        layer: crate::types::MemoryLayer,\n        limit: usize,\n        cursor: Option\u003cString\u003e\n    ) -\u003e Result\u003c(Vec\u003ccrate::types::MemoryEntry\u003e, Option\u003cString\u003e), Self::Error\u003e;\n}\n\n#[async_trait]\npub trait KnowledgeRepository: Send + Sync {\n    type Error;\n\n    async fn get(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        layer: crate::types::KnowledgeLayer,\n        path: \u0026str\n    ) -\u003e Result\u003cOption\u003ccrate::types::KnowledgeEntry\u003e, Self::Error\u003e;\n\n    async fn store(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        entry: crate::types::KnowledgeEntry,\n        message: \u0026str\n    ) -\u003e Result\u003cString, Self::Error\u003e;\n\n    async fn list(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        layer: crate::types::KnowledgeLayer,\n        prefix: \u0026str\n    ) -\u003e Result\u003cVec\u003ccrate::types::KnowledgeEntry\u003e, Self::Error\u003e;\n\n    async fn delete(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        layer: crate::types::KnowledgeLayer,\n        path: \u0026str,\n        message: \u0026str\n    ) -\u003e Result\u003cString, Self::Error\u003e;\n\n    async fn get_head_commit(\n        \u0026self,\n        ctx: crate::types::TenantContext\n    ) -\u003e Result\u003cOption\u003cString\u003e, Self::Error\u003e;\n\n    async fn get_affected_items(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        since_commit: \u0026str\n    ) -\u003e Result\u003cVec\u003c(crate::types::KnowledgeLayer, String)\u003e, Self::Error\u003e;\n\n    async fn search(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        query: \u0026str,\n        layers: Vec\u003ccrate::types::KnowledgeLayer\u003e,\n        limit: usize\n    ) -\u003e Result\u003cVec\u003ccrate::types::KnowledgeEntry\u003e, Self::Error\u003e;\n\n    fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e;\n}\n\n#[async_trait]\npub trait AuthorizationService: Send + Sync {\n    type Error;\n\n    async fn check_permission(\n        \u0026self,\n        ctx: \u0026crate::types::TenantContext,\n        action: \u0026str,\n        resource: \u0026str\n    ) -\u003e Result\u003cbool, Self::Error\u003e;\n\n    async fn get_user_roles(\n        \u0026self,\n        ctx: \u0026crate::types::TenantContext\n    ) -\u003e Result\u003cVec\u003ccrate::types::Role\u003e, Self::Error\u003e;\n\n    async fn assign_role(\n        \u0026self,\n        ctx: \u0026crate::types::TenantContext,\n        user_id: \u0026crate::types::UserId,\n        role: crate::types::Role\n    ) -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn remove_role(\n        \u0026self,\n        ctx: \u0026crate::types::TenantContext,\n        user_id: \u0026crate::types::UserId,\n        role: crate::types::Role\n    ) -\u003e Result\u003c(), Self::Error\u003e;\n}\n\n#[async_trait]\npub trait ContextHooks: Send + Sync {\n    async fn on_session_start(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        session_id: \u0026str\n    ) -\u003e anyhow::Result\u003c()\u003e;\n    async fn on_session_end(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        session_id: \u0026str\n    ) -\u003e anyhow::Result\u003c()\u003e;\n    async fn on_message(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        session_id: \u0026str,\n        message: \u0026str\n    ) -\u003e anyhow::Result\u003c()\u003e;\n    async fn on_tool_use(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        session_id: \u0026str,\n        tool_name: \u0026str,\n        params: serde_json::Value\n    ) -\u003e anyhow::Result\u003c()\u003e;\n}\n\n#[async_trait]\npub trait EmbeddingService: Send + Sync {\n    type Error;\n\n    async fn embed(\u0026self, text: \u0026str) -\u003e Result\u003cVec\u003cf32\u003e, Self::Error\u003e;\n\n    fn dimension(\u0026self) -\u003e usize;\n\n    async fn embed_batch(\u0026self, texts: \u0026[String]) -\u003e Result\u003cVec\u003cVec\u003cf32\u003e\u003e, Self::Error\u003e {\n        let mut results = Vec::with_capacity(texts.len());\n        for text in texts {\n            results.push(self.embed(text).await?);\n        }\n        Ok(results)\n    }\n}\n\n#[async_trait]\npub trait EventPublisher: Send + Sync {\n    type Error;\n\n    async fn publish(\u0026self, event: crate::types::GovernanceEvent) -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn subscribe(\n        \u0026self,\n        channels: \u0026[\u0026str]\n    ) -\u003e Result\u003ctokio::sync::mpsc::Receiver\u003ccrate::types::GovernanceEvent\u003e, Self::Error\u003e;\n}\n\n/// LLM service trait for text generation and reasoning\n#[async_trait]\npub trait LlmService: Send + Sync {\n    type Error;\n\n    /// Generates text based on a prompt\n    async fn generate(\u0026self, prompt: \u0026str) -\u003e Result\u003cString, Self::Error\u003e;\n\n    /// Analyzes content against a set of policies\n    async fn analyze_drift(\n        \u0026self,\n        content: \u0026str,\n        policies: \u0026[crate::types::Policy]\n    ) -\u003e Result\u003ccrate::types::ValidationResult, Self::Error\u003e;\n}\n","traces":[{"line":281,"address":[],"length":0,"stats":{"Line":1}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":284,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}}],"covered":1,"coverable":5},{"path":["/","Users","christian.klat","dev","git","aeterna","mk_core","src","types.rs"],"content":"use schemars::JsonSchema;\nuse serde::{Deserialize, Serialize};\nuse strum::{Display, EnumString};\nuse utoipa::ToSchema;\nuse validator::Validate;\n\n#[derive(\n    Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize, ToSchema, EnumString, Display,\n)]\n#[serde(rename_all = \"camelCase\")]\npub enum Role {\n    Developer,\n    TechLead,\n    Architect,\n    Admin,\n    Agent,\n}\n\n#[derive(\n    Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, ToSchema, EnumString, Display,\n)]\n#[serde(rename_all = \"camelCase\")]\n#[strum(serialize_all = \"camelCase\")]\npub enum UnitType {\n    Company,\n    Organization,\n    Team,\n    Project,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct OrganizationalUnit {\n    pub id: String,\n    pub name: String,\n    pub unit_type: UnitType,\n    pub parent_id: Option\u003cString\u003e,\n    pub tenant_id: TenantId,\n    pub metadata: std::collections::HashMap\u003cString, serde_json::Value\u003e,\n    pub created_at: i64,\n    pub updated_at: i64,\n}\n\n#[derive(\n    Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize, ToSchema, JsonSchema, PartialOrd, Ord,\n)]\n#[serde(transparent)]\npub struct TenantId(String);\n\nimpl TenantId {\n    pub fn new(id: String) -\u003e Option\u003cSelf\u003e {\n        if id.is_empty() || id.len() \u003e 100 {\n            None\n        } else {\n            Some(Self(id))\n        }\n    }\n\n    pub fn as_str(\u0026self) -\u003e \u0026str {\n        \u0026self.0\n    }\n\n    pub fn into_inner(self) -\u003e String {\n        self.0\n    }\n}\n\nimpl std::fmt::Display for TenantId {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        write!(f, \"{}\", self.0)\n    }\n}\n\nimpl Default for TenantId {\n    fn default() -\u003e Self {\n        Self(\"default\".to_string())\n    }\n}\n\nimpl std::str::FromStr for TenantId {\n    type Err = anyhow::Error;\n    fn from_str(s: \u0026str) -\u003e Result\u003cSelf, Self::Err\u003e {\n        Self::new(s.to_string()).ok_or_else(|| anyhow::anyhow!(\"Invalid tenant ID\"))\n    }\n}\n\nimpl Default for TenantContext {\n    fn default() -\u003e Self {\n        Self {\n            tenant_id: TenantId::default(),\n            user_id: UserId::default(),\n            agent_id: None,\n        }\n    }\n}\n\n#[derive(\n    Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize, ToSchema, JsonSchema, PartialOrd, Ord,\n)]\n#[serde(transparent)]\npub struct UserId(String);\n\nimpl UserId {\n    pub fn new(id: String) -\u003e Option\u003cSelf\u003e {\n        if id.is_empty() || id.len() \u003e 100 {\n            None\n        } else {\n            Some(Self(id))\n        }\n    }\n\n    pub fn as_str(\u0026self) -\u003e \u0026str {\n        \u0026self.0\n    }\n\n    pub fn into_inner(self) -\u003e String {\n        self.0\n    }\n}\n\nimpl std::fmt::Display for UserId {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        write!(f, \"{}\", self.0)\n    }\n}\n\nimpl std::str::FromStr for UserId {\n    type Err = anyhow::Error;\n    fn from_str(s: \u0026str) -\u003e Result\u003cSelf, Self::Err\u003e {\n        Self::new(s.to_string()).ok_or_else(|| anyhow::anyhow!(\"Invalid user ID\"))\n    }\n}\n\nimpl Default for UserId {\n    fn default() -\u003e Self {\n        Self(\"default\".to_string())\n    }\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\npub struct TenantContext {\n    pub tenant_id: TenantId,\n    pub user_id: UserId,\n    pub agent_id: Option\u003cString\u003e,\n}\n\nimpl TenantContext {\n    pub fn new(tenant_id: TenantId, user_id: UserId) -\u003e Self {\n        Self {\n            tenant_id,\n            user_id,\n            agent_id: None,\n        }\n    }\n\n    pub fn with_agent(tenant_id: TenantId, user_id: UserId, agent_id: String) -\u003e Self {\n        Self {\n            tenant_id,\n            user_id,\n            agent_id: Some(agent_id),\n        }\n    }\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\npub struct HierarchyPath {\n    pub company: String,\n    pub org: Option\u003cString\u003e,\n    pub team: Option\u003cString\u003e,\n    pub project: Option\u003cString\u003e,\n}\n\nimpl HierarchyPath {\n    pub fn company(id: String) -\u003e Self {\n        Self {\n            company: id,\n            org: None,\n            team: None,\n            project: None,\n        }\n    }\n\n    pub fn org(company: String, id: String) -\u003e Self {\n        Self {\n            company,\n            org: Some(id),\n            team: None,\n            project: None,\n        }\n    }\n\n    pub fn team(company: String, org: String, id: String) -\u003e Self {\n        Self {\n            company,\n            org: Some(org),\n            team: Some(id),\n            project: None,\n        }\n    }\n\n    pub fn project(company: String, org: String, team: String, id: String) -\u003e Self {\n        Self {\n            company,\n            org: Some(org),\n            team: Some(team),\n            project: Some(id),\n        }\n    }\n\n    pub fn depth(\u0026self) -\u003e usize {\n        if self.project.is_some() {\n            4\n        } else if self.team.is_some() {\n            3\n        } else if self.org.is_some() {\n            2\n        } else {\n            1\n        }\n    }\n\n    pub fn path_string(\u0026self) -\u003e String {\n        let mut parts = vec![self.company.clone()];\n        if let Some(o) = \u0026self.org {\n            parts.push(o.clone());\n        }\n        if let Some(t) = \u0026self.team {\n            parts.push(t.clone());\n        }\n        if let Some(p) = \u0026self.project {\n            parts.push(p.clone());\n        }\n        parts.join(\" \u003e \")\n    }\n}\n\nimpl Role {\n    #[must_use]\n    pub fn precedence(\u0026self) -\u003e u8 {\n        match self {\n            Role::Admin =\u003e 4,\n            Role::Architect =\u003e 3,\n            Role::TechLead =\u003e 2,\n            Role::Developer =\u003e 1,\n            Role::Agent =\u003e 0,\n        }\n    }\n\n    #[must_use]\n    pub fn display_name(\u0026self) -\u003e \u0026'static str {\n        match self {\n            Role::Developer =\u003e \"Developer\",\n            Role::TechLead =\u003e \"Tech Lead\",\n            Role::Architect =\u003e \"Architect\",\n            Role::Admin =\u003e \"Admin\",\n            Role::Agent =\u003e \"Agent\",\n        }\n    }\n}\n\n/// Knowledge types\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub enum KnowledgeType {\n    Adr,\n    Policy,\n    Pattern,\n    Spec,\n}\n\n/// Knowledge status\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub enum KnowledgeStatus {\n    Draft,\n    Proposed,\n    Accepted,\n    Deprecated,\n    Superseded,\n}\n\n#[derive(\n    Debug,\n    Clone,\n    Copy,\n    PartialEq,\n    Eq,\n    Hash,\n    Serialize,\n    Deserialize,\n    ToSchema,\n    PartialOrd,\n    Ord,\n    JsonSchema,\n)]\n#[serde(rename_all = \"camelCase\")]\npub enum KnowledgeLayer {\n    Company,\n    Org,\n    Team,\n    Project,\n}\n\n/// Constraint severity levels\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub enum ConstraintSeverity {\n    Info,\n    Warn,\n    Block,\n}\n\n/// Constraint operators\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub enum ConstraintOperator {\n    MustUse,\n    MustNotUse,\n    MustMatch,\n    MustNotMatch,\n    MustExist,\n    MustNotExist,\n}\n\n/// Constraint targets\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub enum ConstraintTarget {\n    File,\n    Code,\n    Dependency,\n    Import,\n    Config,\n}\n\n/// Memory layers for hierarchical storage\n#[derive(\n    Debug,\n    Clone,\n    Copy,\n    PartialEq,\n    Eq,\n    Hash,\n    Serialize,\n    Deserialize,\n    JsonSchema,\n    strum::EnumString,\n    strum::Display,\n    ToSchema,\n)]\n#[serde(rename_all = \"camelCase\")]\npub enum MemoryLayer {\n    Agent,\n    User,\n    Session,\n    Project,\n    Team,\n    Org,\n    Company,\n}\n\nimpl MemoryLayer {\n    #[must_use]\n    pub fn precedence(\u0026self) -\u003e u8 {\n        match self {\n            MemoryLayer::Agent =\u003e 1,\n            MemoryLayer::User =\u003e 2,\n            MemoryLayer::Session =\u003e 3,\n            MemoryLayer::Project =\u003e 4,\n            MemoryLayer::Team =\u003e 5,\n            MemoryLayer::Org =\u003e 6,\n            MemoryLayer::Company =\u003e 7,\n        }\n    }\n\n    #[must_use]\n    pub fn display_name(\u0026self) -\u003e \u0026'static str {\n        match self {\n            MemoryLayer::Agent =\u003e \"Agent\",\n            MemoryLayer::User =\u003e \"User\",\n            MemoryLayer::Session =\u003e \"Session\",\n            MemoryLayer::Project =\u003e \"Project\",\n            MemoryLayer::Team =\u003e \"Team\",\n            MemoryLayer::Org =\u003e \"Organization\",\n            MemoryLayer::Company =\u003e \"Company\",\n        }\n    }\n}\n\n#[derive(\n    Debug, Clone, PartialEq, Serialize, Deserialize, JsonSchema, Validate, Default, ToSchema,\n)]\n#[serde(rename_all = \"camelCase\")]\npub struct LayerIdentifiers {\n    #[validate(custom(function = \"validate_agent_id\"))]\n    pub agent_id: Option\u003cString\u003e,\n    #[validate(custom(function = \"validate_user_id\"))]\n    pub user_id: Option\u003cString\u003e,\n    #[validate(custom(function = \"validate_session_id\"))]\n    pub session_id: Option\u003cString\u003e,\n    #[validate(custom(function = \"validate_project_id\"))]\n    pub project_id: Option\u003cString\u003e,\n    #[validate(custom(function = \"validate_team_id\"))]\n    pub team_id: Option\u003cString\u003e,\n    #[validate(custom(function = \"validate_org_id\"))]\n    pub org_id: Option\u003cString\u003e,\n    #[validate(custom(function = \"validate_company_id\"))]\n    pub company_id: Option\u003cString\u003e,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct MemoryEntry {\n    pub id: String,\n    pub content: String,\n    pub embedding: Option\u003cVec\u003cf32\u003e\u003e,\n    pub layer: MemoryLayer,\n    pub metadata: std::collections::HashMap\u003cString, serde_json::Value\u003e,\n    pub created_at: i64,\n    pub updated_at: i64,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct KnowledgeEntry {\n    pub path: String,\n    pub content: String,\n    pub layer: KnowledgeLayer,\n    pub kind: KnowledgeType,\n    pub status: KnowledgeStatus,\n    pub metadata: std::collections::HashMap\u003cString, serde_json::Value\u003e,\n    pub commit_hash: Option\u003cString\u003e,\n    pub author: Option\u003cString\u003e,\n    pub updated_at: i64,\n}\n\n#[derive(\n    Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, JsonSchema, Default, ToSchema,\n)]\n#[serde(rename_all = \"camelCase\")]\npub enum PolicyMode {\n    #[default]\n    Optional,\n    Mandatory,\n}\n\n#[derive(\n    Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, JsonSchema, Default, ToSchema,\n)]\n#[serde(rename_all = \"camelCase\")]\npub enum RuleMergeStrategy {\n    #[default]\n    Override,\n    Merge,\n    Intersect,\n}\n\n#[derive(\n    Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, JsonSchema, Default, ToSchema,\n)]\n#[serde(rename_all = \"camelCase\")]\npub enum RuleType {\n    #[default]\n    Allow,\n    Deny,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct Policy {\n    pub id: String,\n    pub name: String,\n    pub description: Option\u003cString\u003e,\n    pub layer: KnowledgeLayer,\n    #[serde(default)]\n    pub mode: PolicyMode,\n    #[serde(default)]\n    pub merge_strategy: RuleMergeStrategy,\n    pub rules: Vec\u003cPolicyRule\u003e,\n    pub metadata: std::collections::HashMap\u003cString, serde_json::Value\u003e,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct PolicyRule {\n    pub id: String,\n    #[serde(default)]\n    pub rule_type: RuleType,\n    pub target: ConstraintTarget,\n    pub operator: ConstraintOperator,\n    pub value: serde_json::Value,\n    pub severity: ConstraintSeverity,\n    pub message: String,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct ValidationResult {\n    pub is_valid: bool,\n    pub violations: Vec\u003cPolicyViolation\u003e,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct PolicyViolation {\n    pub rule_id: String,\n    pub policy_id: String,\n    pub severity: ConstraintSeverity,\n    pub message: String,\n    pub context: std::collections::HashMap\u003cString, serde_json::Value\u003e,\n}\n\n/// Governance event types for auditing and real-time updates\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub enum GovernanceEvent {\n    /// New organizational unit created\n    UnitCreated {\n        unit_id: String,\n        unit_type: UnitType,\n        tenant_id: TenantId,\n        parent_id: Option\u003cString\u003e,\n        timestamp: i64,\n    },\n\n    /// Organizational unit updated\n    UnitUpdated {\n        unit_id: String,\n        tenant_id: TenantId,\n        timestamp: i64,\n    },\n\n    /// Organizational unit deleted\n    UnitDeleted {\n        unit_id: String,\n        tenant_id: TenantId,\n        timestamp: i64,\n    },\n\n    /// Role assigned to a user for a specific unit\n    RoleAssigned {\n        user_id: UserId,\n        unit_id: String,\n        role: Role,\n        tenant_id: TenantId,\n        timestamp: i64,\n    },\n\n    /// Role removed from a user\n    RoleRemoved {\n        user_id: UserId,\n        unit_id: String,\n        role: Role,\n        tenant_id: TenantId,\n        timestamp: i64,\n    },\n\n    /// Policy created or updated\n    PolicyUpdated {\n        policy_id: String,\n        layer: KnowledgeLayer,\n        tenant_id: TenantId,\n        timestamp: i64,\n    },\n\n    /// Policy deleted\n    PolicyDeleted {\n        policy_id: String,\n        tenant_id: TenantId,\n        timestamp: i64,\n    },\n\n    /// Drift detected in a project\n    DriftDetected {\n        project_id: String,\n        tenant_id: TenantId,\n        drift_score: f32,\n        timestamp: i64,\n    },\n}\n\nimpl GovernanceEvent {\n    #[must_use]\n    pub fn tenant_id(\u0026self) -\u003e \u0026TenantId {\n        match self {\n            GovernanceEvent::UnitCreated { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::UnitUpdated { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::UnitDeleted { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::RoleAssigned { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::RoleRemoved { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::PolicyUpdated { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::PolicyDeleted { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::DriftDetected { tenant_id, .. } =\u003e tenant_id,\n        }\n    }\n}\n\n/// Drift analysis result\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct DriftResult {\n    pub project_id: String,\n    pub tenant_id: TenantId,\n    pub drift_score: f32,\n    pub violations: Vec\u003cPolicyViolation\u003e,\n    pub timestamp: i64,\n}\n\npub fn validate_user_id(id: \u0026\u0026String) -\u003e Result\u003c(), validator::ValidationError\u003e {\n    if id.is_empty() {\n        return Err(validator::ValidationError::new(\"User ID cannot be empty\"));\n    }\n    if id.len() \u003e 100 {\n        return Err(validator::ValidationError::new(\"User ID is too long\"));\n    }\n    Ok(())\n}\n\npub fn validate_session_id(id: \u0026\u0026String) -\u003e Result\u003c(), validator::ValidationError\u003e {\n    if id.is_empty() {\n        return Err(validator::ValidationError::new(\n            \"Session ID cannot be empty\",\n        ));\n    }\n    Ok(())\n}\n\npub fn validate_project_id(id: \u0026\u0026String) -\u003e Result\u003c(), validator::ValidationError\u003e {\n    if id.is_empty() {\n        return Err(validator::ValidationError::new(\n            \"Project ID cannot be empty\",\n        ));\n    }\n    Ok(())\n}\n\npub fn validate_team_id(id: \u0026\u0026String) -\u003e Result\u003c(), validator::ValidationError\u003e {\n    if id.is_empty() {\n        return Err(validator::ValidationError::new(\"Team ID cannot be empty\"));\n    }\n    Ok(())\n}\n\npub fn validate_org_id(id: \u0026\u0026String) -\u003e Result\u003c(), validator::ValidationError\u003e {\n    if id.is_empty() {\n        return Err(validator::ValidationError::new(\"Org ID cannot be empty\"));\n    }\n    Ok(())\n}\n\npub fn validate_company_id(id: \u0026\u0026String) -\u003e Result\u003c(), validator::ValidationError\u003e {\n    if id.is_empty() {\n        return Err(validator::ValidationError::new(\n            \"Company ID cannot be empty\",\n        ));\n    }\n    Ok(())\n}\n\npub fn validate_agent_id(id: \u0026\u0026String) -\u003e Result\u003c(), validator::ValidationError\u003e {\n    if id.is_empty() {\n        return Err(validator::ValidationError::new(\"Agent ID cannot be empty\"));\n    }\n    if id.len() \u003e 100 {\n        return Err(validator::ValidationError::new(\"Agent ID is too long\"));\n    }\n    Ok(())\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use validator::Validate;\n\n    #[test]\n    fn test_knowledge_type_serialization() {\n        let adr = KnowledgeType::Adr;\n        let json = serde_json::to_string(\u0026adr).unwrap();\n        assert_eq!(json, \"\\\"adr\\\"\");\n\n        let deserialized: KnowledgeType = serde_json::from_str(\u0026json).unwrap();\n        assert_eq!(deserialized, KnowledgeType::Adr);\n    }\n\n    #[test]\n    fn test_knowledge_layer_serialization() {\n        let company = KnowledgeLayer::Company;\n        let json = serde_json::to_string(\u0026company).unwrap();\n        assert_eq!(json, \"\\\"company\\\"\");\n\n        let deserialized: KnowledgeLayer = serde_json::from_str(\u0026json).unwrap();\n        assert_eq!(deserialized, KnowledgeLayer::Company);\n    }\n\n    #[test]\n    fn test_memory_layer_precedence() {\n        assert_eq!(MemoryLayer::Agent.precedence(), 1);\n        assert_eq!(MemoryLayer::User.precedence(), 2);\n        assert_eq!(MemoryLayer::Session.precedence(), 3);\n        assert_eq!(MemoryLayer::Project.precedence(), 4);\n        assert_eq!(MemoryLayer::Team.precedence(), 5);\n        assert_eq!(MemoryLayer::Org.precedence(), 6);\n        assert_eq!(MemoryLayer::Company.precedence(), 7);\n    }\n\n    #[test]\n    fn test_memory_layer_serialization() {\n        let agent = MemoryLayer::Agent;\n        let json = serde_json::to_string(\u0026agent).unwrap();\n        assert_eq!(json, \"\\\"agent\\\"\");\n\n        let deserialized: MemoryLayer = serde_json::from_str(\u0026json).unwrap();\n        assert_eq!(deserialized, MemoryLayer::Agent);\n    }\n\n    #[test]\n    fn test_constraint_severity_serialization() {\n        let block = ConstraintSeverity::Block;\n        let json = serde_json::to_string(\u0026block).unwrap();\n        assert_eq!(json, \"\\\"block\\\"\");\n\n        let deserialized: ConstraintSeverity = serde_json::from_str(\u0026json).unwrap();\n        assert_eq!(deserialized, ConstraintSeverity::Block);\n    }\n\n    #[test]\n    fn test_constraint_operator_serialization() {\n        let must_use = ConstraintOperator::MustUse;\n        let json = serde_json::to_string(\u0026must_use).unwrap();\n        assert_eq!(json, \"\\\"mustUse\\\"\");\n\n        let deserialized: ConstraintOperator = serde_json::from_str(\u0026json).unwrap();\n        assert_eq!(deserialized, ConstraintOperator::MustUse);\n    }\n\n    #[test]\n    fn test_constraint_target_serialization() {\n        let file = ConstraintTarget::File;\n        let json = serde_json::to_string(\u0026file).unwrap();\n        assert_eq!(json, \"\\\"file\\\"\");\n\n        let deserialized: ConstraintTarget = serde_json::from_str(\u0026json).unwrap();\n        assert_eq!(deserialized, ConstraintTarget::File);\n    }\n\n    #[test]\n    fn test_memory_entry_creation() {\n        let entry = MemoryEntry {\n            id: \"test_id\".to_string(),\n            content: \"Test content\".to_string(),\n            embedding: Some(vec![0.1, 0.2, 0.3]),\n            layer: MemoryLayer::User,\n            metadata: std::collections::HashMap::new(),\n            created_at: 1234567890,\n            updated_at: 1234567890,\n        };\n\n        assert_eq!(entry.id, \"test_id\");\n        assert_eq!(entry.content, \"Test content\");\n        assert_eq!(entry.layer, MemoryLayer::User);\n        assert_eq!(entry.embedding.unwrap().len(), 3);\n    }\n\n    #[test]\n    fn test_knowledge_entry_creation() {\n        let entry = KnowledgeEntry {\n            path: \"docs/adr/001.md\".to_string(),\n            content: \"# ADR 001: Use Rust\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Adr,\n            metadata: std::collections::HashMap::new(),\n            commit_hash: Some(\"abc123\".to_string()),\n            author: Some(\"Alice\".to_string()),\n            status: KnowledgeStatus::Accepted,\n            updated_at: 1234567890,\n        };\n\n        assert_eq!(entry.path, \"docs/adr/001.md\");\n        assert_eq!(entry.layer, KnowledgeLayer::Project);\n        assert_eq!(entry.kind, KnowledgeType::Adr);\n        assert_eq!(entry.commit_hash.unwrap(), \"abc123\");\n    }\n\n    #[test]\n    fn test_policy_creation() {\n        let rule = PolicyRule {\n            id: \"rule_1\".to_string(),\n            rule_type: RuleType::Deny,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustNotUse,\n            value: serde_json::json!(\"unsafe-lib\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Do not use unsafe libraries\".to_string(),\n        };\n\n        let policy = Policy {\n            id: \"policy_1\".to_string(),\n            name: \"Security Policy\".to_string(),\n            description: Some(\"Security constraints\".to_string()),\n            layer: KnowledgeLayer::Company,\n            mode: PolicyMode::Mandatory,\n            merge_strategy: RuleMergeStrategy::Merge,\n            rules: vec![rule],\n            metadata: std::collections::HashMap::new(),\n        };\n\n        assert_eq!(policy.id, \"policy_1\");\n        assert_eq!(policy.layer, KnowledgeLayer::Company);\n        assert_eq!(policy.rules.len(), 1);\n        assert_eq!(policy.rules[0].target, ConstraintTarget::Dependency);\n    }\n\n    #[test]\n    fn test_validation_result_creation() {\n        let violation = PolicyViolation {\n            rule_id: \"rule_1\".to_string(),\n            policy_id: \"policy_1\".to_string(),\n            severity: ConstraintSeverity::Warn,\n            message: \"Warning message\".to_string(),\n            context: std::collections::HashMap::new(),\n        };\n\n        let result = ValidationResult {\n            is_valid: false,\n            violations: vec![violation],\n        };\n\n        assert!(!result.is_valid);\n        assert_eq!(result.violations.len(), 1);\n        assert_eq!(result.violations[0].severity, ConstraintSeverity::Warn);\n    }\n\n    #[test]\n    fn test_validate_user_id_valid() {\n        let user_id = \"user_123\".to_string();\n        let result = validate_user_id(\u0026\u0026user_id);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_validate_user_id_empty() {\n        let user_id = \"\".to_string();\n        let result = validate_user_id(\u0026\u0026user_id);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_validate_user_id_too_long() {\n        let user_id = \"a\".repeat(101);\n        let result = validate_user_id(\u0026\u0026user_id);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_validate_session_id_valid() {\n        let session_id = \"session_456\".to_string();\n        let result = validate_session_id(\u0026\u0026session_id);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_validate_project_id_valid() {\n        let project_id = \"project_789\".to_string();\n        let result = validate_project_id(\u0026\u0026project_id);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_validate_team_id_valid() {\n        let team_id = \"team_abc\".to_string();\n        let result = validate_team_id(\u0026\u0026team_id);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_validate_org_id_valid() {\n        let org_id = \"org_xyz\".to_string();\n        let result = validate_org_id(\u0026\u0026org_id);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_validate_company_id_valid() {\n        let company_id = \"company_123\".to_string();\n        let result = validate_company_id(\u0026\u0026company_id);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_layer_identifiers_validation() {\n        let identifiers = LayerIdentifiers {\n            agent_id: Some(\"agent_1\".to_string()),\n            user_id: Some(\"user_123\".to_string()),\n            session_id: Some(\"session_456\".to_string()),\n            project_id: Some(\"project_789\".to_string()),\n            team_id: Some(\"team_abc\".to_string()),\n            org_id: Some(\"org_xyz\".to_string()),\n            company_id: Some(\"company_123\".to_string()),\n        };\n\n        let result = identifiers.validate();\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_layer_identifiers_invalid_user_id() {\n        let identifiers = LayerIdentifiers {\n            agent_id: Some(\"agent_1\".to_string()),\n            user_id: Some(\"\".to_string()),\n            session_id: None,\n            project_id: None,\n            team_id: None,\n            org_id: None,\n            company_id: None,\n        };\n\n        let result = identifiers.validate();\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_memory_layer_display_name() {\n        assert_eq!(MemoryLayer::Agent.display_name(), \"Agent\");\n        assert_eq!(MemoryLayer::User.display_name(), \"User\");\n        assert_eq!(MemoryLayer::Session.display_name(), \"Session\");\n        assert_eq!(MemoryLayer::Project.display_name(), \"Project\");\n        assert_eq!(MemoryLayer::Team.display_name(), \"Team\");\n        assert_eq!(MemoryLayer::Org.display_name(), \"Organization\");\n        assert_eq!(MemoryLayer::Company.display_name(), \"Company\");\n    }\n\n    #[test]\n    fn test_validate_agent_id_valid() {\n        let agent_id = \"agent_123\".to_string();\n        let result = validate_agent_id(\u0026\u0026agent_id);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_validate_agent_id_empty() {\n        let agent_id = \"\".to_string();\n        let result = validate_agent_id(\u0026\u0026agent_id);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_validate_agent_id_too_long() {\n        let agent_id = \"a\".repeat(101);\n        let result = validate_agent_id(\u0026\u0026agent_id);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_validate_session_id_empty() {\n        let id = \"\".to_string();\n        assert!(validate_session_id(\u0026\u0026id).is_err());\n    }\n\n    #[test]\n    fn test_validate_project_id_empty() {\n        let id = \"\".to_string();\n        assert!(validate_project_id(\u0026\u0026id).is_err());\n    }\n\n    #[test]\n    fn test_validate_team_id_empty() {\n        let id = \"\".to_string();\n        assert!(validate_team_id(\u0026\u0026id).is_err());\n    }\n\n    #[test]\n    fn test_validate_org_id_empty() {\n        let id = \"\".to_string();\n        assert!(validate_org_id(\u0026\u0026id).is_err());\n    }\n\n    #[test]\n    fn test_validate_company_id_empty() {\n        let id = \"\".to_string();\n        assert!(validate_company_id(\u0026\u0026id).is_err());\n    }\n\n    #[test]\n    fn test_memory_layer_from_str() {\n        use std::str::FromStr;\n        assert_eq!(MemoryLayer::from_str(\"Agent\").unwrap(), MemoryLayer::Agent);\n        assert_eq!(\n            MemoryLayer::from_str(\"Session\").unwrap(),\n            MemoryLayer::Session\n        );\n        assert!(MemoryLayer::from_str(\"Invalid\").is_err());\n    }\n\n    #[test]\n    fn test_memory_layer_display() {\n        assert_eq!(format!(\"{}\", MemoryLayer::Agent), \"Agent\");\n        assert_eq!(format!(\"{}\", MemoryLayer::User), \"User\");\n        assert_eq!(format!(\"{}\", MemoryLayer::Session), \"Session\");\n        assert_eq!(format!(\"{}\", MemoryLayer::Project), \"Project\");\n        assert_eq!(format!(\"{}\", MemoryLayer::Team), \"Team\");\n        assert_eq!(format!(\"{}\", MemoryLayer::Org), \"Org\");\n        assert_eq!(format!(\"{}\", MemoryLayer::Company), \"Company\");\n    }\n\n    #[test]\n    fn test_role_serialization() {\n        let architect = Role::Architect;\n        let json = serde_json::to_string(\u0026architect).unwrap();\n        assert_eq!(json, \"\\\"architect\\\"\");\n\n        let deserialized: Role = serde_json::from_str(\u0026json).unwrap();\n        assert_eq!(deserialized, Role::Architect);\n    }\n\n    #[test]\n    fn test_role_precedence() {\n        assert_eq!(Role::Admin.precedence(), 4);\n        assert_eq!(Role::Architect.precedence(), 3);\n        assert_eq!(Role::TechLead.precedence(), 2);\n        assert_eq!(Role::Developer.precedence(), 1);\n        assert_eq!(Role::Agent.precedence(), 0);\n    }\n\n    #[test]\n    fn test_role_display_name() {\n        assert_eq!(Role::Developer.display_name(), \"Developer\");\n        assert_eq!(Role::TechLead.display_name(), \"Tech Lead\");\n        assert_eq!(Role::Architect.display_name(), \"Architect\");\n        assert_eq!(Role::Admin.display_name(), \"Admin\");\n        assert_eq!(Role::Agent.display_name(), \"Agent\");\n    }\n\n    #[test]\n    fn test_tenant_id_validation() {\n        assert!(TenantId::new(\"comp_123\".to_string()).is_some());\n        assert!(TenantId::new(\"\".to_string()).is_none());\n        assert!(TenantId::new(\"a\".repeat(101)).is_none());\n    }\n\n    #[test]\n    fn test_user_id_validation() {\n        assert!(UserId::new(\"user_456\".to_string()).is_some());\n        assert!(UserId::new(\"\".to_string()).is_none());\n        assert!(UserId::new(\"a\".repeat(101)).is_none());\n    }\n\n    #[test]\n    fn test_hierarchy_path_depth() {\n        let company = HierarchyPath::company(\"c1\".to_string());\n        assert_eq!(company.depth(), 1);\n\n        let org = HierarchyPath::org(\"c1\".to_string(), \"o1\".to_string());\n        assert_eq!(org.depth(), 2);\n\n        let team = HierarchyPath::team(\"c1\".to_string(), \"o1\".to_string(), \"t1\".to_string());\n        assert_eq!(team.depth(), 3);\n\n        let project = HierarchyPath::project(\n            \"c1\".to_string(),\n            \"o1\".to_string(),\n            \"t1\".to_string(),\n            \"p1\".to_string(),\n        );\n        assert_eq!(project.depth(), 4);\n    }\n\n    #[test]\n    fn test_hierarchy_path_string() {\n        let project = HierarchyPath::project(\n            \"c1\".to_string(),\n            \"o1\".to_string(),\n            \"t1\".to_string(),\n            \"p1\".to_string(),\n        );\n        assert_eq!(project.path_string(), \"c1 \u003e o1 \u003e t1 \u003e p1\");\n    }\n\n    #[test]\n    fn test_tenant_context_creation() {\n        let tenant_id = TenantId::new(\"c1\".to_string()).unwrap();\n        let user_id = UserId::new(\"u1\".to_string()).unwrap();\n        let ctx = TenantContext::new(tenant_id, user_id);\n\n        assert_eq!(ctx.tenant_id.as_str(), \"c1\");\n        assert_eq!(ctx.user_id.as_str(), \"u1\");\n        assert!(ctx.agent_id.is_none());\n    }\n\n    #[test]\n    fn test_tenant_context_with_agent() {\n        let tenant_id = TenantId::new(\"c1\".to_string()).unwrap();\n        let user_id = UserId::new(\"u1\".to_string()).unwrap();\n        let ctx = TenantContext::with_agent(tenant_id, user_id, \"a1\".to_string());\n\n        assert_eq!(ctx.agent_id.unwrap(), \"a1\");\n    }\n\n    #[test]\n    fn test_tenant_id_display() {\n        let id = TenantId::new(\"c1\".to_string()).unwrap();\n        assert_eq!(format!(\"{}\", id), \"c1\");\n    }\n\n    #[test]\n    fn test_user_id_display() {\n        let id = UserId::new(\"u1\".to_string()).unwrap();\n        assert_eq!(format!(\"{}\", id), \"u1\");\n    }\n\n    #[test]\n    fn test_tenant_id_from_str() {\n        use std::str::FromStr;\n        let id = TenantId::from_str(\"c1\").unwrap();\n        assert_eq!(id.as_str(), \"c1\");\n        assert!(TenantId::from_str(\"\").is_err());\n    }\n\n    #[test]\n    fn test_user_id_from_str() {\n        use std::str::FromStr;\n        let id = UserId::from_str(\"u1\").unwrap();\n        assert_eq!(id.as_str(), \"u1\");\n        assert!(UserId::from_str(\"\").is_err());\n    }\n\n    #[test]\n    fn test_tenant_id_into_inner() {\n        let id = TenantId::new(\"c1\".to_string()).unwrap();\n        assert_eq!(id.into_inner(), \"c1\");\n    }\n\n    #[test]\n    fn test_user_id_into_inner() {\n        let id = UserId::new(\"u1\".to_string()).unwrap();\n        assert_eq!(id.into_inner(), \"u1\");\n    }\n}\n","traces":[{"line":51,"address":[],"length":0,"stats":{"Line":221}},{"line":52,"address":[],"length":0,"stats":{"Line":661}},{"line":53,"address":[],"length":0,"stats":{"Line":3}},{"line":55,"address":[],"length":0,"stats":{"Line":218}},{"line":59,"address":[],"length":0,"stats":{"Line":165}},{"line":60,"address":[],"length":0,"stats":{"Line":165}},{"line":63,"address":[],"length":0,"stats":{"Line":1}},{"line":64,"address":[],"length":0,"stats":{"Line":1}},{"line":69,"address":[],"length":0,"stats":{"Line":1}},{"line":70,"address":[],"length":0,"stats":{"Line":3}},{"line":75,"address":[],"length":0,"stats":{"Line":1070}},{"line":76,"address":[],"length":0,"stats":{"Line":1070}},{"line":82,"address":[],"length":0,"stats":{"Line":71}},{"line":83,"address":[],"length":0,"stats":{"Line":286}},{"line":88,"address":[],"length":0,"stats":{"Line":1047}},{"line":90,"address":[],"length":0,"stats":{"Line":2094}},{"line":91,"address":[],"length":0,"stats":{"Line":1047}},{"line":104,"address":[],"length":0,"stats":{"Line":136}},{"line":105,"address":[],"length":0,"stats":{"Line":406}},{"line":106,"address":[],"length":0,"stats":{"Line":3}},{"line":108,"address":[],"length":0,"stats":{"Line":133}},{"line":112,"address":[],"length":0,"stats":{"Line":212}},{"line":113,"address":[],"length":0,"stats":{"Line":212}},{"line":116,"address":[],"length":0,"stats":{"Line":1}},{"line":117,"address":[],"length":0,"stats":{"Line":1}},{"line":122,"address":[],"length":0,"stats":{"Line":1}},{"line":123,"address":[],"length":0,"stats":{"Line":3}},{"line":129,"address":[],"length":0,"stats":{"Line":32}},{"line":130,"address":[],"length":0,"stats":{"Line":130}},{"line":135,"address":[],"length":0,"stats":{"Line":1095}},{"line":136,"address":[],"length":0,"stats":{"Line":1095}},{"line":148,"address":[],"length":0,"stats":{"Line":137}},{"line":156,"address":[],"length":0,"stats":{"Line":2}},{"line":160,"address":[],"length":0,"stats":{"Line":2}},{"line":174,"address":[],"length":0,"stats":{"Line":1}},{"line":183,"address":[],"length":0,"stats":{"Line":1}},{"line":186,"address":[],"length":0,"stats":{"Line":2}},{"line":192,"address":[],"length":0,"stats":{"Line":1}},{"line":195,"address":[],"length":0,"stats":{"Line":2}},{"line":196,"address":[],"length":0,"stats":{"Line":1}},{"line":201,"address":[],"length":0,"stats":{"Line":2}},{"line":204,"address":[],"length":0,"stats":{"Line":4}},{"line":205,"address":[],"length":0,"stats":{"Line":2}},{"line":206,"address":[],"length":0,"stats":{"Line":2}},{"line":210,"address":[],"length":0,"stats":{"Line":4}},{"line":211,"address":[],"length":0,"stats":{"Line":8}},{"line":212,"address":[],"length":0,"stats":{"Line":1}},{"line":213,"address":[],"length":0,"stats":{"Line":6}},{"line":214,"address":[],"length":0,"stats":{"Line":1}},{"line":215,"address":[],"length":0,"stats":{"Line":4}},{"line":216,"address":[],"length":0,"stats":{"Line":1}},{"line":218,"address":[],"length":0,"stats":{"Line":1}},{"line":222,"address":[],"length":0,"stats":{"Line":1}},{"line":223,"address":[],"length":0,"stats":{"Line":4}},{"line":224,"address":[],"length":0,"stats":{"Line":3}},{"line":225,"address":[],"length":0,"stats":{"Line":3}},{"line":227,"address":[],"length":0,"stats":{"Line":3}},{"line":228,"address":[],"length":0,"stats":{"Line":3}},{"line":230,"address":[],"length":0,"stats":{"Line":3}},{"line":231,"address":[],"length":0,"stats":{"Line":3}},{"line":233,"address":[],"length":0,"stats":{"Line":2}},{"line":239,"address":[],"length":0,"stats":{"Line":5}},{"line":240,"address":[],"length":0,"stats":{"Line":5}},{"line":241,"address":[],"length":0,"stats":{"Line":1}},{"line":242,"address":[],"length":0,"stats":{"Line":1}},{"line":243,"address":[],"length":0,"stats":{"Line":1}},{"line":244,"address":[],"length":0,"stats":{"Line":1}},{"line":245,"address":[],"length":0,"stats":{"Line":1}},{"line":250,"address":[],"length":0,"stats":{"Line":5}},{"line":251,"address":[],"length":0,"stats":{"Line":5}},{"line":252,"address":[],"length":0,"stats":{"Line":1}},{"line":253,"address":[],"length":0,"stats":{"Line":1}},{"line":254,"address":[],"length":0,"stats":{"Line":1}},{"line":255,"address":[],"length":0,"stats":{"Line":1}},{"line":256,"address":[],"length":0,"stats":{"Line":1}},{"line":364,"address":[],"length":0,"stats":{"Line":13}},{"line":365,"address":[],"length":0,"stats":{"Line":13}},{"line":366,"address":[],"length":0,"stats":{"Line":3}},{"line":367,"address":[],"length":0,"stats":{"Line":4}},{"line":368,"address":[],"length":0,"stats":{"Line":2}},{"line":369,"address":[],"length":0,"stats":{"Line":1}},{"line":370,"address":[],"length":0,"stats":{"Line":1}},{"line":371,"address":[],"length":0,"stats":{"Line":1}},{"line":372,"address":[],"length":0,"stats":{"Line":1}},{"line":377,"address":[],"length":0,"stats":{"Line":7}},{"line":378,"address":[],"length":0,"stats":{"Line":7}},{"line":379,"address":[],"length":0,"stats":{"Line":1}},{"line":380,"address":[],"length":0,"stats":{"Line":1}},{"line":381,"address":[],"length":0,"stats":{"Line":1}},{"line":382,"address":[],"length":0,"stats":{"Line":1}},{"line":383,"address":[],"length":0,"stats":{"Line":1}},{"line":384,"address":[],"length":0,"stats":{"Line":1}},{"line":385,"address":[],"length":0,"stats":{"Line":1}},{"line":584,"address":[],"length":0,"stats":{"Line":0}},{"line":585,"address":[],"length":0,"stats":{"Line":0}},{"line":586,"address":[],"length":0,"stats":{"Line":0}},{"line":587,"address":[],"length":0,"stats":{"Line":0}},{"line":588,"address":[],"length":0,"stats":{"Line":0}},{"line":589,"address":[],"length":0,"stats":{"Line":0}},{"line":590,"address":[],"length":0,"stats":{"Line":0}},{"line":591,"address":[],"length":0,"stats":{"Line":0}},{"line":592,"address":[],"length":0,"stats":{"Line":0}},{"line":593,"address":[],"length":0,"stats":{"Line":0}},{"line":609,"address":[],"length":0,"stats":{"Line":5}},{"line":610,"address":[],"length":0,"stats":{"Line":10}},{"line":611,"address":[],"length":0,"stats":{"Line":2}},{"line":613,"address":[],"length":0,"stats":{"Line":3}},{"line":614,"address":[],"length":0,"stats":{"Line":1}},{"line":616,"address":[],"length":0,"stats":{"Line":2}},{"line":619,"address":[],"length":0,"stats":{"Line":3}},{"line":620,"address":[],"length":0,"stats":{"Line":6}},{"line":621,"address":[],"length":0,"stats":{"Line":1}},{"line":622,"address":[],"length":0,"stats":{"Line":1}},{"line":625,"address":[],"length":0,"stats":{"Line":2}},{"line":628,"address":[],"length":0,"stats":{"Line":3}},{"line":629,"address":[],"length":0,"stats":{"Line":6}},{"line":630,"address":[],"length":0,"stats":{"Line":1}},{"line":631,"address":[],"length":0,"stats":{"Line":1}},{"line":634,"address":[],"length":0,"stats":{"Line":2}},{"line":637,"address":[],"length":0,"stats":{"Line":3}},{"line":638,"address":[],"length":0,"stats":{"Line":6}},{"line":639,"address":[],"length":0,"stats":{"Line":1}},{"line":641,"address":[],"length":0,"stats":{"Line":2}},{"line":644,"address":[],"length":0,"stats":{"Line":3}},{"line":645,"address":[],"length":0,"stats":{"Line":6}},{"line":646,"address":[],"length":0,"stats":{"Line":1}},{"line":648,"address":[],"length":0,"stats":{"Line":2}},{"line":651,"address":[],"length":0,"stats":{"Line":3}},{"line":652,"address":[],"length":0,"stats":{"Line":6}},{"line":653,"address":[],"length":0,"stats":{"Line":1}},{"line":654,"address":[],"length":0,"stats":{"Line":1}},{"line":657,"address":[],"length":0,"stats":{"Line":2}},{"line":660,"address":[],"length":0,"stats":{"Line":5}},{"line":661,"address":[],"length":0,"stats":{"Line":10}},{"line":662,"address":[],"length":0,"stats":{"Line":1}},{"line":664,"address":[],"length":0,"stats":{"Line":4}},{"line":665,"address":[],"length":0,"stats":{"Line":1}},{"line":667,"address":[],"length":0,"stats":{"Line":3}}],"covered":128,"coverable":138},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","src","events.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::EventPublisher;\nuse mk_core::types::GovernanceEvent;\nuse redis::AsyncCommands;\nuse std::sync::Arc;\nuse thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum EventError {\n    #[error(\"Redis error: {0}\")]\n    Redis(#[from] redis::RedisError),\n    #[error(\"Serialization error: {0}\")]\n    Serialization(#[from] serde_json::Error),\n    #[error(\"Internal error: {0}\")]\n    Internal(String),\n}\n\npub struct RedisPublisher {\n    client: Arc\u003credis::Client\u003e,\n    stream_name: String,\n}\n\nimpl RedisPublisher {\n    pub fn new(connection_url: \u0026str, stream_name: \u0026str) -\u003e Result\u003cSelf, EventError\u003e {\n        let client = redis::Client::open(connection_url)?;\n        Ok(Self {\n            client: Arc::new(client),\n            stream_name: stream_name.to_string(),\n        })\n    }\n}\n\n#[async_trait]\nimpl EventPublisher for RedisPublisher {\n    type Error = EventError;\n\n    async fn publish(\u0026self, event: GovernanceEvent) -\u003e Result\u003c(), Self::Error\u003e {\n        let mut conn = self.client.get_connection_manager().await?;\n        let event_json = serde_json::to_string(\u0026event)?;\n\n        let _: String = conn\n            .xadd(\u0026self.stream_name, \"*\", \u0026[(\"event\", event_json)])\n            .await?;\n\n        Ok(())\n    }\n\n    async fn subscribe(\n        \u0026self,\n        _channels: \u0026[\u0026str],\n    ) -\u003e Result\u003ctokio::sync::mpsc::Receiver\u003cGovernanceEvent\u003e, Self::Error\u003e {\n        let client = self.client.clone();\n        let stream_name = self.stream_name.clone();\n        let (tx, rx) = tokio::sync::mpsc::channel(100);\n\n        tokio::spawn(async move {\n            if let Ok(mut conn) = client.get_connection_manager().await {\n                let mut last_id = \"0\".to_string();\n\n                loop {\n                    let opts = redis::streams::StreamReadOptions::default()\n                        .block(0)\n                        .count(10);\n\n                    let result: Result\u003credis::streams::StreamReadReply, redis::RedisError\u003e = conn\n                        .xread_options(\u0026[\u0026stream_name], \u0026[\u0026last_id], \u0026opts)\n                        .await;\n\n                    match result {\n                        Ok(reply) =\u003e {\n                            for stream in reply.keys {\n                                for record in stream.ids {\n                                    if let Some(event_json) = record.map.get(\"event\") {\n                                        let event_str: String =\n                                            redis::from_redis_value(event_json.clone())\n                                                .unwrap_or_default();\n                                        if let Ok(event) =\n                                            serde_json::from_str::\u003cGovernanceEvent\u003e(\u0026event_str)\n                                        {\n                                            if tx.send(event).await.is_err() {\n                                                return;\n                                            }\n                                        }\n                                    }\n                                    last_id = record.id;\n                                }\n                            }\n                        }\n                        Err(e) =\u003e {\n                            tracing::error!(\"Redis subscription error: {}\", e);\n                            tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;\n                        }\n                    }\n                }\n            }\n        });\n\n        Ok(rx)\n    }\n}\n\npub struct MultiPublisher\u003cE: std::error::Error + Send + Sync + 'static\u003e {\n    publishers: Vec\u003cBox\u003cdyn EventPublisher\u003cError = E\u003e + Send + Sync\u003e\u003e,\n}\n\nimpl\u003cE: std::error::Error + Send + Sync + 'static\u003e MultiPublisher\u003cE\u003e {\n    pub fn new(publishers: Vec\u003cBox\u003cdyn EventPublisher\u003cError = E\u003e + Send + Sync\u003e\u003e) -\u003e Self {\n        Self { publishers }\n    }\n}\n\n#[async_trait]\nimpl\u003cE: std::error::Error + Send + Sync + 'static\u003e EventPublisher for MultiPublisher\u003cE\u003e {\n    type Error = E;\n\n    async fn publish(\u0026self, event: GovernanceEvent) -\u003e Result\u003c(), Self::Error\u003e {\n        for publisher in \u0026self.publishers {\n            publisher.publish(event.clone()).await?;\n        }\n        Ok(())\n    }\n\n    async fn subscribe(\n        \u0026self,\n        _channels: \u0026[\u0026str],\n    ) -\u003e Result\u003ctokio::sync::mpsc::Receiver\u003cGovernanceEvent\u003e, Self::Error\u003e {\n        panic!(\"Subscribe not implemented for multi-publisher\")\n    }\n}\n","traces":[{"line":24,"address":[],"length":0,"stats":{"Line":3}},{"line":25,"address":[],"length":0,"stats":{"Line":9}},{"line":26,"address":[],"length":0,"stats":{"Line":3}},{"line":27,"address":[],"length":0,"stats":{"Line":9}},{"line":28,"address":[],"length":0,"stats":{"Line":3}},{"line":37,"address":[],"length":0,"stats":{"Line":3}},{"line":56,"address":[],"length":0,"stats":{"Line":1}},{"line":57,"address":[],"length":0,"stats":{"Line":3}},{"line":58,"address":[],"length":0,"stats":{"Line":3}},{"line":61,"address":[],"length":0,"stats":{"Line":4}},{"line":62,"address":[],"length":0,"stats":{"Line":2}},{"line":63,"address":[],"length":0,"stats":{"Line":2}},{"line":65,"address":[],"length":0,"stats":{"Line":6}},{"line":66,"address":[],"length":0,"stats":{"Line":8}},{"line":67,"address":[],"length":0,"stats":{"Line":2}},{"line":69,"address":[],"length":0,"stats":{"Line":1}},{"line":70,"address":[],"length":0,"stats":{"Line":1}},{"line":71,"address":[],"length":0,"stats":{"Line":3}},{"line":72,"address":[],"length":0,"stats":{"Line":3}},{"line":73,"address":[],"length":0,"stats":{"Line":3}},{"line":74,"address":[],"length":0,"stats":{"Line":2}},{"line":75,"address":[],"length":0,"stats":{"Line":3}},{"line":76,"address":[],"length":0,"stats":{"Line":1}},{"line":77,"address":[],"length":0,"stats":{"Line":1}},{"line":78,"address":[],"length":0,"stats":{"Line":1}},{"line":80,"address":[],"length":0,"stats":{"Line":5}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":2}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":1}},{"line":116,"address":[],"length":0,"stats":{"Line":1}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}}],"covered":29,"coverable":37},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","src","lib.rs"],"content":"pub mod events;\npub mod postgres;\npub mod redis;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","src","postgres.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::StorageBackend;\nuse mk_core::types::{OrganizationalUnit, TenantContext, UnitType};\nuse sqlx::{Pool, Postgres, Row};\nuse thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum PostgresError {\n    #[error(\"Database error: {0}\")]\n    Database(#[from] sqlx::Error),\n    #[error(\"Serialization error: {0}\")]\n    Serialization(#[from] serde_json::Error),\n    #[error(\"Unit not found: {0}\")]\n    NotFound(String),\n}\n\npub struct PostgresBackend {\n    pool: Pool\u003cPostgres\u003e,\n}\n\nimpl PostgresBackend {\n    pub fn pool(\u0026self) -\u003e \u0026Pool\u003cPostgres\u003e {\n        \u0026self.pool\n    }\n\n    pub async fn new(connection_url: \u0026str) -\u003e Result\u003cSelf, PostgresError\u003e {\n        let pool = Pool::connect(connection_url).await?;\n        Ok(Self { pool })\n    }\n\n    pub async fn initialize_schema(\u0026self) -\u003e Result\u003c(), PostgresError\u003e {\n        // Enable pgcrypto extension for gen_random_uuid()\n        sqlx::query(\"CREATE EXTENSION IF NOT EXISTS pgcrypto\")\n            .execute(\u0026self.pool)\n            .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS sync_state (\n                id TEXT NOT NULL,\n                tenant_id TEXT NOT NULL,\n                data JSONB NOT NULL,\n                updated_at BIGINT NOT NULL,\n                PRIMARY KEY (id, tenant_id)\n            )\",\n        )\n        .execute(\u0026self.pool)\n        .await?;\n\n        sqlx::query(\"CREATE INDEX IF NOT EXISTS idx_sync_state_tenant_id ON sync_state(tenant_id)\")\n            .execute(\u0026self.pool)\n            .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS organizational_units (\n                id TEXT PRIMARY KEY,\n                name TEXT NOT NULL,\n                type TEXT NOT NULL, -- 'company', 'organization', 'team', 'project'\n                parent_id TEXT REFERENCES organizational_units(id),\n                tenant_id TEXT NOT NULL,\n                metadata JSONB DEFAULT '{}',\n                created_at BIGINT NOT NULL,\n                updated_at BIGINT NOT NULL\n            )\",\n        )\n        .execute(\u0026self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS user_roles (\n                user_id TEXT NOT NULL,\n                tenant_id TEXT NOT NULL,\n                unit_id TEXT NOT NULL REFERENCES organizational_units(id),\n                role TEXT NOT NULL,\n                created_at BIGINT NOT NULL,\n                PRIMARY KEY (user_id, tenant_id, unit_id, role)\n            )\",\n        )\n        .execute(\u0026self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS unit_policies (\n                id TEXT PRIMARY KEY,\n                unit_id TEXT NOT NULL REFERENCES organizational_units(id),\n                policy JSONB NOT NULL,\n                created_at BIGINT NOT NULL,\n                updated_at BIGINT NOT NULL\n            )\",\n        )\n        .execute(\u0026self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS governance_events (\n                id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n                event_type TEXT NOT NULL,\n                tenant_id TEXT NOT NULL,\n                payload JSONB NOT NULL,\n                timestamp BIGINT NOT NULL\n            )\",\n        )\n        .execute(\u0026self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS drift_results (\n                project_id TEXT NOT NULL,\n                tenant_id TEXT NOT NULL,\n                drift_score REAL NOT NULL,\n                violations JSONB NOT NULL,\n                timestamp BIGINT NOT NULL,\n                PRIMARY KEY (project_id, tenant_id, timestamp)\n            )\",\n        )\n        .execute(\u0026self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS job_status (\n                id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n                job_name TEXT NOT NULL,\n                tenant_id TEXT NOT NULL,\n                status TEXT NOT NULL, -- 'running', 'completed', 'failed'\n                message TEXT,\n                started_at BIGINT NOT NULL,\n                finished_at BIGINT,\n                duration_ms BIGINT\n            )\",\n        )\n        .execute(\u0026self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    pub async fn create_unit(\u0026self, unit: \u0026OrganizationalUnit) -\u003e Result\u003c(), PostgresError\u003e {\n        if let Some(ref parent_id) = unit.parent_id {\n            let parent = self\n                .get_unit_by_id(parent_id)\n                .await?\n                .ok_or_else(|| PostgresError::NotFound(parent_id.clone()))?;\n\n            match (parent.unit_type, unit.unit_type) {\n                (UnitType::Company, UnitType::Organization) =\u003e {}\n                (UnitType::Organization, UnitType::Team) =\u003e {}\n                (UnitType::Team, UnitType::Project) =\u003e {}\n                _ =\u003e {\n                    return Err(PostgresError::Database(sqlx::Error::Decode(\n                        format!(\n                            \"Invalid hierarchy: cannot create {:?} under {:?}\",\n                            unit.unit_type, parent.unit_type\n                        )\n                        .into(),\n                    )));\n                }\n            }\n        } else if unit.unit_type != UnitType::Company {\n            return Err(PostgresError::Database(sqlx::Error::Decode(\n                \"Only Company units can be root units (no parent)\".into(),\n            )));\n        }\n\n        sqlx::query(\n            \"INSERT INTO organizational_units (id, name, type, parent_id, tenant_id, metadata, \\\n             created_at, updated_at)\n             VALUES ($1, $2, $3, $4, $5, $6, $7, $8)\",\n        )\n        .bind(\u0026unit.id)\n        .bind(\u0026unit.name)\n        .bind(unit.unit_type.to_string().to_lowercase())\n        .bind(\u0026unit.parent_id)\n        .bind(unit.tenant_id.as_str())\n        .bind(serde_json::to_value(\u0026unit.metadata)?)\n        .bind(unit.created_at)\n        .bind(unit.updated_at)\n        .execute(\u0026self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    async fn get_unit_by_id(\u0026self, id: \u0026str) -\u003e Result\u003cOption\u003cOrganizationalUnit\u003e, PostgresError\u003e {\n        let row = sqlx::query(\n            \"SELECT id, name, type, parent_id, tenant_id, metadata, created_at, updated_at \n             FROM organizational_units WHERE id = $1\",\n        )\n        .bind(id)\n        .fetch_optional(\u0026self.pool)\n        .await?;\n\n        if let Some(row) = row {\n            let unit_type_str: String = row.get(\"type\");\n            let unit_type = match unit_type_str.as_str() {\n                \"company\" =\u003e UnitType::Company,\n                \"organization\" =\u003e UnitType::Organization,\n                \"team\" =\u003e UnitType::Team,\n                \"project\" =\u003e UnitType::Project,\n                _ =\u003e {\n                    return Err(PostgresError::Database(sqlx::Error::Decode(\n                        \"Invalid unit type\".into(),\n                    )));\n                }\n            };\n\n            Ok(Some(OrganizationalUnit {\n                id: row.get(\"id\"),\n                name: row.get(\"name\"),\n                unit_type,\n                parent_id: row.get(\"parent_id\"),\n                tenant_id: row.get::\u003cString, _\u003e(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                metadata: serde_json::from_value(row.get(\"metadata\"))?,\n                created_at: row.get(\"created_at\"),\n                updated_at: row.get(\"updated_at\"),\n            }))\n        } else {\n            Ok(None)\n        }\n    }\n\n    pub async fn get_unit(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cOrganizationalUnit\u003e, PostgresError\u003e {\n        let row = sqlx::query(\n            \"SELECT id, name, type, parent_id, tenant_id, metadata, created_at, updated_at \n             FROM organizational_units WHERE id = $1 AND tenant_id = $2\",\n        )\n        .bind(id)\n        .bind(ctx.tenant_id.as_str())\n        .fetch_optional(\u0026self.pool)\n        .await?;\n\n        if let Some(row) = row {\n            let unit_type_str: String = row.get(\"type\");\n            let unit_type = match unit_type_str.as_str() {\n                \"company\" =\u003e UnitType::Company,\n                \"organization\" =\u003e UnitType::Organization,\n                \"team\" =\u003e UnitType::Team,\n                \"project\" =\u003e UnitType::Project,\n                _ =\u003e {\n                    return Err(PostgresError::Database(sqlx::Error::Decode(\n                        \"Invalid unit type\".into(),\n                    )));\n                }\n            };\n\n            Ok(Some(OrganizationalUnit {\n                id: row.get(\"id\"),\n                name: row.get(\"name\"),\n                unit_type,\n                parent_id: row.get(\"parent_id\"),\n                tenant_id: row.get::\u003cString, _\u003e(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                metadata: serde_json::from_value(row.get(\"metadata\"))?,\n                created_at: row.get(\"created_at\"),\n                updated_at: row.get(\"updated_at\"),\n            }))\n        } else {\n            Ok(None)\n        }\n    }\n\n    pub async fn list_children(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        parent_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, PostgresError\u003e {\n        let rows = sqlx::query(\n            \"SELECT id, name, type, parent_id, tenant_id, metadata, created_at, updated_at \n             FROM organizational_units WHERE parent_id = $1 AND tenant_id = $2\",\n        )\n        .bind(parent_id)\n        .bind(ctx.tenant_id.as_str())\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        let mut units = Vec::new();\n        for row in rows {\n            let unit_type_str: String = row.get(\"type\");\n            let unit_type = match unit_type_str.as_str() {\n                \"company\" =\u003e UnitType::Company,\n                \"organization\" =\u003e UnitType::Organization,\n                \"team\" =\u003e UnitType::Team,\n                \"project\" =\u003e UnitType::Project,\n                _ =\u003e continue,\n            };\n\n            units.push(OrganizationalUnit {\n                id: row.get(\"id\"),\n                name: row.get(\"name\"),\n                unit_type,\n                parent_id: row.get(\"parent_id\"),\n                tenant_id: row.get::\u003cString, _\u003e(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                metadata: serde_json::from_value(row.get(\"metadata\"))?,\n                created_at: row.get(\"created_at\"),\n                updated_at: row.get(\"updated_at\"),\n            });\n        }\n\n        Ok(units)\n    }\n\n    pub async fn get_ancestors(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, PostgresError\u003e {\n        let rows = sqlx::query(\n            \"WITH RECURSIVE ancestors AS (\n                SELECT id, name, type, parent_id, tenant_id, metadata, created_at, updated_at\n                FROM organizational_units\n                WHERE id = $1 AND tenant_id = $2\n                UNION ALL\n                SELECT u.id, u.name, u.type, u.parent_id, u.tenant_id, u.metadata, u.created_at, \\\n             u.updated_at\n                FROM organizational_units u\n                INNER JOIN ancestors a ON u.id = a.parent_id AND u.tenant_id = a.tenant_id\n            )\n            SELECT * FROM ancestors WHERE id != $1\",\n        )\n        .bind(id)\n        .bind(ctx.tenant_id.as_str())\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        let mut units = Vec::new();\n        for row in rows {\n            let unit_type_str: String = row.get(\"type\");\n            let unit_type = match unit_type_str.as_str() {\n                \"company\" =\u003e UnitType::Company,\n                \"organization\" =\u003e UnitType::Organization,\n                \"team\" =\u003e UnitType::Team,\n                \"project\" =\u003e UnitType::Project,\n                _ =\u003e continue,\n            };\n\n            units.push(OrganizationalUnit {\n                id: row.get(\"id\"),\n                name: row.get(\"name\"),\n                unit_type,\n                parent_id: row.get(\"parent_id\"),\n                tenant_id: row.get::\u003cString, _\u003e(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                metadata: serde_json::from_value(row.get(\"metadata\"))?,\n                created_at: row.get(\"created_at\"),\n                updated_at: row.get(\"updated_at\"),\n            });\n        }\n\n        Ok(units)\n    }\n\n    pub async fn get_unit_ancestors(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, PostgresError\u003e {\n        self.get_ancestors(ctx, id).await\n    }\n\n    pub async fn get_unit_descendants(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, PostgresError\u003e {\n        let rows = sqlx::query(\n            \"WITH RECURSIVE descendants AS (\n                SELECT id, name, type, parent_id, tenant_id, metadata, created_at, updated_at\n                FROM organizational_units\n                WHERE id = $1 AND tenant_id = $2\n                UNION ALL\n                SELECT u.id, u.name, u.type, u.parent_id, u.tenant_id, u.metadata, u.created_at, \\\n             u.updated_at\n                FROM organizational_units u\n                INNER JOIN descendants d ON u.parent_id = d.id AND u.tenant_id = d.tenant_id\n            )\n            SELECT * FROM descendants WHERE id != $1\",\n        )\n        .bind(id)\n        .bind(ctx.tenant_id.as_str())\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        let mut units = Vec::new();\n        for row in rows {\n            let unit_type_str: String = row.get(\"type\");\n            let unit_type = match unit_type_str.as_str() {\n                \"company\" =\u003e UnitType::Company,\n                \"organization\" =\u003e UnitType::Organization,\n                \"team\" =\u003e UnitType::Team,\n                \"project\" =\u003e UnitType::Project,\n                _ =\u003e continue,\n            };\n\n            units.push(OrganizationalUnit {\n                id: row.get(\"id\"),\n                name: row.get(\"name\"),\n                unit_type,\n                parent_id: row.get(\"parent_id\"),\n                tenant_id: row.get::\u003cString, _\u003e(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                metadata: serde_json::from_value(row.get(\"metadata\"))?,\n                created_at: row.get(\"created_at\"),\n                updated_at: row.get(\"updated_at\"),\n            });\n        }\n\n        Ok(units)\n    }\n\n    pub async fn update_unit(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        unit: \u0026OrganizationalUnit,\n    ) -\u003e Result\u003c(), PostgresError\u003e {\n        sqlx::query(\n            \"UPDATE organizational_units \n             SET name = $3, type = $4, parent_id = $5, metadata = $6, updated_at = $7\n             WHERE id = $1 AND tenant_id = $2\",\n        )\n        .bind(\u0026unit.id)\n        .bind(ctx.tenant_id.as_str())\n        .bind(\u0026unit.name)\n        .bind(unit.unit_type.to_string().to_lowercase())\n        .bind(\u0026unit.parent_id)\n        .bind(serde_json::to_value(\u0026unit.metadata)?)\n        .bind(unit.updated_at)\n        .execute(\u0026self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    pub async fn delete_unit(\u0026self, ctx: \u0026TenantContext, id: \u0026str) -\u003e Result\u003c(), PostgresError\u003e {\n        sqlx::query(\"DELETE FROM organizational_units WHERE id = $1 AND tenant_id = $2\")\n            .bind(id)\n            .bind(ctx.tenant_id.as_str())\n            .execute(\u0026self.pool)\n            .await?;\n\n        Ok(())\n    }\n\n    pub async fn add_unit_policy(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        unit_id: \u0026str,\n        policy: \u0026mk_core::types::Policy,\n    ) -\u003e Result\u003c(), PostgresError\u003e {\n        let exists: Option\u003c(i64,)\u003e =\n            sqlx::query_as(\"SELECT 1 FROM organizational_units WHERE id = $1 AND tenant_id = $2\")\n                .bind(unit_id)\n                .bind(ctx.tenant_id.as_str())\n                .fetch_optional(\u0026self.pool)\n                .await?;\n\n        if exists.is_none() {\n            return Err(PostgresError::NotFound(unit_id.to_string()));\n        }\n\n        sqlx::query(\n            \"INSERT INTO unit_policies (id, unit_id, policy, created_at, updated_at)\n             VALUES ($1, $2, $3, $4, $5)\n             ON CONFLICT (id) DO UPDATE SET policy = $3, updated_at = $5\",\n        )\n        .bind(\u0026policy.id)\n        .bind(unit_id)\n        .bind(serde_json::to_value(policy)?)\n        .bind(chrono::Utc::now().timestamp())\n        .bind(chrono::Utc::now().timestamp())\n        .execute(\u0026self.pool)\n        .await?;\n        Ok(())\n    }\n\n    pub async fn get_unit_policies(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::Policy\u003e, PostgresError\u003e {\n        let rows = sqlx::query(\n            \"SELECT p.policy \n             FROM unit_policies p\n             JOIN organizational_units u ON p.unit_id = u.id\n             WHERE p.unit_id = $1 AND u.tenant_id = $2\",\n        )\n        .bind(unit_id)\n        .bind(ctx.tenant_id.as_str())\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        let mut policies = Vec::new();\n        for row in rows {\n            let policy: mk_core::types::Policy = serde_json::from_value(row.get(\"policy\"))?;\n            policies.push(policy);\n        }\n        Ok(policies)\n    }\n\n    pub async fn assign_role(\n        \u0026self,\n        user_id: \u0026mk_core::types::UserId,\n        tenant_id: \u0026mk_core::types::TenantId,\n        unit_id: \u0026str,\n        role: mk_core::types::Role,\n    ) -\u003e Result\u003c(), PostgresError\u003e {\n        sqlx::query(\n            \"INSERT INTO user_roles (user_id, tenant_id, unit_id, role, created_at)\n             VALUES ($1, $2, $3, $4, $5)\n             ON CONFLICT (user_id, tenant_id, unit_id, role) DO NOTHING\",\n        )\n        .bind(user_id.as_str())\n        .bind(tenant_id.as_str())\n        .bind(unit_id)\n        .bind(role.to_string().to_lowercase())\n        .bind(chrono::Utc::now().timestamp())\n        .execute(\u0026self.pool)\n        .await?;\n        Ok(())\n    }\n\n    pub async fn remove_role(\n        \u0026self,\n        user_id: \u0026mk_core::types::UserId,\n        tenant_id: \u0026mk_core::types::TenantId,\n        unit_id: \u0026str,\n        role: mk_core::types::Role,\n    ) -\u003e Result\u003c(), PostgresError\u003e {\n        sqlx::query(\n            \"DELETE FROM user_roles \n             WHERE user_id = $1 AND tenant_id = $2 AND unit_id = $3 AND role = $4\",\n        )\n        .bind(user_id.as_str())\n        .bind(tenant_id.as_str())\n        .bind(unit_id)\n        .bind(role.to_string().to_lowercase())\n        .execute(\u0026self.pool)\n        .await?;\n        Ok(())\n    }\n\n    pub async fn get_user_roles(\n        \u0026self,\n        user_id: \u0026mk_core::types::UserId,\n        tenant_id: \u0026mk_core::types::TenantId,\n    ) -\u003e Result\u003cVec\u003c(String, mk_core::types::Role)\u003e, PostgresError\u003e {\n        let rows = sqlx::query(\n            \"SELECT unit_id, role FROM user_roles WHERE user_id = $1 AND tenant_id = $2\",\n        )\n        .bind(user_id.as_str())\n        .bind(tenant_id.as_str())\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        let mut roles = Vec::new();\n        for row in rows {\n            let unit_id: String = row.get(\"unit_id\");\n            let role_str: String = row.get(\"role\");\n            if let Ok(role) = role_str.parse() {\n                roles.push((unit_id, role));\n            }\n        }\n        Ok(roles)\n    }\n    pub async fn log_event(\n        \u0026self,\n        event: \u0026mk_core::types::GovernanceEvent,\n    ) -\u003e Result\u003c(), PostgresError\u003e {\n        let (event_type, tenant_id, timestamp) = match event {\n            mk_core::types::GovernanceEvent::UnitCreated {\n                unit_id: _,\n                unit_type: _,\n                tenant_id,\n                parent_id: _,\n                timestamp,\n            } =\u003e (\"unit_created\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::UnitUpdated {\n                unit_id: _,\n                tenant_id,\n                timestamp,\n            } =\u003e (\"unit_updated\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::UnitDeleted {\n                unit_id: _,\n                tenant_id,\n                timestamp,\n            } =\u003e (\"unit_deleted\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::RoleAssigned {\n                user_id: _,\n                unit_id: _,\n                role: _,\n                tenant_id,\n                timestamp,\n            } =\u003e (\"role_assigned\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::RoleRemoved {\n                user_id: _,\n                unit_id: _,\n                role: _,\n                tenant_id,\n                timestamp,\n            } =\u003e (\"role_removed\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::PolicyUpdated {\n                policy_id: _,\n                layer: _,\n                tenant_id,\n                timestamp,\n            } =\u003e (\"policy_updated\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::PolicyDeleted {\n                policy_id: _,\n                tenant_id,\n                timestamp,\n            } =\u003e (\"policy_deleted\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::DriftDetected {\n                project_id: _,\n                tenant_id,\n                drift_score: _,\n                timestamp,\n            } =\u003e (\"drift_detected\", tenant_id, *timestamp),\n        };\n\n        sqlx::query(\n            \"INSERT INTO governance_events (event_type, tenant_id, payload, timestamp)\n             VALUES ($1, $2, $3, $4)\",\n        )\n        .bind(event_type)\n        .bind(tenant_id.as_str())\n        .bind(serde_json::to_value(event)?)\n        .bind(timestamp)\n        .execute(\u0026self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    pub async fn get_governance_events_internal(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        since_timestamp: i64,\n        limit: usize,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e, PostgresError\u003e {\n        let rows = sqlx::query(\n            \"SELECT payload FROM governance_events \n             WHERE tenant_id = $1 AND timestamp \u003e $2 \n             ORDER BY timestamp ASC LIMIT $3\",\n        )\n        .bind(ctx.tenant_id.as_str())\n        .bind(since_timestamp)\n        .bind(limit as i64)\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        let mut events = Vec::new();\n        for row in rows {\n            use sqlx::Row;\n            let payload: serde_json::Value = row.get(\"payload\");\n            let event: mk_core::types::GovernanceEvent = serde_json::from_value(payload)?;\n            events.push(event);\n        }\n        Ok(events)\n    }\n}\n\n#[async_trait]\nimpl mk_core::traits::EventPublisher for PostgresBackend {\n    type Error = PostgresError;\n\n    async fn publish(\u0026self, event: mk_core::types::GovernanceEvent) -\u003e Result\u003c(), Self::Error\u003e {\n        self.log_event(\u0026event).await\n    }\n\n    async fn subscribe(\n        \u0026self,\n        _channels: \u0026[\u0026str],\n    ) -\u003e Result\u003ctokio::sync::mpsc::Receiver\u003cmk_core::types::GovernanceEvent\u003e, Self::Error\u003e {\n        Err(PostgresError::Database(sqlx::Error::Decode(\n            \"Subscribe not implemented for Postgres backend\".into(),\n        )))\n    }\n}\n\n#[async_trait]\nimpl StorageBackend for PostgresBackend {\n    type Error = PostgresError;\n\n    async fn store(\u0026self, ctx: TenantContext, key: \u0026str, value: \u0026[u8]) -\u003e Result\u003c(), Self::Error\u003e {\n        sqlx::query(\n            \"INSERT INTO sync_state (id, tenant_id, data, updated_at)\n             VALUES ($1, $2, $3, $4)\n             ON CONFLICT (id, tenant_id) DO UPDATE SET data = $3, updated_at = $4\",\n        )\n        .bind(key)\n        .bind(ctx.tenant_id.as_str())\n        .bind(serde_json::from_slice::\u003cserde_json::Value\u003e(value).unwrap_or_default())\n        .bind(chrono::Utc::now().timestamp())\n        .execute(\u0026self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    async fn retrieve(\n        \u0026self,\n        ctx: TenantContext,\n        key: \u0026str,\n    ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e {\n        let row: Option\u003c(serde_json::Value,)\u003e =\n            sqlx::query_as(\"SELECT data FROM sync_state WHERE id = $1 AND tenant_id = $2\")\n                .bind(key)\n                .bind(ctx.tenant_id.as_str())\n                .fetch_optional(\u0026self.pool)\n                .await?;\n\n        Ok(row.and_then(|(v,)| serde_json::to_vec(\u0026v).ok()))\n    }\n\n    async fn delete(\u0026self, ctx: TenantContext, key: \u0026str) -\u003e Result\u003c(), Self::Error\u003e {\n        sqlx::query(\"DELETE FROM sync_state WHERE id = $1 AND tenant_id = $2\")\n            .bind(key)\n            .bind(ctx.tenant_id.as_str())\n            .execute(\u0026self.pool)\n            .await?;\n\n        Ok(())\n    }\n\n    async fn exists(\u0026self, ctx: TenantContext, key: \u0026str) -\u003e Result\u003cbool, Self::Error\u003e {\n        let row: Option\u003c(i32,)\u003e =\n            sqlx::query_as(\"SELECT 1 FROM sync_state WHERE id = $1 AND tenant_id = $2\")\n                .bind(key)\n                .bind(ctx.tenant_id.as_str())\n                .fetch_optional(\u0026self.pool)\n                .await?;\n\n        Ok(row.is_some())\n    }\n\n    async fn get_ancestors(\n        \u0026self,\n        ctx: TenantContext,\n        unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, Self::Error\u003e {\n        self.get_unit_ancestors(\u0026ctx, unit_id).await\n    }\n\n    async fn get_descendants(\n        \u0026self,\n        ctx: TenantContext,\n        unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, Self::Error\u003e {\n        self.get_unit_descendants(\u0026ctx, unit_id).await\n    }\n\n    async fn get_unit_policies(\n        \u0026self,\n        ctx: TenantContext,\n        unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::Policy\u003e, Self::Error\u003e {\n        self.get_unit_policies(\u0026ctx, unit_id).await\n    }\n\n    async fn create_unit(\u0026self, unit: \u0026OrganizationalUnit) -\u003e Result\u003c(), Self::Error\u003e {\n        self.create_unit(unit).await\n    }\n\n    async fn add_unit_policy(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        unit_id: \u0026str,\n        policy: \u0026mk_core::types::Policy,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        self.add_unit_policy(ctx, unit_id, policy).await\n    }\n\n    async fn assign_role(\n        \u0026self,\n        user_id: \u0026mk_core::types::UserId,\n        tenant_id: \u0026mk_core::types::TenantId,\n        unit_id: \u0026str,\n        role: mk_core::types::Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        self.assign_role(user_id, tenant_id, unit_id, role).await\n    }\n\n    async fn remove_role(\n        \u0026self,\n        user_id: \u0026mk_core::types::UserId,\n        tenant_id: \u0026mk_core::types::TenantId,\n        unit_id: \u0026str,\n        role: mk_core::types::Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        self.remove_role(user_id, tenant_id, unit_id, role).await\n    }\n\n    async fn store_drift_result(\n        \u0026self,\n        result: mk_core::types::DriftResult,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        sqlx::query(\n            \"INSERT INTO drift_results (project_id, tenant_id, drift_score, violations, timestamp)\n             VALUES ($1, $2, $3, $4, $5)\",\n        )\n        .bind(\u0026result.project_id)\n        .bind(result.tenant_id.as_str())\n        .bind(result.drift_score)\n        .bind(serde_json::to_value(\u0026result.violations)?)\n        .bind(result.timestamp)\n        .execute(\u0026self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    async fn get_latest_drift_result(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        project_id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cmk_core::types::DriftResult\u003e, Self::Error\u003e {\n        let row = sqlx::query(\n            \"SELECT project_id, tenant_id, drift_score, violations, timestamp \n             FROM drift_results \n             WHERE project_id = $1 AND tenant_id = $2 \n             ORDER BY timestamp DESC LIMIT 1\",\n        )\n        .bind(project_id)\n        .bind(ctx.tenant_id.as_str())\n        .fetch_optional(\u0026self.pool)\n        .await?;\n\n        if let Some(row) = row {\n            Ok(Some(mk_core::types::DriftResult {\n                project_id: row.get(\"project_id\"),\n                tenant_id: row.get::\u003cString, _\u003e(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                drift_score: row.get(\"drift_score\"),\n                violations: serde_json::from_value(row.get(\"violations\"))?,\n                timestamp: row.get(\"timestamp\"),\n            }))\n        } else {\n            Ok(None)\n        }\n    }\n\n    async fn record_job_status(\n        \u0026self,\n        job_name: \u0026str,\n        tenant_id: \u0026str,\n        status: \u0026str,\n        message: Option\u003c\u0026str\u003e,\n        started_at: i64,\n        finished_at: Option\u003ci64\u003e,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        let duration_ms = finished_at.map(|f| (f - started_at) * 1000);\n\n        sqlx::query(\n            \"INSERT INTO job_status (job_name, tenant_id, status, message, started_at, \\\n             finished_at, duration_ms)\n             VALUES ($1, $2, $3, $4, $5, $6, $7)\",\n        )\n        .bind(job_name)\n        .bind(tenant_id)\n        .bind(status)\n        .bind(message)\n        .bind(started_at)\n        .bind(finished_at)\n        .bind(duration_ms)\n        .execute(\u0026self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    async fn get_governance_events(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        since_timestamp: i64,\n        limit: usize,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e, Self::Error\u003e {\n        self.get_governance_events_internal(ctx, since_timestamp, limit)\n            .await\n    }\n\n    async fn list_all_units(\u0026self) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        let rows = sqlx::query(\n            \"SELECT id, name, type, parent_id, tenant_id, metadata, created_at, updated_at \n             FROM organizational_units\",\n        )\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        let mut units = Vec::new();\n        for row in rows {\n            let unit_type_str: String = row.get(\"type\");\n            let unit_type = match unit_type_str.as_str() {\n                \"company\" =\u003e UnitType::Company,\n                \"organization\" =\u003e UnitType::Organization,\n                \"team\" =\u003e UnitType::Team,\n                \"project\" =\u003e UnitType::Project,\n                _ =\u003e continue,\n            };\n\n            units.push(mk_core::types::OrganizationalUnit {\n                id: row.get(\"id\"),\n                name: row.get(\"name\"),\n                unit_type,\n                parent_id: row.get(\"parent_id\"),\n                tenant_id: row.get::\u003cString, _\u003e(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                metadata: serde_json::from_value(row.get(\"metadata\"))?,\n                created_at: row.get(\"created_at\"),\n                updated_at: row.get(\"updated_at\"),\n            });\n        }\n\n        Ok(units)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use chrono::Datelike;\n    use serde_json::json;\n\n    // Test PostgresError display\n    #[test]\n    fn test_postgres_error_display() {\n        let error = PostgresError::Database(sqlx::Error::Configuration(\n            \"Invalid connection string\".into(),\n        ));\n\n        assert!(error.to_string().contains(\"Database error\"));\n        assert!(error.to_string().contains(\"Invalid connection string\"));\n    }\n\n    // Test error conversion from sqlx::Error\n    #[test]\n    fn test_postgres_error_from_sqlx() {\n        let sqlx_error = sqlx::Error::Configuration(\"test\".into());\n        let pg_error: PostgresError = sqlx_error.into();\n\n        match pg_error {\n            PostgresError::Database(_) =\u003e (),\n            PostgresError::Serialization(_) =\u003e (),\n            PostgresError::NotFound(_) =\u003e (),\n        }\n    }\n\n    // Test PostgresBackend struct (compile-time checks)\n    #[test]\n    fn test_postgres_backend_struct() {\n        // Verify the struct has expected fields\n        struct TestBackend {\n            _pool: Pool\u003cPostgres\u003e,\n        }\n\n        // This is a compile-time test - if it compiles, PostgresBackend has the right\n        // structure We can't instantiate it without a real database connection\n        let _backend_type = std::any::type_name::\u003cPostgresBackend\u003e();\n        assert_eq!(_backend_type, \"storage::postgres::PostgresBackend\");\n    }\n\n    // Test StorageBackend trait implementation\n    #[test]\n    fn test_storage_backend_trait_implementation() {\n        use mk_core::traits::StorageBackend;\n\n        // Compile-time check that PostgresBackend implements StorageBackend\n        fn assert_implements_storage_backend\u003cT: StorageBackend\u003e() {}\n\n        assert_implements_storage_backend::\u003cPostgresBackend\u003e();\n    }\n\n    // Test JSON serialization patterns used in the code\n    #[test]\n    fn test_json_serialization_patterns() {\n        // Test the serialization pattern used in store() method\n        let value = json!({\"key\": \"value\", \"number\": 42});\n        let bytes = serde_json::to_vec(\u0026value).unwrap();\n\n        // Test deserialization pattern used in retrieve() method\n        let deserialized: serde_json::Value = serde_json::from_slice(\u0026bytes).unwrap();\n        assert_eq!(deserialized[\"key\"], \"value\");\n        assert_eq!(deserialized[\"number\"], 42);\n\n        // Test default fallback used in store()\n        let invalid_bytes = b\"not json\";\n        let default_value =\n            serde_json::from_slice::\u003cserde_json::Value\u003e(invalid_bytes).unwrap_or_default();\n        assert!(default_value.is_null() || default_value == json!({}));\n    }\n\n    // Test timestamp generation pattern\n    #[test]\n    fn test_timestamp_generation() {\n        use chrono::Utc;\n\n        let timestamp = Utc::now().timestamp();\n        assert!(timestamp \u003e 0); // Should be positive (after 1970)\n\n        // Verify it's a reasonable timestamp (not in distant future)\n        let current_year = Utc::now().year();\n        let timestamp_year = chrono::DateTime::from_timestamp(timestamp, 0)\n            .map(|dt| dt.year())\n            .unwrap_or(1970);\n\n        // Should be within 10 years of current year\n        assert!((timestamp_year - current_year).abs() \u003c= 10);\n    }\n\n    // Test SQL query patterns for correctness\n    #[test]\n    fn test_sql_query_patterns() {\n        // Verify the SQL queries are syntactically correct\n        let create_table_query = \"CREATE TABLE IF NOT EXISTS sync_state (\n                id TEXT PRIMARY KEY,\n                data JSONB NOT NULL,\n                updated_at BIGINT NOT NULL\n            )\";\n\n        let insert_query = \"INSERT INTO sync_state (id, data, updated_at)\n             VALUES ($1, $2, $3)\n             ON CONFLICT (id) DO UPDATE SET data = $2, updated_at = $3\";\n\n        let select_query = \"SELECT data FROM sync_state WHERE id = $1\";\n        let delete_query = \"DELETE FROM sync_state WHERE id = $1\";\n        let exists_query = \"SELECT 1 FROM sync_state WHERE id = $1\";\n\n        // Just verify they're non-empty strings\n        assert!(!create_table_query.is_empty());\n        assert!(!insert_query.is_empty());\n        assert!(!select_query.is_empty());\n        assert!(!delete_query.is_empty());\n        assert!(!exists_query.is_empty());\n\n        // Verify they contain expected keywords\n        assert!(create_table_query.contains(\"CREATE TABLE\"));\n        assert!(insert_query.contains(\"INSERT INTO\"));\n        assert!(select_query.contains(\"SELECT\"));\n        assert!(delete_query.contains(\"DELETE\"));\n        assert!(exists_query.contains(\"SELECT 1\"));\n    }\n}\n","traces":[{"line":22,"address":[],"length":0,"stats":{"Line":3}},{"line":23,"address":[],"length":0,"stats":{"Line":3}},{"line":26,"address":[],"length":0,"stats":{"Line":62}},{"line":27,"address":[],"length":0,"stats":{"Line":93}},{"line":28,"address":[],"length":0,"stats":{"Line":30}},{"line":31,"address":[],"length":0,"stats":{"Line":34}},{"line":33,"address":[],"length":0,"stats":{"Line":34}},{"line":34,"address":[],"length":0,"stats":{"Line":34}},{"line":35,"address":[],"length":0,"stats":{"Line":17}},{"line":46,"address":[],"length":0,"stats":{"Line":34}},{"line":47,"address":[],"length":0,"stats":{"Line":17}},{"line":49,"address":[],"length":0,"stats":{"Line":34}},{"line":50,"address":[],"length":0,"stats":{"Line":34}},{"line":51,"address":[],"length":0,"stats":{"Line":17}},{"line":65,"address":[],"length":0,"stats":{"Line":34}},{"line":66,"address":[],"length":0,"stats":{"Line":17}},{"line":78,"address":[],"length":0,"stats":{"Line":34}},{"line":79,"address":[],"length":0,"stats":{"Line":17}},{"line":90,"address":[],"length":0,"stats":{"Line":34}},{"line":91,"address":[],"length":0,"stats":{"Line":17}},{"line":102,"address":[],"length":0,"stats":{"Line":34}},{"line":103,"address":[],"length":0,"stats":{"Line":17}},{"line":115,"address":[],"length":0,"stats":{"Line":34}},{"line":116,"address":[],"length":0,"stats":{"Line":17}},{"line":130,"address":[],"length":0,"stats":{"Line":34}},{"line":131,"address":[],"length":0,"stats":{"Line":17}},{"line":133,"address":[],"length":0,"stats":{"Line":17}},{"line":136,"address":[],"length":0,"stats":{"Line":46}},{"line":137,"address":[],"length":0,"stats":{"Line":40}},{"line":138,"address":[],"length":0,"stats":{"Line":51}},{"line":139,"address":[],"length":0,"stats":{"Line":34}},{"line":140,"address":[],"length":0,"stats":{"Line":17}},{"line":141,"address":[],"length":0,"stats":{"Line":17}},{"line":143,"address":[],"length":0,"stats":{"Line":34}},{"line":144,"address":[],"length":0,"stats":{"Line":5}},{"line":145,"address":[],"length":0,"stats":{"Line":5}},{"line":146,"address":[],"length":0,"stats":{"Line":5}},{"line":148,"address":[],"length":0,"stats":{"Line":2}},{"line":149,"address":[],"length":0,"stats":{"Line":4}},{"line":150,"address":[],"length":0,"stats":{"Line":2}},{"line":151,"address":[],"length":0,"stats":{"Line":2}},{"line":153,"address":[],"length":0,"stats":{"Line":2}},{"line":157,"address":[],"length":0,"stats":{"Line":6}},{"line":158,"address":[],"length":0,"stats":{"Line":1}},{"line":159,"address":[],"length":0,"stats":{"Line":1}},{"line":168,"address":[],"length":0,"stats":{"Line":40}},{"line":169,"address":[],"length":0,"stats":{"Line":40}},{"line":170,"address":[],"length":0,"stats":{"Line":40}},{"line":171,"address":[],"length":0,"stats":{"Line":40}},{"line":172,"address":[],"length":0,"stats":{"Line":60}},{"line":173,"address":[],"length":0,"stats":{"Line":60}},{"line":174,"address":[],"length":0,"stats":{"Line":40}},{"line":175,"address":[],"length":0,"stats":{"Line":40}},{"line":176,"address":[],"length":0,"stats":{"Line":40}},{"line":177,"address":[],"length":0,"stats":{"Line":20}},{"line":179,"address":[],"length":0,"stats":{"Line":20}},{"line":182,"address":[],"length":0,"stats":{"Line":34}},{"line":187,"address":[],"length":0,"stats":{"Line":51}},{"line":188,"address":[],"length":0,"stats":{"Line":34}},{"line":189,"address":[],"length":0,"stats":{"Line":17}},{"line":191,"address":[],"length":0,"stats":{"Line":34}},{"line":192,"address":[],"length":0,"stats":{"Line":68}},{"line":193,"address":[],"length":0,"stats":{"Line":34}},{"line":194,"address":[],"length":0,"stats":{"Line":23}},{"line":195,"address":[],"length":0,"stats":{"Line":17}},{"line":196,"address":[],"length":0,"stats":{"Line":10}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":34}},{"line":207,"address":[],"length":0,"stats":{"Line":34}},{"line":208,"address":[],"length":0,"stats":{"Line":17}},{"line":209,"address":[],"length":0,"stats":{"Line":34}},{"line":210,"address":[],"length":0,"stats":{"Line":34}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":51}},{"line":216,"address":[],"length":0,"stats":{"Line":34}},{"line":217,"address":[],"length":0,"stats":{"Line":34}},{"line":220,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":235,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":240,"address":[],"length":0,"stats":{"Line":0}},{"line":241,"address":[],"length":0,"stats":{"Line":0}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":0}},{"line":254,"address":[],"length":0,"stats":{"Line":0}},{"line":255,"address":[],"length":0,"stats":{"Line":0}},{"line":256,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":264,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":298,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":3}},{"line":333,"address":[],"length":0,"stats":{"Line":9}},{"line":334,"address":[],"length":0,"stats":{"Line":12}},{"line":335,"address":[],"length":0,"stats":{"Line":6}},{"line":336,"address":[],"length":0,"stats":{"Line":3}},{"line":338,"address":[],"length":0,"stats":{"Line":6}},{"line":339,"address":[],"length":0,"stats":{"Line":15}},{"line":340,"address":[],"length":0,"stats":{"Line":24}},{"line":341,"address":[],"length":0,"stats":{"Line":12}},{"line":342,"address":[],"length":0,"stats":{"Line":8}},{"line":343,"address":[],"length":0,"stats":{"Line":6}},{"line":344,"address":[],"length":0,"stats":{"Line":4}},{"line":345,"address":[],"length":0,"stats":{"Line":0}},{"line":346,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":12}},{"line":350,"address":[],"length":0,"stats":{"Line":12}},{"line":351,"address":[],"length":0,"stats":{"Line":12}},{"line":352,"address":[],"length":0,"stats":{"Line":6}},{"line":353,"address":[],"length":0,"stats":{"Line":12}},{"line":354,"address":[],"length":0,"stats":{"Line":12}},{"line":355,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":0}},{"line":359,"address":[],"length":0,"stats":{"Line":18}},{"line":360,"address":[],"length":0,"stats":{"Line":12}},{"line":361,"address":[],"length":0,"stats":{"Line":12}},{"line":365,"address":[],"length":0,"stats":{"Line":3}},{"line":368,"address":[],"length":0,"stats":{"Line":2}},{"line":373,"address":[],"length":0,"stats":{"Line":8}},{"line":376,"address":[],"length":0,"stats":{"Line":5}},{"line":394,"address":[],"length":0,"stats":{"Line":15}},{"line":395,"address":[],"length":0,"stats":{"Line":20}},{"line":396,"address":[],"length":0,"stats":{"Line":10}},{"line":397,"address":[],"length":0,"stats":{"Line":5}},{"line":399,"address":[],"length":0,"stats":{"Line":10}},{"line":400,"address":[],"length":0,"stats":{"Line":31}},{"line":401,"address":[],"length":0,"stats":{"Line":52}},{"line":402,"address":[],"length":0,"stats":{"Line":26}},{"line":403,"address":[],"length":0,"stats":{"Line":13}},{"line":404,"address":[],"length":0,"stats":{"Line":16}},{"line":405,"address":[],"length":0,"stats":{"Line":15}},{"line":406,"address":[],"length":0,"stats":{"Line":10}},{"line":407,"address":[],"length":0,"stats":{"Line":0}},{"line":410,"address":[],"length":0,"stats":{"Line":26}},{"line":411,"address":[],"length":0,"stats":{"Line":26}},{"line":412,"address":[],"length":0,"stats":{"Line":26}},{"line":413,"address":[],"length":0,"stats":{"Line":13}},{"line":414,"address":[],"length":0,"stats":{"Line":26}},{"line":415,"address":[],"length":0,"stats":{"Line":26}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":417,"address":[],"length":0,"stats":{"Line":0}},{"line":420,"address":[],"length":0,"stats":{"Line":39}},{"line":421,"address":[],"length":0,"stats":{"Line":26}},{"line":422,"address":[],"length":0,"stats":{"Line":26}},{"line":426,"address":[],"length":0,"stats":{"Line":5}},{"line":429,"address":[],"length":0,"stats":{"Line":0}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":441,"address":[],"length":0,"stats":{"Line":0}},{"line":442,"address":[],"length":0,"stats":{"Line":0}},{"line":443,"address":[],"length":0,"stats":{"Line":0}},{"line":444,"address":[],"length":0,"stats":{"Line":0}},{"line":445,"address":[],"length":0,"stats":{"Line":0}},{"line":446,"address":[],"length":0,"stats":{"Line":0}},{"line":447,"address":[],"length":0,"stats":{"Line":0}},{"line":449,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":453,"address":[],"length":0,"stats":{"Line":0}},{"line":454,"address":[],"length":0,"stats":{"Line":0}},{"line":455,"address":[],"length":0,"stats":{"Line":0}},{"line":456,"address":[],"length":0,"stats":{"Line":0}},{"line":457,"address":[],"length":0,"stats":{"Line":0}},{"line":459,"address":[],"length":0,"stats":{"Line":0}},{"line":462,"address":[],"length":0,"stats":{"Line":0}},{"line":468,"address":[],"length":0,"stats":{"Line":0}},{"line":469,"address":[],"length":0,"stats":{"Line":0}},{"line":470,"address":[],"length":0,"stats":{"Line":0}},{"line":471,"address":[],"length":0,"stats":{"Line":0}},{"line":472,"address":[],"length":0,"stats":{"Line":0}},{"line":473,"address":[],"length":0,"stats":{"Line":0}},{"line":475,"address":[],"length":0,"stats":{"Line":0}},{"line":476,"address":[],"length":0,"stats":{"Line":0}},{"line":484,"address":[],"length":0,"stats":{"Line":0}},{"line":485,"address":[],"length":0,"stats":{"Line":0}},{"line":486,"address":[],"length":0,"stats":{"Line":0}},{"line":487,"address":[],"length":0,"stats":{"Line":0}},{"line":488,"address":[],"length":0,"stats":{"Line":0}},{"line":489,"address":[],"length":0,"stats":{"Line":0}},{"line":490,"address":[],"length":0,"stats":{"Line":0}},{"line":491,"address":[],"length":0,"stats":{"Line":0}},{"line":494,"address":[],"length":0,"stats":{"Line":0}},{"line":505,"address":[],"length":0,"stats":{"Line":0}},{"line":506,"address":[],"length":0,"stats":{"Line":0}},{"line":507,"address":[],"length":0,"stats":{"Line":0}},{"line":508,"address":[],"length":0,"stats":{"Line":0}},{"line":510,"address":[],"length":0,"stats":{"Line":0}},{"line":511,"address":[],"length":0,"stats":{"Line":0}},{"line":512,"address":[],"length":0,"stats":{"Line":0}},{"line":513,"address":[],"length":0,"stats":{"Line":0}},{"line":515,"address":[],"length":0,"stats":{"Line":0}},{"line":518,"address":[],"length":0,"stats":{"Line":0}},{"line":530,"address":[],"length":0,"stats":{"Line":0}},{"line":531,"address":[],"length":0,"stats":{"Line":0}},{"line":532,"address":[],"length":0,"stats":{"Line":0}},{"line":533,"address":[],"length":0,"stats":{"Line":0}},{"line":534,"address":[],"length":0,"stats":{"Line":0}},{"line":535,"address":[],"length":0,"stats":{"Line":0}},{"line":536,"address":[],"length":0,"stats":{"Line":0}},{"line":537,"address":[],"length":0,"stats":{"Line":0}},{"line":540,"address":[],"length":0,"stats":{"Line":0}},{"line":551,"address":[],"length":0,"stats":{"Line":0}},{"line":552,"address":[],"length":0,"stats":{"Line":0}},{"line":553,"address":[],"length":0,"stats":{"Line":0}},{"line":554,"address":[],"length":0,"stats":{"Line":0}},{"line":555,"address":[],"length":0,"stats":{"Line":0}},{"line":556,"address":[],"length":0,"stats":{"Line":0}},{"line":557,"address":[],"length":0,"stats":{"Line":0}},{"line":560,"address":[],"length":0,"stats":{"Line":0}},{"line":568,"address":[],"length":0,"stats":{"Line":0}},{"line":569,"address":[],"length":0,"stats":{"Line":0}},{"line":570,"address":[],"length":0,"stats":{"Line":0}},{"line":571,"address":[],"length":0,"stats":{"Line":0}},{"line":573,"address":[],"length":0,"stats":{"Line":0}},{"line":574,"address":[],"length":0,"stats":{"Line":0}},{"line":575,"address":[],"length":0,"stats":{"Line":0}},{"line":576,"address":[],"length":0,"stats":{"Line":0}},{"line":577,"address":[],"length":0,"stats":{"Line":0}},{"line":578,"address":[],"length":0,"stats":{"Line":0}},{"line":581,"address":[],"length":0,"stats":{"Line":0}},{"line":583,"address":[],"length":0,"stats":{"Line":2}},{"line":587,"address":[],"length":0,"stats":{"Line":8}},{"line":591,"address":[],"length":0,"stats":{"Line":2}},{"line":593,"address":[],"length":0,"stats":{"Line":2}},{"line":594,"address":[],"length":0,"stats":{"Line":2}},{"line":597,"address":[],"length":0,"stats":{"Line":0}},{"line":598,"address":[],"length":0,"stats":{"Line":0}},{"line":599,"address":[],"length":0,"stats":{"Line":0}},{"line":602,"address":[],"length":0,"stats":{"Line":0}},{"line":603,"address":[],"length":0,"stats":{"Line":0}},{"line":604,"address":[],"length":0,"stats":{"Line":0}},{"line":609,"address":[],"length":0,"stats":{"Line":0}},{"line":610,"address":[],"length":0,"stats":{"Line":0}},{"line":611,"address":[],"length":0,"stats":{"Line":0}},{"line":616,"address":[],"length":0,"stats":{"Line":0}},{"line":617,"address":[],"length":0,"stats":{"Line":0}},{"line":618,"address":[],"length":0,"stats":{"Line":0}},{"line":622,"address":[],"length":0,"stats":{"Line":0}},{"line":623,"address":[],"length":0,"stats":{"Line":0}},{"line":624,"address":[],"length":0,"stats":{"Line":0}},{"line":627,"address":[],"length":0,"stats":{"Line":0}},{"line":628,"address":[],"length":0,"stats":{"Line":0}},{"line":629,"address":[],"length":0,"stats":{"Line":0}},{"line":632,"address":[],"length":0,"stats":{"Line":0}},{"line":634,"address":[],"length":0,"stats":{"Line":0}},{"line":635,"address":[],"length":0,"stats":{"Line":0}},{"line":642,"address":[],"length":0,"stats":{"Line":4}},{"line":643,"address":[],"length":0,"stats":{"Line":6}},{"line":644,"address":[],"length":0,"stats":{"Line":6}},{"line":645,"address":[],"length":0,"stats":{"Line":4}},{"line":646,"address":[],"length":0,"stats":{"Line":4}},{"line":647,"address":[],"length":0,"stats":{"Line":2}},{"line":649,"address":[],"length":0,"stats":{"Line":2}},{"line":652,"address":[],"length":0,"stats":{"Line":2}},{"line":663,"address":[],"length":0,"stats":{"Line":8}},{"line":664,"address":[],"length":0,"stats":{"Line":6}},{"line":665,"address":[],"length":0,"stats":{"Line":6}},{"line":666,"address":[],"length":0,"stats":{"Line":4}},{"line":667,"address":[],"length":0,"stats":{"Line":2}},{"line":669,"address":[],"length":0,"stats":{"Line":4}},{"line":670,"address":[],"length":0,"stats":{"Line":8}},{"line":672,"address":[],"length":0,"stats":{"Line":12}},{"line":673,"address":[],"length":0,"stats":{"Line":12}},{"line":674,"address":[],"length":0,"stats":{"Line":9}},{"line":676,"address":[],"length":0,"stats":{"Line":2}},{"line":684,"address":[],"length":0,"stats":{"Line":2}},{"line":702,"address":[],"length":0,"stats":{"Line":8}},{"line":730,"address":[],"length":0,"stats":{"Line":15}},{"line":733,"address":[],"length":0,"stats":{"Line":2}},{"line":743,"address":[],"length":0,"stats":{"Line":6}},{"line":778,"address":[],"length":0,"stats":{"Line":0}},{"line":849,"address":[],"length":0,"stats":{"Line":0}},{"line":850,"address":[],"length":0,"stats":{"Line":0}},{"line":851,"address":[],"length":0,"stats":{"Line":0}},{"line":872,"address":[],"length":0,"stats":{"Line":3}},{"line":902,"address":[],"length":0,"stats":{"Line":0}},{"line":926,"address":[],"length":0,"stats":{"Line":0}},{"line":927,"address":[],"length":0,"stats":{"Line":0}},{"line":928,"address":[],"length":0,"stats":{"Line":0}}],"covered":151,"coverable":318},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","src","redis.rs"],"content":"use async_trait::async_trait;\nuse errors::StorageError;\nuse mk_core::traits::EventPublisher;\nuse mk_core::types::GovernanceEvent;\nuse redis::AsyncCommands;\nuse std::sync::Arc;\n\npub struct RedisStorage {\n    client: Arc\u003credis::Client\u003e,\n    connection_manager: redis::aio::ConnectionManager\n}\n\nimpl RedisStorage {\n    pub async fn new(connection_string: \u0026str) -\u003e Result\u003cSelf, StorageError\u003e {\n        let client =\n            redis::Client::open(connection_string).map_err(|e| StorageError::ConnectionError {\n                backend: \"Redis\".to_string(),\n                reason: e.to_string()\n            })?;\n\n        let connection_manager =\n            client\n                .get_connection_manager()\n                .await\n                .map_err(|e| StorageError::ConnectionError {\n                    backend: \"Redis\".to_string(),\n                    reason: e.to_string()\n                })?;\n\n        Ok(Self {\n            client: Arc::new(client),\n            connection_manager\n        })\n    }\n\n    pub async fn get(\u0026self, key: \u0026str) -\u003e Result\u003cOption\u003cString\u003e, StorageError\u003e {\n        let mut conn = self.connection_manager.clone();\n        conn.get(key).await.map_err(|e| StorageError::QueryError {\n            backend: \"Redis\".to_string(),\n            reason: e.to_string()\n        })\n    }\n\n    pub async fn set(\n        \u0026self,\n        key: \u0026str,\n        value: \u0026str,\n        ttl_seconds: Option\u003cusize\u003e\n    ) -\u003e Result\u003c(), StorageError\u003e {\n        let mut conn = self.connection_manager.clone();\n        if let Some(ttl) = ttl_seconds {\n            conn.set_ex(key, value, ttl as u64)\n                .await\n                .map_err(|e| StorageError::QueryError {\n                    backend: \"Redis\".to_string(),\n                    reason: e.to_string()\n                })\n        } else {\n            conn.set(key, value)\n                .await\n                .map_err(|e| StorageError::QueryError {\n                    backend: \"Redis\".to_string(),\n                    reason: e.to_string()\n                })\n        }\n    }\n\n    pub async fn delete_key(\u0026self, key: \u0026str) -\u003e Result\u003c(), StorageError\u003e {\n        let mut conn = self.connection_manager.clone();\n        conn.del(key).await.map_err(|e| StorageError::QueryError {\n            backend: \"Redis\".to_string(),\n            reason: e.to_string()\n        })\n    }\n\n    pub async fn exists_key(\u0026self, key: \u0026str) -\u003e Result\u003cbool, StorageError\u003e {\n        let mut conn = self.connection_manager.clone();\n        conn.exists(key)\n            .await\n            .map_err(|e| StorageError::QueryError {\n                backend: \"Redis\".to_string(),\n                reason: e.to_string()\n            })\n    }\n    pub fn scoped_key(\u0026self, ctx: \u0026mk_core::types::TenantContext, key: \u0026str) -\u003e String {\n        format!(\"{}:{}\", ctx.tenant_id.as_str(), key)\n    }\n}\n\n#[async_trait]\nimpl EventPublisher for RedisStorage {\n    type Error = StorageError;\n\n    async fn publish(\u0026self, event: GovernanceEvent) -\u003e Result\u003c(), Self::Error\u003e {\n        let mut conn = self.connection_manager.clone();\n        let event_json =\n            serde_json::to_string(\u0026event).map_err(|e| StorageError::SerializationError {\n                error_type: \"JSON\".to_string(),\n                reason: e.to_string()\n            })?;\n\n        let stream_key = format!(\"governance:events:{}\", event.tenant_id());\n        let _: String = conn\n            .xadd(stream_key, \"*\", \u0026[(\"event\", event_json)])\n            .await\n            .map_err(|e| StorageError::QueryError {\n                backend: \"Redis\".to_string(),\n                reason: e.to_string()\n            })?;\n\n        Ok(())\n    }\n\n    async fn subscribe(\n        \u0026self,\n        channels: \u0026[\u0026str]\n    ) -\u003e Result\u003ctokio::sync::mpsc::Receiver\u003cGovernanceEvent\u003e, Self::Error\u003e {\n        let (tx, rx) = tokio::sync::mpsc::channel(100);\n        let client = self.client.clone();\n        let stream_keys: Vec\u003cString\u003e = channels.iter().map(|s| s.to_string()).collect();\n\n        tokio::spawn(async move {\n            if let Ok(mut conn) = client.get_connection_manager().await {\n                let mut last_ids: Vec\u003cString\u003e = vec![\"$\".to_string(); stream_keys.len()];\n\n                loop {\n                    let opts = redis::streams::StreamReadOptions::default()\n                        .block(0)\n                        .count(10);\n\n                    let result: Result\u003credis::streams::StreamReadReply, redis::RedisError\u003e =\n                        conn.xread_options(\u0026stream_keys, \u0026last_ids, \u0026opts).await;\n\n                    match result {\n                        Ok(reply) =\u003e {\n                            for (i, stream) in reply.keys.into_iter().enumerate() {\n                                for record in stream.ids {\n                                    if let Some(event_json) = record.map.get(\"event\") {\n                                        if let Ok(event_str) =\n                                            redis::from_redis_value::\u003cString\u003e(event_json.clone())\n                                        {\n                                            if let Ok(event) =\n                                                serde_json::from_str::\u003cGovernanceEvent\u003e(\u0026event_str)\n                                            {\n                                                if tx.send(event).await.is_err() {\n                                                    return;\n                                                }\n                                            }\n                                        }\n                                    }\n                                    last_ids[i] = record.id;\n                                }\n                            }\n                        }\n                        Err(_) =\u003e {\n                            tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;\n                        }\n                    }\n                }\n            }\n        });\n\n        Ok(rx)\n    }\n}\n\n#[async_trait]\nimpl mk_core::traits::StorageBackend for RedisStorage {\n    type Error = StorageError;\n\n    async fn store(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        key: \u0026str,\n        value: \u0026[u8]\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        let mut conn = self.connection_manager.clone();\n        let scoped_key = self.scoped_key(\u0026ctx, key);\n        conn.set(scoped_key, value)\n            .await\n            .map_err(|e| StorageError::QueryError {\n                backend: \"Redis\".to_string(),\n                reason: e.to_string()\n            })\n    }\n\n    async fn retrieve(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        key: \u0026str\n    ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e {\n        let mut conn = self.connection_manager.clone();\n        let scoped_key = self.scoped_key(\u0026ctx, key);\n        conn.get(scoped_key)\n            .await\n            .map_err(|e| StorageError::QueryError {\n                backend: \"Redis\".to_string(),\n                reason: e.to_string()\n            })\n    }\n\n    async fn delete(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        key: \u0026str\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        let scoped_key = self.scoped_key(\u0026ctx, key);\n        self.delete_key(\u0026scoped_key).await\n    }\n\n    async fn exists(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        key: \u0026str\n    ) -\u003e Result\u003cbool, Self::Error\u003e {\n        let scoped_key = self.scoped_key(\u0026ctx, key);\n        self.exists_key(\u0026scoped_key).await\n    }\n\n    async fn get_ancestors(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _unit_id: \u0026str\n    ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn get_unit_policies(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _unit_id: \u0026str\n    ) -\u003e Result\u003cVec\u003cmk_core::types::Policy\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn create_unit(\n        \u0026self,\n        _unit: \u0026mk_core::types::OrganizationalUnit\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn add_unit_policy(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _unit_id: \u0026str,\n        _policy: \u0026mk_core::types::Policy\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn assign_role(\n        \u0026self,\n        _user_id: \u0026mk_core::types::UserId,\n        _tenant_id: \u0026mk_core::types::TenantId,\n        _unit_id: \u0026str,\n        _role: mk_core::types::Role\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn remove_role(\n        \u0026self,\n        _user_id: \u0026mk_core::types::UserId,\n        _tenant_id: \u0026mk_core::types::TenantId,\n        _unit_id: \u0026str,\n        _role: mk_core::types::Role\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn get_descendants(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _unit_id: \u0026str\n    ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn store_drift_result(\n        \u0026self,\n        _result: mk_core::types::DriftResult\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn get_latest_drift_result(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _project_id: \u0026str\n    ) -\u003e Result\u003cOption\u003cmk_core::types::DriftResult\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n\n    async fn list_all_units(\u0026self) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn record_job_status(\n        \u0026self,\n        _job_name: \u0026str,\n        _tenant_id: \u0026str,\n        _status: \u0026str,\n        _message: Option\u003c\u0026str\u003e,\n        _started_at: i64,\n        _finished_at: Option\u003ci64\u003e\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn get_governance_events(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _since_timestamp: i64,\n        _limit: usize\n    ) -\u003e Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use errors::StorageError;\n\n    // Test error type conversions and patterns\n    #[test]\n    fn test_storage_error_display() {\n        let conn_error = StorageError::ConnectionError {\n            backend: \"Redis\".to_string(),\n            reason: \"Connection refused\".to_string()\n        };\n\n        let query_error = StorageError::QueryError {\n            backend: \"Redis\".to_string(),\n            reason: \"Command failed\".to_string()\n        };\n\n        assert_eq!(\n            conn_error.to_string(),\n            \"Connection to Redis failed: Connection refused\"\n        );\n\n        assert_eq!(\n            query_error.to_string(),\n            \"Query on Redis failed: Command failed\"\n        );\n    }\n\n    // Test RedisStorage struct creation (without actual connection)\n    #[tokio::test]\n    async fn test_redis_storage_error_handling() {\n        // This test verifies that invalid connection strings produce appropriate errors\n        // Note: We can't easily mock the redis client, but we can verify error types\n\n        // Test with obviously invalid URL\n        let result = RedisStorage::new(\"not-a-valid-url\").await;\n        assert!(result.is_err());\n\n        if let Err(StorageError::ConnectionError { backend, .. }) = result {\n            assert_eq!(backend, \"Redis\");\n        } else {\n            panic!(\"Expected ConnectionError for invalid URL\");\n        }\n    }\n\n    // Test StorageBackend trait implementation consistency\n    #[test]\n    fn test_storage_backend_trait_bounds() {\n        use mk_core::traits::StorageBackend;\n\n        // This is a compile-time test to ensure RedisStorage implements StorageBackend\n        fn assert_storage_backend\u003cT: StorageBackend\u003e() {}\n\n        // If this compiles, RedisStorage implements StorageBackend\n        assert_storage_backend::\u003cRedisStorage\u003e();\n    }\n\n    // Test error message formatting for different scenarios\n    #[test]\n    fn test_error_messages_include_backend_name() {\n        let errors = vec![\n            StorageError::ConnectionError {\n                backend: \"Redis\".to_string(),\n                reason: \"test\".to_string()\n            },\n            StorageError::QueryError {\n                backend: \"Redis\".to_string(),\n                reason: \"test\".to_string()\n            },\n            StorageError::SerializationError {\n                error_type: \"JSON\".to_string(),\n                reason: \"test\".to_string()\n            },\n            StorageError::NotFound {\n                backend: \"Redis\".to_string(),\n                id: \"key123\".to_string()\n            },\n            StorageError::TransactionError {\n                backend: \"Redis\".to_string(),\n                reason: \"test\".to_string()\n            },\n        ];\n\n        for error in errors {\n            let msg = error.to_string();\n            assert!(\n                msg.contains(\"Redis\") || msg.contains(\"JSON\"),\n                \"Error message should contain backend or error type: {}\",\n                msg\n            );\n        }\n    }\n\n    // Test that RedisStorage methods have correct signatures\n    #[test]\n    fn test_method_signatures() {\n        // This is a compile-time check\n\n        // Verify RedisStorage has the expected method signature\n        // The existence of the method is verified by compilation\n        // We can't easily test async method signatures in a unit test\n        let _ = RedisStorage::new;\n    }\n}\n","traces":[{"line":14,"address":[],"length":0,"stats":{"Line":12}},{"line":15,"address":[],"length":0,"stats":{"Line":5}},{"line":16,"address":[],"length":0,"stats":{"Line":18}},{"line":17,"address":[],"length":0,"stats":{"Line":2}},{"line":18,"address":[],"length":0,"stats":{"Line":2}},{"line":21,"address":[],"length":0,"stats":{"Line":4}},{"line":22,"address":[],"length":0,"stats":{"Line":10}},{"line":24,"address":[],"length":0,"stats":{"Line":5}},{"line":25,"address":[],"length":0,"stats":{"Line":5}},{"line":26,"address":[],"length":0,"stats":{"Line":2}},{"line":27,"address":[],"length":0,"stats":{"Line":2}},{"line":30,"address":[],"length":0,"stats":{"Line":4}},{"line":31,"address":[],"length":0,"stats":{"Line":8}},{"line":32,"address":[],"length":0,"stats":{"Line":4}},{"line":36,"address":[],"length":0,"stats":{"Line":4}},{"line":37,"address":[],"length":0,"stats":{"Line":6}},{"line":38,"address":[],"length":0,"stats":{"Line":8}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":3}},{"line":50,"address":[],"length":0,"stats":{"Line":9}},{"line":51,"address":[],"length":0,"stats":{"Line":5}},{"line":52,"address":[],"length":0,"stats":{"Line":10}},{"line":53,"address":[],"length":0,"stats":{"Line":2}},{"line":54,"address":[],"length":0,"stats":{"Line":2}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":4}},{"line":60,"address":[],"length":0,"stats":{"Line":1}},{"line":61,"address":[],"length":0,"stats":{"Line":1}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":2}},{"line":69,"address":[],"length":0,"stats":{"Line":3}},{"line":70,"address":[],"length":0,"stats":{"Line":4}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":10}},{"line":77,"address":[],"length":0,"stats":{"Line":15}},{"line":78,"address":[],"length":0,"stats":{"Line":15}},{"line":79,"address":[],"length":0,"stats":{"Line":5}},{"line":80,"address":[],"length":0,"stats":{"Line":5}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}}],"covered":34,"coverable":78},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","tests","events_test.rs"],"content":"use mk_core::traits::EventPublisher;\nuse mk_core::types::{GovernanceEvent, TenantId};\nuse std::time::Duration;\nuse storage::events::{MultiPublisher, RedisPublisher};\nuse testcontainers::runners::AsyncRunner;\nuse testcontainers_modules::redis::Redis;\n\n#[tokio::test]\nasync fn test_redis_publisher_publish_subscribe() {\n    let container = match Redis::default().start().await {\n        Ok(c) =\u003e c,\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Redis test: Docker not available\");\n            return;\n        }\n    };\n\n    let port = container.get_host_port_ipv4(6379).await.unwrap();\n    let connection_url = format!(\"redis://localhost:{}\", port);\n    let stream_name = \"test-stream\";\n\n    let publisher = RedisPublisher::new(\u0026connection_url, stream_name).unwrap();\n    let mut rx = publisher.subscribe(\u0026[]).await.unwrap();\n\n    let event = GovernanceEvent::UnitCreated {\n        unit_id: \"unit-1\".to_string(),\n        unit_type: mk_core::types::UnitType::Project,\n        tenant_id: TenantId::new(\"tenant-1\".to_string()).unwrap(),\n        parent_id: None,\n        timestamp: chrono::Utc::now().timestamp(),\n    };\n\n    publisher.publish(event.clone()).await.unwrap();\n\n    let received = tokio::time::timeout(Duration::from_secs(5), rx.recv()).await;\n\n    assert!(received.is_ok(), \"Timed out waiting for event\");\n    let received_event = received.unwrap().expect(\"Channel closed\");\n\n    match (event, received_event) {\n        (\n            GovernanceEvent::UnitCreated { unit_id: id1, .. },\n            GovernanceEvent::UnitCreated { unit_id: id2, .. },\n        ) =\u003e {\n            assert_eq!(id1, id2);\n        }\n        _ =\u003e panic!(\"Event type mismatch or incorrect data\"),\n    }\n}\n\n#[tokio::test]\nasync fn test_multi_publisher() {\n    let container = match Redis::default().start().await {\n        Ok(c) =\u003e c,\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Redis test: Docker not available\");\n            return;\n        }\n    };\n\n    let port = container.get_host_port_ipv4(6379).await.unwrap();\n    let connection_url = format!(\"redis://localhost:{}\", port);\n\n    let pub1 = Box::new(RedisPublisher::new(\u0026connection_url, \"stream-1\").unwrap());\n    let pub2 = Box::new(RedisPublisher::new(\u0026connection_url, \"stream-2\").unwrap());\n\n    let multi = MultiPublisher::new(vec![pub1, pub2]);\n\n    let event = GovernanceEvent::UnitUpdated {\n        unit_id: \"unit-1\".to_string(),\n        tenant_id: TenantId::new(\"tenant-1\".to_string()).unwrap(),\n        timestamp: chrono::Utc::now().timestamp(),\n    };\n\n    let result = multi.publish(event).await;\n    assert!(result.is_ok());\n}\n\n#[test]\nfn test_event_error_display() {\n    use storage::events::EventError;\n    let err = EventError::Internal(\"test error\".to_string());\n    assert_eq!(format!(\"{}\", err), \"Internal error: test error\");\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","tests","governance_integration.rs"],"content":"//! Integration tests for the governance event system and multi-publisher.\n\nuse mk_core::traits::{AuthorizationService, EventPublisher, StorageBackend};\nuse mk_core::types::{GovernanceEvent, TenantContext, TenantId, UserId};\nuse std::sync::Arc;\nuse storage::events::RedisPublisher;\nuse storage::postgres::PostgresBackend;\nuse testcontainers::ContainerAsync;\nuse testcontainers::runners::AsyncRunner;\nuse testcontainers_modules::postgres::Postgres;\nuse testcontainers_modules::redis::Redis;\n\n#[tokio::test]\n#[ignore = \"Flaky: Redis pub/sub timing sensitive with testcontainers\"]\nasync fn test_governance_event_propagation() {\n    let result: Result\u003c\n        (\n            String,\n            String,\n            ContainerAsync\u003cPostgres\u003e,\n            ContainerAsync\u003cRedis\u003e,\n        ),\n        Box\u003cdyn std::error::Error\u003e,\n    \u003e = async {\n        let (_pg_container, pg_url) = setup_postgres_test().await?;\n        let (_redis_container, redis_url) = setup_redis_test().await?;\n        Ok((pg_url, redis_url, _pg_container, _redis_container))\n    }\n    .await;\n\n    match result {\n        Ok((pg_url, redis_url, _pg_container, _redis_container)) =\u003e {\n            let pg_backend = Arc::new(PostgresBackend::new(\u0026pg_url).await.unwrap());\n            pg_backend.initialize_schema().await.unwrap();\n\n            let redis_publisher = Arc::new(RedisPublisher::new(\u0026redis_url, \"gov_events\").unwrap());\n\n            let mut rx = redis_publisher.subscribe(\u0026[\"gov_events\"]).await.unwrap();\n\n            tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;\n\n            let tenant_id = TenantId::new(\"tenant-1\".to_string()).unwrap();\n            let event = GovernanceEvent::DriftDetected {\n                project_id: \"project-1\".to_string(),\n                tenant_id: tenant_id.clone(),\n                drift_score: 0.75,\n                timestamp: chrono::Utc::now().timestamp(),\n            };\n\n            pg_backend.publish(event.clone()).await.unwrap();\n            redis_publisher.publish(event.clone()).await.unwrap();\n\n            let received = tokio::time::timeout(tokio::time::Duration::from_secs(5), rx.recv())\n                .await\n                .expect(\"Timeout waiting for event\")\n                .expect(\"Channel closed\");\n\n            if let GovernanceEvent::DriftDetected { drift_score, .. } = received {\n                assert_eq!(drift_score, 0.75);\n            } else {\n                panic!(\"Wrong event type received\");\n            }\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping governance integration test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_full_governance_workflow() {\n    let result: Result\u003c(String, ContainerAsync\u003cPostgres\u003e), Box\u003cdyn std::error::Error\u003e\u003e = async {\n        let (_pg_container, pg_url) = setup_postgres_test().await?;\n        Ok((pg_url, _pg_container))\n    }\n    .await;\n\n    match result {\n        Ok((pg_url, _pg_container)) =\u003e {\n            let pg_backend = Arc::new(PostgresBackend::new(\u0026pg_url).await.unwrap());\n            pg_backend.initialize_schema().await.unwrap();\n\n            let tenant_id = TenantId::new(\"comp1\".to_string()).unwrap();\n            let user_id = UserId::new(\"user1\".to_string()).unwrap();\n            let agent_id = \"agent1\".to_string();\n\n            let company = mk_core::types::OrganizationalUnit {\n                id: \"comp1\".into(),\n                name: \"Company 1\".into(),\n                unit_type: mk_core::types::UnitType::Company,\n                parent_id: None,\n                tenant_id: tenant_id.clone(),\n                metadata: std::collections::HashMap::new(),\n                created_at: chrono::Utc::now().timestamp(),\n                updated_at: chrono::Utc::now().timestamp(),\n            };\n            pg_backend.create_unit(\u0026company).await.unwrap();\n\n            let org = mk_core::types::OrganizationalUnit {\n                id: \"org1\".into(),\n                name: \"Organization 1\".into(),\n                unit_type: mk_core::types::UnitType::Organization,\n                parent_id: Some(\"comp1\".into()),\n                tenant_id: tenant_id.clone(),\n                metadata: std::collections::HashMap::new(),\n                created_at: chrono::Utc::now().timestamp(),\n                updated_at: chrono::Utc::now().timestamp(),\n            };\n            pg_backend.create_unit(\u0026org).await.unwrap();\n\n            let team = mk_core::types::OrganizationalUnit {\n                id: \"team1\".into(),\n                name: \"Team 1\".into(),\n                unit_type: mk_core::types::UnitType::Team,\n                parent_id: Some(\"org1\".into()),\n                tenant_id: tenant_id.clone(),\n                metadata: std::collections::HashMap::new(),\n                created_at: chrono::Utc::now().timestamp(),\n                updated_at: chrono::Utc::now().timestamp(),\n            };\n            pg_backend.create_unit(\u0026team).await.unwrap();\n\n            let project = mk_core::types::OrganizationalUnit {\n                id: \"proj1\".into(),\n                name: \"Project 1\".into(),\n                unit_type: mk_core::types::UnitType::Project,\n                parent_id: Some(\"team1\".into()),\n                tenant_id: tenant_id.clone(),\n                metadata: std::collections::HashMap::new(),\n                created_at: chrono::Utc::now().timestamp(),\n                updated_at: chrono::Utc::now().timestamp(),\n            };\n            pg_backend.create_unit(\u0026project).await.unwrap();\n\n            let cedar_policies = r#\"\n                permit(principal == User::\"agent1\", action == Action::\"ActAs\", resource == User::\"user1\");\n                permit(principal == User::\"user1\", action == Action::\"Update\", resource == Unit::\"proj1\");\n            \"#;\n            let cedar_schema = \"{}\";\n            let authorizer =\n                adapters::auth::cedar::CedarAuthorizer::new(cedar_policies, cedar_schema).unwrap();\n\n            let ctx = TenantContext::with_agent(tenant_id.clone(), user_id.clone(), agent_id);\n            let allowed = authorizer\n                .check_permission(\u0026ctx, \"Update\", \"Unit::\\\"proj1\\\"\")\n                .await\n                .unwrap();\n            assert!(allowed);\n\n            pg_backend\n                .record_job_status(\n                    \"drift_scan\",\n                    tenant_id.as_str(),\n                    \"completed\",\n                    None,\n                    chrono::Utc::now().timestamp() - 100,\n                    Some(chrono::Utc::now().timestamp()),\n                )\n                .await\n                .unwrap();\n\n            let drift = mk_core::types::DriftResult {\n                project_id: \"proj1\".to_string(),\n                tenant_id: tenant_id.clone(),\n                drift_score: 0.2,\n                violations: vec![],\n                timestamp: chrono::Utc::now().timestamp(),\n            };\n            pg_backend.store_drift_result(drift).await.unwrap();\n\n            let engine = Arc::new(\n                knowledge::governance::GovernanceEngine::new().with_storage(pg_backend.clone()),\n            );\n            let deployment_config = config::DeploymentConfig::default();\n            let api = Arc::new(knowledge::api::GovernanceDashboardApi::new(\n                engine,\n                pg_backend.clone(),\n                deployment_config,\n            ));\n\n            let drift_status = knowledge::api::get_drift_status(api.clone(), \u0026ctx, \"proj1\")\n                .await\n                .unwrap();\n            assert!(drift_status.is_some());\n            assert_eq!(drift_status.unwrap().drift_score, 0.2);\n\n            let jobs = knowledge::api::get_job_status(api, \u0026ctx, Some(\"drift_scan\"))\n                .await\n                .unwrap();\n            assert!(jobs.as_array().unwrap().len() \u003e= 1);\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping governance workflow test: Docker not available\");\n        }\n    }\n}\n\nasync fn setup_postgres_test()\n-\u003e Result\u003c(ContainerAsync\u003cPostgres\u003e, String), Box\u003cdyn std::error::Error\u003e\u003e {\n    let container = Postgres::default()\n        .with_db_name(\"govdb\")\n        .with_user(\"govuser\")\n        .with_password(\"govpass\")\n        .start()\n        .await?;\n\n    let url = format!(\n        \"postgres://govuser:govpass@localhost:{}/govdb\",\n        container.get_host_port_ipv4(5432).await?\n    );\n    Ok((container, url))\n}\n\nasync fn setup_redis_test() -\u003e Result\u003c(ContainerAsync\u003cRedis\u003e, String), Box\u003cdyn std::error::Error\u003e\u003e {\n    let container = Redis::default().start().await?;\n    let url = format!(\n        \"redis://localhost:{}\",\n        container.get_host_port_ipv4(6379).await?\n    );\n    Ok((container, url))\n}\n","traces":[{"line":198,"address":[],"length":0,"stats":{"Line":1}},{"line":200,"address":[],"length":0,"stats":{"Line":3}},{"line":205,"address":[],"length":0,"stats":{"Line":1}},{"line":207,"address":[],"length":0,"stats":{"Line":2}},{"line":209,"address":[],"length":0,"stats":{"Line":1}},{"line":211,"address":[],"length":0,"stats":{"Line":1}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":0}}],"covered":6,"coverable":11},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","tests","hierarchy_integration.rs"],"content":"//! Integration tests for organizational hierarchy in PostgreSQL storage backend\n//!\n//! These tests verify the strict hierarchy enforcement and recursive navigation\n//! logic.\n\nuse mk_core::types::{OrganizationalUnit, TenantContext, TenantId, UnitType, UserId};\nuse std::collections::HashMap;\nuse storage::postgres::PostgresBackend;\nuse testcontainers::ContainerAsync;\nuse testcontainers::runners::AsyncRunner;\nuse testcontainers_modules::postgres::Postgres;\n\nasync fn setup_postgres_container()\n-\u003e Result\u003c(ContainerAsync\u003cPostgres\u003e, String), Box\u003cdyn std::error::Error\u003e\u003e {\n    let container = Postgres::default()\n        .with_db_name(\"testdb\")\n        .with_user(\"testuser\")\n        .with_password(\"testpass\")\n        .start()\n        .await?;\n\n    let connection_url = format!(\n        \"postgres://testuser:testpass@localhost:{}/testdb\",\n        container.get_host_port_ipv4(5432).await?\n    );\n\n    Ok((container, connection_url))\n}\n\nfn create_test_unit(\n    id: \u0026str,\n    name: \u0026str,\n    unit_type: UnitType,\n    parent_id: Option\u003cString\u003e,\n    tenant_id: \u0026str\n) -\u003e OrganizationalUnit {\n    OrganizationalUnit {\n        id: id.to_string(),\n        name: name.to_string(),\n        unit_type,\n        parent_id,\n        tenant_id: TenantId::new(tenant_id.to_string()).unwrap(),\n        metadata: HashMap::new(),\n        created_at: chrono::Utc::now().timestamp(),\n        updated_at: chrono::Utc::now().timestamp()\n    }\n}\n\n#[tokio::test]\nasync fn test_hierarchy_strict_enforcement() {\n    match setup_postgres_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let backend = PostgresBackend::new(\u0026connection_url).await.unwrap();\n            backend.initialize_schema().await.unwrap();\n\n            let tenant_id = \"tenant-1\";\n\n            // 1. Root must be a Company\n            let org_root =\n                create_test_unit(\"org-1\", \"Org Root\", UnitType::Organization, None, tenant_id);\n            let result = backend.create_unit(\u0026org_root).await;\n            assert!(result.is_err(), \"Root unit must be a Company\");\n\n            let company =\n                create_test_unit(\"comp-1\", \"Comp Root\", UnitType::Company, None, tenant_id);\n            backend\n                .create_unit(\u0026company)\n                .await\n                .expect(\"Company can be root\");\n\n            // 2. Organization must be under Company\n            let team_under_comp = create_test_unit(\n                \"team-1\",\n                \"Team Under Comp\",\n                UnitType::Team,\n                Some(\"comp-1\".to_string()),\n                tenant_id\n            );\n            let result = backend.create_unit(\u0026team_under_comp).await;\n            assert!(result.is_err(), \"Team cannot be directly under Company\");\n\n            let org = create_test_unit(\n                \"org-1\",\n                \"Org\",\n                UnitType::Organization,\n                Some(\"comp-1\".to_string()),\n                tenant_id\n            );\n            backend\n                .create_unit(\u0026org)\n                .await\n                .expect(\"Organization can be under Company\");\n\n            // 3. Team must be under Organization\n            let project_under_org = create_test_unit(\n                \"proj-1\",\n                \"Proj Under Org\",\n                UnitType::Project,\n                Some(\"org-1\".to_string()),\n                tenant_id\n            );\n            let result = backend.create_unit(\u0026project_under_org).await;\n            assert!(\n                result.is_err(),\n                \"Project cannot be directly under Organization\"\n            );\n\n            let team = create_test_unit(\n                \"team-1\",\n                \"Team\",\n                UnitType::Team,\n                Some(\"org-1\".to_string()),\n                tenant_id\n            );\n            backend\n                .create_unit(\u0026team)\n                .await\n                .expect(\"Team can be under Organization\");\n\n            // 4. Project must be under Team\n            let project = create_test_unit(\n                \"proj-1\",\n                \"Project\",\n                UnitType::Project,\n                Some(\"team-1\".to_string()),\n                tenant_id\n            );\n            backend\n                .create_unit(\u0026project)\n                .await\n                .expect(\"Project can be under Team\");\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping PostgreSQL hierarchy test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_recursive_hierarchy_navigation() {\n    match setup_postgres_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let backend = PostgresBackend::new(\u0026connection_url).await.unwrap();\n            backend.initialize_schema().await.unwrap();\n\n            let tenant_id = \"tenant-1\";\n            let ctx = TenantContext::new(\n                TenantId::new(tenant_id.to_string()).unwrap(),\n                UserId::default()\n            );\n\n            // Build hierarchy: Comp -\u003e Org -\u003e Team -\u003e Proj\n            let company = create_test_unit(\"comp-1\", \"Comp\", UnitType::Company, None, tenant_id);\n            let org = create_test_unit(\n                \"org-1\",\n                \"Org\",\n                UnitType::Organization,\n                Some(\"comp-1\".to_string()),\n                tenant_id\n            );\n            let team = create_test_unit(\n                \"team-1\",\n                \"Team\",\n                UnitType::Team,\n                Some(\"org-1\".to_string()),\n                tenant_id\n            );\n            let project = create_test_unit(\n                \"proj-1\",\n                \"Proj\",\n                UnitType::Project,\n                Some(\"team-1\".to_string()),\n                tenant_id\n            );\n\n            backend.create_unit(\u0026company).await.unwrap();\n            backend.create_unit(\u0026org).await.unwrap();\n            backend.create_unit(\u0026team).await.unwrap();\n            backend.create_unit(\u0026project).await.unwrap();\n\n            // Test Ancestors of Project\n            let ancestors = backend.get_unit_ancestors(\u0026ctx, \"proj-1\").await.unwrap();\n            assert_eq!(ancestors.len(), 3);\n            assert_eq!(ancestors[0].id, \"team-1\");\n            assert_eq!(ancestors[1].id, \"org-1\");\n            assert_eq!(ancestors[2].id, \"comp-1\");\n\n            // Test Descendants of Company\n            let descendants = backend.get_unit_descendants(\u0026ctx, \"comp-1\").await.unwrap();\n            assert_eq!(descendants.len(), 3);\n            assert_eq!(descendants[0].id, \"org-1\");\n            assert_eq!(descendants[1].id, \"team-1\");\n            assert_eq!(descendants[2].id, \"proj-1\");\n\n            // Test Descendants of Organization\n            let descendants_org = backend.get_unit_descendants(\u0026ctx, \"org-1\").await.unwrap();\n            assert_eq!(descendants_org.len(), 2);\n            assert_eq!(descendants_org[0].id, \"team-1\");\n            assert_eq!(descendants_org[1].id, \"proj-1\");\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping PostgreSQL hierarchy test: Docker not available\");\n        }\n    }\n}\n","traces":[{"line":13,"address":[],"length":0,"stats":{"Line":2}},{"line":15,"address":[],"length":0,"stats":{"Line":6}},{"line":20,"address":[],"length":0,"stats":{"Line":2}},{"line":22,"address":[],"length":0,"stats":{"Line":4}},{"line":24,"address":[],"length":0,"stats":{"Line":2}},{"line":27,"address":[],"length":0,"stats":{"Line":2}},{"line":30,"address":[],"length":0,"stats":{"Line":11}},{"line":38,"address":[],"length":0,"stats":{"Line":33}},{"line":39,"address":[],"length":0,"stats":{"Line":33}},{"line":42,"address":[],"length":0,"stats":{"Line":55}},{"line":43,"address":[],"length":0,"stats":{"Line":22}},{"line":44,"address":[],"length":0,"stats":{"Line":33}},{"line":45,"address":[],"length":0,"stats":{"Line":11}}],"covered":13,"coverable":13},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","tests","hierarchy_test.rs"],"content":"use storage::postgres::PostgresBackend;\nuse mk_core::types::{OrganizationalUnit, TenantContext, TenantId, UnitType, UserId};\nuse mk_core::traits::StorageBackend;\nuse testcontainers::runners::AsyncRunner;\nuse testcontainers_modules::postgres::Postgres;\n\n#[tokio::test]\nasync fn test_recursive_hierarchy_queries() {\n    let container = match Postgres::default().start().await {\n        Ok(c) =\u003e c,\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Postgres test: Docker not available\");\n            return;\n        }\n    };\n\n    let host = container.get_host().await.unwrap();\n    let port = container.get_host_port_ipv4(5432).await.unwrap();\n    let conn_str = format!(\n        \"postgres://postgres:postgres@{}:{}/postgres?sslmode=disable\",\n        host, port\n    );\n\n    let storage = PostgresBackend::new(\u0026conn_str).await.unwrap();\n    storage.initialize_schema().await.unwrap();\n\n    let tenant_id = TenantId::new(\"t1\".to_string()).unwrap();\n    let ctx = TenantContext {\n        tenant_id: tenant_id.clone(),\n        user_id: UserId::new(\"u1\".to_string()).unwrap(),\n        agent_id: None,\n    };\n\n    // Create deep hierarchy\n    // Company -\u003e Org1 -\u003e Team1 -\u003e Project1\n    //                  -\u003e Team2 -\u003e Project2\n    \n    let company = OrganizationalUnit {\n        id: \"comp\".to_string(),\n        name: \"Company\".to_string(),\n        unit_type: UnitType::Company,\n        tenant_id: tenant_id.clone(),\n        parent_id: None,\n        metadata: std::collections::HashMap::new(),\n        created_at: 1000,\n        updated_at: 1000,\n    };\n    storage.create_unit(\u0026company).await.unwrap();\n\n    let org1 = OrganizationalUnit {\n        id: \"org1\".to_string(),\n        name: \"Org 1\".to_string(),\n        unit_type: UnitType::Organization,\n        tenant_id: tenant_id.clone(),\n        parent_id: Some(\"comp\".to_string()),\n        metadata: std::collections::HashMap::new(),\n        created_at: 1000,\n        updated_at: 1000,\n    };\n    storage.create_unit(\u0026org1).await.unwrap();\n\n    let team1 = OrganizationalUnit {\n        id: \"team1\".to_string(),\n        name: \"Team 1\".to_string(),\n        unit_type: UnitType::Team,\n        tenant_id: tenant_id.clone(),\n        parent_id: Some(\"org1\".to_string()),\n        metadata: std::collections::HashMap::new(),\n        created_at: 1000,\n        updated_at: 1000,\n    };\n    storage.create_unit(\u0026team1).await.unwrap();\n\n    let project1 = OrganizationalUnit {\n        id: \"proj1\".to_string(),\n        name: \"Project 1\".to_string(),\n        unit_type: UnitType::Project,\n        tenant_id: tenant_id.clone(),\n        parent_id: Some(\"team1\".to_string()),\n        metadata: std::collections::HashMap::new(),\n        created_at: 1000,\n        updated_at: 1000,\n    };\n    storage.create_unit(\u0026project1).await.unwrap();\n\n    // Test Descendants from Company\n    let descendants = StorageBackend::get_descendants(\u0026storage, ctx.clone(), \"comp\").await.unwrap();\n    assert_eq!(descendants.len(), 3);\n    let ids: Vec\u003cString\u003e = descendants.iter().map(|u| u.id.clone()).collect();\n    assert!(ids.contains(\u0026\"org1\".to_string()));\n    assert!(ids.contains(\u0026\"team1\".to_string()));\n    assert!(ids.contains(\u0026\"proj1\".to_string()));\n\n    // Test Descendants from Org1\n    let descendants = StorageBackend::get_descendants(\u0026storage, ctx.clone(), \"org1\").await.unwrap();\n    assert_eq!(descendants.len(), 2);\n\n    // Test Ancestors from Project1\n    let ancestors = StorageBackend::get_ancestors(\u0026storage, ctx.clone(), \"proj1\").await.unwrap();\n    assert_eq!(ancestors.len(), 3);\n    let ids: Vec\u003cString\u003e = ancestors.iter().map(|u| u.id.clone()).collect();\n    assert!(ids.contains(\u0026\"team1\".to_string()));\n    assert!(ids.contains(\u0026\"org1\".to_string()));\n    assert!(ids.contains(\u0026\"comp\".to_string()));\n\n    // Test Isolation\n    let tenant2_id = TenantId::new(\"t2\".to_string()).unwrap();\n    let ctx2 = TenantContext {\n        tenant_id: tenant2_id.clone(),\n        user_id: UserId::new(\"u2\".to_string()).unwrap(),\n        agent_id: None,\n    };\n\n    let ancestors_t2 = storage.get_ancestors(\u0026ctx2, \"proj1\").await.unwrap();\n    assert_eq!(ancestors_t2.len(), 0);\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","tests","postgres_test.rs"],"content":"//! Integration tests for PostgreSQL storage backend\n//!\n//! These tests use testcontainers to spin up a PostgreSQL instance.\n\nuse mk_core::traits::StorageBackend;\nuse mk_core::types::{TenantContext, TenantId, UserId};\nuse storage::postgres::{PostgresBackend, PostgresError};\nuse testcontainers::ContainerAsync;\nuse testcontainers::runners::AsyncRunner;\nuse testcontainers_modules::postgres::Postgres;\n\nasync fn setup_postgres_container()\n-\u003e Result\u003c(ContainerAsync\u003cPostgres\u003e, String), Box\u003cdyn std::error::Error\u003e\u003e {\n    let container = Postgres::default()\n        .with_db_name(\"testdb\")\n        .with_user(\"testuser\")\n        .with_password(\"testpass\")\n        .start()\n        .await?;\n\n    let connection_url = format!(\n        \"postgres://testuser:testpass@localhost:{}/testdb\",\n        container.get_host_port_ipv4(5432).await?\n    );\n\n    Ok((container, connection_url))\n}\n\n#[tokio::test]\nasync fn test_postgres_backend_new() {\n    match setup_postgres_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let backend = PostgresBackend::new(\u0026connection_url).await;\n            assert!(backend.is_ok(), \"Should connect to PostgreSQL\");\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping PostgreSQL test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_postgres_backend_initialize_schema() {\n    match setup_postgres_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let backend = PostgresBackend::new(\u0026connection_url).await.unwrap();\n            let result = backend.initialize_schema().await;\n            assert!(result.is_ok(), \"Should initialize schema\");\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping PostgreSQL test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_postgres_backend_store_and_retrieve() {\n    match setup_postgres_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let backend = PostgresBackend::new(\u0026connection_url).await.unwrap();\n            backend.initialize_schema().await.unwrap();\n\n            let ctx = TenantContext::new(\n                TenantId::new(\"test-tenant\".to_string()).unwrap(),\n                UserId::default(),\n            );\n            let key = \"test_key\";\n            let value = b\"{\\\"test\\\": \\\"data\\\"}\";\n            let store_result = backend.store(ctx.clone(), key, value).await;\n            assert!(store_result.is_ok(), \"Should store data\");\n\n            let retrieve_result = backend.retrieve(ctx, key).await;\n            assert!(retrieve_result.is_ok(), \"Should retrieve data\");\n            let retrieved = retrieve_result.unwrap();\n            assert!(retrieved.is_some(), \"Should have retrieved data\");\n            let retrieved_json: serde_json::Value =\n                serde_json::from_slice(\u0026retrieved.unwrap()).unwrap();\n            let expected_json: serde_json::Value = serde_json::from_slice(value).unwrap();\n            assert_eq!(\n                retrieved_json, expected_json,\n                \"Retrieved JSON should match semantically\"\n            );\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping PostgreSQL test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_postgres_backend_store_update() {\n    match setup_postgres_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let backend = PostgresBackend::new(\u0026connection_url).await.unwrap();\n            backend.initialize_schema().await.unwrap();\n\n            let ctx = TenantContext::new(\n                TenantId::new(\"test-tenant\".to_string()).unwrap(),\n                UserId::default(),\n            );\n            let key = \"update_key\";\n            let value1 = b\"{\\\"version\\\": 1}\";\n            backend.store(ctx.clone(), key, value1).await.unwrap();\n\n            let value2 = b\"{\\\"version\\\": 2}\";\n            backend.store(ctx.clone(), key, value2).await.unwrap();\n\n            let retrieved = backend.retrieve(ctx, key).await.unwrap().unwrap();\n            let retrieved_json: serde_json::Value = serde_json::from_slice(\u0026retrieved).unwrap();\n            let expected_json: serde_json::Value = serde_json::from_slice(value2).unwrap();\n            assert_eq!(\n                retrieved_json, expected_json,\n                \"Should retrieve updated value\"\n            );\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping PostgreSQL test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_postgres_backend_delete() {\n    match setup_postgres_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let backend = PostgresBackend::new(\u0026connection_url).await.unwrap();\n            backend.initialize_schema().await.unwrap();\n\n            let ctx = TenantContext::new(\n                TenantId::new(\"test-tenant\".to_string()).unwrap(),\n                UserId::default(),\n            );\n            let key = \"delete_key\";\n            let value = b\"{\\\"to_delete\\\": true}\";\n            backend.store(ctx.clone(), key, value).await.unwrap();\n\n            let exists_before = backend.exists(ctx.clone(), key).await.unwrap();\n            assert!(exists_before, \"Key should exist before delete\");\n\n            let delete_result = backend.delete(ctx.clone(), key).await;\n            assert!(delete_result.is_ok(), \"Should delete data\");\n\n            let exists_after = backend.exists(ctx.clone(), key).await.unwrap();\n            assert!(!exists_after, \"Key should not exist after delete\");\n\n            let retrieved = backend.retrieve(ctx, key).await.unwrap();\n            assert!(retrieved.is_none(), \"Should return None for deleted key\");\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping PostgreSQL test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_postgres_backend_exists() {\n    match setup_postgres_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let backend = PostgresBackend::new(\u0026connection_url).await.unwrap();\n            backend.initialize_schema().await.unwrap();\n\n            let ctx = TenantContext::new(\n                TenantId::new(\"test-tenant\".to_string()).unwrap(),\n                UserId::default(),\n            );\n            let exists = backend.exists(ctx.clone(), \"nonexistent\").await.unwrap();\n            assert!(!exists, \"Nonexistent key should not exist\");\n\n            let key = \"exists_key\";\n            let value = b\"{\\\"exists\\\": true}\";\n            backend.store(ctx.clone(), key, value).await.unwrap();\n\n            let exists = backend.exists(ctx, key).await.unwrap();\n            assert!(exists, \"Stored key should exist\");\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping PostgreSQL test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_postgres_backend_retrieve_nonexistent() {\n    match setup_postgres_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let backend = PostgresBackend::new(\u0026connection_url).await.unwrap();\n            backend.initialize_schema().await.unwrap();\n\n            let ctx = TenantContext::new(\n                TenantId::new(\"test-tenant\".to_string()).unwrap(),\n                UserId::default(),\n            );\n            let result = backend.retrieve(ctx, \"nonexistent_key\").await;\n            assert!(result.is_ok(), \"Should handle nonexistent key\");\n            assert!(\n                result.unwrap().is_none(),\n                \"Should return None for nonexistent key\"\n            );\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping PostgreSQL test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_postgres_backend_invalid_json() {\n    match setup_postgres_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let backend = PostgresBackend::new(\u0026connection_url).await.unwrap();\n            backend.initialize_schema().await.unwrap();\n\n            let ctx = TenantContext::new(\n                TenantId::new(\"test-tenant\".to_string()).unwrap(),\n                UserId::default(),\n            );\n            let key = \"invalid_json_key\";\n            let invalid_json = b\"not valid json\";\n            let result = backend.store(ctx.clone(), key, invalid_json).await;\n            assert!(result.is_ok(), \"Should handle invalid JSON gracefully\");\n\n            let retrieved = backend.retrieve(ctx, key).await.unwrap();\n            assert!(retrieved.is_some(), \"Should retrieve something\");\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping PostgreSQL test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_postgres_backend_tenant_isolation() {\n    match setup_postgres_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let backend = PostgresBackend::new(\u0026connection_url).await.unwrap();\n            backend.initialize_schema().await.unwrap();\n\n            let ctx1 = TenantContext::new(\n                TenantId::new(\"tenant-1\".to_string()).unwrap(),\n                UserId::default(),\n            );\n            let ctx2 = TenantContext::new(\n                TenantId::new(\"tenant-2\".to_string()).unwrap(),\n                UserId::default(),\n            );\n            let key = \"shared-key\";\n            let val1 = b\"{\\\"tenant\\\": 1}\";\n            let val2 = b\"{\\\"tenant\\\": 2}\";\n\n            // Tenant 1 stores data\n            backend.store(ctx1.clone(), key, val1).await.unwrap();\n\n            // Tenant 2 should NOT see it\n            let res2 = backend.retrieve(ctx2.clone(), key).await.unwrap();\n            assert!(res2.is_none(), \"Tenant 2 should not see Tenant 1 data\");\n\n            // Tenant 2 stores different data for same key\n            backend.store(ctx2.clone(), key, val2).await.unwrap();\n\n            // Both should now see their own data\n            let res1 = backend.retrieve(ctx1.clone(), key).await.unwrap();\n            let res1_json: serde_json::Value = serde_json::from_slice(\u0026res1.unwrap()).unwrap();\n            let val1_json: serde_json::Value = serde_json::from_slice(val1).unwrap();\n            assert_eq!(res1_json, val1_json);\n\n            let res2 = backend.retrieve(ctx2.clone(), key).await.unwrap();\n            let res2_json: serde_json::Value = serde_json::from_slice(\u0026res2.unwrap()).unwrap();\n            let val2_json: serde_json::Value = serde_json::from_slice(val2).unwrap();\n            assert_eq!(res2_json, val2_json);\n\n            // Deleting from Tenant 1 should NOT affect Tenant 2\n            backend.delete(ctx1.clone(), key).await.unwrap();\n            assert!(!backend.exists(ctx1, key).await.unwrap());\n            assert!(backend.exists(ctx2, key).await.unwrap());\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping PostgreSQL test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_postgres_backend_connection_error() {\n    let result = PostgresBackend::new(\"postgres://invalid:5432/invalid\").await;\n    assert!(result.is_err(), \"Should fail with invalid connection\");\n\n    match result {\n        Err(PostgresError::Database(_)) =\u003e {}\n        _ =\u003e {\n            panic!(\"Expected PostgresError::Database\");\n        }\n    }\n}\n","traces":[{"line":12,"address":[],"length":0,"stats":{"Line":9}},{"line":14,"address":[],"length":0,"stats":{"Line":27}},{"line":19,"address":[],"length":0,"stats":{"Line":9}},{"line":21,"address":[],"length":0,"stats":{"Line":18}},{"line":23,"address":[],"length":0,"stats":{"Line":9}},{"line":26,"address":[],"length":0,"stats":{"Line":9}}],"covered":6,"coverable":6},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","tests","redis_test.rs"],"content":"//! Integration tests for Redis storage backend\n//!\n//! These tests use testcontainers to spin up a Redis instance.\n\nuse errors::StorageError;\nuse storage::redis::RedisStorage;\nuse testcontainers::ContainerAsync;\nuse testcontainers::runners::AsyncRunner;\nuse testcontainers_modules::redis::Redis;\n\nasync fn setup_redis_container()\n-\u003e Result\u003c(ContainerAsync\u003cRedis\u003e, String), Box\u003cdyn std::error::Error\u003e\u003e {\n    let container = Redis::default().start().await?;\n\n    let port = container.get_host_port_ipv4(6379).await?;\n    let connection_url = format!(\"redis://localhost:{}\", port);\n\n    Ok((container, connection_url))\n}\n\n#[tokio::test]\nasync fn test_redis_basic_operations() {\n    match setup_redis_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let redis = RedisStorage::new(\u0026connection_url)\n                .await\n                .expect(\"Failed to create Redis storage\");\n\n            let set_result = redis.set(\"test_key\", \"test_value\", Some(60)).await;\n            assert!(set_result.is_ok(), \"Set operation should succeed\");\n\n            let get_result = redis.get(\"test_key\").await;\n            assert!(get_result.is_ok(), \"Get operation should succeed\");\n            assert_eq!(\n                get_result.unwrap(),\n                Some(\"test_value\".to_string()),\n                \"Retrieved value should match\"\n            );\n\n            let exists_result = redis.exists_key(\"test_key\").await;\n            assert!(exists_result.is_ok(), \"Exists operation should succeed\");\n            assert!(exists_result.unwrap(), \"Key should exist\");\n\n            let delete_result = redis.delete_key(\"test_key\").await;\n            assert!(delete_result.is_ok(), \"Delete operation should succeed\");\n\n            let exists_after_delete = redis.exists_key(\"test_key\").await;\n            assert!(\n                exists_after_delete.is_ok(),\n                \"Exists operation should succeed\"\n            );\n            assert!(\n                !exists_after_delete.unwrap(),\n                \"Key should not exist after delete\"\n            );\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Redis test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_redis_ttl_expiration() {\n    match setup_redis_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let redis = RedisStorage::new(\u0026connection_url)\n                .await\n                .expect(\"Failed to create Redis storage\");\n\n            let set_result = redis.set(\"ttl_key\", \"ttl_value\", Some(1)).await;\n            assert!(set_result.is_ok(), \"Set with TTL should succeed\");\n\n            let exists_immediately = redis.exists_key(\"ttl_key\").await;\n            assert!(\n                exists_immediately.is_ok() \u0026\u0026 exists_immediately.unwrap(),\n                \"Key should exist immediately\"\n            );\n\n            tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;\n\n            let exists_after_ttl = redis.exists_key(\"ttl_key\").await;\n            assert!(\n                exists_after_ttl.is_ok() \u0026\u0026 !exists_after_ttl.unwrap(),\n                \"Key should not exist after TTL\"\n            );\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Redis test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_redis_without_ttl() {\n    match setup_redis_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let redis = RedisStorage::new(\u0026connection_url)\n                .await\n                .expect(\"Failed to create Redis storage\");\n\n            let set_result = redis.set(\"no_ttl_key\", \"persistent_value\", None).await;\n            assert!(set_result.is_ok(), \"Set without TTL should succeed\");\n\n            let exists_result = redis.exists_key(\"no_ttl_key\").await;\n            assert!(\n                exists_result.is_ok() \u0026\u0026 exists_result.unwrap(),\n                \"Key should exist\"\n            );\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Redis test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_redis_get_nonexistent_key() {\n    match setup_redis_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let redis = RedisStorage::new(\u0026connection_url)\n                .await\n                .expect(\"Failed to create Redis storage\");\n\n            let get_result = redis.get(\"nonexistent_key\").await;\n            assert!(get_result.is_ok(), \"Get operation should succeed\");\n            assert_eq!(\n                get_result.unwrap(),\n                None,\n                \"Should return None for nonexistent key\"\n            );\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Redis test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_redis_connection_error() {\n    let result = RedisStorage::new(\"redis://invalid:6379\").await;\n\n    assert!(result.is_err(), \"Should fail with invalid connection\");\n\n    match result {\n        Err(StorageError::ConnectionError { backend, .. }) =\u003e {\n            assert_eq!(backend, \"Redis\", \"Error should be for Redis backend\");\n        }\n        _ =\u003e {\n            panic!(\"Expected ConnectionError\");\n        }\n    }\n}\n","traces":[{"line":11,"address":[],"length":0,"stats":{"Line":4}},{"line":13,"address":[],"length":0,"stats":{"Line":12}},{"line":15,"address":[],"length":0,"stats":{"Line":8}},{"line":16,"address":[],"length":0,"stats":{"Line":12}},{"line":18,"address":[],"length":0,"stats":{"Line":4}}],"covered":5,"coverable":5},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","bridge.rs"],"content":"use crate::error::{Result, SyncError};\nuse crate::pointer::{KnowledgePointer, KnowledgePointerMetadata, map_layer};\nuse crate::state::{FederationConflict, SyncConflict, SyncFailure, SyncState, SyncTrigger};\nuse crate::state_persister::SyncStatePersister;\nuse config::config::DeploymentConfig;\nuse knowledge::federation::FederationProvider;\nuse knowledge::governance::GovernanceEngine;\nuse knowledge::governance_client::{GovernanceClient, RemoteGovernanceClient};\nuse memory::manager::MemoryManager;\nuse mk_core::traits::KnowledgeRepository;\nuse mk_core::types::{KnowledgeEntry, KnowledgeLayer, MemoryEntry, TenantContext};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\n#[derive(Debug, Clone, PartialEq, Default)]\npub struct DeltaResult {\n    pub added: Vec\u003cKnowledgeEntry\u003e,\n    pub updated: Vec\u003cKnowledgeEntry\u003e,\n    pub deleted: Vec\u003cString\u003e,\n    pub unchanged: Vec\u003cString\u003e,\n}\n\npub struct SyncManager {\n    memory_manager: Arc\u003cMemoryManager\u003e,\n    knowledge_repo: Arc\u003cdyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e\u003e,\n    governance_engine: Arc\u003cGovernanceEngine\u003e,\n    governance_client: Option\u003cArc\u003cdyn GovernanceClient\u003e\u003e,\n    deployment_config: DeploymentConfig,\n    federation_manager: Option\u003cArc\u003cdyn FederationProvider\u003e\u003e,\n    persister: Arc\u003cdyn SyncStatePersister\u003e,\n    states: Arc\u003cRwLock\u003cHashMap\u003cmk_core::types::TenantId, SyncState\u003e\u003e\u003e,\n    checkpoints: Arc\u003cRwLock\u003cHashMap\u003cmk_core::types::TenantId, SyncState\u003e\u003e\u003e,\n}\n\nimpl SyncManager {\n    #[tracing::instrument(skip(\n        memory_manager,\n        knowledge_repo,\n        governance_engine,\n        federation_manager,\n        persister\n    ))]\n    pub async fn new(\n        memory_manager: Arc\u003cMemoryManager\u003e,\n        knowledge_repo: Arc\u003c\n            dyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e,\n        \u003e,\n        governance_engine: Arc\u003cGovernanceEngine\u003e,\n        deployment_config: DeploymentConfig,\n        federation_manager: Option\u003cArc\u003cdyn FederationProvider\u003e\u003e,\n        persister: Arc\u003cdyn SyncStatePersister\u003e,\n    ) -\u003e Result\u003cSelf\u003e {\n        let governance_client =\n            if deployment_config.mode == \"hybrid\" || deployment_config.mode == \"remote\" {\n                deployment_config.remote_url.as_ref().map(|url: \u0026String| {\n                    Arc::new(RemoteGovernanceClient::new(url.clone())) as Arc\u003cdyn GovernanceClient\u003e\n                })\n            } else {\n                None\n            };\n\n        let states = HashMap::new();\n        let checkpoints = HashMap::new();\n\n        Ok(Self {\n            memory_manager,\n            knowledge_repo,\n            governance_engine,\n            governance_client,\n            deployment_config,\n            federation_manager,\n            persister,\n            states: Arc::new(RwLock::new(states)),\n            checkpoints: Arc::new(RwLock::new(checkpoints)),\n        })\n    }\n\n    async fn get_or_load_state(\u0026self, tenant_id: \u0026mk_core::types::TenantId) -\u003e Result\u003cSyncState\u003e {\n        {\n            let states = self.states.read().await;\n            if let Some(state) = states.get(tenant_id) {\n                return Ok(state.clone());\n            }\n        }\n\n        let state = self\n            .persister\n            .load(tenant_id)\n            .await\n            .map_err(|e| SyncError::Persistence(e.to_string()))?;\n\n        let mut states = self.states.write().await;\n        states.insert(tenant_id.clone(), state.clone());\n        Ok(state)\n    }\n\n    async fn update_state(\u0026self, tenant_id: \u0026mk_core::types::TenantId, state: SyncState) {\n        let mut states = self.states.write().await;\n        states.insert(tenant_id.clone(), state);\n    }\n\n    #[tracing::instrument(skip(self))]\n    pub async fn initialize(\u0026self, ctx: TenantContext) -\u003e Result\u003c()\u003e {\n        tracing::info!(\"Initializing SyncManager for tenant: {}\", ctx.tenant_id);\n\n        self.knowledge_repo\n            .get_head_commit(ctx.clone())\n            .await\n            .map_err(|e| {\n                tracing::error!(\n                    \"Failed to access knowledge repository during initialization: {}\",\n                    e\n                );\n                SyncError::Internal(format!(\"Repo access failed: {}\", e))\n            })?;\n\n        let state = self.get_or_load_state(\u0026ctx.tenant_id).await?;\n        tracing::info!(\n            \"SyncManager initialized for tenant {} with version {}, last sync: {:?}\",\n            ctx.tenant_id,\n            state.version,\n            state.last_sync_at\n        );\n\n        Ok(())\n    }\n\n    #[tracing::instrument(skip(self))]\n    pub async fn shutdown(\u0026self) -\u003e Result\u003c()\u003e {\n        tracing::info!(\"Shutting down SyncManager\");\n        let states = self.states.read().await;\n        for (tenant_id, state) in states.iter() {\n            self.persister.save(tenant_id, state).await.map_err(|e| {\n                tracing::error!(\"Failed to persist state for tenant {}: {}\", tenant_id, e);\n                SyncError::Persistence(e.to_string())\n            })?;\n        }\n        tracing::info!(\"SyncManager states persisted successfully\");\n        Ok(())\n    }\n\n    #[tracing::instrument(skip(self))]\n    pub async fn scheduled_sync(\n        \u0026self,\n        ctx: TenantContext,\n        staleness_threshold_mins: u32,\n    ) -\u003e Result\u003c()\u003e {\n        if let Some(trigger) = self\n            .check_triggers(ctx.clone(), staleness_threshold_mins)\n            .await?\n        {\n            tracing::info!(\"Scheduled sync triggered by {:?}\", trigger);\n            self.run_sync_cycle(ctx, staleness_threshold_mins as u64)\n                .await?;\n        }\n        Ok(())\n    }\n}\n\nimpl SyncManager {\n    #[tracing::instrument(skip(self))]\n    pub async fn run_sync_cycle(\u0026self, ctx: TenantContext, interval_secs: u64) -\u003e Result\u003c()\u003e {\n        if self.deployment_config.mode == \"hybrid\" \u0026\u0026 !self.deployment_config.sync_enabled {\n            tracing::info!(\"Sync disabled in Hybrid mode for tenant: {}\", ctx.tenant_id);\n            return Ok(());\n        }\n\n        if let Some(trigger) = self\n            .check_triggers(ctx.clone(), (interval_secs / 60) as u32)\n            .await?\n        {\n            tracing::info!(\"Sync triggered by {:?}\", trigger);\n\n            self.create_checkpoint(\u0026ctx.tenant_id).await?;\n\n            if let Some(fed_manager) = \u0026self.federation_manager {\n                let fed_start = std::time::Instant::now();\n                if let Err(e) = self\n                    .sync_federation(ctx.clone(), fed_manager.as_ref())\n                    .await\n                {\n                    tracing::error!(\"Federation sync failed, rolling back: {}\", e);\n                    metrics::counter!(\"sync.federation.failures\", 1);\n                    self.rollback(\u0026ctx.tenant_id).await?;\n                    return Err(e);\n                }\n                metrics::histogram!(\n                    \"sync.federation.duration_ms\",\n                    fed_start.elapsed().as_millis() as f64\n                );\n            }\n\n            let inc_start = std::time::Instant::now();\n            let mut retry_count = 0;\n            let max_retries = 3;\n            let mut sync_result = self.sync_incremental(ctx.clone()).await;\n\n            while let Err(e) = sync_result {\n                if retry_count \u003e= max_retries {\n                    tracing::error!(\n                        \"Incremental sync failed after {} retries, rolling back: {}\",\n                        max_retries,\n                        e\n                    );\n                    metrics::counter!(\"sync.incremental.failures\", 1);\n                    self.rollback(\u0026ctx.tenant_id).await?;\n                    return Err(e);\n                }\n\n                retry_count += 1;\n                let backoff_ms = 100 * 2u64.pow(retry_count);\n                tracing::warn!(\n                    \"Sync failed, retrying in {}ms (attempt {}/{}): {}\",\n                    backoff_ms,\n                    retry_count,\n                    max_retries,\n                    e\n                );\n                tokio::time::sleep(std::time::Duration::from_millis(backoff_ms)).await;\n                sync_result = self.sync_incremental(ctx.clone()).await;\n            }\n\n            metrics::histogram!(\n                \"sync.incremental.duration_ms\",\n                inc_start.elapsed().as_millis() as f64\n            );\n\n            self.prune_failed_items(ctx.clone(), 30).await?;\n\n            let conflicts = self.detect_conflicts(ctx.clone()).await?;\n            if !conflicts.is_empty() {\n                tracing::info!(\"Found {} conflicts during sync cycle\", conflicts.len());\n                metrics::counter!(\"sync.conflicts.detected\", conflicts.len() as u64);\n                let mut state = self.get_or_load_state(\u0026ctx.tenant_id).await?;\n                state.stats.total_conflicts += conflicts.len() as u64;\n                self.update_state(\u0026ctx.tenant_id, state).await;\n\n                let tenant_id = ctx.tenant_id.clone();\n                if let Err(e) = self.resolve_conflicts(ctx, conflicts).await {\n                    tracing::error!(\"Conflict resolution failed, rolling back: {}\", e);\n                    metrics::counter!(\"sync.conflicts.resolution_failures\", 1);\n                    self.rollback(\u0026tenant_id).await?;\n                    return Err(e);\n                }\n                metrics::counter!(\"sync.conflicts.resolved\", 1);\n            }\n        }\n\n        Ok(())\n    }\n\n    pub async fn create_checkpoint(\u0026self, tenant_id: \u0026mk_core::types::TenantId) -\u003e Result\u003c()\u003e {\n        let mut checkpoints = self.checkpoints.write().await;\n        let state = self.get_or_load_state(tenant_id).await?;\n        checkpoints.insert(tenant_id.clone(), state);\n        tracing::debug!(\"Sync checkpoint created for tenant: {}\", tenant_id);\n        Ok(())\n    }\n\n    pub async fn rollback(\u0026self, tenant_id: \u0026mk_core::types::TenantId) -\u003e Result\u003c()\u003e {\n        let mut checkpoints = self.checkpoints.write().await;\n        if let Some(old_state) = checkpoints.remove(tenant_id) {\n            let mut states = self.states.write().await;\n            states.insert(tenant_id.clone(), old_state.clone());\n            self.persister\n                .save(tenant_id, \u0026old_state)\n                .await\n                .map_err(|e| {\n                    metrics::counter!(\"sync.persistence.rollback_failures\", 1);\n                    SyncError::Persistence(e.to_string())\n                })?;\n            tracing::info!(\n                \"Sync state rolled back to checkpoint for tenant: {}\",\n                tenant_id\n            );\n            Ok(())\n        } else {\n            tracing::warn!(\n                \"Rollback requested but no checkpoint found for tenant: {}\",\n                tenant_id\n            );\n            Ok(())\n        }\n    }\n\n    pub async fn sync_federation(\n        \u0026self,\n        ctx: TenantContext,\n        fed: \u0026dyn FederationProvider,\n    ) -\u003e Result\u003c()\u003e {\n        tracing::info!(\"Starting federation sync for tenant: {}\", ctx.tenant_id);\n        let mut state = self.get_or_load_state(\u0026ctx.tenant_id).await?;\n        let upstreams = fed.config().upstreams.clone();\n\n        for upstream in upstreams {\n            let upstream_id = upstream.id.clone();\n\n            let target_path = self\n                .knowledge_repo\n                .root_path()\n                .unwrap_or_else(|| std::path::PathBuf::from(\"data/knowledge\"))\n                .join(\"federated\")\n                .join(\u0026upstream_id);\n\n            match fed.sync_upstream(\u0026upstream_id, \u0026target_path).await {\n                Ok(_) =\u003e {\n                    tracing::info!(\"Successfully synced upstream: {}\", upstream_id);\n                    state\n                        .federation_conflicts\n                        .retain(|c| c.upstream_id != upstream_id);\n                }\n                Err(knowledge::repository::RepositoryError::InvalidPath(msg))\n                    if msg.contains(\"conflict\") || msg.contains(\"upstream\") =\u003e\n                {\n                    tracing::error!(\"Federation conflict for upstream {}: {}\", upstream_id, msg);\n                    state\n                        .federation_conflicts\n                        .retain(|c| c.upstream_id != upstream_id);\n                    state.federation_conflicts.push(FederationConflict {\n                        upstream_id: upstream_id.clone(),\n                        reason: msg,\n                        detected_at: chrono::Utc::now().timestamp(),\n                    });\n                }\n                Err(e) =\u003e {\n                    tracing::error!(\"Error syncing upstream {}: {}\", upstream_id, e);\n                }\n            }\n        }\n\n        self.persister\n            .save(\u0026ctx.tenant_id, \u0026state)\n            .await\n            .map_err(|e| SyncError::Persistence(e.to_string()))?;\n        self.update_state(\u0026ctx.tenant_id, state).await;\n        Ok(())\n    }\n\n    pub async fn get_state(\u0026self, tenant_id: \u0026mk_core::types::TenantId) -\u003e Result\u003cSyncState\u003e {\n        self.get_or_load_state(tenant_id).await\n    }\n\n    #[tracing::instrument(skip(self))]\n    pub async fn sync_incremental(\u0026self, ctx: TenantContext) -\u003e Result\u003c()\u003e {\n        let mut state = self.get_or_load_state(\u0026ctx.tenant_id).await?;\n        let start_time = std::time::Instant::now();\n\n        let last_commit = match \u0026state.last_knowledge_commit {\n            Some(c) =\u003e c.clone(),\n            None =\u003e return self.sync_all_internal(ctx, \u0026mut state, start_time).await,\n        };\n\n        let head_commit = self.knowledge_repo.get_head_commit(ctx.clone()).await?;\n        if let Some(head) = \u0026head_commit\n            \u0026\u0026 head == \u0026last_commit\n        {\n            return Ok(());\n        }\n\n        let mut sync_errors = Vec::new();\n        let affected_items = self\n            .knowledge_repo\n            .get_affected_items(ctx.clone(), \u0026last_commit)\n            .await?;\n\n        for (layer, path) in affected_items {\n            let entry = match self.knowledge_repo.get(ctx.clone(), layer, \u0026path).await {\n                Ok(Some(e)) =\u003e e,\n                Ok(None) =\u003e {\n                    if let Some(memory_id) = self.find_memory_id_by_knowledge_id(\u0026path, \u0026state) {\n                        self.memory_manager\n                            .delete_from_layer(ctx.clone(), map_layer(layer), \u0026memory_id)\n                            .await?;\n                        state.knowledge_hashes.remove(\u0026path);\n                        state.pointer_mapping.remove(\u0026memory_id);\n                        state.knowledge_layers.remove(\u0026path);\n                    }\n                    continue;\n                }\n                Err(e) =\u003e {\n                    sync_errors.push(SyncFailure {\n                        knowledge_id: path,\n                        error: e.to_string(),\n                        failed_at: chrono::Utc::now().timestamp(),\n                        retry_count: 0,\n                    });\n                    continue;\n                }\n            };\n\n            if let Err(e) = self.sync_entry(ctx.clone(), \u0026entry, \u0026mut state).await {\n                sync_errors.push(SyncFailure {\n                    knowledge_id: entry.path.clone(),\n                    error: e.to_string(),\n                    failed_at: chrono::Utc::now().timestamp(),\n                    retry_count: 0,\n                });\n            }\n        }\n\n        state.last_sync_at = Some(chrono::Utc::now().timestamp());\n        state.last_knowledge_commit = head_commit;\n        state.failed_items.extend(sync_errors);\n        state.stats.total_syncs += 1;\n        let duration = start_time.elapsed().as_millis() as u64;\n        state.stats.avg_sync_duration_ms = duration;\n\n        metrics::counter!(\"sync.cycles.total\", 1);\n        metrics::histogram!(\"sync.cycle.duration_ms\", duration as f64);\n        metrics::gauge!(\"sync.items.failed\", state.failed_items.len() as f64);\n\n        self.persister\n            .save(\u0026ctx.tenant_id, \u0026state)\n            .await\n            .map_err(|e| SyncError::Persistence(e.to_string()))?;\n        self.update_state(\u0026ctx.tenant_id, state).await;\n\n        Ok(())\n    }\n\n    #[tracing::instrument(skip(self))]\n    pub async fn sync_all(\u0026self, ctx: TenantContext) -\u003e Result\u003c()\u003e {\n        let mut state = self.get_or_load_state(\u0026ctx.tenant_id).await?;\n        let start_time = std::time::Instant::now();\n        self.sync_all_internal(ctx, \u0026mut state, start_time).await\n    }\n\n    async fn sync_all_internal(\n        \u0026self,\n        ctx: TenantContext,\n        state: \u0026mut SyncState,\n        start_time: std::time::Instant,\n    ) -\u003e Result\u003c()\u003e {\n        let head_commit = self.knowledge_repo.get_head_commit(ctx.clone()).await?;\n        let mut sync_errors = Vec::new();\n\n        for layer in [\n            mk_core::types::KnowledgeLayer::Company,\n            mk_core::types::KnowledgeLayer::Org,\n            mk_core::types::KnowledgeLayer::Team,\n            mk_core::types::KnowledgeLayer::Project,\n        ] {\n            let entries = match self.knowledge_repo.list(ctx.clone(), layer, \"\").await {\n                Ok(e) =\u003e e,\n                Err(e) =\u003e {\n                    sync_errors.push(SyncFailure {\n                        knowledge_id: format!(\"layer:{layer:?}\"),\n                        error: e.to_string(),\n                        failed_at: chrono::Utc::now().timestamp(),\n                        retry_count: 0,\n                    });\n                    continue;\n                }\n            };\n\n            for entry in entries {\n                if let Err(e) = self.sync_entry(ctx.clone(), \u0026entry, state).await {\n                    sync_errors.push(SyncFailure {\n                        knowledge_id: entry.path.clone(),\n                        error: e.to_string(),\n                        failed_at: chrono::Utc::now().timestamp(),\n                        retry_count: 0,\n                    });\n                }\n            }\n        }\n\n        state.last_sync_at = Some(chrono::Utc::now().timestamp());\n        state.last_knowledge_commit = head_commit;\n        state.failed_items.extend(sync_errors);\n        state.stats.total_syncs += 1;\n        let duration = start_time.elapsed().as_millis() as u64;\n        state.stats.avg_sync_duration_ms = duration;\n\n        metrics::counter!(\"sync.cycles.total\", 1);\n        metrics::histogram!(\"sync.cycle.duration_ms\", duration as f64);\n        metrics::gauge!(\"sync.items.failed\", state.failed_items.len() as f64);\n\n        self.persister\n            .save(\u0026ctx.tenant_id, state)\n            .await\n            .map_err(|e| SyncError::Persistence(e.to_string()))?;\n\n        self.update_state(\u0026ctx.tenant_id, state.clone()).await;\n\n        Ok(())\n    }\n\n    pub async fn check_triggers(\n        \u0026self,\n        ctx: TenantContext,\n        staleness_threshold_mins: u32,\n    ) -\u003e Result\u003cOption\u003cSyncTrigger\u003e\u003e {\n        if self.deployment_config.mode == \"remote\" {\n            return Ok(Some(SyncTrigger::Manual));\n        }\n\n        let state = self.get_or_load_state(\u0026ctx.tenant_id).await?;\n\n        let head_commit = self.knowledge_repo.get_head_commit(ctx).await?;\n        if let Some(head) = head_commit {\n            if let Some(last) = \u0026state.last_knowledge_commit {\n                if head != *last {\n                    return Ok(Some(SyncTrigger::CommitMismatch {\n                        last_commit: last.clone(),\n                        head_commit: head,\n                    }));\n                }\n            } else {\n                return Ok(Some(SyncTrigger::CommitMismatch {\n                    last_commit: \"none\".to_string(),\n                    head_commit: head,\n                }));\n            }\n        }\n\n        if let Some(last_sync) = state.last_sync_at {\n            let now = chrono::Utc::now().timestamp();\n            let elapsed_mins = (now - last_sync) / 60;\n            if elapsed_mins \u003e= staleness_threshold_mins as i64 {\n                return Ok(Some(SyncTrigger::Staleness {\n                    last_sync_at: last_sync,\n                    threshold_mins: staleness_threshold_mins,\n                }));\n            }\n        } else {\n            return Ok(Some(SyncTrigger::Manual));\n        }\n\n        Ok(None)\n    }\n\n    pub async fn resolve_federation_conflict(\n        \u0026self,\n        tenant_id: mk_core::types::TenantId,\n        upstream_id: \u0026str,\n        resolution: \u0026str,\n    ) -\u003e Result\u003c()\u003e {\n        let mut state = self.get_or_load_state(\u0026tenant_id).await?;\n\n        state\n            .federation_conflicts\n            .retain(|c| c.upstream_id != upstream_id);\n\n        tracing::info!(\n            \"Resolved federation conflict for tenant {} upstream {}: {}\",\n            tenant_id,\n            upstream_id,\n            resolution\n        );\n\n        self.persister\n            .save(\u0026tenant_id, \u0026state)\n            .await\n            .map_err(|e| SyncError::Persistence(e.to_string()))?;\n        self.update_state(\u0026tenant_id, state).await;\n        Ok(())\n    }\n\n    pub async fn resolve_conflicts(\n        \u0026self,\n        ctx: TenantContext,\n        conflicts: Vec\u003cSyncConflict\u003e,\n    ) -\u003e Result\u003c()\u003e {\n        let mut state = self.get_or_load_state(\u0026ctx.tenant_id).await?;\n\n        for conflict in conflicts {\n            match conflict {\n                SyncConflict::HashMismatch { knowledge_id, .. }\n                | SyncConflict::MissingPointer { knowledge_id, .. } =\u003e {\n                    state.knowledge_hashes.remove(\u0026knowledge_id);\n                    let layer = state\n                        .knowledge_layers\n                        .get(\u0026knowledge_id)\n                        .cloned()\n                        .unwrap_or(mk_core::types::KnowledgeLayer::Company);\n                    if let Some(entry) = self\n                        .knowledge_repo\n                        .get(ctx.clone(), layer, \u0026knowledge_id)\n                        .await?\n                    {\n                        self.sync_entry(ctx.clone(), \u0026entry, \u0026mut state).await?;\n                        metrics::counter!(\"sync.conflicts.resolved.hash_mismatch\", 1);\n                    }\n                }\n                SyncConflict::OrphanedPointer {\n                    memory_id,\n                    knowledge_id,\n                } =\u003e {\n                    for layer in [\n                        mk_core::types::MemoryLayer::Company,\n                        mk_core::types::MemoryLayer::Org,\n                        mk_core::types::MemoryLayer::Team,\n                        mk_core::types::MemoryLayer::Project,\n                    ] {\n                        let _ = self\n                            .memory_manager\n                            .delete_from_layer(ctx.clone(), layer, \u0026memory_id)\n                            .await;\n                    }\n                    state.knowledge_hashes.remove(\u0026knowledge_id);\n                    state.pointer_mapping.remove(\u0026memory_id);\n                    state.knowledge_layers.remove(\u0026knowledge_id);\n                    metrics::counter!(\"sync.conflicts.resolved.orphaned\", 1);\n                }\n                SyncConflict::DuplicatePointer {\n                    knowledge_id,\n                    mut memory_ids,\n                } =\u003e {\n                    memory_ids.sort();\n                    let _to_keep = memory_ids.remove(0);\n\n                    for mid in memory_ids {\n                        for layer in [\n                            mk_core::types::MemoryLayer::Company,\n                            mk_core::types::MemoryLayer::Org,\n                            mk_core::types::MemoryLayer::Team,\n                            mk_core::types::MemoryLayer::Project,\n                        ] {\n                            let _ = self\n                                .memory_manager\n                                .delete_from_layer(ctx.clone(), layer, \u0026mid)\n                                .await;\n                        }\n                        state.pointer_mapping.remove(\u0026mid);\n                    }\n\n                    let layer = state\n                        .knowledge_layers\n                        .get(\u0026knowledge_id)\n                        .cloned()\n                        .unwrap_or(mk_core::types::KnowledgeLayer::Company);\n                    if let Some(entry) = self\n                        .knowledge_repo\n                        .get(ctx.clone(), layer, \u0026knowledge_id)\n                        .await?\n                    {\n                        self.sync_entry(ctx.clone(), \u0026entry, \u0026mut state).await?;\n                    }\n                    metrics::counter!(\"sync.conflicts.resolved.duplicate\", 1);\n                }\n                SyncConflict::StatusChange {\n                    knowledge_id,\n                    memory_id,\n                    ..\n                } =\u003e {\n                    let layer = state\n                        .knowledge_layers\n                        .get(\u0026knowledge_id)\n                        .cloned()\n                        .unwrap_or(mk_core::types::KnowledgeLayer::Company);\n                    if let Some(entry) = self\n                        .knowledge_repo\n                        .get(ctx.clone(), layer, \u0026knowledge_id)\n                        .await?\n                    {\n                        self.sync_entry(ctx.clone(), \u0026entry, \u0026mut state).await?;\n                    }\n                    tracing::info!(\n                        \"Resolved status_change conflict for {} (memory: {})\",\n                        knowledge_id,\n                        memory_id\n                    );\n                    metrics::counter!(\"sync.conflicts.resolved.status_change\", 1);\n                }\n                SyncConflict::LayerMismatch {\n                    knowledge_id,\n                    memory_id,\n                    expected_layer,\n                    actual_layer,\n                } =\u003e {\n                    let old_memory_layer = map_layer(expected_layer);\n                    let _ = self\n                        .memory_manager\n                        .delete_from_layer(ctx.clone(), old_memory_layer, \u0026memory_id)\n                        .await;\n\n                    state.knowledge_hashes.remove(\u0026knowledge_id);\n                    state.pointer_mapping.remove(\u0026memory_id);\n                    state.knowledge_layers.remove(\u0026knowledge_id);\n\n                    if let Some(entry) = self\n                        .knowledge_repo\n                        .get(ctx.clone(), actual_layer, \u0026knowledge_id)\n                        .await?\n                    {\n                        self.sync_entry(ctx.clone(), \u0026entry, \u0026mut state).await?;\n                    }\n\n                    tracing::info!(\n                        \"Resolved layer_mismatch conflict for {}: {:?} -\u003e {:?}\",\n                        knowledge_id,\n                        expected_layer,\n                        actual_layer\n                    );\n                    metrics::counter!(\"sync.conflicts.resolved.layer_mismatch\", 1);\n                }\n                SyncConflict::DetectionError { target_id, error } =\u003e {\n                    tracing::warn!(\n                        \"Skipping resolution for detection error on {}: {}\",\n                        target_id,\n                        error\n                    );\n                }\n            }\n        }\n\n        self.persister\n            .save(\u0026ctx.tenant_id, \u0026state)\n            .await\n            .map_err(|e| SyncError::Persistence(e.to_string()))?;\n        self.update_state(\u0026ctx.tenant_id, state).await;\n        Ok(())\n    }\n\n    pub async fn detect_conflicts(\u0026self, ctx: TenantContext) -\u003e Result\u003cVec\u003cSyncConflict\u003e\u003e {\n        let state = self.get_or_load_state(\u0026ctx.tenant_id).await?;\n        let mut conflicts = Vec::new();\n\n        let mut knowledge_to_memories: HashMap\u003cString, Vec\u003cString\u003e\u003e = HashMap::new();\n        for (memory_id, knowledge_id) in \u0026state.pointer_mapping {\n            knowledge_to_memories\n                .entry(knowledge_id.clone())\n                .or_default()\n                .push(memory_id.clone());\n        }\n\n        for (knowledge_id, memory_ids) in knowledge_to_memories {\n            if memory_ids.len() \u003e 1 {\n                conflicts.push(SyncConflict::DuplicatePointer {\n                    knowledge_id,\n                    memory_ids,\n                });\n            }\n        }\n\n        for (memory_id, knowledge_id) in \u0026state.pointer_mapping {\n            println!(\n                \"Checking pointer mapping: {} -\u003e {}\",\n                memory_id, knowledge_id\n            );\n            let layer = state\n                .knowledge_layers\n                .get(knowledge_id)\n                .cloned()\n                .unwrap_or(mk_core::types::KnowledgeLayer::Company);\n            println!(\"Expected layer for {}: {:?}\", knowledge_id, layer);\n\n            let entry_res = self\n                .knowledge_repo\n                .get(ctx.clone(), layer, knowledge_id)\n                .await;\n            if let Ok(Some(ref entry)) = entry_res {\n                println!(\n                    \"Got entry from repo: {:?} at layer {:?}\",\n                    entry.path, entry.layer\n                );\n            } else if let Ok(None) = entry_res {\n                println!(\"Entry not found in repo at layer {:?}\", layer);\n            } else if let Err(ref e) = entry_res {\n                println!(\"Error getting entry from repo: {}\", e);\n            }\n\n            match entry_res {\n                Ok(Some(k_entry)) =\u003e {\n                    let expected_hash = state.knowledge_hashes.get(knowledge_id);\n                    let actual_hash = utils::compute_content_hash(\u0026k_entry.content);\n\n                    if let Some(exp) = expected_hash\n                        \u0026\u0026 exp != \u0026actual_hash\n                    {\n                        conflicts.push(SyncConflict::HashMismatch {\n                            knowledge_id: knowledge_id.clone(),\n                            memory_id: memory_id.clone(),\n                            expected_hash: exp.clone(),\n                            actual_hash,\n                        });\n                    }\n\n                    if k_entry.status == mk_core::types::KnowledgeStatus::Deprecated\n                        || k_entry.status == mk_core::types::KnowledgeStatus::Superseded\n                    {\n                        conflicts.push(SyncConflict::StatusChange {\n                            knowledge_id: knowledge_id.clone(),\n                            memory_id: memory_id.clone(),\n                            new_status: k_entry.status,\n                        });\n                    }\n\n                    if k_entry.layer != layer {\n                        conflicts.push(SyncConflict::LayerMismatch {\n                            knowledge_id: knowledge_id.clone(),\n                            memory_id: memory_id.clone(),\n                            expected_layer: layer,\n                            actual_layer: k_entry.layer,\n                        });\n                    }\n\n                    let m_layer = map_layer(k_entry.layer);\n                    match self\n                        .memory_manager\n                        .get_from_layer(ctx.clone(), m_layer, memory_id)\n                        .await\n                    {\n                        Ok(None) =\u003e {\n                            conflicts.push(SyncConflict::MissingPointer {\n                                knowledge_id: knowledge_id.clone(),\n                                expected_memory_id: memory_id.clone(),\n                            });\n                        }\n                        Ok(Some(m_entry)) =\u003e {\n                            let mut content = k_entry.content.clone();\n                            content = utils::redact_pii(\u0026content);\n                            let expected_content =\n                                self.generate_summary_internal(\u0026k_entry, \u0026content);\n                            if m_entry.content != expected_content {\n                                conflicts.push(SyncConflict::HashMismatch {\n                                    knowledge_id: knowledge_id.clone(),\n                                    memory_id: memory_id.clone(),\n                                    expected_hash: \"summary_mismatch\".to_string(),\n                                    actual_hash: \"summary_mismatch\".to_string(),\n                                });\n                            }\n                        }\n                        Err(e) =\u003e {\n                            conflicts.push(SyncConflict::DetectionError {\n                                target_id: memory_id.clone(),\n                                error: e.to_string(),\n                            });\n                            tracing::warn!(\"Failed to check memory entry {}: {}\", memory_id, e)\n                        }\n                    }\n                }\n                Ok(None) =\u003e {\n                    let mut found_elsewhere = false;\n                    for other_layer in [\n                        mk_core::types::KnowledgeLayer::Company,\n                        mk_core::types::KnowledgeLayer::Org,\n                        mk_core::types::KnowledgeLayer::Team,\n                        mk_core::types::KnowledgeLayer::Project,\n                    ] {\n                        if other_layer == layer {\n                            continue;\n                        }\n\n                        if let Ok(Some(_actual_entry)) = self\n                            .knowledge_repo\n                            .get(ctx.clone(), other_layer, knowledge_id)\n                            .await\n                        {\n                            conflicts.push(SyncConflict::LayerMismatch {\n                                knowledge_id: knowledge_id.clone(),\n                                memory_id: memory_id.clone(),\n                                expected_layer: layer,\n                                actual_layer: other_layer,\n                            });\n                            found_elsewhere = true;\n                            break;\n                        }\n                    }\n\n                    if !found_elsewhere {\n                        conflicts.push(SyncConflict::OrphanedPointer {\n                            memory_id: memory_id.clone(),\n                            knowledge_id: knowledge_id.clone(),\n                        });\n                    }\n                }\n                Err(e) =\u003e {\n                    conflicts.push(SyncConflict::DetectionError {\n                        target_id: knowledge_id.clone(),\n                        error: e.to_string(),\n                    });\n                    tracing::error!(\n                        \"Error fetching knowledge {} for conflict detection: {}\",\n                        knowledge_id,\n                        e\n                    )\n                }\n            }\n        }\n\n        Ok(conflicts)\n    }\n\n    fn find_memory_id_by_knowledge_id(\n        \u0026self,\n        knowledge_id: \u0026str,\n        state: \u0026SyncState,\n    ) -\u003e Option\u003cString\u003e {\n        state\n            .pointer_mapping\n            .iter()\n            .find(|(_, kid)| *kid == knowledge_id)\n            .map(|(mid, _)| mid.clone())\n    }\n\n    pub async fn sync_entry(\n        \u0026self,\n        ctx: TenantContext,\n        entry: \u0026KnowledgeEntry,\n        state: \u0026mut SyncState,\n    ) -\u003e Result\u003c()\u003e {\n        let mut content = entry.content.clone();\n        content = utils::redact_pii(\u0026content);\n\n        let mut context = HashMap::new();\n        context.insert(\"path\".to_string(), serde_json::json!(entry.path));\n        context.insert(\"content\".to_string(), serde_json::json!(content));\n\n        if self.deployment_config.mode == \"hybrid\" || self.deployment_config.mode == \"remote\" {\n            if let Some(client) = \u0026self.governance_client {\n                let validation = client\n                    .validate(\u0026ctx, entry.layer, \u0026context)\n                    .await\n                    .map_err(|e| SyncError::Internal(format!(\"Remote validation failed: {}\", e)))?;\n\n                if !validation.is_valid {\n                    state.stats.total_governance_blocks += 1;\n                    metrics::counter!(\"sync.governance.blocks\", 1);\n                    for violation in validation.violations {\n                        if violation.severity == mk_core::types::ConstraintSeverity::Block {\n                            state.failed_items.push(SyncFailure {\n                                knowledge_id: entry.path.clone(),\n                                error: format!(\n                                    \"Remote governance violation (BLOCK): {}\",\n                                    violation.message\n                                ),\n                                failed_at: chrono::Utc::now().timestamp(),\n                                retry_count: 0,\n                            });\n                            return Err(SyncError::GovernanceBlock(violation.message));\n                        }\n                        tracing::warn!(\n                            \"Remote governance violation ({:?}) for {}: {}\",\n                            violation.severity,\n                            entry.path,\n                            violation.message\n                        );\n                    }\n                }\n            }\n        }\n\n        if self.deployment_config.mode != \"remote\" {\n            let validation = self.governance_engine.validate(entry.layer, \u0026context);\n            if !validation.is_valid {\n                state.stats.total_governance_blocks += 1;\n                metrics::counter!(\"sync.governance.blocks\", 1);\n                for violation in validation.violations {\n                    if violation.severity == mk_core::types::ConstraintSeverity::Block {\n                        state.failed_items.push(SyncFailure {\n                            knowledge_id: entry.path.clone(),\n                            error: format!(\"Governance violation (BLOCK): {}\", violation.message),\n                            failed_at: chrono::Utc::now().timestamp(),\n                            retry_count: 0,\n                        });\n                        return Err(SyncError::GovernanceBlock(violation.message));\n                    }\n                    tracing::warn!(\n                        \"Governance violation ({:?}) for {}: {}\",\n                        violation.severity,\n                        entry.path,\n                        violation.message\n                    );\n                }\n            }\n        }\n\n        let content_hash = utils::compute_content_hash(\u0026content);\n        let knowledge_id = \u0026entry.path;\n\n        if let Some(prev_hash) = state.knowledge_hashes.get(knowledge_id)\n            \u0026\u0026 prev_hash == \u0026content_hash\n        {\n            return Ok(());\n        }\n\n        let memory_layer = map_layer(entry.layer);\n        let pointer = KnowledgePointer {\n            source_type: entry.kind,\n            source_id: knowledge_id.clone(),\n            content_hash: content_hash.clone(),\n            synced_at: chrono::Utc::now().timestamp(),\n            source_layer: entry.layer,\n            is_orphaned: false,\n        };\n\n        let metadata = KnowledgePointerMetadata {\n            kind: \"knowledge_pointer\".to_string(),\n            knowledge_pointer: pointer,\n            tags: Vec::new(),\n        };\n\n        let metadata_map = match serde_json::to_value(metadata)? {\n            serde_json::Value::Object(map) =\u003e {\n                let mut hmap = HashMap::new();\n                for (k, v) in map {\n                    hmap.insert(k, v);\n                }\n                hmap\n            }\n            _ =\u003e {\n                return Err(SyncError::Internal(\n                    \"Failed to serialize metadata\".to_string(),\n                ));\n            }\n        };\n\n        let memory_entry = MemoryEntry {\n            id: format!(\"ptr_{knowledge_id}\"),\n            content: self.generate_summary_internal(entry, \u0026content),\n            embedding: None,\n            layer: memory_layer,\n            metadata: metadata_map,\n            created_at: chrono::Utc::now().timestamp(),\n            updated_at: chrono::Utc::now().timestamp(),\n        };\n\n        self.memory_manager\n            .add_to_layer(ctx, memory_layer, memory_entry)\n            .await?;\n\n        tracing::info!(\"Synced entry: {}\", entry.path);\n\n        state\n            .knowledge_hashes\n            .insert(knowledge_id.clone(), content_hash);\n        state\n            .pointer_mapping\n            .insert(format!(\"ptr_{knowledge_id}\"), knowledge_id.clone());\n        state\n            .knowledge_layers\n            .insert(knowledge_id.clone(), entry.layer);\n        state.stats.total_items_synced += 1;\n        metrics::counter!(\"sync.items.synced\", 1);\n\n        Ok(())\n    }\n\n    pub fn generate_summary(\u0026self, entry: \u0026KnowledgeEntry) -\u003e String {\n        self.generate_summary_internal(entry, \u0026entry.content)\n    }\n\n    fn generate_summary_internal(\u0026self, entry: \u0026KnowledgeEntry, content: \u0026str) -\u003e String {\n        let mut summary = format!(\n            \"[{:?}] [{:?}] {}\\n\\n{}\",\n            entry.kind,\n            entry.status,\n            entry.path,\n            content.lines().next().unwrap_or(\"\")\n        );\n\n        let mut context = HashMap::new();\n        context.insert(\"path\".to_string(), serde_json::json!(entry.path));\n        context.insert(\"content\".to_string(), serde_json::json!(content));\n\n        let validation = self.governance_engine.validate(entry.layer, \u0026context);\n        if !validation.is_valid {\n            let blocks: Vec\u003c_\u003e = validation\n                .violations\n                .iter()\n                .filter(|v| v.severity == mk_core::types::ConstraintSeverity::Block)\n                .map(|v| v.message.as_str())\n                .collect();\n\n            if !blocks.is_empty() {\n                summary.push_str(\"\\n\\nGOVERNANCE BLOCKS:\\n- \");\n                summary.push_str(\u0026blocks.join(\"\\n- \"));\n            }\n        }\n\n        summary\n    }\n\n    pub async fn prune_failed_items(\u0026self, ctx: TenantContext, days_old: i64) -\u003e Result\u003c()\u003e {\n        let mut state = self.get_or_load_state(\u0026ctx.tenant_id).await?;\n        let now = chrono::Utc::now().timestamp();\n        let threshold = days_old * 24 * 60 * 60;\n\n        let before_count = state.failed_items.len();\n        state\n            .failed_items\n            .retain(|f| (now - f.failed_at) \u003c threshold);\n\n        let pruned = before_count - state.failed_items.len();\n        if pruned \u003e 0 {\n            tracing::info!(\n                \"Pruned {} failed items older than {} days for tenant: {}\",\n                pruned,\n                days_old,\n                ctx.tenant_id\n            );\n            self.persister\n                .save(\u0026ctx.tenant_id, \u0026state)\n                .await\n                .map_err(|e| SyncError::Persistence(e.to_string()))?;\n            self.update_state(\u0026ctx.tenant_id, state).await;\n        }\n\n        Ok(())\n    }\n\n    pub fn find_memory_id_by_knowledge_id_for_test(\n        \u0026self,\n        knowledge_id: \u0026str,\n        state: \u0026SyncState,\n    ) -\u003e Option\u003cString\u003e {\n        self.find_memory_id_by_knowledge_id(knowledge_id, state)\n    }\n\n    pub async fn detect_delta(\u0026self, ctx: TenantContext, state: \u0026SyncState) -\u003e Result\u003cDeltaResult\u003e {\n        let mut delta = DeltaResult::default();\n        let layers = [\n            KnowledgeLayer::Company,\n            KnowledgeLayer::Org,\n            KnowledgeLayer::Team,\n            KnowledgeLayer::Project,\n        ];\n\n        for layer in layers {\n            let entries = self.knowledge_repo.list(ctx.clone(), layer, \"\").await?;\n            for entry in entries {\n                let knowledge_id = \u0026entry.path;\n                let content_hash = utils::compute_content_hash(\u0026utils::redact_pii(\u0026entry.content));\n\n                match state.knowledge_hashes.get(knowledge_id) {\n                    Some(prev_hash) if prev_hash == \u0026content_hash =\u003e {\n                        delta.unchanged.push(knowledge_id.clone());\n                    }\n                    Some(_) =\u003e {\n                        delta.updated.push(entry);\n                    }\n                    None =\u003e {\n                        delta.added.push(entry);\n                    }\n                }\n            }\n        }\n\n        for (knowledge_id, _) in \u0026state.knowledge_hashes {\n            if !delta.unchanged.contains(knowledge_id)\n                \u0026\u0026 !delta.updated.iter().any(|e| \u0026e.path == knowledge_id)\n            {\n                delta.deleted.push(knowledge_id.clone());\n            }\n        }\n\n        Ok(delta)\n    }\n\n    #[tracing::instrument(skip(self, rx))]\n    pub async fn start_background_sync(\n        self: Arc\u003cSelf\u003e,\n        ctx: TenantContext,\n        interval_secs: u64,\n        staleness_threshold_mins: u32,\n        mut rx: tokio::sync::watch::Receiver\u003cbool\u003e,\n    ) -\u003e tokio::task::JoinHandle\u003c()\u003e {\n        tokio::spawn(async move {\n            let mut interval = tokio::time::interval(std::time::Duration::from_secs(interval_secs));\n            loop {\n                tokio::select! {\n                    _ = interval.tick() =\u003e {\n                        if let Err(e) = self.run_sync_cycle(ctx.clone(), staleness_threshold_mins as u64).await {\n                            metrics::counter!(\"sync.background.errors\", 1);\n                            tracing::error!(\"Background sync error for tenant {}: {}\", ctx.tenant_id, e);\n                        }\n                    }\n                    _ = rx.changed() =\u003e {\n                        if *rx.borrow() {\n                            tracing::info!(\"Background sync shutting down for tenant: {}\", ctx.tenant_id);\n                            break;\n                        }\n                    }\n                }\n            }\n        })\n    }\n}\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::TenantId;\n    use mk_core::types::{KnowledgeEntry, KnowledgeLayer, KnowledgeStatus, KnowledgeType};\n    use std::collections::HashMap;\n    use std::time::Instant;\n\n    struct MockPersister;\n    #[async_trait::async_trait]\n    impl SyncStatePersister for MockPersister {\n        async fn load(\n            \u0026self,\n            _tenant_id: \u0026mk_core::types::TenantId,\n        ) -\u003e std::result::Result\u003cSyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n            Ok(SyncState::default())\n        }\n        async fn save(\n            \u0026self,\n            _tenant_id: \u0026mk_core::types::TenantId,\n            _s: \u0026SyncState,\n        ) -\u003e std::result::Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n            Ok(())\n        }\n    }\n\n    struct MockKnowledgeRepository;\n    impl MockKnowledgeRepository {\n        fn new() -\u003e Self {\n            Self\n        }\n    }\n    #[async_trait::async_trait]\n    impl KnowledgeRepository for MockKnowledgeRepository {\n        type Error = knowledge::repository::RepositoryError;\n        async fn store(\n            \u0026self,\n            _ctx: TenantContext,\n            _e: KnowledgeEntry,\n            _m: \u0026str,\n        ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n            Ok(\"hash\".to_string())\n        }\n        async fn get(\n            \u0026self,\n            _ctx: TenantContext,\n            _l: KnowledgeLayer,\n            _p: \u0026str,\n        ) -\u003e std::result::Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(None)\n        }\n        async fn list(\n            \u0026self,\n            _ctx: TenantContext,\n            _l: KnowledgeLayer,\n            _p: \u0026str,\n        ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(Vec::new())\n        }\n        async fn delete(\n            \u0026self,\n            _ctx: TenantContext,\n            _l: KnowledgeLayer,\n            _p: \u0026str,\n            _m: \u0026str,\n        ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n            Ok(\"hash\".to_string())\n        }\n        async fn get_head_commit(\n            \u0026self,\n            _ctx: TenantContext,\n        ) -\u003e std::result::Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n            Ok(None)\n        }\n        async fn get_affected_items(\n            \u0026self,\n            _ctx: TenantContext,\n            _f: \u0026str,\n        ) -\u003e std::result::Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n            Ok(Vec::new())\n        }\n        async fn search(\n            \u0026self,\n            _ctx: TenantContext,\n            _q: \u0026str,\n            _l: Vec\u003cKnowledgeLayer\u003e,\n            _li: usize,\n        ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(Vec::new())\n        }\n        fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n            None\n        }\n    }\n\n    /// Helper to create a SyncManager with pre-populated state for a specific\n    /// tenant\n    fn create_sync_manager_with_state(\n        memory_manager: Arc\u003cMemoryManager\u003e,\n        knowledge_repo: Arc\u003c\n            dyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e,\n        \u003e,\n        state: SyncState,\n        tenant_id: \u0026mk_core::types::TenantId,\n    ) -\u003e SyncManager {\n        let mut states_map = HashMap::new();\n        states_map.insert(tenant_id.clone(), state);\n        SyncManager {\n            memory_manager,\n            knowledge_repo,\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(states_map)),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        }\n    }\n\n    #[test]\n    fn test_generate_summary() {\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let entry = KnowledgeEntry {\n            path: \"test.md\".to_string(),\n            content: \"First line\\nSecond line\\nThird line\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 1234567890,\n        };\n\n        let summary = sync_manager.generate_summary(\u0026entry);\n        assert_eq!(summary, \"[Spec] [Accepted] test.md\\n\\nFirst line\");\n    }\n\n    #[tokio::test]\n    async fn test_generate_summary_empty_content() {\n        let _ctx = TenantContext::default();\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let entry = KnowledgeEntry {\n            path: \"empty.md\".to_string(),\n            content: \"\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Adr,\n            status: KnowledgeStatus::Draft,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 1234567890,\n        };\n\n        let summary = sync_manager.generate_summary(\u0026entry);\n        assert_eq!(summary, \"[Adr] [Draft] empty.md\\n\\n\");\n    }\n\n    #[test]\n    fn test_find_memory_id_by_knowledge_id() {\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let mut state = SyncState::default();\n        state\n            .pointer_mapping\n            .insert(\"ptr_test\".to_string(), \"test.md\".to_string());\n        state\n            .pointer_mapping\n            .insert(\"ptr_other\".to_string(), \"other.md\".to_string());\n\n        let memory_id = sync_manager.find_memory_id_by_knowledge_id(\"test.md\", \u0026state);\n        assert_eq!(memory_id, Some(\"ptr_test\".to_string()));\n\n        let memory_id = sync_manager.find_memory_id_by_knowledge_id(\"nonexistent.md\", \u0026state);\n        assert_eq!(memory_id, None);\n    }\n\n    struct MockRepoWithEntries {\n        entries: Vec\u003cKnowledgeEntry\u003e,\n    }\n    impl MockRepoWithEntries {\n        fn new() -\u003e Self {\n            Self {\n                entries: Vec::new(),\n            }\n        }\n        fn add_entry(\u0026mut self, e: KnowledgeEntry) {\n            self.entries.push(e);\n        }\n    }\n    #[async_trait::async_trait]\n    impl KnowledgeRepository for MockRepoWithEntries {\n        type Error = knowledge::repository::RepositoryError;\n        async fn store(\n            \u0026self,\n            _ctx: TenantContext,\n            _e: KnowledgeEntry,\n            _m: \u0026str,\n        ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n            Ok(\"hash\".to_string())\n        }\n        async fn get(\n            \u0026self,\n            _ctx: TenantContext,\n            l: KnowledgeLayer,\n            p: \u0026str,\n        ) -\u003e std::result::Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(self\n                .entries\n                .iter()\n                .find(|e| e.path == p \u0026\u0026 e.layer == l)\n                .cloned())\n        }\n        async fn list(\n            \u0026self,\n            _ctx: TenantContext,\n            l: KnowledgeLayer,\n            _p: \u0026str,\n        ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(self\n                .entries\n                .iter()\n                .filter(|e| e.layer == l)\n                .cloned()\n                .collect())\n        }\n        async fn delete(\n            \u0026self,\n            _ctx: TenantContext,\n            _l: KnowledgeLayer,\n            _p: \u0026str,\n            _m: \u0026str,\n        ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n            Ok(\"hash\".to_string())\n        }\n        async fn get_head_commit(\n            \u0026self,\n            _ctx: TenantContext,\n        ) -\u003e std::result::Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n            Ok(None)\n        }\n        async fn get_affected_items(\n            \u0026self,\n            _ctx: TenantContext,\n            _f: \u0026str,\n        ) -\u003e std::result::Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n            Ok(Vec::new())\n        }\n        async fn search(\n            \u0026self,\n            _ctx: TenantContext,\n            _q: \u0026str,\n            _l: Vec\u003cKnowledgeLayer\u003e,\n            _li: usize,\n        ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(Vec::new())\n        }\n        fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n            None\n        }\n    }\n\n    #[tokio::test]\n    async fn test_detect_conflicts_layer_mismatch() {\n        let mut state = SyncState::default();\n        let k_id = \"moved_item.md\".to_string();\n        let m_id = format!(\"ptr_{}\", k_id);\n        let ctx = TenantContext::default();\n\n        state.pointer_mapping.insert(m_id.clone(), k_id.clone());\n        state\n            .knowledge_hashes\n            .insert(k_id.clone(), utils::compute_content_hash(\"content\"));\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: k_id.clone(),\n            content: \"content\".to_string(),\n            layer: KnowledgeLayer::Org,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n        });\n\n        let memory = Arc::new(MemoryManager::new());\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Org,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        memory\n            .add_to_layer(\n                ctx.clone(),\n                mk_core::types::MemoryLayer::Project,\n                MemoryEntry {\n                    id: m_id.clone(),\n                    content: \"[Spec] [Accepted] moved_item.md\\n\\ncontent\".to_string(),\n                    embedding: None,\n                    layer: mk_core::types::MemoryLayer::Project,\n                    metadata: HashMap::new(),\n                    created_at: 0,\n                    updated_at: 0,\n                },\n            )\n            .await\n            .unwrap();\n\n        let sync_manager =\n            create_sync_manager_with_state(memory, Arc::new(repo), state, \u0026ctx.tenant_id);\n\n        let conflicts = sync_manager.detect_conflicts(ctx).await.unwrap();\n\n        let layer_mismatch = conflicts\n            .iter()\n            .find(|c| matches!(c, SyncConflict::LayerMismatch { .. }));\n\n        assert!(\n            layer_mismatch.is_some(),\n            \"Expected LayerMismatch conflict, found: {:?}\",\n            conflicts\n        );\n\n        if let Some(SyncConflict::LayerMismatch {\n            knowledge_id,\n            expected_layer,\n            actual_layer,\n            ..\n        }) = layer_mismatch\n        {\n            assert_eq!(knowledge_id, \"moved_item.md\");\n            assert_eq!(expected_layer, \u0026KnowledgeLayer::Project);\n            assert_eq!(actual_layer, \u0026KnowledgeLayer::Org);\n        }\n    }\n\n    #[tokio::test]\n    async fn test_detect_conflicts_performance() {\n        let count = 1000;\n        let mut state = SyncState::default();\n        let mut repo = MockRepoWithEntries::new();\n\n        for i in 0..count {\n            let k_id = format!(\"item_{}.md\", i);\n            let m_id = format!(\"ptr_{}\", k_id);\n            state.pointer_mapping.insert(m_id.clone(), k_id.clone());\n            state\n                .knowledge_hashes\n                .insert(k_id.clone(), utils::compute_content_hash(\"content\"));\n            state\n                .knowledge_layers\n                .insert(k_id.clone(), KnowledgeLayer::Project);\n\n            repo.add_entry(KnowledgeEntry {\n                path: k_id.clone(),\n                content: \"content\".to_string(),\n                layer: KnowledgeLayer::Project,\n                kind: KnowledgeType::Spec,\n                status: KnowledgeStatus::Accepted,\n                metadata: HashMap::new(),\n                commit_hash: None,\n                author: None,\n                updated_at: 0,\n            });\n        }\n\n        let memory = Arc::new(MemoryManager::new());\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        for i in 0..count {\n            let k_id = format!(\"item_{}.md\", i);\n            let m_id = format!(\"ptr_{}\", k_id);\n            memory\n                .add_to_layer(\n                    mk_core::types::TenantContext::default(),\n                    mk_core::types::MemoryLayer::Project,\n                    MemoryEntry {\n                        id: m_id,\n                        content: \"[Spec] [Accepted] item.md\\n\\ncontent\".to_string(),\n                        embedding: None,\n                        layer: mk_core::types::MemoryLayer::Project,\n                        metadata: HashMap::new(),\n                        created_at: 0,\n                        updated_at: 0,\n                    },\n                )\n                .await\n                .unwrap();\n        }\n\n        let ctx = TenantContext::default();\n        let sync_manager =\n            create_sync_manager_with_state(memory, Arc::new(repo), state, \u0026ctx.tenant_id);\n\n        let start = Instant::now();\n        let _ = sync_manager.detect_conflicts(ctx).await.unwrap();\n        let duration = start.elapsed();\n\n        println!(\n            \"Conflict detection for {} items took: {:?}\",\n            count, duration\n        );\n        assert!(duration.as_secs() \u003c 5);\n    }\n\n    #[tokio::test]\n    async fn test_sync_federation_general_error() {\n        let ctx = TenantContext::default();\n        let sync_manager = SyncManager::new(\n            Arc::new(MemoryManager::new()),\n            Arc::new(MockKnowledgeRepository::new()),\n            Arc::new(GovernanceEngine::new()),\n            DeploymentConfig::default(),\n            None,\n            Arc::new(MockPersister),\n        )\n        .await\n        .unwrap();\n\n        struct ErrorFed {\n            config: knowledge::federation::FederationConfig,\n        }\n        impl ErrorFed {\n            fn new() -\u003e Self {\n                Self {\n                    config: knowledge::federation::FederationConfig {\n                        upstreams: vec![knowledge::federation::UpstreamConfig {\n                            id: \"upstream1\".to_string(),\n                            url: \"http://test\".to_string(),\n                            branch: \"main\".to_string(),\n                            auth_token: None,\n                        }],\n                        sync_interval_secs: 60,\n                    },\n                }\n            }\n        }\n        #[async_trait::async_trait]\n        impl FederationProvider for ErrorFed {\n            fn config(\u0026self) -\u003e \u0026knowledge::federation::FederationConfig {\n                \u0026self.config\n            }\n            async fn fetch_upstream_manifest(\n                \u0026self,\n                _id: \u0026str,\n            ) -\u003e std::result::Result\u003c\n                knowledge::federation::KnowledgeManifest,\n                knowledge::repository::RepositoryError,\n            \u003e {\n                Ok(knowledge::federation::KnowledgeManifest {\n                    version: \"1\".to_string(),\n                    items: HashMap::new(),\n                })\n            }\n            async fn sync_upstream(\n                \u0026self,\n                _id: \u0026str,\n                _p: \u0026std::path::Path,\n            ) -\u003e std::result::Result\u003c(), knowledge::repository::RepositoryError\u003e {\n                Err(knowledge::repository::RepositoryError::InvalidPath(\n                    \"something went wrong\".to_string(),\n                ))\n            }\n        }\n\n        let fed = ErrorFed::new();\n        let result = sync_manager.sync_federation(ctx, \u0026fed).await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_background_sync_shutdown_with_receiver() {\n        let ctx = TenantContext::default();\n        let sync_manager = Arc::new(SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        });\n\n        let (tx, rx) = tokio::sync::watch::channel(false);\n        let handle = sync_manager.start_background_sync(ctx, 1, 60, rx).await;\n\n        tokio::time::sleep(std::time::Duration::from_millis(100)).await;\n        tx.send(true).unwrap();\n\n        let result = tokio::time::timeout(std::time::Duration::from_secs(2), handle).await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_background_sync_runs_cycle() {\n        let ctx = TenantContext::default();\n        let sync_manager = Arc::new(\n            SyncManager::new(\n                Arc::new(MemoryManager::new()),\n                Arc::new(MockKnowledgeRepository::new()),\n                Arc::new(GovernanceEngine::new()),\n                DeploymentConfig::default(),\n                None,\n                Arc::new(MockPersister),\n            )\n            .await\n            .unwrap(),\n        );\n\n        let (tx, rx) = tokio::sync::watch::channel(false);\n        let handle = sync_manager.start_background_sync(ctx, 1, 0, rx).await;\n\n        tokio::time::sleep(std::time::Duration::from_millis(1500)).await;\n        tx.send(true).unwrap();\n        handle.await.unwrap();\n    }\n\n    #[tokio::test]\n    async fn test_initialize_shutdown() {\n        let ctx = TenantContext::default();\n        let sync_manager = SyncManager::new(\n            Arc::new(MemoryManager::new()),\n            Arc::new(MockKnowledgeRepository::new()),\n            Arc::new(GovernanceEngine::new()),\n            DeploymentConfig::default(),\n            None,\n            Arc::new(MockPersister),\n        )\n        .await\n        .unwrap();\n\n        sync_manager.initialize(ctx).await.unwrap();\n        sync_manager.shutdown().await.unwrap();\n    }\n\n    #[tokio::test]\n    async fn test_checkpoint_rollback() {\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let tenant_id = TenantId::default();\n\n        // Set initial state with version \"before\"\n        let mut initial_state = SyncState::default();\n        initial_state.version = \"before\".to_string();\n        sync_manager.update_state(\u0026tenant_id, initial_state).await;\n\n        sync_manager.create_checkpoint(\u0026tenant_id).await.unwrap();\n\n        // Modify state to version \"after\"\n        let mut modified_state = sync_manager.get_or_load_state(\u0026tenant_id).await.unwrap();\n        modified_state.version = \"after\".to_string();\n        sync_manager.update_state(\u0026tenant_id, modified_state).await;\n\n        sync_manager.rollback(\u0026tenant_id).await.unwrap();\n\n        let state = sync_manager.get_or_load_state(\u0026tenant_id).await.unwrap();\n        assert_eq!(state.version, \"before\");\n    }\n\n    #[tokio::test]\n    async fn test_sync_entry_governance_block() {\n        use mk_core::types::{\n            ConstraintOperator, ConstraintSeverity, ConstraintTarget, Policy, PolicyMode,\n            PolicyRule, RuleMergeStrategy, RuleType,\n        };\n\n        let ctx = TenantContext::default();\n        let mut engine = GovernanceEngine::new();\n        engine.add_policy(Policy {\n            id: \"p1\".to_string(),\n            name: \"Banned Word\".to_string(),\n            description: None,\n            layer: KnowledgeLayer::Company,\n            mode: PolicyMode::Mandatory,\n            merge_strategy: RuleMergeStrategy::Merge,\n            rules: vec![PolicyRule {\n                id: \"r1\".to_string(),\n                rule_type: RuleType::Deny,\n                target: ConstraintTarget::Code,\n                operator: ConstraintOperator::MustMatch,\n                value: serde_json::json!(\"BANNED\"),\n                severity: ConstraintSeverity::Block,\n                message: \"BANNED word found\".to_string(),\n            }],\n            metadata: HashMap::new(),\n        });\n\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(engine),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let entry = KnowledgeEntry {\n            path: \"test.md\".to_string(),\n            content: \"This is BANNED content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n        };\n\n        let mut state = SyncState::default();\n        let result = sync_manager.sync_entry(ctx, \u0026entry, \u0026mut state).await;\n\n        assert!(matches!(result, Err(SyncError::GovernanceBlock(_))));\n        assert_eq!(state.stats.total_governance_blocks, 1);\n    }\n\n    #[tokio::test]\n    async fn test_check_triggers_manual() {\n        let ctx = TenantContext::default();\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let trigger = sync_manager.check_triggers(ctx, 60).await.unwrap();\n        assert!(matches!(trigger, Some(SyncTrigger::Manual)));\n    }\n\n    #[tokio::test]\n    async fn test_detect_delta_comprehensive() {\n        let ctx = TenantContext::default();\n        let mut state = SyncState::default();\n        state.knowledge_hashes.insert(\n            \"unchanged.md\".to_string(),\n            utils::compute_content_hash(\"content\"),\n        );\n        state\n            .knowledge_hashes\n            .insert(\"updated.md\".to_string(), \"old_hash\".to_string());\n        state\n            .knowledge_hashes\n            .insert(\"deleted.md\".to_string(), \"some_hash\".to_string());\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: \"unchanged.md\".to_string(),\n            content: \"content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n        });\n        repo.add_entry(KnowledgeEntry {\n            path: \"updated.md\".to_string(),\n            content: \"new_content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n        });\n        repo.add_entry(KnowledgeEntry {\n            path: \"added.md\".to_string(),\n            content: \"new\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n        });\n\n        let sync_manager = create_sync_manager_with_state(\n            Arc::new(MemoryManager::new()),\n            Arc::new(repo),\n            state.clone(),\n            \u0026ctx.tenant_id,\n        );\n\n        let delta = sync_manager.detect_delta(ctx, \u0026state).await.unwrap();\n        assert_eq!(delta.added.len(), 1);\n        assert_eq!(delta.updated.len(), 1);\n        assert_eq!(delta.deleted.len(), 1);\n        assert_eq!(delta.unchanged.len(), 1);\n    }\n\n    #[tokio::test]\n    async fn test_sync_all_basic() {\n        let ctx = TenantContext::default();\n        let memory = Arc::new(MemoryManager::new());\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: \"test.md\".to_string(),\n            content: \"content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n        });\n\n        let sync_manager = SyncManager {\n            memory_manager: memory.clone(),\n            knowledge_repo: Arc::new(repo),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        sync_manager.sync_all(ctx.clone()).await.unwrap();\n\n        let state = sync_manager\n            .get_or_load_state(\u0026ctx.tenant_id)\n            .await\n            .unwrap();\n        assert!(state.pointer_mapping.contains_key(\"ptr_test.md\"));\n    }\n\n    #[tokio::test]\n    async fn test_resolve_orphaned_conflict() {\n        let ctx = TenantContext::default();\n        let memory = Arc::new(MemoryManager::new());\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        let m_id = \"ptr_orphaned\".to_string();\n        memory\n            .add_to_layer(\n                ctx.clone(),\n                mk_core::types::MemoryLayer::Project,\n                MemoryEntry {\n                    id: m_id.clone(),\n                    content: \"content\".to_string(),\n                    embedding: None,\n                    layer: mk_core::types::MemoryLayer::Project,\n                    metadata: HashMap::new(),\n                    created_at: 0,\n                    updated_at: 0,\n                },\n            )\n            .await\n            .unwrap();\n\n        let mut state = SyncState::default();\n        state\n            .pointer_mapping\n            .insert(m_id.clone(), \"old.md\".to_string());\n        state\n            .knowledge_layers\n            .insert(\"old.md\".to_string(), KnowledgeLayer::Project);\n\n        let sync_manager = create_sync_manager_with_state(\n            memory.clone(),\n            Arc::new(MockKnowledgeRepository::new()),\n            state,\n            \u0026ctx.tenant_id,\n        );\n\n        let conflicts = vec![SyncConflict::OrphanedPointer {\n            memory_id: m_id.clone(),\n            knowledge_id: \"old.md\".to_string(),\n        }];\n\n        sync_manager\n            .resolve_conflicts(ctx.clone(), conflicts)\n            .await\n            .unwrap();\n\n        let state = sync_manager\n            .get_or_load_state(\u0026ctx.tenant_id)\n            .await\n            .unwrap();\n        assert!(!state.pointer_mapping.contains_key(\u0026m_id));\n    }\n\n    #[tokio::test]\n    async fn test_resolve_hash_mismatch_conflict() {\n        let ctx = TenantContext::default();\n        let memory = Arc::new(MemoryManager::new());\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        let k_id = \"mismatch.md\".to_string();\n        let m_id = format!(\"ptr_{}\", k_id);\n\n        let mut state = SyncState::default();\n        state.pointer_mapping.insert(m_id.clone(), k_id.clone());\n        state\n            .knowledge_hashes\n            .insert(k_id.clone(), \"old_hash\".to_string());\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: k_id.clone(),\n            content: \"new content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n        });\n\n        let sync_manager =\n            create_sync_manager_with_state(memory.clone(), Arc::new(repo), state, \u0026ctx.tenant_id);\n\n        let conflicts = vec![SyncConflict::HashMismatch {\n            knowledge_id: k_id.clone(),\n            memory_id: m_id.clone(),\n            expected_hash: \"old_hash\".to_string(),\n            actual_hash: utils::compute_content_hash(\"new content\"),\n        }];\n\n        sync_manager\n            .resolve_conflicts(ctx.clone(), conflicts)\n            .await\n            .unwrap();\n\n        let state = sync_manager\n            .get_or_load_state(\u0026ctx.tenant_id)\n            .await\n            .unwrap();\n        assert_eq!(\n            state.knowledge_hashes.get(\u0026k_id).unwrap(),\n            \u0026utils::compute_content_hash(\"new content\")\n        );\n    }\n\n    #[tokio::test]\n    async fn test_resolve_missing_pointer_conflict() {\n        let ctx = TenantContext::default();\n        let memory = Arc::new(MemoryManager::new());\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        let k_id = \"missing.md\".to_string();\n        let m_id = format!(\"ptr_{}\", k_id);\n\n        let mut state = SyncState::default();\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: k_id.clone(),\n            content: \"content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n        });\n\n        let sync_manager =\n            create_sync_manager_with_state(memory.clone(), Arc::new(repo), state, \u0026ctx.tenant_id);\n\n        let conflicts = vec![SyncConflict::MissingPointer {\n            knowledge_id: k_id.clone(),\n            expected_memory_id: m_id.clone(),\n        }];\n\n        sync_manager\n            .resolve_conflicts(ctx.clone(), conflicts)\n            .await\n            .unwrap();\n\n        let state = sync_manager\n            .get_or_load_state(\u0026ctx.tenant_id)\n            .await\n            .unwrap();\n        assert!(state.pointer_mapping.contains_key(\u0026m_id));\n    }\n\n    #[tokio::test]\n    async fn test_prune_failed_items() {\n        let mut state = SyncState::default();\n        state.failed_items.push(SyncFailure {\n            knowledge_id: \"old_fail.md\".to_string(),\n            error: \"err\".to_string(),\n            failed_at: chrono::Utc::now().timestamp() - (40 * 24 * 60 * 60),\n            retry_count: 0,\n        });\n        state.failed_items.push(SyncFailure {\n            knowledge_id: \"new_fail.md\".to_string(),\n            error: \"err\".to_string(),\n            failed_at: chrono::Utc::now().timestamp(),\n            retry_count: 0,\n        });\n\n        let ctx = TenantContext::default();\n        let sync_manager = create_sync_manager_with_state(\n            Arc::new(MemoryManager::new()),\n            Arc::new(MockKnowledgeRepository::new()),\n            state,\n            \u0026ctx.tenant_id,\n        );\n\n        sync_manager\n            .prune_failed_items(ctx.clone(), 30)\n            .await\n            .unwrap();\n\n        let state = sync_manager\n            .get_or_load_state(\u0026ctx.tenant_id)\n            .await\n            .unwrap();\n        assert_eq!(state.failed_items.len(), 1);\n        assert_eq!(state.failed_items[0].knowledge_id, \"new_fail.md\");\n    }\n\n    #[tokio::test]\n    async fn test_resolve_detection_error() {\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let conflicts = vec![SyncConflict::DetectionError {\n            target_id: \"test\".to_string(),\n            error: \"some error\".to_string(),\n        }];\n\n        let result = sync_manager\n            .resolve_conflicts(TenantContext::default(), conflicts)\n            .await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_scheduled_sync_no_trigger() {\n        let mut state = SyncState::default();\n        state.last_sync_at = Some(chrono::Utc::now().timestamp());\n        state.last_knowledge_commit = Some(\"commit\".to_string());\n\n        let ctx = TenantContext::default();\n        let sync_manager = create_sync_manager_with_state(\n            Arc::new(MemoryManager::new()),\n            Arc::new(MockKnowledgeRepository::new()),\n            state,\n            \u0026ctx.tenant_id,\n        );\n\n        sync_manager.scheduled_sync(ctx, 120).await.unwrap();\n    }\n\n    #[tokio::test]\n    async fn test_sync_incremental_with_changes() {\n        let memory = Arc::new(MemoryManager::new());\n        let ctx = TenantContext::default();\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        let k_id = \"existing.md\".to_string();\n        let m_id = format!(\"ptr_{}\", k_id);\n\n        let mut state = SyncState::default();\n        state.last_knowledge_commit = Some(\"old_commit\".to_string());\n        state.last_sync_at = Some(chrono::Utc::now().timestamp() - 3600);\n        state.pointer_mapping.insert(m_id.clone(), k_id.clone());\n        state\n            .knowledge_hashes\n            .insert(k_id.clone(), \"old_hash\".to_string());\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        memory\n            .add_to_layer(\n                ctx.clone(),\n                mk_core::types::MemoryLayer::Project,\n                MemoryEntry {\n                    id: m_id.clone(),\n                    content: \"old\".to_string(),\n                    embedding: None,\n                    layer: mk_core::types::MemoryLayer::Project,\n                    metadata: HashMap::new(),\n                    created_at: 0,\n                    updated_at: 0,\n                },\n            )\n            .await\n            .unwrap();\n\n        struct IncrementalRepo;\n        #[async_trait::async_trait]\n        impl KnowledgeRepository for IncrementalRepo {\n            type Error = knowledge::repository::RepositoryError;\n            async fn store(\n                \u0026self,\n                _ctx: TenantContext,\n                _e: KnowledgeEntry,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"\".to_string())\n            }\n            async fn get(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                p: \u0026str,\n            ) -\u003e std::result::Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                if p == \"existing.md\" {\n                    Ok(Some(KnowledgeEntry {\n                        path: p.to_string(),\n                        content: \"updated content\".to_string(),\n                        layer: KnowledgeLayer::Project,\n                        kind: KnowledgeType::Spec,\n                        status: KnowledgeStatus::Accepted,\n                        metadata: HashMap::new(),\n                        commit_hash: None,\n                        author: None,\n                        updated_at: 0,\n                    }))\n                } else {\n                    Ok(None)\n                }\n            }\n            async fn list(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            async fn delete(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"\".to_string())\n            }\n            async fn get_head_commit(\n                \u0026self,\n                _ctx: TenantContext,\n            ) -\u003e std::result::Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n                Ok(Some(\"new_commit\".to_string()))\n            }\n            async fn get_affected_items(\n                \u0026self,\n                _ctx: TenantContext,\n                _f: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n                Ok(vec![(KnowledgeLayer::Project, \"existing.md\".to_string())])\n            }\n            async fn search(\n                \u0026self,\n                _ctx: TenantContext,\n                _q: \u0026str,\n                _l: Vec\u003cKnowledgeLayer\u003e,\n                _li: usize,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n                None\n            }\n        }\n\n        let sync_manager = create_sync_manager_with_state(\n            memory.clone(),\n            Arc::new(IncrementalRepo),\n            state,\n            \u0026ctx.tenant_id,\n        );\n\n        sync_manager.sync_incremental(ctx.clone()).await.unwrap();\n\n        let state = sync_manager\n            .get_or_load_state(\u0026ctx.tenant_id)\n            .await\n            .unwrap();\n        assert_eq!(state.last_knowledge_commit, Some(\"new_commit\".to_string()));\n    }\n\n    #[tokio::test]\n    async fn test_sync_incremental_deletion() {\n        let memory = Arc::new(MemoryManager::new());\n        let ctx = TenantContext::default();\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        let k_id = \"deleted.md\".to_string();\n        let m_id = format!(\"ptr_{}\", k_id);\n\n        let mut state = SyncState::default();\n        state.last_knowledge_commit = Some(\"old_commit\".to_string());\n        state.pointer_mapping.insert(m_id.clone(), k_id.clone());\n        state\n            .knowledge_hashes\n            .insert(k_id.clone(), \"hash\".to_string());\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        memory\n            .add_to_layer(\n                ctx.clone(),\n                mk_core::types::MemoryLayer::Project,\n                MemoryEntry {\n                    id: m_id.clone(),\n                    content: \"content\".to_string(),\n                    embedding: None,\n                    layer: mk_core::types::MemoryLayer::Project,\n                    metadata: HashMap::new(),\n                    created_at: 0,\n                    updated_at: 0,\n                },\n            )\n            .await\n            .unwrap();\n\n        struct DeletingRepo;\n        #[async_trait::async_trait]\n        impl KnowledgeRepository for DeletingRepo {\n            type Error = knowledge::repository::RepositoryError;\n            async fn store(\n                \u0026self,\n                _ctx: TenantContext,\n                _e: KnowledgeEntry,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"\".to_string())\n            }\n            async fn get(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n            ) -\u003e std::result::Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(None)\n            }\n            async fn list(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            async fn delete(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"\".to_string())\n            }\n            async fn get_head_commit(\n                \u0026self,\n                _ctx: TenantContext,\n            ) -\u003e std::result::Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n                Ok(Some(\"new_commit\".to_string()))\n            }\n            async fn get_affected_items(\n                \u0026self,\n                _ctx: TenantContext,\n                _f: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n                Ok(vec![(KnowledgeLayer::Project, \"deleted.md\".to_string())])\n            }\n            async fn search(\n                \u0026self,\n                _ctx: TenantContext,\n                _q: \u0026str,\n                _l: Vec\u003cKnowledgeLayer\u003e,\n                _li: usize,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n                None\n            }\n        }\n\n        let sync_manager = create_sync_manager_with_state(\n            memory.clone(),\n            Arc::new(DeletingRepo),\n            state,\n            \u0026ctx.tenant_id,\n        );\n\n        sync_manager.sync_incremental(ctx.clone()).await.unwrap();\n\n        let state = sync_manager\n            .get_or_load_state(\u0026ctx.tenant_id)\n            .await\n            .unwrap();\n        assert!(!state.pointer_mapping.contains_key(\u0026m_id));\n        assert!(!state.knowledge_hashes.contains_key(\u0026k_id));\n    }\n\n    #[tokio::test]\n    async fn test_resolve_federation_conflict() {\n        let mut state = SyncState::default();\n        state\n            .federation_conflicts\n            .push(crate::state::FederationConflict {\n                upstream_id: \"upstream1\".to_string(),\n                reason: \"conflict\".to_string(),\n                detected_at: 0,\n            });\n\n        let ctx = TenantContext::default();\n        let sync_manager = create_sync_manager_with_state(\n            Arc::new(MemoryManager::new()),\n            Arc::new(MockKnowledgeRepository::new()),\n            state,\n            \u0026ctx.tenant_id,\n        );\n\n        sync_manager\n            .resolve_federation_conflict(ctx.tenant_id.clone(), \"upstream1\", \"manual fix\")\n            .await\n            .unwrap();\n\n        let state = sync_manager\n            .get_or_load_state(\u0026ctx.tenant_id)\n            .await\n            .unwrap();\n        assert!(state.federation_conflicts.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_check_triggers_commit_mismatch() {\n        struct RepoWithHead(String);\n        #[async_trait::async_trait]\n        impl KnowledgeRepository for RepoWithHead {\n            type Error = knowledge::repository::RepositoryError;\n            async fn store(\n                \u0026self,\n                _ctx: TenantContext,\n                _e: KnowledgeEntry,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"\".to_string())\n            }\n            async fn get(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n            ) -\u003e std::result::Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(None)\n            }\n            async fn list(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            async fn delete(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"\".to_string())\n            }\n            async fn get_head_commit(\n                \u0026self,\n                _ctx: TenantContext,\n            ) -\u003e std::result::Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n                Ok(Some(self.0.clone()))\n            }\n            async fn get_affected_items(\n                \u0026self,\n                _ctx: TenantContext,\n                _f: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            async fn search(\n                \u0026self,\n                _ctx: TenantContext,\n                _q: \u0026str,\n                _l: Vec\u003cKnowledgeLayer\u003e,\n                _li: usize,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n                None\n            }\n        }\n\n        let mut state = SyncState::default();\n        state.last_knowledge_commit = Some(\"old\".to_string());\n        state.last_sync_at = Some(chrono::Utc::now().timestamp());\n\n        let ctx = TenantContext::default();\n        let sync_manager = create_sync_manager_with_state(\n            Arc::new(MemoryManager::new()),\n            Arc::new(RepoWithHead(\"new\".to_string())),\n            state,\n            \u0026ctx.tenant_id,\n        );\n\n        let trigger = sync_manager.check_triggers(ctx, 120).await.unwrap();\n        assert!(matches!(trigger, Some(SyncTrigger::CommitMismatch { .. })));\n    }\n\n    #[tokio::test]\n    async fn test_check_triggers_staleness() {\n        struct RepoWithHead(String);\n        #[async_trait::async_trait]\n        impl KnowledgeRepository for RepoWithHead {\n            type Error = knowledge::repository::RepositoryError;\n            async fn store(\n                \u0026self,\n                _ctx: TenantContext,\n                _e: KnowledgeEntry,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"\".to_string())\n            }\n            async fn get(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n            ) -\u003e std::result::Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(None)\n            }\n            async fn list(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            async fn delete(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"\".to_string())\n            }\n            async fn get_head_commit(\n                \u0026self,\n                _ctx: TenantContext,\n            ) -\u003e std::result::Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n                Ok(Some(self.0.clone()))\n            }\n            async fn get_affected_items(\n                \u0026self,\n                _ctx: TenantContext,\n                _f: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            async fn search(\n                \u0026self,\n                _ctx: TenantContext,\n                _q: \u0026str,\n                _l: Vec\u003cKnowledgeLayer\u003e,\n                _li: usize,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n                None\n            }\n        }\n\n        let mut state = SyncState::default();\n        state.last_knowledge_commit = Some(\"same\".to_string());\n        state.last_sync_at = Some(chrono::Utc::now().timestamp() - 3600);\n\n        let ctx = TenantContext::default();\n        let sync_manager = create_sync_manager_with_state(\n            Arc::new(MemoryManager::new()),\n            Arc::new(RepoWithHead(\"same\".to_string())),\n            state,\n            \u0026ctx.tenant_id,\n        );\n\n        let trigger = sync_manager.check_triggers(ctx, 30).await.unwrap();\n        assert!(matches!(trigger, Some(SyncTrigger::Staleness { .. })));\n    }\n\n    #[tokio::test]\n    async fn test_run_sync_cycle_with_trigger() {\n        let memory = Arc::new(MemoryManager::new());\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        let sync_manager = SyncManager {\n            memory_manager: memory,\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let ctx = TenantContext::default();\n        sync_manager.run_sync_cycle(ctx.clone(), 60).await.unwrap();\n\n        let state = sync_manager\n            .get_or_load_state(\u0026ctx.tenant_id)\n            .await\n            .unwrap();\n        assert!(state.last_sync_at.is_some());\n    }\n\n    #[tokio::test]\n    async fn test_resolve_status_change_conflict() {\n        let memory = Arc::new(MemoryManager::new());\n        let ctx = TenantContext::default();\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        let k_id = \"deprecated.md\".to_string();\n        let m_id = format!(\"ptr_{}\", k_id);\n\n        let mut state = SyncState::default();\n        state.pointer_mapping.insert(m_id.clone(), k_id.clone());\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: k_id.clone(),\n            content: \"content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Deprecated,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n        });\n\n        let sync_manager =\n            create_sync_manager_with_state(memory.clone(), Arc::new(repo), state, \u0026ctx.tenant_id);\n\n        let conflicts = vec![SyncConflict::StatusChange {\n            knowledge_id: k_id.clone(),\n            memory_id: m_id.clone(),\n            new_status: KnowledgeStatus::Deprecated,\n        }];\n\n        sync_manager\n            .resolve_conflicts(ctx.clone(), conflicts)\n            .await\n            .unwrap();\n\n        let mem_entry = memory\n            .get_from_layer(ctx, mk_core::types::MemoryLayer::Project, \u0026m_id)\n            .await\n            .unwrap()\n            .unwrap();\n        assert!(mem_entry.content.contains(\"[Deprecated]\"));\n    }\n\n    #[tokio::test]\n    async fn test_resolve_layer_mismatch_conflict() {\n        let memory = Arc::new(MemoryManager::new());\n        let ctx = TenantContext::default();\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Org,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        let k_id = \"moved.md\".to_string();\n        let m_id = format!(\"ptr_{}\", k_id);\n\n        let mut state = SyncState::default();\n        state.pointer_mapping.insert(m_id.clone(), k_id.clone());\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        memory\n            .add_to_layer(\n                ctx.clone(),\n                mk_core::types::MemoryLayer::Project,\n                MemoryEntry {\n                    id: m_id.clone(),\n                    content: \"old\".to_string(),\n                    embedding: None,\n                    layer: mk_core::types::MemoryLayer::Project,\n                    metadata: HashMap::new(),\n                    created_at: 0,\n                    updated_at: 0,\n                },\n            )\n            .await\n            .unwrap();\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: k_id.clone(),\n            content: \"content\".to_string(),\n            layer: KnowledgeLayer::Org,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n        });\n\n        let sync_manager =\n            create_sync_manager_with_state(memory.clone(), Arc::new(repo), state, \u0026ctx.tenant_id);\n\n        let conflicts = vec![SyncConflict::LayerMismatch {\n            knowledge_id: k_id.clone(),\n            memory_id: m_id.clone(),\n            expected_layer: KnowledgeLayer::Project,\n            actual_layer: KnowledgeLayer::Org,\n        }];\n\n        sync_manager\n            .resolve_conflicts(ctx.clone(), conflicts)\n            .await\n            .unwrap();\n\n        assert!(\n            memory\n                .get_from_layer(ctx.clone(), mk_core::types::MemoryLayer::Project, \u0026m_id)\n                .await\n                .unwrap()\n                .is_none()\n        );\n        assert!(\n            memory\n                .get_from_layer(ctx, mk_core::types::MemoryLayer::Org, \u0026m_id)\n                .await\n                .unwrap()\n                .is_some()\n        );\n    }\n\n    #[tokio::test]\n    async fn test_resolve_duplicate_pointer_conflict() {\n        let memory = Arc::new(MemoryManager::new());\n        let ctx = TenantContext::default();\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        let k_id = \"duplicate.md\".to_string();\n        let m_id1 = \"ptr_1\".to_string();\n        let m_id2 = \"ptr_2\".to_string();\n\n        let mut state = SyncState::default();\n        state.pointer_mapping.insert(m_id1.clone(), k_id.clone());\n        state.pointer_mapping.insert(m_id2.clone(), k_id.clone());\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: k_id.clone(),\n            content: \"content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n        });\n\n        let sync_manager =\n            create_sync_manager_with_state(memory.clone(), Arc::new(repo), state, \u0026ctx.tenant_id);\n\n        let conflicts = vec![SyncConflict::DuplicatePointer {\n            knowledge_id: k_id.clone(),\n            memory_ids: vec![m_id1.clone(), m_id2.clone()],\n        }];\n\n        sync_manager\n            .resolve_conflicts(ctx.clone(), conflicts)\n            .await\n            .unwrap();\n\n        let state = sync_manager\n            .get_or_load_state(\u0026ctx.tenant_id)\n            .await\n            .unwrap();\n        assert!(state.pointer_mapping.contains_key(\u0026format!(\"ptr_{}\", k_id)));\n    }\n\n    #[tokio::test]\n    async fn test_check_triggers_no_last_commit() {\n        // Given: State with no last_knowledge_commit and no last_sync_at\n        let state = SyncState::default();\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: \"test.md\".to_string(),\n            content: \"content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: Some(\"abc123\".to_string()),\n            author: None,\n            updated_at: 0,\n        });\n\n        struct MockRepoWithCommit;\n        #[async_trait::async_trait]\n        impl KnowledgeRepository for MockRepoWithCommit {\n            type Error = knowledge::repository::RepositoryError;\n            async fn store(\n                \u0026self,\n                _ctx: TenantContext,\n                _e: KnowledgeEntry,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"hash\".to_string())\n            }\n            async fn get(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n            ) -\u003e std::result::Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(None)\n            }\n            async fn list(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            async fn delete(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"hash\".to_string())\n            }\n            async fn get_head_commit(\n                \u0026self,\n                _ctx: TenantContext,\n            ) -\u003e std::result::Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n                Ok(Some(\"abc123\".to_string()))\n            }\n            async fn get_affected_items(\n                \u0026self,\n                _ctx: TenantContext,\n                _f: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            async fn search(\n                \u0026self,\n                _ctx: TenantContext,\n                _q: \u0026str,\n                _l: Vec\u003cKnowledgeLayer\u003e,\n                _li: usize,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n                None\n            }\n        }\n\n        let ctx = TenantContext::default();\n        let sync_manager = create_sync_manager_with_state(\n            Arc::new(MemoryManager::new()),\n            Arc::new(MockRepoWithCommit),\n            state,\n            \u0026ctx.tenant_id,\n        );\n\n        let trigger = sync_manager.check_triggers(ctx, 60).await.unwrap();\n\n        assert!(matches!(\n            trigger,\n            Some(SyncTrigger::CommitMismatch {\n                last_commit,\n                head_commit\n            }) if last_commit == \"none\" \u0026\u0026 head_commit == \"abc123\"\n        ));\n    }\n\n    #[tokio::test]\n    async fn test_find_memory_id_wrapper() {\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let mut state = SyncState::default();\n        state\n            .pointer_mapping\n            .insert(\"ptr_test\".to_string(), \"test.md\".to_string());\n\n        // When: calling the test wrapper\n        let result = sync_manager.find_memory_id_by_knowledge_id_for_test(\"test.md\", \u0026state);\n\n        // Then: Should find the mapping\n        assert_eq!(result, Some(\"ptr_test\".to_string()));\n    }\n\n    #[tokio::test]\n    async fn test_sync_all_with_list_error() {\n        struct MockRepoListError;\n        #[async_trait::async_trait]\n        impl KnowledgeRepository for MockRepoListError {\n            type Error = knowledge::repository::RepositoryError;\n            async fn store(\n                \u0026self,\n                _ctx: TenantContext,\n                _e: KnowledgeEntry,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"hash\".to_string())\n            }\n            async fn get(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n            ) -\u003e std::result::Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(None)\n            }\n            async fn list(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Err(knowledge::repository::RepositoryError::InvalidPath(\n                    \"test error\".to_string(),\n                ))\n            }\n            async fn delete(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"hash\".to_string())\n            }\n            async fn get_head_commit(\n                \u0026self,\n                _ctx: TenantContext,\n            ) -\u003e std::result::Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n                Ok(Some(\"abc\".to_string()))\n            }\n            async fn get_affected_items(\n                \u0026self,\n                _ctx: TenantContext,\n                _f: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            async fn search(\n                \u0026self,\n                _ctx: TenantContext,\n                _q: \u0026str,\n                _l: Vec\u003cKnowledgeLayer\u003e,\n                _li: usize,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n                None\n            }\n        }\n\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockRepoListError),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let ctx = TenantContext::default();\n\n        // When: sync_all is called with repo returning list errors\n        sync_manager.sync_all(ctx.clone()).await.unwrap();\n\n        // Then: State should contain failed items for each layer\n        let state = sync_manager\n            .get_or_load_state(\u0026ctx.tenant_id)\n            .await\n            .unwrap();\n        assert!(\n            state.failed_items.len() \u003e= 4,\n            \"Expected failed items for each layer, got {}\",\n            state.failed_items.len()\n        );\n    }\n\n    #[tokio::test]\n    async fn test_rollback_no_checkpoint() {\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let tenant_id = TenantId::default();\n\n        // When: rollback is called with no checkpoint\n        let result = sync_manager.rollback(\u0026tenant_id).await;\n\n        // Then: Should succeed (no-op)\n        assert!(result.is_ok());\n    }\n}\n","traces":[{"line":44,"address":[],"length":0,"stats":{"Line":26}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":160}},{"line":81,"address":[],"length":0,"stats":{"Line":160}},{"line":82,"address":[],"length":0,"stats":{"Line":226}},{"line":83,"address":[],"length":0,"stats":{"Line":66}},{"line":87,"address":[],"length":0,"stats":{"Line":42}},{"line":88,"address":[],"length":0,"stats":{"Line":28}},{"line":89,"address":[],"length":0,"stats":{"Line":14}},{"line":90,"address":[],"length":0,"stats":{"Line":14}},{"line":91,"address":[],"length":0,"stats":{"Line":14}},{"line":93,"address":[],"length":0,"stats":{"Line":28}},{"line":94,"address":[],"length":0,"stats":{"Line":70}},{"line":95,"address":[],"length":0,"stats":{"Line":14}},{"line":98,"address":[],"length":0,"stats":{"Line":58}},{"line":99,"address":[],"length":0,"stats":{"Line":58}},{"line":100,"address":[],"length":0,"stats":{"Line":116}},{"line":104,"address":[],"length":0,"stats":{"Line":2}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":2}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":1}},{"line":163,"address":[],"length":0,"stats":{"Line":12}},{"line":253,"address":[],"length":0,"stats":{"Line":14}},{"line":254,"address":[],"length":0,"stats":{"Line":14}},{"line":255,"address":[],"length":0,"stats":{"Line":28}},{"line":256,"address":[],"length":0,"stats":{"Line":28}},{"line":257,"address":[],"length":0,"stats":{"Line":7}},{"line":258,"address":[],"length":0,"stats":{"Line":7}},{"line":261,"address":[],"length":0,"stats":{"Line":4}},{"line":262,"address":[],"length":0,"stats":{"Line":4}},{"line":263,"address":[],"length":0,"stats":{"Line":5}},{"line":264,"address":[],"length":0,"stats":{"Line":2}},{"line":265,"address":[],"length":0,"stats":{"Line":5}},{"line":266,"address":[],"length":0,"stats":{"Line":2}},{"line":267,"address":[],"length":0,"stats":{"Line":2}},{"line":268,"address":[],"length":0,"stats":{"Line":1}},{"line":269,"address":[],"length":0,"stats":{"Line":1}},{"line":270,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":1}},{"line":274,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":1}},{"line":279,"address":[],"length":0,"stats":{"Line":1}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":1}},{"line":287,"address":[],"length":0,"stats":{"Line":2}},{"line":292,"address":[],"length":0,"stats":{"Line":2}},{"line":293,"address":[],"length":0,"stats":{"Line":8}},{"line":294,"address":[],"length":0,"stats":{"Line":6}},{"line":296,"address":[],"length":0,"stats":{"Line":6}},{"line":297,"address":[],"length":0,"stats":{"Line":6}},{"line":299,"address":[],"length":0,"stats":{"Line":4}},{"line":300,"address":[],"length":0,"stats":{"Line":2}},{"line":302,"address":[],"length":0,"stats":{"Line":3}},{"line":304,"address":[],"length":0,"stats":{"Line":4}},{"line":306,"address":[],"length":0,"stats":{"Line":10}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":1}},{"line":314,"address":[],"length":0,"stats":{"Line":5}},{"line":316,"address":[],"length":0,"stats":{"Line":1}},{"line":317,"address":[],"length":0,"stats":{"Line":1}},{"line":318,"address":[],"length":0,"stats":{"Line":1}},{"line":319,"address":[],"length":0,"stats":{"Line":1}},{"line":320,"address":[],"length":0,"stats":{"Line":3}},{"line":321,"address":[],"length":0,"stats":{"Line":3}},{"line":322,"address":[],"length":0,"stats":{"Line":2}},{"line":323,"address":[],"length":0,"stats":{"Line":1}},{"line":326,"address":[],"length":0,"stats":{"Line":1}},{"line":327,"address":[],"length":0,"stats":{"Line":1}},{"line":332,"address":[],"length":0,"stats":{"Line":4}},{"line":333,"address":[],"length":0,"stats":{"Line":4}},{"line":334,"address":[],"length":0,"stats":{"Line":2}},{"line":335,"address":[],"length":0,"stats":{"Line":2}},{"line":336,"address":[],"length":0,"stats":{"Line":8}},{"line":337,"address":[],"length":0,"stats":{"Line":2}},{"line":340,"address":[],"length":0,"stats":{"Line":6}},{"line":341,"address":[],"length":0,"stats":{"Line":9}},{"line":345,"address":[],"length":0,"stats":{"Line":20}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":423,"address":[],"length":0,"stats":{"Line":8}},{"line":429,"address":[],"length":0,"stats":{"Line":10}},{"line":435,"address":[],"length":0,"stats":{"Line":40}},{"line":436,"address":[],"length":0,"stats":{"Line":20}},{"line":438,"address":[],"length":0,"stats":{"Line":40}},{"line":439,"address":[],"length":0,"stats":{"Line":10}},{"line":440,"address":[],"length":0,"stats":{"Line":10}},{"line":441,"address":[],"length":0,"stats":{"Line":10}},{"line":442,"address":[],"length":0,"stats":{"Line":10}},{"line":444,"address":[],"length":0,"stats":{"Line":276}},{"line":445,"address":[],"length":0,"stats":{"Line":72}},{"line":446,"address":[],"length":0,"stats":{"Line":4}},{"line":447,"address":[],"length":0,"stats":{"Line":12}},{"line":448,"address":[],"length":0,"stats":{"Line":12}},{"line":449,"address":[],"length":0,"stats":{"Line":12}},{"line":450,"address":[],"length":0,"stats":{"Line":4}},{"line":451,"address":[],"length":0,"stats":{"Line":4}},{"line":453,"address":[],"length":0,"stats":{"Line":4}},{"line":457,"address":[],"length":0,"stats":{"Line":46}},{"line":458,"address":[],"length":0,"stats":{"Line":37}},{"line":459,"address":[],"length":0,"stats":{"Line":3}},{"line":460,"address":[],"length":0,"stats":{"Line":3}},{"line":461,"address":[],"length":0,"stats":{"Line":3}},{"line":462,"address":[],"length":0,"stats":{"Line":1}},{"line":463,"address":[],"length":0,"stats":{"Line":1}},{"line":469,"address":[],"length":0,"stats":{"Line":10}},{"line":470,"address":[],"length":0,"stats":{"Line":20}},{"line":471,"address":[],"length":0,"stats":{"Line":30}},{"line":472,"address":[],"length":0,"stats":{"Line":10}},{"line":473,"address":[],"length":0,"stats":{"Line":20}},{"line":474,"address":[],"length":0,"stats":{"Line":10}},{"line":476,"address":[],"length":0,"stats":{"Line":10}},{"line":477,"address":[],"length":0,"stats":{"Line":10}},{"line":478,"address":[],"length":0,"stats":{"Line":10}},{"line":480,"address":[],"length":0,"stats":{"Line":20}},{"line":481,"address":[],"length":0,"stats":{"Line":20}},{"line":482,"address":[],"length":0,"stats":{"Line":10}},{"line":483,"address":[],"length":0,"stats":{"Line":10}},{"line":485,"address":[],"length":0,"stats":{"Line":50}},{"line":487,"address":[],"length":0,"stats":{"Line":10}},{"line":490,"address":[],"length":0,"stats":{"Line":11}},{"line":495,"address":[],"length":0,"stats":{"Line":11}},{"line":496,"address":[],"length":0,"stats":{"Line":0}},{"line":499,"address":[],"length":0,"stats":{"Line":44}},{"line":501,"address":[],"length":0,"stats":{"Line":33}},{"line":502,"address":[],"length":0,"stats":{"Line":16}},{"line":503,"address":[],"length":0,"stats":{"Line":8}},{"line":504,"address":[],"length":0,"stats":{"Line":3}},{"line":505,"address":[],"length":0,"stats":{"Line":1}},{"line":506,"address":[],"length":0,"stats":{"Line":2}},{"line":507,"address":[],"length":0,"stats":{"Line":1}},{"line":511,"address":[],"length":0,"stats":{"Line":2}},{"line":512,"address":[],"length":0,"stats":{"Line":4}},{"line":513,"address":[],"length":0,"stats":{"Line":2}},{"line":518,"address":[],"length":0,"stats":{"Line":12}},{"line":519,"address":[],"length":0,"stats":{"Line":12}},{"line":520,"address":[],"length":0,"stats":{"Line":8}},{"line":521,"address":[],"length":0,"stats":{"Line":4}},{"line":522,"address":[],"length":0,"stats":{"Line":3}},{"line":523,"address":[],"length":0,"stats":{"Line":3}},{"line":524,"address":[],"length":0,"stats":{"Line":3}},{"line":528,"address":[],"length":0,"stats":{"Line":4}},{"line":531,"address":[],"length":0,"stats":{"Line":1}},{"line":534,"address":[],"length":0,"stats":{"Line":1}},{"line":540,"address":[],"length":0,"stats":{"Line":4}},{"line":542,"address":[],"length":0,"stats":{"Line":1}},{"line":543,"address":[],"length":0,"stats":{"Line":1}},{"line":544,"address":[],"length":0,"stats":{"Line":3}},{"line":546,"address":[],"length":0,"stats":{"Line":1}},{"line":547,"address":[],"length":0,"stats":{"Line":0}},{"line":553,"address":[],"length":0,"stats":{"Line":2}},{"line":554,"address":[],"length":0,"stats":{"Line":2}},{"line":555,"address":[],"length":0,"stats":{"Line":1}},{"line":556,"address":[],"length":0,"stats":{"Line":1}},{"line":557,"address":[],"length":0,"stats":{"Line":4}},{"line":558,"address":[],"length":0,"stats":{"Line":1}},{"line":561,"address":[],"length":0,"stats":{"Line":9}},{"line":566,"address":[],"length":0,"stats":{"Line":36}},{"line":568,"address":[],"length":0,"stats":{"Line":29}},{"line":569,"address":[],"length":0,"stats":{"Line":10}},{"line":570,"address":[],"length":0,"stats":{"Line":3}},{"line":571,"address":[],"length":0,"stats":{"Line":2}},{"line":572,"address":[],"length":0,"stats":{"Line":15}},{"line":573,"address":[],"length":0,"stats":{"Line":10}},{"line":574,"address":[],"length":0,"stats":{"Line":5}},{"line":575,"address":[],"length":0,"stats":{"Line":10}},{"line":577,"address":[],"length":0,"stats":{"Line":10}},{"line":578,"address":[],"length":0,"stats":{"Line":15}},{"line":579,"address":[],"length":0,"stats":{"Line":10}},{"line":580,"address":[],"length":0,"stats":{"Line":20}},{"line":581,"address":[],"length":0,"stats":{"Line":5}},{"line":583,"address":[],"length":0,"stats":{"Line":30}},{"line":584,"address":[],"length":0,"stats":{"Line":5}},{"line":588,"address":[],"length":0,"stats":{"Line":1}},{"line":589,"address":[],"length":0,"stats":{"Line":1}},{"line":591,"address":[],"length":0,"stats":{"Line":4}},{"line":592,"address":[],"length":0,"stats":{"Line":1}},{"line":593,"address":[],"length":0,"stats":{"Line":1}},{"line":594,"address":[],"length":0,"stats":{"Line":1}},{"line":595,"address":[],"length":0,"stats":{"Line":1}},{"line":597,"address":[],"length":0,"stats":{"Line":8}},{"line":598,"address":[],"length":0,"stats":{"Line":8}},{"line":599,"address":[],"length":0,"stats":{"Line":16}},{"line":600,"address":[],"length":0,"stats":{"Line":4}},{"line":602,"address":[],"length":0,"stats":{"Line":3}},{"line":603,"address":[],"length":0,"stats":{"Line":3}},{"line":604,"address":[],"length":0,"stats":{"Line":3}},{"line":605,"address":[],"length":0,"stats":{"Line":1}},{"line":608,"address":[],"length":0,"stats":{"Line":1}},{"line":609,"address":[],"length":0,"stats":{"Line":1}},{"line":611,"address":[],"length":0,"stats":{"Line":1}},{"line":612,"address":[],"length":0,"stats":{"Line":3}},{"line":614,"address":[],"length":0,"stats":{"Line":3}},{"line":615,"address":[],"length":0,"stats":{"Line":4}},{"line":616,"address":[],"length":0,"stats":{"Line":1}},{"line":617,"address":[],"length":0,"stats":{"Line":1}},{"line":618,"address":[],"length":0,"stats":{"Line":1}},{"line":619,"address":[],"length":0,"stats":{"Line":1}},{"line":621,"address":[],"length":0,"stats":{"Line":8}},{"line":622,"address":[],"length":0,"stats":{"Line":8}},{"line":623,"address":[],"length":0,"stats":{"Line":16}},{"line":624,"address":[],"length":0,"stats":{"Line":4}},{"line":626,"address":[],"length":0,"stats":{"Line":3}},{"line":629,"address":[],"length":0,"stats":{"Line":2}},{"line":630,"address":[],"length":0,"stats":{"Line":1}},{"line":631,"address":[],"length":0,"stats":{"Line":2}},{"line":633,"address":[],"length":0,"stats":{"Line":2}},{"line":634,"address":[],"length":0,"stats":{"Line":3}},{"line":635,"address":[],"length":0,"stats":{"Line":2}},{"line":636,"address":[],"length":0,"stats":{"Line":4}},{"line":637,"address":[],"length":0,"stats":{"Line":1}},{"line":639,"address":[],"length":0,"stats":{"Line":6}},{"line":641,"address":[],"length":0,"stats":{"Line":1}},{"line":644,"address":[],"length":0,"stats":{"Line":1}},{"line":645,"address":[],"length":0,"stats":{"Line":1}},{"line":648,"address":[],"length":0,"stats":{"Line":2}},{"line":649,"address":[],"length":0,"stats":{"Line":1}},{"line":650,"address":[],"length":0,"stats":{"Line":2}},{"line":652,"address":[],"length":0,"stats":{"Line":2}},{"line":653,"address":[],"length":0,"stats":{"Line":3}},{"line":654,"address":[],"length":0,"stats":{"Line":2}},{"line":655,"address":[],"length":0,"stats":{"Line":4}},{"line":656,"address":[],"length":0,"stats":{"Line":1}},{"line":658,"address":[],"length":0,"stats":{"Line":6}},{"line":660,"address":[],"length":0,"stats":{"Line":1}},{"line":661,"address":[],"length":0,"stats":{"Line":0}},{"line":665,"address":[],"length":0,"stats":{"Line":1}},{"line":668,"address":[],"length":0,"stats":{"Line":1}},{"line":669,"address":[],"length":0,"stats":{"Line":1}},{"line":670,"address":[],"length":0,"stats":{"Line":1}},{"line":671,"address":[],"length":0,"stats":{"Line":1}},{"line":673,"address":[],"length":0,"stats":{"Line":3}},{"line":674,"address":[],"length":0,"stats":{"Line":2}},{"line":675,"address":[],"length":0,"stats":{"Line":2}},{"line":676,"address":[],"length":0,"stats":{"Line":4}},{"line":677,"address":[],"length":0,"stats":{"Line":1}},{"line":679,"address":[],"length":0,"stats":{"Line":3}},{"line":680,"address":[],"length":0,"stats":{"Line":3}},{"line":681,"address":[],"length":0,"stats":{"Line":3}},{"line":683,"address":[],"length":0,"stats":{"Line":3}},{"line":684,"address":[],"length":0,"stats":{"Line":2}},{"line":685,"address":[],"length":0,"stats":{"Line":4}},{"line":686,"address":[],"length":0,"stats":{"Line":1}},{"line":688,"address":[],"length":0,"stats":{"Line":6}},{"line":691,"address":[],"length":0,"stats":{"Line":1}},{"line":692,"address":[],"length":0,"stats":{"Line":0}},{"line":697,"address":[],"length":0,"stats":{"Line":1}},{"line":699,"address":[],"length":0,"stats":{"Line":2}},{"line":700,"address":[],"length":0,"stats":{"Line":1}},{"line":701,"address":[],"length":0,"stats":{"Line":0}},{"line":709,"address":[],"length":0,"stats":{"Line":18}},{"line":710,"address":[],"length":0,"stats":{"Line":18}},{"line":711,"address":[],"length":0,"stats":{"Line":9}},{"line":712,"address":[],"length":0,"stats":{"Line":9}},{"line":713,"address":[],"length":0,"stats":{"Line":36}},{"line":714,"address":[],"length":0,"stats":{"Line":9}},{"line":717,"address":[],"length":0,"stats":{"Line":22}},{"line":718,"address":[],"length":0,"stats":{"Line":44}},{"line":719,"address":[],"length":0,"stats":{"Line":22}},{"line":721,"address":[],"length":0,"stats":{"Line":33}},{"line":722,"address":[],"length":0,"stats":{"Line":4035}},{"line":723,"address":[],"length":0,"stats":{"Line":3018}},{"line":724,"address":[],"length":0,"stats":{"Line":4024}},{"line":726,"address":[],"length":0,"stats":{"Line":2012}},{"line":729,"address":[],"length":0,"stats":{"Line":3029}},{"line":730,"address":[],"length":0,"stats":{"Line":1006}},{"line":731,"address":[],"length":0,"stats":{"Line":0}},{"line":732,"address":[],"length":0,"stats":{"Line":0}},{"line":733,"address":[],"length":0,"stats":{"Line":0}},{"line":738,"address":[],"length":0,"stats":{"Line":3029}},{"line":739,"address":[],"length":0,"stats":{"Line":1006}},{"line":740,"address":[],"length":0,"stats":{"Line":1006}},{"line":743,"address":[],"length":0,"stats":{"Line":2012}},{"line":744,"address":[],"length":0,"stats":{"Line":1006}},{"line":745,"address":[],"length":0,"stats":{"Line":2012}},{"line":747,"address":[],"length":0,"stats":{"Line":2012}},{"line":748,"address":[],"length":0,"stats":{"Line":2012}},{"line":750,"address":[],"length":0,"stats":{"Line":3018}},{"line":751,"address":[],"length":0,"stats":{"Line":2012}},{"line":752,"address":[],"length":0,"stats":{"Line":4024}},{"line":753,"address":[],"length":0,"stats":{"Line":1006}},{"line":754,"address":[],"length":0,"stats":{"Line":3016}},{"line":755,"address":[],"length":0,"stats":{"Line":1005}},{"line":756,"address":[],"length":0,"stats":{"Line":1005}},{"line":757,"address":[],"length":0,"stats":{"Line":1005}},{"line":759,"address":[],"length":0,"stats":{"Line":1007}},{"line":760,"address":[],"length":0,"stats":{"Line":1}},{"line":761,"address":[],"length":0,"stats":{"Line":1}},{"line":762,"address":[],"length":0,"stats":{"Line":0}},{"line":765,"address":[],"length":0,"stats":{"Line":1006}},{"line":766,"address":[],"length":0,"stats":{"Line":1005}},{"line":767,"address":[],"length":0,"stats":{"Line":4020}},{"line":768,"address":[],"length":0,"stats":{"Line":3015}},{"line":770,"address":[],"length":0,"stats":{"Line":2010}},{"line":771,"address":[],"length":0,"stats":{"Line":1005}},{"line":773,"address":[],"length":0,"stats":{"Line":3}},{"line":774,"address":[],"length":0,"stats":{"Line":3}},{"line":775,"address":[],"length":0,"stats":{"Line":3}},{"line":776,"address":[],"length":0,"stats":{"Line":2}},{"line":777,"address":[],"length":0,"stats":{"Line":1}},{"line":781,"address":[],"length":0,"stats":{"Line":1005}},{"line":782,"address":[],"length":0,"stats":{"Line":1005}},{"line":784,"address":[],"length":0,"stats":{"Line":0}},{"line":785,"address":[],"length":0,"stats":{"Line":0}},{"line":786,"address":[],"length":0,"stats":{"Line":0}},{"line":787,"address":[],"length":0,"stats":{"Line":0}},{"line":791,"address":[],"length":0,"stats":{"Line":1005}},{"line":792,"address":[],"length":0,"stats":{"Line":0}},{"line":793,"address":[],"length":0,"stats":{"Line":0}},{"line":794,"address":[],"length":0,"stats":{"Line":0}},{"line":795,"address":[],"length":0,"stats":{"Line":0}},{"line":796,"address":[],"length":0,"stats":{"Line":0}},{"line":800,"address":[],"length":0,"stats":{"Line":3015}},{"line":801,"address":[],"length":0,"stats":{"Line":2010}},{"line":802,"address":[],"length":0,"stats":{"Line":2010}},{"line":803,"address":[],"length":0,"stats":{"Line":4020}},{"line":804,"address":[],"length":0,"stats":{"Line":1005}},{"line":806,"address":[],"length":0,"stats":{"Line":1}},{"line":807,"address":[],"length":0,"stats":{"Line":3}},{"line":808,"address":[],"length":0,"stats":{"Line":3}},{"line":809,"address":[],"length":0,"stats":{"Line":1}},{"line":812,"address":[],"length":0,"stats":{"Line":1004}},{"line":813,"address":[],"length":0,"stats":{"Line":3012}},{"line":814,"address":[],"length":0,"stats":{"Line":3012}},{"line":815,"address":[],"length":0,"stats":{"Line":1004}},{"line":816,"address":[],"length":0,"stats":{"Line":4016}},{"line":817,"address":[],"length":0,"stats":{"Line":2005}},{"line":818,"address":[],"length":0,"stats":{"Line":3003}},{"line":819,"address":[],"length":0,"stats":{"Line":3003}},{"line":820,"address":[],"length":0,"stats":{"Line":3003}},{"line":821,"address":[],"length":0,"stats":{"Line":3003}},{"line":822,"address":[],"length":0,"stats":{"Line":1001}},{"line":826,"address":[],"length":0,"stats":{"Line":0}},{"line":827,"address":[],"length":0,"stats":{"Line":0}},{"line":828,"address":[],"length":0,"stats":{"Line":0}},{"line":829,"address":[],"length":0,"stats":{"Line":0}},{"line":831,"address":[],"length":0,"stats":{"Line":0}},{"line":836,"address":[],"length":0,"stats":{"Line":2}},{"line":837,"address":[],"length":0,"stats":{"Line":2}},{"line":838,"address":[],"length":0,"stats":{"Line":1}},{"line":839,"address":[],"length":0,"stats":{"Line":1}},{"line":840,"address":[],"length":0,"stats":{"Line":1}},{"line":841,"address":[],"length":0,"stats":{"Line":1}},{"line":843,"address":[],"length":0,"stats":{"Line":2}},{"line":844,"address":[],"length":0,"stats":{"Line":0}},{"line":847,"address":[],"length":0,"stats":{"Line":5}},{"line":848,"address":[],"length":0,"stats":{"Line":4}},{"line":849,"address":[],"length":0,"stats":{"Line":8}},{"line":850,"address":[],"length":0,"stats":{"Line":2}},{"line":852,"address":[],"length":0,"stats":{"Line":3}},{"line":853,"address":[],"length":0,"stats":{"Line":3}},{"line":854,"address":[],"length":0,"stats":{"Line":3}},{"line":855,"address":[],"length":0,"stats":{"Line":1}},{"line":856,"address":[],"length":0,"stats":{"Line":1}},{"line":858,"address":[],"length":0,"stats":{"Line":1}},{"line":859,"address":[],"length":0,"stats":{"Line":1}},{"line":863,"address":[],"length":0,"stats":{"Line":1}},{"line":864,"address":[],"length":0,"stats":{"Line":0}},{"line":865,"address":[],"length":0,"stats":{"Line":0}},{"line":866,"address":[],"length":0,"stats":{"Line":0}},{"line":870,"address":[],"length":0,"stats":{"Line":0}},{"line":871,"address":[],"length":0,"stats":{"Line":0}},{"line":872,"address":[],"length":0,"stats":{"Line":0}},{"line":873,"address":[],"length":0,"stats":{"Line":0}},{"line":875,"address":[],"length":0,"stats":{"Line":0}},{"line":884,"address":[],"length":0,"stats":{"Line":11}},{"line":887,"address":[],"length":0,"stats":{"Line":4}},{"line":892,"address":[],"length":0,"stats":{"Line":4}},{"line":893,"address":[],"length":0,"stats":{"Line":4}},{"line":895,"address":[],"length":0,"stats":{"Line":16}},{"line":896,"address":[],"length":0,"stats":{"Line":10}},{"line":899,"address":[],"length":0,"stats":{"Line":16}},{"line":905,"address":[],"length":0,"stats":{"Line":48}},{"line":906,"address":[],"length":0,"stats":{"Line":48}},{"line":908,"address":[],"length":0,"stats":{"Line":32}},{"line":909,"address":[],"length":0,"stats":{"Line":80}},{"line":910,"address":[],"length":0,"stats":{"Line":80}},{"line":912,"address":[],"length":0,"stats":{"Line":32}},{"line":913,"address":[],"length":0,"stats":{"Line":0}},{"line":914,"address":[],"length":0,"stats":{"Line":0}},{"line":915,"address":[],"length":0,"stats":{"Line":0}},{"line":916,"address":[],"length":0,"stats":{"Line":0}},{"line":917,"address":[],"length":0,"stats":{"Line":0}},{"line":919,"address":[],"length":0,"stats":{"Line":0}},{"line":920,"address":[],"length":0,"stats":{"Line":0}},{"line":921,"address":[],"length":0,"stats":{"Line":0}},{"line":922,"address":[],"length":0,"stats":{"Line":0}},{"line":923,"address":[],"length":0,"stats":{"Line":0}},{"line":924,"address":[],"length":0,"stats":{"Line":0}},{"line":925,"address":[],"length":0,"stats":{"Line":0}},{"line":926,"address":[],"length":0,"stats":{"Line":0}},{"line":927,"address":[],"length":0,"stats":{"Line":0}},{"line":928,"address":[],"length":0,"stats":{"Line":0}},{"line":930,"address":[],"length":0,"stats":{"Line":0}},{"line":931,"address":[],"length":0,"stats":{"Line":0}},{"line":933,"address":[],"length":0,"stats":{"Line":0}},{"line":935,"address":[],"length":0,"stats":{"Line":0}},{"line":936,"address":[],"length":0,"stats":{"Line":0}},{"line":946,"address":[],"length":0,"stats":{"Line":16}},{"line":947,"address":[],"length":0,"stats":{"Line":64}},{"line":948,"address":[],"length":0,"stats":{"Line":16}},{"line":949,"address":[],"length":0,"stats":{"Line":3}},{"line":950,"address":[],"length":0,"stats":{"Line":3}},{"line":951,"address":[],"length":0,"stats":{"Line":6}},{"line":952,"address":[],"length":0,"stats":{"Line":3}},{"line":953,"address":[],"length":0,"stats":{"Line":9}},{"line":954,"address":[],"length":0,"stats":{"Line":9}},{"line":955,"address":[],"length":0,"stats":{"Line":9}},{"line":956,"address":[],"length":0,"stats":{"Line":3}},{"line":957,"address":[],"length":0,"stats":{"Line":3}},{"line":959,"address":[],"length":0,"stats":{"Line":3}},{"line":961,"address":[],"length":0,"stats":{"Line":0}},{"line":962,"address":[],"length":0,"stats":{"Line":0}},{"line":971,"address":[],"length":0,"stats":{"Line":39}},{"line":972,"address":[],"length":0,"stats":{"Line":26}},{"line":974,"address":[],"length":0,"stats":{"Line":27}},{"line":975,"address":[],"length":0,"stats":{"Line":1}},{"line":977,"address":[],"length":0,"stats":{"Line":0}},{"line":980,"address":[],"length":0,"stats":{"Line":39}},{"line":982,"address":[],"length":0,"stats":{"Line":26}},{"line":983,"address":[],"length":0,"stats":{"Line":39}},{"line":984,"address":[],"length":0,"stats":{"Line":39}},{"line":985,"address":[],"length":0,"stats":{"Line":26}},{"line":986,"address":[],"length":0,"stats":{"Line":13}},{"line":991,"address":[],"length":0,"stats":{"Line":39}},{"line":993,"address":[],"length":0,"stats":{"Line":13}},{"line":996,"address":[],"length":0,"stats":{"Line":39}},{"line":997,"address":[],"length":0,"stats":{"Line":13}},{"line":998,"address":[],"length":0,"stats":{"Line":26}},{"line":999,"address":[],"length":0,"stats":{"Line":169}},{"line":1000,"address":[],"length":0,"stats":{"Line":117}},{"line":1002,"address":[],"length":0,"stats":{"Line":13}},{"line":1005,"address":[],"length":0,"stats":{"Line":0}},{"line":1006,"address":[],"length":0,"stats":{"Line":0}},{"line":1012,"address":[],"length":0,"stats":{"Line":39}},{"line":1013,"address":[],"length":0,"stats":{"Line":65}},{"line":1017,"address":[],"length":0,"stats":{"Line":39}},{"line":1018,"address":[],"length":0,"stats":{"Line":13}},{"line":1021,"address":[],"length":0,"stats":{"Line":26}},{"line":1022,"address":[],"length":0,"stats":{"Line":39}},{"line":1023,"address":[],"length":0,"stats":{"Line":13}},{"line":1025,"address":[],"length":0,"stats":{"Line":13}},{"line":1027,"address":[],"length":0,"stats":{"Line":13}},{"line":1028,"address":[],"length":0,"stats":{"Line":13}},{"line":1029,"address":[],"length":0,"stats":{"Line":52}},{"line":1030,"address":[],"length":0,"stats":{"Line":13}},{"line":1031,"address":[],"length":0,"stats":{"Line":13}},{"line":1032,"address":[],"length":0,"stats":{"Line":65}},{"line":1033,"address":[],"length":0,"stats":{"Line":13}},{"line":1034,"address":[],"length":0,"stats":{"Line":13}},{"line":1035,"address":[],"length":0,"stats":{"Line":52}},{"line":1036,"address":[],"length":0,"stats":{"Line":13}},{"line":1037,"address":[],"length":0,"stats":{"Line":13}},{"line":1039,"address":[],"length":0,"stats":{"Line":13}},{"line":1042,"address":[],"length":0,"stats":{"Line":2}},{"line":1043,"address":[],"length":0,"stats":{"Line":8}},{"line":1046,"address":[],"length":0,"stats":{"Line":1019}},{"line":1047,"address":[],"length":0,"stats":{"Line":2038}},{"line":1052,"address":[],"length":0,"stats":{"Line":4076}},{"line":1055,"address":[],"length":0,"stats":{"Line":2038}},{"line":1056,"address":[],"length":0,"stats":{"Line":5095}},{"line":1057,"address":[],"length":0,"stats":{"Line":5095}},{"line":1059,"address":[],"length":0,"stats":{"Line":4076}},{"line":1060,"address":[],"length":0,"stats":{"Line":1019}},{"line":1061,"address":[],"length":0,"stats":{"Line":0}},{"line":1062,"address":[],"length":0,"stats":{"Line":0}},{"line":1064,"address":[],"length":0,"stats":{"Line":0}},{"line":1065,"address":[],"length":0,"stats":{"Line":0}},{"line":1068,"address":[],"length":0,"stats":{"Line":0}},{"line":1069,"address":[],"length":0,"stats":{"Line":0}},{"line":1070,"address":[],"length":0,"stats":{"Line":0}},{"line":1074,"address":[],"length":0,"stats":{"Line":1019}},{"line":1077,"address":[],"length":0,"stats":{"Line":14}},{"line":1078,"address":[],"length":0,"stats":{"Line":28}},{"line":1079,"address":[],"length":0,"stats":{"Line":21}},{"line":1080,"address":[],"length":0,"stats":{"Line":14}},{"line":1082,"address":[],"length":0,"stats":{"Line":21}},{"line":1083,"address":[],"length":0,"stats":{"Line":7}},{"line":1084,"address":[],"length":0,"stats":{"Line":7}},{"line":1085,"address":[],"length":0,"stats":{"Line":11}},{"line":1087,"address":[],"length":0,"stats":{"Line":21}},{"line":1088,"address":[],"length":0,"stats":{"Line":7}},{"line":1089,"address":[],"length":0,"stats":{"Line":1}},{"line":1090,"address":[],"length":0,"stats":{"Line":0}},{"line":1095,"address":[],"length":0,"stats":{"Line":2}},{"line":1096,"address":[],"length":0,"stats":{"Line":2}},{"line":1097,"address":[],"length":0,"stats":{"Line":1}},{"line":1098,"address":[],"length":0,"stats":{"Line":1}},{"line":1099,"address":[],"length":0,"stats":{"Line":4}},{"line":1102,"address":[],"length":0,"stats":{"Line":7}},{"line":1105,"address":[],"length":0,"stats":{"Line":1}},{"line":1110,"address":[],"length":0,"stats":{"Line":4}},{"line":1113,"address":[],"length":0,"stats":{"Line":2}},{"line":1114,"address":[],"length":0,"stats":{"Line":2}},{"line":1115,"address":[],"length":0,"stats":{"Line":2}},{"line":1116,"address":[],"length":0,"stats":{"Line":2}},{"line":1117,"address":[],"length":0,"stats":{"Line":2}},{"line":1118,"address":[],"length":0,"stats":{"Line":1}},{"line":1119,"address":[],"length":0,"stats":{"Line":1}},{"line":1122,"address":[],"length":0,"stats":{"Line":9}},{"line":1123,"address":[],"length":0,"stats":{"Line":24}},{"line":1124,"address":[],"length":0,"stats":{"Line":10}},{"line":1125,"address":[],"length":0,"stats":{"Line":6}},{"line":1126,"address":[],"length":0,"stats":{"Line":9}},{"line":1128,"address":[],"length":0,"stats":{"Line":9}},{"line":1129,"address":[],"length":0,"stats":{"Line":5}},{"line":1130,"address":[],"length":0,"stats":{"Line":3}},{"line":1132,"address":[],"length":0,"stats":{"Line":1}},{"line":1133,"address":[],"length":0,"stats":{"Line":2}},{"line":1135,"address":[],"length":0,"stats":{"Line":1}},{"line":1136,"address":[],"length":0,"stats":{"Line":2}},{"line":1142,"address":[],"length":0,"stats":{"Line":7}},{"line":1143,"address":[],"length":0,"stats":{"Line":6}},{"line":1144,"address":[],"length":0,"stats":{"Line":8}},{"line":1146,"address":[],"length":0,"stats":{"Line":3}},{"line":1150,"address":[],"length":0,"stats":{"Line":1}},{"line":1154,"address":[],"length":0,"stats":{"Line":3}},{"line":1161,"address":[],"length":0,"stats":{"Line":3}},{"line":1162,"address":[],"length":0,"stats":{"Line":12}},{"line":1164,"address":[],"length":0,"stats":{"Line":7}},{"line":1165,"address":[],"length":0,"stats":{"Line":14}},{"line":1166,"address":[],"length":0,"stats":{"Line":20}},{"line":1167,"address":[],"length":0,"stats":{"Line":0}},{"line":1168,"address":[],"length":0,"stats":{"Line":0}},{"line":1171,"address":[],"length":0,"stats":{"Line":14}},{"line":1172,"address":[],"length":0,"stats":{"Line":2}},{"line":1173,"address":[],"length":0,"stats":{"Line":2}},{"line":1174,"address":[],"length":0,"stats":{"Line":2}}],"covered":452,"coverable":537},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","error.rs"],"content":"use thiserror::Error;\n\n#[derive(Debug, Error)]\npub enum SyncError {\n    #[error(\"Governance violation: {0}\")]\n    GovernanceBlock(String),\n    #[error(\"Knowledge repository error: {0}\")]\n    Repository(#[from] knowledge::repository::RepositoryError),\n    #[error(\"Memory manager error: {0}\")]\n    Memory(#[from] memory::error::MemoryError),\n    #[error(\"Serialization error: {0}\")]\n    Serialization(#[from] serde_json::Error),\n    #[error(\"IO error: {0}\")]\n    Io(#[from] std::io::Error),\n    #[error(\"Conflict detection failed: {0}\")]\n    ConflictDetection(String),\n    #[error(\"State persistence failed: {0}\")]\n    Persistence(String),\n    #[error(\"Internal error: {0}\")]\n    Internal(String),\n    #[error(\"Other error: {0}\")]\n    Other(String)\n}\n\nimpl From\u003cBox\u003cdyn std::error::Error + Send + Sync\u003e\u003e for SyncError {\n    fn from(err: Box\u003cdyn std::error::Error + Send + Sync\u003e) -\u003e Self {\n        SyncError::Other(err.to_string())\n    }\n}\n\npub type Result\u003cT\u003e = std::result::Result\u003cT, SyncError\u003e;\n","traces":[{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":2},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","lib.rs"],"content":"//! # Sync Bridge\n//!\n//! Pointer-based synchronization between memory and knowledge.\n\npub mod bridge;\npub mod error;\npub mod pointer;\npub mod state;\npub mod state_persister;\n\n#[cfg(test)]\nmod proptests;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","pointer.rs"],"content":"use mk_core::types::{KnowledgeLayer, KnowledgeType, MemoryLayer};\nuse serde::{Deserialize, Serialize};\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct KnowledgePointer {\n    pub source_type: KnowledgeType,\n    pub source_id: String,\n    pub content_hash: String,\n    pub synced_at: i64,\n    pub source_layer: KnowledgeLayer,\n    pub is_orphaned: bool\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct KnowledgePointerMetadata {\n    #[serde(rename = \"type\")]\n    pub kind: String,\n    pub knowledge_pointer: KnowledgePointer,\n    pub tags: Vec\u003cString\u003e\n}\n\nimpl Default for KnowledgePointerMetadata {\n    fn default() -\u003e Self {\n        Self {\n            kind: \"knowledge_pointer\".to_string(),\n            knowledge_pointer: KnowledgePointer {\n                source_type: KnowledgeType::Adr,\n                source_id: String::new(),\n                content_hash: String::new(),\n                synced_at: 0,\n                source_layer: KnowledgeLayer::Company,\n                is_orphaned: false\n            },\n            tags: Vec::new()\n        }\n    }\n}\n\npub fn map_layer(knowledge_layer: KnowledgeLayer) -\u003e MemoryLayer {\n    match knowledge_layer {\n        KnowledgeLayer::Company =\u003e MemoryLayer::Company,\n        KnowledgeLayer::Org =\u003e MemoryLayer::Org,\n        KnowledgeLayer::Team =\u003e MemoryLayer::Team,\n        KnowledgeLayer::Project =\u003e MemoryLayer::Project\n    }\n}\n","traces":[{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":28,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":1020}},{"line":42,"address":[],"length":0,"stats":{"Line":1020}},{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":1}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":1019}}],"covered":4,"coverable":10},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","proptests.rs"],"content":"#[cfg(test)]\nmod proptests {\n    use proptest::prelude::*;\n\n    proptest! {\n        #[test]\n        fn test_hash_consistency(content in \"\\\\PC*\") {\n            let hash1 = utils::compute_content_hash(\u0026content);\n            let hash2 = utils::compute_content_hash(\u0026content);\n            prop_assert_eq!(hash1, hash2);\n        }\n\n        #[test]\n        fn test_hash_different_for_different_content(c1 in \"\\\\PC*\", c2 in \"\\\\PC*\") {\n            if c1 != c2 {\n                let hash1 = utils::compute_content_hash(\u0026c1);\n                let hash2 = utils::compute_content_hash(\u0026c2);\n                prop_assert_ne!(hash1, hash2);\n            }\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","state.rs"],"content":"use serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct SyncState {\n    pub version: String,\n    pub last_sync_at: Option\u003ci64\u003e,\n    pub last_knowledge_commit: Option\u003cString\u003e,\n    pub knowledge_hashes: HashMap\u003cString, String\u003e,\n    pub pointer_mapping: HashMap\u003cString, String\u003e,\n    pub knowledge_layers: HashMap\u003cString, mk_core::types::KnowledgeLayer\u003e,\n    pub failed_items: Vec\u003cSyncFailure\u003e,\n    pub federation_conflicts: Vec\u003cFederationConflict\u003e,\n    pub upstream_commits: HashMap\u003cString, String\u003e,\n    pub stats: SyncStats\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct FederationConflict {\n    pub upstream_id: String,\n    pub reason: String,\n    pub detected_at: i64\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct SyncFailure {\n    pub knowledge_id: String,\n    pub error: String,\n    pub failed_at: i64,\n    pub retry_count: u32\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\npub enum SyncConflict {\n    HashMismatch {\n        knowledge_id: String,\n        memory_id: String,\n        expected_hash: String,\n        actual_hash: String\n    },\n    OrphanedPointer {\n        memory_id: String,\n        knowledge_id: String\n    },\n    MissingPointer {\n        knowledge_id: String,\n        expected_memory_id: String\n    },\n    DuplicatePointer {\n        knowledge_id: String,\n        memory_ids: Vec\u003cString\u003e\n    },\n    StatusChange {\n        knowledge_id: String,\n        memory_id: String,\n        new_status: mk_core::types::KnowledgeStatus\n    },\n    LayerMismatch {\n        knowledge_id: String,\n        memory_id: String,\n        expected_layer: mk_core::types::KnowledgeLayer,\n        actual_layer: mk_core::types::KnowledgeLayer\n    },\n    DetectionError {\n        target_id: String,\n        error: String\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\npub enum SyncTrigger {\n    Staleness {\n        last_sync_at: i64,\n        threshold_mins: u32\n    },\n    CommitMismatch {\n        last_commit: String,\n        head_commit: String\n    },\n    Manual\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, Default, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct SyncStats {\n    pub total_syncs: u64,\n    pub total_items_synced: u64,\n    pub total_conflicts: u64,\n    pub total_governance_blocks: u64,\n    pub avg_sync_duration_ms: u64,\n    pub drift_score: f32,\n    pub policy_violations: u64\n}\n\nimpl Default for SyncState {\n    fn default() -\u003e Self {\n        Self {\n            version: \"1.0\".to_string(),\n            last_sync_at: None,\n            last_knowledge_commit: None,\n            knowledge_hashes: HashMap::new(),\n            pointer_mapping: HashMap::new(),\n            knowledge_layers: HashMap::new(),\n            failed_items: Vec::new(),\n            federation_conflicts: Vec::new(),\n            upstream_commits: HashMap::new(),\n            stats: SyncStats::default()\n        }\n    }\n}\n","traces":[{"line":99,"address":[],"length":0,"stats":{"Line":47}},{"line":101,"address":[],"length":0,"stats":{"Line":141}},{"line":104,"address":[],"length":0,"stats":{"Line":94}},{"line":105,"address":[],"length":0,"stats":{"Line":94}},{"line":106,"address":[],"length":0,"stats":{"Line":94}},{"line":107,"address":[],"length":0,"stats":{"Line":94}},{"line":108,"address":[],"length":0,"stats":{"Line":94}},{"line":109,"address":[],"length":0,"stats":{"Line":47}},{"line":110,"address":[],"length":0,"stats":{"Line":47}}],"covered":9,"coverable":9},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","state_persister.rs"],"content":"use crate::state::SyncState;\nuse async_trait::async_trait;\nuse mk_core::traits::StorageBackend;\nuse std::path::PathBuf;\nuse std::sync::Arc;\n\n#[async_trait]\npub trait SyncStatePersister: Send + Sync {\n    async fn load(\n        \u0026self,\n        tenant_id: \u0026mk_core::types::TenantId,\n    ) -\u003e Result\u003cSyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e;\n    async fn save(\n        \u0026self,\n        tenant_id: \u0026mk_core::types::TenantId,\n        state: \u0026SyncState,\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e;\n}\n\npub struct FilePersister {\n    base_path: PathBuf,\n}\n\nimpl FilePersister {\n    pub fn new(base_path: PathBuf) -\u003e Self {\n        Self { base_path }\n    }\n\n    fn get_path(\u0026self, tenant_id: \u0026mk_core::types::TenantId) -\u003e PathBuf {\n        self.base_path\n            .join(format!(\"sync_state_{}.json\", tenant_id.as_str()))\n    }\n}\n\n#[async_trait]\nimpl SyncStatePersister for FilePersister {\n    async fn load(\n        \u0026self,\n        tenant_id: \u0026mk_core::types::TenantId,\n    ) -\u003e Result\u003cSyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let path = self.get_path(tenant_id);\n        match tokio::fs::read(\u0026path).await {\n            Ok(data) =\u003e Ok(serde_json::from_slice(\u0026data)?),\n            Err(e) if e.kind() == std::io::ErrorKind::NotFound =\u003e Ok(SyncState::default()),\n            Err(e) =\u003e Err(e.into()),\n        }\n    }\n\n    async fn save(\n        \u0026self,\n        tenant_id: \u0026mk_core::types::TenantId,\n        state: \u0026SyncState,\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let path = self.get_path(tenant_id);\n        let data = serde_json::to_vec_pretty(state)?;\n        if let Some(parent) = path.parent() {\n            tokio::fs::create_dir_all(parent).await?;\n        }\n        tokio::fs::write(\u0026path, data).await?;\n        Ok(())\n    }\n}\n\npub struct DatabasePersister\u003cS: StorageBackend\u003e {\n    storage: Arc\u003cS\u003e,\n    key_prefix: String,\n}\n\nimpl\u003cS: StorageBackend\u003e DatabasePersister\u003cS\u003e {\n    pub fn new(storage: Arc\u003cS\u003e, key_prefix: String) -\u003e Self {\n        Self {\n            storage,\n            key_prefix,\n        }\n    }\n\n    fn get_key(\u0026self, tenant_id: \u0026mk_core::types::TenantId) -\u003e String {\n        format!(\"{}:{}\", self.key_prefix, tenant_id.as_str())\n    }\n}\n\n#[async_trait]\nimpl\u003cS: StorageBackend\u003e SyncStatePersister for DatabasePersister\u003cS\u003e\nwhere\n    S::Error: std::error::Error + Send + Sync + 'static,\n{\n    async fn load(\n        \u0026self,\n        tenant_id: \u0026mk_core::types::TenantId,\n    ) -\u003e Result\u003cSyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let key = self.get_key(tenant_id);\n        let ctx = mk_core::types::TenantContext::new(\n            tenant_id.clone(),\n            mk_core::types::UserId::default(),\n        );\n        match self.storage.retrieve(ctx, \u0026key).await? {\n            Some(data) =\u003e Ok(serde_json::from_slice(\u0026data)?),\n            None =\u003e Ok(SyncState::default()),\n        }\n    }\n\n    async fn save(\n        \u0026self,\n        tenant_id: \u0026mk_core::types::TenantId,\n        state: \u0026SyncState,\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let key = self.get_key(tenant_id);\n        let data = serde_json::to_vec(state)?;\n        let ctx = mk_core::types::TenantContext::new(\n            tenant_id.clone(),\n            mk_core::types::UserId::default(),\n        );\n        self.storage.store(ctx, \u0026key, \u0026data).await?;\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use async_trait::async_trait;\n    use std::collections::HashMap;\n    use std::sync::Arc;\n    use tokio::sync::RwLock;\n\n    struct MockStorage {\n        data: Arc\u003cRwLock\u003cHashMap\u003cString, Vec\u003cu8\u003e\u003e\u003e\u003e,\n    }\n\n    impl MockStorage {\n        fn new() -\u003e Self {\n            Self {\n                data: Arc::new(RwLock::new(HashMap::new())),\n            }\n        }\n    }\n\n    #[async_trait]\n    impl StorageBackend for MockStorage {\n        type Error = std::io::Error;\n\n        async fn store(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            key: \u0026str,\n            value: \u0026[u8],\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            self.data\n                .write()\n                .await\n                .insert(key.to_string(), value.to_vec());\n            Ok(())\n        }\n\n        async fn retrieve(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            key: \u0026str,\n        ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e {\n            Ok(self.data.read().await.get(key).cloned())\n        }\n\n        async fn delete(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            key: \u0026str,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            self.data.write().await.remove(key);\n            Ok(())\n        }\n\n        async fn exists(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            key: \u0026str,\n        ) -\u003e Result\u003cbool, Self::Error\u003e {\n            Ok(self.data.read().await.contains_key(key))\n        }\n\n        async fn get_ancestors(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _unit_id: \u0026str,\n        ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n\n        async fn get_descendants(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _unit_id: \u0026str,\n        ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n\n        async fn get_unit_policies(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _unit_id: \u0026str,\n        ) -\u003e Result\u003cVec\u003cmk_core::types::Policy\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n\n        async fn create_unit(\n            \u0026self,\n            _unit: \u0026mk_core::types::OrganizationalUnit,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n\n        async fn add_unit_policy(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n            _unit_id: \u0026str,\n            _policy: \u0026mk_core::types::Policy,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n\n        async fn assign_role(\n            \u0026self,\n            _user_id: \u0026mk_core::types::UserId,\n            _tenant_id: \u0026mk_core::types::TenantId,\n            _unit_id: \u0026str,\n            _role: mk_core::types::Role,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n\n        async fn remove_role(\n            \u0026self,\n            _user_id: \u0026mk_core::types::UserId,\n            _tenant_id: \u0026mk_core::types::TenantId,\n            _unit_id: \u0026str,\n            _role: mk_core::types::Role,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n\n        async fn store_drift_result(\n            \u0026self,\n            _result: mk_core::types::DriftResult,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n\n        async fn get_latest_drift_result(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _project_id: \u0026str,\n        ) -\u003e Result\u003cOption\u003cmk_core::types::DriftResult\u003e, Self::Error\u003e {\n            Ok(None)\n        }\n\n        async fn list_all_units(\n            \u0026self,\n        ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n\n        async fn record_job_status(\n            \u0026self,\n            _job_name: \u0026str,\n            _tenant_id: \u0026str,\n            _status: \u0026str,\n            _message: Option\u003c\u0026str\u003e,\n            _started_at: i64,\n            _finished_at: Option\u003ci64\u003e,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n\n        async fn get_governance_events(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _since_timestamp: i64,\n            _limit: usize,\n        ) -\u003e Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n    }\n\n    #[tokio::test]\n    async fn test_file_persister_save_and_load() {\n        let temp_dir = tempfile::tempdir().unwrap();\n        let base_path = temp_dir.path().to_path_buf();\n        let persister = FilePersister::new(base_path);\n        let tenant_id = mk_core::types::TenantId::default();\n\n        let mut state = SyncState::default();\n        state.stats.total_syncs = 10;\n\n        persister.save(\u0026tenant_id, \u0026state).await.unwrap();\n\n        let loaded_state = persister.load(\u0026tenant_id).await.unwrap();\n        assert_eq!(loaded_state.stats.total_syncs, 10);\n    }\n\n    #[tokio::test]\n    async fn test_file_persister_load_default() {\n        let temp_dir = tempfile::tempdir().unwrap();\n        let base_path = temp_dir.path().to_path_buf();\n        let persister = FilePersister::new(base_path);\n        let tenant_id = mk_core::types::TenantId::default();\n\n        let state = persister.load(\u0026tenant_id).await.unwrap();\n        assert_eq!(state, SyncState::default());\n    }\n\n    #[tokio::test]\n    async fn test_database_persister_new() {\n        let storage = Arc::new(MockStorage::new());\n        let persister = DatabasePersister::new(storage, \"test_key\".to_string());\n        assert_eq!(persister.key_prefix, \"test_key\");\n    }\n\n    #[tokio::test]\n    async fn test_database_persister_load_default() {\n        let storage = Arc::new(MockStorage::new());\n        let persister = DatabasePersister::new(storage, \"test_key\".to_string());\n        let tenant_id = mk_core::types::TenantId::default();\n\n        let state = persister.load(\u0026tenant_id).await.unwrap();\n        assert_eq!(state, SyncState::default());\n    }\n\n    #[tokio::test]\n    async fn test_database_persister_save_and_load() {\n        let storage = Arc::new(MockStorage::new());\n        let persister = DatabasePersister::new(storage, \"test_key\".to_string());\n        let tenant_id = mk_core::types::TenantId::default();\n\n        let mut state = SyncState::default();\n        state.stats.total_syncs = 5;\n        state.stats.total_items_synced = 42;\n\n        persister.save(\u0026tenant_id, \u0026state).await.unwrap();\n\n        let loaded_state = persister.load(\u0026tenant_id).await.unwrap();\n        assert_eq!(loaded_state.stats.total_syncs, 5);\n        assert_eq!(loaded_state.stats.total_items_synced, 42);\n    }\n\n    #[tokio::test]\n    async fn test_database_persister_save_overwrites() {\n        let storage = Arc::new(MockStorage::new());\n        let persister = DatabasePersister::new(storage, \"test_key\".to_string());\n        let tenant_id = mk_core::types::TenantId::default();\n\n        let mut state1 = SyncState::default();\n        state1.stats.total_syncs = 1;\n\n        let mut state2 = SyncState::default();\n        state2.stats.total_syncs = 2;\n\n        persister.save(\u0026tenant_id, \u0026state1).await.unwrap();\n        persister.save(\u0026tenant_id, \u0026state2).await.unwrap();\n\n        let loaded_state = persister.load(\u0026tenant_id).await.unwrap();\n        assert_eq!(loaded_state.stats.total_syncs, 2);\n    }\n\n    #[tokio::test]\n    async fn test_database_persister_different_keys() {\n        let storage = Arc::new(MockStorage::new());\n        let persister1 = DatabasePersister::new(storage.clone(), \"key1\".to_string());\n        let persister2 = DatabasePersister::new(storage, \"key2\".to_string());\n        let tenant_id = mk_core::types::TenantId::default();\n\n        let mut state1 = SyncState::default();\n        state1.stats.total_syncs = 100;\n\n        let mut state2 = SyncState::default();\n        state2.stats.total_syncs = 200;\n\n        persister1.save(\u0026tenant_id, \u0026state1).await.unwrap();\n        persister2.save(\u0026tenant_id, \u0026state2).await.unwrap();\n\n        let loaded1 = persister1.load(\u0026tenant_id).await.unwrap();\n        let loaded2 = persister2.load(\u0026tenant_id).await.unwrap();\n\n        assert_eq!(loaded1.stats.total_syncs, 100);\n        assert_eq!(loaded2.stats.total_syncs, 200);\n    }\n\n    #[tokio::test]\n    async fn test_database_persister_storage_error() {\n        struct ErrorStorage;\n\n        #[async_trait]\n        impl StorageBackend for ErrorStorage {\n            type Error = std::io::Error;\n\n            async fn store(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _key: \u0026str,\n                _value: \u0026[u8],\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn retrieve(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _key: \u0026str,\n            ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn delete(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _key: \u0026str,\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn exists(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _key: \u0026str,\n            ) -\u003e Result\u003cbool, Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn get_ancestors(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _unit_id: \u0026str,\n            ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn get_descendants(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _unit_id: \u0026str,\n            ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn get_unit_policies(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _unit_id: \u0026str,\n            ) -\u003e Result\u003cVec\u003cmk_core::types::Policy\u003e, Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn create_unit(\n                \u0026self,\n                _unit: \u0026mk_core::types::OrganizationalUnit,\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn add_unit_policy(\n                \u0026self,\n                _ctx: \u0026mk_core::types::TenantContext,\n                _unit_id: \u0026str,\n                _policy: \u0026mk_core::types::Policy,\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn assign_role(\n                \u0026self,\n                _user_id: \u0026mk_core::types::UserId,\n                _tenant_id: \u0026mk_core::types::TenantId,\n                _unit_id: \u0026str,\n                _role: mk_core::types::Role,\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn remove_role(\n                \u0026self,\n                _user_id: \u0026mk_core::types::UserId,\n                _tenant_id: \u0026mk_core::types::TenantId,\n                _unit_id: \u0026str,\n                _role: mk_core::types::Role,\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn store_drift_result(\n                \u0026self,\n                _result: mk_core::types::DriftResult,\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn get_latest_drift_result(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _project_id: \u0026str,\n            ) -\u003e Result\u003cOption\u003cmk_core::types::DriftResult\u003e, Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn list_all_units(\n                \u0026self,\n            ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn record_job_status(\n                \u0026self,\n                _job_name: \u0026str,\n                _tenant_id: \u0026str,\n                _status: \u0026str,\n                _message: Option\u003c\u0026str\u003e,\n                _started_at: i64,\n                _finished_at: Option\u003ci64\u003e,\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn get_governance_events(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _since_timestamp: i64,\n                _limit: usize,\n            ) -\u003e Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e, Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n        }\n\n        let storage = Arc::new(ErrorStorage);\n        let persister = DatabasePersister::new(storage, \"test_key\".to_string());\n        let tenant_id = mk_core::types::TenantId::default();\n\n        let state = SyncState::default();\n        let save_result = persister.save(\u0026tenant_id, \u0026state).await;\n        assert!(save_result.is_err());\n\n        let load_result = persister.load(\u0026tenant_id).await;\n        assert!(load_result.is_err());\n    }\n}\n","traces":[{"line":25,"address":[],"length":0,"stats":{"Line":2}},{"line":29,"address":[],"length":0,"stats":{"Line":3}},{"line":30,"address":[],"length":0,"stats":{"Line":6}},{"line":31,"address":[],"length":0,"stats":{"Line":12}},{"line":70,"address":[],"length":0,"stats":{"Line":8}},{"line":77,"address":[],"length":0,"stats":{"Line":12}},{"line":78,"address":[],"length":0,"stats":{"Line":48}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}}],"covered":7,"coverable":19},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","tests","federation_tests.rs"],"content":"use knowledge::federation::{\n    FederationConfig, FederationProvider, KnowledgeManifest, UpstreamConfig,\n};\nuse knowledge::governance::GovernanceEngine;\nuse knowledge::repository::RepositoryError;\nuse memory::manager::MemoryManager;\nuse mk_core::traits::KnowledgeRepository;\nuse mk_core::types::{\n    ConstraintOperator, ConstraintSeverity, ConstraintTarget, KnowledgeEntry, KnowledgeLayer,\n    KnowledgeStatus, KnowledgeType, Policy, PolicyMode, PolicyRule, RuleMergeStrategy, RuleType,\n    TenantContext, TenantId,\n};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse sync::bridge::SyncManager;\nuse sync::state::SyncState;\nuse sync::state_persister::SyncStatePersister;\n\nstruct MockFedProvider {\n    config: FederationConfig,\n    should_fail: bool,\n}\n\n#[async_trait::async_trait]\nimpl FederationProvider for MockFedProvider {\n    fn config(\u0026self) -\u003e \u0026FederationConfig {\n        \u0026self.config\n    }\n\n    async fn fetch_upstream_manifest(\n        \u0026self,\n        _id: \u0026str,\n    ) -\u003e Result\u003cKnowledgeManifest, RepositoryError\u003e {\n        Ok(KnowledgeManifest {\n            version: \"1.0\".to_string(),\n            items: HashMap::new(),\n        })\n    }\n\n    async fn sync_upstream(\n        \u0026self,\n        _id: \u0026str,\n        _path: \u0026std::path::Path,\n    ) -\u003e Result\u003c(), RepositoryError\u003e {\n        if self.should_fail {\n            return Err(RepositoryError::InvalidPath(\n                \"Local changes conflict with upstream\".to_string(),\n            ));\n        }\n        Ok(())\n    }\n}\n\nstruct MockRepo;\n\n#[async_trait::async_trait]\nimpl KnowledgeRepository for MockRepo {\n    type Error = RepositoryError;\n    async fn store(\n        \u0026self,\n        _ctx: TenantContext,\n        _e: KnowledgeEntry,\n        _m: \u0026str,\n    ) -\u003e Result\u003cString, Self::Error\u003e {\n        Ok(\"hash\".into())\n    }\n    async fn get(\n        \u0026self,\n        _ctx: TenantContext,\n        _l: KnowledgeLayer,\n        _p: \u0026str,\n    ) -\u003e Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n    async fn list(\n        \u0026self,\n        _ctx: TenantContext,\n        _l: KnowledgeLayer,\n        _p: \u0026str,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n    async fn delete(\n        \u0026self,\n        _ctx: TenantContext,\n        _l: KnowledgeLayer,\n        _p: \u0026str,\n        _m: \u0026str,\n    ) -\u003e Result\u003cString, Self::Error\u003e {\n        Ok(\"hash\".into())\n    }\n    async fn get_head_commit(\u0026self, _ctx: TenantContext) -\u003e Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n        Ok(Some(\"head\".into()))\n    }\n    async fn get_affected_items(\n        \u0026self,\n        _ctx: TenantContext,\n        _f: \u0026str,\n    ) -\u003e Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n    async fn search(\n        \u0026self,\n        _ctx: TenantContext,\n        _q: \u0026str,\n        _l: Vec\u003cKnowledgeLayer\u003e,\n        _li: usize,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n    fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n        Some(\"data/test\".into())\n    }\n}\n\nstruct MockPersister;\n#[async_trait::async_trait]\nimpl SyncStatePersister for MockPersister {\n    async fn load(\n        \u0026self,\n        _tenant_id: \u0026TenantId,\n    ) -\u003e Result\u003cSyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        Ok(SyncState::default())\n    }\n    async fn save(\n        \u0026self,\n        _tenant_id: \u0026TenantId,\n        _s: \u0026SyncState,\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        Ok(())\n    }\n}\n\n#[tokio::test]\nasync fn test_sync_federation_conflict_recording() {\n    let memory = Arc::new(MemoryManager::new());\n    let repo = Arc::new(MockRepo);\n    let gov = Arc::new(GovernanceEngine::new());\n    let fed_config = FederationConfig {\n        upstreams: vec![UpstreamConfig {\n            id: \"hub-1\".to_string(),\n            url: \"http://test\".to_string(),\n            branch: \"main\".to_string(),\n            auth_token: None,\n        }],\n        sync_interval_secs: 60,\n    };\n    let fed = Arc::new(MockFedProvider {\n        config: fed_config,\n        should_fail: true,\n    });\n    let persister = Arc::new(MockPersister);\n\n    let sync_manager = SyncManager::new(\n        memory,\n        repo,\n        gov,\n        config::config::DeploymentConfig::default(),\n        Some(fed.clone() as Arc\u003cdyn FederationProvider\u003e),\n        persister,\n    )\n    .await\n    .unwrap();\n\n    sync_manager\n        .sync_federation(TenantContext::default(), fed.as_ref())\n        .await\n        .unwrap();\n\n    let ctx = TenantContext::default();\n    let state = sync_manager.get_state(\u0026ctx.tenant_id).await.unwrap();\n    assert_eq!(state.federation_conflicts.len(), 1);\n    assert_eq!(state.federation_conflicts[0].upstream_id, \"hub-1\");\n    assert!(state.federation_conflicts[0].reason.contains(\"conflict\"));\n}\n\n#[tokio::test]\nasync fn test_sync_governance_telemetry() {\n    let memory = Arc::new(MemoryManager::new());\n    let repo = Arc::new(MockRepo);\n    let mut gov = GovernanceEngine::new();\n\n    gov.add_policy(Policy {\n        id: \"p-test\".to_string(),\n        name: \"Test Policy\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Project,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"r-test\".to_string(),\n            rule_type: RuleType::Deny,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustMatch,\n            value: serde_json::json!(\"forbidden\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Forbidden content detected\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    });\n\n    let gov = Arc::new(gov);\n    let persister = Arc::new(MockPersister);\n\n    let sync_manager = SyncManager::new(\n        memory,\n        repo,\n        gov,\n        config::config::DeploymentConfig::default(),\n        None,\n        persister,\n    )\n    .await\n    .unwrap();\n\n    let entry = KnowledgeEntry {\n        path: \"forbidden.md\".to_string(),\n        content: \"this is forbidden\".to_string(),\n        layer: KnowledgeLayer::Project,\n        kind: KnowledgeType::Spec,\n        metadata: HashMap::new(),\n        status: KnowledgeStatus::Accepted,\n        commit_hash: None,\n        author: None,\n        updated_at: chrono::Utc::now().timestamp(),\n    };\n\n    let mut state = SyncState::default();\n    let _ = sync_manager\n        .sync_entry(TenantContext::default(), \u0026entry, \u0026mut state)\n        .await;\n\n    assert_eq!(state.stats.total_governance_blocks, 1);\n    assert_eq!(state.failed_items.len(), 1);\n    assert!(\n        state.failed_items[0]\n            .error\n            .contains(\"Governance violation (BLOCK)\")\n    );\n}\n","traces":[{"line":26,"address":[],"length":0,"stats":{"Line":1}},{"line":27,"address":[],"length":0,"stats":{"Line":1}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":1}},{"line":112,"address":[],"length":0,"stats":{"Line":1}}],"covered":4,"coverable":5},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","tests","sync_integration.rs"],"content":"use async_trait::async_trait;\nuse knowledge::governance::GovernanceEngine;\nuse knowledge::repository::GitRepository;\nuse memory::manager::MemoryManager;\nuse memory::providers::MockProvider;\nuse mk_core::traits::{KnowledgeRepository, StorageBackend};\nuse mk_core::types::{\n    KnowledgeEntry, KnowledgeLayer, KnowledgeStatus, KnowledgeType, MemoryLayer, TenantContext,\n    TenantId,\n};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse sync::bridge::SyncManager;\nuse sync::state::SyncState;\nuse sync::state_persister::SyncStatePersister;\nuse tokio::sync::RwLock;\n\nstruct MockStorage {\n    data: Arc\u003cRwLock\u003cHashMap\u003cString, Vec\u003cu8\u003e\u003e\u003e\u003e,\n}\n\nimpl MockStorage {\n    fn new() -\u003e Self {\n        Self {\n            data: Arc::new(RwLock::new(HashMap::new())),\n        }\n    }\n}\n\n#[async_trait]\nimpl StorageBackend for MockStorage {\n    type Error = std::io::Error;\n\n    async fn store(\u0026self, _ctx: TenantContext, key: \u0026str, value: \u0026[u8]) -\u003e Result\u003c(), Self::Error\u003e {\n        self.data\n            .write()\n            .await\n            .insert(key.to_string(), value.to_vec());\n        Ok(())\n    }\n\n    async fn retrieve(\n        \u0026self,\n        _ctx: TenantContext,\n        key: \u0026str,\n    ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e {\n        Ok(self.data.read().await.get(key).cloned())\n    }\n\n    async fn delete(\u0026self, _ctx: TenantContext, key: \u0026str) -\u003e Result\u003c(), Self::Error\u003e {\n        self.data.write().await.remove(key);\n        Ok(())\n    }\n\n    async fn exists(\u0026self, _ctx: TenantContext, key: \u0026str) -\u003e Result\u003cbool, Self::Error\u003e {\n        Ok(self.data.read().await.contains_key(key))\n    }\n\n    async fn get_ancestors(\n        \u0026self,\n        _ctx: TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn get_descendants(\n        \u0026self,\n        _ctx: TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn get_unit_policies(\n        \u0026self,\n        _ctx: TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::Policy\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn create_unit(\n        \u0026self,\n        _unit: \u0026mk_core::types::OrganizationalUnit,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn add_unit_policy(\n        \u0026self,\n        _ctx: \u0026TenantContext,\n        _unit_id: \u0026str,\n        _policy: \u0026mk_core::types::Policy,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn assign_role(\n        \u0026self,\n        _user_id: \u0026mk_core::types::UserId,\n        _tenant_id: \u0026mk_core::types::TenantId,\n        _unit_id: \u0026str,\n        _role: mk_core::types::Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn remove_role(\n        \u0026self,\n        _user_id: \u0026mk_core::types::UserId,\n        _tenant_id: \u0026mk_core::types::TenantId,\n        _unit_id: \u0026str,\n        _role: mk_core::types::Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn store_drift_result(\n        \u0026self,\n        _result: mk_core::types::DriftResult,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn get_latest_drift_result(\n        \u0026self,\n        _ctx: TenantContext,\n        _project_id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cmk_core::types::DriftResult\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n\n    async fn list_all_units(\u0026self) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn record_job_status(\n        \u0026self,\n        _job_name: \u0026str,\n        _tenant_id: \u0026str,\n        _status: \u0026str,\n        _message: Option\u003c\u0026str\u003e,\n        _started_at: i64,\n        _finished_at: Option\u003ci64\u003e,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn get_governance_events(\n        \u0026self,\n        _ctx: TenantContext,\n        _since_timestamp: i64,\n        _limit: usize,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n}\n\npub struct SimplePersister {\n    storage: Arc\u003cMockStorage\u003e,\n}\n\n#[async_trait]\nimpl SyncStatePersister for SimplePersister {\n    async fn load(\n        \u0026self,\n        tenant_id: \u0026TenantId,\n    ) -\u003e Result\u003cSyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let ctx = TenantContext::new(tenant_id.clone(), mk_core::types::UserId::default());\n        match self.storage.retrieve(ctx, \"sync_state\").await? {\n            Some(data) =\u003e Ok(serde_json::from_slice(\u0026data)?),\n            None =\u003e Ok(SyncState::default()),\n        }\n    }\n\n    async fn save(\n        \u0026self,\n        tenant_id: \u0026TenantId,\n        state: \u0026SyncState,\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let ctx = TenantContext::new(tenant_id.clone(), mk_core::types::UserId::default());\n        let data = serde_json::to_vec(state)?;\n        self.storage.store(ctx, \"sync_state\", \u0026data).await?;\n        Ok(())\n    }\n}\n\n#[tokio::test]\nasync fn test_sync_persistence_and_delta() -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    let repo_dir = tempfile::tempdir()?;\n    let knowledge_repo = Arc::new(GitRepository::new(repo_dir.path())?);\n    let governance_engine = Arc::new(GovernanceEngine::new());\n\n    let memory_manager = Arc::new(MemoryManager::new());\n    let mock_provider = MockProvider::new();\n    memory_manager\n        .register_provider(MemoryLayer::Project, Box::new(mock_provider))\n        .await;\n\n    let storage = Arc::new(MockStorage::new());\n    let persister = Arc::new(SimplePersister {\n        storage: storage.clone(),\n    });\n\n    let sync_manager = SyncManager::new(\n        memory_manager.clone(),\n        knowledge_repo.clone(),\n        governance_engine.clone(),\n        config::DeploymentConfig::default(),\n        None,\n        persister.clone(),\n    )\n    .await?;\n\n    let entry = KnowledgeEntry {\n        path: \"test.md\".to_string(),\n        content: \"initial content\".to_string(),\n        layer: KnowledgeLayer::Project,\n        kind: KnowledgeType::Spec,\n        status: KnowledgeStatus::Accepted,\n        metadata: HashMap::new(),\n        commit_hash: None,\n        author: None,\n        updated_at: chrono::Utc::now().timestamp(),\n    };\n    knowledge_repo\n        .store(TenantContext::default(), entry.clone(), \"first commit\")\n        .await?;\n\n    sync_manager.sync_all(TenantContext::default()).await?;\n\n    let ctx = TenantContext::default();\n    assert!(storage.exists(ctx, \"sync_state\").await?);\n    let tenant_id = TenantId::default();\n    let state = persister.load(\u0026tenant_id).await?;\n    assert_eq!(state.stats.total_items_synced, 1);\n    assert!(state.last_knowledge_commit.is_some());\n\n    let updated_entry = KnowledgeEntry {\n        content: \"updated content\".to_string(),\n        ..entry.clone()\n    };\n    knowledge_repo\n        .store(TenantContext::default(), updated_entry, \"second commit\")\n        .await?;\n\n    sync_manager\n        .sync_incremental(TenantContext::default())\n        .await?;\n\n    let state = persister.load(\u0026tenant_id).await?;\n    assert_eq!(state.stats.total_syncs, 2);\n\n    sync_manager\n        .run_sync_cycle(TenantContext::default(), 0)\n        .await?;\n\n    let _ = sync_manager\n        .detect_conflicts(TenantContext::default())\n        .await?;\n\n    let memory_id = format!(\"ptr_{}\", entry.path);\n    memory_manager\n        .delete_from_layer(TenantContext::default(), MemoryLayer::Project, \u0026memory_id)\n        .await?;\n\n    let conflicts = sync_manager\n        .detect_conflicts(TenantContext::default())\n        .await?;\n    assert_eq!(conflicts.len(), 1);\n\n    sync_manager\n        .resolve_conflicts(TenantContext::default(), conflicts)\n        .await?;\n\n    let conflicts = sync_manager\n        .detect_conflicts(TenantContext::default())\n        .await?;\n    if !conflicts.is_empty() {\n        println!(\"Final conflicts: {:?}\", conflicts);\n    }\n    assert!(conflicts.is_empty());\n\n    Ok(())\n}\n\n#[tokio::test]\nasync fn test_background_sync_trigger() -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    let repo_dir = tempfile::tempdir()?;\n    let knowledge_repo = Arc::new(GitRepository::new(repo_dir.path())?);\n    let governance_engine = Arc::new(GovernanceEngine::new());\n    let memory_manager = Arc::new(MemoryManager::new());\n    let mock_provider = MockProvider::new();\n    memory_manager\n        .register_provider(MemoryLayer::Project, Box::new(mock_provider))\n        .await;\n\n    let storage = Arc::new(MockStorage::new());\n    let persister = Arc::new(SimplePersister {\n        storage: storage.clone(),\n    });\n\n    let sync_manager = Arc::new(\n        SyncManager::new(\n            memory_manager.clone(),\n            knowledge_repo.clone(),\n            governance_engine.clone(),\n            config::DeploymentConfig::default(),\n            None,\n            persister.clone(),\n        )\n        .await?,\n    );\n\n    let entry = KnowledgeEntry {\n        path: \"bg_test.md\".to_string(),\n        content: \"initial content\".to_string(),\n        layer: KnowledgeLayer::Project,\n        kind: KnowledgeType::Spec,\n        status: KnowledgeStatus::Accepted,\n        metadata: HashMap::new(),\n        commit_hash: None,\n        author: None,\n        updated_at: chrono::Utc::now().timestamp(),\n    };\n    knowledge_repo\n        .store(TenantContext::default(), entry.clone(), \"first commit\")\n        .await?;\n\n    let (_tx, rx) = tokio::sync::watch::channel(false);\n    let handle = sync_manager\n        .clone()\n        .start_background_sync(TenantContext::default(), 1, 0, rx)\n        .await;\n\n    let mut synced = false;\n    let tenant_id = TenantId::default();\n    for _ in 0..10 {\n        tokio::time::sleep(std::time::Duration::from_millis(500)).await;\n        let state = persister.load(\u0026tenant_id).await?;\n        if state.stats.total_items_synced \u003e 0 {\n            synced = true;\n            break;\n        }\n    }\n\n    handle.abort();\n    assert!(synced, \"Background sync should have picked up the change\");\n\n    Ok(())\n}\n\n#[tokio::test]\nasync fn test_governance_blocking_sync() -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    let repo_dir = tempfile::tempdir()?;\n    let knowledge_repo = Arc::new(GitRepository::new(repo_dir.path())?);\n    let mut governance_engine = GovernanceEngine::new();\n\n    governance_engine.add_policy(mk_core::types::Policy {\n        id: \"p1\".to_string(),\n        name: \"No Secrets\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: mk_core::types::PolicyMode::Mandatory,\n        merge_strategy: mk_core::types::RuleMergeStrategy::Override,\n        rules: vec![mk_core::types::PolicyRule {\n            id: \"r1\".to_string(),\n            rule_type: mk_core::types::RuleType::Allow,\n            target: mk_core::types::ConstraintTarget::Code,\n            operator: mk_core::types::ConstraintOperator::MustNotMatch,\n            value: serde_json::json!(\"SECRET\"),\n            severity: mk_core::types::ConstraintSeverity::Block,\n            message: \"No secrets allowed\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    });\n\n    let memory_manager = Arc::new(MemoryManager::new());\n    let mock_provider = MockProvider::new();\n    memory_manager\n        .register_provider(MemoryLayer::Project, Box::new(mock_provider))\n        .await;\n\n    let storage = Arc::new(MockStorage::new());\n    let persister = Arc::new(SimplePersister {\n        storage: storage.clone(),\n    });\n\n    let sync_manager = SyncManager::new(\n        memory_manager.clone(),\n        knowledge_repo.clone(),\n        Arc::new(governance_engine),\n        config::DeploymentConfig::default(),\n        None,\n        persister.clone(),\n    )\n    .await?;\n\n    let entry = KnowledgeEntry {\n        path: \"secret.md\".to_string(),\n        content: \"My SECRET is 12345\".to_string(),\n        layer: KnowledgeLayer::Project,\n        kind: KnowledgeType::Spec,\n        status: KnowledgeStatus::Accepted,\n        metadata: HashMap::new(),\n        commit_hash: None,\n        author: None,\n        updated_at: chrono::Utc::now().timestamp(),\n    };\n    knowledge_repo\n        .store(TenantContext::default(), entry, \"secret commit\")\n        .await?;\n\n    sync_manager.sync_all(TenantContext::default()).await?;\n\n    let tenant_id = TenantId::default();\n    let state = persister.load(\u0026tenant_id).await?;\n    assert_eq!(state.stats.total_items_synced, 0);\n    assert!(state.stats.total_governance_blocks \u003e 0);\n\n    Ok(())\n}\n","traces":[{"line":23,"address":[],"length":0,"stats":{"Line":3}},{"line":25,"address":[],"length":0,"stats":{"Line":6}},{"line":34,"address":[],"length":0,"stats":{"Line":6}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":1}},{"line":134,"address":[],"length":0,"stats":{"Line":0}}],"covered":4,"coverable":6},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","backend.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","bridge.rs"],"content":"use crate::tools::Tool;\nuse async_trait::async_trait;\nuse mk_core::types::TenantContext;\nuse schemars::JsonSchema;\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Value, json};\nuse std::sync::Arc;\nuse sync::bridge::SyncManager;\nuse validator::Validate;\n\npub struct SyncNowTool {\n    sync_manager: Arc\u003cSyncManager\u003e\n}\n\nimpl SyncNowTool {\n    pub fn new(sync_manager: Arc\u003cSyncManager\u003e) -\u003e Self {\n        Self { sync_manager }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct SyncNowparams {\n    #[serde(default)]\n    pub force: bool,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[async_trait]\nimpl Tool for SyncNowTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"sync_now\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Trigger manual synchronization between memory and knowledge systems.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"force\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Force full sync (ignore delta detection)\",\n                    \"default\": false\n                },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            }\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: SyncNowparams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        if p.force {\n            self.sync_manager.sync_all(ctx).await?;\n        } else {\n            self.sync_manager.sync_incremental(ctx).await?;\n        }\n\n        Ok(json!({\n            \"success\": true,\n            \"message\": \"Synchronization completed\"\n        }))\n    }\n}\n\npub struct SyncStatusTool {\n    sync_manager: Arc\u003cSyncManager\u003e\n}\n\nimpl SyncStatusTool {\n    pub fn new(sync_manager: Arc\u003cSyncManager\u003e) -\u003e Self {\n        Self { sync_manager }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct SyncStatusParams {\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[async_trait]\nimpl Tool for SyncStatusTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"sync_status\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Check the current sync status, including last sync time and health.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            }\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: SyncStatusParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let state = self.sync_manager.get_state(\u0026ctx.tenant_id).await?;\n\n        Ok(json!({\n            \"success\": true,\n            \"healthy\": state.failed_items.is_empty() \u0026\u0026 state.federation_conflicts.is_empty(),\n            \"lastSyncAt\": state.last_sync_at,\n            \"failedItems\": state.failed_items.len(),\n            \"federationConflicts\": state.federation_conflicts,\n            \"stats\": {\n                \"totalSyncs\": state.stats.total_syncs,\n                \"totalItemsSynced\": state.stats.total_items_synced,\n                \"totalConflicts\": state.stats.total_conflicts,\n                \"totalGovernanceBlocks\": state.stats.total_governance_blocks,\n                \"avgSyncDurationMs\": state.stats.avg_sync_duration_ms,\n                \"driftScore\": state.stats.drift_score,\n                \"policyViolations\": state.stats.policy_violations\n            }\n        }))\n    }\n}\n\npub struct ResolveFederationConflictTool {\n    sync_manager: Arc\u003cSyncManager\u003e\n}\n\nimpl ResolveFederationConflictTool {\n    pub fn new(sync_manager: Arc\u003cSyncManager\u003e) -\u003e Self {\n        Self { sync_manager }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct ResolveFederationConflictParams {\n    pub upstream_id: String,\n    pub resolution: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[async_trait]\nimpl Tool for ResolveFederationConflictTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"knowledge_resolve_conflict\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Resolve a federation conflict by choosing a resolution strategy (ours, theirs, manual).\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"upstream_id\": {\n                    \"type\": \"string\",\n                    \"description\": \"ID of the upstream with conflict\"\n                },\n                \"resolution\": {\n                    \"type\": \"string\",\n                    \"description\": \"Resolution strategy: ours, theirs, or manual\",\n                    \"enum\": [\"ours\", \"theirs\", \"manual\"]\n                },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"upstream_id\", \"resolution\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: ResolveFederationConflictParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        self.sync_manager\n            .resolve_federation_conflict(ctx.tenant_id, \u0026p.upstream_id, \u0026p.resolution)\n            .await?;\n\n        Ok(json!({\n            \"success\": true,\n            \"message\": format!(\"Conflict for {} resolved as {}\", p.upstream_id, p.resolution)\n        }))\n    }\n}\n","traces":[{"line":16,"address":[],"length":0,"stats":{"Line":19}},{"line":31,"address":[],"length":0,"stats":{"Line":23}},{"line":32,"address":[],"length":0,"stats":{"Line":23}},{"line":35,"address":[],"length":0,"stats":{"Line":5}},{"line":36,"address":[],"length":0,"stats":{"Line":5}},{"line":39,"address":[],"length":0,"stats":{"Line":5}},{"line":40,"address":[],"length":0,"stats":{"Line":5}},{"line":41,"address":[],"length":0,"stats":{"Line":5}},{"line":42,"address":[],"length":0,"stats":{"Line":5}},{"line":43,"address":[],"length":0,"stats":{"Line":5}},{"line":44,"address":[],"length":0,"stats":{"Line":5}},{"line":45,"address":[],"length":0,"stats":{"Line":5}},{"line":46,"address":[],"length":0,"stats":{"Line":5}},{"line":48,"address":[],"length":0,"stats":{"Line":10}},{"line":53,"address":[],"length":0,"stats":{"Line":1}},{"line":77,"address":[],"length":0,"stats":{"Line":19}},{"line":90,"address":[],"length":0,"stats":{"Line":23}},{"line":91,"address":[],"length":0,"stats":{"Line":23}},{"line":94,"address":[],"length":0,"stats":{"Line":5}},{"line":95,"address":[],"length":0,"stats":{"Line":5}},{"line":98,"address":[],"length":0,"stats":{"Line":5}},{"line":99,"address":[],"length":0,"stats":{"Line":5}},{"line":100,"address":[],"length":0,"stats":{"Line":5}},{"line":101,"address":[],"length":0,"stats":{"Line":5}},{"line":102,"address":[],"length":0,"stats":{"Line":10}},{"line":107,"address":[],"length":0,"stats":{"Line":2}},{"line":139,"address":[],"length":0,"stats":{"Line":18}},{"line":154,"address":[],"length":0,"stats":{"Line":23}},{"line":155,"address":[],"length":0,"stats":{"Line":23}},{"line":158,"address":[],"length":0,"stats":{"Line":5}},{"line":159,"address":[],"length":0,"stats":{"Line":5}},{"line":162,"address":[],"length":0,"stats":{"Line":5}},{"line":163,"address":[],"length":0,"stats":{"Line":5}},{"line":164,"address":[],"length":0,"stats":{"Line":5}},{"line":165,"address":[],"length":0,"stats":{"Line":5}},{"line":166,"address":[],"length":0,"stats":{"Line":5}},{"line":167,"address":[],"length":0,"stats":{"Line":5}},{"line":168,"address":[],"length":0,"stats":{"Line":5}},{"line":170,"address":[],"length":0,"stats":{"Line":5}},{"line":171,"address":[],"length":0,"stats":{"Line":5}},{"line":172,"address":[],"length":0,"stats":{"Line":5}},{"line":173,"address":[],"length":0,"stats":{"Line":5}},{"line":175,"address":[],"length":0,"stats":{"Line":10}},{"line":177,"address":[],"length":0,"stats":{"Line":5}},{"line":181,"address":[],"length":0,"stats":{"Line":0}}],"covered":44,"coverable":45},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","config.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","ecosystem.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","episodic.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","governance.rs"],"content":"use crate::tools::Tool;\nuse async_trait::async_trait;\nuse knowledge::governance::GovernanceEngine;\nuse mk_core::types::{GovernanceEvent, OrganizationalUnit, Role, TenantContext, UnitType};\nuse schemars::JsonSchema;\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Value, json};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse validator::Validate;\n\n/// Tool to create a new organizational unit.\npub struct UnitCreateTool {\n    backend: Arc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e,\n    governance_engine: Arc\u003cGovernanceEngine\u003e\n}\n\nimpl UnitCreateTool {\n    pub fn new(\n        backend: Arc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e,\n        governance_engine: Arc\u003cGovernanceEngine\u003e\n    ) -\u003e Self {\n        Self {\n            backend,\n            governance_engine\n        }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct UnitCreateParams {\n    pub name: String,\n    pub unit_type: String,\n    pub parent_id: Option\u003cString\u003e,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e,\n    #[serde(default)]\n    pub metadata: HashMap\u003cString, Value\u003e\n}\n\n#[async_trait]\nimpl Tool for UnitCreateTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"governance_unit_create\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Create a new organizational unit (Company, Organization, Team, or Project).\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"name\": { \"type\": \"string\", \"description\": \"Name of the unit\" },\n                \"unit_type\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"company\", \"organization\", \"team\", \"project\"],\n                    \"description\": \"Type of the unit\"\n                },\n                \"parent_id\": { \"type\": \"string\", \"description\": \"Parent unit ID\" },\n                \"metadata\": { \"type\": \"object\", \"description\": \"Optional metadata\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"name\", \"unit_type\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: UnitCreateParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let unit_type = match p.unit_type.as_str() {\n            \"company\" =\u003e UnitType::Company,\n            \"organization\" =\u003e UnitType::Organization,\n            \"team\" =\u003e UnitType::Team,\n            \"project\" =\u003e UnitType::Project,\n            _ =\u003e return Err(\"Invalid unit type\".into())\n        };\n\n        let unit = OrganizationalUnit {\n            id: uuid::Uuid::new_v4().to_string(),\n            name: p.name,\n            unit_type,\n            parent_id: p.parent_id,\n            tenant_id: ctx.tenant_id.clone(),\n            metadata: p.metadata,\n            created_at: chrono::Utc::now().timestamp(),\n            updated_at: chrono::Utc::now().timestamp()\n        };\n\n        self.backend.create_unit(\u0026unit).await?;\n\n        let _ = self\n            .governance_engine\n            .publish_event(GovernanceEvent::UnitCreated {\n                unit_id: unit.id.clone(),\n                unit_type: unit.unit_type,\n                tenant_id: ctx.tenant_id.clone(),\n                parent_id: unit.parent_id.clone(),\n                timestamp: chrono::Utc::now().timestamp()\n            })\n            .await;\n\n        Ok(json!({\n            \"success\": true,\n            \"unit_id\": unit.id\n        }))\n    }\n}\n\n/// Tool to add a policy to an organizational unit.\npub struct UnitPolicyAddTool {\n    backend: Arc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e,\n    governance_engine: Arc\u003cGovernanceEngine\u003e\n}\n\nimpl UnitPolicyAddTool {\n    pub fn new(\n        backend: Arc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e,\n        governance_engine: Arc\u003cGovernanceEngine\u003e\n    ) -\u003e Self {\n        Self {\n            backend,\n            governance_engine\n        }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct UnitPolicyAddParams {\n    pub unit_id: String,\n    pub policy: mk_core::types::Policy,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[async_trait]\nimpl Tool for UnitPolicyAddTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"governance_policy_add\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Add or update a policy for an organizational unit.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"unit_id\": { \"type\": \"string\", \"description\": \"Unit ID to attach policy to\" },\n                \"policy\": { \"type\": \"object\", \"description\": \"Policy definition\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"unit_id\", \"policy\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: UnitPolicyAddParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        self.backend\n            .add_unit_policy(\u0026ctx, \u0026p.unit_id, \u0026p.policy)\n            .await?;\n\n        let _ = self\n            .governance_engine\n            .publish_event(GovernanceEvent::PolicyUpdated {\n                policy_id: p.policy.id.clone(),\n                layer: p.policy.layer,\n                tenant_id: ctx.tenant_id.clone(),\n                timestamp: chrono::Utc::now().timestamp()\n            })\n            .await;\n\n        Ok(json!({\n            \"success\": true,\n            \"policy_id\": p.policy.id\n        }))\n    }\n}\n\n/// Tool to assign a role to a user within an organizational unit.\npub struct UserRoleAssignTool {\n    backend: Arc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e,\n    governance_engine: Arc\u003cGovernanceEngine\u003e\n}\n\nimpl UserRoleAssignTool {\n    pub fn new(\n        backend: Arc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e,\n        governance_engine: Arc\u003cGovernanceEngine\u003e\n    ) -\u003e Self {\n        Self {\n            backend,\n            governance_engine\n        }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct UserRoleAssignParams {\n    pub user_id: String,\n    pub unit_id: String,\n    pub role: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[async_trait]\nimpl Tool for UserRoleAssignTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"governance_role_assign\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Assign a role to a user within a specific organizational unit.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"user_id\": { \"type\": \"string\", \"description\": \"User ID\" },\n                \"unit_id\": { \"type\": \"string\", \"description\": \"Unit ID\" },\n                \"role\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"developer\", \"techlead\", \"architect\", \"admin\", \"agent\"],\n                    \"description\": \"Role to assign\"\n                },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"user_id\", \"unit_id\", \"role\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: UserRoleAssignParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n        let user_id = mk_core::types::UserId::new(p.user_id).ok_or(\"Invalid user ID\")?;\n        let role: Role = p.role.parse()?;\n\n        self.backend\n            .assign_role(\u0026user_id, \u0026ctx.tenant_id, \u0026p.unit_id, role.clone())\n            .await?;\n\n        let _ = self\n            .governance_engine\n            .publish_event(GovernanceEvent::RoleAssigned {\n                user_id: user_id.clone(),\n                unit_id: p.unit_id.clone(),\n                role,\n                tenant_id: ctx.tenant_id.clone(),\n                timestamp: chrono::Utc::now().timestamp()\n            })\n            .await;\n\n        Ok(json!({\n            \"success\": true\n        }))\n    }\n}\n\n/// Tool to remove a role from a user within an organizational unit.\npub struct UserRoleRemoveTool {\n    backend: Arc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e,\n    governance_engine: Arc\u003cGovernanceEngine\u003e\n}\n\nimpl UserRoleRemoveTool {\n    pub fn new(\n        backend: Arc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e,\n        governance_engine: Arc\u003cGovernanceEngine\u003e\n    ) -\u003e Self {\n        Self {\n            backend,\n            governance_engine\n        }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct UserRoleRemoveParams {\n    pub user_id: String,\n    pub unit_id: String,\n    pub role: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[async_trait]\nimpl Tool for UserRoleRemoveTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"governance_role_remove\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Remove a role from a user within a specific organizational unit.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"user_id\": { \"type\": \"string\", \"description\": \"User ID\" },\n                \"unit_id\": { \"type\": \"string\", \"description\": \"Unit ID\" },\n                \"role\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"developer\", \"techlead\", \"architect\", \"admin\", \"agent\"],\n                    \"description\": \"Role to remove\"\n                },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"user_id\", \"unit_id\", \"role\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: UserRoleRemoveParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n        let user_id = mk_core::types::UserId::new(p.user_id).ok_or(\"Invalid user ID\")?;\n        let role: Role = p.role.parse()?;\n\n        self.backend\n            .remove_role(\u0026user_id, \u0026ctx.tenant_id, \u0026p.unit_id, role.clone())\n            .await?;\n\n        let _ = self\n            .governance_engine\n            .publish_event(GovernanceEvent::RoleRemoved {\n                user_id: user_id.clone(),\n                unit_id: p.unit_id.clone(),\n                role,\n                tenant_id: ctx.tenant_id.clone(),\n                timestamp: chrono::Utc::now().timestamp()\n            })\n            .await;\n\n        Ok(json!({\n            \"success\": true\n        }))\n    }\n}\n\npub struct HierarchyNavigateTool {\n    backend: Arc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e\n}\n\nimpl HierarchyNavigateTool {\n    pub fn new(\n        backend: Arc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e\n    ) -\u003e Self {\n        Self { backend }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct HierarchyNavigateParams {\n    pub unit_id: String,\n    pub direction: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[async_trait]\nimpl Tool for HierarchyNavigateTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"governance_hierarchy_navigate\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Navigate the organizational hierarchy (ancestors or descendants) for a unit.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"unit_id\": { \"type\": \"string\", \"description\": \"Starting Unit ID\" },\n                \"direction\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"ancestors\", \"descendants\"],\n                    \"description\": \"Navigation direction\"\n                },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"unit_id\", \"direction\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: HierarchyNavigateParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let units = match p.direction.as_str() {\n            \"ancestors\" =\u003e self.backend.get_ancestors(ctx, \u0026p.unit_id).await?,\n            \"descendants\" =\u003e self.backend.get_descendants(ctx, \u0026p.unit_id).await?,\n            _ =\u003e return Err(\"Invalid direction\".into())\n        };\n\n        Ok(json!({\n            \"success\": true,\n            \"units\": units\n        }))\n    }\n}\n","traces":[{"line":19,"address":[],"length":0,"stats":{"Line":18}},{"line":43,"address":[],"length":0,"stats":{"Line":23}},{"line":44,"address":[],"length":0,"stats":{"Line":23}},{"line":47,"address":[],"length":0,"stats":{"Line":5}},{"line":48,"address":[],"length":0,"stats":{"Line":5}},{"line":51,"address":[],"length":0,"stats":{"Line":5}},{"line":52,"address":[],"length":0,"stats":{"Line":5}},{"line":53,"address":[],"length":0,"stats":{"Line":5}},{"line":54,"address":[],"length":0,"stats":{"Line":5}},{"line":55,"address":[],"length":0,"stats":{"Line":15}},{"line":56,"address":[],"length":0,"stats":{"Line":5}},{"line":57,"address":[],"length":0,"stats":{"Line":5}},{"line":58,"address":[],"length":0,"stats":{"Line":5}},{"line":59,"address":[],"length":0,"stats":{"Line":5}},{"line":61,"address":[],"length":0,"stats":{"Line":15}},{"line":62,"address":[],"length":0,"stats":{"Line":15}},{"line":63,"address":[],"length":0,"stats":{"Line":10}},{"line":65,"address":[],"length":0,"stats":{"Line":5}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":18}},{"line":142,"address":[],"length":0,"stats":{"Line":23}},{"line":143,"address":[],"length":0,"stats":{"Line":23}},{"line":146,"address":[],"length":0,"stats":{"Line":5}},{"line":147,"address":[],"length":0,"stats":{"Line":5}},{"line":150,"address":[],"length":0,"stats":{"Line":5}},{"line":151,"address":[],"length":0,"stats":{"Line":5}},{"line":152,"address":[],"length":0,"stats":{"Line":5}},{"line":153,"address":[],"length":0,"stats":{"Line":5}},{"line":154,"address":[],"length":0,"stats":{"Line":15}},{"line":155,"address":[],"length":0,"stats":{"Line":15}},{"line":156,"address":[],"length":0,"stats":{"Line":10}},{"line":158,"address":[],"length":0,"stats":{"Line":5}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":18}},{"line":218,"address":[],"length":0,"stats":{"Line":23}},{"line":219,"address":[],"length":0,"stats":{"Line":23}},{"line":222,"address":[],"length":0,"stats":{"Line":5}},{"line":223,"address":[],"length":0,"stats":{"Line":5}},{"line":226,"address":[],"length":0,"stats":{"Line":5}},{"line":227,"address":[],"length":0,"stats":{"Line":5}},{"line":228,"address":[],"length":0,"stats":{"Line":5}},{"line":229,"address":[],"length":0,"stats":{"Line":5}},{"line":230,"address":[],"length":0,"stats":{"Line":15}},{"line":231,"address":[],"length":0,"stats":{"Line":15}},{"line":232,"address":[],"length":0,"stats":{"Line":5}},{"line":233,"address":[],"length":0,"stats":{"Line":5}},{"line":234,"address":[],"length":0,"stats":{"Line":5}},{"line":235,"address":[],"length":0,"stats":{"Line":5}},{"line":237,"address":[],"length":0,"stats":{"Line":10}},{"line":239,"address":[],"length":0,"stats":{"Line":5}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":18}},{"line":301,"address":[],"length":0,"stats":{"Line":23}},{"line":302,"address":[],"length":0,"stats":{"Line":23}},{"line":305,"address":[],"length":0,"stats":{"Line":5}},{"line":306,"address":[],"length":0,"stats":{"Line":5}},{"line":309,"address":[],"length":0,"stats":{"Line":5}},{"line":310,"address":[],"length":0,"stats":{"Line":5}},{"line":311,"address":[],"length":0,"stats":{"Line":5}},{"line":312,"address":[],"length":0,"stats":{"Line":5}},{"line":313,"address":[],"length":0,"stats":{"Line":15}},{"line":314,"address":[],"length":0,"stats":{"Line":15}},{"line":315,"address":[],"length":0,"stats":{"Line":5}},{"line":316,"address":[],"length":0,"stats":{"Line":5}},{"line":317,"address":[],"length":0,"stats":{"Line":5}},{"line":318,"address":[],"length":0,"stats":{"Line":5}},{"line":320,"address":[],"length":0,"stats":{"Line":10}},{"line":322,"address":[],"length":0,"stats":{"Line":5}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":360,"address":[],"length":0,"stats":{"Line":18}},{"line":377,"address":[],"length":0,"stats":{"Line":23}},{"line":378,"address":[],"length":0,"stats":{"Line":23}},{"line":381,"address":[],"length":0,"stats":{"Line":5}},{"line":382,"address":[],"length":0,"stats":{"Line":5}},{"line":385,"address":[],"length":0,"stats":{"Line":5}},{"line":386,"address":[],"length":0,"stats":{"Line":5}},{"line":387,"address":[],"length":0,"stats":{"Line":5}},{"line":388,"address":[],"length":0,"stats":{"Line":5}},{"line":389,"address":[],"length":0,"stats":{"Line":15}},{"line":390,"address":[],"length":0,"stats":{"Line":5}},{"line":391,"address":[],"length":0,"stats":{"Line":5}},{"line":392,"address":[],"length":0,"stats":{"Line":5}},{"line":393,"address":[],"length":0,"stats":{"Line":5}},{"line":395,"address":[],"length":0,"stats":{"Line":10}},{"line":397,"address":[],"length":0,"stats":{"Line":5}},{"line":401,"address":[],"length":0,"stats":{"Line":0}}],"covered":81,"coverable":86},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","hot_reload.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","knowledge.rs"],"content":"use crate::tools::Tool;\nuse async_trait::async_trait;\nuse memory::manager::MemoryManager;\nuse mk_core::traits::KnowledgeRepository;\nuse mk_core::types::{MemoryEntry, TenantContext};\nuse schemars::JsonSchema;\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Value, json};\nuse std::sync::Arc;\nuse validator::Validate;\n\npub struct KnowledgeGetTool {\n    repo: Arc\u003cdyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e\u003e\n}\n\nimpl KnowledgeGetTool {\n    pub fn new(\n        repo: Arc\u003cdyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e\u003e\n    ) -\u003e Self {\n        Self { repo }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct KnowledgeGetParams {\n    pub path: String,\n    pub layer: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct KnowledgeListParams {\n    pub layer: String,\n    #[serde(default)]\n    pub prefix: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct KnowledgeQueryParams {\n    pub query: String,\n    #[serde(default)]\n    pub layers: Vec\u003cString\u003e,\n    pub limit: Option\u003cusize\u003e,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[async_trait]\nimpl Tool for KnowledgeGetTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"knowledge_get\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Retrieve a specific knowledge entry by path and layer.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"path\": { \"type\": \"string\" },\n                \"layer\": { \"type\": \"string\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"path\", \"layer\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: KnowledgeGetParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let layer = match p.layer.to_lowercase().as_str() {\n            \"company\" =\u003e mk_core::types::KnowledgeLayer::Company,\n            \"org\" =\u003e mk_core::types::KnowledgeLayer::Org,\n            \"team\" =\u003e mk_core::types::KnowledgeLayer::Team,\n            \"project\" =\u003e mk_core::types::KnowledgeLayer::Project,\n            _ =\u003e return Err(format!(\"Unknown layer: {}\", p.layer).into())\n        };\n\n        let entry = self.repo.get(ctx, layer, \u0026p.path).await?;\n        Ok(json!({ \"success\": true, \"entry\": entry }))\n    }\n}\n\npub struct KnowledgeListTool {\n    repo: Arc\u003cdyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e\u003e\n}\n\nimpl KnowledgeListTool {\n    pub fn new(\n        repo: Arc\u003cdyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e\u003e\n    ) -\u003e Self {\n        Self { repo }\n    }\n}\n\n#[async_trait]\nimpl Tool for KnowledgeListTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"knowledge_list\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"List knowledge entries in a specific layer, optionally filtered by prefix.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"layer\": { \"type\": \"string\" },\n                \"prefix\": { \"type\": \"string\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"layer\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: KnowledgeListParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let layer = match p.layer.to_lowercase().as_str() {\n            \"company\" =\u003e mk_core::types::KnowledgeLayer::Company,\n            \"org\" =\u003e mk_core::types::KnowledgeLayer::Org,\n            \"team\" =\u003e mk_core::types::KnowledgeLayer::Team,\n            \"project\" =\u003e mk_core::types::KnowledgeLayer::Project,\n            _ =\u003e return Err(format!(\"Unknown layer: {}\", p.layer).into())\n        };\n\n        let entries = self.repo.list(ctx, layer, \u0026p.prefix).await?;\n        Ok(json!({ \"success\": true, \"entries\": entries }))\n    }\n}\n\npub struct KnowledgeQueryTool {\n    memory_manager: Arc\u003cMemoryManager\u003e,\n    repo: Arc\u003cdyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e\u003e\n}\n\nimpl KnowledgeQueryTool {\n    pub fn new(\n        memory_manager: Arc\u003cMemoryManager\u003e,\n        repo: Arc\u003cdyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e\u003e\n    ) -\u003e Self {\n        Self {\n            memory_manager,\n            repo\n        }\n    }\n}\n\n#[async_trait]\nimpl Tool for KnowledgeQueryTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"knowledge_query\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Search for knowledge entries across layers using semantic or keyword search.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": { \"type\": \"string\" },\n                \"layers\": { \"type\": \"array\", \"items\": { \"type\": \"string\" } },\n                \"limit\": { \"type\": \"integer\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"query\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: KnowledgeQueryParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let mut layers = Vec::new();\n        if p.layers.is_empty() {\n            layers = vec![\n                mk_core::types::KnowledgeLayer::Company,\n                mk_core::types::KnowledgeLayer::Org,\n                mk_core::types::KnowledgeLayer::Team,\n                mk_core::types::KnowledgeLayer::Project,\n            ];\n        } else {\n            for l in \u0026p.layers {\n                let layer = match l.to_lowercase().as_str() {\n                    \"company\" =\u003e mk_core::types::KnowledgeLayer::Company,\n                    \"org\" =\u003e mk_core::types::KnowledgeLayer::Org,\n                    \"team\" =\u003e mk_core::types::KnowledgeLayer::Team,\n                    \"project\" =\u003e mk_core::types::KnowledgeLayer::Project,\n                    _ =\u003e continue\n                };\n                layers.push(layer);\n            }\n        }\n\n        let vector_results: Vec\u003cMemoryEntry\u003e = self\n            .memory_manager\n            .search_text_with_threshold(\n                ctx.clone(),\n                \u0026p.query,\n                p.limit.unwrap_or(10),\n                0.7,\n                std::collections::HashMap::new()\n            )\n            .await\n            .unwrap_or_default();\n\n        let repo_results = self\n            .repo\n            .search(ctx, \u0026p.query, layers, p.limit.unwrap_or(10))\n            .await?;\n\n        Ok(json!({\n            \"success\": true,\n            \"results\": {\n                \"semantic\": vector_results,\n                \"keyword\": repo_results\n            }\n        }))\n    }\n}\n","traces":[{"line":17,"address":[],"length":0,"stats":{"Line":19}},{"line":53,"address":[],"length":0,"stats":{"Line":23}},{"line":54,"address":[],"length":0,"stats":{"Line":23}},{"line":57,"address":[],"length":0,"stats":{"Line":5}},{"line":58,"address":[],"length":0,"stats":{"Line":5}},{"line":61,"address":[],"length":0,"stats":{"Line":5}},{"line":62,"address":[],"length":0,"stats":{"Line":5}},{"line":63,"address":[],"length":0,"stats":{"Line":5}},{"line":64,"address":[],"length":0,"stats":{"Line":5}},{"line":65,"address":[],"length":0,"stats":{"Line":10}},{"line":66,"address":[],"length":0,"stats":{"Line":10}},{"line":67,"address":[],"length":0,"stats":{"Line":10}},{"line":69,"address":[],"length":0,"stats":{"Line":5}},{"line":73,"address":[],"length":0,"stats":{"Line":2}},{"line":97,"address":[],"length":0,"stats":{"Line":18}},{"line":106,"address":[],"length":0,"stats":{"Line":23}},{"line":107,"address":[],"length":0,"stats":{"Line":23}},{"line":110,"address":[],"length":0,"stats":{"Line":5}},{"line":111,"address":[],"length":0,"stats":{"Line":5}},{"line":114,"address":[],"length":0,"stats":{"Line":5}},{"line":115,"address":[],"length":0,"stats":{"Line":5}},{"line":116,"address":[],"length":0,"stats":{"Line":5}},{"line":117,"address":[],"length":0,"stats":{"Line":5}},{"line":118,"address":[],"length":0,"stats":{"Line":10}},{"line":119,"address":[],"length":0,"stats":{"Line":10}},{"line":120,"address":[],"length":0,"stats":{"Line":10}},{"line":122,"address":[],"length":0,"stats":{"Line":5}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":19}},{"line":164,"address":[],"length":0,"stats":{"Line":23}},{"line":165,"address":[],"length":0,"stats":{"Line":23}},{"line":168,"address":[],"length":0,"stats":{"Line":5}},{"line":169,"address":[],"length":0,"stats":{"Line":5}},{"line":172,"address":[],"length":0,"stats":{"Line":5}},{"line":173,"address":[],"length":0,"stats":{"Line":5}},{"line":174,"address":[],"length":0,"stats":{"Line":5}},{"line":175,"address":[],"length":0,"stats":{"Line":5}},{"line":176,"address":[],"length":0,"stats":{"Line":10}},{"line":177,"address":[],"length":0,"stats":{"Line":20}},{"line":178,"address":[],"length":0,"stats":{"Line":10}},{"line":179,"address":[],"length":0,"stats":{"Line":10}},{"line":181,"address":[],"length":0,"stats":{"Line":5}},{"line":185,"address":[],"length":0,"stats":{"Line":2}}],"covered":42,"coverable":43},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","lib.rs"],"content":"//! # MCP Tools Interface\n//!\n//! 8 MCP tools for memory-knowledge system.\n\npub mod bridge;\npub mod governance;\npub mod knowledge;\npub mod memory;\npub mod redis_publisher;\npub mod server;\npub mod tools;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","loader.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","memory.rs"],"content":"use crate::tools::Tool;\nuse async_trait::async_trait;\nuse memory::manager::MemoryManager;\nuse mk_core::types::TenantContext;\nuse schemars::JsonSchema;\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Value, json};\nuse std::sync::Arc;\nuse validator::Validate;\n\npub struct MemoryAddTool {\n    memory_manager: Arc\u003cMemoryManager\u003e\n}\n\nimpl MemoryAddTool {\n    pub fn new(memory_manager: Arc\u003cMemoryManager\u003e) -\u003e Self {\n        Self { memory_manager }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct MemoryAddParams {\n    pub content: String,\n    pub layer: String,\n    #[serde(default)]\n    pub metadata: serde_json::Map\u003cString, Value\u003e,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct MemorySearchParams {\n    pub query: String,\n    pub limit: Option\u003cusize\u003e,\n    pub threshold: Option\u003cf32\u003e,\n    #[serde(default)]\n    pub filters: serde_json::Map\u003cString, Value\u003e,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct MemoryDeleteParams {\n    pub memory_id: String,\n    pub layer: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Debug)]\n#[serde(rename_all = \"camelCase\")]\npub enum CloseTarget {\n    Session,\n    Agent\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct MemoryCloseParams {\n    pub id: String,\n    pub target: CloseTarget,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[async_trait]\nimpl Tool for MemoryAddTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"memory_add\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Store a piece of information in memory for future reference.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"content\": { \"type\": \"string\" },\n                \"layer\": { \"type\": \"string\" },\n                \"metadata\": { \"type\": \"object\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"content\", \"layer\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: MemoryAddParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let layer = match p.layer.to_lowercase().as_str() {\n            \"agent\" =\u003e mk_core::types::MemoryLayer::Agent,\n            \"user\" =\u003e mk_core::types::MemoryLayer::User,\n            \"session\" =\u003e mk_core::types::MemoryLayer::Session,\n            \"project\" =\u003e mk_core::types::MemoryLayer::Project,\n            \"team\" =\u003e mk_core::types::MemoryLayer::Team,\n            \"org\" =\u003e mk_core::types::MemoryLayer::Org,\n            \"company\" =\u003e mk_core::types::MemoryLayer::Company,\n            _ =\u003e return Err(format!(\"Unknown layer: {}\", p.layer).into())\n        };\n        let entry = mk_core::types::MemoryEntry {\n            id: uuid::Uuid::new_v4().to_string(),\n            content: p.content,\n            embedding: None,\n            layer,\n            metadata: p.metadata.into_iter().collect(),\n            created_at: chrono::Utc::now().timestamp(),\n            updated_at: chrono::Utc::now().timestamp()\n        };\n\n        let id = self.memory_manager.add_to_layer(ctx, layer, entry).await?;\n        Ok(json!({ \"success\": true, \"memoryId\": id }))\n    }\n}\n\npub struct MemorySearchTool {\n    memory_manager: Arc\u003cMemoryManager\u003e\n}\n\nimpl MemorySearchTool {\n    pub fn new(memory_manager: Arc\u003cMemoryManager\u003e) -\u003e Self {\n        Self { memory_manager }\n    }\n}\n\n#[async_trait]\nimpl Tool for MemorySearchTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"memory_search\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Search for memories across layers.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": { \"type\": \"string\" },\n                \"limit\": { \"type\": \"integer\" },\n                \"threshold\": { \"type\": \"number\" },\n                \"filters\": { \"type\": \"object\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"query\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: MemorySearchParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let limit = p.limit.unwrap_or(10);\n        let threshold = p.threshold.unwrap_or(0.0);\n        let filters: std::collections::HashMap\u003cString, Value\u003e = p.filters.into_iter().collect();\n\n        let results = self\n            .memory_manager\n            .search_text_with_threshold(ctx, \u0026p.query, limit, threshold, filters)\n            .await?;\n\n        Ok(json!({\n            \"success\": true,\n            \"results\": results,\n            \"totalCount\": results.len()\n        }))\n    }\n}\n\npub struct MemoryDeleteTool {\n    memory_manager: Arc\u003cMemoryManager\u003e\n}\n\nimpl MemoryDeleteTool {\n    pub fn new(memory_manager: Arc\u003cMemoryManager\u003e) -\u003e Self {\n        Self { memory_manager }\n    }\n}\n\n#[async_trait]\nimpl Tool for MemoryDeleteTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"memory_delete\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Delete a memory from a specific layer.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"id\": { \"type\": \"string\" },\n                \"layer\": { \"type\": \"string\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"id\", \"layer\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: MemoryDeleteParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let layer = match p.layer.to_lowercase().as_str() {\n            \"agent\" =\u003e mk_core::types::MemoryLayer::Agent,\n            \"user\" =\u003e mk_core::types::MemoryLayer::User,\n            \"session\" =\u003e mk_core::types::MemoryLayer::Session,\n            \"project\" =\u003e mk_core::types::MemoryLayer::Project,\n            \"team\" =\u003e mk_core::types::MemoryLayer::Team,\n            \"org\" =\u003e mk_core::types::MemoryLayer::Org,\n            \"company\" =\u003e mk_core::types::MemoryLayer::Company,\n            _ =\u003e return Err(format!(\"Unknown layer: {}\", p.layer).into())\n        };\n        self.memory_manager\n            .delete_from_layer(ctx, layer, \u0026p.memory_id)\n            .await?;\n        Ok(json!({ \"success\": true }))\n    }\n}\n\npub struct MemoryCloseTool {\n    memory_manager: Arc\u003cMemoryManager\u003e\n}\n\nimpl MemoryCloseTool {\n    pub fn new(memory_manager: Arc\u003cMemoryManager\u003e) -\u003e Self {\n        Self { memory_manager }\n    }\n}\n\n#[async_trait]\nimpl Tool for MemoryCloseTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"memory_close\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Close a session or agent, triggering memory promotion and cleanup.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"id\": { \"type\": \"string\", \"description\": \"Session or Agent ID\" },\n                \"target\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"session\", \"agent\"],\n                    \"description\": \"What to close\"\n                },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"id\", \"target\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: MemoryCloseParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        match p.target {\n            CloseTarget::Session =\u003e self.memory_manager.close_session(ctx, \u0026p.id).await?,\n            CloseTarget::Agent =\u003e self.memory_manager.close_agent(ctx, \u0026p.id).await?\n        }\n\n        Ok(json!({\n            \"success\": true,\n            \"message\": format!(\"{:?} closed successfully\", p.target)\n        }))\n    }\n}\n","traces":[{"line":16,"address":[],"length":0,"stats":{"Line":19}},{"line":67,"address":[],"length":0,"stats":{"Line":23}},{"line":68,"address":[],"length":0,"stats":{"Line":23}},{"line":71,"address":[],"length":0,"stats":{"Line":5}},{"line":72,"address":[],"length":0,"stats":{"Line":5}},{"line":75,"address":[],"length":0,"stats":{"Line":5}},{"line":76,"address":[],"length":0,"stats":{"Line":5}},{"line":77,"address":[],"length":0,"stats":{"Line":5}},{"line":78,"address":[],"length":0,"stats":{"Line":5}},{"line":79,"address":[],"length":0,"stats":{"Line":10}},{"line":80,"address":[],"length":0,"stats":{"Line":10}},{"line":81,"address":[],"length":0,"stats":{"Line":10}},{"line":82,"address":[],"length":0,"stats":{"Line":10}},{"line":84,"address":[],"length":0,"stats":{"Line":5}},{"line":88,"address":[],"length":0,"stats":{"Line":4}},{"line":124,"address":[],"length":0,"stats":{"Line":19}},{"line":131,"address":[],"length":0,"stats":{"Line":23}},{"line":132,"address":[],"length":0,"stats":{"Line":23}},{"line":135,"address":[],"length":0,"stats":{"Line":5}},{"line":136,"address":[],"length":0,"stats":{"Line":5}},{"line":139,"address":[],"length":0,"stats":{"Line":5}},{"line":140,"address":[],"length":0,"stats":{"Line":5}},{"line":141,"address":[],"length":0,"stats":{"Line":5}},{"line":142,"address":[],"length":0,"stats":{"Line":5}},{"line":143,"address":[],"length":0,"stats":{"Line":10}},{"line":144,"address":[],"length":0,"stats":{"Line":10}},{"line":145,"address":[],"length":0,"stats":{"Line":10}},{"line":146,"address":[],"length":0,"stats":{"Line":10}},{"line":147,"address":[],"length":0,"stats":{"Line":10}},{"line":149,"address":[],"length":0,"stats":{"Line":5}},{"line":153,"address":[],"length":0,"stats":{"Line":2}},{"line":181,"address":[],"length":0,"stats":{"Line":19}},{"line":188,"address":[],"length":0,"stats":{"Line":23}},{"line":189,"address":[],"length":0,"stats":{"Line":23}},{"line":192,"address":[],"length":0,"stats":{"Line":5}},{"line":193,"address":[],"length":0,"stats":{"Line":5}},{"line":196,"address":[],"length":0,"stats":{"Line":5}},{"line":197,"address":[],"length":0,"stats":{"Line":5}},{"line":198,"address":[],"length":0,"stats":{"Line":5}},{"line":199,"address":[],"length":0,"stats":{"Line":5}},{"line":200,"address":[],"length":0,"stats":{"Line":10}},{"line":201,"address":[],"length":0,"stats":{"Line":10}},{"line":202,"address":[],"length":0,"stats":{"Line":10}},{"line":204,"address":[],"length":0,"stats":{"Line":5}},{"line":208,"address":[],"length":0,"stats":{"Line":1}},{"line":236,"address":[],"length":0,"stats":{"Line":18}},{"line":243,"address":[],"length":0,"stats":{"Line":23}},{"line":244,"address":[],"length":0,"stats":{"Line":23}},{"line":247,"address":[],"length":0,"stats":{"Line":5}},{"line":248,"address":[],"length":0,"stats":{"Line":5}},{"line":251,"address":[],"length":0,"stats":{"Line":5}},{"line":252,"address":[],"length":0,"stats":{"Line":5}},{"line":253,"address":[],"length":0,"stats":{"Line":5}},{"line":254,"address":[],"length":0,"stats":{"Line":5}},{"line":255,"address":[],"length":0,"stats":{"Line":15}},{"line":256,"address":[],"length":0,"stats":{"Line":5}},{"line":257,"address":[],"length":0,"stats":{"Line":5}},{"line":258,"address":[],"length":0,"stats":{"Line":5}},{"line":259,"address":[],"length":0,"stats":{"Line":5}},{"line":261,"address":[],"length":0,"stats":{"Line":10}},{"line":263,"address":[],"length":0,"stats":{"Line":5}},{"line":267,"address":[],"length":0,"stats":{"Line":0}}],"covered":61,"coverable":62},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","opencode.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","pointer.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","pool.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","postgres.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","procedural.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","providers.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","qdrant.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","redis.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","redis_publisher.rs"],"content":"use mk_core::types::{GovernanceEvent, TenantId};\nuse tokio::sync::mpsc::UnboundedReceiver;\nuse tracing::{error, info};\n\n/// Redis publisher for governance events with tenant isolation.\n///\n/// Listens for governance events on a channel and publishes them to Redis\n/// Streams with per-tenant isolation. Routes events to the correct\n/// tenant stream based on the tenant_id in each event.\npub struct RedisPublisher {\n    redis_url: String,\n    base_stream_key: String,\n}\n\nimpl RedisPublisher {\n    /// Creates a new Redis publisher with tenant isolation.\n    ///\n    /// Events will be published to streams named\n    /// `{base_stream_key}:{tenant_id}`.\n    pub fn new_with_tenant_isolation(redis_url: String, base_stream_key: String) -\u003e Self {\n        Self {\n            redis_url,\n            base_stream_key,\n        }\n    }\n\n    /// Creates a new Redis publisher for a specific tenant (legacy API).\n    pub fn new_for_tenant(redis_url: String, tenant_id: \u0026TenantId) -\u003e Self {\n        let base_stream_key = format!(\"governance:events:{}\", tenant_id.as_str());\n        Self {\n            redis_url,\n            base_stream_key,\n        }\n    }\n\n    /// Creates a new Redis publisher with a custom stream key (no tenant\n    /// isolation).\n    pub fn new(redis_url: String, stream_key: String) -\u003e Self {\n        Self {\n            redis_url,\n            base_stream_key: stream_key,\n        }\n    }\n\n    /// Starts the Redis publisher task.\n    ///\n    /// This spawns a Tokio task that listens for events and publishes them to\n    /// Redis. Returns a channel sender that can be used to send events.\n    pub fn start(\n        self,\n    ) -\u003e (\n        tokio::sync::mpsc::UnboundedSender\u003cGovernanceEvent\u003e,\n        tokio::task::JoinHandle\u003c()\u003e,\n    ) {\n        let (event_tx, event_rx) = tokio::sync::mpsc::unbounded_channel();\n\n        let handle = tokio::spawn(async move {\n            if let Err(e) = self.run(event_rx).await {\n                error!(\"Redis publisher task failed: {}\", e);\n            }\n        });\n\n        (event_tx, handle)\n    }\n\n    /// Main loop for the Redis publisher.\n    async fn run(\n        self,\n        mut event_rx: UnboundedReceiver\u003cGovernanceEvent\u003e,\n    ) -\u003e Result\u003c(), anyhow::Error\u003e {\n        info!(\n            \"Starting Redis publisher with tenant isolation, base stream: {}\",\n            self.base_stream_key\n        );\n\n        let redis_url = self.redis_url.clone();\n        let base_stream_key = self.base_stream_key.clone();\n\n        let client = redis::Client::open(redis_url)?;\n        let mut con = client.get_connection_manager().await?;\n\n        while let Some(event) = event_rx.recv().await {\n            match Self::publish_event(\u0026base_stream_key, \u0026mut con, \u0026event).await {\n                Ok(_) =\u003e {\n                    info!(\"Published governance event: {:?}\", event);\n                }\n                Err(e) =\u003e {\n                    error!(\"Failed to publish event to Redis: {}\", e);\n                }\n            }\n        }\n\n        info!(\"Redis publisher shutting down\");\n        Ok(())\n    }\n\n    /// Publishes a single event to the appropriate tenant stream.\n    async fn publish_event(\n        base_stream_key: \u0026str,\n        con: \u0026mut redis::aio::ConnectionManager,\n        event: \u0026GovernanceEvent,\n    ) -\u003e Result\u003c(), anyhow::Error\u003e {\n        let tenant_id = match event {\n            GovernanceEvent::UnitCreated { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::UnitUpdated { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::UnitDeleted { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::PolicyUpdated { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::PolicyDeleted { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::RoleAssigned { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::RoleRemoved { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::DriftDetected { tenant_id, .. } =\u003e tenant_id,\n        };\n\n        let stream_key = format!(\"{}:{}\", base_stream_key, tenant_id.as_str());\n\n        println!(\"DEBUG: Publishing to stream key: {}\", stream_key);\n        let event_json = serde_json::to_string(event)?;\n\n        let _: String = redis::cmd(\"XADD\")\n            .arg(\u0026stream_key)\n            .arg(\"*\")\n            .arg(\"event\")\n            .arg(\u0026event_json)\n            .query_async(con)\n            .await?;\n\n        Ok(())\n    }\n}\n\n/// Creates a Redis publisher with tenant isolation and returns the event\n/// channel sender.\n///\n/// Events will be routed to per-tenant streams:\n/// `governance:events:{tenant_id}`. Caller should use the returned sender to\n/// create GovernanceEngine: ```rust\n/// let (event_tx, publisher_handle) =\n///     create_redis_publisher_with_tenant_isolation(\"redis://localhost:6379\".\n/// to_string()); let governance_engine =\n/// GovernanceEngine::new().with_events(event_tx); ```\npub fn create_redis_publisher_with_tenant_isolation(\n    redis_url: String,\n) -\u003e (\n    tokio::sync::mpsc::UnboundedSender\u003cGovernanceEvent\u003e,\n    tokio::task::JoinHandle\u003c()\u003e,\n) {\n    let publisher =\n        RedisPublisher::new_with_tenant_isolation(redis_url, \"governance:events\".to_string());\n    publisher.start()\n}\n\n/// Creates a Redis publisher for a specific tenant (legacy API).\npub fn create_redis_publisher_for_tenant(\n    redis_url: String,\n    tenant_id: \u0026TenantId,\n) -\u003e (\n    tokio::sync::mpsc::UnboundedSender\u003cGovernanceEvent\u003e,\n    tokio::task::JoinHandle\u003c()\u003e,\n) {\n    let publisher = RedisPublisher::new_for_tenant(redis_url, tenant_id);\n    publisher.start()\n}\n\n/// Creates a Redis publisher with a custom stream key (no tenant isolation).\npub fn create_redis_publisher(\n    redis_url: String,\n    stream_key: String,\n) -\u003e (\n    tokio::sync::mpsc::UnboundedSender\u003cGovernanceEvent\u003e,\n    tokio::task::JoinHandle\u003c()\u003e,\n) {\n    let publisher = RedisPublisher::new(redis_url, stream_key);\n    publisher.start()\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::{KnowledgeLayer, Role, UnitType, UserId};\n\n    #[test]\n    fn test_redis_publisher_tenant_isolation() {\n        let tenant_id1 = TenantId::new(\"tenant-1\".to_string()).unwrap();\n        let tenant_id2 = TenantId::new(\"tenant-2\".to_string()).unwrap();\n\n        let publisher = RedisPublisher::new_with_tenant_isolation(\n            \"redis://localhost:6379\".to_string(),\n            \"governance:events\".to_string(),\n        );\n\n        let event1 = GovernanceEvent::UnitCreated {\n            unit_id: \"unit-1\".to_string(),\n            unit_type: UnitType::Company,\n            tenant_id: tenant_id1.clone(),\n            parent_id: None,\n            timestamp: 1234567890,\n        };\n\n        let event2 = GovernanceEvent::UnitCreated {\n            unit_id: \"unit-2\".to_string(),\n            unit_type: UnitType::Team,\n            tenant_id: tenant_id2.clone(),\n            parent_id: Some(\"unit-1\".to_string()),\n            timestamp: 1234567891,\n        };\n\n        let _legacy_publisher =\n            RedisPublisher::new_for_tenant(\"redis://localhost:6379\".to_string(), \u0026tenant_id1);\n\n        assert!(true);\n    }\n\n    #[test]\n    fn test_event_tenant_id_extraction() {\n        let tenant_id = TenantId::new(\"test-tenant\".to_string()).unwrap();\n        let user_id = UserId::new(\"user-1\".to_string()).unwrap();\n\n        let events = vec![\n            GovernanceEvent::UnitCreated {\n                unit_id: \"unit-1\".to_string(),\n                unit_type: UnitType::Company,\n                tenant_id: tenant_id.clone(),\n                parent_id: None,\n                timestamp: 1234567890,\n            },\n            GovernanceEvent::PolicyUpdated {\n                policy_id: \"policy-1\".to_string(),\n                layer: KnowledgeLayer::Company,\n                tenant_id: tenant_id.clone(),\n                timestamp: 1234567891,\n            },\n            GovernanceEvent::RoleAssigned {\n                user_id: user_id.clone(),\n                unit_id: \"unit-1\".to_string(),\n                role: Role::Admin,\n                tenant_id: tenant_id.clone(),\n                timestamp: 1234567892,\n            },\n            GovernanceEvent::DriftDetected {\n                project_id: \"project-1\".to_string(),\n                tenant_id: tenant_id.clone(),\n                drift_score: 0.5,\n                timestamp: 1234567893,\n            },\n        ];\n\n        for event in events {\n            let extracted_tenant_id = match \u0026event {\n                GovernanceEvent::UnitCreated { tenant_id, .. } =\u003e tenant_id,\n                GovernanceEvent::UnitUpdated { tenant_id, .. } =\u003e tenant_id,\n                GovernanceEvent::UnitDeleted { tenant_id, .. } =\u003e tenant_id,\n                GovernanceEvent::PolicyUpdated { tenant_id, .. } =\u003e tenant_id,\n                GovernanceEvent::PolicyDeleted { tenant_id, .. } =\u003e tenant_id,\n                GovernanceEvent::RoleAssigned { tenant_id, .. } =\u003e tenant_id,\n                GovernanceEvent::RoleRemoved { tenant_id, .. } =\u003e tenant_id,\n                GovernanceEvent::DriftDetected { tenant_id, .. } =\u003e tenant_id,\n            };\n            assert_eq!(extracted_tenant_id, \u0026tenant_id);\n        }\n    }\n}\n","traces":[{"line":20,"address":[],"length":0,"stats":{"Line":3}},{"line":28,"address":[],"length":0,"stats":{"Line":2}},{"line":29,"address":[],"length":0,"stats":{"Line":10}},{"line":38,"address":[],"length":0,"stats":{"Line":1}},{"line":49,"address":[],"length":0,"stats":{"Line":4}},{"line":55,"address":[],"length":0,"stats":{"Line":12}},{"line":57,"address":[],"length":0,"stats":{"Line":9}},{"line":58,"address":[],"length":0,"stats":{"Line":4}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":4}},{"line":67,"address":[],"length":0,"stats":{"Line":1}},{"line":71,"address":[],"length":0,"stats":{"Line":1}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":3}},{"line":77,"address":[],"length":0,"stats":{"Line":3}},{"line":79,"address":[],"length":0,"stats":{"Line":3}},{"line":80,"address":[],"length":0,"stats":{"Line":3}},{"line":82,"address":[],"length":0,"stats":{"Line":7}},{"line":83,"address":[],"length":0,"stats":{"Line":5}},{"line":85,"address":[],"length":0,"stats":{"Line":1}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":1}},{"line":103,"address":[],"length":0,"stats":{"Line":2}},{"line":104,"address":[],"length":0,"stats":{"Line":2}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":5}},{"line":116,"address":[],"length":0,"stats":{"Line":2}},{"line":117,"address":[],"length":0,"stats":{"Line":3}},{"line":119,"address":[],"length":0,"stats":{"Line":5}},{"line":120,"address":[],"length":0,"stats":{"Line":3}},{"line":123,"address":[],"length":0,"stats":{"Line":2}},{"line":124,"address":[],"length":0,"stats":{"Line":2}},{"line":125,"address":[],"length":0,"stats":{"Line":1}},{"line":127,"address":[],"length":0,"stats":{"Line":1}},{"line":141,"address":[],"length":0,"stats":{"Line":1}},{"line":147,"address":[],"length":0,"stats":{"Line":1}},{"line":148,"address":[],"length":0,"stats":{"Line":4}},{"line":149,"address":[],"length":0,"stats":{"Line":2}},{"line":153,"address":[],"length":0,"stats":{"Line":1}},{"line":160,"address":[],"length":0,"stats":{"Line":4}},{"line":161,"address":[],"length":0,"stats":{"Line":2}},{"line":165,"address":[],"length":0,"stats":{"Line":1}},{"line":172,"address":[],"length":0,"stats":{"Line":4}},{"line":173,"address":[],"length":0,"stats":{"Line":2}}],"covered":40,"coverable":53},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","repository.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","server.rs"],"content":"use crate::bridge::{ResolveFederationConflictTool, SyncNowTool, SyncStatusTool};\nuse crate::governance::{\n    HierarchyNavigateTool, UnitCreateTool, UnitPolicyAddTool, UserRoleAssignTool,\n    UserRoleRemoveTool,\n};\nuse crate::knowledge::{KnowledgeGetTool, KnowledgeListTool, KnowledgeQueryTool};\nuse crate::memory::{MemoryAddTool, MemoryCloseTool, MemoryDeleteTool, MemorySearchTool};\nuse crate::tools::{ToolDefinition, ToolRegistry};\nuse knowledge::governance::GovernanceEngine;\nuse memory::manager::MemoryManager;\nuse mk_core::traits::{AuthorizationService, EventPublisher, KnowledgeRepository};\nuse serde::{Deserialize, Serialize};\nuse serde_json::Value;\nuse std::sync::Arc;\nuse std::time::Duration;\nuse storage::events::EventError;\nuse sync::bridge::SyncManager;\nuse tokio::time::timeout;\nuse tracing::{Span, debug, error, info, instrument};\n\n/// MCP JSON-RPC server for tool orchestration.\n///\n/// Handles tool discovery and execution with integrated timeouts and tracing.\npub struct McpServer {\n    registry: ToolRegistry,\n    auth_service: Arc\u003cdyn AuthorizationService\u003cError = anyhow::Error\u003e\u003e,\n    event_publisher: Option\u003cArc\u003cdyn EventPublisher\u003cError = EventError\u003e\u003e\u003e,\n    timeout_duration: Duration,\n}\n\nimpl McpServer {\n    /// Creates a new McpServer with initialized core tools.\n    pub fn new(\n        memory_manager: Arc\u003cMemoryManager\u003e,\n        sync_manager: Arc\u003cSyncManager\u003e,\n        knowledge_repository: Arc\u003c\n            dyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e,\n        \u003e,\n        storage_backend: Arc\u003c\n            dyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e,\n        \u003e,\n        governance_engine: Arc\u003cGovernanceEngine\u003e,\n        auth_service: Arc\u003cdyn AuthorizationService\u003cError = anyhow::Error\u003e\u003e,\n        event_publisher: Option\u003cArc\u003cdyn EventPublisher\u003cError = EventError\u003e\u003e\u003e,\n    ) -\u003e Self {\n        let mut registry = ToolRegistry::new();\n\n        registry.register(Box::new(MemoryAddTool::new(memory_manager.clone())));\n        registry.register(Box::new(MemorySearchTool::new(memory_manager.clone())));\n        registry.register(Box::new(MemoryDeleteTool::new(memory_manager.clone())));\n        registry.register(Box::new(MemoryCloseTool::new(memory_manager.clone())));\n\n        registry.register(Box::new(KnowledgeGetTool::new(\n            knowledge_repository.clone(),\n        )));\n        registry.register(Box::new(KnowledgeListTool::new(\n            knowledge_repository.clone(),\n        )));\n        registry.register(Box::new(KnowledgeQueryTool::new(\n            memory_manager.clone(),\n            knowledge_repository.clone(),\n        )));\n\n        registry.register(Box::new(SyncNowTool::new(sync_manager.clone())));\n        registry.register(Box::new(SyncStatusTool::new(sync_manager.clone())));\n        registry.register(Box::new(ResolveFederationConflictTool::new(sync_manager)));\n\n        registry.register(Box::new(UnitCreateTool::new(\n            storage_backend.clone(),\n            governance_engine.clone(),\n        )));\n        registry.register(Box::new(UnitPolicyAddTool::new(\n            storage_backend.clone(),\n            governance_engine.clone(),\n        )));\n        registry.register(Box::new(UserRoleAssignTool::new(\n            storage_backend.clone(),\n            governance_engine.clone(),\n        )));\n        registry.register(Box::new(UserRoleRemoveTool::new(\n            storage_backend.clone(),\n            governance_engine,\n        )));\n        registry.register(Box::new(HierarchyNavigateTool::new(storage_backend)));\n\n        Self {\n            registry,\n            auth_service,\n            event_publisher,\n            timeout_duration: Duration::from_secs(30),\n        }\n    }\n\n    pub fn with_timeout(mut self, duration: Duration) -\u003e Self {\n        self.timeout_duration = duration;\n        self\n    }\n\n    pub fn registry(\u0026self) -\u003e \u0026ToolRegistry {\n        \u0026self.registry\n    }\n\n    pub fn list_tools(\u0026self) -\u003e Vec\u003cToolDefinition\u003e {\n        self.registry.list_tools()\n    }\n\n    #[instrument(skip(self, request), fields(method = %request.method, request_id = ?request.id))]\n    pub async fn handle_request(\u0026self, request: JsonRpcRequest) -\u003e JsonRpcResponse {\n        debug!(method = %request.method, \"Handling JSON-RPC request\");\n\n        let timeout_duration = self.timeout_duration;\n\n        let result = timeout(timeout_duration, self.dispatch(request)).await;\n\n        match result {\n            Ok(response) =\u003e response,\n            Err(_) =\u003e {\n                error!(\"Request timed out\");\n                JsonRpcResponse {\n                    jsonrpc: \"2.0\".to_string(),\n                    id: Value::Null,\n                    result: None,\n                    error: Some(JsonRpcError::request_timeout(\"Request timed out\")),\n                }\n            }\n        }\n    }\n\n    async fn dispatch(\u0026self, request: JsonRpcRequest) -\u003e JsonRpcResponse {\n        match request.method.as_str() {\n            \"initialize\" =\u003e JsonRpcResponse {\n                jsonrpc: \"2.0\".to_string(),\n                id: request.id,\n                result: Some(serde_json::json!({\n                    \"protocolVersion\": \"2024-11-05\",\n                    \"capabilities\": {\n                        \"tools\": {\n                            \"listChanged\": false\n                        }\n                    },\n                    \"serverInfo\": {\n                        \"name\": \"aeterna-tools\",\n                        \"version\": \"0.1.0\"\n                    }\n                })),\n                error: None,\n            },\n            \"tools/list\" =\u003e {\n                let tools = self.registry.list_tools();\n                JsonRpcResponse {\n                    jsonrpc: \"2.0\".to_string(),\n                    id: request.id,\n                    result: Some(serde_json::to_value(tools).unwrap()),\n                    error: None,\n                }\n            }\n            \"tools/call\" =\u003e {\n                let params = match request.params {\n                    Some(p) =\u003e p,\n                    None =\u003e {\n                        return JsonRpcResponse {\n                            jsonrpc: \"2.0\".to_string(),\n                            id: request.id,\n                            result: None,\n                            error: Some(JsonRpcError::invalid_params(\"Invalid params\")),\n                        };\n                    }\n                };\n\n                let tenant_context: mk_core::types::TenantContext =\n                    match serde_json::from_value(params[\"tenantContext\"].clone()) {\n                        Ok(ctx) =\u003e ctx,\n                        Err(_) =\u003e {\n                            return JsonRpcResponse {\n                                jsonrpc: \"2.0\".to_string(),\n                                id: request.id,\n                                result: None,\n                                error: Some(JsonRpcError::invalid_params(\n                                    \"Missing or invalid tenant context\",\n                                )),\n                            };\n                        }\n                    };\n\n                let (name, tool_params) = match self.extract_call_params(\u0026params, \u0026tenant_context) {\n                    Ok(res) =\u003e res,\n                    Err(e) =\u003e {\n                        return JsonRpcResponse {\n                            jsonrpc: \"2.0\".to_string(),\n                            id: request.id,\n                            result: None,\n                            error: Some(JsonRpcError::invalid_params(e)),\n                        };\n                    }\n                };\n\n                Span::current().record(\"tool_name\", \u0026name);\n                info!(tool = %name, \"Calling tool\");\n\n                let auth_result = self\n                    .auth_service\n                    .check_permission(\u0026tenant_context, \"call_tool\", \u0026name)\n                    .await;\n\n                match auth_result {\n                    Ok(allowed) =\u003e {\n                        if !allowed {\n                            error!(tool = %name, \"Authorization denied\");\n                            return JsonRpcResponse {\n                                jsonrpc: \"2.0\".to_string(),\n                                id: request.id,\n                                result: None,\n                                error: Some(JsonRpcError {\n                                    code: -32002,\n                                    message: format!(\n                                        \"Authorization error: access denied for tool {}\",\n                                        name\n                                    ),\n                                    data: None,\n                                }),\n                            };\n                        }\n                    }\n                    Err(e) =\u003e {\n                        error!(tool = %name, error = %e, \"Authorization check failed\");\n                        return JsonRpcResponse {\n                            jsonrpc: \"2.0\".to_string(),\n                            id: request.id,\n                            result: None,\n                            error: Some(JsonRpcError {\n                                code: -32002,\n                                message: format!(\"Authorization error: {}\", e),\n                                data: None,\n                            }),\n                        };\n                    }\n                }\n\n                let call_result = self.registry.call(\u0026name, tool_params).await;\n\n                match call_result {\n                    Ok(result) =\u003e {\n                        info!(tool = %name, \"Tool call successful\");\n\n                        if let Some(ref publisher) = self.event_publisher {\n                            let timestamp = chrono::Utc::now().timestamp();\n                            let event = match name.as_str() {\n                                \"unit_create\" =\u003e {\n                                    Some(mk_core::types::GovernanceEvent::UnitCreated {\n                                        unit_id: result[\"unit_id\"]\n                                            .as_str()\n                                            .unwrap_or_default()\n                                            .to_string(),\n                                        unit_type: serde_json::from_value(\n                                            result[\"unit_type\"].clone(),\n                                        )\n                                        .unwrap_or(mk_core::types::UnitType::Project),\n                                        tenant_id: tenant_context.tenant_id.clone(),\n                                        parent_id: result[\"parent_id\"]\n                                            .as_str()\n                                            .map(|s| s.to_string()),\n                                        timestamp,\n                                    })\n                                }\n                                \"role_assign\" =\u003e {\n                                    Some(mk_core::types::GovernanceEvent::RoleAssigned {\n                                        user_id: serde_json::from_value(result[\"user_id\"].clone())\n                                            .unwrap_or_default(),\n                                        unit_id: result[\"unit_id\"]\n                                            .as_str()\n                                            .unwrap_or_default()\n                                            .to_string(),\n                                        role: serde_json::from_value(result[\"role\"].clone())\n                                            .unwrap_or(mk_core::types::Role::Developer),\n                                        tenant_id: tenant_context.tenant_id.clone(),\n                                        timestamp,\n                                    })\n                                }\n                                \"role_remove\" =\u003e {\n                                    Some(mk_core::types::GovernanceEvent::RoleRemoved {\n                                        user_id: serde_json::from_value(result[\"user_id\"].clone())\n                                            .unwrap_or_default(),\n                                        unit_id: result[\"unit_id\"]\n                                            .as_str()\n                                            .unwrap_or_default()\n                                            .to_string(),\n                                        role: serde_json::from_value(result[\"role\"].clone())\n                                            .unwrap_or(mk_core::types::Role::Developer),\n                                        tenant_id: tenant_context.tenant_id.clone(),\n                                        timestamp,\n                                    })\n                                }\n                                \"unit_policy_add\" =\u003e {\n                                    Some(mk_core::types::GovernanceEvent::PolicyUpdated {\n                                        policy_id: result[\"policy_id\"]\n                                            .as_str()\n                                            .unwrap_or_default()\n                                            .to_string(),\n                                        layer: serde_json::from_value(result[\"layer\"].clone())\n                                            .unwrap_or(mk_core::types::KnowledgeLayer::Project),\n                                        tenant_id: tenant_context.tenant_id.clone(),\n                                        timestamp,\n                                    })\n                                }\n                                _ =\u003e None,\n                            };\n\n                            if let Some(event) = event {\n                                if let Err(e) = publisher.publish(event).await {\n                                    error!(error = %e, \"Failed to publish governance event\");\n                                }\n                            }\n                        }\n\n                        JsonRpcResponse {\n                            jsonrpc: \"2.0\".to_string(),\n                            id: request.id,\n                            result: Some(result),\n                            error: None,\n                        }\n                    }\n                    Err(e) =\u003e {\n                        let error_str = e.to_string();\n                        error!(tool = %name, error = %error_str, \"Tool call failed\");\n                        let rpc_error = if error_str.contains(\"not found\") {\n                            JsonRpcError::method_not_found(error_str)\n                        } else if e.is::\u003cserde_json::Error\u003e()\n                            || error_str.contains(\"Validation error\")\n                        {\n                            JsonRpcError::invalid_params(error_str)\n                        } else {\n                            JsonRpcError::internal_error(error_str)\n                        };\n\n                        JsonRpcResponse {\n                            jsonrpc: \"2.0\".to_string(),\n                            id: request.id,\n                            result: None,\n                            error: Some(rpc_error),\n                        }\n                    }\n                }\n            }\n            _ =\u003e {\n                debug!(method = %request.method, \"Method not found\");\n                JsonRpcResponse {\n                    jsonrpc: \"2.0\".to_string(),\n                    id: request.id,\n                    result: None,\n                    error: Some(JsonRpcError::method_not_found(\"Method not found\")),\n                }\n            }\n        }\n    }\n\n    fn extract_call_params(\n        \u0026self,\n        params: \u0026Value,\n        tenant_context: \u0026mk_core::types::TenantContext,\n    ) -\u003e Result\u003c(String, Value), String\u003e {\n        let name = match params[\"name\"].as_str() {\n            Some(n) =\u003e n.to_string(),\n            None =\u003e return Err(\"Missing tool name\".to_string()),\n        };\n\n        let mut tool_params = params[\"arguments\"].clone();\n        if tool_params.is_null() {\n            tool_params = serde_json::json!({});\n        }\n\n        if let Some(obj) = tool_params.as_object_mut() {\n            obj.insert(\n                \"tenant_context\".to_string(),\n                serde_json::to_value(tenant_context).unwrap(),\n            );\n            obj.insert(\n                \"tenantContext\".to_string(),\n                serde_json::to_value(tenant_context).unwrap(),\n            );\n        } else {\n            tool_params = serde_json::json!({\n                \"tenant_context\": tenant_context,\n                \"tenantContext\": tenant_context\n            });\n        }\n\n        Ok((name, tool_params))\n    }\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct JsonRpcResponse {\n    pub jsonrpc: String,\n    pub id: Value,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub result: Option\u003cValue\u003e,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub error: Option\u003cJsonRpcError\u003e,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct JsonRpcError {\n    pub code: i32,\n    pub message: String,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub data: Option\u003cValue\u003e,\n}\n\nimpl JsonRpcError {\n    pub fn invalid_params(message: impl Into\u003cString\u003e) -\u003e Self {\n        Self {\n            code: -32602,\n            message: message.into(),\n            data: None,\n        }\n    }\n\n    pub fn method_not_found(message: impl Into\u003cString\u003e) -\u003e Self {\n        Self {\n            code: -32601,\n            message: message.into(),\n            data: None,\n        }\n    }\n\n    pub fn internal_error(message: impl Into\u003cString\u003e) -\u003e Self {\n        Self {\n            code: -32000,\n            message: message.into(),\n            data: None,\n        }\n    }\n\n    pub fn request_timeout(message: impl Into\u003cString\u003e) -\u003e Self {\n        Self {\n            code: -32001,\n            message: message.into(),\n            data: None,\n        }\n    }\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct JsonRpcRequest {\n    pub jsonrpc: String,\n    pub id: Value,\n    pub method: String,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub params: Option\u003cValue\u003e,\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use memory::manager::MemoryManager;\n    use mk_core::traits::KnowledgeRepository;\n    use mk_core::types::{KnowledgeEntry, KnowledgeLayer};\n    use serde_json::json;\n    use sync::bridge::SyncManager;\n    use sync::state_persister::SyncStatePersister;\n    use testcontainers::ContainerAsync;\n    use testcontainers::runners::AsyncRunner;\n    use testcontainers_modules::postgres::Postgres;\n\n    struct MockRepo;\n    #[async_trait::async_trait]\n    impl KnowledgeRepository for MockRepo {\n        type Error = knowledge::repository::RepositoryError;\n        async fn store(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: KnowledgeEntry,\n            _: \u0026str,\n        ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n            Ok(\"hash\".into())\n        }\n        async fn get(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: KnowledgeLayer,\n            _: \u0026str,\n        ) -\u003e std::result::Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(None)\n        }\n        async fn list(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: KnowledgeLayer,\n            _: \u0026str,\n        ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n        async fn delete(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: KnowledgeLayer,\n            _: \u0026str,\n            _: \u0026str,\n        ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n            Ok(\"hash\".into())\n        }\n        async fn get_head_commit(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n        ) -\u003e std::result::Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n            Ok(None)\n        }\n        async fn get_affected_items(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: \u0026str,\n        ) -\u003e std::result::Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n        async fn search(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: \u0026str,\n            _: Vec\u003cKnowledgeLayer\u003e,\n            _: usize,\n        ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n        fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n            None\n        }\n    }\n\n    struct MockPersister;\n    #[async_trait::async_trait]\n    impl SyncStatePersister for MockPersister {\n        async fn load(\n            \u0026self,\n            _tenant_id: \u0026mk_core::types::TenantId,\n        ) -\u003e std::result::Result\u003csync::state::SyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e\n        {\n            Ok(sync::state::SyncState::default())\n        }\n        async fn save(\n            \u0026self,\n            _tenant_id: \u0026mk_core::types::TenantId,\n            _: \u0026sync::state::SyncState,\n        ) -\u003e std::result::Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n            Ok(())\n        }\n    }\n\n    struct MockAuthService;\n    #[async_trait::async_trait]\n    impl mk_core::traits::AuthorizationService for MockAuthService {\n        type Error = anyhow::Error;\n        async fn check_permission(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n            _action: \u0026str,\n            _resource: \u0026str,\n        ) -\u003e anyhow::Result\u003cbool\u003e {\n            Ok(true)\n        }\n        async fn get_user_roles(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n        ) -\u003e anyhow::Result\u003cVec\u003cmk_core::types::Role\u003e\u003e {\n            Ok(vec![])\n        }\n        async fn assign_role(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n            _user_id: \u0026mk_core::types::UserId,\n            _role: mk_core::types::Role,\n        ) -\u003e anyhow::Result\u003c()\u003e {\n            Ok(())\n        }\n        async fn remove_role(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n            _user_id: \u0026mk_core::types::UserId,\n            _role: mk_core::types::Role,\n        ) -\u003e anyhow::Result\u003c()\u003e {\n            Ok(())\n        }\n    }\n\n    async fn setup_postgres_container()\n    -\u003e Result\u003c(ContainerAsync\u003cPostgres\u003e, String), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let container = Postgres::default()\n            .with_db_name(\"testdb\")\n            .with_user(\"testuser\")\n            .with_password(\"testpass\")\n            .start()\n            .await\n            .map_err(|e| Box::new(e) as Box\u003cdyn std::error::Error + Send + Sync\u003e)?;\n\n        let connection_url = format!(\n            \"postgres://testuser:testpass@localhost:{}/testdb\",\n            container\n                .get_host_port_ipv4(5432)\n                .await\n                .map_err(|e| Box::new(e) as Box\u003cdyn std::error::Error + Send + Sync\u003e)?\n        );\n\n        Ok((container, connection_url))\n    }\n\n    async fn setup_server() -\u003e McpServer {\n        let memory_manager = Arc::new(MemoryManager::new());\n        let repo = Arc::new(MockRepo);\n        let governance = Arc::new(knowledge::governance::GovernanceEngine::new());\n        let sync_manager = Arc::new(\n            SyncManager::new(\n                memory_manager.clone(),\n                repo.clone(),\n                governance.clone(),\n                config::config::DeploymentConfig::default(),\n                None,\n                Arc::new(MockPersister),\n            )\n            .await\n            .unwrap(),\n        );\n\n        let (container, connection_url) = setup_postgres_container()\n            .await\n            .expect(\"Failed to setup PostgreSQL test container. Make sure Docker is running.\");\n\n        let backend = storage::postgres::PostgresBackend::new(\u0026connection_url)\n            .await\n            .expect(\"Failed to connect to PostgreSQL test container\");\n\n        let _container = container;\n\n        McpServer::new(\n            memory_manager,\n            sync_manager,\n            repo,\n            Arc::new(backend),\n            governance,\n            Arc::new(MockAuthService),\n            None,\n        )\n    }\n\n    #[tokio::test]\n    async fn test_server_initialize() {\n        let server = setup_server().await;\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"initialize\".to_string(),\n            params: None,\n        };\n\n        let response = server.handle_request(request).await;\n        assert!(response.result.is_some());\n        let result = response.result.unwrap();\n        assert_eq!(result[\"protocolVersion\"], \"2024-11-05\");\n    }\n\n    #[tokio::test]\n    async fn test_server_list_tools() {\n        let server = setup_server().await;\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"tools/list\".to_string(),\n            params: None,\n        };\n\n        let response = server.handle_request(request).await;\n        assert!(response.result.is_some());\n        let tools = response.result.unwrap();\n        assert!(tools.as_array().unwrap().len() \u003e= 8);\n    }\n\n    #[tokio::test]\n    async fn test_server_method_not_found() {\n        let server = setup_server().await;\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"unknown_method\".to_string(),\n            params: None,\n        };\n\n        let response = server.handle_request(request).await;\n        assert!(response.error.is_some());\n        assert_eq!(response.error.unwrap().code, -32601);\n    }\n\n    #[tokio::test]\n    async fn test_server_invalid_params() {\n        let server = setup_server().await;\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"tools/call\".to_string(),\n            params: None,\n        };\n\n        let response = server.handle_request(request).await;\n        assert!(response.error.is_some());\n        assert_eq!(response.error.unwrap().code, -32602);\n    }\n\n    #[tokio::test]\n    async fn test_server_tool_not_found() {\n        let server = setup_server().await;\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"tools/call\".to_string(),\n            params: Some(json!({\n                \"tenantContext\": {\n                    \"tenant_id\": \"c1\",\n                    \"user_id\": \"u1\"\n                },\n                \"name\": \"non_existent_tool\",\n                \"arguments\": {}\n            })),\n        };\n\n        let response = server.handle_request(request).await;\n        assert!(response.error.is_some());\n        assert_eq!(response.error.unwrap().code, -32601);\n    }\n\n    #[tokio::test]\n    async fn test_extract_tenant_context() {\n        let server = setup_server().await;\n\n        let params = json!({\n            \"tenantContext\": {\n                \"tenantId\": \"company_1\",\n                \"userId\": \"user_1\"\n            },\n            \"name\": \"memory_add\",\n            \"arguments\": {\n                \"content\": \"test\"\n            }\n        });\n\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"tools/call\".to_string(),\n            params: Some(params),\n        };\n\n        let _response = server.handle_request(request).await;\n    }\n\n    #[tokio::test]\n    async fn test_extract_tenant_context_missing() {\n        let server = setup_server().await;\n\n        let params = json!({\n            \"name\": \"memory_add\",\n            \"arguments\": {\n                \"content\": \"test\"\n            }\n        });\n\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"tools/call\".to_string(),\n            params: Some(params),\n        };\n\n        let response = server.handle_request(request).await;\n        assert!(response.error.is_some());\n        let err = response.error.unwrap();\n        assert_eq!(err.code, -32602);\n        assert!(err.message.contains(\"Missing or invalid tenant context\"));\n    }\n\n    #[tokio::test]\n    async fn test_server_timeout() {\n        let server = setup_server().await.with_timeout(Duration::from_millis(1));\n\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"initialize\".to_string(),\n            params: None,\n        };\n\n        let _response = server.handle_request(request).await;\n    }\n}\n","traces":[{"line":33,"address":[],"length":0,"stats":{"Line":18}},{"line":46,"address":[],"length":0,"stats":{"Line":36}},{"line":48,"address":[],"length":0,"stats":{"Line":90}},{"line":49,"address":[],"length":0,"stats":{"Line":90}},{"line":50,"address":[],"length":0,"stats":{"Line":90}},{"line":51,"address":[],"length":0,"stats":{"Line":90}},{"line":53,"address":[],"length":0,"stats":{"Line":90}},{"line":54,"address":[],"length":0,"stats":{"Line":18}},{"line":56,"address":[],"length":0,"stats":{"Line":90}},{"line":57,"address":[],"length":0,"stats":{"Line":18}},{"line":59,"address":[],"length":0,"stats":{"Line":90}},{"line":60,"address":[],"length":0,"stats":{"Line":54}},{"line":61,"address":[],"length":0,"stats":{"Line":18}},{"line":64,"address":[],"length":0,"stats":{"Line":90}},{"line":65,"address":[],"length":0,"stats":{"Line":90}},{"line":66,"address":[],"length":0,"stats":{"Line":72}},{"line":68,"address":[],"length":0,"stats":{"Line":90}},{"line":69,"address":[],"length":0,"stats":{"Line":36}},{"line":70,"address":[],"length":0,"stats":{"Line":18}},{"line":72,"address":[],"length":0,"stats":{"Line":90}},{"line":73,"address":[],"length":0,"stats":{"Line":36}},{"line":74,"address":[],"length":0,"stats":{"Line":18}},{"line":76,"address":[],"length":0,"stats":{"Line":90}},{"line":77,"address":[],"length":0,"stats":{"Line":36}},{"line":78,"address":[],"length":0,"stats":{"Line":18}},{"line":80,"address":[],"length":0,"stats":{"Line":90}},{"line":81,"address":[],"length":0,"stats":{"Line":18}},{"line":82,"address":[],"length":0,"stats":{"Line":18}},{"line":84,"address":[],"length":0,"stats":{"Line":72}},{"line":90,"address":[],"length":0,"stats":{"Line":18}},{"line":94,"address":[],"length":0,"stats":{"Line":2}},{"line":95,"address":[],"length":0,"stats":{"Line":2}},{"line":96,"address":[],"length":0,"stats":{"Line":2}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":4}},{"line":104,"address":[],"length":0,"stats":{"Line":8}},{"line":108,"address":[],"length":0,"stats":{"Line":30}},{"line":111,"address":[],"length":0,"stats":{"Line":15}},{"line":129,"address":[],"length":0,"stats":{"Line":30}},{"line":130,"address":[],"length":0,"stats":{"Line":15}},{"line":132,"address":[],"length":0,"stats":{"Line":6}},{"line":133,"address":[],"length":0,"stats":{"Line":4}},{"line":134,"address":[],"length":0,"stats":{"Line":4}},{"line":148,"address":[],"length":0,"stats":{"Line":13}},{"line":149,"address":[],"length":0,"stats":{"Line":3}},{"line":151,"address":[],"length":0,"stats":{"Line":3}},{"line":152,"address":[],"length":0,"stats":{"Line":2}},{"line":153,"address":[],"length":0,"stats":{"Line":2}},{"line":157,"address":[],"length":0,"stats":{"Line":12}},{"line":158,"address":[],"length":0,"stats":{"Line":21}},{"line":159,"address":[],"length":0,"stats":{"Line":20}},{"line":161,"address":[],"length":0,"stats":{"Line":1}},{"line":162,"address":[],"length":0,"stats":{"Line":3}},{"line":163,"address":[],"length":0,"stats":{"Line":2}},{"line":164,"address":[],"length":0,"stats":{"Line":1}},{"line":165,"address":[],"length":0,"stats":{"Line":1}},{"line":170,"address":[],"length":0,"stats":{"Line":16}},{"line":171,"address":[],"length":0,"stats":{"Line":20}},{"line":172,"address":[],"length":0,"stats":{"Line":16}},{"line":174,"address":[],"length":0,"stats":{"Line":2}},{"line":175,"address":[],"length":0,"stats":{"Line":6}},{"line":176,"address":[],"length":0,"stats":{"Line":4}},{"line":177,"address":[],"length":0,"stats":{"Line":2}},{"line":178,"address":[],"length":0,"stats":{"Line":2}},{"line":179,"address":[],"length":0,"stats":{"Line":2}},{"line":185,"address":[],"length":0,"stats":{"Line":40}},{"line":186,"address":[],"length":0,"stats":{"Line":16}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":32}},{"line":198,"address":[],"length":0,"stats":{"Line":8}},{"line":200,"address":[],"length":0,"stats":{"Line":24}},{"line":201,"address":[],"length":0,"stats":{"Line":16}},{"line":202,"address":[],"length":0,"stats":{"Line":24}},{"line":203,"address":[],"length":0,"stats":{"Line":8}},{"line":205,"address":[],"length":0,"stats":{"Line":8}},{"line":206,"address":[],"length":0,"stats":{"Line":8}},{"line":207,"address":[],"length":0,"stats":{"Line":8}},{"line":208,"address":[],"length":0,"stats":{"Line":2}},{"line":209,"address":[],"length":0,"stats":{"Line":2}},{"line":210,"address":[],"length":0,"stats":{"Line":6}},{"line":211,"address":[],"length":0,"stats":{"Line":4}},{"line":212,"address":[],"length":0,"stats":{"Line":4}},{"line":213,"address":[],"length":0,"stats":{"Line":2}},{"line":214,"address":[],"length":0,"stats":{"Line":2}},{"line":215,"address":[],"length":0,"stats":{"Line":4}},{"line":216,"address":[],"length":0,"stats":{"Line":2}},{"line":217,"address":[],"length":0,"stats":{"Line":2}},{"line":219,"address":[],"length":0,"stats":{"Line":2}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":225,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":231,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":30}},{"line":241,"address":[],"length":0,"stats":{"Line":6}},{"line":242,"address":[],"length":0,"stats":{"Line":5}},{"line":243,"address":[],"length":0,"stats":{"Line":5}},{"line":245,"address":[],"length":0,"stats":{"Line":5}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":0}},{"line":252,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":0}},{"line":254,"address":[],"length":0,"stats":{"Line":0}},{"line":255,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":0}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":270,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":272,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":274,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":276,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":284,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":298,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":15}},{"line":317,"address":[],"length":0,"stats":{"Line":10}},{"line":318,"address":[],"length":0,"stats":{"Line":5}},{"line":322,"address":[],"length":0,"stats":{"Line":1}},{"line":323,"address":[],"length":0,"stats":{"Line":3}},{"line":324,"address":[],"length":0,"stats":{"Line":1}},{"line":325,"address":[],"length":0,"stats":{"Line":2}},{"line":326,"address":[],"length":0,"stats":{"Line":2}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":3}},{"line":337,"address":[],"length":0,"stats":{"Line":2}},{"line":339,"address":[],"length":0,"stats":{"Line":1}},{"line":345,"address":[],"length":0,"stats":{"Line":1}},{"line":347,"address":[],"length":0,"stats":{"Line":3}},{"line":348,"address":[],"length":0,"stats":{"Line":2}},{"line":350,"address":[],"length":0,"stats":{"Line":1}},{"line":356,"address":[],"length":0,"stats":{"Line":8}},{"line":361,"address":[],"length":0,"stats":{"Line":16}},{"line":362,"address":[],"length":0,"stats":{"Line":24}},{"line":363,"address":[],"length":0,"stats":{"Line":0}},{"line":366,"address":[],"length":0,"stats":{"Line":24}},{"line":367,"address":[],"length":0,"stats":{"Line":16}},{"line":368,"address":[],"length":0,"stats":{"Line":0}},{"line":371,"address":[],"length":0,"stats":{"Line":24}},{"line":372,"address":[],"length":0,"stats":{"Line":24}},{"line":373,"address":[],"length":0,"stats":{"Line":24}},{"line":374,"address":[],"length":0,"stats":{"Line":32}},{"line":376,"address":[],"length":0,"stats":{"Line":24}},{"line":377,"address":[],"length":0,"stats":{"Line":24}},{"line":378,"address":[],"length":0,"stats":{"Line":16}},{"line":381,"address":[],"length":0,"stats":{"Line":0}},{"line":382,"address":[],"length":0,"stats":{"Line":0}},{"line":383,"address":[],"length":0,"stats":{"Line":0}},{"line":387,"address":[],"length":0,"stats":{"Line":8}},{"line":410,"address":[],"length":0,"stats":{"Line":3}},{"line":412,"address":[],"length":0,"stats":{"Line":3}},{"line":413,"address":[],"length":0,"stats":{"Line":6}},{"line":418,"address":[],"length":0,"stats":{"Line":2}},{"line":420,"address":[],"length":0,"stats":{"Line":2}},{"line":421,"address":[],"length":0,"stats":{"Line":4}},{"line":426,"address":[],"length":0,"stats":{"Line":0}},{"line":428,"address":[],"length":0,"stats":{"Line":0}},{"line":429,"address":[],"length":0,"stats":{"Line":0}},{"line":434,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":0}}],"covered":125,"coverable":211},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","state.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","tools.rs"],"content":"use async_trait::async_trait;\nuse serde::{Deserialize, Serialize};\nuse serde_json::Value;\nuse std::collections::HashMap;\n\n/// Core trait for implementing MCP (Model Context Protocol) tools.\n///\n/// Tools provide a standardized interface for AI agents to interact with system\n/// capabilities. Each tool defines its name, description, input schema, and\n/// execution logic.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Defines the contract that all tools must implement to be registered and\n/// invoked through the tool registry. Enables pluggable, type-safe tool\n/// execution with JSON Schema validation.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use async_trait::async_trait;\n/// use serde_json::Value;\n/// use tools::tools::Tool;\n///\n/// struct MyCustomTool;\n///\n/// #[async_trait]\n/// impl Tool for MyCustomTool {\n///     fn name(\u0026self) -\u003e \u0026str {\n///         \"my_custom_tool\"\n///     }\n///\n///     fn description(\u0026self) -\u003e \u0026str {\n///         \"Does something useful\"\n///     }\n///\n///     fn input_schema(\u0026self) -\u003e Value {\n///         serde_json::json!({\n///             \"type\": \"object\",\n///             \"properties\": {\n///                 \"input\": { \"type\": \"string\" }\n///             },\n///             \"required\": [\"input\"]\n///         })\n///     }\n///\n///     async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n///         // Process params and return result\n///         Ok(serde_json::json!({ \"result\": \"success\" }))\n///     }\n/// }\n/// ```\n///\n/// ## Methods\n/// - `name`: Unique identifier for the tool\n/// - `description`: Human-readable description of what the tool does\n/// - `input_schema`: JSON Schema defining valid input parameters\n/// - `call`: Async execution method that processes input and returns output\n#[async_trait]\npub trait Tool: Send + Sync {\n    fn name(\u0026self) -\u003e \u0026str;\n    fn description(\u0026self) -\u003e \u0026str;\n    fn input_schema(\u0026self) -\u003e Value;\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e;\n}\n\n/// Error codes for tool execution failures.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Provides standardized error classification for tool operations, enabling\n/// proper error handling and retry logic.\n///\n/// ## Variants\n/// - `InvalidInput`: Input validation failed (non-retryable)\n/// - `NotFound`: Requested resource not found (non-retryable)\n/// - `ProviderError`: External provider or service failure (retryable)\n/// - `RateLimited`: Request rate limit exceeded (retryable)\n/// - `Unauthorized`: Authentication/authorization failure (non-retryable)\n/// - `Timeout`: Operation timed out (retryable)\n/// - `Conflict`: Concurrent modification or state conflict (retryable)\n/// - `InternalError`: Unexpected system error (non-retryable)\n#[derive(Serialize, Deserialize)]\n#[serde(rename_all = \"SCREAMING_SNAKE_CASE\")]\npub enum ToolErrorCode {\n    InvalidInput,\n    NotFound,\n    ProviderError,\n    RateLimited,\n    Unauthorized,\n    Timeout,\n    Conflict,\n    InternalError\n}\n\n/// Generic response wrapper for tool execution results.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Provides a consistent response format for all tool operations, enabling\n/// success/failure detection and structured error handling across all tools.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use serde_json::json;\n/// use tools::tools::{ToolError, ToolErrorCode, ToolResponse};\n///\n/// // Success response\n/// let success = ToolResponse::\u003cString\u003e {\n///     success: true,\n///     data: Some(\"result data\".to_string()),\n///     error: None\n/// };\n///\n/// // Error response\n/// let error = ToolResponse::\u003c()\u003e {\n///     success: false,\n///     data: None,\n///     error: Some(ToolError::new(ToolErrorCode::NotFound, \"Not found\"))\n/// };\n/// ```\n///\n/// ## Fields\n/// - `success`: Indicates whether the operation succeeded\n/// - `data`: Result data on success (omitted on failure)\n/// - `error`: Error details on failure (omitted on success)\n#[derive(Serialize, Deserialize)]\npub struct ToolResponse\u003cT\u003e {\n    pub success: bool,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub data: Option\u003cT\u003e,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub error: Option\u003cToolError\u003e\n}\n\n/// Detailed error information for tool failures.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Encapsulates error details including error code, message, retryability\n/// status, and optional context. Enables consumers to make informed decisions\n/// about error handling and retries.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use tools::tools::{ToolError, ToolErrorCode};\n/// use serde_json::json;\n///\n/// // Basic error\n/// let error = ToolError::new(ToolErrorCode::InvalidInput, \"Missing required field\");\n///\n/// // Error with details\n/// let error = ToolError::new(ToolErrorCode::NotFound, \"Resource not found\")\n///     .with_details(json!({ \"resource_id\": \"123\" }));\n///\n/// // Check if retryable\n/// if error.retryable {\n///     // Retry logic\n/// }\n/// ```\n///\n/// ## Fields\n/// - `code`: Standardized error code for classification\n/// - `message`: Human-readable error description\n/// - `retryable`: Whether the operation can be safely retried\n/// - `details`: Additional context for debugging (optional)\n#[derive(Serialize, Deserialize)]\npub struct ToolError {\n    pub code: ToolErrorCode,\n    pub message: String,\n    pub retryable: bool,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub details: Option\u003cValue\u003e\n}\n\nimpl ToolError {\n    pub fn new(code: ToolErrorCode, message: impl Into\u003cString\u003e) -\u003e Self {\n        let retryable = matches!(\n            code,\n            ToolErrorCode::RateLimited | ToolErrorCode::Timeout | ToolErrorCode::ProviderError\n        );\n        Self {\n            code,\n            message: message.into(),\n            retryable,\n            details: None\n        }\n    }\n\n    pub fn with_details(mut self, details: Value) -\u003e Self {\n        self.details = Some(details);\n        self\n    }\n}\n\n/// Central registry for managing and invoking tools.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Provides a centralized mechanism for registering, discovering, and invoking\n/// tools. Enables dynamic tool management and type-safe execution across the\n/// system.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use tools::tools::{ToolRegistry, Tool, ToolDefinition};\n/// use async_trait::async_trait;\n/// use serde_json::{json, Value};\n/// use std::error::Error;\n///\n/// struct MyTool;\n///\n/// #[async_trait]\n/// impl Tool for MyTool {\n///     fn name(\u0026self) -\u003e \u0026str { \"my_tool\" }\n///     fn description(\u0026self) -\u003e \u0026str { \"My example tool\" }\n///     fn input_schema(\u0026self) -\u003e Value { json!({}) }\n///     async fn call(\u0026self, _params: Value) -\u003e Result\u003cValue, Box\u003cdyn Error + Send + Sync\u003e\u003e {\n///         Ok(json!({ \"result\": \"success\" }))\n///     }\n/// }\n///\n/// // Create registry\n/// let mut registry = ToolRegistry::new();\n///\n/// // Register tools\n/// registry.register(Box::new(MyTool));\n///\n/// // List available tools\n/// let tools: Vec\u003cToolDefinition\u003e = registry.list_tools();\n/// ```\n///\n/// ## Methods\n/// - `new`: Creates an empty tool registry\n/// - `register`: Registers a tool by its unique name\n/// - `call`: Invokes a registered tool with the given parameters\n/// - `list_tools`: Returns metadata for all registered tools\npub struct ToolRegistry {\n    tools: HashMap\u003cString, Box\u003cdyn Tool\u003e\u003e\n}\n\n#[allow(clippy::new_without_default)]\nimpl Default for ToolRegistry {\n    fn default() -\u003e Self {\n        Self {\n            tools: HashMap::new()\n        }\n    }\n}\n\nimpl ToolRegistry {\n    pub fn new() -\u003e Self {\n        Self::default()\n    }\n\n    pub fn register(\u0026mut self, tool: Box\u003cdyn Tool\u003e) {\n        self.tools.insert(tool.name().to_string(), tool);\n    }\n\n    pub async fn call(\n        \u0026self,\n        name: \u0026str,\n        params: Value\n    ) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let tool = self\n            .tools\n            .get(name)\n            .ok_or(format!(\"Tool {} not found\", name))?;\n        tool.call(params).await\n    }\n\n    pub fn list_tools(\u0026self) -\u003e Vec\u003cToolDefinition\u003e {\n        self.tools\n            .values()\n            .map(|t| ToolDefinition {\n                name: t.name().to_string(),\n                description: t.description().to_string(),\n                input_schema: t.input_schema()\n            })\n            .collect()\n    }\n}\n\n/// Metadata definition for a registered tool.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Provides tool discovery information without exposing implementation details.\n/// Used for tool listing, documentation generation, and client UI.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use tools::tools::ToolDefinition;\n/// use serde_json::json;\n///\n/// let definition = ToolDefinition {\n///     name: \"my_tool\".to_string(),\n///     description: \"Does something useful\".to_string(),\n///     input_schema: json!({\n///         \"type\": \"object\",\n///         \"properties\": {\n///             \"input\": { \"type\": \"string\" }\n///         },\n///         \"required\": [\"input\"]\n///     }),\n/// };\n/// ```\n///\n/// ## Fields\n/// - `name`: Unique tool identifier used for invocation\n/// - `description`: Human-readable description of tool purpose\n/// - `input_schema`: JSON Schema defining valid input parameters\n#[derive(Serialize, Deserialize)]\npub struct ToolDefinition {\n    pub name: String,\n    pub description: String,\n    pub input_schema: Value\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    struct TestTool {\n        name: String\n    }\n\n    #[async_trait]\n    impl Tool for TestTool {\n        fn name(\u0026self) -\u003e \u0026str {\n            \u0026self.name\n        }\n        fn description(\u0026self) -\u003e \u0026str {\n            \"Test tool\"\n        }\n        fn input_schema(\u0026self) -\u003e Value {\n            serde_json::json!({})\n        }\n        async fn call(\n            \u0026self,\n            _params: Value\n        ) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n            Ok(serde_json::json!({\"result\": \"success\"}))\n        }\n    }\n\n    #[tokio::test]\n    async fn test_tool_registry_operations() {\n        let mut registry = ToolRegistry::new();\n\n        registry.register(Box::new(TestTool {\n            name: \"tool1\".to_string()\n        }));\n        registry.register(Box::new(TestTool {\n            name: \"tool2\".to_string()\n        }));\n\n        let tools = registry.list_tools();\n        assert_eq!(tools.len(), 2);\n        assert!(tools.iter().any(|t| t.name == \"tool1\"));\n        assert!(tools.iter().any(|t| t.name == \"tool2\"));\n\n        let result = registry.call(\"tool1\", serde_json::json!({})).await.unwrap();\n        assert_eq!(result[\"result\"], \"success\");\n\n        let err = registry.call(\"nonexistent\", serde_json::json!({})).await;\n        assert!(err.is_err());\n        assert!(err.unwrap_err().to_string().contains(\"not found\"));\n    }\n\n    #[test]\n    fn test_tool_registry_duplicate_registration() {\n        let mut registry = ToolRegistry::new();\n\n        registry.register(Box::new(TestTool {\n            name: \"same\".to_string()\n        }));\n        registry.register(Box::new(TestTool {\n            name: \"same\".to_string()\n        }));\n\n        let tools = registry.list_tools();\n        assert_eq!(tools.len(), 1);\n    }\n\n    #[test]\n    fn test_tool_error_retryability() {\n        let err = ToolError::new(ToolErrorCode::RateLimited, \"Too many requests\");\n        assert!(err.retryable);\n\n        let err = ToolError::new(ToolErrorCode::InvalidInput, \"Bad params\");\n        assert!(!err.retryable);\n\n        let err = ToolError::new(ToolErrorCode::NotFound, \"Not found\");\n        assert!(!err.retryable);\n\n        let err = ToolError::new(ToolErrorCode::Timeout, \"Timed out\");\n        assert!(err.retryable);\n    }\n}\n","traces":[{"line":180,"address":[],"length":0,"stats":{"Line":4}},{"line":181,"address":[],"length":0,"stats":{"Line":6}},{"line":182,"address":[],"length":0,"stats":{"Line":4}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":12}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":20}},{"line":250,"address":[],"length":0,"stats":{"Line":20}},{"line":256,"address":[],"length":0,"stats":{"Line":20}},{"line":257,"address":[],"length":0,"stats":{"Line":20}},{"line":260,"address":[],"length":0,"stats":{"Line":274}},{"line":261,"address":[],"length":0,"stats":{"Line":1370}},{"line":264,"address":[],"length":0,"stats":{"Line":8}},{"line":269,"address":[],"length":0,"stats":{"Line":14}},{"line":270,"address":[],"length":0,"stats":{"Line":8}},{"line":271,"address":[],"length":0,"stats":{"Line":16}},{"line":272,"address":[],"length":0,"stats":{"Line":26}},{"line":273,"address":[],"length":0,"stats":{"Line":18}},{"line":276,"address":[],"length":0,"stats":{"Line":7}},{"line":277,"address":[],"length":0,"stats":{"Line":7}},{"line":279,"address":[],"length":0,"stats":{"Line":7}},{"line":280,"address":[],"length":0,"stats":{"Line":156}},{"line":281,"address":[],"length":0,"stats":{"Line":156}},{"line":282,"address":[],"length":0,"stats":{"Line":156}}],"covered":22,"coverable":26},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","validator.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","working.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","tests","bridge_tools.rs"],"content":"use async_trait::async_trait;\nuse knowledge::repository::GitRepository;\nuse memory::manager::MemoryManager;\nuse mk_core::traits::KnowledgeRepository;\nuse mk_core::types::{KnowledgeEntry, KnowledgeLayer, KnowledgeStatus, KnowledgeType, TenantId};\nuse serde_json::json;\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse sync::bridge::SyncManager;\nuse sync::state::SyncState;\nuse sync::state_persister::SyncStatePersister;\nuse tools::bridge::{SyncNowTool, SyncStatusTool};\nuse tools::tools::Tool;\n\nstruct MockPersister;\n\n#[async_trait]\nimpl SyncStatePersister for MockPersister {\n    async fn load(\n        \u0026self,\n        _tenant_id: \u0026TenantId,\n    ) -\u003e Result\u003cSyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        Ok(SyncState::default())\n    }\n    async fn save(\n        \u0026self,\n        _tenant_id: \u0026TenantId,\n        _state: \u0026SyncState,\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        Ok(())\n    }\n}\n\n#[tokio::test]\nasync fn test_sync_tools() -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    // GIVEN a SyncManager and tools\n    let repo_dir = tempfile::tempdir()?;\n    let knowledge_repo = Arc::new(GitRepository::new(repo_dir.path())?);\n    let memory_manager = Arc::new(MemoryManager::new());\n\n    use memory::providers::MockProvider;\n    memory_manager\n        .register_provider(\n            mk_core::types::MemoryLayer::Project,\n            Box::new(MockProvider::new()),\n        )\n        .await;\n\n    let persister = Arc::new(MockPersister);\n\n    let sync_manager = Arc::new(\n        SyncManager::new(\n            memory_manager,\n            knowledge_repo.clone(),\n            Arc::new(knowledge::governance::GovernanceEngine::new()),\n            config::config::DeploymentConfig::default(),\n            None,\n            persister,\n        )\n        .await?,\n    );\n\n    let sync_now_tool = SyncNowTool::new(sync_manager.clone());\n    let sync_status_tool = SyncStatusTool::new(sync_manager.clone());\n\n    let tenant_id = mk_core::types::TenantId::new(\"t1\".into()).unwrap();\n    let user_id = mk_core::types::UserId::new(\"u1\".into()).unwrap();\n    let ctx = mk_core::types::TenantContext::new(tenant_id, user_id);\n\n    // WHEN initial sync status is requested\n    let status_resp = sync_status_tool\n        .call(json!({\n            \"tenantContext\": {\n                \"tenant_id\": \"t1\",\n                \"user_id\": \"u1\"\n            }\n        }))\n        .await?;\n\n    // THEN it should be healthy and have zero stats\n    assert!(status_resp[\"success\"].as_bool().unwrap());\n    assert!(status_resp[\"healthy\"].as_bool().unwrap());\n    assert_eq!(status_resp[\"stats\"][\"totalSyncs\"], 0);\n\n    // WHEN adding knowledge and triggering sync_now\n    let entry = KnowledgeEntry {\n        path: \"test.md\".to_string(),\n        content: \"test content\".to_string(),\n        layer: KnowledgeLayer::Project,\n        kind: KnowledgeType::Spec,\n        metadata: HashMap::new(),\n        status: KnowledgeStatus::Accepted,\n        commit_hash: None,\n        author: None,\n        updated_at: chrono::Utc::now().timestamp(),\n    };\n    knowledge_repo.store(ctx, entry, \"commit\").await?;\n\n    let sync_resp = sync_now_tool\n        .call(json!({\n            \"force\": false,\n            \"tenantContext\": {\n                \"tenant_id\": \"t1\",\n                \"user_id\": \"u1\"\n            }\n        }))\n        .await?;\n    assert!(sync_resp[\"success\"].as_bool().unwrap());\n\n    // THEN status should reflect the sync\n    let status_resp = sync_status_tool\n        .call(json!({\n            \"tenantContext\": {\n                \"tenant_id\": \"t1\",\n                \"user_id\": \"u1\"\n            }\n        }))\n        .await?;\n    assert_eq!(status_resp[\"stats\"][\"totalSyncs\"], 1);\n    assert_eq!(status_resp[\"stats\"][\"totalItemsSynced\"], 1);\n\n    Ok(())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","tests","governance_e2e.rs"],"content":"use async_trait::async_trait;\nuse knowledge::governance::GovernanceEngine;\nuse mk_core::traits::StorageBackend;\nuse mk_core::types::{\n    ConstraintOperator, ConstraintSeverity, ConstraintTarget, KnowledgeLayer, OrganizationalUnit,\n    Policy, PolicyMode, PolicyRule, Role, RuleMergeStrategy, RuleType, TenantContext, TenantId,\n    UnitType, UserId,\n};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse storage::postgres::PostgresError;\nuse tokio::sync::RwLock;\n\nstruct MockGovernanceStorage {\n    policies: Arc\u003cRwLock\u003cHashMap\u003cString, Vec\u003cPolicy\u003e\u003e\u003e\u003e,\n    units: Arc\u003cRwLock\u003cHashMap\u003cString, OrganizationalUnit\u003e\u003e\u003e,\n    drift_results: Arc\u003cRwLock\u003cVec\u003cmk_core::types::DriftResult\u003e\u003e\u003e,\n}\n\nimpl MockGovernanceStorage {\n    fn new() -\u003e Self {\n        Self {\n            policies: Arc::new(RwLock::new(HashMap::new())),\n            units: Arc::new(RwLock::new(HashMap::new())),\n            drift_results: Arc::new(RwLock::new(Vec::new())),\n        }\n    }\n\n    async fn add_unit(\u0026self, unit: OrganizationalUnit) {\n        self.units.write().await.insert(unit.id.clone(), unit);\n    }\n\n    async fn add_policy_for_unit(\u0026self, unit_id: \u0026str, policy: Policy) {\n        let mut policies = self.policies.write().await;\n        policies\n            .entry(unit_id.to_string())\n            .or_insert_with(Vec::new)\n            .push(policy);\n    }\n}\n\n#[async_trait]\nimpl StorageBackend for MockGovernanceStorage {\n    type Error = PostgresError;\n\n    async fn store(\n        \u0026self,\n        _ctx: TenantContext,\n        _key: \u0026str,\n        _value: \u0026[u8],\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn retrieve(\n        \u0026self,\n        _ctx: TenantContext,\n        _key: \u0026str,\n    ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n\n    async fn delete(\u0026self, _ctx: TenantContext, _key: \u0026str) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn exists(\u0026self, _ctx: TenantContext, _key: \u0026str) -\u003e Result\u003cbool, Self::Error\u003e {\n        Ok(false)\n    }\n\n    async fn get_ancestors(\n        \u0026self,\n        _ctx: TenantContext,\n        unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, Self::Error\u003e {\n        let units = self.units.read().await;\n        let mut ancestors = Vec::new();\n\n        if let Some(unit) = units.get(unit_id) {\n            let mut current_parent = unit.parent_id.clone();\n            while let Some(parent_id) = current_parent {\n                if let Some(parent) = units.get(\u0026parent_id) {\n                    ancestors.push(parent.clone());\n                    current_parent = parent.parent_id.clone();\n                } else {\n                    break;\n                }\n            }\n        }\n\n        Ok(ancestors)\n    }\n\n    async fn get_descendants(\n        \u0026self,\n        _ctx: TenantContext,\n        unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, Self::Error\u003e {\n        let units = self.units.read().await;\n        let descendants: Vec\u003cOrganizationalUnit\u003e = units\n            .values()\n            .filter(|u| u.parent_id.as_deref() == Some(unit_id))\n            .cloned()\n            .collect();\n        Ok(descendants)\n    }\n\n    async fn get_unit_policies(\n        \u0026self,\n        _ctx: TenantContext,\n        unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cPolicy\u003e, Self::Error\u003e {\n        let policies = self.policies.read().await;\n        Ok(policies.get(unit_id).cloned().unwrap_or_default())\n    }\n\n    async fn add_unit_policy(\n        \u0026self,\n        _ctx: \u0026TenantContext,\n        unit_id: \u0026str,\n        policy: \u0026Policy,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        let mut policies = self.policies.write().await;\n        policies\n            .entry(unit_id.to_string())\n            .or_insert_with(Vec::new)\n            .push(policy.clone());\n        Ok(())\n    }\n\n    async fn assign_role(\n        \u0026self,\n        _user_id: \u0026UserId,\n        _tenant_id: \u0026TenantId,\n        _unit_id: \u0026str,\n        _role: Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn remove_role(\n        \u0026self,\n        _user_id: \u0026UserId,\n        _tenant_id: \u0026TenantId,\n        _unit_id: \u0026str,\n        _role: Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn store_drift_result(\n        \u0026self,\n        result: mk_core::types::DriftResult,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        self.drift_results.write().await.push(result);\n        Ok(())\n    }\n\n    async fn get_latest_drift_result(\n        \u0026self,\n        _ctx: TenantContext,\n        project_id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cmk_core::types::DriftResult\u003e, Self::Error\u003e {\n        let results = self.drift_results.read().await;\n        Ok(results\n            .iter()\n            .filter(|r| r.project_id == project_id)\n            .last()\n            .cloned())\n    }\n\n    async fn list_all_units(\u0026self) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(self.units.read().await.values().cloned().collect())\n    }\n\n    async fn record_job_status(\n        \u0026self,\n        _job_type: \u0026str,\n        _tenant_id: \u0026str,\n        _status: \u0026str,\n        _error: Option\u003c\u0026str\u003e,\n        _started_at: i64,\n        _completed_at: Option\u003ci64\u003e,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn get_governance_events(\n        \u0026self,\n        _ctx: TenantContext,\n        _since_timestamp: i64,\n        _limit: usize,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn create_unit(\u0026self, unit: \u0026OrganizationalUnit) -\u003e Result\u003c(), Self::Error\u003e {\n        self.units\n            .write()\n            .await\n            .insert(unit.id.clone(), unit.clone());\n        Ok(())\n    }\n}\n\nfn create_tenant_context(tenant: \u0026str, user: \u0026str) -\u003e TenantContext {\n    TenantContext::new(\n        TenantId::new(tenant.to_string()).unwrap(),\n        UserId::new(user.to_string()).unwrap(),\n    )\n}\n\nfn create_unit(\n    id: \u0026str,\n    name: \u0026str,\n    unit_type: UnitType,\n    parent: Option\u003c\u0026str\u003e,\n    tenant: \u0026str,\n) -\u003e OrganizationalUnit {\n    OrganizationalUnit {\n        id: id.to_string(),\n        name: name.to_string(),\n        unit_type,\n        parent_id: parent.map(String::from),\n        tenant_id: TenantId::new(tenant.to_string()).unwrap(),\n        metadata: HashMap::new(),\n        created_at: chrono::Utc::now().timestamp(),\n        updated_at: chrono::Utc::now().timestamp(),\n    }\n}\n\n#[tokio::test]\nasync fn test_e2e_complete_governance_workflow() {\n    let storage = Arc::new(MockGovernanceStorage::new());\n\n    let company = create_unit(\n        \"acme-corp\",\n        \"Acme Corporation\",\n        UnitType::Company,\n        None,\n        \"tenant-1\",\n    );\n    let org = create_unit(\n        \"engineering\",\n        \"Engineering Org\",\n        UnitType::Organization,\n        Some(\"acme-corp\"),\n        \"tenant-1\",\n    );\n    let team = create_unit(\n        \"platform-team\",\n        \"Platform Team\",\n        UnitType::Team,\n        Some(\"engineering\"),\n        \"tenant-1\",\n    );\n    let project = create_unit(\n        \"api-gateway\",\n        \"API Gateway\",\n        UnitType::Project,\n        Some(\"platform-team\"),\n        \"tenant-1\",\n    );\n\n    storage.add_unit(company).await;\n    storage.add_unit(org).await;\n    storage.add_unit(team).await;\n    storage.add_unit(project).await;\n\n    let company_policy = Policy {\n        id: \"security-baseline\".to_string(),\n        name: \"Company Security Baseline\".to_string(),\n        description: Some(\"Mandatory security requirements\".to_string()),\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"no-eval\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustNotMatch,\n            value: serde_json::json!(r\"eval\\s*\\(\"),\n            severity: ConstraintSeverity::Block,\n            message: \"eval() is forbidden for security reasons\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    let team_policy = Policy {\n        id: \"team-standards\".to_string(),\n        name: \"Platform Team Standards\".to_string(),\n        description: Some(\"Team coding standards\".to_string()),\n        layer: KnowledgeLayer::Team,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"require-logging\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"tracing\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Projects should use tracing for observability\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    storage\n        .add_policy_for_unit(\"acme-corp\", company_policy)\n        .await;\n    storage\n        .add_policy_for_unit(\"platform-team\", team_policy)\n        .await;\n\n    let engine = GovernanceEngine::new().with_storage(storage.clone());\n\n    let ctx = create_tenant_context(\"tenant-1\", \"developer-1\");\n\n    let mut context = HashMap::new();\n    context.insert(\"unitId\".to_string(), serde_json::json!(\"api-gateway\"));\n    context.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"function safe() { return 1; }\"),\n    );\n    context.insert(\n        \"dependencies\".to_string(),\n        serde_json::json!([\"tracing\", \"tokio\"]),\n    );\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"api-gateway\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(drift_score, 0.0, \"Compliant code should have zero drift\");\n\n    let mut bad_context = HashMap::new();\n    bad_context.insert(\"unitId\".to_string(), serde_json::json!(\"api-gateway\"));\n    bad_context.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"let result = eval('malicious');\"),\n    );\n    bad_context.insert(\"dependencies\".to_string(), serde_json::json!([\"tokio\"]));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"api-gateway\", \u0026bad_context)\n        .await\n        .unwrap();\n    assert!(\n        drift_score \u003e 0.0,\n        \"Violating code should have non-zero drift\"\n    );\n}\n\n#[tokio::test]\nasync fn test_e2e_multi_tenant_isolation() {\n    let storage = Arc::new(MockGovernanceStorage::new());\n\n    let tenant1_company = create_unit(\n        \"company-a\",\n        \"Company A\",\n        UnitType::Company,\n        None,\n        \"tenant-1\",\n    );\n    let tenant2_company = create_unit(\n        \"company-b\",\n        \"Company B\",\n        UnitType::Company,\n        None,\n        \"tenant-2\",\n    );\n\n    storage.add_unit(tenant1_company).await;\n    storage.add_unit(tenant2_company).await;\n\n    let tenant1_policy = Policy {\n        id: \"t1-policy\".to_string(),\n        name: \"Tenant 1 Policy\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![PolicyRule {\n            id: \"t1-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"tenant1-lib\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Tenant 1 requires tenant1-lib\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    let tenant2_policy = Policy {\n        id: \"t2-policy\".to_string(),\n        name: \"Tenant 2 Policy\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![PolicyRule {\n            id: \"t2-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"tenant2-lib\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Tenant 2 requires tenant2-lib\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    storage\n        .add_policy_for_unit(\"company-a\", tenant1_policy)\n        .await;\n    storage\n        .add_policy_for_unit(\"company-b\", tenant2_policy)\n        .await;\n\n    let engine = GovernanceEngine::new().with_storage(storage);\n\n    let ctx1 = create_tenant_context(\"tenant-1\", \"user-1\");\n    let ctx2 = create_tenant_context(\"tenant-2\", \"user-2\");\n\n    let mut context1 = HashMap::new();\n    context1.insert(\"unitId\".to_string(), serde_json::json!(\"company-a\"));\n    context1.insert(\n        \"dependencies\".to_string(),\n        serde_json::json!([\"tenant1-lib\"]),\n    );\n\n    let mut context2 = HashMap::new();\n    context2.insert(\"unitId\".to_string(), serde_json::json!(\"company-b\"));\n    context2.insert(\n        \"dependencies\".to_string(),\n        serde_json::json!([\"tenant2-lib\"]),\n    );\n\n    let score1 = engine\n        .check_drift(\u0026ctx1, \"company-a\", \u0026context1)\n        .await\n        .unwrap();\n    let score2 = engine\n        .check_drift(\u0026ctx2, \"company-b\", \u0026context2)\n        .await\n        .unwrap();\n\n    assert_eq!(score1, 0.0, \"Tenant 1 compliant with tenant1-lib\");\n    assert_eq!(score2, 0.0, \"Tenant 2 compliant with tenant2-lib\");\n\n    let mut cross_context = HashMap::new();\n    cross_context.insert(\"unitId\".to_string(), serde_json::json!(\"company-a\"));\n    cross_context.insert(\n        \"dependencies\".to_string(),\n        serde_json::json!([\"tenant2-lib\"]),\n    );\n\n    let cross_score = engine\n        .check_drift(\u0026ctx1, \"company-a\", \u0026cross_context)\n        .await\n        .unwrap();\n    assert!(\n        cross_score \u003e 0.0,\n        \"Tenant 1 should fail without tenant1-lib\"\n    );\n}\n\n#[tokio::test]\nasync fn test_e2e_policy_inheritance_chain() {\n    let storage = Arc::new(MockGovernanceStorage::new());\n\n    let company = create_unit(\"corp\", \"Corporation\", UnitType::Company, None, \"t1\");\n    let org = create_unit(\n        \"org\",\n        \"Organization\",\n        UnitType::Organization,\n        Some(\"corp\"),\n        \"t1\",\n    );\n    let team = create_unit(\"team\", \"Team\", UnitType::Team, Some(\"org\"), \"t1\");\n    let project = create_unit(\"proj\", \"Project\", UnitType::Project, Some(\"team\"), \"t1\");\n\n    storage.add_unit(company).await;\n    storage.add_unit(org).await;\n    storage.add_unit(team).await;\n    storage.add_unit(project).await;\n\n    storage\n        .add_policy_for_unit(\n            \"corp\",\n            Policy {\n                id: \"company-rule\".to_string(),\n                name: \"Company Rule\".to_string(),\n                description: None,\n                layer: KnowledgeLayer::Company,\n                mode: PolicyMode::Mandatory,\n                merge_strategy: RuleMergeStrategy::Merge,\n                rules: vec![PolicyRule {\n                    id: \"req-a\".to_string(),\n                    rule_type: RuleType::Allow,\n                    target: ConstraintTarget::Dependency,\n                    operator: ConstraintOperator::MustUse,\n                    value: serde_json::json!(\"lib-a\"),\n                    severity: ConstraintSeverity::Info,\n                    message: \"Company requires lib-a\".to_string(),\n                }],\n                metadata: HashMap::new(),\n            },\n        )\n        .await;\n\n    storage\n        .add_policy_for_unit(\n            \"org\",\n            Policy {\n                id: \"org-rule\".to_string(),\n                name: \"Org Rule\".to_string(),\n                description: None,\n                layer: KnowledgeLayer::Org,\n                mode: PolicyMode::Mandatory,\n                merge_strategy: RuleMergeStrategy::Merge,\n                rules: vec![PolicyRule {\n                    id: \"req-b\".to_string(),\n                    rule_type: RuleType::Allow,\n                    target: ConstraintTarget::Dependency,\n                    operator: ConstraintOperator::MustUse,\n                    value: serde_json::json!(\"lib-b\"),\n                    severity: ConstraintSeverity::Info,\n                    message: \"Org requires lib-b\".to_string(),\n                }],\n                metadata: HashMap::new(),\n            },\n        )\n        .await;\n\n    storage\n        .add_policy_for_unit(\n            \"team\",\n            Policy {\n                id: \"team-rule\".to_string(),\n                name: \"Team Rule\".to_string(),\n                description: None,\n                layer: KnowledgeLayer::Team,\n                mode: PolicyMode::Mandatory,\n                merge_strategy: RuleMergeStrategy::Merge,\n                rules: vec![PolicyRule {\n                    id: \"req-c\".to_string(),\n                    rule_type: RuleType::Allow,\n                    target: ConstraintTarget::Dependency,\n                    operator: ConstraintOperator::MustUse,\n                    value: serde_json::json!(\"lib-c\"),\n                    severity: ConstraintSeverity::Info,\n                    message: \"Team requires lib-c\".to_string(),\n                }],\n                metadata: HashMap::new(),\n            },\n        )\n        .await;\n\n    let engine = GovernanceEngine::new().with_storage(storage);\n    let ctx = create_tenant_context(\"t1\", \"user\");\n\n    let mut all_libs = HashMap::new();\n    all_libs.insert(\"unitId\".to_string(), serde_json::json!(\"proj\"));\n    all_libs.insert(\n        \"dependencies\".to_string(),\n        serde_json::json!([\"lib-a\", \"lib-b\", \"lib-c\"]),\n    );\n\n    let score = engine.check_drift(\u0026ctx, \"proj\", \u0026all_libs).await.unwrap();\n    assert_eq!(score, 0.0, \"All inherited requirements satisfied\");\n\n    let mut missing_one = HashMap::new();\n    missing_one.insert(\"unitId\".to_string(), serde_json::json!(\"proj\"));\n    missing_one.insert(\n        \"dependencies\".to_string(),\n        serde_json::json!([\"lib-a\", \"lib-b\"]),\n    );\n\n    let score = engine\n        .check_drift(\u0026ctx, \"proj\", \u0026missing_one)\n        .await\n        .unwrap();\n    assert!(score \u003e 0.0, \"Missing lib-c should trigger drift\");\n}\n\n#[tokio::test]\nasync fn test_e2e_drift_result_persistence() {\n    let storage = Arc::new(MockGovernanceStorage::new());\n\n    let project = create_unit(\"test-proj\", \"Test Project\", UnitType::Project, None, \"t1\");\n    storage.add_unit(project).await;\n\n    storage\n        .add_policy_for_unit(\n            \"test-proj\",\n            Policy {\n                id: \"test-policy\".to_string(),\n                name: \"Test Policy\".to_string(),\n                description: None,\n                layer: KnowledgeLayer::Project,\n                mode: PolicyMode::Mandatory,\n                merge_strategy: RuleMergeStrategy::Override,\n                rules: vec![PolicyRule {\n                    id: \"test-rule\".to_string(),\n                    rule_type: RuleType::Allow,\n                    target: ConstraintTarget::Dependency,\n                    operator: ConstraintOperator::MustUse,\n                    value: serde_json::json!(\"required-lib\"),\n                    severity: ConstraintSeverity::Warn,\n                    message: \"Required lib missing\".to_string(),\n                }],\n                metadata: HashMap::new(),\n            },\n        )\n        .await;\n\n    let engine = GovernanceEngine::new().with_storage(storage.clone());\n    let ctx = create_tenant_context(\"t1\", \"user\");\n\n    let mut context = HashMap::new();\n    context.insert(\"unitId\".to_string(), serde_json::json!(\"test-proj\"));\n    context.insert(\"dependencies\".to_string(), serde_json::json!([\"other-lib\"]));\n\n    let _score = engine\n        .check_drift(\u0026ctx, \"test-proj\", \u0026context)\n        .await\n        .unwrap();\n\n    let stored_result = storage\n        .get_latest_drift_result(ctx.clone(), \"test-proj\")\n        .await\n        .unwrap();\n    assert!(stored_result.is_some(), \"Drift result should be persisted\");\n\n    let result = stored_result.unwrap();\n    assert_eq!(result.project_id, \"test-proj\");\n    assert!(\n        !result.violations.is_empty(),\n        \"Violations should be recorded\"\n    );\n}\n\n#[tokio::test]\nasync fn test_e2e_policy_override_at_lower_layer() {\n    let storage = Arc::new(MockGovernanceStorage::new());\n\n    let company = create_unit(\"corp\", \"Corp\", UnitType::Company, None, \"t1\");\n    let project = create_unit(\"proj\", \"Project\", UnitType::Project, Some(\"corp\"), \"t1\");\n\n    storage.add_unit(company).await;\n    storage.add_unit(project).await;\n\n    storage\n        .add_policy_for_unit(\n            \"corp\",\n            Policy {\n                id: \"shared-policy\".to_string(),\n                name: \"Company Policy\".to_string(),\n                description: None,\n                layer: KnowledgeLayer::Company,\n                mode: PolicyMode::Mandatory,\n                merge_strategy: RuleMergeStrategy::Override,\n                rules: vec![PolicyRule {\n                    id: \"company-rule\".to_string(),\n                    rule_type: RuleType::Allow,\n                    target: ConstraintTarget::Dependency,\n                    operator: ConstraintOperator::MustUse,\n                    value: serde_json::json!(\"old-lib\"),\n                    severity: ConstraintSeverity::Block,\n                    message: \"Company requires old-lib\".to_string(),\n                }],\n                metadata: HashMap::new(),\n            },\n        )\n        .await;\n\n    storage\n        .add_policy_for_unit(\n            \"proj\",\n            Policy {\n                id: \"shared-policy\".to_string(),\n                name: \"Project Override\".to_string(),\n                description: None,\n                layer: KnowledgeLayer::Project,\n                mode: PolicyMode::Mandatory,\n                merge_strategy: RuleMergeStrategy::Override,\n                rules: vec![PolicyRule {\n                    id: \"project-rule\".to_string(),\n                    rule_type: RuleType::Allow,\n                    target: ConstraintTarget::Dependency,\n                    operator: ConstraintOperator::MustUse,\n                    value: serde_json::json!(\"new-lib\"),\n                    severity: ConstraintSeverity::Block,\n                    message: \"Project requires new-lib\".to_string(),\n                }],\n                metadata: HashMap::new(),\n            },\n        )\n        .await;\n\n    let engine = GovernanceEngine::new().with_storage(storage);\n    let ctx = create_tenant_context(\"t1\", \"user\");\n\n    let mut context = HashMap::new();\n    context.insert(\"unitId\".to_string(), serde_json::json!(\"proj\"));\n    context.insert(\"dependencies\".to_string(), serde_json::json!([\"new-lib\"]));\n\n    let score = engine.check_drift(\u0026ctx, \"proj\", \u0026context).await.unwrap();\n    assert_eq!(score, 0.0, \"Project override should take precedence\");\n}\n\n#[tokio::test]\nasync fn test_e2e_validation_result_structure() {\n    let mut engine = GovernanceEngine::new();\n\n    engine.add_policy(Policy {\n        id: \"test-policy\".to_string(),\n        name: \"Test Policy\".to_string(),\n        description: Some(\"Test description\".to_string()),\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![\n            PolicyRule {\n                id: \"block-rule\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Dependency,\n                operator: ConstraintOperator::MustUse,\n                value: serde_json::json!(\"critical-lib\"),\n                severity: ConstraintSeverity::Block,\n                message: \"Critical lib missing\".to_string(),\n            },\n            PolicyRule {\n                id: \"warn-rule\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Dependency,\n                operator: ConstraintOperator::MustUse,\n                value: serde_json::json!(\"recommended-lib\"),\n                severity: ConstraintSeverity::Warn,\n                message: \"Recommended lib missing\".to_string(),\n            },\n        ],\n        metadata: HashMap::new(),\n    });\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([]));\n\n    let result = engine.validate(KnowledgeLayer::Company, \u0026context);\n\n    assert!(!result.is_valid, \"Should be invalid with violations\");\n    assert_eq!(result.violations.len(), 2, \"Should have 2 violations\");\n\n    let block_violation = result.violations.iter().find(|v| v.rule_id == \"block-rule\");\n    let warn_violation = result.violations.iter().find(|v| v.rule_id == \"warn-rule\");\n\n    assert!(block_violation.is_some(), \"Should have block violation\");\n    assert!(warn_violation.is_some(), \"Should have warn violation\");\n\n    assert_eq!(block_violation.unwrap().severity, ConstraintSeverity::Block);\n    assert_eq!(warn_violation.unwrap().severity, ConstraintSeverity::Warn);\n}\n\n#[tokio::test]\nasync fn test_e2e_empty_policy_graceful_handling() {\n    let storage = Arc::new(MockGovernanceStorage::new());\n\n    let project = create_unit(\"empty-proj\", \"Empty Project\", UnitType::Project, None, \"t1\");\n    storage.add_unit(project).await;\n\n    let engine = GovernanceEngine::new().with_storage(storage);\n    let ctx = create_tenant_context(\"t1\", \"user\");\n\n    let mut context = HashMap::new();\n    context.insert(\"unitId\".to_string(), serde_json::json!(\"empty-proj\"));\n    context.insert(\"dependencies\".to_string(), serde_json::json!([\"any-lib\"]));\n\n    let result = engine.check_drift(\u0026ctx, \"empty-proj\", \u0026context).await;\n    assert!(result.is_ok(), \"Should handle empty policies gracefully\");\n\n    let score = result.unwrap();\n    assert!(\n        score \u003c= 0.5,\n        \"Should only have missing mandatory policies warning\"\n    );\n}\n","traces":[{"line":21,"address":[],"length":0,"stats":{"Line":6}},{"line":23,"address":[],"length":0,"stats":{"Line":24}},{"line":24,"address":[],"length":0,"stats":{"Line":24}},{"line":25,"address":[],"length":0,"stats":{"Line":12}},{"line":29,"address":[],"length":0,"stats":{"Line":28}},{"line":30,"address":[],"length":0,"stats":{"Line":84}},{"line":33,"address":[],"length":0,"stats":{"Line":20}},{"line":34,"address":[],"length":0,"stats":{"Line":20}},{"line":35,"address":[],"length":0,"stats":{"Line":20}},{"line":36,"address":[],"length":0,"stats":{"Line":20}},{"line":37,"address":[],"length":0,"stats":{"Line":10}},{"line":38,"address":[],"length":0,"stats":{"Line":20}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":2}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":7}},{"line":208,"address":[],"length":0,"stats":{"Line":28}},{"line":209,"address":[],"length":0,"stats":{"Line":28}},{"line":213,"address":[],"length":0,"stats":{"Line":14}},{"line":221,"address":[],"length":0,"stats":{"Line":42}},{"line":222,"address":[],"length":0,"stats":{"Line":42}},{"line":224,"address":[],"length":0,"stats":{"Line":42}},{"line":225,"address":[],"length":0,"stats":{"Line":70}},{"line":226,"address":[],"length":0,"stats":{"Line":28}},{"line":227,"address":[],"length":0,"stats":{"Line":42}},{"line":228,"address":[],"length":0,"stats":{"Line":14}}],"covered":24,"coverable":29},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","tests","integration.rs"],"content":"use adapters::ecosystem::{EcosystemAdapter, OpenCodeAdapter};\nuse adapters::langchain::LangChainAdapter;\nuse async_trait::async_trait;\nuse memory::manager::MemoryManager;\nuse memory::providers::MockProvider;\nuse mk_core::traits::KnowledgeRepository;\nuse mk_core::types::{KnowledgeEntry, KnowledgeLayer, MemoryLayer, TenantId};\nuse serde_json::json;\nuse std::sync::Arc;\nuse sync::bridge::SyncManager;\nuse sync::state::SyncState;\nuse sync::state_persister::SyncStatePersister;\nuse testcontainers::ContainerAsync;\nuse testcontainers::runners::AsyncRunner;\nuse testcontainers_modules::postgres::Postgres;\nuse tools::server::{JsonRpcRequest, McpServer};\n\nstruct MockKnowledgeRepo;\n\n#[async_trait]\nimpl KnowledgeRepository for MockKnowledgeRepo {\n    type Error = knowledge::repository::RepositoryError;\n\n    async fn get(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _layer: KnowledgeLayer,\n        _path: \u0026str,\n    ) -\u003e Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n\n    async fn store(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _entry: KnowledgeEntry,\n        _message: \u0026str,\n    ) -\u003e Result\u003cString, Self::Error\u003e {\n        Ok(\"hash\".to_string())\n    }\n\n    async fn list(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _layer: KnowledgeLayer,\n        _prefix: \u0026str,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n\n    async fn delete(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _layer: KnowledgeLayer,\n        _path: \u0026str,\n        _message: \u0026str,\n    ) -\u003e Result\u003cString, Self::Error\u003e {\n        Ok(\"hash\".to_string())\n    }\n\n    async fn get_head_commit(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n    ) -\u003e Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n        Ok(Some(\"head\".to_string()))\n    }\n\n    async fn get_affected_items(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _since_commit: \u0026str,\n    ) -\u003e Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n\n    async fn search(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _query: \u0026str,\n        _layers: Vec\u003cKnowledgeLayer\u003e,\n        _limit: usize,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n\n    fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n        None\n    }\n}\n\nstruct MockPersister;\n\n#[async_trait]\nimpl SyncStatePersister for MockPersister {\n    async fn load(\n        \u0026self,\n        _tenant_id: \u0026TenantId,\n    ) -\u003e Result\u003cSyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        Ok(SyncState::default())\n    }\n    async fn save(\n        \u0026self,\n        _tenant_id: \u0026TenantId,\n        _state: \u0026SyncState,\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        Ok(())\n    }\n}\n\nstruct MockAuthService;\n#[async_trait]\nimpl mk_core::traits::AuthorizationService for MockAuthService {\n    type Error = anyhow::Error;\n    async fn check_permission(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _action: \u0026str,\n        _resource: \u0026str,\n    ) -\u003e anyhow::Result\u003cbool\u003e {\n        Ok(true)\n    }\n    async fn get_user_roles(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n    ) -\u003e anyhow::Result\u003cVec\u003cmk_core::types::Role\u003e\u003e {\n        Ok(vec![])\n    }\n    async fn assign_role(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _user_id: \u0026mk_core::types::UserId,\n        _role: mk_core::types::Role,\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n    async fn remove_role(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _user_id: \u0026mk_core::types::UserId,\n        _role: mk_core::types::Role,\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n}\n\nasync fn setup_postgres_container()\n-\u003e Result\u003c(ContainerAsync\u003cPostgres\u003e, String), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    let container = Postgres::default()\n        .with_db_name(\"testdb\")\n        .with_user(\"testuser\")\n        .with_password(\"testpass\")\n        .start()\n        .await\n        .map_err(|e| Box::new(e) as Box\u003cdyn std::error::Error + Send + Sync\u003e)?;\n\n    let connection_url = format!(\n        \"postgres://testuser:testpass@localhost:{}/testdb?sslmode=disable\",\n        container\n            .get_host_port_ipv4(5432)\n            .await\n            .map_err(|e| Box::new(e) as Box\u003cdyn std::error::Error + Send + Sync\u003e)?\n    );\n\n    Ok((container, connection_url))\n}\n\n#[tokio::test]\nasync fn test_full_integration_mcp_to_adapters() -\u003e anyhow::Result\u003c()\u003e {\n    let (_container, connection_url) = setup_postgres_container()\n        .await\n        .map_err(|e| anyhow::anyhow!(e))?;\n    let memory_manager = Arc::new(MemoryManager::new());\n    memory_manager\n        .register_provider(MemoryLayer::User, Box::new(MockProvider::new()))\n        .await;\n\n    let knowledge_repo = Arc::new(MockKnowledgeRepo);\n    let sync_manager = Arc::new(\n        SyncManager::new(\n            memory_manager.clone(),\n            knowledge_repo.clone(),\n            Arc::new(knowledge::governance::GovernanceEngine::new()),\n            config::config::DeploymentConfig::default(),\n            None,\n            Arc::new(MockPersister),\n        )\n        .await\n        .map_err(|e| anyhow::anyhow!(e.to_string()))?,\n    );\n\n    let server = Arc::new(McpServer::new(\n        memory_manager,\n        sync_manager,\n        knowledge_repo.clone(),\n        Arc::new(\n            storage::postgres::PostgresBackend::new(\u0026connection_url)\n                .await\n                .map_err(|e| anyhow::anyhow!(e.to_string()))?,\n        ),\n        Arc::new(knowledge::governance::GovernanceEngine::new()),\n        Arc::new(MockAuthService),\n        None,\n    ));\n\n    let opencode = OpenCodeAdapter::new(server.clone());\n    let memory_tools = opencode.get_memory_tools();\n    assert!(!memory_tools.is_empty());\n\n    let langchain = LangChainAdapter::new(server.clone());\n    let lc_tools = langchain.to_langchain_tools();\n    assert_eq!(lc_tools.len(), 15); // 4 memory + 3 knowledge + 3 sync + 5 governance\n\n    let response = langchain\n        .handle_mcp_request(json!({\n            \"tenantContext\": {\n                \"tenant_id\": \"c1\",\n                \"user_id\": \"u1\"\n            },\n            \"name\": \"memory_add\",\n            \"arguments\": {\n                \"content\": \"Integrated test\",\n                \"layer\": \"user\"\n            }\n        }))\n        .await?;\n\n    if let Some(error) = response[\"error\"].as_object() {\n        panic!(\"Tool call failed: {:?}\", error);\n    }\n    assert!(!response[\"result\"].is_null());\n\n    Ok(())\n}\n\n#[tokio::test]\nasync fn test_server_timeout() -\u003e anyhow::Result\u003c()\u003e {\n    let (_container, connection_url) = setup_postgres_container()\n        .await\n        .map_err(|e| anyhow::anyhow!(e))?;\n    let memory_manager = Arc::new(MemoryManager::new());\n    let knowledge_repo = Arc::new(MockKnowledgeRepo);\n    let sync_manager = Arc::new(\n        SyncManager::new(\n            memory_manager.clone(),\n            knowledge_repo.clone(),\n            Arc::new(knowledge::governance::GovernanceEngine::new()),\n            config::config::DeploymentConfig::default(),\n            None,\n            Arc::new(MockPersister),\n        )\n        .await\n        .map_err(|e| anyhow::anyhow!(e.to_string()))?,\n    );\n\n    let _server = McpServer::new(\n        memory_manager.clone(),\n        sync_manager.clone(),\n        knowledge_repo.clone(),\n        Arc::new(\n            storage::postgres::PostgresBackend::new(\u0026connection_url)\n                .await\n                .map_err(|e| anyhow::anyhow!(e.to_string()))?,\n        ),\n        Arc::new(knowledge::governance::GovernanceEngine::new()),\n        Arc::new(MockAuthService),\n        None,\n    )\n    .with_timeout(std::time::Duration::from_millis(1));\n\n    struct DenyAuthService;\n    #[async_trait]\n    impl mk_core::traits::AuthorizationService for DenyAuthService {\n        type Error = anyhow::Error;\n        async fn check_permission(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n            _action: \u0026str,\n            _resource: \u0026str,\n        ) -\u003e anyhow::Result\u003cbool\u003e {\n            Ok(false)\n        }\n        async fn get_user_roles(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n        ) -\u003e anyhow::Result\u003cVec\u003cmk_core::types::Role\u003e\u003e {\n            Ok(vec![])\n        }\n        async fn assign_role(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n            _user_id: \u0026mk_core::types::UserId,\n            _role: mk_core::types::Role,\n        ) -\u003e anyhow::Result\u003c()\u003e {\n            Ok(())\n        }\n        async fn remove_role(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n            _user_id: \u0026mk_core::types::UserId,\n            _role: mk_core::types::Role,\n        ) -\u003e anyhow::Result\u003c()\u003e {\n            Ok(())\n        }\n    }\n\n    let server = McpServer::new(\n        memory_manager.clone(),\n        sync_manager.clone(),\n        knowledge_repo.clone(),\n        Arc::new(\n            storage::postgres::PostgresBackend::new(\u0026connection_url)\n                .await\n                .map_err(|e| anyhow::anyhow!(e.to_string()))?,\n        ),\n        Arc::new(knowledge::governance::GovernanceEngine::new()),\n        Arc::new(DenyAuthService),\n        None,\n    );\n\n    let request = JsonRpcRequest {\n        jsonrpc: \"2.0\".to_string(),\n        id: json!(1),\n        method: \"tools/call\".to_string(),\n        params: Some(json!({\n            \"tenantContext\": {\n                \"tenant_id\": \"c1\",\n                \"user_id\": \"u1\"\n            },\n            \"name\": \"memory_search\",\n            \"arguments\": {\n                \"query\": \"test\"\n            }\n        })),\n    };\n\n    let response = server.handle_request(request).await;\n\n    assert!(response.error.is_some());\n    let error = response.error.unwrap();\n    assert_eq!(error.code, -32002);\n    assert!(error.message.contains(\"Authorization error\"));\n\n    Ok(())\n}\n","traces":[{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":2}},{"line":148,"address":[],"length":0,"stats":{"Line":6}},{"line":153,"address":[],"length":0,"stats":{"Line":2}},{"line":154,"address":[],"length":0,"stats":{"Line":2}},{"line":156,"address":[],"length":0,"stats":{"Line":4}},{"line":158,"address":[],"length":0,"stats":{"Line":2}},{"line":159,"address":[],"length":0,"stats":{"Line":2}},{"line":160,"address":[],"length":0,"stats":{"Line":2}},{"line":161,"address":[],"length":0,"stats":{"Line":2}},{"line":164,"address":[],"length":0,"stats":{"Line":2}}],"covered":10,"coverable":12},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","tests","knowledge_lifecycle.rs"],"content":"use async_trait::async_trait;\nuse knowledge::repository::GitRepository;\nuse memory::manager::MemoryManager;\nuse memory::providers::MockProvider;\nuse mk_core::traits::{KnowledgeRepository, StorageBackend};\nuse mk_core::types::{KnowledgeEntry, KnowledgeLayer, KnowledgeStatus, KnowledgeType, MemoryLayer};\nuse serde_json::json;\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse sync::bridge::SyncManager;\nuse sync::state_persister::DatabasePersister;\nuse testcontainers::runners::AsyncRunner;\nuse tokio::sync::RwLock;\nuse tools::server::{JsonRpcRequest, McpServer};\n\nstruct MockStorage {\n    data: Arc\u003cRwLock\u003cHashMap\u003cString, Vec\u003cu8\u003e\u003e\u003e\u003e,\n}\n\nimpl MockStorage {\n    fn new() -\u003e Self {\n        Self {\n            data: Arc::new(RwLock::new(HashMap::new())),\n        }\n    }\n}\n\n#[async_trait]\nimpl StorageBackend for MockStorage {\n    type Error = std::io::Error;\n\n    async fn store(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        key: \u0026str,\n        value: \u0026[u8],\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        self.data\n            .write()\n            .await\n            .insert(key.to_string(), value.to_vec());\n        Ok(())\n    }\n\n    async fn retrieve(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        key: \u0026str,\n    ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e {\n        Ok(self.data.read().await.get(key).cloned())\n    }\n\n    async fn delete(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        key: \u0026str,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        self.data.write().await.remove(key);\n        Ok(())\n    }\n\n    async fn exists(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        key: \u0026str,\n    ) -\u003e Result\u003cbool, Self::Error\u003e {\n        Ok(self.data.read().await.contains_key(key))\n    }\n\n    async fn get_ancestors(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn get_descendants(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn get_unit_policies(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::Policy\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn create_unit(\n        \u0026self,\n        _unit: \u0026mk_core::types::OrganizationalUnit,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn add_unit_policy(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _unit_id: \u0026str,\n        _policy: \u0026mk_core::types::Policy,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn assign_role(\n        \u0026self,\n        _user_id: \u0026mk_core::types::UserId,\n        _tenant_id: \u0026mk_core::types::TenantId,\n        _unit_id: \u0026str,\n        _role: mk_core::types::Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn remove_role(\n        \u0026self,\n        _user_id: \u0026mk_core::types::UserId,\n        _tenant_id: \u0026mk_core::types::TenantId,\n        _unit_id: \u0026str,\n        _role: mk_core::types::Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn store_drift_result(\n        \u0026self,\n        _result: mk_core::types::DriftResult,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn get_latest_drift_result(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _project_id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cmk_core::types::DriftResult\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n\n    async fn list_all_units(\u0026self) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn record_job_status(\n        \u0026self,\n        _job_name: \u0026str,\n        _tenant_id: \u0026str,\n        _status: \u0026str,\n        _message: Option\u003c\u0026str\u003e,\n        _started_at: i64,\n        _finished_at: Option\u003ci64\u003e,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn get_governance_events(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _since_timestamp: i64,\n        _limit: usize,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n}\n\nstruct MockAuthService;\n#[async_trait]\nimpl mk_core::traits::AuthorizationService for MockAuthService {\n    type Error = anyhow::Error;\n    async fn check_permission(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _action: \u0026str,\n        _resource: \u0026str,\n    ) -\u003e anyhow::Result\u003cbool\u003e {\n        Ok(true)\n    }\n    async fn get_user_roles(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n    ) -\u003e anyhow::Result\u003cVec\u003cmk_core::types::Role\u003e\u003e {\n        Ok(vec![])\n    }\n    async fn assign_role(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _user_id: \u0026mk_core::types::UserId,\n        _role: mk_core::types::Role,\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n    async fn remove_role(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _user_id: \u0026mk_core::types::UserId,\n        _role: mk_core::types::Role,\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n}\n\nasync fn setup_postgres_container() -\u003e Result\u003c\n    (\n        testcontainers::ContainerAsync\u003ctestcontainers_modules::postgres::Postgres\u003e,\n        String,\n    ),\n    Box\u003cdyn std::error::Error + Send + Sync\u003e,\n\u003e {\n    let container = testcontainers_modules::postgres::Postgres::default()\n        .with_db_name(\"testdb\")\n        .with_user(\"testuser\")\n        .with_password(\"testpass\")\n        .start()\n        .await\n        .map_err(|e| Box::new(e) as Box\u003cdyn std::error::Error + Send + Sync\u003e)?;\n\n    let connection_url = format!(\n        \"postgres://testuser:testpass@localhost:{}/testdb?sslmode=disable\",\n        container\n            .get_host_port_ipv4(5432)\n            .await\n            .map_err(|e| Box::new(e) as Box\u003cdyn std::error::Error + Send + Sync\u003e)?\n    );\n\n    Ok((container, connection_url))\n}\n\n#[tokio::test]\nasync fn test_knowledge_lifecycle_integration() -\u003e anyhow::Result\u003c()\u003e {\n    let (_container, connection_url) = setup_postgres_container()\n        .await\n        .map_err(|e| anyhow::anyhow!(e))?;\n    let temp_dir = tempfile::tempdir()?;\n    let repo_path = temp_dir.path().join(\"repo\");\n    let repo = Arc::new(GitRepository::new(\u0026repo_path)?);\n\n    let memory_manager = Arc::new(MemoryManager::new());\n    let mock_provider = MockProvider::new();\n    memory_manager\n        .register_provider(MemoryLayer::Project, Box::new(mock_provider))\n        .await;\n\n    let storage = Arc::new(MockStorage::new());\n    let persister = Arc::new(DatabasePersister::new(storage, \"sync_key\".to_string()));\n\n    let sync_manager = Arc::new(\n        SyncManager::new(\n            memory_manager.clone(),\n            repo.clone(),\n            Arc::new(knowledge::governance::GovernanceEngine::new()),\n            config::config::DeploymentConfig::default(),\n            None,\n            persister,\n        )\n        .await\n        .map_err(|e| anyhow::anyhow!(e))?,\n    );\n\n    let server = McpServer::new(\n        memory_manager,\n        sync_manager,\n        repo.clone(),\n        Arc::new(\n            storage::postgres::PostgresBackend::new(\u0026connection_url)\n                .await\n                .map_err(|e| anyhow::anyhow!(e.to_string()))?,\n        ),\n        Arc::new(knowledge::governance::GovernanceEngine::new()),\n        Arc::new(MockAuthService),\n        None,\n    );\n\n    // GIVEN a knowledge entry is stored in the repository\n    let entry = KnowledgeEntry {\n        path: \"specs/auth.md\".to_string(),\n        content: \"Auth spec content\".to_string(),\n        layer: KnowledgeLayer::Project,\n        kind: KnowledgeType::Spec,\n        metadata: HashMap::new(),\n        status: KnowledgeStatus::Accepted,\n        commit_hash: None,\n        author: None,\n        updated_at: chrono::Utc::now().timestamp(),\n    };\n    let tenant_id = mk_core::types::TenantId::new(\"t1\".into()).unwrap();\n    let user_id = mk_core::types::UserId::new(\"u1\".into()).unwrap();\n    let ctx = mk_core::types::TenantContext::new(tenant_id, user_id);\n\n    repo.store(ctx.clone(), entry, \"add auth spec\").await?;\n\n    // WHEN we query knowledge via MCP tool\n    let request = JsonRpcRequest {\n        jsonrpc: \"2.0\".to_string(),\n        id: json!(1),\n        method: \"tools/call\".to_string(),\n        params: Some(json!({\n            \"tenantContext\": {\n                \"tenant_id\": \"t1\",\n                \"user_id\": \"u1\"\n            },\n            \"name\": \"knowledge_query\",\n            \"arguments\": {\n                \"query\": \"Auth\",\n                \"layers\": [\"project\"]\n            }\n        })),\n    };\n\n    let response = server.handle_request(request).await;\n\n    // THEN the query should return the entry\n    assert!(\n        response.error.is_none(),\n        \"Response should not have error: {:?}\",\n        response.error\n    );\n    let result = response.result.unwrap();\n    assert!(result[\"success\"].as_bool().unwrap());\n    assert_eq!(result[\"results\"][\"keyword\"].as_array().unwrap().len(), 1);\n\n    // WHEN we fetch the specific entry via MCP tool\n    let request = JsonRpcRequest {\n        jsonrpc: \"2.0\".to_string(),\n        id: json!(2),\n        method: \"tools/call\".to_string(),\n        params: Some(json!({\n            \"tenantContext\": {\n                \"tenant_id\": \"t1\",\n                \"user_id\": \"u1\"\n            },\n            \"name\": \"knowledge_get\",\n            \"arguments\": {\n                \"path\": \"specs/auth.md\",\n                \"layer\": \"project\"\n            }\n        })),\n    };\n\n    let response = server.handle_request(request).await;\n\n    // THEN the entry content should match\n    assert!(response.error.is_none());\n    let result = response.result.unwrap();\n    assert!(result[\"success\"].as_bool().unwrap());\n    assert_eq!(result[\"entry\"][\"content\"], \"Auth spec content\");\n\n    Ok(())\n}\n","traces":[{"line":21,"address":[],"length":0,"stats":{"Line":1}},{"line":23,"address":[],"length":0,"stats":{"Line":2}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":207,"address":[],"length":0,"stats":{"Line":1}},{"line":214,"address":[],"length":0,"stats":{"Line":3}},{"line":219,"address":[],"length":0,"stats":{"Line":1}},{"line":220,"address":[],"length":0,"stats":{"Line":1}},{"line":222,"address":[],"length":0,"stats":{"Line":2}},{"line":224,"address":[],"length":0,"stats":{"Line":1}},{"line":225,"address":[],"length":0,"stats":{"Line":1}},{"line":226,"address":[],"length":0,"stats":{"Line":1}},{"line":227,"address":[],"length":0,"stats":{"Line":1}},{"line":230,"address":[],"length":0,"stats":{"Line":1}}],"covered":12,"coverable":13},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","tests","knowledge_tools.rs"],"content":"use knowledge::repository::GitRepository;\nuse memory::manager::MemoryManager;\nuse mk_core::types::{KnowledgeEntry, KnowledgeLayer, KnowledgeStatus, KnowledgeType};\nuse serde_json::json;\nuse std::sync::Arc;\nuse tempfile::tempdir;\nuse tools::knowledge::{KnowledgeGetTool, KnowledgeQueryTool};\nuse tools::tools::Tool;\n\n#[tokio::test]\nasync fn test_knowledge_tools() -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    // GIVEN a GitRepository and tools\n    let dir = tempdir()?;\n    let repo = Arc::new(GitRepository::new(dir.path())?);\n    let memory_manager = Arc::new(MemoryManager::new());\n\n    let query_tool = KnowledgeQueryTool::new(memory_manager, repo.clone());\n    let show_tool = KnowledgeGetTool::new(repo.clone());\n\n    // AND some existing knowledge\n    let entry = KnowledgeEntry {\n        path: \"architecture/core.md\".to_string(),\n        content: \"# Core Architecture\\nHierarchical memory system.\".to_string(),\n        layer: KnowledgeLayer::Project,\n        kind: KnowledgeType::Spec,\n        metadata: std::collections::HashMap::new(),\n        status: KnowledgeStatus::Accepted,\n        commit_hash: None,\n        author: None,\n        updated_at: chrono::Utc::now().timestamp(),\n    };\n    let tenant_id = mk_core::types::TenantId::new(\"t1\".into()).unwrap();\n    let user_id = mk_core::types::UserId::new(\"u1\".into()).unwrap();\n    let ctx = mk_core::types::TenantContext::new(tenant_id, user_id);\n\n    mk_core::traits::KnowledgeRepository::store(repo.as_ref(), ctx, entry, \"initial docs\").await?;\n\n    // WHEN querying knowledge\n    let query_resp = query_tool\n        .call(json!({\n            \"tenantContext\": {\n                \"tenant_id\": \"t1\",\n                \"user_id\": \"u1\"\n            },\n            \"query\": \"Architecture\",\n            \"layers\": [\"project\"]\n        }))\n        .await?;\n\n    // THEN it should find the entry\n    assert!(query_resp[\"success\"].as_bool().unwrap());\n    assert!(query_resp[\"results\"][\"keyword\"].as_array().unwrap().len() \u003e= 1);\n    assert_eq!(\n        query_resp[\"results\"][\"keyword\"][0][\"path\"],\n        \"architecture/core.md\"\n    );\n\n    // WHEN showing specific knowledge\n    let show_resp = show_tool\n        .call(json!({\n            \"tenantContext\": {\n                \"tenant_id\": \"t1\",\n                \"user_id\": \"u1\"\n            },\n            \"layer\": \"project\",\n            \"path\": \"architecture/core.md\"\n        }))\n        .await?;\n\n    // THEN it should return the full content\n    assert!(show_resp[\"success\"].as_bool().unwrap());\n    assert_eq!(\n        show_resp[\"entry\"][\"content\"],\n        \"# Core Architecture\\nHierarchical memory system.\"\n    );\n\n    Ok(())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","tests","memory_tools.rs"],"content":"use memory::manager::MemoryManager;\nuse memory::providers::MockProvider;\nuse mk_core::types::MemoryLayer;\nuse serde_json::json;\nuse std::sync::Arc;\nuse tools::memory::{MemoryAddTool, MemoryDeleteTool, MemorySearchTool};\nuse tools::tools::Tool;\n\n#[tokio::test]\nasync fn test_memory_tools() -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    // GIVEN a MemoryManager and tools\n    let memory_manager = Arc::new(\n        MemoryManager::new()\n            .with_embedding_service(Arc::new(memory::embedding::MockEmbeddingService::new(1536))),\n    );\n    memory_manager\n        .register_provider(MemoryLayer::User, Box::new(MockProvider::new()))\n        .await;\n\n    let add_tool = MemoryAddTool::new(memory_manager.clone());\n    let search_tool = MemorySearchTool::new(memory_manager.clone());\n    let delete_tool = MemoryDeleteTool::new(memory_manager.clone());\n\n    let tenant_context = json!({\n        \"tenant_id\": \"test-tenant\",\n        \"user_id\": \"test-user\"\n    });\n\n    // WHEN adding memory\n    let add_resp = add_tool\n        .call(json!({\n            \"content\": \"User prefers Rust\",\n            \"layer\": \"user\",\n            \"identifiers\": {\n                \"user_id\": \"test_user_123\"\n            },\n            \"tags\": [\"coding\"],\n            \"tenantContext\": tenant_context\n        }))\n        .await?;\n\n    // THEN it should succeed\n    assert!(add_resp[\"success\"].as_bool().unwrap());\n    let memory_id = add_resp[\"memoryId\"].as_str().unwrap().to_string();\n\n    // WHEN searching memory\n    let search_resp = search_tool\n        .call(json!({\n            \"query\": \"rust\",\n            \"tenantContext\": tenant_context\n        }))\n        .await?;\n\n    // THEN it should find the entry\n    assert!(search_resp[\"success\"].as_bool().unwrap());\n    assert_eq!(search_resp[\"totalCount\"], 1);\n    assert_eq!(search_resp[\"results\"][0][\"content\"], \"User prefers Rust\");\n\n    // WHEN deleting memory\n    let delete_resp = delete_tool\n        .call(json!({\n            \"memory_id\": memory_id,\n            \"layer\": \"user\",\n            \"tenantContext\": tenant_context\n        }))\n        .await?;\n\n    // THEN it should succeed\n    assert!(delete_resp[\"success\"].as_bool().unwrap());\n\n    // AND search should return empty\n    let search_resp = search_tool\n        .call(json!({\n            \"query\": \"rust\",\n            \"tenantContext\": tenant_context\n        }))\n        .await?;\n    assert_eq!(search_resp[\"totalCount\"], 0);\n\n    Ok(())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","tests","redis_publisher_test.rs"],"content":"use mk_core::types::{GovernanceEvent, TenantId, UnitType};\nuse redis::AsyncCommands;\nuse std::time::Duration;\nuse testcontainers::runners::AsyncRunner;\nuse testcontainers_modules::redis::Redis;\nuse tools::redis_publisher::RedisPublisher;\n\n#[tokio::test]\nasync fn test_redis_publisher_start_run() {\n    let container = match Redis::default().start().await {\n        Ok(c) =\u003e c,\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Redis test: Docker not available\");\n            return;\n        }\n    };\n\n    let port = container.get_host_port_ipv4(6379).await.unwrap();\n    let redis_url = format!(\"redis://localhost:{}\", port);\n\n    let publisher = RedisPublisher::new_with_tenant_isolation(\n        redis_url.clone(),\n        \"governance:events\".to_string(),\n    );\n    let (tx, _handle) = publisher.start();\n\n    let tenant_id = TenantId::new(\"tenant-abc\".to_string()).unwrap();\n    let event = GovernanceEvent::UnitCreated {\n        unit_id: \"u1\".to_string(),\n        unit_type: UnitType::Project,\n        tenant_id: tenant_id.clone(),\n        parent_id: None,\n        timestamp: 1000,\n    };\n\n    tx.send(event).unwrap();\n\n    tokio::time::sleep(Duration::from_millis(500)).await;\n\n    let client = redis::Client::open(redis_url).unwrap();\n    let mut conn = client.get_connection_manager().await.unwrap();\n\n    let stream_key = format!(\"governance:events:{}\", tenant_id.as_str());\n\n    let mut results: redis::streams::StreamReadReply =\n        redis::streams::StreamReadReply { keys: vec![] };\n    for _ in 0..15 {\n        let r: redis::streams::StreamReadReply = conn.xread(\u0026[\u0026stream_key], \u0026[\"0\"]).await.unwrap();\n        if !r.keys.is_empty() {\n            results = r;\n            break;\n        }\n        tokio::time::sleep(Duration::from_millis(300)).await;\n    }\n\n    assert!(!results.keys.is_empty());\n    assert!(!results.keys[0].ids.is_empty());\n}\n\n#[tokio::test]\nasync fn test_factory_functions() {\n    let redis_url = \"redis://localhost:6379\".to_string();\n    let tenant_id = TenantId::new(\"t1\".to_string()).unwrap();\n\n    let _ = tools::redis_publisher::create_redis_publisher_with_tenant_isolation(redis_url.clone());\n    let _ =\n        tools::redis_publisher::create_redis_publisher_for_tenant(redis_url.clone(), \u0026tenant_id);\n    let _ = tools::redis_publisher::create_redis_publisher(redis_url, \"custom\".to_string());\n\n    assert!(true);\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","tests","tenant_isolation_e2e.rs"],"content":"use async_trait::async_trait;\nuse knowledge::repository::GitRepository;\nuse memory::providers::MockProvider;\nuse mk_core::traits::{AuthorizationService, KnowledgeRepository, StorageBackend};\nuse mk_core::types::{\n    KnowledgeEntry, KnowledgeLayer, KnowledgeType, OrganizationalUnit, Policy, Role, TenantContext,\n    TenantId, UserId,\n};\nuse serde_json::json;\nuse std::sync::Arc;\nuse tempfile::tempdir;\nuse tools::server::{JsonRpcRequest, McpServer};\n\nstruct MockAuthService;\n\n#[async_trait]\nimpl AuthorizationService for MockAuthService {\n    type Error = anyhow::Error;\n\n    async fn check_permission(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        _action: \u0026str,\n        _resource: \u0026str,\n    ) -\u003e anyhow::Result\u003cbool\u003e {\n        let tenant_id = ctx.tenant_id.as_str();\n        let user_id = ctx.user_id.as_str();\n\n        // Strict isolation for test\n        if (tenant_id == \"t1\" \u0026\u0026 user_id == \"u1\") || (tenant_id == \"t2\" \u0026\u0026 user_id == \"u2\") {\n            Ok(true)\n        } else {\n            Ok(false)\n        }\n    }\n\n    async fn get_user_roles(\u0026self, _ctx: \u0026TenantContext) -\u003e anyhow::Result\u003cVec\u003cRole\u003e\u003e {\n        Ok(vec![])\n    }\n    async fn assign_role(\n        \u0026self,\n        _ctx: \u0026TenantContext,\n        _user_id: \u0026UserId,\n        _role: Role,\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n    async fn remove_role(\n        \u0026self,\n        _ctx: \u0026TenantContext,\n        _user_id: \u0026UserId,\n        _role: Role,\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n}\n\nstruct MockStorage;\n\n#[async_trait]\nimpl StorageBackend for MockStorage {\n    type Error = storage::postgres::PostgresError;\n\n    async fn store(\n        \u0026self,\n        _ctx: TenantContext,\n        _key: \u0026str,\n        _value: \u0026[u8],\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn retrieve(\n        \u0026self,\n        _ctx: TenantContext,\n        _key: \u0026str,\n    ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n    async fn delete(\u0026self, _ctx: TenantContext, _key: \u0026str) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn exists(\u0026self, _ctx: TenantContext, _key: \u0026str) -\u003e Result\u003cbool, Self::Error\u003e {\n        Ok(false)\n    }\n    async fn get_ancestors(\n        \u0026self,\n        _ctx: TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n    async fn get_descendants(\n        \u0026self,\n        _ctx: TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n    async fn get_unit_policies(\n        \u0026self,\n        _ctx: TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cPolicy\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n    async fn create_unit(\u0026self, _unit: \u0026OrganizationalUnit) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn add_unit_policy(\n        \u0026self,\n        _ctx: \u0026TenantContext,\n        _unit_id: \u0026str,\n        _policy: \u0026Policy,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn assign_role(\n        \u0026self,\n        _user_id: \u0026UserId,\n        _tenant_id: \u0026TenantId,\n        _unit_id: \u0026str,\n        _role: Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn remove_role(\n        \u0026self,\n        _user_id: \u0026UserId,\n        _tenant_id: \u0026TenantId,\n        _unit_id: \u0026str,\n        _role: Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn store_drift_result(\n        \u0026self,\n        _result: mk_core::types::DriftResult,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn get_latest_drift_result(\n        \u0026self,\n        _ctx: TenantContext,\n        _project_id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cmk_core::types::DriftResult\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n    async fn list_all_units(\u0026self) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n    async fn record_job_status(\n        \u0026self,\n        _job_name: \u0026str,\n        _tenant_id: \u0026str,\n        _status: \u0026str,\n        _message: Option\u003c\u0026str\u003e,\n        _started_at: i64,\n        _finished_at: Option\u003ci64\u003e,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn get_governance_events(\n        \u0026self,\n        _ctx: TenantContext,\n        _since_timestamp: i64,\n        _limit: usize,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n}\n\nstruct MockPersister;\n#[async_trait]\nimpl sync::state_persister::SyncStatePersister for MockPersister {\n    async fn load(\n        \u0026self,\n        _tenant_id: \u0026TenantId,\n    ) -\u003e Result\u003csync::state::SyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        Ok(sync::state::SyncState::default())\n    }\n    async fn save(\n        \u0026self,\n        _tenant_id: \u0026TenantId,\n        _state: \u0026sync::state::SyncState,\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        Ok(())\n    }\n}\n\n#[tokio::test]\nasync fn test_tenant_isolation_e2e() -\u003e anyhow::Result\u003c()\u003e {\n    // 1. Setup Environment\n    let dir = tempdir()?;\n    let repo = Arc::new(GitRepository::new(dir.path())?);\n    let memory_manager = Arc::new(memory::manager::MemoryManager::new());\n    memory_manager\n        .register_provider(\n            mk_core::types::MemoryLayer::User,\n            Box::new(MockProvider::new()),\n        )\n        .await;\n\n    let governance_engine = Arc::new(knowledge::governance::GovernanceEngine::new());\n\n    let auth_service = Arc::new(MockAuthService);\n    let storage_backend = Arc::new(MockStorage);\n\n    let sync_manager = Arc::new(\n        sync::bridge::SyncManager::new(\n            memory_manager.clone(),\n            repo.clone(),\n            governance_engine.clone(),\n            config::config::DeploymentConfig::default(),\n            None,\n            Arc::new(MockPersister),\n        )\n        .await\n        .map_err(|e| anyhow::anyhow!(e.to_string()))?,\n    );\n\n    let server = McpServer::new(\n        memory_manager,\n        sync_manager,\n        repo,\n        storage_backend,\n        governance_engine,\n        auth_service,\n        None,\n    );\n\n    // 2. Test Success: User u1 calling tool with Tenant t1\n    let success_request = JsonRpcRequest {\n        jsonrpc: \"2.0\".to_string(),\n        id: json!(1),\n        method: \"tools/call\".to_string(),\n        params: Some(json!({\n            \"tenantContext\": {\n                \"tenant_id\": \"t1\",\n                \"user_id\": \"u1\"\n            },\n            \"name\": \"memory_add\",\n            \"arguments\": {\n                \"content\": \"Secret for t1\",\n                \"layer\": \"user\"\n            }\n        })),\n    };\n\n    let response = server.handle_request(success_request).await;\n    assert!(\n        response.error.is_none(),\n        \"Should succeed for authorized user: {:?}\",\n        response.error\n    );\n\n    // 3. Test Failure: User u1 calling tool with Tenant t2 (Cross-tenant attempt)\n    let failure_request = JsonRpcRequest {\n        jsonrpc: \"2.0\".to_string(),\n        id: json!(2),\n        method: \"tools/call\".to_string(),\n        params: Some(json!({\n            \"tenantContext\": {\n                \"tenant_id\": \"t2\",\n                \"user_id\": \"u1\"\n            },\n            \"name\": \"memory_add\",\n            \"arguments\": {\n                \"content\": \"Attempted breach\",\n                \"layer\": \"user\"\n            }\n        })),\n    };\n\n    let response = server.handle_request(failure_request).await;\n    assert!(\n        response.error.is_some(),\n        \"Should fail for cross-tenant access\"\n    );\n    let error = response.error.unwrap();\n    assert_eq!(error.code, -32002); // Authorization error code\n    assert!(error.message.contains(\"Authorization error\"));\n\n    Ok(())\n}\n","traces":[{"line":37,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":5},{"path":["/","Users","christian.klat","dev","git","aeterna","utils","src","lib.rs"],"content":"//! # Memory-Knowledge Utilities\n//!\n//! Common utility functions for hashing, validation, and UUID generation.\n//!\n//! # Best Practices\n//!\n//! - Uses SHA-2 for secure hashing\n//! - Uses UUID v4 with serde support\n//! - Validates inputs with comprehensive error messages\n\nuse sha2::{Digest, Sha256};\nuse uuid::Uuid;\n\n/// Compute SHA-256 hash of content string\n///\n/// # Examples\n///\n/// ```\n/// use utils::compute_content_hash;\n///\n/// let hash = compute_content_hash(\"hello world\");\n/// assert_eq!(hash.len(), 64);\n/// ```\n#[must_use]\npub fn compute_content_hash(content: \u0026str) -\u003e String {\n    let mut hasher = Sha256::new();\n    hasher.update(content.as_bytes());\n    format!(\"{:x}\", hasher.finalize())\n}\n\n/// Compute hash of knowledge item for change detection\n///\n/// Hashes content, constraints, and status fields.\n#[must_use]\npub fn compute_knowledge_hash(item: \u0026serde_json::Value) -\u003e String {\n    let mut hasher = Sha256::new();\n\n    // Extract fields for hashing\n    if let Some(content_str) = item.get(\"content\").and_then(|c| c.as_str()) {\n        hasher.update(content_str.as_bytes());\n    }\n\n    if let Some(constraints) = item.get(\"constraints\") {\n        let constraints_json =\n            serde_json::to_string(constraints).expect(\"Failed to serialize constraints\");\n        hasher.update(constraints_json.as_bytes());\n    }\n\n    if let Some(status_str) = item.get(\"status\").and_then(|s| s.as_str()) {\n        hasher.update(status_str.as_bytes());\n    }\n\n    format!(\"{:x}\", hasher.finalize())\n}\n\n/// Generate UUID v4 string\n#[must_use]\npub fn generate_uuid() -\u003e String {\n    Uuid::new_v4().to_string()\n}\n\n/// Validate memory layer string\n#[must_use]\npub fn is_valid_layer(layer: \u0026str) -\u003e bool {\n    matches!(\n        layer,\n        \"agent\" | \"user\" | \"session\" | \"project\" | \"team\" | \"org\" | \"company\"\n    )\n}\n\n/// Validate knowledge type string\n#[must_use]\npub fn is_valid_knowledge_type(ktype: \u0026str) -\u003e bool {\n    matches!(ktype, \"adr\" | \"policy\" | \"pattern\" | \"spec\")\n}\n\n/// Validate knowledge layer string\n#[must_use]\npub fn is_valid_knowledge_layer(layer: \u0026str) -\u003e bool {\n    matches!(layer, \"company\" | \"org\" | \"team\" | \"project\")\n}\n\n/// Redact PII from content string\n///\n/// Currently redacts emails and simple phone numbers.\n#[must_use]\npub fn redact_pii(content: \u0026str) -\u003e String {\n    let email_re = regex::Regex::new(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\").unwrap();\n    let result = email_re.replace_all(content, \"[REDACTED_EMAIL]\");\n\n    let phone_re = regex::Regex::new(r\"\\d{3}-\\d{3}-\\d{4}\").unwrap();\n    phone_re\n        .replace_all(\u0026result, \"[REDACTED_PHONE]\")\n        .to_string()\n}\n\n/// Get layer precedence value for memory layers\n#[must_use]\npub fn get_layer_precedence(layer: \u0026str) -\u003e u8 {\n    match layer {\n        \"agent\" =\u003e 1,\n        \"user\" =\u003e 2,\n        \"session\" =\u003e 3,\n        \"project\" =\u003e 4,\n        \"team\" =\u003e 5,\n        \"org\" =\u003e 6,\n        \"company\" =\u003e 7,\n        _ =\u003e 7 // Default to lowest precedence\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_compute_content_hash_consistency() {\n        let content = \"test content\";\n        let hash1 = compute_content_hash(content);\n        let hash2 = compute_content_hash(content);\n        assert_eq!(hash1, hash2);\n    }\n\n    #[test]\n    fn test_generate_uuid_uniqueness() {\n        let uuid1 = generate_uuid();\n        let uuid2 = generate_uuid();\n        assert_ne!(uuid1, uuid2);\n    }\n\n    #[test]\n    fn test_layer_validation_valid() {\n        assert!(is_valid_layer(\"agent\"));\n        assert!(is_valid_layer(\"user\"));\n        assert!(is_valid_layer(\"company\"));\n    }\n\n    #[test]\n    fn test_layer_validation_invalid() {\n        assert!(!is_valid_layer(\"invalid\"));\n        assert!(!is_valid_layer(\"agent-user\"));\n    }\n\n    #[test]\n    fn test_redact_pii() {\n        let content = \"Contact alice@example.com at 123-456-7890.\";\n        let redacted = redact_pii(content);\n        assert_eq!(redacted, \"Contact [REDACTED_EMAIL] at [REDACTED_PHONE].\");\n    }\n\n    #[test]\n    fn test_compute_knowledge_hash() {\n        let item = serde_json::json!({\n            \"content\": \"test content\",\n            \"status\": \"accepted\",\n            \"constraints\": [\"rule1\"]\n        });\n        let hash = compute_knowledge_hash(\u0026item);\n        assert_eq!(hash.len(), 64);\n\n        let item2 = serde_json::json!({\n            \"content\": \"test content\",\n            \"status\": \"accepted\",\n            \"constraints\": [\"rule1\"]\n        });\n        assert_eq!(hash, compute_knowledge_hash(\u0026item2));\n\n        let item3 = serde_json::json!({\n            \"content\": \"different content\",\n            \"status\": \"accepted\",\n            \"constraints\": [\"rule1\"]\n        });\n        assert_ne!(hash, compute_knowledge_hash(\u0026item3));\n    }\n\n    #[test]\n    fn test_is_valid_knowledge_type() {\n        assert!(is_valid_knowledge_type(\"adr\"));\n        assert!(is_valid_knowledge_type(\"policy\"));\n        assert!(!is_valid_knowledge_type(\"unknown\"));\n    }\n\n    #[test]\n    fn test_is_valid_knowledge_layer() {\n        assert!(is_valid_knowledge_layer(\"project\"));\n        assert!(is_valid_knowledge_layer(\"company\"));\n        assert!(!is_valid_knowledge_layer(\"user\"));\n    }\n\n    #[test]\n    fn test_get_layer_precedence() {\n        assert_eq!(get_layer_precedence(\"agent\"), 1);\n        assert_eq!(get_layer_precedence(\"company\"), 7);\n        assert_eq!(get_layer_precedence(\"unknown\"), 7);\n    }\n}\n","traces":[{"line":25,"address":[],"length":0,"stats":{"Line":3051}},{"line":26,"address":[],"length":0,"stats":{"Line":6102}},{"line":27,"address":[],"length":0,"stats":{"Line":12204}},{"line":28,"address":[],"length":0,"stats":{"Line":12204}},{"line":35,"address":[],"length":0,"stats":{"Line":3}},{"line":36,"address":[],"length":0,"stats":{"Line":6}},{"line":39,"address":[],"length":0,"stats":{"Line":21}},{"line":40,"address":[],"length":0,"stats":{"Line":9}},{"line":43,"address":[],"length":0,"stats":{"Line":9}},{"line":44,"address":[],"length":0,"stats":{"Line":6}},{"line":45,"address":[],"length":0,"stats":{"Line":15}},{"line":46,"address":[],"length":0,"stats":{"Line":9}},{"line":49,"address":[],"length":0,"stats":{"Line":21}},{"line":50,"address":[],"length":0,"stats":{"Line":9}},{"line":53,"address":[],"length":0,"stats":{"Line":12}},{"line":58,"address":[],"length":0,"stats":{"Line":2}},{"line":59,"address":[],"length":0,"stats":{"Line":4}},{"line":64,"address":[],"length":0,"stats":{"Line":5}},{"line":65,"address":[],"length":0,"stats":{"Line":3}},{"line":66,"address":[],"length":0,"stats":{"Line":5}},{"line":73,"address":[],"length":0,"stats":{"Line":3}},{"line":74,"address":[],"length":0,"stats":{"Line":12}},{"line":79,"address":[],"length":0,"stats":{"Line":3}},{"line":80,"address":[],"length":0,"stats":{"Line":14}},{"line":87,"address":[],"length":0,"stats":{"Line":2074}},{"line":88,"address":[],"length":0,"stats":{"Line":8296}},{"line":89,"address":[],"length":0,"stats":{"Line":8296}},{"line":91,"address":[],"length":0,"stats":{"Line":8296}},{"line":92,"address":[],"length":0,"stats":{"Line":4148}},{"line":93,"address":[],"length":0,"stats":{"Line":2074}},{"line":99,"address":[],"length":0,"stats":{"Line":3}},{"line":100,"address":[],"length":0,"stats":{"Line":3}},{"line":101,"address":[],"length":0,"stats":{"Line":4}},{"line":102,"address":[],"length":0,"stats":{"Line":2}},{"line":103,"address":[],"length":0,"stats":{"Line":2}},{"line":104,"address":[],"length":0,"stats":{"Line":2}},{"line":105,"address":[],"length":0,"stats":{"Line":2}},{"line":106,"address":[],"length":0,"stats":{"Line":2}},{"line":107,"address":[],"length":0,"stats":{"Line":3}},{"line":108,"address":[],"length":0,"stats":{"Line":1}}],"covered":40,"coverable":40}]};
        var previousData = {"files":[{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","auth","cedar.rs"],"content":"use async_trait::async_trait;\nuse cedar_policy::*;\nuse mk_core::traits::AuthorizationService;\nuse mk_core::types::{Role, TenantContext, UserId};\nuse std::str::FromStr;\nuse thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum CedarError {\n    #[error(\"Cedar evaluation error: {0}\")]\n    Evaluation(String),\n    #[error(\"Policy parsing error: {0}\")]\n    Parse(String),\n    #[error(\"Schema error: {0}\")]\n    Schema(String)\n}\n\npub struct CedarAuthorizer {\n    policies: PolicySet,\n    entities: Entities\n}\n\nimpl CedarAuthorizer {\n    pub fn new(policy_text: \u0026str, _schema_text: \u0026str) -\u003e Result\u003cSelf, CedarError\u003e {\n        let policies =\n            PolicySet::from_str(policy_text).map_err(|e| CedarError::Parse(e.to_string()))?;\n\n        Ok(Self {\n            policies,\n            entities: Entities::empty()\n        })\n    }\n}\n\n#[async_trait]\nimpl AuthorizationService for CedarAuthorizer {\n    type Error = CedarError;\n\n    async fn check_permission(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        action: \u0026str,\n        resource: \u0026str\n    ) -\u003e Result\u003cbool, Self::Error\u003e {\n        if let Some(agent_id) = \u0026ctx.agent_id {\n            let agent_principal = EntityUid::from_str(\u0026format!(\"User::\\\"{}\\\"\", agent_id))\n                .map_err(|e| CedarError::Evaluation(e.to_string()))?;\n            let delegate_action = EntityUid::from_str(\"Action::\\\"ActAs\\\"\")\n                .map_err(|e| CedarError::Evaluation(e.to_string()))?;\n            let user_resource = EntityUid::from_str(\u0026format!(\"User::\\\"{}\\\"\", ctx.user_id.as_str()))\n                .map_err(|e| CedarError::Evaluation(e.to_string()))?;\n\n            let delegation_request = Request::new(\n                agent_principal,\n                delegate_action,\n                user_resource,\n                Context::empty(),\n                None\n            )\n            .map_err(|e| CedarError::Evaluation(e.to_string()))?;\n\n            let authorizer = Authorizer::new();\n            let delegation_answer =\n                authorizer.is_authorized(\u0026delegation_request, \u0026self.policies, \u0026self.entities);\n\n            if delegation_answer.decision() != Decision::Allow {\n                return Ok(false);\n            }\n        }\n\n        let principal_str = format!(\"User::\\\"{}\\\"\", ctx.user_id.as_str());\n\n        let principal = EntityUid::from_str(\u0026principal_str)\n            .map_err(|e| CedarError::Evaluation(e.to_string()))?;\n        let action_uid = EntityUid::from_str(\u0026format!(\"Action::\\\"{}\\\"\", action))\n            .map_err(|e| CedarError::Evaluation(e.to_string()))?;\n        let resource_uid =\n            EntityUid::from_str(resource).map_err(|e| CedarError::Evaluation(e.to_string()))?;\n\n        let request = Request::new(principal, action_uid, resource_uid, Context::empty(), None)\n            .map_err(|e| CedarError::Evaluation(e.to_string()))?;\n\n        let authorizer = Authorizer::new();\n        let answer = authorizer.is_authorized(\u0026request, \u0026self.policies, \u0026self.entities);\n\n        Ok(answer.decision() == Decision::Allow)\n    }\n\n    async fn get_user_roles(\u0026self, _ctx: \u0026TenantContext) -\u003e Result\u003cVec\u003cRole\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n\n    async fn assign_role(\n        \u0026self,\n        _ctx: \u0026TenantContext,\n        _user_id: \u0026UserId,\n        _role: Role\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn remove_role(\n        \u0026self,\n        _ctx: \u0026TenantContext,\n        _user_id: \u0026UserId,\n        _role: Role\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::{TenantId, UserId};\n\n    #[tokio::test]\n    async fn test_cedar_authorization() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n        let schema = r#\"{\n            \"\": {\n                \"entityTypes\": {\n                    \"User\": {},\n                    \"Unit\": {}\n                },\n                \"actions\": {\n                    \"View\": {\n                        \"appliesTo\": {\n                            \"principalTypes\": [\"User\"],\n                            \"resourceTypes\": [\"Unit\"]\n                        }\n                    }\n                }\n            }\n        }\"#;\n\n        let policies = r#\"\n            permit(principal == User::\"u1\", action == Action::\"View\", resource == Unit::\"unit1\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, schema)?;\n\n        let ctx = TenantContext::new(\n            TenantId::new(\"t1\".into()).unwrap(),\n            UserId::new(\"u1\".into()).unwrap()\n        );\n\n        let allowed = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"unit1\\\"\")\n            .await?;\n        assert!(allowed);\n\n        let denied = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"unit2\\\"\")\n            .await?;\n        assert!(!denied);\n\n        Ok(())\n    }\n}\n","traces":[{"line":24,"address":[],"length":0,"stats":{"Line":38}},{"line":25,"address":[],"length":0,"stats":{"Line":36}},{"line":26,"address":[],"length":0,"stats":{"Line":120}},{"line":28,"address":[],"length":0,"stats":{"Line":36}},{"line":29,"address":[],"length":0,"stats":{"Line":36}},{"line":30,"address":[],"length":0,"stats":{"Line":36}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":2}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}}],"covered":7,"coverable":15},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","auth","mod.rs"],"content":"pub mod cedar;\npub mod permit;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","auth","permit.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::AuthorizationService;\nuse mk_core::types::{Role, TenantContext, UserId};\nuse serde::{Deserialize, Serialize};\nuse thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum PermitError {\n    #[error(\"Permit.io API error: {0}\")]\n    Api(String),\n    #[error(\"Authorization denied\")]\n    Denied,\n    #[error(\"Configuration error: {0}\")]\n    Config(String),\n    #[error(\"HTTP error: {0}\")]\n    Http(#[from] reqwest::Error)\n}\n\n#[derive(Debug, Serialize, Deserialize)]\nstruct PermitCheckRequest {\n    user: String,\n    action: String,\n    resource: String,\n    tenant: Option\u003cString\u003e\n}\n\n#[derive(Debug, Serialize, Deserialize)]\nstruct PermitCheckResponse {\n    allow: bool\n}\n\npub struct PermitAuthorizationService {\n    pdp_url: String,\n    api_key: String,\n    client: reqwest::Client\n}\n\nimpl PermitAuthorizationService {\n    pub fn new(api_key: \u0026str, pdp_url: \u0026str) -\u003e Self {\n        Self {\n            pdp_url: pdp_url.trim_end_matches('/').to_string(),\n            api_key: api_key.to_string(),\n            client: reqwest::Client::new()\n        }\n    }\n}\n\n#[async_trait]\nimpl AuthorizationService for PermitAuthorizationService {\n    type Error = PermitError;\n\n    async fn check_permission(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        action: \u0026str,\n        resource: \u0026str\n    ) -\u003e Result\u003cbool, Self::Error\u003e {\n        let user_id = if let Some(agent_id) = \u0026ctx.agent_id {\n            agent_id.as_str()\n        } else {\n            ctx.user_id.as_str()\n        };\n        let tenant_id = ctx.tenant_id.as_str();\n\n        let url = format!(\"{}/allowed\", self.pdp_url);\n        let request = PermitCheckRequest {\n            user: user_id.to_string(),\n            action: action.to_string(),\n            resource: resource.to_string(),\n            tenant: Some(tenant_id.to_string())\n        };\n\n        let response = self\n            .client\n            .post(\u0026url)\n            .header(\"Authorization\", format!(\"Bearer {}\", self.api_key))\n            .json(\u0026request)\n            .send()\n            .await?;\n\n        if !response.status().is_success() {\n            return Err(PermitError::Api(format!(\"Status: {}\", response.status())));\n        }\n\n        let result: PermitCheckResponse = response.json().await?;\n        Ok(result.allow)\n    }\n\n    async fn get_user_roles(\u0026self, ctx: \u0026TenantContext) -\u003e Result\u003cVec\u003cRole\u003e, Self::Error\u003e {\n        let user_id = ctx.user_id.as_str();\n        let tenant_id = ctx.tenant_id.as_str();\n\n        let url = format!(\n            \"{}/users/{}/roles?tenant={}\",\n            self.pdp_url, user_id, tenant_id\n        );\n        let response = self\n            .client\n            .get(\u0026url)\n            .header(\"Authorization\", format!(\"Bearer {}\", self.api_key))\n            .send()\n            .await?;\n\n        if !response.status().is_success() {\n            return Err(PermitError::Api(format!(\n                \"Failed to fetch roles: {}\",\n                response.status()\n            )));\n        }\n\n        let roles_str: Vec\u003cString\u003e = response.json().await?;\n        let mut roles = Vec::new();\n        for r in roles_str {\n            if let Ok(role) = r.parse::\u003cRole\u003e() {\n                roles.push(role);\n            }\n        }\n        Ok(roles)\n    }\n\n    async fn assign_role(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        user_id: \u0026UserId,\n        role: Role\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        let tenant_id = ctx.tenant_id.as_str();\n\n        let url = format!(\"{}/roles/assign\", self.pdp_url);\n        let request = serde_json::json!({\n            \"user\": user_id.as_str(),\n            \"role\": role.to_string().to_lowercase(),\n            \"tenant\": tenant_id\n        });\n\n        let response = self\n            .client\n            .post(\u0026url)\n            .header(\"Authorization\", format!(\"Bearer {}\", self.api_key))\n            .json(\u0026request)\n            .send()\n            .await?;\n\n        if !response.status().is_success() {\n            return Err(PermitError::Api(format!(\n                \"Role assignment failed: {}\",\n                response.status()\n            )));\n        }\n\n        Ok(())\n    }\n\n    async fn remove_role(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        user_id: \u0026UserId,\n        role: Role\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        let tenant_id = ctx.tenant_id.as_str();\n\n        let url = format!(\"{}/roles/unassign\", self.pdp_url);\n        let request = serde_json::json!({\n            \"user\": user_id.as_str(),\n            \"role\": role.to_string().to_lowercase(),\n            \"tenant\": tenant_id\n        });\n\n        let response = self\n            .client\n            .post(\u0026url)\n            .header(\"Authorization\", format!(\"Bearer {}\", self.api_key))\n            .json(\u0026request)\n            .send()\n            .await?;\n\n        if !response.status().is_success() {\n            return Err(PermitError::Api(format!(\n                \"Role removal failed: {}\",\n                response.status()\n            )));\n        }\n\n        Ok(())\n    }\n}\n","traces":[{"line":39,"address":[],"length":0,"stats":{"Line":3}},{"line":41,"address":[],"length":0,"stats":{"Line":9}},{"line":42,"address":[],"length":0,"stats":{"Line":6}},{"line":43,"address":[],"length":0,"stats":{"Line":3}},{"line":89,"address":[],"length":0,"stats":{"Line":0}}],"covered":4,"coverable":5},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","ecosystem.rs"],"content":"use async_trait::async_trait;\nuse serde_json::Value;\nuse std::sync::Arc;\nuse tools::server::JsonRpcRequest;\nuse tools::server::McpServer;\n\n#[async_trait]\npub trait EcosystemAdapter: Send + Sync {\n    fn name(\u0026self) -\u003e \u0026str;\n    async fn handle_mcp_request(\u0026self, request: Value) -\u003e anyhow::Result\u003cValue\u003e;\n}\n\npub struct OpenCodeAdapter {\n    server: Arc\u003cMcpServer\u003e\n}\n\nimpl OpenCodeAdapter {\n    pub fn new(server: Arc\u003cMcpServer\u003e) -\u003e Self {\n        Self { server }\n    }\n\n    pub fn get_memory_tools(\u0026self) -\u003e Vec\u003cValue\u003e {\n        self.server\n            .list_tools()\n            .into_iter()\n            .filter(|t| t.name.starts_with(\"memory_\"))\n            .map(|t| serde_json::to_value(t).unwrap())\n            .collect()\n    }\n\n    pub fn get_knowledge_tools(\u0026self) -\u003e Vec\u003cValue\u003e {\n        self.server\n            .list_tools()\n            .into_iter()\n            .filter(|t| t.name.starts_with(\"knowledge_\"))\n            .map(|t| serde_json::to_value(t).unwrap())\n            .collect()\n    }\n}\n\n#[async_trait]\nimpl EcosystemAdapter for OpenCodeAdapter {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"opencode\"\n    }\n\n    async fn handle_mcp_request(\u0026self, request: Value) -\u003e anyhow::Result\u003cValue\u003e {\n        let rpc_request: JsonRpcRequest = serde_json::from_value(request)?;\n        let response = self.server.handle_request(rpc_request).await;\n        Ok(serde_json::to_value(response)?)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_opencode_adapter_name() {\n        fn assert_ecosystem_adapter\u003cT: EcosystemAdapter\u003e() {}\n\n        assert_ecosystem_adapter::\u003cOpenCodeAdapter\u003e();\n    }\n\n    #[test]\n    fn test_ecosystem_adapter_trait_bounds() {\n        fn assert_send_sync\u003cT: Send + Sync\u003e() {}\n\n        assert_send_sync::\u003cOpenCodeAdapter\u003e();\n    }\n\n    #[test]\n    fn test_opencode_adapter_method_signatures() {\n        let _: fn(Arc\u003cMcpServer\u003e) -\u003e OpenCodeAdapter = OpenCodeAdapter::new;\n    }\n}\n","traces":[{"line":18,"address":[],"length":0,"stats":{"Line":1}},{"line":22,"address":[],"length":0,"stats":{"Line":1}},{"line":23,"address":[],"length":0,"stats":{"Line":1}},{"line":26,"address":[],"length":0,"stats":{"Line":31}},{"line":27,"address":[],"length":0,"stats":{"Line":13}},{"line":31,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}}],"covered":5,"coverable":12},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","hooks.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::ContextHooks;\n\npub struct MemoryContextHooks {}\n\nimpl MemoryContextHooks {\n    pub fn new() -\u003e Self {\n        Self {}\n    }\n}\n\n#[async_trait]\nimpl ContextHooks for MemoryContextHooks {\n    async fn on_session_start(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _session_id: \u0026str\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n\n    async fn on_session_end(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _session_id: \u0026str\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n\n    async fn on_message(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _session_id: \u0026str,\n        _message: \u0026str\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n\n    async fn on_tool_use(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _session_id: \u0026str,\n        _tool_name: \u0026str,\n        _params: serde_json::Value\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::TenantContext;\n    use serde_json::json;\n\n    #[test]\n    fn test_memory_context_hooks_new() {\n        let hooks = MemoryContextHooks::new();\n        let _ = hooks;\n    }\n\n    #[tokio::test]\n    async fn test_memory_context_hooks_methods() {\n        let hooks = MemoryContextHooks::new();\n        let ctx = TenantContext::default();\n\n        assert!(\n            hooks\n                .on_session_start(ctx.clone(), \"test-session\")\n                .await\n                .is_ok()\n        );\n        assert!(\n            hooks\n                .on_session_end(ctx.clone(), \"test-session\")\n                .await\n                .is_ok()\n        );\n        assert!(\n            hooks\n                .on_message(ctx.clone(), \"test-session\", \"test message\")\n                .await\n                .is_ok()\n        );\n        assert!(\n            hooks\n                .on_tool_use(ctx, \"test-session\", \"test_tool\", json!({}))\n                .await\n                .is_ok()\n        );\n    }\n\n    #[test]\n    fn test_context_hooks_trait_implementation() {\n        use mk_core::traits::ContextHooks;\n\n        fn assert_implements_context_hooks\u003cT: ContextHooks\u003e() {}\n\n        assert_implements_context_hooks::\u003cMemoryContextHooks\u003e();\n    }\n\n    #[test]\n    fn test_hooks_send_sync_bounds() {\n        fn assert_send_sync\u003cT: Send + Sync\u003e() {}\n\n        assert_send_sync::\u003cMemoryContextHooks\u003e();\n    }\n}\n","traces":[{"line":7,"address":[],"length":0,"stats":{"Line":2}}],"covered":1,"coverable":1},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","langchain.rs"],"content":"use crate::ecosystem::EcosystemAdapter;\nuse async_trait::async_trait;\nuse serde_json::{Value, json};\nuse std::sync::Arc;\nuse tools::server::McpServer;\n\npub struct LangChainAdapter {\n    server: Arc\u003cMcpServer\u003e,\n}\n\nimpl LangChainAdapter {\n    pub fn new(server: Arc\u003cMcpServer\u003e) -\u003e Self {\n        Self { server }\n    }\n\n    pub fn to_langchain_tools(\u0026self) -\u003e Vec\u003cValue\u003e {\n        self.server\n            .list_tools()\n            .into_iter()\n            .map(|tool| {\n                let mut schema = tool.input_schema.clone();\n                if let Some(obj) = schema.as_object_mut() {\n                    obj.insert(\n                        \"$schema\".to_string(),\n                        json!(\"http://json-schema.org/draft-07/schema#\"),\n                    );\n                    obj.insert(\"additionalProperties\".to_string(), json!(false));\n                }\n\n                json!({\n                    \"name\": tool.name,\n                    \"description\": tool.description,\n                    \"parameters\": schema,\n                })\n            })\n            .collect()\n    }\n}\n\n#[async_trait]\nimpl EcosystemAdapter for LangChainAdapter {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"langchain\"\n    }\n\n    async fn handle_mcp_request(\u0026self, request: Value) -\u003e anyhow::Result\u003cValue\u003e {\n        let name = request[\"name\"]\n            .as_str()\n            .ok_or_else(|| anyhow::anyhow!(\"Missing tool name\"))?;\n        let arguments = request[\"arguments\"].clone();\n        let tenant_context = request[\"tenantContext\"].clone();\n\n        let mcp_request = json!({\n            \"jsonrpc\": \"2.0\",\n            \"id\": 1,\n            \"method\": \"tools/call\",\n            \"params\": {\n                \"name\": name,\n                \"arguments\": arguments,\n                \"tenantContext\": tenant_context\n            }\n        });\n\n        let response = self\n            .server\n            .handle_request(serde_json::from_value(mcp_request)?)\n            .await;\n        Ok(serde_json::to_value(response)?)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use memory::manager::MemoryManager;\n    use sync::bridge::SyncManager;\n\n    async fn setup_server() -\u003e McpServer {\n        let memory_manager = Arc::new(MemoryManager::new());\n        let repo = Arc::new(MockRepo);\n        let governance = Arc::new(knowledge::governance::GovernanceEngine::new());\n        let auth_service = Arc::new(MockAuthService);\n        let deployment_config = config::config::DeploymentConfig::default();\n        let sync_manager = Arc::new(\n            SyncManager::new(\n                memory_manager.clone(),\n                repo.clone(),\n                governance.clone(),\n                deployment_config,\n                None,\n                Arc::new(MockPersister),\n            )\n            .await\n            .unwrap(),\n        );\n\n        McpServer::new(\n            memory_manager,\n            sync_manager,\n            repo,\n            Arc::new(MockStorageBackend),\n            governance,\n            auth_service,\n            None,\n        )\n    }\n\n    struct MockStorageBackend;\n    #[async_trait::async_trait]\n    impl mk_core::traits::StorageBackend for MockStorageBackend {\n        type Error = storage::postgres::PostgresError;\n        async fn store(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _key: \u0026str,\n            _value: \u0026[u8],\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n        async fn retrieve(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _key: \u0026str,\n        ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e {\n            Ok(None)\n        }\n        async fn delete(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _key: \u0026str,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n        async fn exists(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _key: \u0026str,\n        ) -\u003e Result\u003cbool, Self::Error\u003e {\n            Ok(false)\n        }\n        async fn get_ancestors(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _unit_id: \u0026str,\n        ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n        async fn get_descendants(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _unit_id: \u0026str,\n        ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n        async fn get_unit_policies(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _unit_id: \u0026str,\n        ) -\u003e Result\u003cVec\u003cmk_core::types::Policy\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n        async fn create_unit(\n            \u0026self,\n            _unit: \u0026mk_core::types::OrganizationalUnit,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n        async fn add_unit_policy(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n            _unit_id: \u0026str,\n            _policy: \u0026mk_core::types::Policy,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n        async fn assign_role(\n            \u0026self,\n            _user_id: \u0026mk_core::types::UserId,\n            _tenant_id: \u0026mk_core::types::TenantId,\n            _unit_id: \u0026str,\n            _role: mk_core::types::Role,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n        async fn remove_role(\n            \u0026self,\n            _user_id: \u0026mk_core::types::UserId,\n            _tenant_id: \u0026mk_core::types::TenantId,\n            _unit_id: \u0026str,\n            _role: mk_core::types::Role,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n        async fn store_drift_result(\n            \u0026self,\n            _result: mk_core::types::DriftResult,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n        async fn get_latest_drift_result(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _project_id: \u0026str,\n        ) -\u003e Result\u003cOption\u003cmk_core::types::DriftResult\u003e, Self::Error\u003e {\n            Ok(None)\n        }\n        async fn list_all_units(\n            \u0026self,\n        ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n        async fn record_job_status(\n            \u0026self,\n            _job_name: \u0026str,\n            _tenant_id: \u0026str,\n            _status: \u0026str,\n            _message: Option\u003c\u0026str\u003e,\n            _started_at: i64,\n            _finished_at: Option\u003ci64\u003e,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n        async fn get_governance_events(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _since_timestamp: i64,\n            _limit: usize,\n        ) -\u003e Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n    }\n\n    struct MockAuthService;\n\n    #[async_trait::async_trait]\n    impl mk_core::traits::AuthorizationService for MockAuthService {\n        type Error = anyhow::Error;\n        async fn check_permission(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n            _action: \u0026str,\n            _resource: \u0026str,\n        ) -\u003e anyhow::Result\u003cbool\u003e {\n            Ok(true)\n        }\n        async fn get_user_roles(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n        ) -\u003e anyhow::Result\u003cVec\u003cmk_core::types::Role\u003e\u003e {\n            Ok(vec![])\n        }\n        async fn assign_role(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n            _user_id: \u0026mk_core::types::UserId,\n            _role: mk_core::types::Role,\n        ) -\u003e anyhow::Result\u003c()\u003e {\n            Ok(())\n        }\n        async fn remove_role(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n            _user_id: \u0026mk_core::types::UserId,\n            _role: mk_core::types::Role,\n        ) -\u003e anyhow::Result\u003c()\u003e {\n            Ok(())\n        }\n    }\n\n    struct MockRepo;\n    #[async_trait::async_trait]\n    impl mk_core::traits::KnowledgeRepository for MockRepo {\n        type Error = knowledge::repository::RepositoryError;\n        async fn store(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: mk_core::types::KnowledgeEntry,\n            _: \u0026str,\n        ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n            Ok(\"hash\".into())\n        }\n        async fn get(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: mk_core::types::KnowledgeLayer,\n            _: \u0026str,\n        ) -\u003e std::result::Result\u003cOption\u003cmk_core::types::KnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(None)\n        }\n        async fn list(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: mk_core::types::KnowledgeLayer,\n            _: \u0026str,\n        ) -\u003e std::result::Result\u003cVec\u003cmk_core::types::KnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n        async fn delete(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: mk_core::types::KnowledgeLayer,\n            _: \u0026str,\n            _: \u0026str,\n        ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n            Ok(\"hash\".into())\n        }\n        async fn get_head_commit(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n        ) -\u003e std::result::Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n            Ok(None)\n        }\n        async fn get_affected_items(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: \u0026str,\n        ) -\u003e std::result::Result\u003cVec\u003c(mk_core::types::KnowledgeLayer, String)\u003e, Self::Error\u003e\n        {\n            Ok(vec![])\n        }\n        async fn search(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: \u0026str,\n            _: Vec\u003cmk_core::types::KnowledgeLayer\u003e,\n            _: usize,\n        ) -\u003e std::result::Result\u003cVec\u003cmk_core::types::KnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n        fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n            None\n        }\n    }\n\n    struct MockPersister;\n    #[async_trait::async_trait]\n    impl sync::state_persister::SyncStatePersister for MockPersister {\n        async fn load(\n            \u0026self,\n            _tenant_id: \u0026mk_core::types::TenantId,\n        ) -\u003e std::result::Result\u003csync::state::SyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e\n        {\n            Ok(sync::state::SyncState::default())\n        }\n        async fn save(\n            \u0026self,\n            _tenant_id: \u0026mk_core::types::TenantId,\n            _: \u0026sync::state::SyncState,\n        ) -\u003e std::result::Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n            Ok(())\n        }\n    }\n\n    #[tokio::test]\n    async fn test_langchain_adapter_name() {\n        let server = Arc::new(setup_server().await);\n        let adapter = LangChainAdapter::new(server);\n        assert_eq!(adapter.name(), \"langchain\");\n    }\n\n    #[tokio::test]\n    async fn test_langchain_handle_request_missing_name() {\n        let server = Arc::new(setup_server().await);\n        let adapter = LangChainAdapter::new(server);\n        let request = json!({\"arguments\": {}});\n        let result = adapter.handle_mcp_request(request).await;\n        assert!(result.is_err());\n        assert_eq!(result.unwrap_err().to_string(), \"Missing tool name\");\n    }\n\n    #[tokio::test]\n    async fn test_to_langchain_tools_empty() {\n        let server = Arc::new(setup_server().await);\n        let adapter = LangChainAdapter::new(server);\n        let tools = adapter.to_langchain_tools();\n        assert!(!tools.is_empty());\n    }\n}\n","traces":[{"line":12,"address":[],"length":0,"stats":{"Line":6}},{"line":16,"address":[],"length":0,"stats":{"Line":3}},{"line":17,"address":[],"length":0,"stats":{"Line":3}},{"line":20,"address":[],"length":0,"stats":{"Line":48}},{"line":21,"address":[],"length":0,"stats":{"Line":135}},{"line":22,"address":[],"length":0,"stats":{"Line":135}},{"line":23,"address":[],"length":0,"stats":{"Line":135}},{"line":24,"address":[],"length":0,"stats":{"Line":135}},{"line":25,"address":[],"length":0,"stats":{"Line":90}},{"line":27,"address":[],"length":0,"stats":{"Line":180}},{"line":30,"address":[],"length":0,"stats":{"Line":45}},{"line":31,"address":[],"length":0,"stats":{"Line":45}},{"line":32,"address":[],"length":0,"stats":{"Line":45}},{"line":33,"address":[],"length":0,"stats":{"Line":45}},{"line":42,"address":[],"length":0,"stats":{"Line":1}},{"line":43,"address":[],"length":0,"stats":{"Line":1}},{"line":46,"address":[],"length":0,"stats":{"Line":3}},{"line":49,"address":[],"length":0,"stats":{"Line":2}}],"covered":18,"coverable":18},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","lib.rs"],"content":"//! # Adapters\n//!\n//! Provider and ecosystem adapters.\n\npub mod auth;\npub mod ecosystem;\npub mod hooks;\npub mod langchain;\npub mod opencode;\npub mod providers;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","opencode.rs"],"content":"\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","src","providers.rs"],"content":"\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","tests","auth_integration.rs"],"content":"use adapters::auth::permit::PermitAuthorizationService;\nuse mk_core::traits::AuthorizationService;\nuse mk_core::types::{TenantContext, TenantId, UserId};\nuse serde_json::json;\nuse std::str::FromStr;\nuse wiremock::matchers::{header, method, path};\nuse wiremock::{Mock, MockServer, ResponseTemplate};\n\n#[tokio::test]\nasync fn test_permit_authorization_allow() {\n    let mock_server = MockServer::start().await;\n    let api_key = \"test_key\";\n    let service = PermitAuthorizationService::new(api_key, \u0026mock_server.uri());\n\n    let ctx = TenantContext {\n        tenant_id: TenantId::from_str(\"tenant-1\").unwrap(),\n        user_id: UserId::from_str(\"user-1\").unwrap(),\n        agent_id: None\n    };\n\n    Mock::given(method(\"POST\"))\n        .and(path(\"/allowed\"))\n        .and(header(\"Authorization\", \u0026format!(\"Bearer {}\", api_key)))\n        .respond_with(ResponseTemplate::new(200).set_body_json(json!({ \"allow\": true })))\n        .mount(\u0026mock_server)\n        .await;\n\n    let allowed = service\n        .check_permission(\u0026ctx, \"memory:read\", \"hierarchical\")\n        .await\n        .unwrap();\n    assert!(allowed);\n}\n\n#[tokio::test]\nasync fn test_permit_authorization_deny() {\n    let mock_server = MockServer::start().await;\n    let api_key = \"test_key\";\n    let service = PermitAuthorizationService::new(api_key, \u0026mock_server.uri());\n\n    let ctx = TenantContext {\n        tenant_id: TenantId::from_str(\"tenant-1\").unwrap(),\n        user_id: UserId::from_str(\"user-1\").unwrap(),\n        agent_id: None\n    };\n\n    Mock::given(method(\"POST\"))\n        .and(path(\"/allowed\"))\n        .respond_with(ResponseTemplate::new(200).set_body_json(json!({ \"allow\": false })))\n        .mount(\u0026mock_server)\n        .await;\n\n    let allowed = service\n        .check_permission(\u0026ctx, \"memory:read\", \"hierarchical\")\n        .await\n        .unwrap();\n    assert!(!allowed);\n}\n\n#[tokio::test]\nasync fn test_permit_api_error() {\n    let mock_server = MockServer::start().await;\n    let api_key = \"test_key\";\n    let service = PermitAuthorizationService::new(api_key, \u0026mock_server.uri());\n\n    let ctx = TenantContext {\n        tenant_id: TenantId::from_str(\"tenant-1\").unwrap(),\n        user_id: UserId::from_str(\"user-1\").unwrap(),\n        agent_id: None\n    };\n\n    Mock::given(method(\"POST\"))\n        .and(path(\"/allowed\"))\n        .respond_with(ResponseTemplate::new(500))\n        .mount(\u0026mock_server)\n        .await;\n\n    let result = service\n        .check_permission(\u0026ctx, \"memory:read\", \"hierarchical\")\n        .await;\n    assert!(result.is_err());\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","tests","cedar_integration.rs"],"content":"//! Cedar Authorization Integration Tests\n//!\n//! Comprehensive tests for Cedar policy evaluation including:\n//! - Multi-tenant authorization isolation\n//! - Agent delegation (ActAs) scenarios  \n//! - Role-based access control (RBAC)\n//! - Hierarchical unit inheritance\n//! - Policy evaluation edge cases\n//! - Error handling for invalid policies/requests\n\nuse adapters::auth::cedar::{CedarAuthorizer, CedarError};\nuse mk_core::traits::AuthorizationService;\nuse mk_core::types::{TenantContext, TenantId, UserId};\n\n// =============================================================================\n// Test Policies\n// =============================================================================\n\n/// Basic schema for Cedar tests\nconst TEST_SCHEMA: \u0026str = r#\"{\n    \"\": {\n        \"entityTypes\": {\n            \"User\": {},\n            \"Unit\": {},\n            \"Role\": {},\n            \"Memory\": {},\n            \"Knowledge\": {}\n        },\n        \"actions\": {\n            \"View\": {\n                \"appliesTo\": {\n                    \"principalTypes\": [\"User\"],\n                    \"resourceTypes\": [\"Unit\", \"Memory\", \"Knowledge\"]\n                }\n            },\n            \"Edit\": {\n                \"appliesTo\": {\n                    \"principalTypes\": [\"User\"],\n                    \"resourceTypes\": [\"Unit\", \"Memory\", \"Knowledge\"]\n                }\n            },\n            \"Delete\": {\n                \"appliesTo\": {\n                    \"principalTypes\": [\"User\"],\n                    \"resourceTypes\": [\"Unit\", \"Memory\", \"Knowledge\"]\n                }\n            },\n            \"Admin\": {\n                \"appliesTo\": {\n                    \"principalTypes\": [\"User\"],\n                    \"resourceTypes\": [\"Unit\"]\n                }\n            },\n            \"ActAs\": {\n                \"appliesTo\": {\n                    \"principalTypes\": [\"User\"],\n                    \"resourceTypes\": [\"User\"]\n                }\n            }\n        }\n    }\n}\"#;\n\n// =============================================================================\n// Helper Functions\n// =============================================================================\n\nfn create_tenant_context(tenant: \u0026str, user: \u0026str) -\u003e TenantContext {\n    TenantContext::new(\n        TenantId::new(tenant.into()).unwrap(),\n        UserId::new(user.into()).unwrap(),\n    )\n}\n\nfn create_agent_context(tenant: \u0026str, user: \u0026str, agent: \u0026str) -\u003e TenantContext {\n    let mut ctx = TenantContext::new(\n        TenantId::new(tenant.into()).unwrap(),\n        UserId::new(user.into()).unwrap(),\n    );\n    ctx.agent_id = Some(agent.to_string());\n    ctx\n}\n\n// =============================================================================\n// Multi-Tenant Isolation Tests\n// =============================================================================\n\nmod multi_tenant_isolation {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_user_can_access_own_tenant_resources() {\n        let policies = r#\"\n            permit(principal == User::\"tenant1-user1\", action == Action::\"View\", resource == Unit::\"tenant1-unit1\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"tenant1-user1\");\n\n        let allowed = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"tenant1-unit1\\\"\")\n            .await\n            .unwrap();\n        assert!(allowed, \"User should access resources in own tenant\");\n    }\n\n    #[tokio::test]\n    async fn test_user_cannot_access_other_tenant_resources() {\n        let policies = r#\"\n            permit(principal == User::\"tenant1-user1\", action == Action::\"View\", resource == Unit::\"tenant1-unit1\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"tenant1-user1\");\n\n        // Try to access tenant2's resource\n        let denied = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"tenant2-unit1\\\"\")\n            .await\n            .unwrap();\n        assert!(!denied, \"User should NOT access resources in other tenant\");\n    }\n\n    #[tokio::test]\n    async fn test_multiple_tenants_isolated() {\n        let policies = r#\"\n            permit(principal == User::\"alice\", action == Action::\"View\", resource == Unit::\"acme-data\");\n            permit(principal == User::\"bob\", action == Action::\"View\", resource == Unit::\"globex-data\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n\n        // Alice can access ACME data\n        let alice_ctx = create_tenant_context(\"acme\", \"alice\");\n        let alice_acme = authorizer\n            .check_permission(\u0026alice_ctx, \"View\", \"Unit::\\\"acme-data\\\"\")\n            .await\n            .unwrap();\n        assert!(alice_acme, \"Alice should access ACME data\");\n\n        // Alice cannot access Globex data\n        let alice_globex = authorizer\n            .check_permission(\u0026alice_ctx, \"View\", \"Unit::\\\"globex-data\\\"\")\n            .await\n            .unwrap();\n        assert!(!alice_globex, \"Alice should NOT access Globex data\");\n\n        // Bob can access Globex data\n        let bob_ctx = create_tenant_context(\"globex\", \"bob\");\n        let bob_globex = authorizer\n            .check_permission(\u0026bob_ctx, \"View\", \"Unit::\\\"globex-data\\\"\")\n            .await\n            .unwrap();\n        assert!(bob_globex, \"Bob should access Globex data\");\n\n        // Bob cannot access ACME data\n        let bob_acme = authorizer\n            .check_permission(\u0026bob_ctx, \"View\", \"Unit::\\\"acme-data\\\"\")\n            .await\n            .unwrap();\n        assert!(!bob_acme, \"Bob should NOT access ACME data\");\n    }\n\n    #[tokio::test]\n    async fn test_tenant_admin_scoped_to_tenant() {\n        let policies = r#\"\n            permit(principal == User::\"tenant1-admin\", action == Action::\"Admin\", resource == Unit::\"tenant1-unit1\");\n            permit(principal == User::\"tenant1-admin\", action == Action::\"Admin\", resource == Unit::\"tenant1-unit2\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"tenant1-admin\");\n\n        // Admin can manage tenant1 units\n        let can_admin_unit1 = authorizer\n            .check_permission(\u0026ctx, \"Admin\", \"Unit::\\\"tenant1-unit1\\\"\")\n            .await\n            .unwrap();\n        assert!(can_admin_unit1);\n\n        let can_admin_unit2 = authorizer\n            .check_permission(\u0026ctx, \"Admin\", \"Unit::\\\"tenant1-unit2\\\"\")\n            .await\n            .unwrap();\n        assert!(can_admin_unit2);\n\n        // Admin cannot manage tenant2 units\n        let cannot_admin_other = authorizer\n            .check_permission(\u0026ctx, \"Admin\", \"Unit::\\\"tenant2-unit1\\\"\")\n            .await\n            .unwrap();\n        assert!(!cannot_admin_other);\n    }\n}\n\n// =============================================================================\n// Agent Delegation (ActAs) Tests\n// =============================================================================\n\nmod agent_delegation {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_agent_with_valid_delegation_can_act() {\n        let policies = r#\"\n            permit(principal == User::\"agent-123\", action == Action::\"ActAs\", resource == User::\"user1\");\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data1\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_agent_context(\"tenant1\", \"user1\", \"agent-123\");\n\n        let allowed = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data1\\\"\")\n            .await\n            .unwrap();\n        assert!(\n            allowed,\n            \"Agent with delegation should act on behalf of user\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_agent_without_delegation_denied() {\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data1\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_agent_context(\"tenant1\", \"user1\", \"unauthorized-agent\");\n\n        let denied = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data1\\\"\")\n            .await\n            .unwrap();\n        assert!(!denied, \"Agent without ActAs delegation should be denied\");\n    }\n\n    #[tokio::test]\n    async fn test_agent_delegation_to_wrong_user_denied() {\n        let policies = r#\"\n            permit(principal == User::\"agent-123\", action == Action::\"ActAs\", resource == User::\"user2\");\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data1\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        // Agent has delegation to user2, but trying to act as user1\n        let ctx = create_agent_context(\"tenant1\", \"user1\", \"agent-123\");\n\n        let denied = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data1\\\"\")\n            .await\n            .unwrap();\n        assert!(\n            !denied,\n            \"Agent delegated to different user should be denied\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_multiple_agents_different_delegations() {\n        let policies = r#\"\n            permit(principal == User::\"agent-a\", action == Action::\"ActAs\", resource == User::\"alice\");\n            permit(principal == User::\"agent-b\", action == Action::\"ActAs\", resource == User::\"bob\");\n            permit(principal == User::\"alice\", action == Action::\"View\", resource == Unit::\"alice-data\");\n            permit(principal == User::\"bob\", action == Action::\"View\", resource == Unit::\"bob-data\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n\n        // Agent-A acting as Alice can access Alice's data\n        let ctx_a = create_agent_context(\"tenant1\", \"alice\", \"agent-a\");\n        let allowed_a = authorizer\n            .check_permission(\u0026ctx_a, \"View\", \"Unit::\\\"alice-data\\\"\")\n            .await\n            .unwrap();\n        assert!(allowed_a, \"Agent-A should access Alice's data\");\n\n        // Agent-A acting as Alice cannot access Bob's data\n        let denied_a = authorizer\n            .check_permission(\u0026ctx_a, \"View\", \"Unit::\\\"bob-data\\\"\")\n            .await\n            .unwrap();\n        assert!(!denied_a, \"Agent-A should NOT access Bob's data via Alice\");\n\n        // Agent-B acting as Bob can access Bob's data\n        let ctx_b = create_agent_context(\"tenant1\", \"bob\", \"agent-b\");\n        let allowed_b = authorizer\n            .check_permission(\u0026ctx_b, \"View\", \"Unit::\\\"bob-data\\\"\")\n            .await\n            .unwrap();\n        assert!(allowed_b, \"Agent-B should access Bob's data\");\n    }\n\n    #[tokio::test]\n    async fn test_direct_user_request_without_agent() {\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data1\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        // No agent_id - direct user request\n        let ctx = create_tenant_context(\"tenant1\", \"user1\");\n\n        let allowed = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data1\\\"\")\n            .await\n            .unwrap();\n        assert!(\n            allowed,\n            \"Direct user request should work without agent check\"\n        );\n    }\n}\n\n// =============================================================================\n// Role-Based Access Control Tests\n// =============================================================================\n\nmod rbac {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_viewer_can_only_view() {\n        let policies = r#\"\n            permit(principal == User::\"viewer\", action == Action::\"View\", resource == Unit::\"data\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"viewer\");\n\n        let can_view = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data\\\"\")\n            .await\n            .unwrap();\n        assert!(can_view, \"Viewer should be able to view\");\n\n        let cannot_edit = authorizer\n            .check_permission(\u0026ctx, \"Edit\", \"Unit::\\\"data\\\"\")\n            .await\n            .unwrap();\n        assert!(!cannot_edit, \"Viewer should NOT be able to edit\");\n\n        let cannot_delete = authorizer\n            .check_permission(\u0026ctx, \"Delete\", \"Unit::\\\"data\\\"\")\n            .await\n            .unwrap();\n        assert!(!cannot_delete, \"Viewer should NOT be able to delete\");\n    }\n\n    #[tokio::test]\n    async fn test_editor_can_view_and_edit() {\n        let policies = r#\"\n            permit(principal == User::\"editor\", action == Action::\"View\", resource == Unit::\"data\");\n            permit(principal == User::\"editor\", action == Action::\"Edit\", resource == Unit::\"data\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"editor\");\n\n        let can_view = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data\\\"\")\n            .await\n            .unwrap();\n        assert!(can_view, \"Editor should be able to view\");\n\n        let can_edit = authorizer\n            .check_permission(\u0026ctx, \"Edit\", \"Unit::\\\"data\\\"\")\n            .await\n            .unwrap();\n        assert!(can_edit, \"Editor should be able to edit\");\n\n        let cannot_delete = authorizer\n            .check_permission(\u0026ctx, \"Delete\", \"Unit::\\\"data\\\"\")\n            .await\n            .unwrap();\n        assert!(!cannot_delete, \"Editor should NOT be able to delete\");\n    }\n\n    #[tokio::test]\n    async fn test_admin_can_do_everything() {\n        let policies = r#\"\n            permit(principal == User::\"admin\", action == Action::\"View\", resource == Unit::\"data\");\n            permit(principal == User::\"admin\", action == Action::\"Edit\", resource == Unit::\"data\");\n            permit(principal == User::\"admin\", action == Action::\"Delete\", resource == Unit::\"data\");\n            permit(principal == User::\"admin\", action == Action::\"Admin\", resource == Unit::\"data\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"admin\");\n\n        for action in \u0026[\"View\", \"Edit\", \"Delete\", \"Admin\"] {\n            let allowed = authorizer\n                .check_permission(\u0026ctx, action, \"Unit::\\\"data\\\"\")\n                .await\n                .unwrap();\n            assert!(allowed, \"Admin should be able to {}\", action);\n        }\n    }\n\n    #[tokio::test]\n    async fn test_role_based_memory_access() {\n        let policies = r#\"\n            permit(principal == User::\"memory-reader\", action == Action::\"View\", resource == Memory::\"personal\");\n            permit(principal == User::\"memory-writer\", action == Action::\"View\", resource == Memory::\"personal\");\n            permit(principal == User::\"memory-writer\", action == Action::\"Edit\", resource == Memory::\"personal\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n\n        // Reader can only view\n        let reader_ctx = create_tenant_context(\"tenant1\", \"memory-reader\");\n        let reader_view = authorizer\n            .check_permission(\u0026reader_ctx, \"View\", \"Memory::\\\"personal\\\"\")\n            .await\n            .unwrap();\n        assert!(reader_view);\n\n        let reader_edit = authorizer\n            .check_permission(\u0026reader_ctx, \"Edit\", \"Memory::\\\"personal\\\"\")\n            .await\n            .unwrap();\n        assert!(!reader_edit);\n\n        // Writer can view and edit\n        let writer_ctx = create_tenant_context(\"tenant1\", \"memory-writer\");\n        let writer_view = authorizer\n            .check_permission(\u0026writer_ctx, \"View\", \"Memory::\\\"personal\\\"\")\n            .await\n            .unwrap();\n        assert!(writer_view);\n\n        let writer_edit = authorizer\n            .check_permission(\u0026writer_ctx, \"Edit\", \"Memory::\\\"personal\\\"\")\n            .await\n            .unwrap();\n        assert!(writer_edit);\n    }\n\n    #[tokio::test]\n    async fn test_knowledge_repository_roles() {\n        let policies = r#\"\n            permit(principal == User::\"knowledge-viewer\", action == Action::\"View\", resource == Knowledge::\"adr-001\");\n            permit(principal == User::\"knowledge-editor\", action == Action::\"View\", resource == Knowledge::\"adr-001\");\n            permit(principal == User::\"knowledge-editor\", action == Action::\"Edit\", resource == Knowledge::\"adr-001\");\n            permit(principal == User::\"knowledge-admin\", action == Action::\"View\", resource == Knowledge::\"adr-001\");\n            permit(principal == User::\"knowledge-admin\", action == Action::\"Edit\", resource == Knowledge::\"adr-001\");\n            permit(principal == User::\"knowledge-admin\", action == Action::\"Delete\", resource == Knowledge::\"adr-001\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n\n        // Viewer\n        let viewer_ctx = create_tenant_context(\"tenant1\", \"knowledge-viewer\");\n        assert!(\n            authorizer\n                .check_permission(\u0026viewer_ctx, \"View\", \"Knowledge::\\\"adr-001\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            !authorizer\n                .check_permission(\u0026viewer_ctx, \"Edit\", \"Knowledge::\\\"adr-001\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            !authorizer\n                .check_permission(\u0026viewer_ctx, \"Delete\", \"Knowledge::\\\"adr-001\\\"\")\n                .await\n                .unwrap()\n        );\n\n        // Editor\n        let editor_ctx = create_tenant_context(\"tenant1\", \"knowledge-editor\");\n        assert!(\n            authorizer\n                .check_permission(\u0026editor_ctx, \"View\", \"Knowledge::\\\"adr-001\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            authorizer\n                .check_permission(\u0026editor_ctx, \"Edit\", \"Knowledge::\\\"adr-001\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            !authorizer\n                .check_permission(\u0026editor_ctx, \"Delete\", \"Knowledge::\\\"adr-001\\\"\")\n                .await\n                .unwrap()\n        );\n\n        // Admin\n        let admin_ctx = create_tenant_context(\"tenant1\", \"knowledge-admin\");\n        assert!(\n            authorizer\n                .check_permission(\u0026admin_ctx, \"View\", \"Knowledge::\\\"adr-001\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            authorizer\n                .check_permission(\u0026admin_ctx, \"Edit\", \"Knowledge::\\\"adr-001\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            authorizer\n                .check_permission(\u0026admin_ctx, \"Delete\", \"Knowledge::\\\"adr-001\\\"\")\n                .await\n                .unwrap()\n        );\n    }\n}\n\n// =============================================================================\n// Hierarchical Unit Permission Tests\n// =============================================================================\n\nmod hierarchical_permissions {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_parent_unit_access_does_not_grant_child_access() {\n        // In this basic policy model, parent access doesn't automatically grant child access\n        let policies = r#\"\n            permit(principal == User::\"manager\", action == Action::\"View\", resource == Unit::\"org\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"manager\");\n\n        let can_view_org = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"org\\\"\")\n            .await\n            .unwrap();\n        assert!(can_view_org, \"Manager can view org unit\");\n\n        // Child unit not explicitly granted\n        let cannot_view_team = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"org-team1\\\"\")\n            .await\n            .unwrap();\n        assert!(\n            !cannot_view_team,\n            \"Without explicit policy, child access not granted\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_explicit_hierarchical_policy() {\n        let policies = r#\"\n            permit(principal == User::\"org-admin\", action == Action::\"View\", resource == Unit::\"org\");\n            permit(principal == User::\"org-admin\", action == Action::\"View\", resource == Unit::\"org-team1\");\n            permit(principal == User::\"org-admin\", action == Action::\"View\", resource == Unit::\"org-team2\");\n            permit(principal == User::\"team1-member\", action == Action::\"View\", resource == Unit::\"org-team1\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n\n        // Org admin can view all levels\n        let admin_ctx = create_tenant_context(\"tenant1\", \"org-admin\");\n        assert!(\n            authorizer\n                .check_permission(\u0026admin_ctx, \"View\", \"Unit::\\\"org\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            authorizer\n                .check_permission(\u0026admin_ctx, \"View\", \"Unit::\\\"org-team1\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            authorizer\n                .check_permission(\u0026admin_ctx, \"View\", \"Unit::\\\"org-team2\\\"\")\n                .await\n                .unwrap()\n        );\n\n        // Team member can only view their team\n        let member_ctx = create_tenant_context(\"tenant1\", \"team1-member\");\n        assert!(!member_ctx.agent_id.is_some()); // Sanity check - no agent\n        assert!(\n            !authorizer\n                .check_permission(\u0026member_ctx, \"View\", \"Unit::\\\"org\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            authorizer\n                .check_permission(\u0026member_ctx, \"View\", \"Unit::\\\"org-team1\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            !authorizer\n                .check_permission(\u0026member_ctx, \"View\", \"Unit::\\\"org-team2\\\"\")\n                .await\n                .unwrap()\n        );\n    }\n\n    #[tokio::test]\n    async fn test_memory_layer_hierarchy() {\n        // Memory layers: agent \u003c user \u003c session \u003c project \u003c team \u003c org \u003c company\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Memory::\"user-layer\");\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Memory::\"session-layer\");\n            permit(principal == User::\"team-member\", action == Action::\"View\", resource == Memory::\"team-layer\");\n            permit(principal == User::\"org-member\", action == Action::\"View\", resource == Memory::\"org-layer\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n\n        let user_ctx = create_tenant_context(\"tenant1\", \"user1\");\n        assert!(\n            authorizer\n                .check_permission(\u0026user_ctx, \"View\", \"Memory::\\\"user-layer\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            authorizer\n                .check_permission(\u0026user_ctx, \"View\", \"Memory::\\\"session-layer\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            !authorizer\n                .check_permission(\u0026user_ctx, \"View\", \"Memory::\\\"team-layer\\\"\")\n                .await\n                .unwrap()\n        );\n    }\n}\n\n// =============================================================================\n// Policy Evaluation Edge Cases\n// =============================================================================\n\nmod edge_cases {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_empty_policy_denies_all() {\n        let policies = \"\";\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"user1\");\n\n        let denied = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"anything\\\"\")\n            .await\n            .unwrap();\n        assert!(!denied, \"Empty policy should deny all requests\");\n    }\n\n    #[tokio::test]\n    async fn test_forbid_overrides_permit() {\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data\");\n            forbid(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"user1\");\n\n        let denied = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data\\\"\")\n            .await\n            .unwrap();\n        assert!(!denied, \"Forbid should override permit\");\n    }\n\n    #[tokio::test]\n    async fn test_specific_forbid_with_general_permit() {\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource);\n            forbid(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"secret\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"user1\");\n\n        // General permit works\n        let allowed = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"public\\\"\")\n            .await\n            .unwrap();\n        assert!(allowed, \"General permit should allow\");\n\n        // Specific forbid blocks\n        let denied = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"secret\\\"\")\n            .await\n            .unwrap();\n        assert!(!denied, \"Specific forbid should block\");\n    }\n\n    #[tokio::test]\n    async fn test_action_not_in_policy() {\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"user1\");\n\n        let denied = authorizer\n            .check_permission(\u0026ctx, \"NonExistentAction\", \"Unit::\\\"data\\\"\")\n            .await\n            .unwrap();\n        assert!(!denied, \"Unknown action should be denied\");\n    }\n\n    #[tokio::test]\n    async fn test_special_characters_in_ids() {\n        let policies = r#\"\n            permit(principal == User::\"user@example.com\", action == Action::\"View\", resource == Unit::\"data-with-dash\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"user@example.com\");\n\n        let allowed = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data-with-dash\\\"\")\n            .await\n            .unwrap();\n        assert!(allowed, \"Should handle special characters in IDs\");\n    }\n\n    #[tokio::test]\n    async fn test_uuid_style_ids() {\n        let policies = r#\"\n            permit(principal == User::\"550e8400-e29b-41d4-a716-446655440000\", action == Action::\"View\", resource == Unit::\"a3bb189e-8bf9-3888-9912-ace4e6543002\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"550e8400-e29b-41d4-a716-446655440000\");\n\n        let allowed = authorizer\n            .check_permission(\n                \u0026ctx,\n                \"View\",\n                \"Unit::\\\"a3bb189e-8bf9-3888-9912-ace4e6543002\\\"\",\n            )\n            .await\n            .unwrap();\n        assert!(allowed, \"Should handle UUID-style IDs\");\n    }\n\n    #[tokio::test]\n    async fn test_when_clause_always_false() {\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data\")\n            when { false };\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"user1\");\n\n        let denied = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data\\\"\")\n            .await\n            .unwrap();\n        assert!(!denied, \"when {{ false }} should always deny\");\n    }\n\n    #[tokio::test]\n    async fn test_unless_clause_always_true() {\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data\")\n            unless { true };\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"user1\");\n\n        let denied = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data\\\"\")\n            .await\n            .unwrap();\n        assert!(!denied, \"unless {{ true }} should always deny\");\n    }\n}\n\n// =============================================================================\n// Error Handling Tests\n// =============================================================================\n\nmod error_handling {\n    use super::*;\n\n    #[test]\n    fn test_invalid_policy_syntax() {\n        let invalid_policies = \"this is not valid cedar policy syntax!!!\";\n        let result = CedarAuthorizer::new(invalid_policies, TEST_SCHEMA);\n        assert!(result.is_err(), \"Invalid policy should return error\");\n\n        if let Err(CedarError::Parse(msg)) = result {\n            assert!(!msg.is_empty(), \"Error message should not be empty\");\n        } else {\n            panic!(\"Expected Parse error\");\n        }\n    }\n\n    #[test]\n    fn test_empty_schema_accepted() {\n        let policies = r#\"\n            permit(principal, action, resource);\n        \"#;\n        // Empty schema string should still work (schema validation is not strict in current impl)\n        let result = CedarAuthorizer::new(policies, \"\");\n        assert!(result.is_ok(), \"Empty schema should be accepted\");\n    }\n\n    #[tokio::test]\n    async fn test_malformed_resource_uid() {\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"user1\");\n\n        // Malformed resource string (missing quotes, wrong format)\n        let result = authorizer\n            .check_permission(\u0026ctx, \"View\", \"not-a-valid-resource-uid\")\n            .await;\n\n        assert!(\n            result.is_err(),\n            \"Malformed resource UID should return error\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_malformed_action_returns_deny() {\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"user1\");\n\n        // Action that doesn't match format (but still parseable)\n        let result = authorizer\n            .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data\\\"\")\n            .await;\n\n        assert!(result.is_ok(), \"Valid format should not error\");\n    }\n\n    #[test]\n    fn test_policy_with_syntax_error_in_condition() {\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource)\n            when { undefined_variable };\n        \"#;\n\n        let result = CedarAuthorizer::new(policies, TEST_SCHEMA);\n        // This should either fail at parse time or evaluation time\n        // Current implementation parses policies at construction\n        assert!(\n            result.is_err(),\n            \"Policy with undefined variable should fail\"\n        );\n    }\n\n    #[test]\n    fn test_duplicate_policy_ids_handled() {\n        // Multiple policies - Cedar handles this by evaluating all\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data\");\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data\");\n        \"#;\n\n        let result = CedarAuthorizer::new(policies, TEST_SCHEMA);\n        assert!(result.is_ok(), \"Duplicate policies should be accepted\");\n    }\n}\n\n// =============================================================================\n// Combined Authorization Scenarios\n// =============================================================================\n\nmod combined_scenarios {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_agent_delegation_with_rbac() {\n        let policies = r#\"\n            permit(principal == User::\"agent-1\", action == Action::\"ActAs\", resource == User::\"viewer\");\n            permit(principal == User::\"agent-2\", action == Action::\"ActAs\", resource == User::\"editor\");\n            permit(principal == User::\"viewer\", action == Action::\"View\", resource == Knowledge::\"doc1\");\n            permit(principal == User::\"editor\", action == Action::\"View\", resource == Knowledge::\"doc1\");\n            permit(principal == User::\"editor\", action == Action::\"Edit\", resource == Knowledge::\"doc1\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n\n        // Agent-1 acting as viewer can only view\n        let viewer_agent_ctx = create_agent_context(\"tenant1\", \"viewer\", \"agent-1\");\n        assert!(\n            authorizer\n                .check_permission(\u0026viewer_agent_ctx, \"View\", \"Knowledge::\\\"doc1\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            !authorizer\n                .check_permission(\u0026viewer_agent_ctx, \"Edit\", \"Knowledge::\\\"doc1\\\"\")\n                .await\n                .unwrap()\n        );\n\n        // Agent-2 acting as editor can view and edit\n        let editor_agent_ctx = create_agent_context(\"tenant1\", \"editor\", \"agent-2\");\n        assert!(\n            authorizer\n                .check_permission(\u0026editor_agent_ctx, \"View\", \"Knowledge::\\\"doc1\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            authorizer\n                .check_permission(\u0026editor_agent_ctx, \"Edit\", \"Knowledge::\\\"doc1\\\"\")\n                .await\n                .unwrap()\n        );\n    }\n\n    #[tokio::test]\n    async fn test_multi_tenant_with_agent_delegation() {\n        let policies = r#\"\n            permit(principal == User::\"agent-acme\", action == Action::\"ActAs\", resource == User::\"acme-user\");\n            permit(principal == User::\"agent-globex\", action == Action::\"ActAs\", resource == User::\"globex-user\");\n            permit(principal == User::\"acme-user\", action == Action::\"View\", resource == Unit::\"acme-data\");\n            permit(principal == User::\"globex-user\", action == Action::\"View\", resource == Unit::\"globex-data\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n\n        // ACME agent can only access ACME data\n        let acme_ctx = create_agent_context(\"acme\", \"acme-user\", \"agent-acme\");\n        assert!(\n            authorizer\n                .check_permission(\u0026acme_ctx, \"View\", \"Unit::\\\"acme-data\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            !authorizer\n                .check_permission(\u0026acme_ctx, \"View\", \"Unit::\\\"globex-data\\\"\")\n                .await\n                .unwrap()\n        );\n\n        // Globex agent can only access Globex data\n        let globex_ctx = create_agent_context(\"globex\", \"globex-user\", \"agent-globex\");\n        assert!(\n            authorizer\n                .check_permission(\u0026globex_ctx, \"View\", \"Unit::\\\"globex-data\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            !authorizer\n                .check_permission(\u0026globex_ctx, \"View\", \"Unit::\\\"acme-data\\\"\")\n                .await\n                .unwrap()\n        );\n\n        // Cross-tenant agent delegation doesn't work\n        let cross_ctx = create_agent_context(\"acme\", \"globex-user\", \"agent-acme\");\n        assert!(\n            !authorizer\n                .check_permission(\u0026cross_ctx, \"View\", \"Unit::\\\"globex-data\\\"\")\n                .await\n                .unwrap()\n        );\n    }\n\n    #[tokio::test]\n    async fn test_complete_governance_scenario() {\n        let policies = r#\"\n            // Company-level admin\n            permit(principal == User::\"company-admin\", action == Action::\"Admin\", resource == Unit::\"company\");\n            permit(principal == User::\"company-admin\", action == Action::\"View\", resource == Knowledge::\"company-policy\");\n            permit(principal == User::\"company-admin\", action == Action::\"Edit\", resource == Knowledge::\"company-policy\");\n            \n            // Org-level editor\n            permit(principal == User::\"org-editor\", action == Action::\"View\", resource == Knowledge::\"org-pattern\");\n            permit(principal == User::\"org-editor\", action == Action::\"Edit\", resource == Knowledge::\"org-pattern\");\n            \n            // Project-level viewer\n            permit(principal == User::\"project-viewer\", action == Action::\"View\", resource == Knowledge::\"project-spec\");\n            \n            // Agent delegation\n            permit(principal == User::\"automation-agent\", action == Action::\"ActAs\", resource == User::\"project-viewer\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n\n        // Company admin has full control\n        let admin_ctx = create_tenant_context(\"company1\", \"company-admin\");\n        assert!(\n            authorizer\n                .check_permission(\u0026admin_ctx, \"Admin\", \"Unit::\\\"company\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            authorizer\n                .check_permission(\u0026admin_ctx, \"Edit\", \"Knowledge::\\\"company-policy\\\"\")\n                .await\n                .unwrap()\n        );\n\n        // Org editor can edit org patterns but not company policies\n        let editor_ctx = create_tenant_context(\"company1\", \"org-editor\");\n        assert!(\n            authorizer\n                .check_permission(\u0026editor_ctx, \"Edit\", \"Knowledge::\\\"org-pattern\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            !authorizer\n                .check_permission(\u0026editor_ctx, \"Edit\", \"Knowledge::\\\"company-policy\\\"\")\n                .await\n                .unwrap()\n        );\n\n        // Project viewer can only view\n        let viewer_ctx = create_tenant_context(\"company1\", \"project-viewer\");\n        assert!(\n            authorizer\n                .check_permission(\u0026viewer_ctx, \"View\", \"Knowledge::\\\"project-spec\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            !authorizer\n                .check_permission(\u0026viewer_ctx, \"Edit\", \"Knowledge::\\\"project-spec\\\"\")\n                .await\n                .unwrap()\n        );\n\n        // Automation agent can view as project-viewer\n        let agent_ctx = create_agent_context(\"company1\", \"project-viewer\", \"automation-agent\");\n        assert!(\n            authorizer\n                .check_permission(\u0026agent_ctx, \"View\", \"Knowledge::\\\"project-spec\\\"\")\n                .await\n                .unwrap()\n        );\n        assert!(\n            !authorizer\n                .check_permission(\u0026agent_ctx, \"Edit\", \"Knowledge::\\\"project-spec\\\"\")\n                .await\n                .unwrap()\n        );\n    }\n}\n\n// =============================================================================\n// Performance/Stress Tests\n// =============================================================================\n\nmod performance {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_large_policy_set() {\n        // Generate a policy with many rules\n        let mut policies = String::new();\n        for i in 0..100 {\n            policies.push_str(\u0026format!(\n                \"permit(principal == User::\\\"user{}\\\", action == Action::\\\"View\\\", resource == Unit::\\\"data{}\\\");\\n\",\n                i, i\n            ));\n        }\n\n        let authorizer = CedarAuthorizer::new(\u0026policies, TEST_SCHEMA).unwrap();\n\n        // Test access for various users\n        for i in [0, 50, 99].iter() {\n            let ctx = create_tenant_context(\"tenant1\", \u0026format!(\"user{}\", i));\n            let allowed = authorizer\n                .check_permission(\u0026ctx, \"View\", \u0026format!(\"Unit::\\\"data{}\\\"\", i))\n                .await\n                .unwrap();\n            assert!(allowed, \"User{} should access data{}\", i, i);\n        }\n    }\n\n    #[tokio::test]\n    async fn test_many_sequential_checks() {\n        let policies = r#\"\n            permit(principal == User::\"user1\", action == Action::\"View\", resource == Unit::\"data\");\n        \"#;\n\n        let authorizer = CedarAuthorizer::new(policies, TEST_SCHEMA).unwrap();\n        let ctx = create_tenant_context(\"tenant1\", \"user1\");\n\n        // Perform many checks\n        for _ in 0..100 {\n            let allowed = authorizer\n                .check_permission(\u0026ctx, \"View\", \"Unit::\\\"data\\\"\")\n                .await\n                .unwrap();\n            assert!(allowed);\n        }\n    }\n}\n","traces":[{"line":68,"address":[],"length":0,"stats":{"Line":35}},{"line":70,"address":[],"length":0,"stats":{"Line":140}},{"line":71,"address":[],"length":0,"stats":{"Line":140}},{"line":75,"address":[],"length":0,"stats":{"Line":11}},{"line":77,"address":[],"length":0,"stats":{"Line":44}},{"line":78,"address":[],"length":0,"stats":{"Line":44}},{"line":80,"address":[],"length":0,"stats":{"Line":22}},{"line":81,"address":[],"length":0,"stats":{"Line":11}}],"covered":8,"coverable":8},{"path":["/","Users","christian.klat","dev","git","aeterna","adapters","tests","langchain_integration.rs"],"content":"use adapters::ecosystem::EcosystemAdapter;\nuse adapters::langchain::LangChainAdapter;\nuse memory::manager::MemoryManager;\nuse memory::providers::MockProvider;\nuse mk_core::traits::KnowledgeRepository;\nuse mk_core::types::{KnowledgeEntry, KnowledgeLayer, MemoryLayer, TenantContext};\nuse serde_json::json;\nuse std::sync::Arc;\nuse sync::bridge::SyncManager;\nuse sync::state::SyncState;\nuse tools::server::McpServer;\n\nstruct MockRepo;\n\n#[async_trait::async_trait]\nimpl KnowledgeRepository for MockRepo {\n    type Error = knowledge::repository::RepositoryError;\n\n    async fn get(\n        \u0026self,\n        _ctx: TenantContext,\n        _layer: KnowledgeLayer,\n        _path: \u0026str,\n    ) -\u003e Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n\n    async fn store(\n        \u0026self,\n        _ctx: TenantContext,\n        _entry: KnowledgeEntry,\n        _message: \u0026str,\n    ) -\u003e Result\u003cString, Self::Error\u003e {\n        Ok(\"hash\".to_string())\n    }\n\n    async fn list(\n        \u0026self,\n        _ctx: TenantContext,\n        _layer: KnowledgeLayer,\n        _prefix: \u0026str,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n\n    async fn delete(\n        \u0026self,\n        _ctx: TenantContext,\n        _layer: KnowledgeLayer,\n        _path: \u0026str,\n        _message: \u0026str,\n    ) -\u003e Result\u003cString, Self::Error\u003e {\n        Ok(\"hash\".to_string())\n    }\n\n    async fn get_head_commit(\u0026self, _ctx: TenantContext) -\u003e Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n        Ok(Some(\"head\".to_string()))\n    }\n\n    async fn get_affected_items(\n        \u0026self,\n        _ctx: TenantContext,\n        _since_commit: \u0026str,\n    ) -\u003e Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n\n    async fn search(\n        \u0026self,\n        _ctx: TenantContext,\n        _query: \u0026str,\n        _layers: Vec\u003cKnowledgeLayer\u003e,\n        _limit: usize,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n\n    fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n        None\n    }\n}\n\nstruct MockPersister;\n\n#[async_trait::async_trait]\nimpl sync::state_persister::SyncStatePersister for MockPersister {\n    async fn load(\n        \u0026self,\n        _tenant_id: \u0026mk_core::types::TenantId,\n    ) -\u003e Result\u003cSyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        Ok(SyncState::default())\n    }\n    async fn save(\n        \u0026self,\n        _tenant_id: \u0026mk_core::types::TenantId,\n        _state: \u0026SyncState,\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        Ok(())\n    }\n}\n\nasync fn setup_server() -\u003e Arc\u003cMcpServer\u003e {\n    let memory_manager = Arc::new(MemoryManager::new());\n    memory_manager\n        .register_provider(MemoryLayer::User, Box::new(MockProvider::new()))\n        .await;\n\n    let repo = Arc::new(MockRepo);\n    let governance = Arc::new(knowledge::governance::GovernanceEngine::new());\n    let deployment_config = config::config::DeploymentConfig::default();\n    let sync_manager = Arc::new(\n        SyncManager::new(\n            memory_manager.clone(),\n            repo.clone(),\n            governance.clone(),\n            deployment_config,\n            None,\n            Arc::new(MockPersister),\n        )\n        .await\n        .unwrap(),\n    );\n\n    let auth_service = Arc::new(MockAuthService);\n\n    Arc::new(McpServer::new(\n        memory_manager,\n        sync_manager,\n        repo,\n        Arc::new(MockStorageBackend),\n        governance,\n        auth_service,\n        None,\n    ))\n}\n\nstruct MockStorageBackend;\n#[async_trait::async_trait]\nimpl mk_core::traits::StorageBackend for MockStorageBackend {\n    type Error = storage::postgres::PostgresError;\n    async fn store(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _key: \u0026str,\n        _value: \u0026[u8],\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn retrieve(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _key: \u0026str,\n    ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n    async fn delete(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _key: \u0026str,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn exists(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _key: \u0026str,\n    ) -\u003e Result\u003cbool, Self::Error\u003e {\n        Ok(false)\n    }\n    async fn get_ancestors(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n    async fn get_descendants(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n    async fn get_unit_policies(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::Policy\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n    async fn create_unit(\n        \u0026self,\n        _unit: \u0026mk_core::types::OrganizationalUnit,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn add_unit_policy(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _unit_id: \u0026str,\n        _policy: \u0026mk_core::types::Policy,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn assign_role(\n        \u0026self,\n        _user_id: \u0026mk_core::types::UserId,\n        _tenant_id: \u0026mk_core::types::TenantId,\n        _unit_id: \u0026str,\n        _role: mk_core::types::Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn remove_role(\n        \u0026self,\n        _user_id: \u0026mk_core::types::UserId,\n        _tenant_id: \u0026mk_core::types::TenantId,\n        _unit_id: \u0026str,\n        _role: mk_core::types::Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn store_drift_result(\n        \u0026self,\n        _result: mk_core::types::DriftResult,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn get_latest_drift_result(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _project_id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cmk_core::types::DriftResult\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n    async fn list_all_units(\u0026self) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n    async fn record_job_status(\n        \u0026self,\n        _job_name: \u0026str,\n        _tenant_id: \u0026str,\n        _status: \u0026str,\n        _message: Option\u003c\u0026str\u003e,\n        _started_at: i64,\n        _finished_at: Option\u003ci64\u003e,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn get_governance_events(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _since_timestamp: i64,\n        _limit: usize,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n}\n\nstruct MockAuthService;\n#[async_trait::async_trait]\nimpl mk_core::traits::AuthorizationService for MockAuthService {\n    type Error = anyhow::Error;\n    async fn check_permission(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _action: \u0026str,\n        _resource: \u0026str,\n    ) -\u003e anyhow::Result\u003cbool\u003e {\n        Ok(true)\n    }\n    async fn get_user_roles(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n    ) -\u003e anyhow::Result\u003cVec\u003cmk_core::types::Role\u003e\u003e {\n        Ok(vec![])\n    }\n    async fn assign_role(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _user_id: \u0026mk_core::types::UserId,\n        _role: mk_core::types::Role,\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n    async fn remove_role(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _user_id: \u0026mk_core::types::UserId,\n        _role: mk_core::types::Role,\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n}\n\n#[tokio::test]\nasync fn test_langchain_adapter_tool_conversion() {\n    // GIVEN\n    let server = setup_server().await;\n    let adapter = LangChainAdapter::new(server);\n\n    // WHEN\n    let tools = adapter.to_langchain_tools();\n\n    // THEN\n    assert!(!tools.is_empty());\n    let memory_add = tools.iter().find(|t| t[\"name\"] == \"memory_add\").unwrap();\n    assert_eq!(\n        memory_add[\"description\"],\n        \"Store a piece of information in memory for future reference.\"\n    );\n    assert!(memory_add[\"parameters\"].is_object());\n    assert_eq!(memory_add[\"parameters\"][\"additionalProperties\"], false);\n    assert_eq!(\n        memory_add[\"parameters\"][\"$schema\"],\n        \"http://json-schema.org/draft-07/schema#\"\n    );\n}\n\n#[tokio::test]\nasync fn test_langchain_adapter_request_handling() {\n    // GIVEN\n    let server = setup_server().await;\n    let lc_adapter = LangChainAdapter::new(server);\n\n    let request = json!({\n        \"tenantContext\": {\n            \"tenant_id\": \"test_tenant\",\n            \"user_id\": \"test_user\"\n        },\n        \"name\": \"memory_add\",\n        \"arguments\": {\n            \"content\": \"test content\",\n            \"layer\": \"user\"\n        }\n    });\n\n    // WHEN\n    let response = lc_adapter.handle_mcp_request(request).await.unwrap();\n\n    // THEN\n    assert_eq!(response[\"jsonrpc\"], \"2.0\");\n    if let Some(err) = response.get(\"error\") {\n        panic!(\"Tool call failed: {}\", err);\n    }\n    assert!(response[\"result\"].is_object());\n    assert!(response[\"result\"][\"success\"].as_bool().unwrap());\n}\n","traces":[{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":4}},{"line":103,"address":[],"length":0,"stats":{"Line":6}},{"line":104,"address":[],"length":0,"stats":{"Line":4}},{"line":105,"address":[],"length":0,"stats":{"Line":6}},{"line":106,"address":[],"length":0,"stats":{"Line":2}},{"line":108,"address":[],"length":0,"stats":{"Line":6}},{"line":109,"address":[],"length":0,"stats":{"Line":6}},{"line":110,"address":[],"length":0,"stats":{"Line":4}},{"line":112,"address":[],"length":0,"stats":{"Line":4}},{"line":113,"address":[],"length":0,"stats":{"Line":6}},{"line":114,"address":[],"length":0,"stats":{"Line":4}},{"line":115,"address":[],"length":0,"stats":{"Line":6}},{"line":116,"address":[],"length":0,"stats":{"Line":4}},{"line":117,"address":[],"length":0,"stats":{"Line":4}},{"line":118,"address":[],"length":0,"stats":{"Line":2}},{"line":120,"address":[],"length":0,"stats":{"Line":2}},{"line":121,"address":[],"length":0,"stats":{"Line":2}},{"line":124,"address":[],"length":0,"stats":{"Line":6}},{"line":126,"address":[],"length":0,"stats":{"Line":4}},{"line":127,"address":[],"length":0,"stats":{"Line":2}},{"line":128,"address":[],"length":0,"stats":{"Line":2}},{"line":129,"address":[],"length":0,"stats":{"Line":2}},{"line":130,"address":[],"length":0,"stats":{"Line":2}},{"line":131,"address":[],"length":0,"stats":{"Line":2}},{"line":132,"address":[],"length":0,"stats":{"Line":2}},{"line":133,"address":[],"length":0,"stats":{"Line":2}},{"line":236,"address":[],"length":0,"stats":{"Line":0}}],"covered":26,"coverable":30},{"path":["/","Users","christian.klat","dev","git","aeterna","agent-a2a","src","main.rs"],"content":"fn main() {\n    println!(\"Hello, world!\");\n}\n","traces":[{"line":1,"address":[],"length":0,"stats":{"Line":0}},{"line":2,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":2},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","backend.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","bridge.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","config.rs"],"content":"//! # Configuration Structures\n//!\n//! This module defines all configuration structures for the Memory-Knowledge\n//! system.\n//!\n//! All configuration structures:\n//! - Use `serde` for serialization/deserialization\n//! - Use `validator` for input validation\n//! - Follow Microsoft Pragmatic Rust Guidelines\n//! - Include comprehensive M-CANONICAL-DOCS\n\nuse serde::{Deserialize, Serialize};\nuse validator::Validate;\n\n/// Main configuration structure for the Memory-Knowledge system.\n///\n/// This is the top-level configuration that aggregates all subsystem\n/// configurations.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Provides centralized configuration for the entire Memory-Knowledge system,\n/// including storage providers, sync behavior, MCP tools, and observability.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::Config;\n///\n/// let config = Config::default();\n/// println!(\"PostgreSQL host: {}\", config.providers.postgres.host);\n/// ```\n///\n/// ## Fields\n/// - `providers`: Configuration for storage backends (PostgreSQL, Qdrant,\n///   Redis)\n/// - `sync`: Configuration for memory-knowledge synchronization\n/// - `tools`: Configuration for MCP server tools\n/// - `observability`: Configuration for metrics and tracing\n///\n/// ## Validation\n/// All nested configurations must pass their own validation rules.\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, Default, PartialEq)]\npub struct Config {\n    /// Storage provider configurations (PostgreSQL, Qdrant, Redis)\n    #[serde(default)]\n    pub providers: ProviderConfig,\n\n    /// Memory-knowledge synchronization configuration\n    #[serde(default)]\n    pub sync: SyncConfig,\n\n    /// Memory system configuration\n    #[serde(default)]\n    pub memory: MemoryConfig,\n\n    /// MCP tool interface configuration\n    #[serde(default)]\n    pub tools: ToolConfig,\n\n    /// Observability configuration (metrics, tracing, logging)\n    #[serde(default)]\n    pub observability: ObservabilityConfig,\n\n    /// Deployment mode configuration (Local, Hybrid, Remote)\n    #[serde(default)]\n    pub deployment: DeploymentConfig,\n}\n\nimpl Config {\n    /// Detects environment settings for deployment mode.\n    ///\n    /// # M-CANONICAL-DOCS\n    ///\n    /// ## Purpose\n    /// Initializes configuration based on AETERNA_ environment variables.\n    pub fn detect_env() -\u003e Self {\n        let mut config = Self::default();\n\n        if let Ok(url) = std::env::var(\"AETERNA_REMOTE_GOVERNANCE_URL\") {\n            config.deployment.remote_url = Some(url);\n            config.deployment.mode =\n                std::env::var(\"AETERNA_DEPLOYMENT_MODE\").unwrap_or_else(|_| \"hybrid\".to_string());\n        }\n\n        if std::env::var(\"AETERNA_THIN_CLIENT\").is_ok() {\n            config.deployment.mode = \"remote\".to_string();\n            config.sync.enabled = false;\n        }\n\n        config\n    }\n}\n\n/// Deployment mode configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages the deployment mode of the system (Local, Hybrid, or Remote).\n///\n/// ## Fields\n/// - `mode`: Deployment mode (default: \"local\")\n/// - `remote_url`: URL of the remote governance server (required for\n///   Hybrid/Remote)\n/// - `sync_enabled`: Enable synchronization in Hybrid mode (default: true)\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct DeploymentConfig {\n    /// Deployment mode\n    #[serde(default = \"default_deployment_mode\")]\n    #[validate(custom(function = \"validate_deployment_mode\"))]\n    pub mode: String,\n\n    /// URL of the remote governance server\n    #[serde(default)]\n    pub remote_url: Option\u003cString\u003e,\n\n    /// Enable synchronization in Hybrid mode\n    #[serde(default = \"default_deployment_sync_enabled\")]\n    pub sync_enabled: bool,\n}\n\nfn default_deployment_mode() -\u003e String {\n    \"local\".to_string()\n}\n\nfn default_deployment_sync_enabled() -\u003e bool {\n    true\n}\n\nfn validate_deployment_mode(value: \u0026str) -\u003e Result\u003c(), validator::ValidationError\u003e {\n    match value {\n        \"local\" | \"hybrid\" | \"remote\" =\u003e Ok(()),\n        _ =\u003e Err(validator::ValidationError::new(\"Invalid deployment mode\")),\n    }\n}\n\nimpl Default for DeploymentConfig {\n    fn default() -\u003e Self {\n        Self {\n            mode: default_deployment_mode(),\n            remote_url: None,\n            sync_enabled: default_deployment_sync_enabled(),\n        }\n    }\n}\n\nimpl DeploymentConfig {\n    pub fn auto_detect() -\u003e Self {\n        let mut config = Self::default();\n\n        if let Ok(mode) = std::env::var(\"AETERNA_DEPLOYMENT_MODE\") {\n            config.mode = mode;\n        }\n\n        if let Ok(url) = std::env::var(\"AETERNA_REMOTE_GOVERNANCE_URL\") {\n            config.remote_url = Some(url);\n            if config.mode == \"local\" {\n                config.mode = \"hybrid\".to_string();\n            }\n        }\n\n        if std::env::var(\"AETERNA_THIN_CLIENT\").is_ok() {\n            config.mode = \"remote\".to_string();\n            config.sync_enabled = false;\n        }\n\n        if let Ok(sync) = std::env::var(\"AETERNA_SYNC_ENABLED\") {\n            config.sync_enabled = sync.to_lowercase() == \"true\" || sync == \"1\";\n        }\n\n        config\n    }\n\n    pub fn is_local(\u0026self) -\u003e bool {\n        self.mode == \"local\"\n    }\n\n    pub fn is_hybrid(\u0026self) -\u003e bool {\n        self.mode == \"hybrid\"\n    }\n\n    pub fn is_remote(\u0026self) -\u003e bool {\n        self.mode == \"remote\"\n    }\n\n    pub fn requires_remote_url(\u0026self) -\u003e bool {\n        self.is_hybrid() || self.is_remote()\n    }\n\n    pub fn requires_local_engine(\u0026self) -\u003e bool {\n        self.is_local() || self.is_hybrid()\n    }\n}\n\n/// Configuration for storage providers.\n///\n/// Manages connection settings for all storage backends.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Centralizes connection configuration for all storage backends:\n/// - PostgreSQL: Primary data storage with pgvector extension\n/// - Qdrant: Vector similarity search\n/// - Redis: Caching layer\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::ProviderConfig;\n///\n/// let providers = ProviderConfig::default();\n/// assert_eq!(providers.postgres.host, \"localhost\");\n/// ```\n///\n/// ## Fields\n/// - `postgres`: PostgreSQL connection configuration\n/// - `qdrant`: Qdrant vector database configuration\n/// - `redis`: Redis caching configuration\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, Default, PartialEq)]\npub struct ProviderConfig {\n    /// PostgreSQL connection configuration\n    #[serde(default)]\n    pub postgres: PostgresConfig,\n\n    /// Qdrant vector database configuration\n    #[serde(default)]\n    pub qdrant: QdrantConfig,\n\n    /// Redis caching configuration\n    #[serde(default)]\n    pub redis: RedisConfig,\n}\n\n/// PostgreSQL configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages connection settings for PostgreSQL, the primary data storage\n/// backend.\n///\n/// ## Fields\n/// - `host`: Database server hostname (default: \"localhost\")\n/// - `port`: Database server port (default: 5432)\n/// - `database`: Database name (required)\n/// - `username`: Database user (required)\n/// - `password`: Database password (required, should use environment variable)\n/// - `pool_size`: Maximum connections in pool (default: 10, range: 1-100)\n/// - `timeout_seconds`: Connection timeout (default: 30, range: 1-300)\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct PostgresConfig {\n    /// Database server hostname\n    #[serde(default = \"default_postgres_host\")]\n    #[validate(length(min = 1, max = 255))]\n    pub host: String,\n\n    /// Database server port\n    #[serde(default = \"default_postgres_port\")]\n    #[validate(range(min = 1, max = 65535))]\n    pub port: u16,\n\n    /// Database name\n    #[serde(default = \"default_postgres_database\")]\n    #[validate(length(min = 1, max = 63))]\n    pub database: String,\n\n    /// Database username\n    #[serde(default = \"default_postgres_username\")]\n    #[validate(length(min = 1, max = 63))]\n    pub username: String,\n\n    /// Database password\n    #[serde(default = \"default_postgres_password\")]\n    #[validate(length(min = 1))]\n    pub password: String,\n\n    /// Maximum connections in pool\n    #[serde(default = \"default_postgres_pool_size\")]\n    #[validate(range(min = 1, max = 100))]\n    pub pool_size: u32,\n\n    /// Connection timeout in seconds\n    #[serde(default = \"default_postgres_timeout\")]\n    #[validate(range(min = 1, max = 300))]\n    pub timeout_seconds: u64,\n}\n\nfn default_postgres_host() -\u003e String {\n    \"localhost\".to_string()\n}\n\nfn default_postgres_port() -\u003e u16 {\n    5432\n}\n\nfn default_postgres_database() -\u003e String {\n    \"memory_knowledge\".to_string()\n}\n\nfn default_postgres_username() -\u003e String {\n    \"postgres\".to_string()\n}\n\nfn default_postgres_password() -\u003e String {\n    \"\".to_string()\n}\n\nfn default_postgres_pool_size() -\u003e u32 {\n    10\n}\n\nfn default_postgres_timeout() -\u003e u64 {\n    30\n}\n\nimpl Default for PostgresConfig {\n    fn default() -\u003e Self {\n        Self {\n            host: default_postgres_host(),\n            port: default_postgres_port(),\n            database: default_postgres_database(),\n            username: default_postgres_username(),\n            password: default_postgres_password(),\n            pool_size: default_postgres_pool_size(),\n            timeout_seconds: default_postgres_timeout(),\n        }\n    }\n}\n\n/// Qdrant vector database configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages connection settings for Qdrant, used for vector similarity search.\n///\n/// ## Fields\n/// - `host`: Qdrant server hostname (default: \"localhost\")\n/// - `port`: Qdrant server port (default: 6333)\n/// - `collection`: Default collection name (required)\n/// - `timeout_seconds`: Request timeout (default: 30, range: 1-300)\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct QdrantConfig {\n    /// Qdrant server hostname\n    #[serde(default = \"default_qdrant_host\")]\n    #[validate(length(min = 1, max = 255))]\n    pub host: String,\n\n    /// Qdrant server port\n    #[serde(default = \"default_qdrant_port\")]\n    #[validate(range(min = 1, max = 65535))]\n    pub port: u16,\n\n    /// Default collection name\n    #[serde(default = \"default_qdrant_collection\")]\n    #[validate(length(min = 1, max = 255))]\n    pub collection: String,\n\n    /// Request timeout in seconds\n    #[serde(default = \"default_qdrant_timeout\")]\n    #[validate(range(min = 1, max = 300))]\n    pub timeout_seconds: u64,\n}\n\nfn default_qdrant_host() -\u003e String {\n    \"localhost\".to_string()\n}\n\nfn default_qdrant_port() -\u003e u16 {\n    6333\n}\n\nfn default_qdrant_collection() -\u003e String {\n    \"memory_embeddings\".to_string()\n}\n\nfn default_qdrant_timeout() -\u003e u64 {\n    30\n}\n\nimpl Default for QdrantConfig {\n    fn default() -\u003e Self {\n        Self {\n            host: default_qdrant_host(),\n            port: default_qdrant_port(),\n            collection: default_qdrant_collection(),\n            timeout_seconds: default_qdrant_timeout(),\n        }\n    }\n}\n\n/// Redis configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages connection settings for Redis, used as a caching layer.\n///\n/// ## Fields\n/// - `host`: Redis server hostname (default: \"localhost\")\n/// - `port`: Redis server port (default: 6379)\n/// - `db`: Redis database number (default: 0, range: 0-15)\n/// - `pool_size`: Maximum connections in pool (default: 10, range: 1-100)\n/// - `timeout_seconds`: Connection timeout (default: 30, range: 1-300)\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct RedisConfig {\n    /// Redis server hostname\n    #[serde(default = \"default_redis_host\")]\n    #[validate(length(min = 1, max = 255))]\n    pub host: String,\n\n    /// Redis server port\n    #[serde(default = \"default_redis_port\")]\n    #[validate(range(min = 1, max = 65535))]\n    pub port: u16,\n\n    /// Redis database number\n    #[serde(default = \"default_redis_db\")]\n    #[validate(range(min = 0, max = 15))]\n    pub db: u8,\n\n    /// Maximum connections in pool\n    #[serde(default = \"default_redis_pool_size\")]\n    #[validate(range(min = 1, max = 100))]\n    pub pool_size: u32,\n\n    /// Connection timeout in seconds\n    #[serde(default = \"default_redis_timeout\")]\n    #[validate(range(min = 1, max = 300))]\n    pub timeout_seconds: u64,\n}\n\nfn default_redis_host() -\u003e String {\n    \"localhost\".to_string()\n}\n\nfn default_redis_port() -\u003e u16 {\n    6379\n}\n\nfn default_redis_db() -\u003e u8 {\n    0\n}\n\nfn default_redis_pool_size() -\u003e u32 {\n    10\n}\n\nfn default_redis_timeout() -\u003e u64 {\n    30\n}\n\nimpl Default for RedisConfig {\n    fn default() -\u003e Self {\n        Self {\n            host: default_redis_host(),\n            port: default_redis_port(),\n            db: default_redis_db(),\n            pool_size: default_redis_pool_size(),\n            timeout_seconds: default_redis_timeout(),\n        }\n    }\n}\n\n/// Synchronization configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages synchronization behavior between memory and knowledge systems.\n///\n/// ## Fields\n/// - `enabled`: Enable/disable automatic sync (default: true)\n/// - `sync_interval_seconds`: Sync interval (default: 60, range: 10-3600)\n/// - `batch_size`: Number of items per sync batch (default: 100, range: 1-1000)\n/// - `checkpoint_enabled`: Enable checkpointing for rollback (default: true)\n/// - `conflict_resolution`: Strategy for conflict resolution (default:\n///   \"prefer_knowledge\")\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct SyncConfig {\n    /// Enable/disable automatic synchronization\n    #[serde(default = \"default_sync_enabled\")]\n    pub enabled: bool,\n\n    /// Sync interval in seconds\n    #[serde(default = \"default_sync_interval\")]\n    #[validate(range(min = 10, max = 3600))]\n    pub sync_interval_seconds: u64,\n\n    /// Number of items per sync batch\n    #[serde(default = \"default_sync_batch_size\")]\n    #[validate(range(min = 1, max = 1000))]\n    pub batch_size: u32,\n\n    /// Enable checkpointing for rollback\n    #[serde(default = \"default_sync_checkpoint\")]\n    pub checkpoint_enabled: bool,\n\n    /// Conflict resolution strategy\n    #[serde(default = \"default_sync_conflict_resolution\")]\n    #[validate(custom(function = \"validate_conflict_resolution\"))]\n    pub conflict_resolution: String,\n}\n\nfn default_sync_enabled() -\u003e bool {\n    true\n}\n\nfn default_sync_interval() -\u003e u64 {\n    60\n}\n\nfn default_sync_batch_size() -\u003e u32 {\n    100\n}\n\nfn default_sync_checkpoint() -\u003e bool {\n    true\n}\n\nfn default_sync_conflict_resolution() -\u003e String {\n    \"prefer_knowledge\".to_string()\n}\n\nfn validate_conflict_resolution(value: \u0026str) -\u003e Result\u003c(), validator::ValidationError\u003e {\n    match value {\n        \"prefer_knowledge\" | \"prefer_memory\" | \"manual\" =\u003e Ok(()),\n        _ =\u003e Err(validator::ValidationError::new(\n            \"Invalid conflict resolution strategy\",\n        )),\n    }\n}\n\nimpl Default for SyncConfig {\n    fn default() -\u003e Self {\n        Self {\n            enabled: default_sync_enabled(),\n            sync_interval_seconds: default_sync_interval(),\n            batch_size: default_sync_batch_size(),\n            checkpoint_enabled: default_sync_checkpoint(),\n            conflict_resolution: default_sync_conflict_resolution(),\n        }\n    }\n}\n\n/// MCP tool interface configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages configuration for the MCP (Model Context Protocol) server interface.\n///\n/// ## Fields\n/// - `enabled`: Enable/disable MCP server (default: true)\n/// - `host`: Server hostname (default: \"localhost\")\n/// - `port`: Server port (default: 8080)\n/// - `api_key`: API key for authentication (optional)\n/// - `rate_limit_requests_per_minute`: Rate limit (default: 60, range: 1-1000)\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct ToolConfig {\n    /// Enable/disable MCP server\n    #[serde(default = \"default_tools_enabled\")]\n    pub enabled: bool,\n\n    /// Server hostname\n    #[serde(default = \"default_tools_host\")]\n    #[validate(length(min = 1, max = 255))]\n    pub host: String,\n\n    /// Server port\n    #[serde(default = \"default_tools_port\")]\n    #[validate(range(min = 1, max = 65535))]\n    pub port: u16,\n\n    /// API key for authentication\n    #[serde(default)]\n    pub api_key: Option\u003cString\u003e,\n\n    /// Rate limit: requests per minute\n    #[serde(default = \"default_tools_rate_limit\")]\n    #[validate(range(min = 1, max = 1000))]\n    pub rate_limit_requests_per_minute: u32,\n}\n\nfn default_tools_enabled() -\u003e bool {\n    true\n}\n\nfn default_tools_host() -\u003e String {\n    \"localhost\".to_string()\n}\n\nfn default_tools_port() -\u003e u16 {\n    8080\n}\n\nfn default_tools_rate_limit() -\u003e u32 {\n    60\n}\n\nimpl Default for ToolConfig {\n    fn default() -\u003e Self {\n        Self {\n            enabled: default_tools_enabled(),\n            host: default_tools_host(),\n            port: default_tools_port(),\n            api_key: None,\n            rate_limit_requests_per_minute: default_tools_rate_limit(),\n        }\n    }\n}\n\n/// Observability configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages configuration for metrics, tracing, and logging.\n///\n/// ## Fields\n/// - `metrics_enabled`: Enable metrics collection (default: true)\n/// - `tracing_enabled`: Enable distributed tracing (default: true)\n/// - `logging_level`: Log level (default: \"info\")\n/// - `metrics_port`: Metrics server port (default: 9090)\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct ObservabilityConfig {\n    /// Enable metrics collection\n    #[serde(default = \"default_observability_metrics_enabled\")]\n    pub metrics_enabled: bool,\n\n    /// Enable distributed tracing\n    #[serde(default = \"default_observability_tracing_enabled\")]\n    pub tracing_enabled: bool,\n\n    /// Logging level\n    #[serde(default = \"default_observability_logging_level\")]\n    #[validate(custom(function = \"validate_logging_level\"))]\n    pub logging_level: String,\n\n    /// Metrics server port\n    #[serde(default = \"default_observability_metrics_port\")]\n    #[validate(range(min = 1, max = 65535))]\n    pub metrics_port: u16,\n}\n\nfn default_observability_metrics_enabled() -\u003e bool {\n    true\n}\n\nfn default_observability_tracing_enabled() -\u003e bool {\n    true\n}\n\nfn default_observability_logging_level() -\u003e String {\n    \"info\".to_string()\n}\n\nfn default_observability_metrics_port() -\u003e u16 {\n    9090\n}\n\nfn validate_logging_level(value: \u0026str) -\u003e Result\u003c(), validator::ValidationError\u003e {\n    match value {\n        \"trace\" | \"debug\" | \"info\" | \"warn\" | \"error\" =\u003e Ok(()),\n        _ =\u003e Err(validator::ValidationError::new(\"Invalid logging level\")),\n    }\n}\n\nimpl Default for ObservabilityConfig {\n    fn default() -\u003e Self {\n        Self {\n            metrics_enabled: default_observability_metrics_enabled(),\n            tracing_enabled: default_observability_tracing_enabled(),\n            logging_level: default_observability_logging_level(),\n            metrics_port: default_observability_metrics_port(),\n        }\n    }\n}\n\n/// Memory system configuration.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Manages configuration for the memory system, including promotion thresholds.\n///\n/// ## Fields\n/// - `promotion_threshold`: Threshold for memory promotion (default: 0.8,\n///   range: 0.0-1.0)\n#[derive(Debug, Clone, Serialize, Deserialize, Validate, PartialEq)]\npub struct MemoryConfig {\n    /// Threshold for memory promotion\n    #[serde(default = \"default_promotion_threshold\")]\n    #[validate(range(min = 0.0, max = 1.0))]\n    pub promotion_threshold: f32,\n}\n\nfn default_promotion_threshold() -\u003e f32 {\n    0.8\n}\n\nimpl Default for MemoryConfig {\n    fn default() -\u003e Self {\n        Self {\n            promotion_threshold: default_promotion_threshold(),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_config_default() {\n        let config = Config::default();\n        assert_eq!(config.providers.postgres.host, \"localhost\");\n        assert_eq!(config.sync.enabled, true);\n        assert_eq!(config.tools.port, 8080);\n        assert_eq!(config.observability.logging_level, \"info\");\n    }\n\n    #[test]\n    fn test_provider_config_default() {\n        let providers = ProviderConfig::default();\n        assert_eq!(providers.postgres.port, 5432);\n        assert_eq!(providers.qdrant.port, 6333);\n        assert_eq!(providers.redis.port, 6379);\n    }\n\n    #[test]\n    fn test_sync_config_default() {\n        let sync = SyncConfig::default();\n        assert_eq!(sync.enabled, true);\n        assert_eq!(sync.sync_interval_seconds, 60);\n        assert_eq!(sync.conflict_resolution, \"prefer_knowledge\");\n    }\n\n    #[test]\n    fn test_postgres_config_validation() {\n        let mut postgres = PostgresConfig::default();\n        postgres.host = \"\".to_string();\n        assert!(postgres.validate().is_err());\n    }\n\n    #[test]\n    fn test_qdrant_config_validation() {\n        let mut qdrant = QdrantConfig::default();\n        qdrant.port = 0;\n        assert!(qdrant.validate().is_err());\n    }\n\n    #[test]\n    fn test_redis_config_validation() {\n        let mut redis = RedisConfig::default();\n        redis.db = 16;\n        assert!(redis.validate().is_err());\n    }\n\n    #[test]\n    fn test_sync_config_conflict_resolution_validation() {\n        let mut sync = SyncConfig::default();\n        sync.conflict_resolution = \"invalid\".to_string();\n        assert!(sync.validate().is_err());\n\n        sync.conflict_resolution = \"prefer_memory\".to_string();\n        assert!(sync.validate().is_ok());\n    }\n\n    #[test]\n    fn test_observability_config_logging_level_validation() {\n        let mut obs = ObservabilityConfig::default();\n        obs.logging_level = \"invalid\".to_string();\n        assert!(obs.validate().is_err());\n\n        obs.logging_level = \"debug\".to_string();\n        assert!(obs.validate().is_ok());\n    }\n\n    #[test]\n    fn test_config_serialization() {\n        let config = Config::default();\n        let json = serde_json::to_string(\u0026config).unwrap();\n        let deserialized: Config = serde_json::from_str(\u0026json).unwrap();\n        assert_eq!(\n            config.providers.postgres.host,\n            deserialized.providers.postgres.host\n        );\n    }\n\n    #[test]\n    fn test_deployment_config_default() {\n        let config = DeploymentConfig::default();\n        assert_eq!(config.mode, \"local\");\n        assert!(config.remote_url.is_none());\n        assert!(config.sync_enabled);\n    }\n\n    #[test]\n    fn test_deployment_config_is_local() {\n        let config = DeploymentConfig {\n            mode: \"local\".to_string(),\n            remote_url: None,\n            sync_enabled: true,\n        };\n        assert!(config.is_local());\n        assert!(!config.is_hybrid());\n        assert!(!config.is_remote());\n    }\n\n    #[test]\n    fn test_deployment_config_is_hybrid() {\n        let config = DeploymentConfig {\n            mode: \"hybrid\".to_string(),\n            remote_url: Some(\"http://localhost:8080\".to_string()),\n            sync_enabled: true,\n        };\n        assert!(!config.is_local());\n        assert!(config.is_hybrid());\n        assert!(!config.is_remote());\n    }\n\n    #[test]\n    fn test_deployment_config_is_remote() {\n        let config = DeploymentConfig {\n            mode: \"remote\".to_string(),\n            remote_url: Some(\"http://localhost:8080\".to_string()),\n            sync_enabled: false,\n        };\n        assert!(!config.is_local());\n        assert!(!config.is_hybrid());\n        assert!(config.is_remote());\n    }\n\n    #[test]\n    fn test_deployment_config_requires_remote_url() {\n        let local = DeploymentConfig {\n            mode: \"local\".to_string(),\n            ..Default::default()\n        };\n        let hybrid = DeploymentConfig {\n            mode: \"hybrid\".to_string(),\n            ..Default::default()\n        };\n        let remote = DeploymentConfig {\n            mode: \"remote\".to_string(),\n            ..Default::default()\n        };\n\n        assert!(!local.requires_remote_url());\n        assert!(hybrid.requires_remote_url());\n        assert!(remote.requires_remote_url());\n    }\n\n    #[test]\n    fn test_deployment_config_requires_local_engine() {\n        let local = DeploymentConfig {\n            mode: \"local\".to_string(),\n            ..Default::default()\n        };\n        let hybrid = DeploymentConfig {\n            mode: \"hybrid\".to_string(),\n            ..Default::default()\n        };\n        let remote = DeploymentConfig {\n            mode: \"remote\".to_string(),\n            ..Default::default()\n        };\n\n        assert!(local.requires_local_engine());\n        assert!(hybrid.requires_local_engine());\n        assert!(!remote.requires_local_engine());\n    }\n\n    #[test]\n    fn test_deployment_mode_validation() {\n        assert!(validate_deployment_mode(\"local\").is_ok());\n        assert!(validate_deployment_mode(\"hybrid\").is_ok());\n        assert!(validate_deployment_mode(\"remote\").is_ok());\n        assert!(validate_deployment_mode(\"invalid\").is_err());\n    }\n}\n","traces":[{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":82}},{"line":124,"address":[],"length":0,"stats":{"Line":164}},{"line":127,"address":[],"length":0,"stats":{"Line":82}},{"line":128,"address":[],"length":0,"stats":{"Line":82}},{"line":131,"address":[],"length":0,"stats":{"Line":4}},{"line":132,"address":[],"length":0,"stats":{"Line":4}},{"line":133,"address":[],"length":0,"stats":{"Line":12}},{"line":134,"address":[],"length":0,"stats":{"Line":1}},{"line":139,"address":[],"length":0,"stats":{"Line":82}},{"line":141,"address":[],"length":0,"stats":{"Line":164}},{"line":143,"address":[],"length":0,"stats":{"Line":82}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":6}},{"line":176,"address":[],"length":0,"stats":{"Line":6}},{"line":179,"address":[],"length":0,"stats":{"Line":8}},{"line":180,"address":[],"length":0,"stats":{"Line":8}},{"line":183,"address":[],"length":0,"stats":{"Line":5}},{"line":184,"address":[],"length":0,"stats":{"Line":5}},{"line":187,"address":[],"length":0,"stats":{"Line":3}},{"line":188,"address":[],"length":0,"stats":{"Line":10}},{"line":191,"address":[],"length":0,"stats":{"Line":3}},{"line":192,"address":[],"length":0,"stats":{"Line":10}},{"line":289,"address":[],"length":0,"stats":{"Line":34}},{"line":290,"address":[],"length":0,"stats":{"Line":68}},{"line":293,"address":[],"length":0,"stats":{"Line":36}},{"line":294,"address":[],"length":0,"stats":{"Line":36}},{"line":297,"address":[],"length":0,"stats":{"Line":36}},{"line":298,"address":[],"length":0,"stats":{"Line":72}},{"line":301,"address":[],"length":0,"stats":{"Line":36}},{"line":302,"address":[],"length":0,"stats":{"Line":72}},{"line":305,"address":[],"length":0,"stats":{"Line":36}},{"line":306,"address":[],"length":0,"stats":{"Line":72}},{"line":309,"address":[],"length":0,"stats":{"Line":38}},{"line":310,"address":[],"length":0,"stats":{"Line":38}},{"line":313,"address":[],"length":0,"stats":{"Line":38}},{"line":314,"address":[],"length":0,"stats":{"Line":38}},{"line":318,"address":[],"length":0,"stats":{"Line":34}},{"line":320,"address":[],"length":0,"stats":{"Line":68}},{"line":321,"address":[],"length":0,"stats":{"Line":68}},{"line":322,"address":[],"length":0,"stats":{"Line":68}},{"line":323,"address":[],"length":0,"stats":{"Line":68}},{"line":324,"address":[],"length":0,"stats":{"Line":68}},{"line":325,"address":[],"length":0,"stats":{"Line":34}},{"line":326,"address":[],"length":0,"stats":{"Line":34}},{"line":366,"address":[],"length":0,"stats":{"Line":32}},{"line":367,"address":[],"length":0,"stats":{"Line":64}},{"line":370,"address":[],"length":0,"stats":{"Line":32}},{"line":371,"address":[],"length":0,"stats":{"Line":32}},{"line":374,"address":[],"length":0,"stats":{"Line":32}},{"line":375,"address":[],"length":0,"stats":{"Line":64}},{"line":378,"address":[],"length":0,"stats":{"Line":34}},{"line":379,"address":[],"length":0,"stats":{"Line":34}},{"line":383,"address":[],"length":0,"stats":{"Line":32}},{"line":385,"address":[],"length":0,"stats":{"Line":64}},{"line":386,"address":[],"length":0,"stats":{"Line":64}},{"line":387,"address":[],"length":0,"stats":{"Line":32}},{"line":388,"address":[],"length":0,"stats":{"Line":32}},{"line":434,"address":[],"length":0,"stats":{"Line":30}},{"line":435,"address":[],"length":0,"stats":{"Line":60}},{"line":438,"address":[],"length":0,"stats":{"Line":30}},{"line":439,"address":[],"length":0,"stats":{"Line":30}},{"line":442,"address":[],"length":0,"stats":{"Line":32}},{"line":443,"address":[],"length":0,"stats":{"Line":32}},{"line":446,"address":[],"length":0,"stats":{"Line":32}},{"line":447,"address":[],"length":0,"stats":{"Line":32}},{"line":450,"address":[],"length":0,"stats":{"Line":32}},{"line":451,"address":[],"length":0,"stats":{"Line":32}},{"line":455,"address":[],"length":0,"stats":{"Line":30}},{"line":457,"address":[],"length":0,"stats":{"Line":60}},{"line":458,"address":[],"length":0,"stats":{"Line":60}},{"line":459,"address":[],"length":0,"stats":{"Line":60}},{"line":460,"address":[],"length":0,"stats":{"Line":30}},{"line":461,"address":[],"length":0,"stats":{"Line":30}},{"line":506,"address":[],"length":0,"stats":{"Line":23}},{"line":507,"address":[],"length":0,"stats":{"Line":23}},{"line":510,"address":[],"length":0,"stats":{"Line":23}},{"line":511,"address":[],"length":0,"stats":{"Line":23}},{"line":514,"address":[],"length":0,"stats":{"Line":25}},{"line":515,"address":[],"length":0,"stats":{"Line":25}},{"line":518,"address":[],"length":0,"stats":{"Line":25}},{"line":519,"address":[],"length":0,"stats":{"Line":25}},{"line":522,"address":[],"length":0,"stats":{"Line":25}},{"line":523,"address":[],"length":0,"stats":{"Line":50}},{"line":526,"address":[],"length":0,"stats":{"Line":2}},{"line":527,"address":[],"length":0,"stats":{"Line":2}},{"line":528,"address":[],"length":0,"stats":{"Line":6}},{"line":529,"address":[],"length":0,"stats":{"Line":1}},{"line":530,"address":[],"length":0,"stats":{"Line":1}},{"line":536,"address":[],"length":0,"stats":{"Line":23}},{"line":538,"address":[],"length":0,"stats":{"Line":46}},{"line":539,"address":[],"length":0,"stats":{"Line":46}},{"line":540,"address":[],"length":0,"stats":{"Line":46}},{"line":541,"address":[],"length":0,"stats":{"Line":23}},{"line":542,"address":[],"length":0,"stats":{"Line":23}},{"line":586,"address":[],"length":0,"stats":{"Line":25}},{"line":587,"address":[],"length":0,"stats":{"Line":25}},{"line":590,"address":[],"length":0,"stats":{"Line":27}},{"line":591,"address":[],"length":0,"stats":{"Line":54}},{"line":594,"address":[],"length":0,"stats":{"Line":25}},{"line":595,"address":[],"length":0,"stats":{"Line":25}},{"line":598,"address":[],"length":0,"stats":{"Line":27}},{"line":599,"address":[],"length":0,"stats":{"Line":27}},{"line":603,"address":[],"length":0,"stats":{"Line":25}},{"line":605,"address":[],"length":0,"stats":{"Line":50}},{"line":606,"address":[],"length":0,"stats":{"Line":50}},{"line":607,"address":[],"length":0,"stats":{"Line":50}},{"line":609,"address":[],"length":0,"stats":{"Line":25}},{"line":647,"address":[],"length":0,"stats":{"Line":22}},{"line":648,"address":[],"length":0,"stats":{"Line":22}},{"line":651,"address":[],"length":0,"stats":{"Line":22}},{"line":652,"address":[],"length":0,"stats":{"Line":22}},{"line":655,"address":[],"length":0,"stats":{"Line":20}},{"line":656,"address":[],"length":0,"stats":{"Line":40}},{"line":659,"address":[],"length":0,"stats":{"Line":22}},{"line":660,"address":[],"length":0,"stats":{"Line":22}},{"line":663,"address":[],"length":0,"stats":{"Line":2}},{"line":664,"address":[],"length":0,"stats":{"Line":2}},{"line":665,"address":[],"length":0,"stats":{"Line":8}},{"line":666,"address":[],"length":0,"stats":{"Line":1}},{"line":671,"address":[],"length":0,"stats":{"Line":20}},{"line":673,"address":[],"length":0,"stats":{"Line":40}},{"line":674,"address":[],"length":0,"stats":{"Line":40}},{"line":675,"address":[],"length":0,"stats":{"Line":20}},{"line":676,"address":[],"length":0,"stats":{"Line":20}},{"line":699,"address":[],"length":0,"stats":{"Line":111}},{"line":700,"address":[],"length":0,"stats":{"Line":111}},{"line":704,"address":[],"length":0,"stats":{"Line":111}},{"line":706,"address":[],"length":0,"stats":{"Line":111}}],"covered":127,"coverable":151},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","ecosystem.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","episodic.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","file_loader.rs"],"content":"//! # Configuration File Loading\n//!\n//! Loads configuration from TOML or YAML files.\n//!\n//! Supports automatic format detection based on file extension.\n\nuse crate::config::Config;\nuse std::path::Path;\n\n/// Configuration file loading error.\n#[derive(Debug, thiserror::Error)]\npub enum ConfigFileError {\n    #[error(\"File not found: {0}\")]\n    FileNotFound(String),\n\n    #[error(\"IO error: {0}\")]\n    Io(#[from] std::io::Error),\n\n    #[error(\"Failed to parse TOML: {0}\")]\n    TomlParse(String),\n\n    #[error(\"Failed to parse YAML: {0}\")]\n    YamlParse(String),\n\n    #[error(\"Config file has no extension\")]\n    NoExtension,\n\n    #[error(\"Unsupported config file format: {0}\")]\n    UnsupportedFormat(String),\n}\n\n/// Load configuration from TOML file.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Loads complete configuration from a TOML format file.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::load_from_toml;\n/// use std::path::Path;\n///\n/// fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n///     let config = load_from_toml(Path::new(\"config.toml\"))?;\n///     println!(\"PostgreSQL host: {}\", config.providers.postgres.host);\n///     Ok(())\n/// }\n/// ```\n///\n/// ## Error Handling\n/// Returns `ConfigFileError` for:\n/// - File not found\n/// - Invalid TOML syntax\n/// - Missing required fields\npub fn load_from_toml(path: \u0026Path) -\u003e Result\u003cConfig, ConfigFileError\u003e {\n    let contents = std::fs::read_to_string(path)\n        .map_err(|_e| ConfigFileError::FileNotFound(path.display().to_string()))?;\n\n    let config: Config =\n        toml::from_str(\u0026contents).map_err(|e| ConfigFileError::TomlParse(e.to_string()))?;\n\n    Ok(config)\n}\n\n/// Load configuration from YAML file.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Loads complete configuration from a YAML format file.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::load_from_yaml;\n/// use std::path::Path;\n///\n/// fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n///     let config = load_from_yaml(Path::new(\"config.yaml\"))?;\n///     println!(\"PostgreSQL host: {}\", config.providers.postgres.host);\n///     Ok(())\n/// }\n/// ```\n///\n/// ## Error Handling\n/// Returns `ConfigFileError` for:\n/// - File not found\n/// - Invalid YAML syntax\n/// - Missing required fields\npub fn load_from_yaml(path: \u0026Path) -\u003e Result\u003cConfig, ConfigFileError\u003e {\n    let contents = std::fs::read_to_string(path)\n        .map_err(|_e| ConfigFileError::FileNotFound(path.display().to_string()))?;\n\n    let config: Config =\n        serde_yaml::from_str(\u0026contents).map_err(|e| ConfigFileError::YamlParse(e.to_string()))?;\n\n    Ok(config)\n}\n\n/// Load configuration from file with auto-detection.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Loads configuration from file, automatically detecting format from\n/// extension.\n///\n/// ## Supported Formats\n/// - `.toml`: TOML format\n/// - `.yaml`: YAML format\n/// - `.yml`: YAML format\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::load_from_file;\n/// use std::path::Path;\n///\n/// fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n///     let config = load_from_file(Path::new(\"config.yaml\"))?;\n///     Ok(())\n/// }\n/// ```\n///\n/// ## Error Handling\n/// Returns `ConfigFileError` for:\n/// - File not found\n/// - Invalid file extension\n/// - Parse errors for detected format\npub fn load_from_file(path: \u0026Path) -\u003e Result\u003cConfig, ConfigFileError\u003e {\n    let extension = path\n        .extension()\n        .and_then(|s| s.to_str())\n        .ok_or(ConfigFileError::NoExtension)?;\n\n    match extension.to_lowercase().as_str() {\n        \"toml\" =\u003e load_from_toml(path),\n        \"yaml\" | \"yml\" =\u003e load_from_yaml(path),\n        other =\u003e Err(ConfigFileError::UnsupportedFormat(other.to_string())),\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::fs;\n    use tempfile::NamedTempFile;\n\n    #[test]\n    fn test_load_from_toml() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"toml\");\n\n        let toml_content = r#\"\n[providers.postgres]\nhost = \"testhost\"\nport = 5433\ndatabase = \"testdb\"\nusername = \"testuser\"\npassword = \"testpass\"\n\n[providers.qdrant]\nhost = \"qdranthost\"\nport = 7333\ncollection = \"test_collection\"\n\n[providers.redis]\nhost = \"redishost\"\nport = 6380\n\n[sync]\nenabled = false\nsync_interval_seconds = 120\n\n[tools]\nenabled = false\nport = 9090\n\n[observability]\nlogging_level = \"debug\"\n\"#;\n        fs::write(\u0026path, toml_content).unwrap();\n\n        let config = load_from_toml(\u0026path).unwrap();\n        assert_eq!(config.providers.postgres.host, \"testhost\");\n        assert_eq!(config.providers.postgres.port, 5433);\n        assert_eq!(config.providers.postgres.database, \"testdb\");\n        assert_eq!(config.providers.qdrant.host, \"qdranthost\");\n        assert_eq!(config.providers.qdrant.port, 7333);\n        assert_eq!(config.providers.redis.host, \"redishost\");\n        assert_eq!(config.sync.enabled, false);\n        assert_eq!(config.sync.sync_interval_seconds, 120);\n        assert_eq!(config.tools.port, 9090);\n        assert_eq!(config.observability.logging_level, \"debug\");\n    }\n\n    #[test]\n    fn test_load_from_yaml() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"yaml\");\n\n        let yaml_content = r#\"\nproviders:\n  postgres:\n    host: testhost\n    port: 5433\n    database: testdb\n    username: testuser\n    password: testpass\n  qdrant:\n    host: qdranthost\n    port: 7333\n    collection: test_collection\n  redis:\n    host: redishost\n    port: 6380\n\nsync:\n  enabled: false\n  sync_interval_seconds: 120\n\ntools:\n  enabled: false\n  port: 9090\n\nobservability:\n  logging_level: debug\n\"#;\n        fs::write(\u0026path, yaml_content).unwrap();\n\n        let config = load_from_yaml(\u0026path).unwrap();\n        assert_eq!(config.providers.postgres.host, \"testhost\");\n        assert_eq!(config.providers.postgres.port, 5433);\n        assert_eq!(config.providers.qdrant.host, \"qdranthost\");\n        assert_eq!(config.sync.enabled, false);\n        assert_eq!(config.tools.port, 9090);\n        assert_eq!(config.observability.logging_level, \"debug\");\n    }\n\n    #[test]\n    fn test_load_from_file_unsupported() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"json\");\n        fs::write(\u0026path, \"{}\").unwrap();\n\n        let result = load_from_file(\u0026path);\n        assert!(matches!(result, Err(ConfigFileError::UnsupportedFormat(_))));\n    }\n\n    #[test]\n    fn test_load_from_file_no_extension() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"\");\n        fs::write(\u0026path, \"\").unwrap();\n\n        let result = load_from_file(\u0026path);\n        assert!(matches!(result, Err(ConfigFileError::NoExtension)));\n    }\n\n    #[test]\n    fn test_load_from_file_auto_detect_toml() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"toml\");\n        let toml_content = r#\"\n[providers.postgres]\nhost = \"autohost\"\n\"#;\n        fs::write(\u0026path, toml_content).unwrap();\n\n        let config = load_from_file(\u0026path).unwrap();\n        assert_eq!(config.providers.postgres.host, \"autohost\");\n    }\n\n    #[test]\n    fn test_load_from_file_auto_detect_yaml() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"yaml\");\n        let yaml_content = r#\"\nproviders:\n  postgres:\n    host: autohost\n\"#;\n        fs::write(\u0026path, yaml_content).unwrap();\n\n        let config = load_from_file(\u0026path).unwrap();\n        assert_eq!(config.providers.postgres.host, \"autohost\");\n    }\n\n    #[test]\n    fn test_load_from_toml_invalid() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"toml\");\n        let invalid_toml = r#\"\n[invalid\n\"#;\n        fs::write(\u0026path, invalid_toml).unwrap();\n\n        let result = load_from_toml(\u0026path);\n        assert!(matches!(result, Err(ConfigFileError::TomlParse(_))));\n    }\n\n    #[test]\n    fn test_load_from_yaml_invalid() {\n        let file = NamedTempFile::new().unwrap();\n        let path = file.path().with_extension(\"yaml\");\n        let invalid_yaml = r#\"\ninvalid: [unmatched\n\"#;\n        fs::write(\u0026path, invalid_yaml).unwrap();\n\n        let result = load_from_yaml(\u0026path);\n        assert!(matches!(result, Err(ConfigFileError::YamlParse(_))));\n    }\n\n    #[test]\n    fn test_load_from_toml_not_found() {\n        let path = Path::new(\"/nonexistent/path/config.toml\");\n        let result = load_from_toml(path);\n        assert!(matches!(result, Err(ConfigFileError::FileNotFound(_))));\n    }\n}\n","traces":[{"line":56,"address":[],"length":0,"stats":{"Line":4}},{"line":57,"address":[],"length":0,"stats":{"Line":11}},{"line":58,"address":[],"length":0,"stats":{"Line":7}},{"line":60,"address":[],"length":0,"stats":{"Line":4}},{"line":61,"address":[],"length":0,"stats":{"Line":12}},{"line":63,"address":[],"length":0,"stats":{"Line":2}},{"line":90,"address":[],"length":0,"stats":{"Line":3}},{"line":91,"address":[],"length":0,"stats":{"Line":9}},{"line":92,"address":[],"length":0,"stats":{"Line":3}},{"line":94,"address":[],"length":0,"stats":{"Line":4}},{"line":95,"address":[],"length":0,"stats":{"Line":12}},{"line":97,"address":[],"length":0,"stats":{"Line":2}},{"line":129,"address":[],"length":0,"stats":{"Line":4}},{"line":130,"address":[],"length":0,"stats":{"Line":7}},{"line":132,"address":[],"length":0,"stats":{"Line":10}},{"line":133,"address":[],"length":0,"stats":{"Line":9}},{"line":135,"address":[],"length":0,"stats":{"Line":3}},{"line":136,"address":[],"length":0,"stats":{"Line":5}},{"line":137,"address":[],"length":0,"stats":{"Line":5}},{"line":138,"address":[],"length":0,"stats":{"Line":2}}],"covered":20,"coverable":20},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","governance.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","hot_reload.rs"],"content":"//! # Configuration Hot Reload\n//!\n//! Watches configuration files for changes and reloads configuration\n//! automatically.\n\nuse notify::{EventKind, RecommendedWatcher, RecursiveMode, Watcher};\nuse std::path::{Path, PathBuf};\nuse tracing::debug;\nuse tracing::{error, info, warn};\n\n/// Configuration reload event.\n#[derive(Debug, Clone, PartialEq)]\npub enum ConfigReloadEvent {\n    Ready,\n\n    /// Configuration file changed\n    Changed(PathBuf),\n\n    /// Configuration file was removed\n    Removed(PathBuf),\n\n    /// Configuration file was created\n    Created(PathBuf),\n\n    /// Configuration reload error\n    Error {\n        path: PathBuf,\n        error: String,\n    },\n}\n\n/// Watch a configuration file for changes and emit reload events.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Monitors configuration file for changes and automatically reloads\n/// configuration. Uses `notify` crate for cross-platform file system watching.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::{hot_reload::ConfigReloadEvent, watch_config};\n/// use tokio::signal;\n///\n/// #[tokio::main]\n/// async fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n///     let config_path = std::path::Path::new(\"config.toml\");\n///     let (_tx, mut rx) = watch_config(\u0026config_path).await?;\n///\n///     loop {\n///         tokio::select! {\n///             _ = signal::ctrl_c() =\u003e break,\n///             Some(event) = rx.recv() =\u003e {\n///                 match event {\n///                     ConfigReloadEvent::Changed(path) =\u003e {\n///                         println!(\"Config changed: {:?}\", path);\n///                     }\n///                     ConfigReloadEvent::Error { path, error } =\u003e {\n///                         eprintln!(\"Error reloading {:?}: {}\", path, error);\n///                     }\n///                     _ =\u003e {}\n///                 }\n///             }\n///         }\n///     }\n///\n///     Ok(())\n/// }\n/// ```\n///\n/// ## Event Types\n/// - `Changed`: File content modified\n/// - `Created`: New file created\n/// - `Removed`: File deleted\n/// - `Error`: Failed to reload configuration\n///\n/// ## Performance\n/// Uses debouncing to avoid multiple reload events for single file change.\npub async fn watch_config(\n    config_path: \u0026Path,\n) -\u003e Result\u003c\n    (\n        tokio::sync::mpsc::Sender\u003cConfigReloadEvent\u003e,\n        tokio::sync::mpsc::Receiver\u003cConfigReloadEvent\u003e,\n    ),\n    Box\u003cdyn std::error::Error\u003e,\n\u003e {\n    let config_path = config_path.to_path_buf();\n\n    if !config_path.exists() {\n        return Err(Box::new(std::io::Error::new(\n            std::io::ErrorKind::NotFound,\n            format!(\"Config file not found: {:?}\", config_path),\n        )));\n    }\n\n    let (tx, rx) = tokio::sync::mpsc::channel(100);\n    let tx_task = tx.clone();\n    let path_task = config_path.clone();\n\n    tokio::spawn(async move {\n        let (event_tx, mut event_rx) = tokio::sync::mpsc::channel(100);\n        let mut watcher = match RecommendedWatcher::new(\n            move |res| {\n                let _ = event_tx.blocking_send(res);\n            },\n            notify::Config::default(),\n        ) {\n            Ok(w) =\u003e w,\n            Err(e) =\u003e {\n                let error_msg = format!(\"Failed to create file watcher: {}\", e);\n                error!(\"{}\", error_msg);\n\n                let _ = tx_task\n                    .send(ConfigReloadEvent::Error {\n                        path: path_task,\n                        error: error_msg,\n                    })\n                    .await;\n\n                return;\n            }\n        };\n\n        if let Err(e) = watcher.watch(\u0026config_path, RecursiveMode::NonRecursive) {\n            let error_msg = format!(\"Failed to watch config file: {}\", e);\n            error!(\"{}\", error_msg);\n\n            let _ = tx_task\n                .send(ConfigReloadEvent::Error {\n                    path: path_task,\n                    error: error_msg,\n                })\n                .await;\n\n            return;\n        }\n\n        info!(\"Watching config file: {:?}\", config_path);\n\n        let _ = tx_task.send(ConfigReloadEvent::Ready).await;\n\n        loop {\n            tokio::select! {\n                _ = tx_task.closed() =\u003e {\n                    debug!(\"Receiver dropped, stopping watcher for {:?}\", config_path);\n                    break;\n                }\n                event_result = event_rx.recv() =\u003e {\n                    let Some(event_result) = event_result else {\n                        break;\n                    };\n\n                    match event_result {\n                        Ok(event) =\u003e {\n                            if !event.paths.is_empty() {\n                                let path = event.paths[0].clone();\n                                let reload_event = match event.kind {\n                                    EventKind::Create(_) | EventKind::Modify(_) =\u003e {\n                                        info!(\"Config file updated: {:?}\", path);\n                                        ConfigReloadEvent::Changed(path)\n                                    }\n                                    EventKind::Remove(_) =\u003e {\n                                        warn!(\"Config file removed: {:?}\", path);\n                                        ConfigReloadEvent::Removed(path)\n                                    }\n                                    _ =\u003e {\n                                        debug!(\"Ignoring event: {:?}\", event.kind);\n                                        continue;\n                                    }\n                                };\n\n                                if let Err(e) = tx_task.send(reload_event).await {\n                                    error!(\"Failed to send config reload event: {}\", e);\n                                    break;\n                                }\n                            }\n                        }\n                        Err(e) =\u003e {\n                            warn!(\"Watch error: {}\", e);\n                        }\n                    }\n                }\n            }\n        }\n    });\n\n    Ok((tx, rx))\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::fs;\n    use tempfile::NamedTempFile;\n    use tokio::time::Duration;\n\n    #[test]\n    fn test_config_reload_event_created() {\n        let path = PathBuf::from(\"/test/config.toml\");\n        let event = ConfigReloadEvent::Created(path.clone());\n        assert!(matches!(event, ConfigReloadEvent::Created(_)));\n        assert_eq!(event, ConfigReloadEvent::Created(path));\n    }\n\n    #[test]\n    fn test_config_reload_event_removed() {\n        let path = PathBuf::from(\"/test/config.toml\");\n        let event = ConfigReloadEvent::Removed(path.clone());\n        assert!(matches!(event, ConfigReloadEvent::Removed(_)));\n        assert_eq!(event, ConfigReloadEvent::Removed(path));\n    }\n\n    #[test]\n    fn test_config_reload_event_changed() {\n        let path = PathBuf::from(\"/test/config.toml\");\n        let event = ConfigReloadEvent::Changed(path.clone());\n        assert!(matches!(event, ConfigReloadEvent::Changed(_)));\n        assert_eq!(event, ConfigReloadEvent::Changed(path));\n    }\n\n    #[test]\n    fn test_config_reload_event_error() {\n        let path = PathBuf::from(\"/test/config.toml\");\n        let event = ConfigReloadEvent::Error {\n            path: path.clone(),\n            error: \"Test error\".to_string(),\n        };\n        assert!(matches!(event, ConfigReloadEvent::Error { .. }));\n        assert_eq!(\n            event,\n            ConfigReloadEvent::Error {\n                path,\n                error: \"Test error\".to_string()\n            }\n        );\n    }\n\n    #[tokio::test]\n    async fn test_tokio_config_reload_event_created() {\n        let path = PathBuf::from(\"/test/config.toml\");\n        let event = ConfigReloadEvent::Created(path.clone());\n        assert!(matches!(event, ConfigReloadEvent::Created(_)));\n        assert_eq!(event, ConfigReloadEvent::Created(path));\n    }\n\n    #[tokio::test]\n    async fn test_tokio_config_reload_event_removed() {\n        let path = PathBuf::from(\"/test/config.toml\");\n        let event = ConfigReloadEvent::Removed(path.clone());\n        assert!(matches!(event, ConfigReloadEvent::Removed(_)));\n        assert_eq!(event, ConfigReloadEvent::Removed(path));\n    }\n\n    #[tokio::test]\n    async fn test_tokio_config_reload_event_error() {\n        let path = PathBuf::from(\"/test/config.toml\");\n        let event = ConfigReloadEvent::Error {\n            path: path.clone(),\n            error: \"Test error\".to_string(),\n        };\n        assert!(matches!(event, ConfigReloadEvent::Error { .. }));\n        assert_eq!(\n            event,\n            ConfigReloadEvent::Error {\n                path,\n                error: \"Test error\".to_string()\n            }\n        );\n    }\n\n    #[tokio::test]\n    async fn test_watch_config_emits_events() {\n        let temp_file = NamedTempFile::new().unwrap();\n        let config_content = r#\"\n[providers.postgres]\nhost = \"testhost\"\n\"#;\n        fs::write(temp_file.path(), config_content).unwrap();\n\n        let (_tx, mut rx) = watch_config(temp_file.path()).await.unwrap();\n\n        let ready_event = tokio::time::timeout(Duration::from_secs(5), rx.recv())\n            .await\n            .expect(\"Timeout waiting for Ready event\")\n            .expect(\"No event received\");\n        assert_eq!(ready_event, ConfigReloadEvent::Ready);\n\n        fs::write(temp_file.path(), \"[providers.postgres]\\nhost = \\\"updated\\\"\").unwrap();\n\n        let event = tokio::time::timeout(Duration::from_secs(5), rx.recv())\n            .await\n            .expect(\"Timeout waiting for config change event\")\n            .expect(\"No event received\");\n\n        match event {\n            ConfigReloadEvent::Changed(path) =\u003e {\n                assert_eq!(\n                    path.canonicalize().unwrap(),\n                    temp_file.path().canonicalize().unwrap()\n                );\n            }\n            _ =\u003e panic!(\"Expected Changed event, got {:?}\", event),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_watch_config_handles_create() {\n        let temp_dir = tempfile::tempdir().unwrap();\n        let config_path = temp_dir.path().join(\"config.toml\");\n\n        fs::write(\u0026config_path, \"initial\").unwrap();\n\n        let (_tx, mut rx) = watch_config(\u0026config_path).await.unwrap();\n\n        let ready_event = tokio::time::timeout(Duration::from_secs(5), rx.recv())\n            .await\n            .expect(\"Timeout waiting for Ready event\")\n            .expect(\"No event received\");\n        assert_eq!(ready_event, ConfigReloadEvent::Ready);\n\n        fs::write(\u0026config_path, \"updated\").unwrap();\n\n        let event = tokio::time::timeout(Duration::from_secs(5), rx.recv())\n            .await\n            .expect(\"Timeout waiting for config change event\")\n            .expect(\"No event received\");\n\n        match event {\n            ConfigReloadEvent::Changed(path) =\u003e {\n                assert_eq!(\n                    path.canonicalize().unwrap(),\n                    config_path.canonicalize().unwrap()\n                );\n            }\n            _ =\u003e panic!(\"Expected Changed event, got {:?}\", event),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_watch_config_nonexistent_file() {\n        let temp_dir = tempfile::tempdir().unwrap();\n        let config_path = temp_dir.path().join(\"nonexistent.toml\");\n\n        let result = watch_config(\u0026config_path).await;\n        assert!(result.is_err());\n\n        let error = result.unwrap_err();\n        let error_str = error.to_string();\n        assert!(error_str.contains(\"not found\") || error_str.contains(\"NotFound\"));\n    }\n\n    #[tokio::test]\n    async fn test_watch_config_error_handling() {\n        let temp_file = NamedTempFile::new().unwrap();\n        fs::write(temp_file.path(), \"test\").unwrap();\n\n        let (_tx, mut rx) = watch_config(temp_file.path()).await.unwrap();\n\n        let _ = tokio::time::timeout(Duration::from_secs(5), rx.recv())\n            .await\n            .expect(\"Timeout waiting for Ready event\");\n\n        drop(rx);\n        tokio::time::sleep(Duration::from_millis(100)).await;\n    }\n\n    #[tokio::test]\n    async fn test_watch_config_removed_file() {\n        let temp_dir = tempfile::tempdir().unwrap();\n        let config_path = temp_dir.path().join(\"config.toml\");\n\n        fs::write(\u0026config_path, \"initial\").unwrap();\n\n        let (_tx, mut rx) = watch_config(\u0026config_path).await.unwrap();\n\n        let ready_event = tokio::time::timeout(Duration::from_secs(5), rx.recv())\n            .await\n            .expect(\"Timeout waiting for Ready event\")\n            .expect(\"No event received\");\n        assert_eq!(ready_event, ConfigReloadEvent::Ready);\n\n        fs::remove_file(\u0026config_path).unwrap();\n\n        let event = tokio::time::timeout(Duration::from_secs(5), rx.recv()).await;\n\n        if let Ok(Some(event)) = event {\n            match event {\n                ConfigReloadEvent::Removed(path) =\u003e {\n                    assert_eq!(\n                        path.canonicalize().unwrap(),\n                        config_path.canonicalize().unwrap()\n                    );\n                }\n                ConfigReloadEvent::Error { path, error } =\u003e {\n                    assert_eq!(\n                        path.canonicalize().unwrap(),\n                        config_path.canonicalize().unwrap()\n                    );\n                    assert!(!error.is_empty());\n                }\n                _ =\u003e {}\n            }\n        }\n    }\n\n    #[test]\n    fn test_config_reload_event_ready() {\n        let event = ConfigReloadEvent::Ready;\n        assert!(matches!(event, ConfigReloadEvent::Ready));\n        assert_eq!(event, ConfigReloadEvent::Ready);\n    }\n\n    #[test]\n    fn test_config_reload_event_partial_eq() {\n        let path1 = PathBuf::from(\"/test/config.toml\");\n        let path2 = PathBuf::from(\"/test/config.toml\");\n        let path3 = PathBuf::from(\"/other/config.toml\");\n\n        // Test equality\n        assert_eq!(\n            ConfigReloadEvent::Changed(path1.clone()),\n            ConfigReloadEvent::Changed(path2.clone())\n        );\n\n        assert_eq!(\n            ConfigReloadEvent::Created(path1.clone()),\n            ConfigReloadEvent::Created(path2.clone())\n        );\n\n        assert_eq!(\n            ConfigReloadEvent::Removed(path1.clone()),\n            ConfigReloadEvent::Removed(path2.clone())\n        );\n\n        assert_eq!(\n            ConfigReloadEvent::Error {\n                path: path1.clone(),\n                error: \"test\".to_string()\n            },\n            ConfigReloadEvent::Error {\n                path: path2.clone(),\n                error: \"test\".to_string()\n            }\n        );\n\n        // Test inequality\n        assert_ne!(\n            ConfigReloadEvent::Changed(path1.clone()),\n            ConfigReloadEvent::Changed(path3.clone())\n        );\n\n        assert_ne!(\n            ConfigReloadEvent::Changed(path1.clone()),\n            ConfigReloadEvent::Created(path1.clone())\n        );\n\n        assert_ne!(\n            ConfigReloadEvent::Error {\n                path: path1.clone(),\n                error: \"error1\".to_string()\n            },\n            ConfigReloadEvent::Error {\n                path: path1.clone(),\n                error: \"error2\".to_string()\n            }\n        );\n    }\n}\n","traces":[{"line":79,"address":[],"length":0,"stats":{"Line":5}},{"line":88,"address":[],"length":0,"stats":{"Line":15}},{"line":90,"address":[],"length":0,"stats":{"Line":5}},{"line":91,"address":[],"length":0,"stats":{"Line":3}},{"line":92,"address":[],"length":0,"stats":{"Line":2}},{"line":93,"address":[],"length":0,"stats":{"Line":1}},{"line":97,"address":[],"length":0,"stats":{"Line":12}},{"line":98,"address":[],"length":0,"stats":{"Line":12}},{"line":99,"address":[],"length":0,"stats":{"Line":12}},{"line":101,"address":[],"length":0,"stats":{"Line":8}},{"line":102,"address":[],"length":0,"stats":{"Line":12}},{"line":103,"address":[],"length":0,"stats":{"Line":8}},{"line":104,"address":[],"length":0,"stats":{"Line":12}},{"line":105,"address":[],"length":0,"stats":{"Line":24}},{"line":107,"address":[],"length":0,"stats":{"Line":4}},{"line":109,"address":[],"length":0,"stats":{"Line":8}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":12}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":4}},{"line":141,"address":[],"length":0,"stats":{"Line":16}},{"line":144,"address":[],"length":0,"stats":{"Line":16}},{"line":145,"address":[],"length":0,"stats":{"Line":32}},{"line":146,"address":[],"length":0,"stats":{"Line":1}},{"line":147,"address":[],"length":0,"stats":{"Line":1}},{"line":149,"address":[],"length":0,"stats":{"Line":44}},{"line":150,"address":[],"length":0,"stats":{"Line":24}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":12}},{"line":155,"address":[],"length":0,"stats":{"Line":12}},{"line":156,"address":[],"length":0,"stats":{"Line":12}},{"line":157,"address":[],"length":0,"stats":{"Line":36}},{"line":158,"address":[],"length":0,"stats":{"Line":24}},{"line":160,"address":[],"length":0,"stats":{"Line":11}},{"line":161,"address":[],"length":0,"stats":{"Line":11}},{"line":164,"address":[],"length":0,"stats":{"Line":1}},{"line":165,"address":[],"length":0,"stats":{"Line":1}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":48}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":4}}],"covered":36,"coverable":60},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","lib.rs"],"content":"//! # Configuration System\n//!\n//! Centralized configuration management for the Memory-Knowledge system.\n//!\n//! This crate provides:\n//! - Configuration structures for all system components\n//! - Environment variable loading (12-factor app principles)\n//! - Configuration file loading (TOML/YAML)\n//! - Configuration precedence (CLI \u003e env \u003e file \u003e defaults)\n//! - Configuration validation\n//! - Hot reload functionality\n//!\n//! # Best Practices\n//!\n//! - Uses `validator` crate for input validation\n//! - Follows 12-factor app configuration principles\n//! - Provides clear error messages for invalid configuration\n//! - Thread-safe configuration access\n\npub mod config;\npub mod file_loader;\npub mod hot_reload;\npub mod loader;\npub mod precedence;\n\npub use config::{\n    Config, DeploymentConfig, MemoryConfig, ObservabilityConfig, ProviderConfig, SyncConfig,\n    ToolConfig,\n};\npub use file_loader::{load_from_file, load_from_toml, load_from_yaml};\npub use hot_reload::watch_config;\npub use loader::load_from_env;\npub use precedence::merge_configs;\npub use validator::Validate;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","loader.rs"],"content":"//! # Environment Variable Loader\n//!\n//! Loads configuration from environment variables following 12-factor app\n//! principles.\n//!\n//! # Naming Convention\n//! - `MK_*`: Memory-related settings\n//! - `KK_*`: Knowledge-related settings\n//! - `SY_*`: Sync-related settings\n//! - `TL_*`: Tool-related settings\n//! - `PG_*`: PostgreSQL settings\n//! - `QD_*`: Qdrant settings\n//! - `RD_*`: Redis settings\n//! - `OB_*`: Observability settings\n\nuse crate::config::{\n    Config, MemoryConfig, ObservabilityConfig, PostgresConfig, ProviderConfig, QdrantConfig,\n    RedisConfig, SyncConfig, ToolConfig,\n};\nuse std::env;\n\n/// Load configuration from environment variables.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Loads configuration from environment variables following 12-factor app\n/// principles. Environment variables override default values but can be\n/// overridden by CLI arguments.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::load_from_env;\n///\n/// fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n///     let config = load_from_env()?;\n///     println!(\"PostgreSQL host: {}\", config.providers.postgres.host);\n///     Ok(())\n/// }\n/// ```\n///\n/// ## Environment Variables\n/// ### General Settings\n/// - `MK_LOG_LEVEL`: Logging level (trace/debug/info/warn/error)\n///\n/// ### PostgreSQL Settings (`PG_*`)\n/// - `PG_HOST`: Database host (default: \"localhost\")\n/// - `PG_PORT`: Database port (default: 5432)\n/// - `PG_DATABASE`: Database name (default: \"memory_knowledge\")\n/// - `PG_USERNAME`: Database user (default: \"postgres\")\n/// - `PG_PASSWORD`: Database password (default: \"\")\n/// - `PG_POOL_SIZE`: Connection pool size (default: 10)\n/// - `PG_TIMEOUT_SECONDS`: Connection timeout in seconds (default: 30)\n///\n/// ### Qdrant Settings (`QD_*`)\n/// - `QD_HOST`: Qdrant host (default: \"localhost\")\n/// - `QD_PORT`: Qdrant port (default: 6333)\n/// - `QD_COLLECTION`: Collection name (default: \"memory_embeddings\")\n/// - `QD_TIMEOUT_SECONDS`: Request timeout in seconds (default: 30)\n///\n/// ### Redis Settings (`RD_*`)\n/// - `RD_HOST`: Redis host (default: \"localhost\")\n/// - `RD_PORT`: Redis port (default: 6379)\n/// - `RD_DB`: Redis database number (default: 0)\n/// - `RD_POOL_SIZE`: Connection pool size (default: 10)\n/// - `RD_TIMEOUT_SECONDS`: Connection timeout in seconds (default: 30)\n///\n/// ### Sync Settings (`SY_*`)\n/// - `SY_ENABLED`: Enable sync (true/false, default: true)\n/// - `SY_SYNC_INTERVAL_SECONDS`: Sync interval (default: 60)\n/// - `SY_BATCH_SIZE`: Batch size (default: 100)\n/// - `SY_CHECKPOINT_ENABLED`: Enable checkpointing (true/false, default: true)\n/// - `SY_CONFLICT_RESOLUTION`: Conflict resolution\n///   (prefer_knowledge/prefer_memory/manual, default: prefer_knowledge)\n///\n/// ### Tools Settings (`TL_*`)\n/// - `TL_ENABLED`: Enable MCP server (true/false, default: true)\n/// - `TL_HOST`: Server host (default: \"localhost\")\n/// - `TL_PORT`: Server port (default: 8080)\n/// - `TL_API_KEY`: API key for authentication (optional)\n/// - `TL_RATE_LIMIT_REQUESTS_PER_MINUTE`: Rate limit (default: 60)\n///\n/// ### Observability Settings (`OB_*`)\n/// - `OB_METRICS_ENABLED`: Enable metrics (true/false, default: true)\n/// - `OB_TRACING_ENABLED`: Enable tracing (true/false, default: true)\n/// - `OB_LOGGING_LEVEL`: Logging level (trace/debug/info/warn/error, default:\n///   \"info\")\n/// - `OB_METRICS_PORT`: Metrics server port (default: 9090)\npub fn load_from_env() -\u003e Result\u003cConfig, Box\u003cdyn std::error::Error\u003e\u003e {\n    let config = Config {\n        providers: load_provider_from_env()?,\n        sync: load_sync_from_env()?,\n        memory: load_memory_from_env()?,\n        tools: load_tools_from_env()?,\n        observability: load_observability_from_env()?,\n        deployment: load_deployment_from_env()?,\n    };\n\n    Ok(config)\n}\n\nfn load_deployment_from_env() -\u003e Result\u003ccrate::config::DeploymentConfig, Box\u003cdyn std::error::Error\u003e\u003e\n{\n    Ok(crate::config::DeploymentConfig {\n        mode: env::var(\"AETERNA_DEPLOYMENT_MODE\").unwrap_or_else(|_| \"local\".to_string()),\n        remote_url: env::var(\"AETERNA_REMOTE_GOVERNANCE_URL\").ok(),\n        sync_enabled: parse_env(\"AETERNA_SYNC_ENABLED\").unwrap_or(true),\n    })\n}\n\nfn load_provider_from_env() -\u003e Result\u003cProviderConfig, Box\u003cdyn std::error::Error\u003e\u003e {\n    Ok(ProviderConfig {\n        postgres: load_postgres_from_env()?,\n        qdrant: load_qdrant_from_env()?,\n        redis: load_redis_from_env()?,\n    })\n}\n\nfn load_postgres_from_env() -\u003e Result\u003cPostgresConfig, Box\u003cdyn std::error::Error\u003e\u003e {\n    Ok(PostgresConfig {\n        host: env::var(\"PG_HOST\").unwrap_or_else(|_| \"localhost\".to_string()),\n        port: parse_env(\"PG_PORT\").unwrap_or(5432),\n        database: env::var(\"PG_DATABASE\").unwrap_or_else(|_| \"memory_knowledge\".to_string()),\n        username: env::var(\"PG_USERNAME\").unwrap_or_else(|_| \"postgres\".to_string()),\n        password: env::var(\"PG_PASSWORD\").unwrap_or_default(),\n        pool_size: parse_env(\"PG_POOL_SIZE\").unwrap_or(10),\n        timeout_seconds: parse_env(\"PG_TIMEOUT_SECONDS\").unwrap_or(30),\n    })\n}\n\nfn load_qdrant_from_env() -\u003e Result\u003cQdrantConfig, Box\u003cdyn std::error::Error\u003e\u003e {\n    Ok(QdrantConfig {\n        host: env::var(\"QD_HOST\").unwrap_or_else(|_| \"localhost\".to_string()),\n        port: parse_env(\"QD_PORT\").unwrap_or(6333),\n        collection: env::var(\"QD_COLLECTION\").unwrap_or_else(|_| \"memory_embeddings\".to_string()),\n        timeout_seconds: parse_env(\"QD_TIMEOUT_SECONDS\").unwrap_or(30),\n    })\n}\n\nfn load_redis_from_env() -\u003e Result\u003cRedisConfig, Box\u003cdyn std::error::Error\u003e\u003e {\n    Ok(RedisConfig {\n        host: env::var(\"RD_HOST\").unwrap_or_else(|_| \"localhost\".to_string()),\n        port: parse_env(\"RD_PORT\").unwrap_or(6379),\n        db: parse_env(\"RD_DB\").unwrap_or(0),\n        pool_size: parse_env(\"RD_POOL_SIZE\").unwrap_or(10),\n        timeout_seconds: parse_env(\"RD_TIMEOUT_SECONDS\").unwrap_or(30),\n    })\n}\n\nfn load_sync_from_env() -\u003e Result\u003cSyncConfig, Box\u003cdyn std::error::Error\u003e\u003e {\n    Ok(SyncConfig {\n        enabled: parse_env(\"SY_ENABLED\").unwrap_or(true),\n        sync_interval_seconds: parse_env(\"SY_SYNC_INTERVAL_SECONDS\").unwrap_or(60),\n        batch_size: parse_env(\"SY_BATCH_SIZE\").unwrap_or(100),\n        checkpoint_enabled: parse_env(\"SY_CHECKPOINT_ENABLED\").unwrap_or(true),\n        conflict_resolution: env::var(\"SY_CONFLICT_RESOLUTION\")\n            .unwrap_or_else(|_| \"prefer_knowledge\".to_string()),\n    })\n}\n\nfn load_memory_from_env() -\u003e Result\u003cMemoryConfig, Box\u003cdyn std::error::Error\u003e\u003e {\n    Ok(MemoryConfig {\n        promotion_threshold: parse_env(\"MK_PROMOTION_THRESHOLD\").unwrap_or(0.8),\n    })\n}\n\nfn load_tools_from_env() -\u003e Result\u003cToolConfig, Box\u003cdyn std::error::Error\u003e\u003e {\n    Ok(ToolConfig {\n        enabled: parse_env(\"TL_ENABLED\").unwrap_or(true),\n        host: env::var(\"TL_HOST\").unwrap_or_else(|_| \"localhost\".to_string()),\n        port: parse_env(\"TL_PORT\").unwrap_or(8080),\n        api_key: env::var(\"TL_API_KEY\").ok(),\n        rate_limit_requests_per_minute: parse_env(\"TL_RATE_LIMIT_REQUESTS_PER_MINUTE\")\n            .unwrap_or(60),\n    })\n}\n\nfn load_observability_from_env() -\u003e Result\u003cObservabilityConfig, Box\u003cdyn std::error::Error\u003e\u003e {\n    Ok(ObservabilityConfig {\n        metrics_enabled: parse_env(\"OB_METRICS_ENABLED\").unwrap_or(true),\n        tracing_enabled: parse_env(\"OB_TRACING_ENABLED\").unwrap_or(true),\n        logging_level: env::var(\"OB_LOGGING_LEVEL\").unwrap_or_else(|_| \"info\".to_string()),\n        metrics_port: parse_env(\"OB_METRICS_PORT\").unwrap_or(9090),\n    })\n}\n\nfn parse_env\u003cT\u003e(key: \u0026str) -\u003e Result\u003cT, Box\u003cdyn std::error::Error\u003e\u003e\nwhere\n    T: std::str::FromStr,\n    T::Err: std::error::Error + Send + Sync + 'static,\n{\n    match env::var(key) {\n        Ok(s) =\u003e s\n            .parse::\u003cT\u003e()\n            .map_err(|e| Box::new(e) as Box\u003cdyn std::error::Error\u003e),\n        Err(e) =\u003e Err(Box::new(e) as Box\u003cdyn std::error::Error\u003e),\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use serial_test::serial;\n\n    #[test]\n    #[serial]\n    fn test_load_from_env_defaults() {\n        unsafe {\n            env::remove_var(\"PG_HOST\");\n            env::remove_var(\"QD_HOST\");\n            env::remove_var(\"RD_HOST\");\n            env::remove_var(\"SY_ENABLED\");\n            env::remove_var(\"TL_PORT\");\n            env::remove_var(\"OB_LOGGING_LEVEL\");\n        }\n        let config = load_from_env().unwrap();\n        assert_eq!(config.providers.postgres.host, \"localhost\");\n        assert_eq!(config.providers.qdrant.host, \"localhost\");\n        assert_eq!(config.providers.redis.host, \"localhost\");\n        assert_eq!(config.sync.enabled, true);\n        assert_eq!(config.tools.port, 8080);\n        assert_eq!(config.observability.logging_level, \"info\");\n    }\n\n    #[test]\n    #[serial]\n    fn test_load_from_env_overrides() {\n        unsafe {\n            env::set_var(\"PG_HOST\", \"testhost\");\n            env::set_var(\"PG_PORT\", \"9999\");\n            env::set_var(\"SY_ENABLED\", \"false\");\n        }\n\n        let config = load_from_env().unwrap();\n        assert_eq!(config.providers.postgres.host, \"testhost\");\n        assert_eq!(config.providers.postgres.port, 9999);\n        assert_eq!(config.sync.enabled, false);\n\n        unsafe {\n            env::remove_var(\"PG_HOST\");\n            env::remove_var(\"PG_PORT\");\n            env::remove_var(\"SY_ENABLED\");\n        }\n    }\n\n    #[test]\n    fn test_parse_env_missing() {\n        let result: Result\u003cu32, _\u003e = parse_env(\"NONEXISTENT_VAR\");\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_parse_env_valid_string() {\n        unsafe {\n            env::set_var(\"TEST_VAR\", \"test_value\");\n        }\n        let result: Result\u003cString, _\u003e = parse_env(\"TEST_VAR\");\n        assert_eq!(result.unwrap(), \"test_value\");\n        unsafe {\n            env::remove_var(\"TEST_VAR\");\n        }\n    }\n\n    #[test]\n    fn test_parse_env_valid_number() {\n        unsafe {\n            env::set_var(\"TEST_VAR\", \"123\");\n        }\n        let result: Result\u003cu32, _\u003e = parse_env(\"TEST_VAR\");\n        assert_eq!(result.unwrap(), 123);\n        unsafe {\n            env::remove_var(\"TEST_VAR\");\n        }\n    }\n\n    #[test]\n    fn test_parse_env_valid_number_with_parse_env() {\n        unsafe {\n            env::set_var(\"TEST_VAR\", \"123\");\n        }\n        let result: Result\u003cu32, _\u003e = parse_env(\"TEST_VAR\");\n        assert_eq!(result.unwrap(), 123);\n        unsafe {\n            env::remove_var(\"TEST_VAR\");\n        }\n    }\n\n    #[test]\n    fn test_parse_env_invalid_number() {\n        unsafe {\n            env::set_var(\"TEST_VAR\", \"not_a_number\");\n        }\n        let result: Result\u003cu32, _\u003e = parse_env(\"TEST_VAR\");\n        assert!(result.is_err());\n        unsafe {\n            env::remove_var(\"TEST_VAR\");\n        }\n    }\n\n    #[test]\n    #[serial]\n    fn test_load_postgres_from_env() {\n        unsafe {\n            env::set_var(\"PG_HOST\", \"customhost\");\n            env::set_var(\"PG_PORT\", \"5433\");\n            env::set_var(\"PG_DATABASE\", \"testdb\");\n            env::set_var(\"PG_USERNAME\", \"testuser\");\n            env::set_var(\"PG_PASSWORD\", \"testpass\");\n            env::set_var(\"PG_POOL_SIZE\", \"20\");\n            env::set_var(\"PG_TIMEOUT_SECONDS\", \"60\");\n        }\n\n        let postgres = load_postgres_from_env().unwrap();\n\n        unsafe {\n            env::remove_var(\"PG_HOST\");\n            env::remove_var(\"PG_PORT\");\n            env::remove_var(\"PG_DATABASE\");\n            env::remove_var(\"PG_USERNAME\");\n            env::remove_var(\"PG_PASSWORD\");\n            env::remove_var(\"PG_POOL_SIZE\");\n            env::remove_var(\"PG_TIMEOUT_SECONDS\");\n        }\n\n        assert_eq!(postgres.host, \"customhost\");\n        assert_eq!(postgres.port, 5433);\n        assert_eq!(postgres.database, \"testdb\");\n        assert_eq!(postgres.username, \"testuser\");\n        assert_eq!(postgres.password, \"testpass\");\n        assert_eq!(postgres.pool_size, 20);\n        assert_eq!(postgres.timeout_seconds, 60);\n    }\n\n    #[test]\n    #[serial]\n    fn test_load_qdrant_from_env() {\n        unsafe {\n            env::set_var(\"QD_HOST\", \"qdranthost\");\n            env::set_var(\"QD_PORT\", \"7333\");\n            env::set_var(\"QD_COLLECTION\", \"test_collection\");\n            env::set_var(\"QD_TIMEOUT_SECONDS\", \"45\");\n        }\n\n        let qdrant = load_qdrant_from_env().unwrap();\n        assert_eq!(qdrant.host, \"qdranthost\");\n        assert_eq!(qdrant.port, 7333);\n        assert_eq!(qdrant.collection, \"test_collection\");\n        assert_eq!(qdrant.timeout_seconds, 45);\n\n        unsafe {\n            env::remove_var(\"QD_HOST\");\n            env::remove_var(\"QD_PORT\");\n            env::remove_var(\"QD_COLLECTION\");\n            env::remove_var(\"QD_TIMEOUT_SECONDS\");\n        }\n    }\n\n    #[test]\n    #[serial]\n    fn test_load_redis_from_env() {\n        unsafe {\n            env::set_var(\"RD_HOST\", \"redishost\");\n            env::set_var(\"RD_PORT\", \"6380\");\n            env::set_var(\"RD_DB\", \"1\");\n            env::set_var(\"RD_POOL_SIZE\", \"15\");\n            env::set_var(\"RD_TIMEOUT_SECONDS\", \"45\");\n        }\n\n        let redis = load_redis_from_env().unwrap();\n        assert_eq!(redis.host, \"redishost\");\n        assert_eq!(redis.port, 6380);\n        assert_eq!(redis.db, 1);\n        assert_eq!(redis.pool_size, 15);\n        assert_eq!(redis.timeout_seconds, 45);\n\n        unsafe {\n            env::remove_var(\"RD_HOST\");\n            env::remove_var(\"RD_PORT\");\n            env::remove_var(\"RD_DB\");\n            env::remove_var(\"RD_POOL_SIZE\");\n            env::remove_var(\"RD_TIMEOUT_SECONDS\");\n        }\n    }\n}\n","traces":[{"line":89,"address":[],"length":0,"stats":{"Line":2}},{"line":91,"address":[],"length":0,"stats":{"Line":2}},{"line":92,"address":[],"length":0,"stats":{"Line":2}},{"line":93,"address":[],"length":0,"stats":{"Line":2}},{"line":94,"address":[],"length":0,"stats":{"Line":2}},{"line":95,"address":[],"length":0,"stats":{"Line":2}},{"line":96,"address":[],"length":0,"stats":{"Line":2}},{"line":99,"address":[],"length":0,"stats":{"Line":2}},{"line":102,"address":[],"length":0,"stats":{"Line":2}},{"line":105,"address":[],"length":0,"stats":{"Line":8}},{"line":106,"address":[],"length":0,"stats":{"Line":4}},{"line":107,"address":[],"length":0,"stats":{"Line":6}},{"line":111,"address":[],"length":0,"stats":{"Line":2}},{"line":113,"address":[],"length":0,"stats":{"Line":2}},{"line":114,"address":[],"length":0,"stats":{"Line":2}},{"line":115,"address":[],"length":0,"stats":{"Line":2}},{"line":119,"address":[],"length":0,"stats":{"Line":3}},{"line":121,"address":[],"length":0,"stats":{"Line":8}},{"line":122,"address":[],"length":0,"stats":{"Line":9}},{"line":123,"address":[],"length":0,"stats":{"Line":10}},{"line":124,"address":[],"length":0,"stats":{"Line":10}},{"line":125,"address":[],"length":0,"stats":{"Line":6}},{"line":126,"address":[],"length":0,"stats":{"Line":9}},{"line":127,"address":[],"length":0,"stats":{"Line":9}},{"line":131,"address":[],"length":0,"stats":{"Line":3}},{"line":133,"address":[],"length":0,"stats":{"Line":10}},{"line":134,"address":[],"length":0,"stats":{"Line":9}},{"line":135,"address":[],"length":0,"stats":{"Line":10}},{"line":136,"address":[],"length":0,"stats":{"Line":9}},{"line":140,"address":[],"length":0,"stats":{"Line":3}},{"line":142,"address":[],"length":0,"stats":{"Line":10}},{"line":143,"address":[],"length":0,"stats":{"Line":9}},{"line":144,"address":[],"length":0,"stats":{"Line":9}},{"line":145,"address":[],"length":0,"stats":{"Line":9}},{"line":146,"address":[],"length":0,"stats":{"Line":9}},{"line":150,"address":[],"length":0,"stats":{"Line":2}},{"line":152,"address":[],"length":0,"stats":{"Line":6}},{"line":153,"address":[],"length":0,"stats":{"Line":6}},{"line":154,"address":[],"length":0,"stats":{"Line":6}},{"line":155,"address":[],"length":0,"stats":{"Line":6}},{"line":156,"address":[],"length":0,"stats":{"Line":2}},{"line":157,"address":[],"length":0,"stats":{"Line":6}},{"line":161,"address":[],"length":0,"stats":{"Line":2}},{"line":162,"address":[],"length":0,"stats":{"Line":2}},{"line":163,"address":[],"length":0,"stats":{"Line":4}},{"line":167,"address":[],"length":0,"stats":{"Line":2}},{"line":169,"address":[],"length":0,"stats":{"Line":6}},{"line":170,"address":[],"length":0,"stats":{"Line":8}},{"line":171,"address":[],"length":0,"stats":{"Line":6}},{"line":172,"address":[],"length":0,"stats":{"Line":4}},{"line":173,"address":[],"length":0,"stats":{"Line":4}},{"line":174,"address":[],"length":0,"stats":{"Line":2}},{"line":178,"address":[],"length":0,"stats":{"Line":2}},{"line":180,"address":[],"length":0,"stats":{"Line":6}},{"line":181,"address":[],"length":0,"stats":{"Line":6}},{"line":182,"address":[],"length":0,"stats":{"Line":8}},{"line":183,"address":[],"length":0,"stats":{"Line":6}},{"line":187,"address":[],"length":0,"stats":{"Line":56}},{"line":192,"address":[],"length":0,"stats":{"Line":56}},{"line":193,"address":[],"length":0,"stats":{"Line":30}},{"line":195,"address":[],"length":0,"stats":{"Line":18}},{"line":196,"address":[],"length":0,"stats":{"Line":123}}],"covered":62,"coverable":62},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","opencode.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","pointer.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","pool.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","postgres.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","precedence.rs"],"content":"//! # Configuration Precedence\n//!\n//! Merges configuration from multiple sources with precedence rules.\n//!\n//! # Precedence Order\n//! 1. CLI arguments (highest priority)\n//! 2. Environment variables\n//! 3. Configuration file\n//! 4. Default values (lowest priority)\n\nuse crate::config::{\n    Config, ObservabilityConfig, PostgresConfig, QdrantConfig, RedisConfig, SyncConfig, ToolConfig,\n};\n\n/// Merge multiple configuration sources with precedence.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Merges configuration from multiple sources following precedence rules:\n/// CLI arguments \u003e environment variables \u003e config file \u003e defaults.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use config::{Config, load_from_env, load_from_file, merge_configs};\n/// use std::path::Path;\n///\n/// fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n///     let defaults = Config::default();\n///     let from_file = load_from_file(Path::new(\"config.toml\"))?;\n///     let from_env = load_from_env()?;\n///\n///     let _config = merge_configs(defaults, from_file, \"file\", from_env, \"env\", None, \"cli\");\n///     Ok(())\n/// }\n/// ```\n///\n/// ## Deep Merge\n/// Performs deep merge on nested structures (providers, sync, tools,\n/// observability). String fields are overridden, not concatenated.\npub fn merge_configs(\n    defaults: Config,\n    file_config: Config,\n    file_source_name: \u0026str,\n    env_config: Config,\n    env_source_name: \u0026str,\n    cli_config: Option\u003cConfig\u003e,\n    cli_source_name: \u0026str,\n) -\u003e Config {\n    let mut config = defaults;\n\n    config = merge_with_logging(config, file_config, file_source_name);\n    config = merge_with_logging(config, env_config, env_source_name);\n\n    if let Some(cli) = cli_config {\n        config = merge_with_logging(config, cli, cli_source_name);\n    }\n\n    config\n}\n\nfn merge_with_logging(mut base: Config, override_config: Config, source_name: \u0026str) -\u003e Config {\n    let mut changes = Vec::new();\n\n    let mut temp_postgres = base.providers.postgres.clone();\n    merge_postgres(\n        \u0026mut temp_postgres,\n        \u0026override_config.providers.postgres,\n        source_name,\n        \u0026mut changes,\n    );\n    if !changes.is_empty() {\n        base.providers.postgres = temp_postgres;\n    }\n\n    let mut qdrant_changes = Vec::new();\n    let mut temp_qdrant = base.providers.qdrant.clone();\n    merge_qdrant(\n        \u0026mut temp_qdrant,\n        \u0026override_config.providers.qdrant,\n        source_name,\n        \u0026mut qdrant_changes,\n    );\n    if !qdrant_changes.is_empty() {\n        base.providers.qdrant = temp_qdrant;\n        changes.extend(qdrant_changes);\n    }\n\n    let mut redis_changes = Vec::new();\n    let mut temp_redis = base.providers.redis.clone();\n    merge_redis(\n        \u0026mut temp_redis,\n        \u0026override_config.providers.redis,\n        source_name,\n        \u0026mut redis_changes,\n    );\n    if !redis_changes.is_empty() {\n        base.providers.redis = temp_redis;\n        changes.extend(redis_changes);\n    }\n\n    let mut sync_changes = Vec::new();\n    let mut temp_sync = base.sync.clone();\n    merge_sync(\n        \u0026mut temp_sync,\n        \u0026override_config.sync,\n        source_name,\n        \u0026mut sync_changes,\n    );\n    if !sync_changes.is_empty() {\n        base.sync = temp_sync;\n        changes.extend(sync_changes);\n    }\n\n    let mut tool_changes = Vec::new();\n    let mut temp_tools = base.tools.clone();\n    merge_tools(\n        \u0026mut temp_tools,\n        \u0026override_config.tools,\n        source_name,\n        \u0026mut tool_changes,\n    );\n    if !tool_changes.is_empty() {\n        base.tools = temp_tools;\n        changes.extend(tool_changes);\n    }\n\n    let mut obs_changes = Vec::new();\n    let mut temp_obs = base.observability.clone();\n    merge_observability(\n        \u0026mut temp_obs,\n        \u0026override_config.observability,\n        source_name,\n        \u0026mut obs_changes,\n    );\n    if !obs_changes.is_empty() {\n        base.observability = temp_obs;\n        changes.extend(obs_changes);\n    }\n\n    if !changes.is_empty() {\n        tracing::info!(\"Configuration from {}: {:?}\", source_name, changes);\n    }\n\n    base\n}\n\nfn merge_postgres(\n    base: \u0026mut PostgresConfig,\n    override_config: \u0026PostgresConfig,\n    _source: \u0026str,\n    changes: \u0026mut Vec\u003cString\u003e,\n) {\n    if override_config.host != \"localhost\" \u0026\u0026 override_config.host != base.host {\n        changes.push(format!(\n            \"providers.postgres.host = {}\",\n            override_config.host\n        ));\n        base.host.clone_from(\u0026override_config.host);\n    }\n    if override_config.port != 5432 \u0026\u0026 override_config.port != base.port {\n        changes.push(format!(\n            \"providers.postgres.port = {}\",\n            override_config.port\n        ));\n        base.port = override_config.port;\n    }\n    if override_config.database != \"memory_knowledge\" \u0026\u0026 override_config.database != base.database {\n        changes.push(format!(\n            \"providers.postgres.database = {}\",\n            override_config.database\n        ));\n        base.database.clone_from(\u0026override_config.database);\n    }\n    if override_config.username != \"postgres\" \u0026\u0026 override_config.username != base.username {\n        changes.push(format!(\n            \"providers.postgres.username = {}\",\n            override_config.username\n        ));\n        base.username.clone_from(\u0026override_config.username);\n    }\n    if !override_config.password.is_empty() \u0026\u0026 override_config.password != base.password {\n        changes.push(\"providers.postgres.password = ***\".to_string());\n        base.password.clone_from(\u0026override_config.password);\n    }\n    if override_config.pool_size != 10 \u0026\u0026 override_config.pool_size != base.pool_size {\n        changes.push(format!(\n            \"providers.postgres.pool_size = {}\",\n            override_config.pool_size\n        ));\n        base.pool_size = override_config.pool_size;\n    }\n    if override_config.timeout_seconds != 30\n        \u0026\u0026 override_config.timeout_seconds != base.timeout_seconds\n    {\n        changes.push(format!(\n            \"providers.postgres.timeout_seconds = {}\",\n            override_config.timeout_seconds\n        ));\n        base.timeout_seconds = override_config.timeout_seconds;\n    }\n}\n\nfn merge_qdrant(\n    base: \u0026mut QdrantConfig,\n    override_config: \u0026QdrantConfig,\n    _source: \u0026str,\n    changes: \u0026mut Vec\u003cString\u003e,\n) {\n    if override_config.host != \"localhost\" \u0026\u0026 override_config.host != base.host {\n        changes.push(format!(\"providers.qdrant.host = {}\", override_config.host));\n        base.host.clone_from(\u0026override_config.host);\n    }\n    if override_config.port != 6333 \u0026\u0026 override_config.port != base.port {\n        changes.push(format!(\"providers.qdrant.port = {}\", override_config.port));\n        base.port = override_config.port;\n    }\n    if override_config.collection != \"memory_embeddings\"\n        \u0026\u0026 override_config.collection != base.collection\n    {\n        changes.push(format!(\n            \"providers.qdrant.collection = {}\",\n            override_config.collection\n        ));\n        base.collection.clone_from(\u0026override_config.collection);\n    }\n    if override_config.timeout_seconds != 30\n        \u0026\u0026 override_config.timeout_seconds != base.timeout_seconds\n    {\n        changes.push(format!(\n            \"providers.qdrant.timeout_seconds = {}\",\n            override_config.timeout_seconds\n        ));\n        base.timeout_seconds = override_config.timeout_seconds;\n    }\n}\n\nfn merge_redis(\n    base: \u0026mut RedisConfig,\n    override_config: \u0026RedisConfig,\n    _source: \u0026str,\n    changes: \u0026mut Vec\u003cString\u003e,\n) {\n    if override_config.host != \"localhost\" \u0026\u0026 override_config.host != base.host {\n        changes.push(format!(\"providers.redis.host = {}\", override_config.host));\n        base.host.clone_from(\u0026override_config.host);\n    }\n    if override_config.port != 6379 \u0026\u0026 override_config.port != base.port {\n        changes.push(format!(\"providers.redis.port = {}\", override_config.port));\n        base.port = override_config.port;\n    }\n    if override_config.db != 0 \u0026\u0026 override_config.db != base.db {\n        changes.push(format!(\"providers.redis.db = {}\", override_config.db));\n        base.db = override_config.db;\n    }\n    if override_config.pool_size != 10 \u0026\u0026 override_config.pool_size != base.pool_size {\n        changes.push(format!(\n            \"providers.redis.pool_size = {}\",\n            override_config.pool_size\n        ));\n        base.pool_size = override_config.pool_size;\n    }\n    if override_config.timeout_seconds != 30\n        \u0026\u0026 override_config.timeout_seconds != base.timeout_seconds\n    {\n        changes.push(format!(\n            \"providers.redis.timeout_seconds = {}\",\n            override_config.timeout_seconds\n        ));\n        base.timeout_seconds = override_config.timeout_seconds;\n    }\n}\n\nfn merge_sync(\n    base: \u0026mut SyncConfig,\n    override_config: \u0026SyncConfig,\n    _source: \u0026str,\n    changes: \u0026mut Vec\u003cString\u003e,\n) {\n    if override_config.enabled != base.enabled {\n        changes.push(format!(\"sync.enabled = {}\", override_config.enabled));\n        base.enabled = override_config.enabled;\n    }\n    if override_config.sync_interval_seconds != 60\n        \u0026\u0026 override_config.sync_interval_seconds != base.sync_interval_seconds\n    {\n        changes.push(format!(\n            \"sync.sync_interval_seconds = {}\",\n            override_config.sync_interval_seconds\n        ));\n        base.sync_interval_seconds = override_config.sync_interval_seconds;\n    }\n    if override_config.batch_size != 100 \u0026\u0026 override_config.batch_size != base.batch_size {\n        changes.push(format!(\"sync.batch_size = {}\", override_config.batch_size));\n        base.batch_size = override_config.batch_size;\n    }\n    if override_config.checkpoint_enabled != base.checkpoint_enabled {\n        changes.push(format!(\n            \"sync.checkpoint_enabled = {}\",\n            override_config.checkpoint_enabled\n        ));\n        base.checkpoint_enabled = override_config.checkpoint_enabled;\n    }\n    if override_config.conflict_resolution != \"prefer_knowledge\"\n        \u0026\u0026 override_config.conflict_resolution != base.conflict_resolution\n    {\n        changes.push(format!(\n            \"sync.conflict_resolution = {}\",\n            override_config.conflict_resolution\n        ));\n        base.conflict_resolution\n            .clone_from(\u0026override_config.conflict_resolution);\n    }\n}\n\nfn merge_tools(\n    base: \u0026mut ToolConfig,\n    override_config: \u0026ToolConfig,\n    _source: \u0026str,\n    changes: \u0026mut Vec\u003cString\u003e,\n) {\n    if override_config.enabled != base.enabled {\n        changes.push(format!(\"tools.enabled = {}\", override_config.enabled));\n        base.enabled = override_config.enabled;\n    }\n    if override_config.host != \"localhost\" \u0026\u0026 override_config.host != base.host {\n        changes.push(format!(\"tools.host = {}\", override_config.host));\n        base.host.clone_from(\u0026override_config.host);\n    }\n    if override_config.port != 8080 \u0026\u0026 override_config.port != base.port {\n        changes.push(format!(\"tools.port = {}\", override_config.port));\n        base.port = override_config.port;\n    }\n    if override_config.api_key != base.api_key {\n        match (\u0026override_config.api_key, \u0026base.api_key) {\n            (Some(_), None) =\u003e changes.push(\"tools.api_key = ***\".to_string()),\n            (None, Some(_)) =\u003e changes.push(\"tools.api_key = (none)\".to_string()),\n            (Some(new_key), Some(old_key)) if new_key != old_key =\u003e {\n                changes.push(\"tools.api_key = ***\".to_string())\n            }\n            _ =\u003e {}\n        }\n        base.api_key.clone_from(\u0026override_config.api_key);\n    }\n    if override_config.rate_limit_requests_per_minute != 60\n        \u0026\u0026 override_config.rate_limit_requests_per_minute != base.rate_limit_requests_per_minute\n    {\n        changes.push(format!(\n            \"tools.rate_limit_requests_per_minute = {}\",\n            override_config.rate_limit_requests_per_minute\n        ));\n        base.rate_limit_requests_per_minute = override_config.rate_limit_requests_per_minute;\n    }\n}\n\nfn merge_observability(\n    base: \u0026mut ObservabilityConfig,\n    override_config: \u0026ObservabilityConfig,\n    _source: \u0026str,\n    changes: \u0026mut Vec\u003cString\u003e,\n) {\n    if override_config.metrics_enabled != base.metrics_enabled {\n        changes.push(format!(\n            \"observability.metrics_enabled = {}\",\n            override_config.metrics_enabled\n        ));\n        base.metrics_enabled = override_config.metrics_enabled;\n    }\n    if override_config.tracing_enabled != base.tracing_enabled {\n        changes.push(format!(\n            \"observability.tracing_enabled = {}\",\n            override_config.tracing_enabled\n        ));\n        base.tracing_enabled = override_config.tracing_enabled;\n    }\n    if override_config.logging_level != \"info\"\n        \u0026\u0026 override_config.logging_level != base.logging_level\n    {\n        changes.push(format!(\n            \"observability.logging_level = {}\",\n            override_config.logging_level\n        ));\n        base.logging_level\n            .clone_from(\u0026override_config.logging_level);\n    }\n    if override_config.metrics_port != 9090 \u0026\u0026 override_config.metrics_port != base.metrics_port {\n        changes.push(format!(\n            \"observability.metrics_port = {}\",\n            override_config.metrics_port\n        ));\n        base.metrics_port = override_config.metrics_port;\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::config::ProviderConfig;\n\n    #[test]\n    fn test_merge_configs_precedence() {\n        let defaults = Config {\n            providers: ProviderConfig {\n                postgres: PostgresConfig {\n                    host: \"default_host\".to_string(),\n                    ..Default::default()\n                },\n                ..Default::default()\n            },\n            ..Default::default()\n        };\n\n        let file_config = Config {\n            providers: ProviderConfig {\n                postgres: PostgresConfig {\n                    host: \"file_host\".to_string(),\n                    ..Default::default()\n                },\n                ..Default::default()\n            },\n            ..Default::default()\n        };\n\n        let env_config = Config {\n            providers: ProviderConfig {\n                postgres: PostgresConfig {\n                    port: 9999,\n                    ..Default::default()\n                },\n                ..Default::default()\n            },\n            ..Default::default()\n        };\n\n        let merged = merge_configs(\n            defaults,\n            file_config,\n            \"file\",\n            env_config,\n            \"env\",\n            None,\n            \"cli\",\n        );\n\n        assert_eq!(merged.providers.postgres.host, \"file_host\");\n        assert_eq!(merged.providers.postgres.port, 9999);\n    }\n\n    #[test]\n    fn test_merge_postgres() {\n        let mut base = PostgresConfig {\n            host: \"base_host\".to_string(),\n            port: 5432,\n            database: \"base_db\".to_string(),\n            ..Default::default()\n        };\n\n        let override_config = PostgresConfig {\n            host: \"override_host\".to_string(),\n            port: 9999,\n            database: \"override_db\".to_string(),\n            ..Default::default()\n        };\n\n        let mut changes = Vec::new();\n        merge_postgres(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(base.host, \"override_host\");\n        assert_eq!(base.port, 9999);\n        assert_eq!(base.database, \"override_db\");\n        assert_eq!(changes.len(), 3);\n    }\n\n    #[test]\n    fn test_merge_sync() {\n        let mut base = SyncConfig {\n            enabled: true,\n            sync_interval_seconds: 60,\n            ..Default::default()\n        };\n\n        let override_config = SyncConfig {\n            enabled: false,\n            sync_interval_seconds: 120,\n            ..Default::default()\n        };\n\n        let mut changes = Vec::new();\n        merge_sync(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(base.enabled, false);\n        assert_eq!(base.sync_interval_seconds, 120);\n        assert_eq!(changes.len(), 2);\n    }\n\n    #[test]\n    fn test_merge_tools_with_api_key() {\n        let mut base = ToolConfig {\n            api_key: Some(\"old_key\".to_string()),\n            ..Default::default()\n        };\n\n        let override_config = ToolConfig {\n            api_key: Some(\"new_key\".to_string()),\n            ..Default::default()\n        };\n\n        let mut changes = Vec::new();\n        merge_tools(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(base.api_key, Some(\"new_key\".to_string()));\n        assert_eq!(changes.len(), 1);\n        assert!(changes[0].contains(\"api_key = ***\"));\n    }\n\n    #[test]\n    fn test_merge_cli_overrides_all() {\n        let defaults = Config::default();\n        let file_config = defaults.clone();\n        let env_config = defaults.clone();\n        let cli_config = Config {\n            providers: ProviderConfig {\n                postgres: PostgresConfig {\n                    host: \"cli_host\".to_string(),\n                    ..Default::default()\n                },\n                ..Default::default()\n            },\n            ..Default::default()\n        };\n\n        let merged = merge_configs(\n            defaults,\n            file_config,\n            \"file\",\n            env_config,\n            \"env\",\n            Some(cli_config),\n            \"cli\",\n        );\n\n        assert_eq!(merged.providers.postgres.host, \"cli_host\");\n    }\n\n    #[test]\n    fn test_merge_qdrant() {\n        let mut base = QdrantConfig {\n            host: \"base_host\".to_string(),\n            port: 6333,\n            collection: \"base_collection\".to_string(),\n            ..Default::default()\n        };\n\n        let override_config = QdrantConfig {\n            host: \"override_host\".to_string(),\n            port: 9999,\n            collection: \"override_collection\".to_string(),\n            ..Default::default()\n        };\n\n        let mut changes = Vec::new();\n        merge_qdrant(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(base.host, \"override_host\");\n        assert_eq!(base.port, 9999);\n        assert_eq!(base.collection, \"override_collection\");\n        assert_eq!(changes.len(), 3);\n    }\n\n    #[test]\n    fn test_merge_redis() {\n        let mut base = RedisConfig {\n            host: \"base_host\".to_string(),\n            port: 6379,\n            db: 0,\n            ..Default::default()\n        };\n\n        let override_config = RedisConfig {\n            host: \"override_host\".to_string(),\n            port: 9999,\n            db: 1,\n            ..Default::default()\n        };\n\n        let mut changes = Vec::new();\n        merge_redis(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(base.host, \"override_host\");\n        assert_eq!(base.port, 9999);\n        assert_eq!(base.db, 1);\n        assert_eq!(changes.len(), 3);\n    }\n\n    #[test]\n    fn test_merge_observability() {\n        let mut base = ObservabilityConfig {\n            metrics_enabled: true,\n            tracing_enabled: true,\n            logging_level: \"info\".to_string(),\n            metrics_port: 9090,\n        };\n\n        let override_config = ObservabilityConfig {\n            metrics_enabled: false,\n            tracing_enabled: false,\n            logging_level: \"debug\".to_string(),\n            metrics_port: 9999,\n        };\n\n        let mut changes = Vec::new();\n        merge_observability(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(base.metrics_enabled, false);\n        assert_eq!(base.tracing_enabled, false);\n        assert_eq!(base.logging_level, \"debug\");\n        assert_eq!(base.metrics_port, 9999);\n        assert_eq!(changes.len(), 4);\n    }\n\n    #[test]\n    fn test_merge_with_default_values() {\n        let mut base = PostgresConfig {\n            host: \"localhost\".to_string(),\n            port: 5432,\n            database: \"memory_knowledge\".to_string(),\n            username: \"postgres\".to_string(),\n            password: \"\".to_string(),\n            pool_size: 10,\n            timeout_seconds: 30,\n        };\n\n        let override_config = PostgresConfig {\n            host: \"localhost\".to_string(),\n            port: 5432,\n            database: \"memory_knowledge\".to_string(),\n            username: \"postgres\".to_string(),\n            password: \"\".to_string(),\n            pool_size: 10,\n            timeout_seconds: 30,\n        };\n\n        let mut changes = Vec::new();\n        merge_postgres(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(changes.len(), 0);\n    }\n\n    #[test]\n    fn test_merge_tools_without_api_key() {\n        let mut base = ToolConfig {\n            api_key: None,\n            ..Default::default()\n        };\n\n        let override_config = ToolConfig {\n            api_key: None,\n            ..Default::default()\n        };\n\n        let mut changes = Vec::new();\n        merge_tools(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(base.api_key, None);\n        assert_eq!(changes.len(), 0);\n    }\n\n    #[test]\n    fn test_merge_tools_remove_api_key() {\n        let mut base = ToolConfig {\n            api_key: Some(\"old_key\".to_string()),\n            ..Default::default()\n        };\n\n        let override_config = ToolConfig {\n            api_key: None,\n            ..Default::default()\n        };\n\n        let mut changes = Vec::new();\n        merge_tools(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(base.api_key, None);\n        assert_eq!(changes.len(), 1);\n        assert!(changes[0].contains(\"api_key = (none)\"));\n    }\n\n    #[test]\n    fn test_merge_configs_no_changes() {\n        let defaults = Config::default();\n        let file_config = Config::default();\n        let env_config = Config::default();\n\n        let merged = merge_configs(\n            defaults,\n            file_config,\n            \"file\",\n            env_config,\n            \"env\",\n            None,\n            \"cli\",\n        );\n\n        assert_eq!(merged, Config::default());\n    }\n\n    #[test]\n    fn test_merge_configs_partial_changes() {\n        let defaults = Config {\n            providers: ProviderConfig {\n                postgres: PostgresConfig {\n                    host: \"default_host\".to_string(),\n                    port: 5432,\n                    ..Default::default()\n                },\n                qdrant: QdrantConfig {\n                    host: \"default_qdrant\".to_string(),\n                    ..Default::default()\n                },\n                ..Default::default()\n            },\n            ..Default::default()\n        };\n\n        let file_config = Config {\n            providers: ProviderConfig {\n                postgres: PostgresConfig {\n                    host: \"file_host\".to_string(),\n                    ..Default::default()\n                },\n                ..Default::default()\n            },\n            ..Default::default()\n        };\n\n        let env_config = Config {\n            providers: ProviderConfig {\n                qdrant: QdrantConfig {\n                    host: \"env_qdrant\".to_string(),\n                    ..Default::default()\n                },\n                ..Default::default()\n            },\n            ..Default::default()\n        };\n\n        let merged = merge_configs(\n            defaults,\n            file_config,\n            \"file\",\n            env_config,\n            \"env\",\n            None,\n            \"cli\",\n        );\n\n        assert_eq!(merged.providers.postgres.host, \"file_host\");\n        assert_eq!(merged.providers.postgres.port, 5432);\n        assert_eq!(merged.providers.qdrant.host, \"env_qdrant\");\n    }\n\n    #[test]\n    fn test_merge_postgres_no_changes() {\n        let mut base = PostgresConfig::default();\n        let override_config = PostgresConfig::default();\n        let mut changes = Vec::new();\n\n        merge_postgres(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(changes.len(), 0);\n        assert_eq!(base, PostgresConfig::default());\n    }\n\n    #[test]\n    fn test_merge_qdrant_no_changes() {\n        let mut base = QdrantConfig::default();\n        let override_config = QdrantConfig::default();\n        let mut changes = Vec::new();\n\n        merge_qdrant(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(changes.len(), 0);\n        assert_eq!(base, QdrantConfig::default());\n    }\n\n    #[test]\n    fn test_merge_redis_no_changes() {\n        let mut base = RedisConfig::default();\n        let override_config = RedisConfig::default();\n        let mut changes = Vec::new();\n\n        merge_redis(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(changes.len(), 0);\n        assert_eq!(base, RedisConfig::default());\n    }\n\n    #[test]\n    fn test_merge_sync_no_changes() {\n        let mut base = SyncConfig::default();\n        let override_config = SyncConfig::default();\n        let mut changes = Vec::new();\n\n        merge_sync(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(changes.len(), 0);\n        assert_eq!(base, SyncConfig::default());\n    }\n\n    #[test]\n    fn test_merge_tools_no_changes() {\n        let mut base = ToolConfig::default();\n        let override_config = ToolConfig::default();\n        let mut changes = Vec::new();\n\n        merge_tools(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(changes.len(), 0);\n        assert_eq!(base, ToolConfig::default());\n    }\n\n    #[test]\n    fn test_merge_observability_no_changes() {\n        let mut base = ObservabilityConfig::default();\n        let override_config = ObservabilityConfig::default();\n        let mut changes = Vec::new();\n\n        merge_observability(\u0026mut base, \u0026override_config, \"test\", \u0026mut changes);\n\n        assert_eq!(changes.len(), 0);\n        assert_eq!(base, ObservabilityConfig::default());\n    }\n}\n","traces":[{"line":41,"address":[],"length":0,"stats":{"Line":4}},{"line":50,"address":[],"length":0,"stats":{"Line":8}},{"line":52,"address":[],"length":0,"stats":{"Line":20}},{"line":53,"address":[],"length":0,"stats":{"Line":20}},{"line":55,"address":[],"length":0,"stats":{"Line":6}},{"line":56,"address":[],"length":0,"stats":{"Line":4}},{"line":59,"address":[],"length":0,"stats":{"Line":4}},{"line":62,"address":[],"length":0,"stats":{"Line":9}},{"line":63,"address":[],"length":0,"stats":{"Line":18}},{"line":65,"address":[],"length":0,"stats":{"Line":27}},{"line":67,"address":[],"length":0,"stats":{"Line":9}},{"line":68,"address":[],"length":0,"stats":{"Line":9}},{"line":69,"address":[],"length":0,"stats":{"Line":9}},{"line":70,"address":[],"length":0,"stats":{"Line":9}},{"line":72,"address":[],"length":0,"stats":{"Line":13}},{"line":73,"address":[],"length":0,"stats":{"Line":4}},{"line":76,"address":[],"length":0,"stats":{"Line":18}},{"line":77,"address":[],"length":0,"stats":{"Line":27}},{"line":79,"address":[],"length":0,"stats":{"Line":9}},{"line":80,"address":[],"length":0,"stats":{"Line":9}},{"line":81,"address":[],"length":0,"stats":{"Line":9}},{"line":82,"address":[],"length":0,"stats":{"Line":9}},{"line":84,"address":[],"length":0,"stats":{"Line":10}},{"line":85,"address":[],"length":0,"stats":{"Line":3}},{"line":86,"address":[],"length":0,"stats":{"Line":2}},{"line":89,"address":[],"length":0,"stats":{"Line":18}},{"line":90,"address":[],"length":0,"stats":{"Line":27}},{"line":92,"address":[],"length":0,"stats":{"Line":9}},{"line":93,"address":[],"length":0,"stats":{"Line":9}},{"line":94,"address":[],"length":0,"stats":{"Line":9}},{"line":95,"address":[],"length":0,"stats":{"Line":9}},{"line":97,"address":[],"length":0,"stats":{"Line":9}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":18}},{"line":103,"address":[],"length":0,"stats":{"Line":27}},{"line":105,"address":[],"length":0,"stats":{"Line":9}},{"line":106,"address":[],"length":0,"stats":{"Line":9}},{"line":107,"address":[],"length":0,"stats":{"Line":9}},{"line":108,"address":[],"length":0,"stats":{"Line":9}},{"line":110,"address":[],"length":0,"stats":{"Line":9}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":18}},{"line":116,"address":[],"length":0,"stats":{"Line":27}},{"line":118,"address":[],"length":0,"stats":{"Line":9}},{"line":119,"address":[],"length":0,"stats":{"Line":9}},{"line":120,"address":[],"length":0,"stats":{"Line":9}},{"line":121,"address":[],"length":0,"stats":{"Line":9}},{"line":123,"address":[],"length":0,"stats":{"Line":9}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":18}},{"line":129,"address":[],"length":0,"stats":{"Line":27}},{"line":131,"address":[],"length":0,"stats":{"Line":9}},{"line":132,"address":[],"length":0,"stats":{"Line":9}},{"line":133,"address":[],"length":0,"stats":{"Line":9}},{"line":134,"address":[],"length":0,"stats":{"Line":9}},{"line":136,"address":[],"length":0,"stats":{"Line":9}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":9}},{"line":142,"address":[],"length":0,"stats":{"Line":5}},{"line":145,"address":[],"length":0,"stats":{"Line":9}},{"line":148,"address":[],"length":0,"stats":{"Line":12}},{"line":154,"address":[],"length":0,"stats":{"Line":20}},{"line":155,"address":[],"length":0,"stats":{"Line":16}},{"line":156,"address":[],"length":0,"stats":{"Line":8}},{"line":157,"address":[],"length":0,"stats":{"Line":4}},{"line":159,"address":[],"length":0,"stats":{"Line":8}},{"line":161,"address":[],"length":0,"stats":{"Line":16}},{"line":162,"address":[],"length":0,"stats":{"Line":8}},{"line":163,"address":[],"length":0,"stats":{"Line":2}},{"line":164,"address":[],"length":0,"stats":{"Line":2}},{"line":166,"address":[],"length":0,"stats":{"Line":2}},{"line":168,"address":[],"length":0,"stats":{"Line":14}},{"line":169,"address":[],"length":0,"stats":{"Line":4}},{"line":170,"address":[],"length":0,"stats":{"Line":2}},{"line":171,"address":[],"length":0,"stats":{"Line":1}},{"line":173,"address":[],"length":0,"stats":{"Line":2}},{"line":175,"address":[],"length":0,"stats":{"Line":12}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":12}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":12}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":12}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":204,"address":[],"length":0,"stats":{"Line":11}},{"line":210,"address":[],"length":0,"stats":{"Line":15}},{"line":211,"address":[],"length":0,"stats":{"Line":10}},{"line":212,"address":[],"length":0,"stats":{"Line":4}},{"line":214,"address":[],"length":0,"stats":{"Line":13}},{"line":215,"address":[],"length":0,"stats":{"Line":4}},{"line":216,"address":[],"length":0,"stats":{"Line":1}},{"line":218,"address":[],"length":0,"stats":{"Line":11}},{"line":219,"address":[],"length":0,"stats":{"Line":1}},{"line":221,"address":[],"length":0,"stats":{"Line":4}},{"line":222,"address":[],"length":0,"stats":{"Line":2}},{"line":223,"address":[],"length":0,"stats":{"Line":1}},{"line":225,"address":[],"length":0,"stats":{"Line":2}},{"line":227,"address":[],"length":0,"stats":{"Line":11}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":231,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":11}},{"line":244,"address":[],"length":0,"stats":{"Line":13}},{"line":245,"address":[],"length":0,"stats":{"Line":5}},{"line":246,"address":[],"length":0,"stats":{"Line":2}},{"line":248,"address":[],"length":0,"stats":{"Line":13}},{"line":249,"address":[],"length":0,"stats":{"Line":4}},{"line":250,"address":[],"length":0,"stats":{"Line":1}},{"line":252,"address":[],"length":0,"stats":{"Line":13}},{"line":253,"address":[],"length":0,"stats":{"Line":4}},{"line":254,"address":[],"length":0,"stats":{"Line":1}},{"line":256,"address":[],"length":0,"stats":{"Line":11}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":11}},{"line":264,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":0}},{"line":270,"address":[],"length":0,"stats":{"Line":0}},{"line":274,"address":[],"length":0,"stats":{"Line":11}},{"line":280,"address":[],"length":0,"stats":{"Line":12}},{"line":281,"address":[],"length":0,"stats":{"Line":4}},{"line":282,"address":[],"length":0,"stats":{"Line":1}},{"line":284,"address":[],"length":0,"stats":{"Line":11}},{"line":285,"address":[],"length":0,"stats":{"Line":1}},{"line":287,"address":[],"length":0,"stats":{"Line":4}},{"line":288,"address":[],"length":0,"stats":{"Line":1}},{"line":289,"address":[],"length":0,"stats":{"Line":1}},{"line":291,"address":[],"length":0,"stats":{"Line":1}},{"line":293,"address":[],"length":0,"stats":{"Line":11}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":11}},{"line":298,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":11}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":13}},{"line":322,"address":[],"length":0,"stats":{"Line":13}},{"line":323,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":13}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":13}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":334,"address":[],"length":0,"stats":{"Line":13}},{"line":335,"address":[],"length":0,"stats":{"Line":4}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":337,"address":[],"length":0,"stats":{"Line":4}},{"line":338,"address":[],"length":0,"stats":{"Line":4}},{"line":339,"address":[],"length":0,"stats":{"Line":4}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":343,"address":[],"length":0,"stats":{"Line":6}},{"line":345,"address":[],"length":0,"stats":{"Line":13}},{"line":346,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":0}},{"line":350,"address":[],"length":0,"stats":{"Line":0}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":11}},{"line":362,"address":[],"length":0,"stats":{"Line":12}},{"line":363,"address":[],"length":0,"stats":{"Line":4}},{"line":364,"address":[],"length":0,"stats":{"Line":1}},{"line":365,"address":[],"length":0,"stats":{"Line":1}},{"line":367,"address":[],"length":0,"stats":{"Line":1}},{"line":369,"address":[],"length":0,"stats":{"Line":12}},{"line":370,"address":[],"length":0,"stats":{"Line":4}},{"line":371,"address":[],"length":0,"stats":{"Line":1}},{"line":372,"address":[],"length":0,"stats":{"Line":1}},{"line":374,"address":[],"length":0,"stats":{"Line":1}},{"line":376,"address":[],"length":0,"stats":{"Line":11}},{"line":377,"address":[],"length":0,"stats":{"Line":1}},{"line":379,"address":[],"length":0,"stats":{"Line":4}},{"line":380,"address":[],"length":0,"stats":{"Line":2}},{"line":381,"address":[],"length":0,"stats":{"Line":1}},{"line":383,"address":[],"length":0,"stats":{"Line":2}},{"line":384,"address":[],"length":0,"stats":{"Line":1}},{"line":386,"address":[],"length":0,"stats":{"Line":13}},{"line":387,"address":[],"length":0,"stats":{"Line":4}},{"line":388,"address":[],"length":0,"stats":{"Line":1}},{"line":389,"address":[],"length":0,"stats":{"Line":1}},{"line":391,"address":[],"length":0,"stats":{"Line":1}}],"covered":149,"coverable":211},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","procedural.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","providers.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","qdrant.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","redis.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","repository.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","state.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","tools.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","validator.rs"],"content":"//! # Configuration Validation\n//!\n//! Provides validation for all configuration structures using the `validator` crate.\n\nuse crate::config::{\n    Config, ObservabilityConfig, PostgresConfig, ProviderConfig, QdrantConfig, RedisConfig,\n    SyncConfig, ToolConfig,\n};\nuse validator::Validate;\n\n/// Validate configuration structure.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Validates all configuration fields using the `validator` crate.\n/// Ensures all required fields are present and within valid ranges.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use memory_knowledge_config::{Config, validate};\n///\n/// let config = Config::default();\n/// match validate(\u0026config) {\n///     Ok(()) =\u003e println!(\"Configuration is valid\"),\n///     Err(errors) =\u003e println!(\"Validation errors: {:?}\", errors),\n/// }\n/// ```\n///\n/// ## Validation Rules\n/// ### General\n/// - All string fields: minimum length 1, maximum length varies\n///\n/// ### PostgreSQL\n/// - `host`: 1-255 characters\n/// - `port`: 1-65535\n/// - `database`: 1-63 characters\n/// - `username`: 1-63 characters\n/// - `password`: 1+ characters\n/// - `pool_size`: 1-100\n/// - `timeout_seconds`: 1-300\n///\n/// ### Qdrant\n/// - `host`: 1-255 characters\n/// - `port`: 1-65535\n/// - `collection`: 1-255 characters\n/// - `timeout_seconds`: 1-300\n///\n/// ### Redis\n/// - `host`: 1-255 characters\n/// - `port`: 1-65535\n/// - `db`: 0-15\n/// - `pool_size`: 1-100\n/// - `timeout_seconds`: 1-300\n///\n/// ### Sync\n/// - `sync_interval_seconds`: 10-3600\n/// - `batch_size`: 1-1000\n/// - `conflict_resolution`: must be \"prefer_knowledge\", \"prefer_memory\", or \"manual\"\n///\n/// ### Tools\n/// - `host`: 1-255 characters\n/// - `port`: 1-65535\n/// - `rate_limit_requests_per_minute`: 1-1000\n///\n/// ### Observability\n/// - `logging_level`: must be \"trace\", \"debug\", \"info\", \"warn\", or \"error\"\n/// - `metrics_port`: 1-65535\npub fn validate(config: \u0026Config) -\u003e Result\u003c(), validator::ValidationErrors\u003e {\n    config.validate()\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_validate_valid_config() {\n        let config = Config::default();\n        assert!(validate(\u0026config).is_ok());\n    }\n\n    #[test]\n    fn test_validate_invalid_postgres_host() {\n        let mut config = Config::default();\n        config.providers.postgres.host = \"\".to_string();\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_invalid_postgres_port() {\n        let mut config = Config::default();\n        config.providers.postgres.port = 0;\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_invalid_qdrant_port() {\n        let mut config = Config::default();\n        config.providers.qdrant.port = 0;\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_invalid_redis_db() {\n        let mut config = Config::default();\n        config.providers.redis.db = 16;\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_invalid_sync_interval() {\n        let mut config = Config::default();\n        config.sync.sync_interval_seconds = 5;\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_invalid_sync_interval_high() {\n        let mut config = Config::default();\n        config.sync.sync_interval_seconds = 4000;\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_invalid_batch_size() {\n        let mut config = Config::default();\n        config.sync.batch_size = 0;\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_invalid_conflict_resolution() {\n        let mut config = Config::default();\n        config.sync.conflict_resolution = \"invalid\".to_string();\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_valid_conflict_resolution() {\n        let mut config = Config::default();\n        config.sync.conflict_resolution = \"prefer_memory\".to_string();\n        assert!(validate(\u0026config).is_ok());\n    }\n\n    #[test]\n    fn test_validate_invalid_logging_level() {\n        let mut config = Config::default();\n        config.observability.logging_level = \"invalid\".to_string();\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_valid_logging_levels() {\n        for level in [\"trace\", \"debug\", \"info\", \"warn\", \"error\"] {\n            let mut config = Config::default();\n            config.observability.logging_level = level.to_string();\n            assert!(validate(\u0026config).is_ok());\n        }\n    }\n\n    #[test]\n    fn test_validate_invalid_tools_rate_limit() {\n        let mut config = Config::default();\n        config.tools.rate_limit_requests_per_minute = 0;\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_postgres_pool_size_out_of_range() {\n        let mut config = Config::default();\n        config.providers.postgres.pool_size = 101;\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_postgres_timeout_out_of_range() {\n        let mut config = Config::default();\n        config.providers.postgres.timeout_seconds = 301;\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_qdrant_collection_empty() {\n        let mut config = Config::default();\n        config.providers.qdrant.collection = \"\".to_string();\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_redis_host_empty() {\n        let mut config = Config::default();\n        config.providers.redis.host = \"\".to_string();\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_tools_port_zero() {\n        let mut config = Config::default();\n        config.tools.port = 0;\n        assert!(validate(\u0026config).is_err());\n    }\n\n    #[test]\n    fn test_validate_observability_metrics_port_zero() {\n        let mut config = Config::default();\n        config.observability.metrics_port = 0;\n        assert!(validate(\u0026config).is_err());\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","config","src","working.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","errors","src","lib.rs"],"content":"//! # Memory-Knowledge Errors\n//!\n//! Comprehensive error handling for Memory-Knowledge system.\n//!\n//! Follows Microsoft Pragmatic Rust Guidelines:\n//! - Uses `thiserror` for structured error definitions\n//! - Provides `Display` and `Error` trait implementations\n//! - Includes error context for debugging\n\nuse thiserror::Error;\n\n/// Memory-specific errors\n#[derive(Debug, Error)]\npub enum MemoryError {\n    // FIX: Use named field {layer} instead of positional {0}\n    #[error(\"Invalid memory layer: {layer}\")]\n    InvalidLayer { layer: String },\n\n    // FIX: Use named field {identifier} instead of positional {0}\n    #[error(\"Missing required identifier: {identifier}\")]\n    MissingIdentifier { identifier: String },\n\n    // FIX: Use named field {id} instead of positional {0}\n    #[error(\"Memory not found: {id}\")]\n    MemoryNotFound { id: String },\n\n    // FIX: Use named fields {length} and {max} instead of positional {0} and {1}\n    #[error(\"Content too long: {length} characters max {max}\")]\n    ContentTooLong { length: usize, max: usize },\n\n    // FIX: Use named fields {length} and {max} instead of positional {0} and {1}\n    #[error(\"Query too long: {length} characters max {max}\")]\n    QueryTooLong { length: usize, max: usize },\n\n    // FIX: Use named field {reason} instead of positional {0}\n    #[error(\"Embedding generation failed: {reason}\")]\n    EmbeddingFailed { reason: String },\n\n    // FIX: Use named fields {source_name} and {reason} to match the struct\n    #[error(\"Provider error: {source_name} - {reason}\")]\n    ProviderError { source_name: String, reason: String },\n\n    // FIX: Use named field {retry_after} instead of positional {0}\n    #[error(\"Rate limited: retry after {retry_after}s\")]\n    RateLimited { retry_after: u64 },\n\n    // FIX: Use named field {reason} instead of positional {0}\n    #[error(\"Unauthorized access: {reason}\")]\n    Unauthorized { reason: String },\n\n    // FIX: Use named field {message} instead of positional {0}\n    #[error(\"Configuration error: {message}\")]\n    ConfigurationError { message: String }\n}\n\n/// Knowledge repository errors\n#[derive(Debug, Error)]\npub enum KnowledgeError {\n    // FIX: Use named field {id} instead of positional {0}\n    #[error(\"Knowledge item not found: {id}\")]\n    ItemNotFound { id: String },\n\n    // FIX: Use named field {type_} instead of positional {0}\n    #[error(\"Invalid knowledge type: {type_}\")]\n    InvalidType { type_: String },\n\n    // FIX: Use named field {layer} instead of positional {0}\n    #[error(\"Invalid knowledge layer: {layer}\")]\n    InvalidLayer { layer: String },\n\n    // FIX: Use named fields {from} and {to} instead of positional {0} and {1}\n    #[error(\"Invalid status transition: {from} to {to}\")]\n    InvalidStatusTransition { from: String, to: String },\n\n    // FIX: Use named fields {operation} and {reason} instead of positional {0} and {1}\n    #[error(\"Git operation: {operation} failed: {reason}\")]\n    GitError { operation: String, reason: String },\n\n    // FIX: Use named field {reason} instead of positional {0}\n    #[error(\"Manifest corrupted: {reason}\")]\n    ManifestCorrupted { reason: String },\n\n    // FIX: Use named field {constraint_id} instead of positional {0}\n    #[error(\"Constraint violation: {constraint_id}\")]\n    ConstraintViolation { constraint_id: String }\n}\n\n/// Sync bridge errors\n#[derive(Debug, Error)]\npub enum SyncError {\n    // FIX: Use named field {reason} instead of positional {0}\n    #[error(\"Knowledge unavailable: {reason}\")]\n    KnowledgeUnavailable { reason: String },\n\n    // FIX: Use named field {reason} instead of positional {0}\n    #[error(\"Memory unavailable: {reason}\")]\n    MemoryUnavailable { reason: String },\n\n    // FIX: Use named field {reason} instead of positional {0}\n    #[error(\"State corrupted: {reason}\")]\n    StateCorrupted { reason: String },\n\n    // FIX: Use named field {checkpoint_id} instead of positional {0}\n    #[error(\"Checkpoint failed: {checkpoint_id}\")]\n    CheckpointFailed { checkpoint_id: String },\n\n    // FIX: Use named fields {checkpoint_id} and {reason} instead of positional {0} and {1}\n    #[error(\"Rollback of {checkpoint_id} failed: {reason}\")]\n    RollbackFailed {\n        checkpoint_id: String,\n        reason: String\n    },\n\n    // FIX: Use named field {conflict_id} instead of positional {0}\n    #[error(\"Conflict unresolvable: {conflict_id}\")]\n    ConflictUnresolvable { conflict_id: String },\n\n    // FIX: Use named field {failed_items} instead of positional {0}\n    #[error(\"Partial failure: {failed_items:?} items failed\")]\n    PartialFailure { failed_items: Vec\u003cString\u003e }\n}\n\n/// Tool interface errors\n#[derive(Debug, Error)]\npub enum ToolError {\n    // FIX: Use named fields {field} and {reason} instead of positional {0}\n    #[error(\"Invalid input: {field} reason: {reason}\")]\n    InvalidInput { field: String, reason: String },\n\n    // FIX: Use named fields {resource} and {id} instead of positional {0} and {1}\n    #[error(\"Resource not found: {resource}:{id}\")]\n    NotFound { resource: String, id: String },\n\n    // FIX: Use named fields {source_name} and {reason} to match the struct\n    #[error(\"Provider error: {source_name} - {reason}\")]\n    ProviderError { source_name: String, reason: String },\n\n    // FIX: Use named field {retry_after} instead of positional {0}\n    #[error(\"Rate limited: retry after {retry_after}s\")]\n    RateLimited { retry_after: u64 },\n\n    // FIX: Use named field {reason} instead of positional {0}\n    #[error(\"Unauthorized access: {reason}\")]\n    Unauthorized { reason: String },\n\n    // FIX: Use named field {timeout_ms} instead of positional {0}\n    #[error(\"Timeout: operation took longer than {timeout_ms}ms\")]\n    Timeout { timeout_ms: u64 },\n\n    // FIX: Use named fields {conflict_id} and {details} instead of positional {0} and {1}\n    #[error(\"Conflict: {conflict_id}: {details}\")]\n    Conflict {\n        conflict_id: String,\n        details: String\n    }\n}\n\n/// Storage layer errors\n#[derive(Debug, Error)]\npub enum StorageError {\n    // FIX: Use named fields {backend} and {reason} instead of positional {0} and {1}\n    #[error(\"Connection to {backend} failed: {reason}\")]\n    ConnectionError { backend: String, reason: String },\n\n    // FIX: Use named fields {backend} and {reason} instead of positional {0} and {1}\n    #[error(\"Query on {backend} failed: {reason}\")]\n    QueryError { backend: String, reason: String },\n\n    // FIX: Use named fields {error_type} and {reason} instead of positional {0} and {1}\n    #[error(\"Serialization error: {error_type} - {reason}\")]\n    SerializationError { error_type: String, reason: String },\n\n    // FIX: Use named fields {backend} and {id} instead of positional {0} and {1}\n    #[error(\"Not found on {backend}:{id}\")]\n    NotFound { backend: String, id: String },\n\n    // FIX: Use named fields {backend} and {reason} instead of positional {0} and {1}\n    #[error(\"Transaction on {backend} failed: {reason}\")]\n    TransactionError { backend: String, reason: String }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","expanded_qdrant.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","api.rs"],"content":"use crate::governance::GovernanceEngine;\nuse crate::governance_client::{GovernanceClient, RemoteGovernanceClient};\nuse config::config::DeploymentConfig;\nuse mk_core::traits::StorageBackend;\nuse mk_core::types::{DriftResult, GovernanceEvent, KnowledgeLayer, TenantContext};\nuse std::sync::Arc;\nuse storage::postgres::PostgresBackend;\nuse utoipa::OpenApi;\n\n#[derive(OpenApi)]\n#[openapi(\n    paths(\n        get_drift_status,\n        get_org_report,\n        approve_proposal,\n        reject_proposal,\n        get_job_status,\n        replay_events\n    ),\n    components(\n        schemas(mk_core::types::DriftResult, mk_core::types::PolicyViolation, mk_core::types::GovernanceEvent)\n    ),\n    tags(\n        (name = \"governance\", description = \"Governance Dashboard API\")\n    )\n)]\npub struct GovernanceApiDoc;\n\npub struct GovernanceDashboardApi {\n    engine: Arc\u003cGovernanceEngine\u003e,\n    storage: Arc\u003cPostgresBackend\u003e,\n    governance_client: Option\u003cArc\u003cdyn GovernanceClient\u003e\u003e,\n    deployment_config: DeploymentConfig\n}\n\n#[utoipa::path(\n    get,\n    path = \"/api/v1/governance/drift/{project_id}\",\n    responses(\n        (status = 200, description = \"Drift status fetched successfully\", body = Option\u003cDriftResult\u003e),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"project_id\" = String, Path, description = \"Project ID\")\n    ),\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn get_drift_status(\n    api: Arc\u003cGovernanceDashboardApi\u003e,\n    ctx: \u0026TenantContext,\n    project_id: \u0026str\n) -\u003e anyhow::Result\u003cOption\u003cDriftResult\u003e\u003e {\n    if api.deployment_config.mode == \"remote\" {\n        if let Some(client) = \u0026api.governance_client {\n            return client\n                .get_drift_status(ctx, project_id)\n                .await\n                .map_err(|e| anyhow::anyhow!(\"Remote drift status failed: {}\", e));\n        }\n    }\n\n    let result =\n        StorageBackend::get_latest_drift_result(api.storage.as_ref(), ctx.clone(), project_id)\n            .await\n            .map_err(|e| anyhow::anyhow!(\"Failed to fetch drift result: {:?}\", e))?;\n\n    Ok(result)\n}\n\n#[utoipa::path(\n    get,\n    path = \"/api/v1/governance/reports/{org_id}\",\n    responses(\n        (status = 200, description = \"Organization report fetched successfully\", body = serde_json::Value),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"org_id\" = String, Path, description = \"Organization ID\")\n    ),\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn get_org_report(\n    api: Arc\u003cGovernanceDashboardApi\u003e,\n    ctx: \u0026TenantContext,\n    org_id: \u0026str\n) -\u003e anyhow::Result\u003cserde_json::Value\u003e {\n    let descendants = StorageBackend::get_descendants(api.storage.as_ref(), ctx.clone(), org_id)\n        .await\n        .map_err(|e| anyhow::anyhow!(\"Failed to fetch descendants: {:?}\", e))?;\n\n    let mut project_drifts = Vec::new();\n    for unit in descendants {\n        if unit.unit_type == mk_core::types::UnitType::Project {\n            if let Some(drift) = get_drift_status(api.clone(), ctx, \u0026unit.id).await? {\n                project_drifts.push(drift);\n            }\n        }\n    }\n\n    let avg_drift = if project_drifts.is_empty() {\n        0.0\n    } else {\n        project_drifts.iter().map(|d| d.drift_score).sum::\u003cf32\u003e() / project_drifts.len() as f32\n    };\n\n    Ok(serde_json::json!({\n        \"orgId\": org_id,\n        \"averageDrift\": avg_drift,\n        \"projectCount\": project_drifts.len(),\n        \"projects\": project_drifts,\n        \"timestamp\": chrono::Utc::now().timestamp()\n    }))\n}\n\n#[utoipa::path(\n    post,\n    path = \"/api/v1/governance/proposals/{proposal_id}/approve\",\n    responses(\n        (status = 200, description = \"Proposal approved successfully\"),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 404, description = \"Proposal not found\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"proposal_id\" = String, Path, description = \"Proposal ID\")\n    ),\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn approve_proposal(\n    api: Arc\u003cGovernanceDashboardApi\u003e,\n    ctx: \u0026TenantContext,\n    proposal_id: \u0026str\n) -\u003e anyhow::Result\u003c()\u003e {\n    let repo = api\n        .engine\n        .repository()\n        .ok_or_else(|| anyhow::anyhow!(\"Repository not configured\"))?;\n\n    let entry = repo\n        .get(\n            ctx.clone(),\n            mk_core::types::KnowledgeLayer::Project,\n            proposal_id\n        )\n        .await\n        .map_err(|e| anyhow::anyhow!(\"Failed to fetch proposal: {:?}\", e))?\n        .ok_or_else(|| anyhow::anyhow!(\"Proposal not found\"))?;\n\n    let mut accepted_entry = entry.clone();\n    accepted_entry.status = mk_core::types::KnowledgeStatus::Accepted;\n\n    repo.store(ctx.clone(), accepted_entry, \"Proposal approved\")\n        .await\n        .map_err(|e| anyhow::anyhow!(\"Failed to approve proposal: {:?}\", e))?;\n\n    Ok(())\n}\n\n#[utoipa::path(\n    post,\n    path = \"/api/v1/governance/proposals/{proposal_id}/reject\",\n    responses(\n        (status = 200, description = \"Proposal rejected successfully\"),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 404, description = \"Proposal not found\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"proposal_id\" = String, Path, description = \"Proposal ID\"),\n        (\"reason\" = String, Query, description = \"Rejection reason\")\n    ),\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn reject_proposal(\n    api: Arc\u003cGovernanceDashboardApi\u003e,\n    ctx: \u0026TenantContext,\n    proposal_id: \u0026str,\n    reason: \u0026str\n) -\u003e anyhow::Result\u003c()\u003e {\n    let repo = api\n        .engine\n        .repository()\n        .ok_or_else(|| anyhow::anyhow!(\"Repository not configured\"))?;\n\n    let entry = repo\n        .get(\n            ctx.clone(),\n            mk_core::types::KnowledgeLayer::Project,\n            proposal_id\n        )\n        .await\n        .map_err(|e| anyhow::anyhow!(\"Failed to fetch proposal: {:?}\", e))?\n        .ok_or_else(|| anyhow::anyhow!(\"Proposal not found\"))?;\n\n    let mut rejected_entry = entry.clone();\n    rejected_entry.status = mk_core::types::KnowledgeStatus::Draft;\n    rejected_entry\n        .metadata\n        .insert(\"rejection_reason\".to_string(), serde_json::json!(reason));\n\n    repo.store(\n        ctx.clone(),\n        rejected_entry,\n        \u0026format!(\"Proposal rejected: {}\", reason)\n    )\n    .await\n    .map_err(|e| anyhow::anyhow!(\"Failed to reject proposal: {:?}\", e))?;\n\n    Ok(())\n}\n\n#[utoipa::path(\n    get,\n    path = \"/api/v1/governance/jobs\",\n    responses(\n        (status = 200, description = \"Job status fetched successfully\", body = serde_json::Value),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"job_name\" = Option\u003cString\u003e, Query, description = \"Filter by job name\")\n    ),\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn get_job_status(\n    api: Arc\u003cGovernanceDashboardApi\u003e,\n    ctx: \u0026TenantContext,\n    job_name: Option\u003c\u0026str\u003e\n) -\u003e anyhow::Result\u003cserde_json::Value\u003e {\n    let rows = sqlx::query(\n        \"SELECT id, job_name, status, message, started_at, finished_at, duration_ms \n         FROM job_status \n         WHERE tenant_id = $1 OR tenant_id = 'all' \n         ORDER BY started_at DESC LIMIT 50\"\n    )\n    .bind(ctx.tenant_id.as_str())\n    .fetch_all(api.storage.pool())\n    .await\n    .map_err(|e| anyhow::anyhow!(\"Failed to fetch job status: {:?}\", e))?;\n\n    let mut jobs = Vec::new();\n    for row in rows {\n        use sqlx::Row;\n        let name: String = row.get(\"job_name\");\n        if let Some(filter) = job_name {\n            if name != filter {\n                continue;\n            }\n        }\n\n        jobs.push(serde_json::json!({\n            \"id\": row.get::\u003cuuid::Uuid, _\u003e(\"id\"),\n            \"jobName\": name,\n            \"status\": row.get::\u003cString, _\u003e(\"status\"),\n            \"message\": row.get::\u003cOption\u003cString\u003e, _\u003e(\"message\"),\n            \"startedAt\": row.get::\u003ci64, _\u003e(\"started_at\"),\n            \"finishedAt\": row.get::\u003cOption\u003ci64\u003e, _\u003e(\"finished_at\"),\n            \"durationMs\": row.get::\u003cOption\u003ci64\u003e, _\u003e(\"duration_ms\"),\n        }));\n    }\n\n    Ok(serde_json::json!(jobs))\n}\n\n#[utoipa::path(\n    get,\n    path = \"/api/v1/governance/events/replay\",\n    responses(\n        (status = 200, description = \"Events replayed successfully\", body = Vec\u003cGovernanceEvent\u003e),\n        (status = 401, description = \"Unauthorized\"),\n        (status = 500, description = \"Internal server error\")\n    ),\n    params(\n        (\"since_timestamp\" = i64, Query, description = \"Replay events after this timestamp\"),\n        (\"limit\" = usize, Query, description = \"Maximum number of events to return\")\n    ),\n    security(\n        (\"tenant_auth\" = [])\n    )\n)]\npub async fn replay_events(\n    api: Arc\u003cGovernanceDashboardApi\u003e,\n    ctx: \u0026TenantContext,\n    since_timestamp: i64,\n    limit: usize\n) -\u003e anyhow::Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e\u003e {\n    if api.deployment_config.mode == \"remote\" {\n        if let Some(client) = \u0026api.governance_client {\n            return client\n                .replay_events(ctx, since_timestamp, limit)\n                .await\n                .map_err(|e| anyhow::anyhow!(\"Remote replay events failed: {}\", e));\n        }\n    }\n\n    let events = StorageBackend::get_governance_events(\n        api.storage.as_ref(),\n        ctx.clone(),\n        since_timestamp,\n        limit\n    )\n    .await\n    .map_err(|e| anyhow::anyhow!(\"Failed to replay governance events: {:?}\", e))?;\n\n    Ok(events)\n}\n\nimpl GovernanceDashboardApi {\n    pub fn new(\n        engine: Arc\u003cGovernanceEngine\u003e,\n        storage: Arc\u003cPostgresBackend\u003e,\n        deployment_config: DeploymentConfig\n    ) -\u003e Self {\n        let governance_client = if deployment_config.mode == \"remote\" {\n            deployment_config.remote_url.as_ref().map(|url: \u0026String| {\n                Arc::new(RemoteGovernanceClient::new(url.clone())) as Arc\u003cdyn GovernanceClient\u003e\n            })\n        } else {\n            None\n        };\n\n        Self {\n            engine,\n            storage,\n            governance_client,\n            deployment_config\n        }\n    }\n\n    pub async fn list_proposals(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        layer: Option\u003cKnowledgeLayer\u003e\n    ) -\u003e anyhow::Result\u003cVec\u003cmk_core::types::KnowledgeEntry\u003e\u003e {\n        if self.deployment_config.mode == \"remote\" {\n            if let Some(client) = \u0026self.governance_client {\n                return client\n                    .list_proposals(ctx, layer)\n                    .await\n                    .map_err(|e| anyhow::anyhow!(\"Remote list proposals failed: {}\", e));\n            }\n        }\n\n        let repo = self\n            .engine\n            .repository()\n            .ok_or_else(|| anyhow::anyhow!(\"Repository not configured\"))?;\n\n        let layers = if let Some(l) = layer {\n            vec![l]\n        } else {\n            vec![\n                KnowledgeLayer::Project,\n                KnowledgeLayer::Team,\n                KnowledgeLayer::Org,\n                KnowledgeLayer::Company,\n            ]\n        };\n\n        let mut proposals = Vec::new();\n        for l in layers {\n            let entries: Vec\u003cmk_core::types::KnowledgeEntry\u003e = repo\n                .list(ctx.clone(), l, \"\")\n                .await\n                .map_err(|e| anyhow::anyhow!(\"Failed to list entries in layer {:?}: {:?}\", l, e))?;\n\n            for entry in entries {\n                if entry.status == mk_core::types::KnowledgeStatus::Proposed {\n                    proposals.push(entry);\n                }\n            }\n        }\n\n        Ok(proposals)\n    }\n}\n","traces":[{"line":51,"address":[],"length":0,"stats":{"Line":1}},{"line":56,"address":[],"length":0,"stats":{"Line":1}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":1}},{"line":66,"address":[],"length":0,"stats":{"Line":5}},{"line":67,"address":[],"length":0,"stats":{"Line":1}},{"line":68,"address":[],"length":0,"stats":{"Line":1}},{"line":70,"address":[],"length":0,"stats":{"Line":1}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":201,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":205,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":207,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":1}},{"line":248,"address":[],"length":0,"stats":{"Line":4}},{"line":249,"address":[],"length":0,"stats":{"Line":2}},{"line":250,"address":[],"length":0,"stats":{"Line":1}},{"line":251,"address":[],"length":0,"stats":{"Line":1}},{"line":253,"address":[],"length":0,"stats":{"Line":2}},{"line":254,"address":[],"length":0,"stats":{"Line":3}},{"line":256,"address":[],"length":0,"stats":{"Line":4}},{"line":257,"address":[],"length":0,"stats":{"Line":2}},{"line":258,"address":[],"length":0,"stats":{"Line":1}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":3}},{"line":264,"address":[],"length":0,"stats":{"Line":3}},{"line":265,"address":[],"length":0,"stats":{"Line":1}},{"line":266,"address":[],"length":0,"stats":{"Line":3}},{"line":267,"address":[],"length":0,"stats":{"Line":3}},{"line":268,"address":[],"length":0,"stats":{"Line":3}},{"line":269,"address":[],"length":0,"stats":{"Line":3}},{"line":270,"address":[],"length":0,"stats":{"Line":3}},{"line":274,"address":[],"length":0,"stats":{"Line":1}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":321,"address":[],"length":0,"stats":{"Line":1}},{"line":326,"address":[],"length":0,"stats":{"Line":2}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":331,"address":[],"length":0,"stats":{"Line":1}},{"line":342,"address":[],"length":0,"stats":{"Line":0}},{"line":347,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":0}},{"line":350,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":359,"address":[],"length":0,"stats":{"Line":0}},{"line":361,"address":[],"length":0,"stats":{"Line":0}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":364,"address":[],"length":0,"stats":{"Line":0}},{"line":365,"address":[],"length":0,"stats":{"Line":0}},{"line":366,"address":[],"length":0,"stats":{"Line":0}},{"line":367,"address":[],"length":0,"stats":{"Line":0}},{"line":368,"address":[],"length":0,"stats":{"Line":0}},{"line":372,"address":[],"length":0,"stats":{"Line":0}},{"line":373,"address":[],"length":0,"stats":{"Line":0}},{"line":374,"address":[],"length":0,"stats":{"Line":0}},{"line":375,"address":[],"length":0,"stats":{"Line":0}},{"line":376,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":379,"address":[],"length":0,"stats":{"Line":0}},{"line":380,"address":[],"length":0,"stats":{"Line":0}},{"line":381,"address":[],"length":0,"stats":{"Line":0}},{"line":386,"address":[],"length":0,"stats":{"Line":0}}],"covered":29,"coverable":136},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","backend.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","bridge.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","config.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","ecosystem.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","episodic.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","federation.rs"],"content":"use crate::repository::RepositoryError;\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct UpstreamConfig {\n    pub id: String,\n    pub url: String,\n    pub branch: String,\n    pub auth_token: Option\u003cString\u003e\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct FederationConfig {\n    pub upstreams: Vec\u003cUpstreamConfig\u003e,\n    pub sync_interval_secs: u64\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct KnowledgeManifest {\n    pub version: String,\n    pub items: HashMap\u003cString, String\u003e\n}\n\n#[async_trait::async_trait]\npub trait FederationProvider: Send + Sync {\n    fn config(\u0026self) -\u003e \u0026FederationConfig;\n    async fn fetch_upstream_manifest(\n        \u0026self,\n        upstream_id: \u0026str\n    ) -\u003e Result\u003cKnowledgeManifest, RepositoryError\u003e;\n    async fn sync_upstream(\n        \u0026self,\n        upstream_id: \u0026str,\n        target_path: \u0026std::path::Path\n    ) -\u003e Result\u003c(), RepositoryError\u003e;\n}\n\npub struct FederationManager {\n    config: FederationConfig\n}\n\n#[async_trait::async_trait]\nimpl FederationProvider for FederationManager {\n    fn config(\u0026self) -\u003e \u0026FederationConfig {\n        \u0026self.config\n    }\n\n    async fn fetch_upstream_manifest(\n        \u0026self,\n        upstream_id: \u0026str\n    ) -\u003e Result\u003cKnowledgeManifest, RepositoryError\u003e {\n        let _upstream = self\n            .config\n            .upstreams\n            .iter()\n            .find(|u| u.id == upstream_id)\n            .ok_or_else(|| {\n                RepositoryError::InvalidPath(format!(\"Upstream not found: {}\", upstream_id))\n            })?;\n\n        Ok(KnowledgeManifest {\n            version: \"1.0\".to_string(),\n            items: HashMap::new()\n        })\n    }\n\n    async fn sync_upstream(\n        \u0026self,\n        upstream_id: \u0026str,\n        target_path: \u0026std::path::Path\n    ) -\u003e Result\u003c(), RepositoryError\u003e {\n        let upstream = self\n            .config\n            .upstreams\n            .iter()\n            .find(|u| u.id == upstream_id)\n            .ok_or_else(|| {\n                RepositoryError::InvalidPath(format!(\"Upstream not found: {}\", upstream_id))\n            })?;\n\n        if target_path.exists() {\n            let repo = git2::Repository::open(target_path)?;\n            let mut remote = repo.find_remote(\"origin\")?;\n            remote.fetch(\u0026[\u0026upstream.branch], None, None)?;\n\n            let head = repo.head()?.peel_to_commit()?;\n            let remote_ref =\n                repo.find_reference(\u0026format!(\"refs/remotes/origin/{}\", upstream.branch))?;\n            let remote_commit = remote_ref.peel_to_commit()?;\n\n            if repo.merge_base(head.id(), remote_commit.id())? != remote_commit.id() {\n                return Err(RepositoryError::InvalidPath(\n                    \"Local changes conflict with upstream\".to_string()\n                ));\n            }\n        } else {\n            git2::Repository::clone(\u0026upstream.url, target_path)?;\n        }\n\n        Ok(())\n    }\n}\n\nimpl FederationManager {\n    pub fn new(config: FederationConfig) -\u003e Self {\n        Self { config }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_federation_config_serialization() {\n        let config = FederationConfig {\n            upstreams: vec![UpstreamConfig {\n                id: \"test\".to_string(),\n                url: \"https://github.com/test/repo\".to_string(),\n                branch: \"main\".to_string(),\n                auth_token: Some(\"secret\".to_string())\n            }],\n            sync_interval_secs: 3600\n        };\n\n        let json = serde_json::to_string(\u0026config).unwrap();\n        let decoded: FederationConfig = serde_json::from_str(\u0026json).unwrap();\n\n        assert_eq!(decoded.upstreams.len(), 1);\n        assert_eq!(decoded.upstreams[0].id, \"test\");\n        assert_eq!(decoded.sync_interval_secs, 3600);\n    }\n\n    #[tokio::test]\n    async fn test_fetch_upstream_manifest_not_found() {\n        let manager = FederationManager::new(FederationConfig {\n            upstreams: vec![],\n            sync_interval_secs: 60\n        });\n\n        let result = manager.fetch_upstream_manifest(\"nonexistent\").await;\n        assert!(result.is_err());\n        match result {\n            Err(RepositoryError::InvalidPath(msg)) =\u003e assert!(msg.contains(\"Upstream not found\")),\n            _ =\u003e panic!(\"Expected InvalidPath error\")\n        }\n    }\n\n    #[tokio::test]\n    async fn test_sync_upstream_not_found() {\n        let manager = FederationManager::new(FederationConfig {\n            upstreams: vec![],\n            sync_interval_secs: 60\n        });\n\n        let result = manager\n            .sync_upstream(\"nonexistent\", std::path::Path::new(\"/tmp\"))\n            .await;\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_knowledge_manifest_serialization() {\n        let mut items = HashMap::new();\n        items.insert(\"key1\".to_string(), \"hash1\".to_string());\n\n        let manifest = KnowledgeManifest {\n            version: \"1.0\".to_string(),\n            items\n        };\n\n        let json = serde_json::to_string(\u0026manifest).unwrap();\n        let decoded: KnowledgeManifest = serde_json::from_str(\u0026json).unwrap();\n\n        assert_eq!(decoded.version, \"1.0\");\n        assert_eq!(decoded.items.get(\"key1\").unwrap(), \"hash1\");\n    }\n}\n","traces":[{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":1}},{"line":59,"address":[],"length":0,"stats":{"Line":1}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":1}},{"line":79,"address":[],"length":0,"stats":{"Line":1}},{"line":106,"address":[],"length":0,"stats":{"Line":2}}],"covered":5,"coverable":9},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","governance.rs"],"content":"use crate::telemetry::KnowledgeTelemetry;\nuse mk_core::traits::{EmbeddingService, EventPublisher, LlmService};\nuse mk_core::types::{\n    ConstraintSeverity, GovernanceEvent, KnowledgeLayer, Policy, PolicyViolation, TenantContext,\n    ValidationResult,\n};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse storage::events::EventError;\n\npub struct GovernanceEngine {\n    policies: HashMap\u003cKnowledgeLayer, Vec\u003cPolicy\u003e\u003e,\n    telemetry: KnowledgeTelemetry,\n    storage:\n        Option\u003cArc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e\u003e,\n    event_publisher: Option\u003cArc\u003cdyn EventPublisher\u003cError = EventError\u003e\u003e\u003e,\n    embedding_service: Option\u003cArc\u003cdyn EmbeddingService\u003cError = anyhow::Error\u003e\u003e\u003e,\n    llm_service: Option\u003cArc\u003cdyn LlmService\u003cError = anyhow::Error\u003e\u003e\u003e,\n    knowledge_repository: Option\u003c\n        Arc\u003cdyn mk_core::traits::KnowledgeRepository\u003cError = crate::repository::RepositoryError\u003e\u003e,\n    \u003e,\n}\n\nimpl GovernanceEngine {\n    pub fn new() -\u003e Self {\n        Self {\n            policies: HashMap::new(),\n            telemetry: KnowledgeTelemetry,\n            storage: None,\n            event_publisher: None,\n            embedding_service: None,\n            llm_service: None,\n            knowledge_repository: None,\n        }\n    }\n\n    pub fn with_storage(\n        mut self,\n        storage: Arc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e,\n    ) -\u003e Self {\n        self.storage = Some(storage);\n        self\n    }\n\n    pub fn with_event_publisher(\n        mut self,\n        publisher: Arc\u003cdyn EventPublisher\u003cError = EventError\u003e\u003e,\n    ) -\u003e Self {\n        self.event_publisher = Some(publisher);\n        self\n    }\n\n    pub fn with_embedding_service(\n        mut self,\n        embedding_service: Arc\u003cdyn EmbeddingService\u003cError = anyhow::Error\u003e\u003e,\n    ) -\u003e Self {\n        self.embedding_service = Some(embedding_service);\n        self\n    }\n\n    pub fn with_llm_service(\n        mut self,\n        llm_service: Arc\u003cdyn LlmService\u003cError = anyhow::Error\u003e\u003e,\n    ) -\u003e Self {\n        self.llm_service = Some(llm_service);\n        self\n    }\n\n    pub fn with_repository(\n        mut self,\n        repository: Arc\u003c\n            dyn mk_core::traits::KnowledgeRepository\u003cError = crate::repository::RepositoryError\u003e,\n        \u003e,\n    ) -\u003e Self {\n        self.knowledge_repository = Some(repository);\n        self\n    }\n\n    pub fn storage(\n        \u0026self,\n    ) -\u003e Option\u003cArc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e\u003e\n    {\n        self.storage.clone()\n    }\n\n    pub fn llm_service(\u0026self) -\u003e Option\u003cArc\u003cdyn LlmService\u003cError = anyhow::Error\u003e\u003e\u003e {\n        self.llm_service.clone()\n    }\n\n    pub fn repository(\n        \u0026self,\n    ) -\u003e Option\u003c\n        Arc\u003cdyn mk_core::traits::KnowledgeRepository\u003cError = crate::repository::RepositoryError\u003e\u003e,\n    \u003e {\n        self.knowledge_repository.clone()\n    }\n    pub async fn publish_event(\u0026self, event: GovernanceEvent) -\u003e Result\u003c(), EventError\u003e {\n        if let Some(publisher) = \u0026self.event_publisher {\n            publisher.publish(event).await\n        } else {\n            Ok(())\n        }\n    }\n}\n\nimpl Default for GovernanceEngine {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\nimpl GovernanceEngine {\n    pub fn add_policy(\u0026mut self, policy: Policy) {\n        self.policies.entry(policy.layer).or_default().push(policy);\n    }\n\n    pub fn event_publisher(\u0026self) -\u003e Option\u003cArc\u003cdyn EventPublisher\u003cError = EventError\u003e\u003e\u003e {\n        self.event_publisher.clone()\n    }\n\n    pub fn validate(\n        \u0026self,\n        target_layer: KnowledgeLayer,\n        context: \u0026HashMap\u003cString, serde_json::Value\u003e,\n    ) -\u003e ValidationResult {\n        let mut resolved_map: HashMap\u003cString, Policy\u003e = HashMap::new();\n        let mut mandatory_policies: HashMap\u003cString, KnowledgeLayer\u003e = HashMap::new();\n\n        let layers = [\n            KnowledgeLayer::Company,\n            KnowledgeLayer::Org,\n            KnowledgeLayer::Team,\n            KnowledgeLayer::Project,\n        ];\n\n        for layer in \u0026layers {\n            if let Some(layer_policies) = self.policies.get(layer) {\n                for policy in layer_policies {\n                    let mut p = policy.clone();\n                    p.layer = *layer;\n                    self.merge_policy(\u0026mut resolved_map, \u0026mut mandatory_policies, p);\n                }\n            }\n            if layer == \u0026target_layer {\n                break;\n            }\n        }\n\n        let mut violations = Vec::new();\n        let mut resolved_vec: Vec\u003cPolicy\u003e = resolved_map.into_values().collect();\n        resolved_vec.sort_by_key(|p| p.layer);\n\n        for policy in resolved_vec {\n            for rule in \u0026policy.rules {\n                if let Some(violation) = self.evaluate_rule(\u0026policy, rule, context) {\n                    self.telemetry.record_violation(\n                        \u0026format!(\"{:?}\", policy.layer),\n                        \u0026format!(\"{:?}\", rule.severity),\n                    );\n                    violations.push(violation);\n                }\n            }\n        }\n\n        ValidationResult {\n            is_valid: violations.is_empty(),\n            violations,\n        }\n    }\n\n    pub async fn validate_with_context(\n        \u0026self,\n        target_layer: KnowledgeLayer,\n        context: \u0026HashMap\u003cString, serde_json::Value\u003e,\n        tenant_ctx: Option\u003c\u0026TenantContext\u003e,\n    ) -\u003e ValidationResult {\n        let mut violations = Vec::new();\n\n        let active_policies = self\n            .resolve_active_policies(target_layer, context, tenant_ctx)\n            .await;\n\n        for policy in active_policies {\n            for rule in \u0026policy.rules {\n                if let Some(violation) = self.evaluate_rule(\u0026policy, rule, context) {\n                    self.telemetry.record_violation(\n                        \u0026format!(\"{:?}\", policy.layer),\n                        \u0026format!(\"{:?}\", rule.severity),\n                    );\n                    violations.push(violation);\n                }\n            }\n        }\n\n        if !violations.is_empty() {\n            self.emit_drift_event(context, tenant_ctx, \u0026violations)\n                .await;\n        }\n\n        ValidationResult {\n            is_valid: violations.is_empty(),\n            violations,\n        }\n    }\n\n    async fn resolve_active_policies(\n        \u0026self,\n        target_layer: KnowledgeLayer,\n        context: \u0026HashMap\u003cString, serde_json::Value\u003e,\n        tenant_ctx: Option\u003c\u0026TenantContext\u003e,\n    ) -\u003e Vec\u003cPolicy\u003e {\n        let mut resolved_map: HashMap\u003cString, Policy\u003e = HashMap::new();\n        let mut mandatory_policies: HashMap\u003cString, KnowledgeLayer\u003e = HashMap::new();\n\n        let layers = [\n            KnowledgeLayer::Company,\n            KnowledgeLayer::Org,\n            KnowledgeLayer::Team,\n            KnowledgeLayer::Project,\n        ];\n\n        for layer in \u0026layers {\n            if let Some(layer_policies) = self.policies.get(layer) {\n                for policy in layer_policies {\n                    self.merge_policy(\u0026mut resolved_map, \u0026mut mandatory_policies, policy.clone());\n                }\n            }\n            if layer == \u0026target_layer {\n                break;\n            }\n        }\n\n        if let Some(storage) = \u0026self.storage {\n            let unit_id = context\n                .get(\"unitId\")\n                .or_else(|| context.get(\"projectId\"))\n                .and_then(|v| v.as_str());\n\n            if let Some(uid) = unit_id {\n                let ctx = tenant_ctx.cloned().unwrap_or_default();\n\n                let mut units = Vec::new();\n                if let Ok(mut ancestors) = storage.get_ancestors(ctx.clone(), uid).await {\n                    units.append(\u0026mut ancestors);\n                }\n\n                units.reverse();\n\n                for unit in units {\n                    if let Ok(unit_policies) =\n                        storage.get_unit_policies(ctx.clone(), \u0026unit.id).await\n                    {\n                        for policy in unit_policies {\n                            self.merge_policy(\u0026mut resolved_map, \u0026mut mandatory_policies, policy);\n                        }\n                    }\n                }\n\n                if let Ok(unit_policies) = storage.get_unit_policies(ctx, uid).await {\n                    for policy in unit_policies {\n                        self.merge_policy(\u0026mut resolved_map, \u0026mut mandatory_policies, policy);\n                    }\n                }\n            }\n        }\n\n        resolved_map.into_values().collect()\n    }\n\n    fn merge_policy(\n        \u0026self,\n        resolved: \u0026mut HashMap\u003cString, Policy\u003e,\n        mandatory_policies: \u0026mut HashMap\u003cString, KnowledgeLayer\u003e,\n        incoming: Policy,\n    ) {\n        use mk_core::types::{PolicyMode, RuleMergeStrategy};\n\n        let policy_id = incoming.id.clone();\n\n        if let Some(mandatory_layer) = mandatory_policies.get(\u0026policy_id) {\n            if incoming.layer != *mandatory_layer\n                \u0026\u0026 incoming.merge_strategy != RuleMergeStrategy::Override\n            {\n                return;\n            }\n        }\n\n        if incoming.mode == PolicyMode::Mandatory {\n            mandatory_policies.insert(policy_id.clone(), incoming.layer);\n        }\n\n        if let Some(existing) = resolved.get_mut(\u0026policy_id) {\n            match incoming.merge_strategy {\n                RuleMergeStrategy::Override =\u003e {\n                    *existing = incoming;\n                }\n                RuleMergeStrategy::Merge =\u003e {\n                    for rule in incoming.rules {\n                        if !existing.rules.iter().any(|r| r.id == rule.id) {\n                            existing.rules.push(rule);\n                        }\n                    }\n                    for (k, v) in incoming.metadata {\n                        existing.metadata.insert(k, v);\n                    }\n                    existing.layer = incoming.layer;\n                }\n                RuleMergeStrategy::Intersect =\u003e {\n                    existing\n                        .rules\n                        .retain(|r| incoming.rules.iter().any(|ir| ir.id == r.id));\n                    existing.layer = incoming.layer;\n                }\n            }\n        } else {\n            resolved.insert(policy_id, incoming);\n        }\n    }\n\n    pub async fn check_drift(\n        \u0026self,\n        tenant_ctx: \u0026TenantContext,\n        _project_id: \u0026str,\n        context: \u0026HashMap\u003cString, serde_json::Value\u003e,\n    ) -\u003e Result\u003cf32, anyhow::Error\u003e {\n        let mut violations = Vec::new();\n\n        let content = context.get(\"content\").and_then(|v| v.as_str());\n        if let Some(c) = content {\n            if self.embedding_service.is_some() {\n                let mut semantic_violations = self.check_contradictions(tenant_ctx, c, 0.8).await?;\n                violations.append(\u0026mut semantic_violations);\n            }\n        }\n\n        let active_policies = self\n            .resolve_active_policies(KnowledgeLayer::Project, context, Some(tenant_ctx))\n            .await;\n\n        for policy in \u0026active_policies {\n            for rule in \u0026policy.rules {\n                if let Some(violation) = self.evaluate_rule(policy, rule, context) {\n                    violations.push(violation);\n                }\n            }\n        }\n\n        let mandatory_policies_count = active_policies\n            .iter()\n            .filter(|p| p.mode == mk_core::types::PolicyMode::Mandatory)\n            .count();\n\n        if mandatory_policies_count == 0 {\n            violations.push(PolicyViolation {\n                rule_id: \"missing_mandatory_policies\".to_string(),\n                policy_id: \"governance_requirement\".to_string(),\n                severity: ConstraintSeverity::Warn,\n                message: \"No mandatory policies detected for this project layer\".to_string(),\n                context: context.clone(),\n            });\n        }\n\n        for policy in \u0026active_policies {\n            if let Some(expected_hash) =\n                policy.metadata.get(\"version_hash\").and_then(|v| v.as_str())\n            {\n                let actual_hash = context.get(\"version_hash\").and_then(|v| v.as_str());\n                if let Some(actual) = actual_hash {\n                    if actual != expected_hash {\n                        violations.push(PolicyViolation {\n                            rule_id: \"stale_policy_reference\".to_string(),\n                            policy_id: policy.id.clone(),\n                            severity: ConstraintSeverity::Warn,\n                            message: format!(\n                                \"Project uses stale policy version (expected: {}, actual: {})\",\n                                expected_hash, actual\n                            ),\n                            context: context.clone(),\n                        });\n                    }\n                }\n            }\n        }\n\n        if let Some(c) = content {\n            if let Some(llm_violations) = self\n                .analyze_drift_with_llm(c, \u0026active_policies, context)\n                .await\n            {\n                for v in llm_violations {\n                    if !violations\n                        .iter()\n                        .any(|existing| existing.rule_id == v.rule_id)\n                    {\n                        violations.push(v);\n                    }\n                }\n            }\n        }\n\n        let drift_score = self.calculate_drift_score(\u0026violations);\n\n        if drift_score \u003e 0.0 {\n            self.emit_drift_event(context, Some(tenant_ctx), \u0026violations)\n                .await;\n        }\n\n        if let Some(storage) = \u0026self.storage {\n            let _ = storage\n                .store_drift_result(mk_core::types::DriftResult {\n                    project_id: _project_id.to_string(),\n                    tenant_id: tenant_ctx.tenant_id.clone(),\n                    drift_score,\n                    violations: violations.clone(),\n                    timestamp: chrono::Utc::now().timestamp(),\n                })\n                .await;\n        }\n\n        Ok(drift_score)\n    }\n\n    async fn analyze_drift_with_llm(\n        \u0026self,\n        content: \u0026str,\n        policies: \u0026[Policy],\n        context: \u0026HashMap\u003cString, serde_json::Value\u003e,\n    ) -\u003e Option\u003cVec\u003cPolicyViolation\u003e\u003e {\n        let llm = self.llm_service.as_ref()?;\n\n        if policies.is_empty() {\n            return None;\n        }\n\n        match llm.analyze_drift(content, policies).await {\n            Ok(result) =\u003e {\n                if result.is_valid {\n                    return None;\n                }\n\n                let violations = result\n                    .violations\n                    .into_iter()\n                    .map(|v| PolicyViolation {\n                        rule_id: format!(\"llm_{}\", v.rule_id),\n                        policy_id: v.policy_id,\n                        severity: v.severity,\n                        message: format!(\"[LLM Analysis] {}\", v.message),\n                        context: context.clone(),\n                    })\n                    .collect();\n\n                Some(violations)\n            }\n            Err(e) =\u003e {\n                tracing::warn!(\"LLM drift analysis failed: {}\", e);\n                None\n            }\n        }\n    }\n\n    fn calculate_drift_score(\u0026self, violations: \u0026[PolicyViolation]) -\u003e f32 {\n        if violations.is_empty() {\n            return 0.0;\n        }\n\n        let score = violations\n            .iter()\n            .map(|v| match v.severity {\n                ConstraintSeverity::Block =\u003e 1.0,\n                ConstraintSeverity::Warn =\u003e 0.5,\n                ConstraintSeverity::Info =\u003e 0.1,\n            })\n            .sum::\u003cf32\u003e();\n\n        score.min(1.0)\n    }\n\n    async fn emit_drift_event(\n        \u0026self,\n        context: \u0026HashMap\u003cString, serde_json::Value\u003e,\n        tenant_ctx: Option\u003c\u0026TenantContext\u003e,\n        violations: \u0026[PolicyViolation],\n    ) {\n        if let Some(publisher) = \u0026self.event_publisher {\n            let project_id = context\n                .get(\"projectId\")\n                .and_then(|v| v.as_str())\n                .or_else(|| context.get(\"unitId\").and_then(|v| v.as_str()));\n\n            if let Some(pid) = project_id {\n                let drift_score = violations\n                    .iter()\n                    .map(|v| match v.severity {\n                        mk_core::types::ConstraintSeverity::Block =\u003e 1.0,\n                        mk_core::types::ConstraintSeverity::Warn =\u003e 0.5,\n                        mk_core::types::ConstraintSeverity::Info =\u003e 0.1,\n                    })\n                    .sum::\u003cf32\u003e();\n\n                let _ = publisher\n                    .publish(GovernanceEvent::DriftDetected {\n                        project_id: pid.to_string(),\n                        tenant_id: tenant_ctx.map(|c| c.tenant_id.clone()).unwrap_or_default(),\n                        drift_score: drift_score.min(1.0),\n                        timestamp: chrono::Utc::now().timestamp(),\n                    })\n                    .await;\n            }\n        }\n    }\n\n    fn evaluate_rule(\n        \u0026self,\n        policy: \u0026Policy,\n        rule: \u0026mk_core::types::PolicyRule,\n        context: \u0026HashMap\u003cString, serde_json::Value\u003e,\n    ) -\u003e Option\u003cPolicyViolation\u003e {\n        use mk_core::types::{ConstraintOperator, RuleType};\n\n        let target_key = match rule.target {\n            mk_core::types::ConstraintTarget::File =\u003e \"path\",\n            mk_core::types::ConstraintTarget::Code =\u003e \"content\",\n            mk_core::types::ConstraintTarget::Dependency =\u003e \"dependencies\",\n            mk_core::types::ConstraintTarget::Import =\u003e \"imports\",\n            mk_core::types::ConstraintTarget::Config =\u003e \"config\",\n        };\n\n        let value = context.get(target_key);\n\n        let is_condition_met = match rule.operator {\n            ConstraintOperator::MustExist =\u003e value.is_some(),\n            ConstraintOperator::MustNotExist =\u003e value.is_none(),\n            ConstraintOperator::MustUse =\u003e {\n                if let Some(v) = value {\n                    if let Some(arr) = v.as_array() {\n                        arr.contains(\u0026rule.value)\n                    } else {\n                        v == \u0026rule.value\n                    }\n                } else {\n                    false\n                }\n            }\n            ConstraintOperator::MustNotUse =\u003e {\n                if let Some(v) = value {\n                    if let Some(arr) = v.as_array() {\n                        !arr.contains(\u0026rule.value)\n                    } else {\n                        v != \u0026rule.value\n                    }\n                } else {\n                    true\n                }\n            }\n            ConstraintOperator::MustMatch =\u003e {\n                if let Some(v) = value {\n                    if let Some(s) = v.as_str() {\n                        if let Some(re_str) = rule.value.as_str() {\n                            if let Ok(re) = regex::Regex::new(re_str) {\n                                re.is_match(s)\n                            } else {\n                                false\n                            }\n                        } else {\n                            false\n                        }\n                    } else {\n                        false\n                    }\n                } else {\n                    false\n                }\n            }\n            ConstraintOperator::MustNotMatch =\u003e {\n                if let Some(v) = value {\n                    if let Some(s) = v.as_str() {\n                        if let Some(re_str) = rule.value.as_str() {\n                            if let Ok(re) = regex::Regex::new(re_str) {\n                                !re.is_match(s)\n                            } else {\n                                true\n                            }\n                        } else {\n                            true\n                        }\n                    } else {\n                        true\n                    }\n                } else {\n                    true\n                }\n            }\n        };\n\n        let is_violated = match rule.rule_type {\n            RuleType::Allow =\u003e !is_condition_met,\n            RuleType::Deny =\u003e is_condition_met,\n        };\n\n        if is_violated {\n            Some(PolicyViolation {\n                rule_id: rule.id.clone(),\n                policy_id: policy.id.clone(),\n                severity: rule.severity,\n                message: rule.message.clone(),\n                context: context.clone(),\n            })\n        } else {\n            None\n        }\n    }\n\n    pub async fn check_contradictions(\n        \u0026self,\n        tenant_ctx: \u0026TenantContext,\n        content: \u0026str,\n        threshold: f32,\n    ) -\u003e Result\u003cVec\u003cPolicyViolation\u003e, anyhow::Error\u003e {\n        let embedding_service = self\n            .embedding_service\n            .as_ref()\n            .ok_or_else(|| anyhow::anyhow!(\"Embedding service not configured\"))?;\n\n        let content_embedding = embedding_service.embed(content).await?;\n\n        let mut violations = Vec::new();\n\n        let mut context = HashMap::new();\n        context.insert(\"content\".to_string(), serde_json::json!(content));\n\n        let active_policies = self\n            .resolve_active_policies(KnowledgeLayer::Project, \u0026context, Some(tenant_ctx))\n            .await;\n\n        for policy in active_policies {\n            for rule in \u0026policy.rules {\n                if let Some(rule_embedding_val) =\n                    policy.metadata.get(\u0026format!(\"rule_{}_embedding\", rule.id))\n                {\n                    if let Ok(rule_embedding) =\n                        serde_json::from_value::\u003cVec\u003cf32\u003e\u003e(rule_embedding_val.clone())\n                    {\n                        let similarity =\n                            self.cosine_similarity(\u0026content_embedding, \u0026rule_embedding);\n                        if similarity \u003e threshold {\n                            violations.push(PolicyViolation {\n                                rule_id: rule.id.clone(),\n                                policy_id: policy.id.clone(),\n                                severity: rule.severity,\n                                message: format!(\n                                    \"Semantic contradiction detected (similarity: {:.2}): {}\",\n                                    similarity, rule.message\n                                ),\n                                context: context.clone(),\n                            });\n                        }\n                    }\n                }\n            }\n        }\n\n        Ok(violations)\n    }\n\n    fn cosine_similarity(\u0026self, v1: \u0026[f32], v2: \u0026[f32]) -\u003e f32 {\n        if v1.len() != v2.len() || v1.is_empty() {\n            return 0.0;\n        }\n        let dot_product: f32 = v1.iter().zip(v2.iter()).map(|(a, b)| a * b).sum();\n        let norm1: f32 = v1.iter().map(|a| a * a).sum::\u003cf32\u003e().sqrt();\n        let norm2: f32 = v2.iter().map(|a| a * a).sum::\u003cf32\u003e().sqrt();\n\n        if norm1 == 0.0 || norm2 == 0.0 {\n            0.0\n        } else {\n            dot_product / (norm1 * norm2)\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::{ConstraintOperator, ConstraintSeverity, ConstraintTarget, PolicyRule};\n\n    #[test]\n    fn test_governance_engine_evaluation() {\n        let mut engine = GovernanceEngine::new();\n\n        let company_policy = Policy {\n            id: \"p1\".to_string(),\n            name: \"Security Standards\".to_string(),\n            description: None,\n            layer: KnowledgeLayer::Company,\n            rules: vec![\n                PolicyRule {\n                    id: \"r1\".to_string(),\n                    target: ConstraintTarget::Dependency,\n                    operator: ConstraintOperator::MustNotUse,\n                    value: serde_json::json!(\"unsafe-lib\"),\n                    severity: ConstraintSeverity::Block,\n                    message: \"unsafe-lib is banned\".to_string(),\n                    rule_type: mk_core::types::RuleType::Allow,\n                },\n                PolicyRule {\n                    id: \"r2\".to_string(),\n                    target: ConstraintTarget::Code,\n                    operator: ConstraintOperator::MustMatch,\n                    value: serde_json::json!(\"^# ADR\"),\n                    severity: ConstraintSeverity::Warn,\n                    message: \"ADRs must start with # ADR\".to_string(),\n                    rule_type: mk_core::types::RuleType::Allow,\n                },\n            ],\n            metadata: HashMap::new(),\n            mode: mk_core::types::PolicyMode::Optional,\n            merge_strategy: mk_core::types::RuleMergeStrategy::Merge,\n        };\n\n        engine.add_policy(company_policy);\n\n        let mut context = HashMap::new();\n        context.insert(\n            \"dependencies\".to_string(),\n            serde_json::json!([\"safe-lib\", \"unsafe-lib\"]),\n        );\n        context.insert(\"content\".to_string(), serde_json::json!(\"# ADR 001\\n...\"));\n\n        let result = engine.validate(KnowledgeLayer::Project, \u0026context);\n        assert!(!result.is_valid);\n        assert_eq!(result.violations.len(), 1);\n        assert_eq!(result.violations[0].rule_id, \"r1\");\n\n        let mut context = HashMap::new();\n        context.insert(\"dependencies\".to_string(), serde_json::json!([\"safe-lib\"]));\n        context.insert(\"content\".to_string(), serde_json::json!(\"ADR 001\\n...\"));\n\n        let result = engine.validate(KnowledgeLayer::Project, \u0026context);\n        assert!(!result.is_valid);\n        assert_eq!(result.violations.len(), 1);\n        assert_eq!(result.violations[0].rule_id, \"r2\");\n\n        let mut context = HashMap::new();\n        context.insert(\"dependencies\".to_string(), serde_json::json!([\"safe-lib\"]));\n        context.insert(\"content\".to_string(), serde_json::json!(\"# ADR 001\\n...\"));\n\n        let result = engine.validate(KnowledgeLayer::Project, \u0026context);\n        assert!(result.is_valid);\n    }\n}\n","traces":[{"line":25,"address":[],"length":0,"stats":{"Line":130}},{"line":27,"address":[],"length":0,"stats":{"Line":260}},{"line":37,"address":[],"length":0,"stats":{"Line":7}},{"line":41,"address":[],"length":0,"stats":{"Line":14}},{"line":42,"address":[],"length":0,"stats":{"Line":7}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":5}},{"line":65,"address":[],"length":0,"stats":{"Line":10}},{"line":66,"address":[],"length":0,"stats":{"Line":5}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":3}},{"line":83,"address":[],"length":0,"stats":{"Line":6}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":3}},{"line":95,"address":[],"length":0,"stats":{"Line":6}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":49}},{"line":114,"address":[],"length":0,"stats":{"Line":245}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":1063}},{"line":126,"address":[],"length":0,"stats":{"Line":3189}},{"line":127,"address":[],"length":0,"stats":{"Line":3189}},{"line":129,"address":[],"length":0,"stats":{"Line":2126}},{"line":130,"address":[],"length":0,"stats":{"Line":2126}},{"line":131,"address":[],"length":0,"stats":{"Line":2126}},{"line":132,"address":[],"length":0,"stats":{"Line":1063}},{"line":133,"address":[],"length":0,"stats":{"Line":1063}},{"line":136,"address":[],"length":0,"stats":{"Line":8458}},{"line":137,"address":[],"length":0,"stats":{"Line":8502}},{"line":138,"address":[],"length":0,"stats":{"Line":182}},{"line":139,"address":[],"length":0,"stats":{"Line":184}},{"line":140,"address":[],"length":0,"stats":{"Line":92}},{"line":141,"address":[],"length":0,"stats":{"Line":184}},{"line":144,"address":[],"length":0,"stats":{"Line":4229}},{"line":145,"address":[],"length":0,"stats":{"Line":1063}},{"line":149,"address":[],"length":0,"stats":{"Line":2126}},{"line":150,"address":[],"length":0,"stats":{"Line":5315}},{"line":151,"address":[],"length":0,"stats":{"Line":2126}},{"line":153,"address":[],"length":0,"stats":{"Line":1137}},{"line":154,"address":[],"length":0,"stats":{"Line":135}},{"line":155,"address":[],"length":0,"stats":{"Line":246}},{"line":156,"address":[],"length":0,"stats":{"Line":75}},{"line":157,"address":[],"length":0,"stats":{"Line":50}},{"line":158,"address":[],"length":0,"stats":{"Line":50}},{"line":160,"address":[],"length":0,"stats":{"Line":50}},{"line":166,"address":[],"length":0,"stats":{"Line":2126}},{"line":171,"address":[],"length":0,"stats":{"Line":3}},{"line":177,"address":[],"length":0,"stats":{"Line":6}},{"line":179,"address":[],"length":0,"stats":{"Line":9}},{"line":180,"address":[],"length":0,"stats":{"Line":12}},{"line":181,"address":[],"length":0,"stats":{"Line":3}},{"line":183,"address":[],"length":0,"stats":{"Line":3}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":3}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":201,"address":[],"length":0,"stats":{"Line":6}},{"line":206,"address":[],"length":0,"stats":{"Line":42}},{"line":212,"address":[],"length":0,"stats":{"Line":126}},{"line":213,"address":[],"length":0,"stats":{"Line":126}},{"line":215,"address":[],"length":0,"stats":{"Line":84}},{"line":216,"address":[],"length":0,"stats":{"Line":84}},{"line":217,"address":[],"length":0,"stats":{"Line":84}},{"line":218,"address":[],"length":0,"stats":{"Line":42}},{"line":219,"address":[],"length":0,"stats":{"Line":42}},{"line":222,"address":[],"length":0,"stats":{"Line":336}},{"line":223,"address":[],"length":0,"stats":{"Line":362}},{"line":224,"address":[],"length":0,"stats":{"Line":107}},{"line":225,"address":[],"length":0,"stats":{"Line":135}},{"line":228,"address":[],"length":0,"stats":{"Line":168}},{"line":229,"address":[],"length":0,"stats":{"Line":42}},{"line":233,"address":[],"length":0,"stats":{"Line":52}},{"line":234,"address":[],"length":0,"stats":{"Line":20}},{"line":236,"address":[],"length":0,"stats":{"Line":10}},{"line":237,"address":[],"length":0,"stats":{"Line":30}},{"line":239,"address":[],"length":0,"stats":{"Line":20}},{"line":240,"address":[],"length":0,"stats":{"Line":40}},{"line":242,"address":[],"length":0,"stats":{"Line":20}},{"line":243,"address":[],"length":0,"stats":{"Line":70}},{"line":244,"address":[],"length":0,"stats":{"Line":20}},{"line":247,"address":[],"length":0,"stats":{"Line":10}},{"line":249,"address":[],"length":0,"stats":{"Line":36}},{"line":250,"address":[],"length":0,"stats":{"Line":13}},{"line":251,"address":[],"length":0,"stats":{"Line":65}},{"line":253,"address":[],"length":0,"stats":{"Line":46}},{"line":254,"address":[],"length":0,"stats":{"Line":44}},{"line":259,"address":[],"length":0,"stats":{"Line":50}},{"line":260,"address":[],"length":0,"stats":{"Line":25}},{"line":261,"address":[],"length":0,"stats":{"Line":20}},{"line":267,"address":[],"length":0,"stats":{"Line":126}},{"line":270,"address":[],"length":0,"stats":{"Line":89}},{"line":278,"address":[],"length":0,"stats":{"Line":267}},{"line":280,"address":[],"length":0,"stats":{"Line":182}},{"line":281,"address":[],"length":0,"stats":{"Line":4}},{"line":282,"address":[],"length":0,"stats":{"Line":4}},{"line":284,"address":[],"length":0,"stats":{"Line":2}},{"line":288,"address":[],"length":0,"stats":{"Line":145}},{"line":289,"address":[],"length":0,"stats":{"Line":232}},{"line":292,"address":[],"length":0,"stats":{"Line":182}},{"line":293,"address":[],"length":0,"stats":{"Line":8}},{"line":294,"address":[],"length":0,"stats":{"Line":5}},{"line":295,"address":[],"length":0,"stats":{"Line":5}},{"line":298,"address":[],"length":0,"stats":{"Line":9}},{"line":299,"address":[],"length":0,"stats":{"Line":15}},{"line":300,"address":[],"length":0,"stats":{"Line":6}},{"line":303,"address":[],"length":0,"stats":{"Line":3}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":306,"address":[],"length":0,"stats":{"Line":3}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":237}},{"line":320,"address":[],"length":0,"stats":{"Line":39}},{"line":326,"address":[],"length":0,"stats":{"Line":78}},{"line":328,"address":[],"length":0,"stats":{"Line":211}},{"line":329,"address":[],"length":0,"stats":{"Line":47}},{"line":330,"address":[],"length":0,"stats":{"Line":16}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":117}},{"line":337,"address":[],"length":0,"stats":{"Line":156}},{"line":338,"address":[],"length":0,"stats":{"Line":39}},{"line":340,"address":[],"length":0,"stats":{"Line":123}},{"line":341,"address":[],"length":0,"stats":{"Line":130}},{"line":342,"address":[],"length":0,"stats":{"Line":228}},{"line":343,"address":[],"length":0,"stats":{"Line":52}},{"line":348,"address":[],"length":0,"stats":{"Line":78}},{"line":350,"address":[],"length":0,"stats":{"Line":123}},{"line":353,"address":[],"length":0,"stats":{"Line":45}},{"line":354,"address":[],"length":0,"stats":{"Line":18}},{"line":355,"address":[],"length":0,"stats":{"Line":18}},{"line":356,"address":[],"length":0,"stats":{"Line":18}},{"line":357,"address":[],"length":0,"stats":{"Line":12}},{"line":358,"address":[],"length":0,"stats":{"Line":18}},{"line":359,"address":[],"length":0,"stats":{"Line":6}},{"line":363,"address":[],"length":0,"stats":{"Line":123}},{"line":364,"address":[],"length":0,"stats":{"Line":2}},{"line":365,"address":[],"length":0,"stats":{"Line":172}},{"line":367,"address":[],"length":0,"stats":{"Line":14}},{"line":368,"address":[],"length":0,"stats":{"Line":4}},{"line":369,"address":[],"length":0,"stats":{"Line":3}},{"line":370,"address":[],"length":0,"stats":{"Line":3}},{"line":371,"address":[],"length":0,"stats":{"Line":3}},{"line":372,"address":[],"length":0,"stats":{"Line":3}},{"line":373,"address":[],"length":0,"stats":{"Line":2}},{"line":374,"address":[],"length":0,"stats":{"Line":2}},{"line":375,"address":[],"length":0,"stats":{"Line":2}},{"line":376,"address":[],"length":0,"stats":{"Line":1}},{"line":378,"address":[],"length":0,"stats":{"Line":1}},{"line":385,"address":[],"length":0,"stats":{"Line":47}},{"line":386,"address":[],"length":0,"stats":{"Line":11}},{"line":387,"address":[],"length":0,"stats":{"Line":32}},{"line":388,"address":[],"length":0,"stats":{"Line":8}},{"line":390,"address":[],"length":0,"stats":{"Line":9}},{"line":391,"address":[],"length":0,"stats":{"Line":3}},{"line":392,"address":[],"length":0,"stats":{"Line":3}},{"line":393,"address":[],"length":0,"stats":{"Line":7}},{"line":395,"address":[],"length":0,"stats":{"Line":6}},{"line":401,"address":[],"length":0,"stats":{"Line":156}},{"line":403,"address":[],"length":0,"stats":{"Line":39}},{"line":404,"address":[],"length":0,"stats":{"Line":145}},{"line":405,"address":[],"length":0,"stats":{"Line":29}},{"line":408,"address":[],"length":0,"stats":{"Line":49}},{"line":409,"address":[],"length":0,"stats":{"Line":20}},{"line":410,"address":[],"length":0,"stats":{"Line":20}},{"line":411,"address":[],"length":0,"stats":{"Line":30}},{"line":412,"address":[],"length":0,"stats":{"Line":30}},{"line":413,"address":[],"length":0,"stats":{"Line":20}},{"line":414,"address":[],"length":0,"stats":{"Line":30}},{"line":415,"address":[],"length":0,"stats":{"Line":10}},{"line":417,"address":[],"length":0,"stats":{"Line":10}},{"line":420,"address":[],"length":0,"stats":{"Line":39}},{"line":423,"address":[],"length":0,"stats":{"Line":8}},{"line":429,"address":[],"length":0,"stats":{"Line":24}},{"line":431,"address":[],"length":0,"stats":{"Line":10}},{"line":432,"address":[],"length":0,"stats":{"Line":2}},{"line":435,"address":[],"length":0,"stats":{"Line":12}},{"line":436,"address":[],"length":0,"stats":{"Line":3}},{"line":437,"address":[],"length":0,"stats":{"Line":3}},{"line":438,"address":[],"length":0,"stats":{"Line":0}},{"line":441,"address":[],"length":0,"stats":{"Line":6}},{"line":442,"address":[],"length":0,"stats":{"Line":3}},{"line":444,"address":[],"length":0,"stats":{"Line":3}},{"line":445,"address":[],"length":0,"stats":{"Line":6}},{"line":446,"address":[],"length":0,"stats":{"Line":3}},{"line":447,"address":[],"length":0,"stats":{"Line":3}},{"line":448,"address":[],"length":0,"stats":{"Line":6}},{"line":449,"address":[],"length":0,"stats":{"Line":6}},{"line":453,"address":[],"length":0,"stats":{"Line":3}},{"line":455,"address":[],"length":0,"stats":{"Line":0}},{"line":456,"address":[],"length":0,"stats":{"Line":0}},{"line":457,"address":[],"length":0,"stats":{"Line":0}},{"line":462,"address":[],"length":0,"stats":{"Line":39}},{"line":463,"address":[],"length":0,"stats":{"Line":78}},{"line":464,"address":[],"length":0,"stats":{"Line":10}},{"line":467,"address":[],"length":0,"stats":{"Line":58}},{"line":469,"address":[],"length":0,"stats":{"Line":65}},{"line":470,"address":[],"length":0,"stats":{"Line":13}},{"line":471,"address":[],"length":0,"stats":{"Line":17}},{"line":472,"address":[],"length":0,"stats":{"Line":6}},{"line":476,"address":[],"length":0,"stats":{"Line":58}},{"line":479,"address":[],"length":0,"stats":{"Line":29}},{"line":485,"address":[],"length":0,"stats":{"Line":29}},{"line":486,"address":[],"length":0,"stats":{"Line":0}},{"line":488,"address":[],"length":0,"stats":{"Line":0}},{"line":489,"address":[],"length":0,"stats":{"Line":0}},{"line":491,"address":[],"length":0,"stats":{"Line":0}},{"line":492,"address":[],"length":0,"stats":{"Line":0}},{"line":494,"address":[],"length":0,"stats":{"Line":0}},{"line":495,"address":[],"length":0,"stats":{"Line":0}},{"line":496,"address":[],"length":0,"stats":{"Line":0}},{"line":497,"address":[],"length":0,"stats":{"Line":0}},{"line":501,"address":[],"length":0,"stats":{"Line":0}},{"line":502,"address":[],"length":0,"stats":{"Line":0}},{"line":503,"address":[],"length":0,"stats":{"Line":0}},{"line":504,"address":[],"length":0,"stats":{"Line":0}},{"line":505,"address":[],"length":0,"stats":{"Line":0}},{"line":506,"address":[],"length":0,"stats":{"Line":0}},{"line":508,"address":[],"length":0,"stats":{"Line":0}},{"line":513,"address":[],"length":0,"stats":{"Line":93}},{"line":521,"address":[],"length":0,"stats":{"Line":186}},{"line":522,"address":[],"length":0,"stats":{"Line":6}},{"line":523,"address":[],"length":0,"stats":{"Line":41}},{"line":524,"address":[],"length":0,"stats":{"Line":42}},{"line":525,"address":[],"length":0,"stats":{"Line":0}},{"line":526,"address":[],"length":0,"stats":{"Line":4}},{"line":529,"address":[],"length":0,"stats":{"Line":372}},{"line":531,"address":[],"length":0,"stats":{"Line":186}},{"line":532,"address":[],"length":0,"stats":{"Line":10}},{"line":533,"address":[],"length":0,"stats":{"Line":4}},{"line":535,"address":[],"length":0,"stats":{"Line":72}},{"line":536,"address":[],"length":0,"stats":{"Line":72}},{"line":537,"address":[],"length":0,"stats":{"Line":72}},{"line":539,"address":[],"length":0,"stats":{"Line":0}},{"line":542,"address":[],"length":0,"stats":{"Line":0}},{"line":546,"address":[],"length":0,"stats":{"Line":10}},{"line":547,"address":[],"length":0,"stats":{"Line":10}},{"line":548,"address":[],"length":0,"stats":{"Line":10}},{"line":550,"address":[],"length":0,"stats":{"Line":0}},{"line":553,"address":[],"length":0,"stats":{"Line":0}},{"line":557,"address":[],"length":0,"stats":{"Line":36}},{"line":558,"address":[],"length":0,"stats":{"Line":36}},{"line":559,"address":[],"length":0,"stats":{"Line":36}},{"line":560,"address":[],"length":0,"stats":{"Line":36}},{"line":561,"address":[],"length":0,"stats":{"Line":54}},{"line":563,"address":[],"length":0,"stats":{"Line":0}},{"line":566,"address":[],"length":0,"stats":{"Line":0}},{"line":569,"address":[],"length":0,"stats":{"Line":0}},{"line":572,"address":[],"length":0,"stats":{"Line":0}},{"line":576,"address":[],"length":0,"stats":{"Line":54}},{"line":577,"address":[],"length":0,"stats":{"Line":54}},{"line":578,"address":[],"length":0,"stats":{"Line":54}},{"line":579,"address":[],"length":0,"stats":{"Line":54}},{"line":580,"address":[],"length":0,"stats":{"Line":54}},{"line":582,"address":[],"length":0,"stats":{"Line":0}},{"line":585,"address":[],"length":0,"stats":{"Line":0}},{"line":588,"address":[],"length":0,"stats":{"Line":0}},{"line":591,"address":[],"length":0,"stats":{"Line":0}},{"line":596,"address":[],"length":0,"stats":{"Line":186}},{"line":597,"address":[],"length":0,"stats":{"Line":89}},{"line":598,"address":[],"length":0,"stats":{"Line":4}},{"line":601,"address":[],"length":0,"stats":{"Line":93}},{"line":602,"address":[],"length":0,"stats":{"Line":51}},{"line":603,"address":[],"length":0,"stats":{"Line":153}},{"line":604,"address":[],"length":0,"stats":{"Line":153}},{"line":605,"address":[],"length":0,"stats":{"Line":102}},{"line":606,"address":[],"length":0,"stats":{"Line":153}},{"line":607,"address":[],"length":0,"stats":{"Line":51}},{"line":610,"address":[],"length":0,"stats":{"Line":42}},{"line":614,"address":[],"length":0,"stats":{"Line":0}},{"line":620,"address":[],"length":0,"stats":{"Line":0}},{"line":621,"address":[],"length":0,"stats":{"Line":0}},{"line":623,"address":[],"length":0,"stats":{"Line":0}},{"line":625,"address":[],"length":0,"stats":{"Line":0}},{"line":627,"address":[],"length":0,"stats":{"Line":0}},{"line":629,"address":[],"length":0,"stats":{"Line":0}},{"line":630,"address":[],"length":0,"stats":{"Line":0}},{"line":632,"address":[],"length":0,"stats":{"Line":0}},{"line":633,"address":[],"length":0,"stats":{"Line":0}},{"line":634,"address":[],"length":0,"stats":{"Line":0}},{"line":636,"address":[],"length":0,"stats":{"Line":0}},{"line":637,"address":[],"length":0,"stats":{"Line":0}},{"line":638,"address":[],"length":0,"stats":{"Line":0}},{"line":639,"address":[],"length":0,"stats":{"Line":0}},{"line":641,"address":[],"length":0,"stats":{"Line":0}},{"line":642,"address":[],"length":0,"stats":{"Line":0}},{"line":644,"address":[],"length":0,"stats":{"Line":0}},{"line":645,"address":[],"length":0,"stats":{"Line":0}},{"line":646,"address":[],"length":0,"stats":{"Line":0}},{"line":647,"address":[],"length":0,"stats":{"Line":0}},{"line":648,"address":[],"length":0,"stats":{"Line":0}},{"line":649,"address":[],"length":0,"stats":{"Line":0}},{"line":650,"address":[],"length":0,"stats":{"Line":0}},{"line":651,"address":[],"length":0,"stats":{"Line":0}},{"line":652,"address":[],"length":0,"stats":{"Line":0}},{"line":653,"address":[],"length":0,"stats":{"Line":0}},{"line":655,"address":[],"length":0,"stats":{"Line":0}},{"line":663,"address":[],"length":0,"stats":{"Line":0}},{"line":666,"address":[],"length":0,"stats":{"Line":0}},{"line":667,"address":[],"length":0,"stats":{"Line":0}},{"line":668,"address":[],"length":0,"stats":{"Line":0}},{"line":670,"address":[],"length":0,"stats":{"Line":0}},{"line":671,"address":[],"length":0,"stats":{"Line":0}},{"line":672,"address":[],"length":0,"stats":{"Line":0}},{"line":674,"address":[],"length":0,"stats":{"Line":0}},{"line":675,"address":[],"length":0,"stats":{"Line":0}},{"line":677,"address":[],"length":0,"stats":{"Line":0}}],"covered":222,"coverable":327},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","governance_client.rs"],"content":"use async_trait::async_trait;\nuse mk_core::types::{\n    DriftResult, GovernanceEvent, KnowledgeEntry, KnowledgeLayer, TenantContext, ValidationResult,\n};\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse std::time::{Duration, Instant};\nuse tokio::sync::RwLock;\n\n#[derive(Debug, thiserror::Error)]\npub enum GovernanceClientError {\n    #[error(\"Network error: {0}\")]\n    Network(#[from] reqwest::Error),\n    #[error(\"API error: {0}\")]\n    Api(String),\n    #[error(\"Serialization error: {0}\")]\n    Serialization(#[from] serde_json::Error),\n    #[error(\"Internal error: {0}\")]\n    Internal(String),\n    #[error(\"Remote unavailable, using cached data\")]\n    RemoteUnavailable,\n    #[error(\"Sync conflict: {0}\")]\n    SyncConflict(String),\n}\n\npub type Result\u003cT\u003e = std::result::Result\u003cT, GovernanceClientError\u003e;\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct SyncState {\n    pub last_sync_timestamp: i64,\n    pub local_version: u64,\n    pub remote_version: u64,\n    pub pending_changes: Vec\u003cPendingChange\u003e,\n}\n\nimpl Default for SyncState {\n    fn default() -\u003e Self {\n        Self {\n            last_sync_timestamp: 0,\n            local_version: 0,\n            remote_version: 0,\n            pending_changes: Vec::new(),\n        }\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PendingChange {\n    pub id: String,\n    pub change_type: ChangeType,\n    pub data: serde_json::Value,\n    pub created_at: i64,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\npub enum ChangeType {\n    PolicyUpdate,\n    DriftResult,\n    ProposalAction,\n}\n\n#[derive(Debug, Clone)]\nstruct CacheEntry\u003cT\u003e {\n    data: T,\n    inserted_at: Instant,\n    ttl: Duration,\n}\n\nimpl\u003cT: Clone\u003e CacheEntry\u003cT\u003e {\n    fn new(data: T, ttl: Duration) -\u003e Self {\n        Self {\n            data,\n            inserted_at: Instant::now(),\n            ttl,\n        }\n    }\n\n    fn is_expired(\u0026self) -\u003e bool {\n        self.inserted_at.elapsed() \u003e self.ttl\n    }\n}\n\n#[async_trait]\npub trait GovernanceClient: Send + Sync {\n    async fn validate(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        layer: KnowledgeLayer,\n        context: \u0026std::collections::HashMap\u003cString, serde_json::Value\u003e,\n    ) -\u003e Result\u003cValidationResult\u003e;\n\n    async fn get_drift_status(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        project_id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cDriftResult\u003e\u003e;\n\n    async fn list_proposals(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        layer: Option\u003cKnowledgeLayer\u003e,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e\u003e;\n\n    async fn replay_events(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        since_timestamp: i64,\n        limit: usize,\n    ) -\u003e Result\u003cVec\u003cGovernanceEvent\u003e\u003e;\n}\n\npub struct RemoteGovernanceClient {\n    client: reqwest::Client,\n    base_url: String,\n}\n\nimpl RemoteGovernanceClient {\n    pub fn new(base_url: String) -\u003e Self {\n        Self {\n            client: reqwest::Client::new(),\n            base_url,\n        }\n    }\n}\n\npub struct HybridGovernanceClient {\n    remote_client: RemoteGovernanceClient,\n    local_engine: Arc\u003ccrate::governance::GovernanceEngine\u003e,\n    cache: Arc\u003cRwLock\u003cHybridCache\u003e\u003e,\n    sync_state: Arc\u003cRwLock\u003cSyncState\u003e\u003e,\n    cache_ttl: Duration,\n    sync_interval: Duration,\n}\n\nstruct HybridCache {\n    drift_results: HashMap\u003cString, CacheEntry\u003cDriftResult\u003e\u003e,\n    proposals: Option\u003cCacheEntry\u003cVec\u003cKnowledgeEntry\u003e\u003e\u003e,\n}\n\nimpl Default for HybridCache {\n    fn default() -\u003e Self {\n        Self {\n            drift_results: HashMap::new(),\n            proposals: None,\n        }\n    }\n}\n\nimpl HybridGovernanceClient {\n    pub fn new(remote_url: String, local_engine: Arc\u003ccrate::governance::GovernanceEngine\u003e) -\u003e Self {\n        Self {\n            remote_client: RemoteGovernanceClient::new(remote_url),\n            local_engine,\n            cache: Arc::new(RwLock::new(HybridCache::default())),\n            sync_state: Arc::new(RwLock::new(SyncState::default())),\n            cache_ttl: Duration::from_secs(300),\n            sync_interval: Duration::from_secs(60),\n        }\n    }\n\n    pub fn with_cache_ttl(mut self, ttl: Duration) -\u003e Self {\n        self.cache_ttl = ttl;\n        self\n    }\n\n    pub fn with_sync_interval(mut self, interval: Duration) -\u003e Self {\n        self.sync_interval = interval;\n        self\n    }\n\n    fn cache_key(ctx: \u0026TenantContext, suffix: \u0026str) -\u003e String {\n        format!(\n            \"{}:{}:{}\",\n            ctx.tenant_id.as_str(),\n            ctx.user_id.as_str(),\n            suffix\n        )\n    }\n\n    pub async fn sync_pending_changes(\u0026self, ctx: \u0026TenantContext) -\u003e Result\u003cusize\u003e {\n        let mut state = self.sync_state.write().await;\n        let pending = std::mem::take(\u0026mut state.pending_changes);\n        let mut synced = 0;\n\n        for change in pending {\n            match self.push_change_to_remote(ctx, \u0026change).await {\n                Ok(_) =\u003e {\n                    synced += 1;\n                    state.local_version += 1;\n                }\n                Err(e) =\u003e {\n                    tracing::error!(\"Failed to sync change {}: {:?}\", change.id, e);\n                    state.pending_changes.push(change);\n                }\n            }\n        }\n\n        if synced \u003e 0 {\n            state.last_sync_timestamp = chrono::Utc::now().timestamp();\n        }\n\n        Ok(synced)\n    }\n\n    async fn push_change_to_remote(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        change: \u0026PendingChange,\n    ) -\u003e Result\u003c()\u003e {\n        let url = match change.change_type {\n            ChangeType::PolicyUpdate =\u003e {\n                format!(\n                    \"{}/api/v1/governance/policies/sync\",\n                    self.remote_client.base_url\n                )\n            }\n            ChangeType::DriftResult =\u003e {\n                format!(\n                    \"{}/api/v1/governance/drift/sync\",\n                    self.remote_client.base_url\n                )\n            }\n            ChangeType::ProposalAction =\u003e {\n                format!(\n                    \"{}/api/v1/governance/proposals/sync\",\n                    self.remote_client.base_url\n                )\n            }\n        };\n\n        let response = self\n            .remote_client\n            .client\n            .post(\u0026url)\n            .header(\"X-Tenant-Id\", ctx.tenant_id.as_str())\n            .header(\"X-User-Id\", ctx.user_id.as_str())\n            .json(\u0026change.data)\n            .send()\n            .await?;\n\n        if response.status().is_success() {\n            Ok(())\n        } else {\n            Err(GovernanceClientError::Api(response.text().await?))\n        }\n    }\n\n    pub async fn queue_local_change(\u0026self, change: PendingChange) {\n        let mut state = self.sync_state.write().await;\n        state.pending_changes.push(change);\n    }\n\n    pub async fn get_sync_state(\u0026self) -\u003e SyncState {\n        self.sync_state.read().await.clone()\n    }\n}\n\n#[async_trait]\nimpl GovernanceClient for HybridGovernanceClient {\n    async fn validate(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        layer: KnowledgeLayer,\n        context: \u0026std::collections::HashMap\u003cString, serde_json::Value\u003e,\n    ) -\u003e Result\u003cValidationResult\u003e {\n        let local_result = self\n            .local_engine\n            .validate_with_context(layer, context, Some(ctx))\n            .await;\n\n        self.queue_local_change(PendingChange {\n            id: uuid::Uuid::new_v4().to_string(),\n            change_type: ChangeType::PolicyUpdate,\n            data: serde_json::json!({\n                \"layer\": layer,\n                \"context\": context,\n                \"result\": local_result\n            }),\n            created_at: chrono::Utc::now().timestamp(),\n        })\n        .await;\n\n        Ok(local_result)\n    }\n\n    async fn get_drift_status(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        project_id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cDriftResult\u003e\u003e {\n        let cache_key = Self::cache_key(ctx, \u0026format!(\"drift:{}\", project_id));\n\n        {\n            let cache = self.cache.read().await;\n            if let Some(entry) = cache.drift_results.get(\u0026cache_key) {\n                if !entry.is_expired() {\n                    return Ok(Some(entry.data.clone()));\n                }\n            }\n        }\n\n        match self.remote_client.get_drift_status(ctx, project_id).await {\n            Ok(result) =\u003e {\n                if let Some(ref drift) = result {\n                    let mut cache = self.cache.write().await;\n                    cache\n                        .drift_results\n                        .insert(cache_key, CacheEntry::new(drift.clone(), self.cache_ttl));\n                }\n                Ok(result)\n            }\n            Err(_) =\u003e {\n                if let Some(storage) = self.local_engine.storage() {\n                    match storage\n                        .get_latest_drift_result(ctx.clone(), project_id)\n                        .await\n                    {\n                        Ok(result) =\u003e Ok(result),\n                        Err(e) =\u003e Err(GovernanceClientError::Internal(format!(\"{:?}\", e))),\n                    }\n                } else {\n                    Ok(None)\n                }\n            }\n        }\n    }\n\n    async fn list_proposals(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        layer: Option\u003cKnowledgeLayer\u003e,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e\u003e {\n        {\n            let cache = self.cache.read().await;\n            if let Some(ref entry) = cache.proposals {\n                if !entry.is_expired() {\n                    let filtered: Vec\u003c_\u003e = entry\n                        .data\n                        .iter()\n                        .filter(|e| layer.is_none() || Some(e.layer) == layer)\n                        .cloned()\n                        .collect();\n                    return Ok(filtered);\n                }\n            }\n        }\n\n        match self.remote_client.list_proposals(ctx, layer).await {\n            Ok(proposals) =\u003e {\n                let mut cache = self.cache.write().await;\n                cache.proposals = Some(CacheEntry::new(proposals.clone(), self.cache_ttl));\n                Ok(proposals)\n            }\n            Err(_) =\u003e {\n                if let Some(repo) = self.local_engine.repository() {\n                    let target_layer = layer.unwrap_or(KnowledgeLayer::Project);\n                    match repo.list(ctx.clone(), target_layer, \"proposals/\").await {\n                        Ok(entries) =\u003e Ok(entries),\n                        Err(e) =\u003e Err(GovernanceClientError::Internal(format!(\"{:?}\", e))),\n                    }\n                } else {\n                    Ok(vec![])\n                }\n            }\n        }\n    }\n\n    async fn replay_events(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        since_timestamp: i64,\n        limit: usize,\n    ) -\u003e Result\u003cVec\u003cGovernanceEvent\u003e\u003e {\n        self.remote_client\n            .replay_events(ctx, since_timestamp, limit)\n            .await\n    }\n}\n\npub enum GovernanceClientKind {\n    Local(LocalGovernanceClient),\n    Hybrid(HybridGovernanceClient),\n    Remote(RemoteGovernanceClient),\n}\n\nimpl std::fmt::Debug for GovernanceClientKind {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        match self {\n            GovernanceClientKind::Local(_) =\u003e f.debug_tuple(\"Local\").finish(),\n            GovernanceClientKind::Hybrid(_) =\u003e f.debug_tuple(\"Hybrid\").finish(),\n            GovernanceClientKind::Remote(_) =\u003e f.debug_tuple(\"Remote\").finish(),\n        }\n    }\n}\n\nimpl GovernanceClientKind {\n    pub fn as_client(\u0026self) -\u003e \u0026dyn GovernanceClient {\n        match self {\n            GovernanceClientKind::Local(c) =\u003e c,\n            GovernanceClientKind::Hybrid(c) =\u003e c,\n            GovernanceClientKind::Remote(c) =\u003e c,\n        }\n    }\n}\n\npub fn create_governance_client(\n    config: \u0026config::DeploymentConfig,\n    engine: Option\u003cArc\u003ccrate::governance::GovernanceEngine\u003e\u003e,\n) -\u003e Result\u003cGovernanceClientKind\u003e {\n    match config.mode.as_str() {\n        \"local\" =\u003e {\n            let engine = engine.ok_or_else(|| {\n                GovernanceClientError::Internal(\n                    \"Local mode requires a GovernanceEngine instance\".to_string(),\n                )\n            })?;\n            Ok(GovernanceClientKind::Local(LocalGovernanceClient::new(\n                engine,\n            )))\n        }\n        \"hybrid\" =\u003e {\n            let engine = engine.ok_or_else(|| {\n                GovernanceClientError::Internal(\n                    \"Hybrid mode requires a GovernanceEngine instance\".to_string(),\n                )\n            })?;\n            let remote_url = config.remote_url.clone().ok_or_else(|| {\n                GovernanceClientError::Internal(\n                    \"Hybrid mode requires a remote_url configuration\".to_string(),\n                )\n            })?;\n            Ok(GovernanceClientKind::Hybrid(HybridGovernanceClient::new(\n                remote_url, engine,\n            )))\n        }\n        \"remote\" =\u003e {\n            let remote_url = config.remote_url.clone().ok_or_else(|| {\n                GovernanceClientError::Internal(\n                    \"Remote mode requires a remote_url configuration\".to_string(),\n                )\n            })?;\n            Ok(GovernanceClientKind::Remote(RemoteGovernanceClient::new(\n                remote_url,\n            )))\n        }\n        other =\u003e Err(GovernanceClientError::Internal(format!(\n            \"Invalid deployment mode: {}\",\n            other\n        ))),\n    }\n}\n\n/// Local governance client that wraps the `GovernanceEngine` directly.\n///\n/// Used in \"local\" deployment mode where all governance operations are\n/// performed locally without any remote communication.\npub struct LocalGovernanceClient {\n    engine: Arc\u003ccrate::governance::GovernanceEngine\u003e,\n}\n\nimpl LocalGovernanceClient {\n    pub fn new(engine: Arc\u003ccrate::governance::GovernanceEngine\u003e) -\u003e Self {\n        Self { engine }\n    }\n}\n\n#[async_trait]\nimpl GovernanceClient for LocalGovernanceClient {\n    async fn validate(\n        \u0026self,\n        _ctx: \u0026TenantContext,\n        layer: KnowledgeLayer,\n        context: \u0026std::collections::HashMap\u003cString, serde_json::Value\u003e,\n    ) -\u003e Result\u003cValidationResult\u003e {\n        Ok(self\n            .engine\n            .validate_with_context(layer, context, None)\n            .await)\n    }\n\n    async fn get_drift_status(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        project_id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cDriftResult\u003e\u003e {\n        if let Some(storage) = self.engine.storage() {\n            match storage\n                .get_latest_drift_result(ctx.clone(), project_id)\n                .await\n            {\n                Ok(result) =\u003e Ok(result),\n                Err(e) =\u003e Err(GovernanceClientError::Internal(format!(\"{:?}\", e))),\n            }\n        } else {\n            Ok(None)\n        }\n    }\n\n    async fn list_proposals(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        layer: Option\u003cKnowledgeLayer\u003e,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e\u003e {\n        if let Some(repo) = self.engine.repository() {\n            let target_layer = layer.unwrap_or(KnowledgeLayer::Project);\n            match repo.list(ctx.clone(), target_layer, \"proposals/\").await {\n                Ok(entries) =\u003e Ok(entries),\n                Err(e) =\u003e Err(GovernanceClientError::Internal(format!(\"{:?}\", e))),\n            }\n        } else {\n            Ok(vec![])\n        }\n    }\n\n    async fn replay_events(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        since_timestamp: i64,\n        limit: usize,\n    ) -\u003e Result\u003cVec\u003cGovernanceEvent\u003e\u003e {\n        if let Some(storage) = self.engine.storage() {\n            match storage\n                .get_governance_events(ctx.clone(), since_timestamp, limit)\n                .await\n            {\n                Ok(events) =\u003e Ok(events),\n                Err(e) =\u003e Err(GovernanceClientError::Internal(format!(\"{:?}\", e))),\n            }\n        } else {\n            Ok(vec![])\n        }\n    }\n}\n\n#[async_trait]\nimpl GovernanceClient for RemoteGovernanceClient {\n    async fn validate(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        layer: KnowledgeLayer,\n        context: \u0026std::collections::HashMap\u003cString, serde_json::Value\u003e,\n    ) -\u003e Result\u003cValidationResult\u003e {\n        let url = format!(\"{}/api/v1/governance/validate\", self.base_url);\n        let response = self\n            .client\n            .post(\u0026url)\n            .header(\"X-Tenant-Id\", ctx.tenant_id.as_str())\n            .header(\"X-User-Id\", ctx.user_id.as_str())\n            .json(\u0026serde_json::json!({\n                \"layer\": layer,\n                \"context\": context\n            }))\n            .send()\n            .await?;\n\n        if response.status().is_success() {\n            Ok(response.json().await?)\n        } else {\n            Err(GovernanceClientError::Api(response.text().await?))\n        }\n    }\n\n    async fn get_drift_status(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        project_id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cDriftResult\u003e\u003e {\n        let url = format!(\"{}/api/v1/governance/drift/{}\", self.base_url, project_id);\n        let response = self\n            .client\n            .get(\u0026url)\n            .header(\"X-Tenant-Id\", ctx.tenant_id.as_str())\n            .header(\"X-User-Id\", ctx.user_id.as_str())\n            .send()\n            .await?;\n\n        if response.status().is_success() {\n            Ok(response.json().await?)\n        } else {\n            Err(GovernanceClientError::Api(response.text().await?))\n        }\n    }\n\n    async fn list_proposals(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        layer: Option\u003cKnowledgeLayer\u003e,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e\u003e {\n        let mut url = format!(\"{}/api/v1/governance/proposals\", self.base_url);\n        if let Some(l) = layer {\n            url.push_str(\u0026format!(\"?layer={:?}\", l));\n        }\n\n        let response = self\n            .client\n            .get(\u0026url)\n            .header(\"X-Tenant-Id\", ctx.tenant_id.as_str())\n            .header(\"X-User-Id\", ctx.user_id.as_str())\n            .send()\n            .await?;\n\n        if response.status().is_success() {\n            Ok(response.json().await?)\n        } else {\n            Err(GovernanceClientError::Api(response.text().await?))\n        }\n    }\n\n    async fn replay_events(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        since_timestamp: i64,\n        limit: usize,\n    ) -\u003e Result\u003cVec\u003cGovernanceEvent\u003e\u003e {\n        let url = format!(\n            \"{}/api/v1/governance/events/replay?since_timestamp={}\u0026limit={}\",\n            self.base_url, since_timestamp, limit\n        );\n\n        let response = self\n            .client\n            .get(\u0026url)\n            .header(\"X-Tenant-Id\", ctx.tenant_id.as_str())\n            .header(\"X-User-Id\", ctx.user_id.as_str())\n            .send()\n            .await?;\n\n        if response.status().is_success() {\n            Ok(response.json().await?)\n        } else {\n            Err(GovernanceClientError::Api(response.text().await?))\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::{TenantId, UserId};\n\n    fn test_tenant_context() -\u003e TenantContext {\n        TenantContext::new(TenantId::default(), UserId::default())\n    }\n\n    #[test]\n    fn test_sync_state_default() {\n        let state = SyncState::default();\n        assert_eq!(state.last_sync_timestamp, 0);\n        assert_eq!(state.local_version, 0);\n        assert_eq!(state.remote_version, 0);\n        assert!(state.pending_changes.is_empty());\n    }\n\n    #[test]\n    fn test_pending_change_serialization() {\n        let change = PendingChange {\n            id: \"change-1\".to_string(),\n            change_type: ChangeType::PolicyUpdate,\n            data: serde_json::json!({\"key\": \"value\"}),\n            created_at: 1234567890,\n        };\n\n        let json = serde_json::to_string(\u0026change).unwrap();\n        let deserialized: PendingChange = serde_json::from_str(\u0026json).unwrap();\n\n        assert_eq!(deserialized.id, \"change-1\");\n        assert_eq!(deserialized.change_type, ChangeType::PolicyUpdate);\n        assert_eq!(deserialized.created_at, 1234567890);\n    }\n\n    #[test]\n    fn test_change_type_variants() {\n        assert_eq!(ChangeType::PolicyUpdate, ChangeType::PolicyUpdate);\n        assert_eq!(ChangeType::DriftResult, ChangeType::DriftResult);\n        assert_eq!(ChangeType::ProposalAction, ChangeType::ProposalAction);\n        assert_ne!(ChangeType::PolicyUpdate, ChangeType::DriftResult);\n    }\n\n    #[test]\n    fn test_cache_entry_expiration() {\n        let entry = CacheEntry::new(\"test data\".to_string(), Duration::from_millis(10));\n        assert!(!entry.is_expired());\n\n        std::thread::sleep(Duration::from_millis(15));\n        assert!(entry.is_expired());\n    }\n\n    #[test]\n    fn test_cache_entry_not_expired() {\n        let entry = CacheEntry::new(42i32, Duration::from_secs(60));\n        assert!(!entry.is_expired());\n    }\n\n    #[test]\n    fn test_hybrid_cache_default() {\n        let cache = HybridCache::default();\n        assert!(cache.drift_results.is_empty());\n        assert!(cache.proposals.is_none());\n    }\n\n    #[test]\n    fn test_cache_key_generation() {\n        let ctx = test_tenant_context();\n        let key = HybridGovernanceClient::cache_key(\u0026ctx, \"drift:proj-1\");\n        assert_eq!(key, \"default:default:drift:proj-1\");\n    }\n\n    #[test]\n    fn test_remote_client_construction() {\n        let client = RemoteGovernanceClient::new(\"http://localhost:8080\".to_string());\n        assert_eq!(client.base_url, \"http://localhost:8080\");\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_client_construction() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client =\n            HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine.clone());\n\n        assert_eq!(client.cache_ttl, Duration::from_secs(300));\n        assert_eq!(client.sync_interval, Duration::from_secs(60));\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_client_with_custom_ttl() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine)\n            .with_cache_ttl(Duration::from_secs(120));\n\n        assert_eq!(client.cache_ttl, Duration::from_secs(120));\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_client_with_custom_sync_interval() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine)\n            .with_sync_interval(Duration::from_secs(30));\n\n        assert_eq!(client.sync_interval, Duration::from_secs(30));\n    }\n\n    #[tokio::test]\n    async fn test_queue_local_change() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine);\n\n        let change = PendingChange {\n            id: \"test-change\".to_string(),\n            change_type: ChangeType::PolicyUpdate,\n            data: serde_json::json!({\"test\": true}),\n            created_at: chrono::Utc::now().timestamp(),\n        };\n\n        client.queue_local_change(change).await;\n\n        let state = client.get_sync_state().await;\n        assert_eq!(state.pending_changes.len(), 1);\n        assert_eq!(state.pending_changes[0].id, \"test-change\");\n    }\n\n    #[tokio::test]\n    async fn test_get_sync_state_initial() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine);\n\n        let state = client.get_sync_state().await;\n        assert_eq!(state.last_sync_timestamp, 0);\n        assert_eq!(state.local_version, 0);\n        assert_eq!(state.remote_version, 0);\n        assert!(state.pending_changes.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_validate_queues_change() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine);\n\n        let ctx = test_tenant_context();\n        let context = HashMap::new();\n\n        let result = client\n            .validate(\u0026ctx, KnowledgeLayer::Project, \u0026context)\n            .await;\n        assert!(result.is_ok());\n\n        let state = client.get_sync_state().await;\n        assert_eq!(state.pending_changes.len(), 1);\n        assert_eq!(\n            state.pending_changes[0].change_type,\n            ChangeType::PolicyUpdate\n        );\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_get_drift_status_no_storage() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://invalid-host:9999\".to_string(), engine);\n\n        let ctx = test_tenant_context();\n        let result = client.get_drift_status(\u0026ctx, \"proj-1\").await;\n\n        assert!(result.is_ok());\n        assert!(result.unwrap().is_none());\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_list_proposals_no_repo() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://invalid-host:9999\".to_string(), engine);\n\n        let ctx = test_tenant_context();\n        let result = client.list_proposals(\u0026ctx, None).await;\n\n        assert!(result.is_ok());\n        assert!(result.unwrap().is_empty());\n    }\n\n    #[test]\n    fn test_governance_client_error_display() {\n        let err = GovernanceClientError::Api(\"Not found\".to_string());\n        assert_eq!(err.to_string(), \"API error: Not found\");\n\n        let err = GovernanceClientError::Internal(\"Something went wrong\".to_string());\n        assert_eq!(err.to_string(), \"Internal error: Something went wrong\");\n\n        let err = GovernanceClientError::RemoteUnavailable;\n        assert_eq!(err.to_string(), \"Remote unavailable, using cached data\");\n\n        let err = GovernanceClientError::SyncConflict(\"Version mismatch\".to_string());\n        assert_eq!(err.to_string(), \"Sync conflict: Version mismatch\");\n    }\n\n    #[test]\n    fn test_sync_state_serialization() {\n        let state = SyncState {\n            last_sync_timestamp: 1234567890,\n            local_version: 5,\n            remote_version: 3,\n            pending_changes: vec![PendingChange {\n                id: \"change-1\".to_string(),\n                change_type: ChangeType::DriftResult,\n                data: serde_json::json!({}),\n                created_at: 1234567890,\n            }],\n        };\n\n        let json = serde_json::to_string(\u0026state).unwrap();\n        let deserialized: SyncState = serde_json::from_str(\u0026json).unwrap();\n\n        assert_eq!(deserialized.last_sync_timestamp, 1234567890);\n        assert_eq!(deserialized.local_version, 5);\n        assert_eq!(deserialized.remote_version, 3);\n        assert_eq!(deserialized.pending_changes.len(), 1);\n    }\n\n    #[tokio::test]\n    async fn test_multiple_queued_changes() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine);\n\n        for i in 0..5 {\n            client\n                .queue_local_change(PendingChange {\n                    id: format!(\"change-{}\", i),\n                    change_type: ChangeType::PolicyUpdate,\n                    data: serde_json::json!({\"index\": i}),\n                    created_at: chrono::Utc::now().timestamp(),\n                })\n                .await;\n        }\n\n        let state = client.get_sync_state().await;\n        assert_eq!(state.pending_changes.len(), 5);\n    }\n\n    #[tokio::test]\n    async fn test_sync_pending_changes_empty() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine);\n\n        let ctx = test_tenant_context();\n        let synced = client.sync_pending_changes(\u0026ctx).await.unwrap();\n\n        assert_eq!(synced, 0);\n    }\n\n    #[tokio::test]\n    async fn test_cache_key_with_custom_context() {\n        let tenant_id = TenantId::new(\"acme-corp\".to_string()).unwrap();\n        let user_id = UserId::new(\"john-doe\".to_string()).unwrap();\n        let ctx = TenantContext::new(tenant_id, user_id);\n\n        let key = HybridGovernanceClient::cache_key(\u0026ctx, \"proposals\");\n        assert_eq!(key, \"acme-corp:john-doe:proposals\");\n    }\n\n    #[test]\n    fn test_change_type_serialization() {\n        let policy = ChangeType::PolicyUpdate;\n        let drift = ChangeType::DriftResult;\n        let proposal = ChangeType::ProposalAction;\n\n        let policy_json = serde_json::to_string(\u0026policy).unwrap();\n        let drift_json = serde_json::to_string(\u0026drift).unwrap();\n        let proposal_json = serde_json::to_string(\u0026proposal).unwrap();\n\n        assert_eq!(policy_json, \"\\\"PolicyUpdate\\\"\");\n        assert_eq!(drift_json, \"\\\"DriftResult\\\"\");\n        assert_eq!(proposal_json, \"\\\"ProposalAction\\\"\");\n\n        let deserialized: ChangeType = serde_json::from_str(\u0026policy_json).unwrap();\n        assert_eq!(deserialized, ChangeType::PolicyUpdate);\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_client_builder_chain() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine)\n            .with_cache_ttl(Duration::from_secs(600))\n            .with_sync_interval(Duration::from_secs(120));\n\n        assert_eq!(client.cache_ttl, Duration::from_secs(600));\n        assert_eq!(client.sync_interval, Duration::from_secs(120));\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_validate_returns_valid_result() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://localhost:8080\".to_string(), engine);\n\n        let ctx = test_tenant_context();\n        let context = HashMap::new();\n\n        let result = client\n            .validate(\u0026ctx, KnowledgeLayer::Project, \u0026context)\n            .await\n            .unwrap();\n\n        assert!(result.is_valid);\n        assert!(result.violations.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_list_proposals_with_layer_filter() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = HybridGovernanceClient::new(\"http://invalid-host:9999\".to_string(), engine);\n\n        let ctx = test_tenant_context();\n        let result = client\n            .list_proposals(\u0026ctx, Some(KnowledgeLayer::Company))\n            .await;\n\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_local_client_construction() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let _client = LocalGovernanceClient::new(engine);\n    }\n\n    #[tokio::test]\n    async fn test_local_client_validate() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = LocalGovernanceClient::new(engine);\n\n        let ctx = test_tenant_context();\n        let context = HashMap::new();\n\n        let result = client\n            .validate(\u0026ctx, KnowledgeLayer::Project, \u0026context)\n            .await;\n        assert!(result.is_ok());\n        assert!(result.unwrap().is_valid);\n    }\n\n    #[tokio::test]\n    async fn test_local_client_get_drift_status_no_storage() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = LocalGovernanceClient::new(engine);\n\n        let ctx = test_tenant_context();\n        let result = client.get_drift_status(\u0026ctx, \"proj-1\").await;\n\n        assert!(result.is_ok());\n        assert!(result.unwrap().is_none());\n    }\n\n    #[tokio::test]\n    async fn test_local_client_list_proposals_no_repo() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = LocalGovernanceClient::new(engine);\n\n        let ctx = test_tenant_context();\n        let result = client.list_proposals(\u0026ctx, None).await;\n\n        assert!(result.is_ok());\n        assert!(result.unwrap().is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_local_client_replay_events_no_storage() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client = LocalGovernanceClient::new(engine);\n\n        let ctx = test_tenant_context();\n        let result = client.replay_events(\u0026ctx, 0, 100).await;\n\n        assert!(result.is_ok());\n        assert!(result.unwrap().is_empty());\n    }\n\n    #[test]\n    fn test_create_governance_client_local_mode() {\n        let config = config::DeploymentConfig {\n            mode: \"local\".to_string(),\n            remote_url: None,\n            sync_enabled: true,\n        };\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n\n        let result = create_governance_client(\u0026config, Some(engine));\n        assert!(result.is_ok());\n        assert!(matches!(result.unwrap(), GovernanceClientKind::Local(_)));\n    }\n\n    #[test]\n    fn test_create_governance_client_local_mode_requires_engine() {\n        let config = config::DeploymentConfig {\n            mode: \"local\".to_string(),\n            remote_url: None,\n            sync_enabled: true,\n        };\n\n        let result = create_governance_client(\u0026config, None);\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Local mode requires\")\n        );\n    }\n\n    #[test]\n    fn test_create_governance_client_hybrid_mode() {\n        let config = config::DeploymentConfig {\n            mode: \"hybrid\".to_string(),\n            remote_url: Some(\"http://localhost:8080\".to_string()),\n            sync_enabled: true,\n        };\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n\n        let result = create_governance_client(\u0026config, Some(engine));\n        assert!(result.is_ok());\n        assert!(matches!(result.unwrap(), GovernanceClientKind::Hybrid(_)));\n    }\n\n    #[test]\n    fn test_create_governance_client_hybrid_mode_requires_engine() {\n        let config = config::DeploymentConfig {\n            mode: \"hybrid\".to_string(),\n            remote_url: Some(\"http://localhost:8080\".to_string()),\n            sync_enabled: true,\n        };\n\n        let result = create_governance_client(\u0026config, None);\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Hybrid mode requires a GovernanceEngine\")\n        );\n    }\n\n    #[test]\n    fn test_create_governance_client_hybrid_mode_requires_url() {\n        let config = config::DeploymentConfig {\n            mode: \"hybrid\".to_string(),\n            remote_url: None,\n            sync_enabled: true,\n        };\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n\n        let result = create_governance_client(\u0026config, Some(engine));\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Hybrid mode requires a remote_url\")\n        );\n    }\n\n    #[test]\n    fn test_create_governance_client_remote_mode() {\n        let config = config::DeploymentConfig {\n            mode: \"remote\".to_string(),\n            remote_url: Some(\"http://localhost:8080\".to_string()),\n            sync_enabled: false,\n        };\n\n        let result = create_governance_client(\u0026config, None);\n        assert!(result.is_ok());\n        assert!(matches!(result.unwrap(), GovernanceClientKind::Remote(_)));\n    }\n\n    #[test]\n    fn test_create_governance_client_remote_mode_requires_url() {\n        let config = config::DeploymentConfig {\n            mode: \"remote\".to_string(),\n            remote_url: None,\n            sync_enabled: false,\n        };\n\n        let result = create_governance_client(\u0026config, None);\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Remote mode requires a remote_url\")\n        );\n    }\n\n    #[test]\n    fn test_create_governance_client_invalid_mode() {\n        let config = config::DeploymentConfig {\n            mode: \"invalid\".to_string(),\n            remote_url: None,\n            sync_enabled: true,\n        };\n\n        let result = create_governance_client(\u0026config, None);\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Invalid deployment mode\")\n        );\n    }\n\n    #[test]\n    fn test_governance_client_kind_as_client_local() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client_kind = GovernanceClientKind::Local(LocalGovernanceClient::new(engine));\n        let _client: \u0026dyn GovernanceClient = client_kind.as_client();\n    }\n\n    #[test]\n    fn test_governance_client_kind_as_client_hybrid() {\n        let engine = Arc::new(crate::governance::GovernanceEngine::new());\n        let client_kind = GovernanceClientKind::Hybrid(HybridGovernanceClient::new(\n            \"http://localhost:8080\".to_string(),\n            engine,\n        ));\n        let _client: \u0026dyn GovernanceClient = client_kind.as_client();\n    }\n\n    #[test]\n    fn test_governance_client_kind_as_client_remote() {\n        let client_kind = GovernanceClientKind::Remote(RemoteGovernanceClient::new(\n            \"http://localhost:8080\".to_string(),\n        ));\n        let _client: \u0026dyn GovernanceClient = client_kind.as_client();\n    }\n}\n","traces":[{"line":38,"address":[],"length":0,"stats":{"Line":16}},{"line":43,"address":[],"length":0,"stats":{"Line":16}},{"line":71,"address":[],"length":0,"stats":{"Line":2}},{"line":74,"address":[],"length":0,"stats":{"Line":2}},{"line":79,"address":[],"length":0,"stats":{"Line":3}},{"line":80,"address":[],"length":0,"stats":{"Line":3}},{"line":119,"address":[],"length":0,"stats":{"Line":18}},{"line":121,"address":[],"length":0,"stats":{"Line":18}},{"line":142,"address":[],"length":0,"stats":{"Line":16}},{"line":144,"address":[],"length":0,"stats":{"Line":16}},{"line":151,"address":[],"length":0,"stats":{"Line":15}},{"line":153,"address":[],"length":0,"stats":{"Line":45}},{"line":155,"address":[],"length":0,"stats":{"Line":60}},{"line":156,"address":[],"length":0,"stats":{"Line":60}},{"line":157,"address":[],"length":0,"stats":{"Line":15}},{"line":158,"address":[],"length":0,"stats":{"Line":15}},{"line":162,"address":[],"length":0,"stats":{"Line":2}},{"line":163,"address":[],"length":0,"stats":{"Line":2}},{"line":164,"address":[],"length":0,"stats":{"Line":2}},{"line":167,"address":[],"length":0,"stats":{"Line":2}},{"line":168,"address":[],"length":0,"stats":{"Line":2}},{"line":169,"address":[],"length":0,"stats":{"Line":2}},{"line":172,"address":[],"length":0,"stats":{"Line":3}},{"line":173,"address":[],"length":0,"stats":{"Line":3}},{"line":175,"address":[],"length":0,"stats":{"Line":6}},{"line":176,"address":[],"length":0,"stats":{"Line":6}},{"line":181,"address":[],"length":0,"stats":{"Line":2}},{"line":182,"address":[],"length":0,"stats":{"Line":2}},{"line":183,"address":[],"length":0,"stats":{"Line":3}},{"line":184,"address":[],"length":0,"stats":{"Line":2}},{"line":186,"address":[],"length":0,"stats":{"Line":1}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":1}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":1}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":225,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":235,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":240,"address":[],"length":0,"stats":{"Line":0}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":16}},{"line":250,"address":[],"length":0,"stats":{"Line":16}},{"line":251,"address":[],"length":0,"stats":{"Line":24}},{"line":254,"address":[],"length":0,"stats":{"Line":8}},{"line":255,"address":[],"length":0,"stats":{"Line":12}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":388,"address":[],"length":0,"stats":{"Line":0}},{"line":389,"address":[],"length":0,"stats":{"Line":0}},{"line":390,"address":[],"length":0,"stats":{"Line":0}},{"line":391,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":0}},{"line":398,"address":[],"length":0,"stats":{"Line":3}},{"line":399,"address":[],"length":0,"stats":{"Line":3}},{"line":400,"address":[],"length":0,"stats":{"Line":2}},{"line":401,"address":[],"length":0,"stats":{"Line":2}},{"line":402,"address":[],"length":0,"stats":{"Line":2}},{"line":407,"address":[],"length":0,"stats":{"Line":8}},{"line":411,"address":[],"length":0,"stats":{"Line":8}},{"line":412,"address":[],"length":0,"stats":{"Line":8}},{"line":413,"address":[],"length":0,"stats":{"Line":6}},{"line":414,"address":[],"length":0,"stats":{"Line":1}},{"line":415,"address":[],"length":0,"stats":{"Line":1}},{"line":418,"address":[],"length":0,"stats":{"Line":1}},{"line":419,"address":[],"length":0,"stats":{"Line":1}},{"line":422,"address":[],"length":0,"stats":{"Line":6}},{"line":423,"address":[],"length":0,"stats":{"Line":9}},{"line":424,"address":[],"length":0,"stats":{"Line":1}},{"line":425,"address":[],"length":0,"stats":{"Line":1}},{"line":428,"address":[],"length":0,"stats":{"Line":8}},{"line":429,"address":[],"length":0,"stats":{"Line":1}},{"line":430,"address":[],"length":0,"stats":{"Line":1}},{"line":433,"address":[],"length":0,"stats":{"Line":2}},{"line":434,"address":[],"length":0,"stats":{"Line":1}},{"line":437,"address":[],"length":0,"stats":{"Line":3}},{"line":438,"address":[],"length":0,"stats":{"Line":8}},{"line":439,"address":[],"length":0,"stats":{"Line":1}},{"line":440,"address":[],"length":0,"stats":{"Line":1}},{"line":443,"address":[],"length":0,"stats":{"Line":1}},{"line":444,"address":[],"length":0,"stats":{"Line":1}},{"line":447,"address":[],"length":0,"stats":{"Line":2}},{"line":448,"address":[],"length":0,"stats":{"Line":1}},{"line":449,"address":[],"length":0,"stats":{"Line":1}},{"line":463,"address":[],"length":0,"stats":{"Line":7}}],"covered":70,"coverable":100},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","hot_reload.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","lib.rs"],"content":"//! # Knowledge Repository\n//!\n//! Git-based knowledge management with governance.\n\npub mod api;\npub mod federation;\npub mod governance;\npub mod governance_client;\npub mod repository;\npub mod scheduler;\npub mod telemetry;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","loader.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","opencode.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","pointer.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","pool.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","postgres.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","procedural.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","providers.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","qdrant.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","redis.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","repository.rs"],"content":"use async_trait::async_trait;\nuse git2::{Repository, Signature};\nuse mk_core::traits::KnowledgeRepository;\nuse mk_core::types::{KnowledgeEntry, KnowledgeLayer, KnowledgeType};\nuse std::path::PathBuf;\nuse thiserror::Error;\nuse walkdir::WalkDir;\n\n#[derive(Error, Debug)]\npub enum RepositoryError {\n    #[error(\"Git error: {0}\")]\n    Git(#[from] git2::Error),\n    #[error(\"IO error: {0}\")]\n    Io(#[from] std::io::Error),\n    #[error(\"Invalid path: {0}\")]\n    InvalidPath(String),\n    #[error(\"Serialization error: {0}\")]\n    Serialization(#[from] serde_json::Error),\n}\n\npub struct GitRepository {\n    root_path: PathBuf,\n}\n\nimpl GitRepository {\n    pub fn new(root_path: impl Into\u003cPathBuf\u003e) -\u003e Result\u003cSelf, RepositoryError\u003e {\n        let root_path = root_path.into();\n        if !root_path.exists() {\n            std::fs::create_dir_all(\u0026root_path)?;\n        }\n\n        if Repository::open(\u0026root_path).is_err() {\n            Repository::init(\u0026root_path)?;\n        }\n\n        Ok(Self { root_path })\n    }\n\n    fn resolve_path(\n        \u0026self,\n        ctx: \u0026mk_core::types::TenantContext,\n        layer: KnowledgeLayer,\n        path: \u0026str,\n    ) -\u003e PathBuf {\n        let layer_dir = match layer {\n            KnowledgeLayer::Company =\u003e \"company\",\n            KnowledgeLayer::Org =\u003e \"org\",\n            KnowledgeLayer::Team =\u003e \"team\",\n            KnowledgeLayer::Project =\u003e \"project\",\n        };\n        self.root_path\n            .join(ctx.tenant_id.as_str())\n            .join(layer_dir)\n            .join(path)\n    }\n\n    pub fn commit(\u0026self, message: \u0026str) -\u003e Result\u003cString, RepositoryError\u003e {\n        let span = tracing::info_span!(\"knowledge_commit\", message = %message);\n        let _enter = span.enter();\n\n        let repo = Repository::open(\u0026self.root_path)?;\n        let mut index = repo.index()?;\n        index.add_all([\"*\"].iter(), git2::IndexAddOption::DEFAULT, None)?;\n        index.write()?;\n\n        let tree_id = index.write_tree()?;\n        let tree = repo.find_tree(tree_id)?;\n\n        let sig = repo\n            .signature()\n            .or_else(|_| Signature::now(\"Aeterna\", \"system@aeterna.ai\"))?;\n\n        let parent_commit = match repo.head() {\n            Ok(head) =\u003e Some(head.peel_to_commit()?),\n            Err(_) =\u003e None,\n        };\n\n        let parents = match \u0026parent_commit {\n            Some(c) =\u003e vec![c],\n            None =\u003e vec![],\n        };\n\n        let commit_id = repo.commit(Some(\"HEAD\"), \u0026sig, \u0026sig, message, \u0026tree, \u0026parents)?;\n\n        Ok(commit_id.to_string())\n    }\n\n    pub fn get_head_commit_sync(\u0026self) -\u003e Result\u003cOption\u003cString\u003e, RepositoryError\u003e {\n        let repo = Repository::open(\u0026self.root_path)?;\n        match repo.head() {\n            Ok(head) =\u003e Ok(Some(head.peel_to_commit()?.id().to_string())),\n            Err(_) =\u003e Ok(None),\n        }\n    }\n\n    pub fn root_path(\u0026self) -\u003e \u0026std::path::Path {\n        \u0026self.root_path\n    }\n\n    pub async fn get_by_path(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        path: \u0026str,\n    ) -\u003e Result\u003cOption\u003cKnowledgeEntry\u003e, RepositoryError\u003e {\n        for layer in [\n            KnowledgeLayer::Company,\n            KnowledgeLayer::Org,\n            KnowledgeLayer::Team,\n            KnowledgeLayer::Project,\n        ] {\n            if let Some(entry) = self.get(ctx.clone(), layer, path).await? {\n                return Ok(Some(entry));\n            }\n        }\n        Ok(None)\n    }\n}\n\n#[async_trait]\nimpl KnowledgeRepository for GitRepository {\n    type Error = RepositoryError;\n\n    async fn get_head_commit(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n    ) -\u003e Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n        self.get_head_commit_sync()\n    }\n\n    async fn get_affected_items(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        since_commit: \u0026str,\n    ) -\u003e Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n        let repo = Repository::open(\u0026self.root_path)?;\n        let from_obj = repo.revparse_single(since_commit)?;\n        let from_commit = from_obj.peel_to_commit()?;\n        let from_tree = from_commit.tree()?;\n\n        let head = repo.head()?.peel_to_commit()?;\n        let head_tree = head.tree()?;\n\n        let diff = repo.diff_tree_to_tree(Some(\u0026from_tree), Some(\u0026head_tree), None)?;\n        let mut affected = Vec::new();\n\n        diff.foreach(\n            \u0026mut |delta, _| {\n                if let Some(path) = delta.new_file().path().and_then(|p| p.to_str()) {\n                    let parts: Vec\u003c\u0026str\u003e = path.split('/').collect();\n                    if parts.len() \u003e= 2 {\n                        let layer = match parts[0] {\n                            \"company\" =\u003e KnowledgeLayer::Company,\n                            \"org\" =\u003e KnowledgeLayer::Org,\n                            \"team\" =\u003e KnowledgeLayer::Team,\n                            \"project\" =\u003e KnowledgeLayer::Project,\n                            _ =\u003e return true,\n                        };\n                        let inner_path = parts[1..].join(\"/\");\n                        affected.push((layer, inner_path));\n                    }\n                }\n                true\n            },\n            None,\n            None,\n            None,\n        )?;\n\n        Ok(affected)\n    }\n\n    async fn get(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        layer: KnowledgeLayer,\n        path: \u0026str,\n    ) -\u003e Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        let full_path = self.resolve_path(\u0026ctx, layer, path);\n        if !full_path.exists() {\n            return Ok(None);\n        }\n\n        let metadata_path = full_path.with_extension(\"metadata.json\");\n\n        let content = tokio::fs::read_to_string(\u0026full_path).await?;\n\n        let commit_hash = {\n            let repo = Repository::open(\u0026self.root_path)?;\n            let mut revwalk = repo.revwalk()?;\n            revwalk.push_head().ok();\n            revwalk.next().transpose()?.map(|id| id.to_string())\n        };\n\n        let (kind, status, metadata, author, updated_at) = if metadata_path.exists() {\n            let meta_content = tokio::fs::read_to_string(\u0026metadata_path).await?;\n            let meta: serde_json::Value = serde_json::from_str(\u0026meta_content)?;\n            (\n                serde_json::from_value(meta[\"kind\"].clone()).unwrap_or(KnowledgeType::Spec),\n                serde_json::from_value(meta[\"status\"].clone())\n                    .unwrap_or(mk_core::types::KnowledgeStatus::Accepted),\n                serde_json::from_value(meta[\"metadata\"].clone()).unwrap_or_default(),\n                serde_json::from_value(meta[\"author\"].clone()).unwrap_or_default(),\n                meta[\"updated_at\"]\n                    .as_i64()\n                    .unwrap_or_else(|| chrono::Utc::now().timestamp()),\n            )\n        } else {\n            (\n                KnowledgeType::Spec,\n                mk_core::types::KnowledgeStatus::Accepted,\n                std::collections::HashMap::new(),\n                None,\n                chrono::Utc::now().timestamp(),\n            )\n        };\n\n        Ok(Some(KnowledgeEntry {\n            path: path.to_string(),\n            content,\n            layer,\n            kind,\n            status,\n            metadata,\n            commit_hash,\n            author,\n            updated_at,\n        }))\n    }\n\n    async fn store(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        entry: KnowledgeEntry,\n        message: \u0026str,\n    ) -\u003e Result\u003cString, Self::Error\u003e {\n        let full_path = self.resolve_path(\u0026ctx, entry.layer, \u0026entry.path);\n        let metadata_path = full_path.with_extension(\"metadata.json\");\n\n        if let Some(parent) = full_path.parent() {\n            tokio::fs::create_dir_all(parent).await?;\n        }\n\n        tokio::fs::write(\u0026full_path, entry.content).await?;\n\n        let meta = serde_json::json!({\n            \"kind\": entry.kind,\n            \"status\": entry.status,\n            \"metadata\": entry.metadata,\n            \"author\": entry.author,\n            \"updated_at\": entry.updated_at,\n        });\n        tokio::fs::write(\u0026metadata_path, serde_json::to_string(\u0026meta)?).await?;\n\n        self.commit(message)\n    }\n\n    async fn list(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        layer: KnowledgeLayer,\n        prefix: \u0026str,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        let tenant_path = self.root_path.join(ctx.tenant_id.as_str());\n        let layer_path = match layer {\n            KnowledgeLayer::Company =\u003e tenant_path.join(\"company\"),\n            KnowledgeLayer::Org =\u003e tenant_path.join(\"org\"),\n            KnowledgeLayer::Team =\u003e tenant_path.join(\"team\"),\n            KnowledgeLayer::Project =\u003e tenant_path.join(\"project\"),\n        };\n\n        if !layer_path.exists() {\n            return Ok(vec![]);\n        }\n\n        let mut entries = Vec::new();\n        for entry in WalkDir::new(\u0026layer_path)\n            .into_iter()\n            .filter_map(|e| e.ok())\n            .filter(|e| {\n                e.file_type().is_file() \u0026\u0026 !e.path().to_string_lossy().ends_with(\".metadata.json\")\n            })\n        {\n            let path = entry.path();\n            let relative_path = path\n                .strip_prefix(\u0026layer_path)\n                .map_err(|_| RepositoryError::InvalidPath(path.to_string_lossy().into_owned()))?;\n\n            if relative_path.to_string_lossy().starts_with(prefix) {\n                if let Some(ke) = self\n                    .get(ctx.clone(), layer, \u0026relative_path.to_string_lossy())\n                    .await?\n                {\n                    entries.push(ke);\n                }\n            }\n        }\n\n        Ok(entries)\n    }\n\n    async fn delete(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        layer: KnowledgeLayer,\n        path: \u0026str,\n        message: \u0026str,\n    ) -\u003e Result\u003cString, Self::Error\u003e {\n        let full_path = self.resolve_path(\u0026ctx, layer, path);\n        let metadata_path = full_path.with_extension(\"metadata.json\");\n\n        if full_path.exists() {\n            tokio::fs::remove_file(full_path).await?;\n            if metadata_path.exists() {\n                tokio::fs::remove_file(metadata_path).await?;\n            }\n            self.commit(message)\n        } else {\n            Ok(String::new())\n        }\n    }\n\n    async fn search(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        query: \u0026str,\n        layers: Vec\u003cKnowledgeLayer\u003e,\n        limit: usize,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        let mut results = Vec::new();\n        for layer in layers {\n            let entries = self.list(ctx.clone(), layer, \"\").await?;\n            for entry in entries {\n                if entry.content.contains(query) || entry.path.contains(query) {\n                    results.push(entry);\n                }\n                if results.len() \u003e= limit {\n                    return Ok(results);\n                }\n            }\n        }\n        Ok(results)\n    }\n\n    fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n        Some(self.root_path.clone())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use tempfile::tempdir;\n\n    #[tokio::test]\n    async fn test_git_repository_lifecycle() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n        let dir = tempdir()?;\n        let repo = GitRepository::new(dir.path())?;\n        let tenant_id = mk_core::types::TenantId::new(\"c1\".into()).unwrap();\n        let user_id = mk_core::types::UserId::new(\"u1\".into()).unwrap();\n        let ctx = mk_core::types::TenantContext::new(tenant_id, user_id);\n\n        let entry = KnowledgeEntry {\n            path: \"test.md\".to_string(),\n            content: \"hello world\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: mk_core::types::KnowledgeStatus::Draft,\n            metadata: std::collections::HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: chrono::Utc::now().timestamp(),\n        };\n\n        repo.store(ctx.clone(), entry.clone(), \"initial commit\")\n            .await?;\n\n        let retrieved = repo\n            .get(ctx.clone(), KnowledgeLayer::Project, \"test.md\")\n            .await?;\n        assert!(retrieved.is_some());\n        let retrieved = retrieved.unwrap();\n        assert_eq!(retrieved.content, \"hello world\");\n        assert_eq!(retrieved.status, mk_core::types::KnowledgeStatus::Draft);\n\n        let list = repo.list(ctx.clone(), KnowledgeLayer::Project, \"\").await?;\n        assert_eq!(list.len(), 1);\n\n        repo.delete(\n            ctx.clone(),\n            KnowledgeLayer::Project,\n            \"test.md\",\n            \"delete file\",\n        )\n        .await?;\n        let after_delete = repo.get(ctx, KnowledgeLayer::Project, \"test.md\").await?;\n        assert!(after_delete.is_none());\n\n        Ok(())\n    }\n\n    #[tokio::test]\n    async fn test_git_repository_isolation() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n        let dir = tempdir()?;\n        let repo = GitRepository::new(dir.path())?;\n\n        let tenant_a = mk_core::types::TenantId::new(\"tenant_a\".into()).unwrap();\n        let user_a = mk_core::types::UserId::new(\"user_a\".into()).unwrap();\n        let ctx_a = mk_core::types::TenantContext::new(tenant_a, user_a);\n\n        let tenant_b = mk_core::types::TenantId::new(\"tenant_b\".into()).unwrap();\n        let user_b = mk_core::types::UserId::new(\"user_b\".into()).unwrap();\n        let ctx_b = mk_core::types::TenantContext::new(tenant_b, user_b);\n\n        let entry = KnowledgeEntry {\n            path: \"secret.md\".to_string(),\n            content: \"tenant a secret\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: mk_core::types::KnowledgeStatus::Accepted,\n            metadata: std::collections::HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: chrono::Utc::now().timestamp(),\n        };\n\n        repo.store(ctx_a.clone(), entry, \"tenant a commit\").await?;\n\n        let retrieved_b = repo\n            .get(ctx_b.clone(), KnowledgeLayer::Project, \"secret.md\")\n            .await?;\n        assert!(\n            retrieved_b.is_none(),\n            \"Tenant B should not see Tenant A data\"\n        );\n\n        let retrieved_a = repo\n            .get(ctx_a.clone(), KnowledgeLayer::Project, \"secret.md\")\n            .await?;\n        assert!(retrieved_a.is_some());\n        assert_eq!(retrieved_a.unwrap().content, \"tenant a secret\");\n\n        let list_b = repo.list(ctx_b, KnowledgeLayer::Project, \"\").await?;\n        assert!(list_b.is_empty(), \"Tenant B list should be empty\");\n\n        let list_a = repo.list(ctx_a, KnowledgeLayer::Project, \"\").await?;\n        assert_eq!(list_a.len(), 1, \"Tenant A should see its entry\");\n\n        Ok(())\n    }\n}\n","traces":[{"line":26,"address":[],"length":0,"stats":{"Line":9}},{"line":27,"address":[],"length":0,"stats":{"Line":27}},{"line":28,"address":[],"length":0,"stats":{"Line":9}},{"line":29,"address":[],"length":0,"stats":{"Line":2}},{"line":32,"address":[],"length":0,"stats":{"Line":18}},{"line":33,"address":[],"length":0,"stats":{"Line":18}},{"line":36,"address":[],"length":0,"stats":{"Line":9}},{"line":39,"address":[],"length":0,"stats":{"Line":32}},{"line":45,"address":[],"length":0,"stats":{"Line":64}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":48,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":32}},{"line":51,"address":[],"length":0,"stats":{"Line":128}},{"line":52,"address":[],"length":0,"stats":{"Line":128}},{"line":53,"address":[],"length":0,"stats":{"Line":64}},{"line":54,"address":[],"length":0,"stats":{"Line":32}},{"line":57,"address":[],"length":0,"stats":{"Line":10}},{"line":58,"address":[],"length":0,"stats":{"Line":20}},{"line":59,"address":[],"length":0,"stats":{"Line":30}},{"line":61,"address":[],"length":0,"stats":{"Line":30}},{"line":62,"address":[],"length":0,"stats":{"Line":30}},{"line":63,"address":[],"length":0,"stats":{"Line":50}},{"line":64,"address":[],"length":0,"stats":{"Line":20}},{"line":66,"address":[],"length":0,"stats":{"Line":30}},{"line":67,"address":[],"length":0,"stats":{"Line":40}},{"line":69,"address":[],"length":0,"stats":{"Line":20}},{"line":71,"address":[],"length":0,"stats":{"Line":10}},{"line":73,"address":[],"length":0,"stats":{"Line":20}},{"line":74,"address":[],"length":0,"stats":{"Line":6}},{"line":75,"address":[],"length":0,"stats":{"Line":8}},{"line":78,"address":[],"length":0,"stats":{"Line":20}},{"line":79,"address":[],"length":0,"stats":{"Line":6}},{"line":80,"address":[],"length":0,"stats":{"Line":8}},{"line":83,"address":[],"length":0,"stats":{"Line":90}},{"line":85,"address":[],"length":0,"stats":{"Line":10}},{"line":88,"address":[],"length":0,"stats":{"Line":8}},{"line":89,"address":[],"length":0,"stats":{"Line":24}},{"line":90,"address":[],"length":0,"stats":{"Line":8}},{"line":91,"address":[],"length":0,"stats":{"Line":40}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":1}},{"line":148,"address":[],"length":0,"stats":{"Line":6}},{"line":149,"address":[],"length":0,"stats":{"Line":5}},{"line":150,"address":[],"length":0,"stats":{"Line":1}},{"line":151,"address":[],"length":0,"stats":{"Line":1}},{"line":152,"address":[],"length":0,"stats":{"Line":1}},{"line":153,"address":[],"length":0,"stats":{"Line":1}},{"line":154,"address":[],"length":0,"stats":{"Line":1}},{"line":155,"address":[],"length":0,"stats":{"Line":1}},{"line":156,"address":[],"length":0,"stats":{"Line":1}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":40}},{"line":242,"address":[],"length":0,"stats":{"Line":36}},{"line":243,"address":[],"length":0,"stats":{"Line":36}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}}],"covered":50,"coverable":71},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","scheduler.rs"],"content":"use crate::governance::GovernanceEngine;\nuse config::config::DeploymentConfig;\nuse mk_core::traits::KnowledgeRepository;\nuse mk_core::types::{DriftResult, KnowledgeLayer, TenantContext, UnitType, UserId};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse std::time::Duration;\nuse tokio::time;\n\npub struct GovernanceScheduler {\n    engine: Arc\u003cGovernanceEngine\u003e,\n    repository: Arc\u003cdyn KnowledgeRepository\u003cError = crate::repository::RepositoryError\u003e\u003e,\n    deployment_config: DeploymentConfig,\n    quick_scan_interval: Duration,\n    semantic_scan_interval: Duration,\n    report_interval: Duration,\n}\n\nimpl GovernanceScheduler {\n    pub fn new(\n        engine: Arc\u003cGovernanceEngine\u003e,\n        repository: Arc\u003cdyn KnowledgeRepository\u003cError = crate::repository::RepositoryError\u003e\u003e,\n        deployment_config: DeploymentConfig,\n        quick_scan_interval: Duration,\n        semantic_scan_interval: Duration,\n        report_interval: Duration,\n    ) -\u003e Self {\n        Self {\n            engine,\n            repository,\n            deployment_config,\n            quick_scan_interval,\n            semantic_scan_interval,\n            report_interval,\n        }\n    }\n\n    pub async fn start(\u0026self) {\n        if self.deployment_config.mode == \"remote\" {\n            tracing::info!(\"Governance scheduler disabled in Remote mode\");\n            return;\n        }\n\n        let mut quick_interval = time::interval(self.quick_scan_interval);\n        let mut semantic_interval = time::interval(self.semantic_scan_interval);\n        let mut report_interval = time::interval(self.report_interval);\n\n        loop {\n            tokio::select! {\n                _ = quick_interval.tick() =\u003e {\n                    let _ = self.run_job(\"quick_drift_scan\", \"all\", self.run_batch_drift_scan()).await;\n                }\n                _ = semantic_interval.tick() =\u003e {\n                    if self.deployment_config.mode != \"hybrid\" {\n                        let _ = self.run_job(\"semantic_analysis\", \"all\", self.run_semantic_analysis_job()).await;\n                    } else {\n                        tracing::debug!(\"Skipping local semantic analysis in Hybrid mode (relying on remote)\");\n                    }\n                }\n                _ = report_interval.tick() =\u003e {\n                    if self.deployment_config.mode == \"local\" {\n                        let _ = self.run_job(\"weekly_report\", \"all\", self.run_weekly_report_job()).await;\n                    }\n                }\n            }\n        }\n    }\n\n    async fn run_job\u003cF\u003e(\u0026self, name: \u0026str, tenant_id: \u0026str, job_future: F) -\u003e anyhow::Result\u003c()\u003e\n    where\n        F: std::future::Future\u003cOutput = anyhow::Result\u003c()\u003e\u003e,\n    {\n        let started_at = chrono::Utc::now().timestamp();\n        tracing::info!(\"Starting job: {}\", name);\n\n        let storage = self\n            .engine\n            .storage()\n            .ok_or_else(|| anyhow::anyhow!(\"Storage not configured\"))?;\n\n        let _ = storage\n            .record_job_status(name, tenant_id, \"running\", None, started_at, None)\n            .await;\n\n        match job_future.await {\n            Ok(_) =\u003e {\n                let finished_at = chrono::Utc::now().timestamp();\n                let _ = storage\n                    .record_job_status(\n                        name,\n                        tenant_id,\n                        \"completed\",\n                        None,\n                        started_at,\n                        Some(finished_at),\n                    )\n                    .await;\n                Ok(())\n            }\n            Err(e) =\u003e {\n                let finished_at = chrono::Utc::now().timestamp();\n                let message = format!(\"{:?}\", e);\n                let _ = storage\n                    .record_job_status(\n                        name,\n                        tenant_id,\n                        \"failed\",\n                        Some(\u0026message),\n                        started_at,\n                        Some(finished_at),\n                    )\n                    .await;\n                Err(e)\n            }\n        }\n    }\n\n    async fn run_batch_drift_scan(\u0026self) -\u003e anyhow::Result\u003c()\u003e {\n        tracing::info!(\"Starting batch drift scan\");\n\n        let storage = self\n            .engine\n            .storage()\n            .ok_or_else(|| anyhow::anyhow!(\"Storage not configured\"))?;\n        let units = storage\n            .list_all_units()\n            .await\n            .map_err(|e| anyhow::anyhow!(\"Failed to list units: {:?}\", e))?;\n\n        for unit in units {\n            if unit.unit_type == UnitType::Project {\n                let tenant_ctx =\n                    TenantContext::new(unit.tenant_id.clone(), mk_core::types::UserId::default());\n                let mut context = HashMap::new();\n                context.insert(\"projectId\".to_string(), serde_json::json!(unit.id));\n                context.insert(\"content\".to_string(), serde_json::json!(\"\"));\n\n                let _ = self\n                    .engine\n                    .check_drift(\u0026tenant_ctx, \u0026unit.id, \u0026context)\n                    .await;\n            }\n        }\n\n        Ok(())\n    }\n\n    async fn run_semantic_analysis_job(\u0026self) -\u003e anyhow::Result\u003c()\u003e {\n        tracing::info!(\"Starting daily semantic analysis job\");\n\n        let llm = self\n            .engine\n            .llm_service()\n            .ok_or_else(|| anyhow::anyhow!(\"LLM service not configured\"))?;\n\n        let storage = self\n            .engine\n            .storage()\n            .ok_or_else(|| anyhow::anyhow!(\"Storage not configured\"))?;\n\n        let units = storage\n            .list_all_units()\n            .await\n            .map_err(|e| anyhow::anyhow!(\"Failed to list units: {:?}\", e))?;\n\n        for unit in units {\n            if unit.unit_type == UnitType::Project {\n                let ctx = TenantContext::new(unit.tenant_id.clone(), UserId::default());\n\n                let policies = storage\n                    .get_unit_policies(ctx.clone(), \u0026unit.id)\n                    .await\n                    .map_err(|e| anyhow::anyhow!(\"Failed to fetch policies: {:?}\", e))?;\n\n                if policies.is_empty() {\n                    continue;\n                }\n\n                let entries = self\n                    .repository\n                    .list(ctx.clone(), KnowledgeLayer::Project, \"\")\n                    .await\n                    .map_err(|e| anyhow::anyhow!(\"Failed to list project files: {:?}\", e))?;\n\n                let content = entries\n                    .into_iter()\n                    .map(|e| format!(\"File: {}\\n---\\n{}\\n---\", e.path, e.content))\n                    .collect::\u003cVec\u003c_\u003e\u003e()\n                    .join(\"\\n\\n\");\n\n                if content.is_empty() {\n                    continue;\n                }\n\n                match llm.analyze_drift(\u0026content, \u0026policies).await {\n                    Ok(result) =\u003e {\n                        let drift_score = if result.is_valid { 0.0 } else { 1.0 };\n                        let _ = storage\n                            .store_drift_result(DriftResult {\n                                project_id: unit.id.clone(),\n                                tenant_id: unit.tenant_id.clone(),\n                                drift_score,\n                                violations: result.violations,\n                                timestamp: chrono::Utc::now().timestamp(),\n                            })\n                            .await;\n                    }\n                    Err(e) =\u003e {\n                        tracing::error!(\n                            \"Semantic analysis failed for project {}: {:?}\",\n                            unit.id,\n                            e\n                        );\n                    }\n                }\n            }\n        }\n\n        Ok(())\n    }\n\n    async fn run_weekly_report_job(\u0026self) -\u003e anyhow::Result\u003c()\u003e {\n        tracing::info!(\"Starting weekly governance report job\");\n\n        let storage = self\n            .engine\n            .storage()\n            .ok_or_else(|| anyhow::anyhow!(\"Storage not configured\"))?;\n\n        let units = storage\n            .list_all_units()\n            .await\n            .map_err(|e| anyhow::anyhow!(\"Failed to list units: {:?}\", e))?;\n\n        let now = chrono::Utc::now().timestamp();\n        let one_week_ago = now - (7 * 24 * 60 * 60);\n\n        for unit in units {\n            if unit.unit_type == UnitType::Organization {\n                let mut report_data = HashMap::new();\n                let children = storage\n                    .get_descendants(\n                        TenantContext::new(unit.tenant_id.clone(), UserId::default()),\n                        \u0026unit.id,\n                    )\n                    .await\n                    .map_err(|e| anyhow::anyhow!(\"Failed to list projects: {:?}\", e))?;\n\n                let mut total_drift = 0.0;\n                let mut project_count = 0;\n                let mut all_violations = Vec::new();\n\n                for child in children {\n                    if child.unit_type == UnitType::Project {\n                        if let Some(result) = storage\n                            .get_latest_drift_result(\n                                TenantContext::new(child.tenant_id.clone(), UserId::default()),\n                                \u0026child.id,\n                            )\n                            .await\n                            .map_err(|e| anyhow::anyhow!(\"Failed to fetch drift: {:?}\", e))?\n                        {\n                            if result.timestamp \u003e= one_week_ago {\n                                total_drift += result.drift_score;\n                                project_count += 1;\n                                all_violations.extend(result.violations);\n                            }\n                        }\n                    }\n                }\n\n                let avg_drift = if project_count \u003e 0 {\n                    total_drift / project_count as f32\n                } else {\n                    0.0\n                };\n\n                report_data.insert(\"average_drift\".to_string(), serde_json::json!(avg_drift));\n                report_data.insert(\n                    \"project_count\".to_string(),\n                    serde_json::json!(project_count),\n                );\n                report_data.insert(\n                    \"violation_count\".to_string(),\n                    serde_json::json!(all_violations.len()),\n                );\n\n                tracing::info!(\n                    \"Weekly report for Org {}: Avg Drift: {}, Projects: {}, Violations: {}\",\n                    unit.id,\n                    avg_drift,\n                    project_count,\n                    all_violations.len()\n                );\n            }\n        }\n\n        Ok(())\n    }\n}\n","traces":[{"line":20,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":201,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":204,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":223,"address":[],"length":0,"stats":{"Line":0}},{"line":225,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":235,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":240,"address":[],"length":0,"stats":{"Line":0}},{"line":241,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":0}},{"line":254,"address":[],"length":0,"stats":{"Line":0}},{"line":255,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":264,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":272,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":284,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":298,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":159},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","state.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","telemetry.rs"],"content":"use metrics::increment_counter;\n\npub struct KnowledgeTelemetry;\n\nimpl KnowledgeTelemetry {\n    pub fn record_operation(\u0026self, operation: \u0026str, status: \u0026str) {\n        // GIVEN an operation and status\n        // WHEN recording metrics\n        // THEN increment the operation counter with status label\n\n        increment_counter!(\"knowledge_operations_total\", \"operation\" =\u003e operation.to_string(), \"status\" =\u003e status.to_string());\n    }\n\n    pub fn record_violation(\u0026self, layer: \u0026str, severity: \u0026str) {\n        // GIVEN a layer and severity\n        // WHEN recording metrics\n        // THEN increment the violation counter with layer and severity labels\n\n        increment_counter!(\"knowledge_violations_total\", \"layer\" =\u003e layer.to_string(), \"severity\" =\u003e severity.to_string());\n    }\n}\n","traces":[{"line":6,"address":[],"length":0,"stats":{"Line":0}},{"line":11,"address":[],"length":0,"stats":{"Line":0}},{"line":14,"address":[],"length":0,"stats":{"Line":25}},{"line":19,"address":[],"length":0,"stats":{"Line":25}}],"covered":2,"coverable":4},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","tools.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","validator.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","src","working.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","tests","drift_detection_test.rs"],"content":"//! Tests for drift detection accuracy in the GovernanceEngine.\n//!\n//! These tests verify:\n//! - Drift score calculation based on violation severity\n//! - Missing mandatory policies detection\n//! - Stale policy version detection\n//! - Semantic contradiction detection\n//! - Edge cases and boundary conditions\n\nuse knowledge::governance::GovernanceEngine;\nuse mk_core::types::{\n    ConstraintOperator, ConstraintSeverity, ConstraintTarget, KnowledgeLayer, Policy, PolicyMode,\n    PolicyRule, RuleMergeStrategy, RuleType, TenantContext, TenantId, UserId,\n};\nuse std::collections::HashMap;\nuse std::sync::Arc;\n\nfn create_test_context() -\u003e TenantContext {\n    TenantContext::new(\n        TenantId::new(\"test-tenant\".to_string()).unwrap(),\n        UserId::new(\"test-user\".to_string()).unwrap(),\n    )\n}\n\nfn create_mandatory_policy(id: \u0026str, rules: Vec\u003cPolicyRule\u003e) -\u003e Policy {\n    Policy {\n        id: id.to_string(),\n        name: format!(\"Policy {}\", id),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules,\n        metadata: HashMap::new(),\n    }\n}\n\nfn create_advisory_policy(id: \u0026str, rules: Vec\u003cPolicyRule\u003e) -\u003e Policy {\n    Policy {\n        id: id.to_string(),\n        name: format!(\"Policy {}\", id),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules,\n        metadata: HashMap::new(),\n    }\n}\n\n#[tokio::test]\nasync fn test_drift_score_zero_when_no_violations() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"valid-policy\",\n        vec![PolicyRule {\n            id: \"rule-1\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::File,\n            operator: ConstraintOperator::MustExist,\n            value: serde_json::json!(null),\n            severity: ConstraintSeverity::Block,\n            message: \"File must exist\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"path\".to_string(), serde_json::json!(\"/src/main.rs\"));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(\n        drift_score, 0.0,\n        \"No violations should yield drift score of 0.0\"\n    );\n}\n\n#[tokio::test]\nasync fn test_drift_score_block_severity_yields_one() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"blocking-policy\",\n        vec![PolicyRule {\n            id: \"block-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"required-lib\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Required library missing\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([\"other-lib\"]));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(\n        drift_score, 1.0,\n        \"Block severity violation should yield drift score of 1.0\"\n    );\n}\n\n#[tokio::test]\nasync fn test_drift_score_warn_severity_yields_half() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"warning-policy\",\n        vec![PolicyRule {\n            id: \"warn-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"recommended-lib\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Recommended library missing\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([\"other-lib\"]));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(\n        drift_score, 0.5,\n        \"Warn severity violation should yield drift score of 0.5\"\n    );\n}\n\n#[tokio::test]\nasync fn test_drift_score_info_severity_yields_point_one() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"info-policy\",\n        vec![PolicyRule {\n            id: \"info-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"optional-lib\"),\n            severity: ConstraintSeverity::Info,\n            message: \"Optional library missing\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([\"other-lib\"]));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert!(\n        (drift_score - 0.1).abs() \u003c 0.01,\n        \"Info severity violation should yield drift score of ~0.1\"\n    );\n}\n\n#[tokio::test]\nasync fn test_drift_score_capped_at_one() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"multi-violation-policy\",\n        vec![\n            PolicyRule {\n                id: \"block-1\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Dependency,\n                operator: ConstraintOperator::MustUse,\n                value: serde_json::json!(\"lib-1\"),\n                severity: ConstraintSeverity::Block,\n                message: \"Missing lib-1\".to_string(),\n            },\n            PolicyRule {\n                id: \"block-2\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Dependency,\n                operator: ConstraintOperator::MustUse,\n                value: serde_json::json!(\"lib-2\"),\n                severity: ConstraintSeverity::Block,\n                message: \"Missing lib-2\".to_string(),\n            },\n            PolicyRule {\n                id: \"block-3\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Dependency,\n                operator: ConstraintOperator::MustUse,\n                value: serde_json::json!(\"lib-3\"),\n                severity: ConstraintSeverity::Block,\n                message: \"Missing lib-3\".to_string(),\n            },\n        ],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([]));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(\n        drift_score, 1.0,\n        \"Drift score should be capped at 1.0 even with multiple Block violations\"\n    );\n}\n\n#[tokio::test]\nasync fn test_drift_score_mixed_severities() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"mixed-policy\",\n        vec![\n            PolicyRule {\n                id: \"warn-rule\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Dependency,\n                operator: ConstraintOperator::MustUse,\n                value: serde_json::json!(\"warn-lib\"),\n                severity: ConstraintSeverity::Warn,\n                message: \"Missing warn-lib\".to_string(),\n            },\n            PolicyRule {\n                id: \"info-rule\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Dependency,\n                operator: ConstraintOperator::MustUse,\n                value: serde_json::json!(\"info-lib\"),\n                severity: ConstraintSeverity::Info,\n                message: \"Missing info-lib\".to_string(),\n            },\n        ],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([]));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert!(\n        (drift_score - 0.6).abs() \u003c 0.01,\n        \"Warn (0.5) + Info (0.1) should yield ~0.6\"\n    );\n}\n\n#[tokio::test]\nasync fn test_missing_mandatory_policies_detection() {\n    let engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let context: HashMap\u003cString, serde_json::Value\u003e = HashMap::new();\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n\n    assert!(\n        drift_score \u003e 0.0,\n        \"Missing mandatory policies should trigger drift\"\n    );\n    assert!(\n        drift_score \u003c= 0.5,\n        \"Missing mandatory policies is a Warn severity (0.5)\"\n    );\n}\n\n#[tokio::test]\nasync fn test_stale_policy_version_detection() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let mut metadata = HashMap::new();\n    metadata.insert(\"version_hash\".to_string(), serde_json::json!(\"v2.0.0\"));\n\n    let policy = Policy {\n        id: \"versioned-policy\".to_string(),\n        name: \"Versioned Policy\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Project,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![],\n        metadata,\n    };\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"version_hash\".to_string(), serde_json::json!(\"v1.0.0\"));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert!(\n        drift_score \u003e 0.0,\n        \"Stale policy version should trigger drift\"\n    );\n}\n\n#[tokio::test]\nasync fn test_no_stale_policy_when_versions_match() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let mut metadata = HashMap::new();\n    metadata.insert(\"version_hash\".to_string(), serde_json::json!(\"v2.0.0\"));\n\n    let policy = Policy {\n        id: \"versioned-policy\".to_string(),\n        name: \"Versioned Policy\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Project,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![],\n        metadata,\n    };\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"version_hash\".to_string(), serde_json::json!(\"v2.0.0\"));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(\n        drift_score, 0.0,\n        \"Matching versions should not trigger drift\"\n    );\n}\n\n#[tokio::test]\nasync fn test_advisory_policies_dont_count_as_mandatory() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_advisory_policy(\n        \"advisory-only\",\n        vec![PolicyRule {\n            id: \"advisory-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::File,\n            operator: ConstraintOperator::MustExist,\n            value: serde_json::json!(null),\n            severity: ConstraintSeverity::Info,\n            message: \"Advisory check\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"path\".to_string(), serde_json::json!(\"/src/main.rs\"));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert!(\n        drift_score \u003e 0.0,\n        \"Only advisory policies should still trigger missing mandatory drift\"\n    );\n}\n\n#[tokio::test]\nasync fn test_multiple_policies_accumulate_violations() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy1 = create_mandatory_policy(\n        \"policy-1\",\n        vec![PolicyRule {\n            id: \"rule-1\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"lib-a\"),\n            severity: ConstraintSeverity::Info,\n            message: \"Missing lib-a\".to_string(),\n        }],\n    );\n\n    let policy2 = create_mandatory_policy(\n        \"policy-2\",\n        vec![PolicyRule {\n            id: \"rule-2\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"lib-b\"),\n            severity: ConstraintSeverity::Info,\n            message: \"Missing lib-b\".to_string(),\n        }],\n    );\n\n    engine.add_policy(policy1);\n    engine.add_policy(policy2);\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([]));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert!(\n        (drift_score - 0.2).abs() \u003c 0.01,\n        \"Two Info violations should yield ~0.2\"\n    );\n}\n\n#[tokio::test]\nasync fn test_deny_rule_violation_detection() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"deny-policy\",\n        vec![PolicyRule {\n            id: \"deny-rule\".to_string(),\n            rule_type: RuleType::Deny,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"forbidden-lib\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Forbidden library detected\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\n        \"dependencies\".to_string(),\n        serde_json::json!([\"forbidden-lib\", \"good-lib\"]),\n    );\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(\n        drift_score, 1.0,\n        \"Using forbidden dependency should yield max drift\"\n    );\n}\n\n#[tokio::test]\nasync fn test_empty_context_with_mandatory_policies() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"requires-deps\",\n        vec![PolicyRule {\n            id: \"check-deps\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustExist,\n            value: serde_json::json!(null),\n            severity: ConstraintSeverity::Block,\n            message: \"Dependencies must be declared\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let context: HashMap\u003cString, serde_json::Value\u003e = HashMap::new();\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(\n        drift_score, 1.0,\n        \"Missing required dependency key should yield max drift\"\n    );\n}\n\n#[tokio::test]\nasync fn test_drift_with_must_not_use_satisfied() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"no-bad-libs\",\n        vec![PolicyRule {\n            id: \"no-bad\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustNotUse,\n            value: serde_json::json!(\"bad-lib\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Bad library forbidden\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([\"good-lib\"]));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(\n        drift_score, 0.0,\n        \"Not using forbidden lib should yield zero drift\"\n    );\n}\n\n#[tokio::test]\nasync fn test_drift_with_must_not_use_violated() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"no-bad-libs\",\n        vec![PolicyRule {\n            id: \"no-bad\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustNotUse,\n            value: serde_json::json!(\"bad-lib\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Bad library forbidden\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\n        \"dependencies\".to_string(),\n        serde_json::json!([\"good-lib\", \"bad-lib\"]),\n    );\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(\n        drift_score, 1.0,\n        \"Using forbidden lib should yield max drift\"\n    );\n}\n\n#[tokio::test]\nasync fn test_drift_with_regex_match_satisfied() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"naming-policy\",\n        vec![PolicyRule {\n            id: \"name-pattern\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::File,\n            operator: ConstraintOperator::MustMatch,\n            value: serde_json::json!(r\"^[a-z_]+\\.rs$\"),\n            severity: ConstraintSeverity::Block,\n            message: \"File must match naming convention\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"path\".to_string(), serde_json::json!(\"my_module.rs\"));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(drift_score, 0.0, \"Matching pattern should yield zero drift\");\n}\n\n#[tokio::test]\nasync fn test_drift_with_regex_match_violated() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"naming-policy\",\n        vec![PolicyRule {\n            id: \"name-pattern\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::File,\n            operator: ConstraintOperator::MustMatch,\n            value: serde_json::json!(r\"^[a-z_]+\\.rs$\"),\n            severity: ConstraintSeverity::Block,\n            message: \"File must match naming convention\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"path\".to_string(), serde_json::json!(\"MyModule.rs\"));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(\n        drift_score, 1.0,\n        \"Non-matching pattern should yield max drift\"\n    );\n}\n\n#[tokio::test]\nasync fn test_drift_with_must_not_match_satisfied() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"no-test-files\",\n        vec![PolicyRule {\n            id: \"no-test\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::File,\n            operator: ConstraintOperator::MustNotMatch,\n            value: serde_json::json!(r\"_test\\.rs$\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Test files not allowed in src\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"path\".to_string(), serde_json::json!(\"main.rs\"));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(drift_score, 0.0, \"Non-test file should yield zero drift\");\n}\n\n#[tokio::test]\nasync fn test_drift_with_must_not_match_violated() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"no-test-files\",\n        vec![PolicyRule {\n            id: \"no-test\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::File,\n            operator: ConstraintOperator::MustNotMatch,\n            value: serde_json::json!(r\"_test\\.rs$\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Test files not allowed in src\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"path\".to_string(), serde_json::json!(\"main_test.rs\"));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(drift_score, 1.0, \"Test file in src should yield max drift\");\n}\n\n#[tokio::test]\nasync fn test_drift_layer_filtering() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let company_policy = Policy {\n        id: \"company-policy\".to_string(),\n        name: \"Company Policy\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![PolicyRule {\n            id: \"company-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"company-lib\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Company lib required\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    let project_policy = Policy {\n        id: \"project-policy\".to_string(),\n        name: \"Project Policy\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Project,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![PolicyRule {\n            id: \"project-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"project-lib\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Project lib required\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(company_policy);\n    engine.add_policy(project_policy);\n\n    let mut context = HashMap::new();\n    context.insert(\n        \"dependencies\".to_string(),\n        serde_json::json!([\"company-lib\"]),\n    );\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert!(\n        drift_score \u003e 0.0,\n        \"Missing project-lib should trigger drift\"\n    );\n    assert!(\n        drift_score \u003c= 0.5,\n        \"Only project-lib missing (Warn) should yield \u003c= 0.5\"\n    );\n}\n\n#[tokio::test]\nasync fn test_drift_idempotent_check() {\n    let mut engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"idempotent-test\",\n        vec![PolicyRule {\n            id: \"rule-1\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"required-lib\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Required lib missing\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([\"other-lib\"]));\n\n    let score1 = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    let score2 = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    let score3 = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n\n    assert_eq!(score1, score2, \"Drift check should be idempotent\");\n    assert_eq!(score2, score3, \"Drift check should be idempotent\");\n}\n\n#[tokio::test]\nasync fn test_llm_enhanced_drift_detects_semantic_violations() {\n    let mock_llm = Arc::new(memory::llm::mock::MockLlmService::new());\n\n    let engine = GovernanceEngine::new().with_llm_service(mock_llm);\n    let ctx = create_test_context();\n\n    let mut context = HashMap::new();\n    context.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"This code violate:security-rule violates security practices\"),\n    );\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n\n    assert!(\n        drift_score \u003e 0.0,\n        \"LLM should detect semantic violations when rule marker present\"\n    );\n}\n\n#[tokio::test]\nasync fn test_llm_enhanced_drift_no_false_positives() {\n    let mock_llm = Arc::new(memory::llm::mock::MockLlmService::new());\n\n    let engine = GovernanceEngine::new().with_llm_service(mock_llm);\n    let ctx = create_test_context();\n\n    let mut context = HashMap::new();\n    context.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"This is perfectly compliant code with no issues\"),\n    );\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n\n    assert!(\n        drift_score \u003c= 0.5,\n        \"LLM should not create false positives for compliant content\"\n    );\n}\n\n#[tokio::test]\nasync fn test_llm_violations_prefixed_with_llm_marker() {\n    let mock_llm = Arc::new(memory::llm::mock::MockLlmService::new());\n\n    let mut engine = GovernanceEngine::new().with_llm_service(mock_llm);\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"semantic-policy\",\n        vec![PolicyRule {\n            id: \"semantic-check\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustMatch,\n            value: serde_json::json!(\".*\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Semantic policy\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"Code that violate:semantic-check triggers LLM analysis\"),\n    );\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert!(drift_score \u003e 0.0, \"Should detect LLM violation\");\n}\n\n#[tokio::test]\nasync fn test_llm_graceful_degradation_without_service() {\n    let engine = GovernanceEngine::new();\n    let ctx = create_test_context();\n\n    let mut context = HashMap::new();\n    context.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"Content that would trigger LLM analysis if available\"),\n    );\n\n    let result = engine.check_drift(\u0026ctx, \"project-1\", \u0026context).await;\n    assert!(result.is_ok(), \"Should work without LLM service configured\");\n}\n\n#[tokio::test]\nasync fn test_llm_combined_with_rule_based_violations() {\n    let mock_llm = Arc::new(memory::llm::mock::MockLlmService::new());\n\n    let mut engine = GovernanceEngine::new().with_llm_service(mock_llm);\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"combined-policy\",\n        vec![\n            PolicyRule {\n                id: \"rule-based\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Dependency,\n                operator: ConstraintOperator::MustUse,\n                value: serde_json::json!(\"required-lib\"),\n                severity: ConstraintSeverity::Warn,\n                message: \"Required lib missing\".to_string(),\n            },\n            PolicyRule {\n                id: \"llm-checked\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Code,\n                operator: ConstraintOperator::MustMatch,\n                value: serde_json::json!(\".*\"),\n                severity: ConstraintSeverity::Info,\n                message: \"LLM semantic check\".to_string(),\n            },\n        ],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([\"other-lib\"]));\n    context.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"Code that violate:llm-checked\"),\n    );\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert!(\n        drift_score \u003e= 0.6,\n        \"Should combine rule-based (0.5) + LLM (0.1) violations\"\n    );\n}\n\n#[tokio::test]\nasync fn test_llm_does_not_duplicate_existing_violations() {\n    let mock_llm = Arc::new(memory::llm::mock::MockLlmService::new());\n\n    let mut engine = GovernanceEngine::new().with_llm_service(mock_llm);\n    let ctx = create_test_context();\n\n    let policy = create_mandatory_policy(\n        \"dup-test-policy\",\n        vec![PolicyRule {\n            id: \"shared-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"must-have-lib\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Must have lib\".to_string(),\n        }],\n    );\n    engine.add_policy(policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([]));\n    context.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"Content that triggers violate:shared-rule\"),\n    );\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"project-1\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(\n        drift_score, 1.0,\n        \"Score should be capped at 1.0, not doubled\"\n    );\n}\n","traces":[{"line":18,"address":[],"length":0,"stats":{"Line":27}},{"line":20,"address":[],"length":0,"stats":{"Line":108}},{"line":21,"address":[],"length":0,"stats":{"Line":108}},{"line":25,"address":[],"length":0,"stats":{"Line":20}},{"line":27,"address":[],"length":0,"stats":{"Line":60}},{"line":28,"address":[],"length":0,"stats":{"Line":60}},{"line":34,"address":[],"length":0,"stats":{"Line":20}},{"line":38,"address":[],"length":0,"stats":{"Line":1}},{"line":40,"address":[],"length":0,"stats":{"Line":3}},{"line":41,"address":[],"length":0,"stats":{"Line":3}},{"line":47,"address":[],"length":0,"stats":{"Line":1}}],"covered":11,"coverable":11},{"path":["/","Users","christian.klat","dev","git","aeterna","knowledge","tests","governance_inheritance_test.rs"],"content":"use knowledge::governance::GovernanceEngine;\nuse mk_core::types::{\n    ConstraintOperator, ConstraintSeverity, ConstraintTarget, KnowledgeLayer, Policy, PolicyMode,\n    PolicyRule, RuleMergeStrategy, RuleType,\n};\nuse std::collections::HashMap;\n\n#[tokio::test]\nasync fn test_policy_shadowing_and_inheritance() {\n    let mut engine = GovernanceEngine::new();\n\n    let company_policy = Policy {\n        id: \"security\".to_string(),\n        name: \"Security\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"no-secrets\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustNotMatch,\n            value: serde_json::json!(\"SECRET_.*\"),\n            severity: ConstraintSeverity::Block,\n            message: \"No secrets allowed\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    let org_policy = Policy {\n        id: \"coding-style\".to_string(),\n        name: \"Style\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Org,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![PolicyRule {\n            id: \"indentation\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustMatch,\n            value: serde_json::json!(r\"^  \\S\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Use 2 spaces\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(company_policy);\n    engine.add_policy(org_policy);\n\n    let project_id = \"proj-1\";\n    let mut context = HashMap::new();\n    context.insert(\"projectId\".to_string(), serde_json::json!(project_id));\n    context.insert(\"content\".to_string(), serde_json::json!(\"    fn main() {}\"));\n\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context);\n    assert!(!result.is_valid);\n\n    let project_policy = Policy {\n        id: \"coding-style\".to_string(),\n        name: \"Project Style\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Project,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![PolicyRule {\n            id: \"indentation\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustMatch,\n            value: serde_json::json!(r\"^    \\S\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Use 4 spaces\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(project_policy);\n\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context);\n    assert!(\n        result.is_valid,\n        \"Project policy should have overridden Org policy\"\n    );\n\n    let project_security_override = Policy {\n        id: \"security\".to_string(),\n        name: \"Insecure Project\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Project,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(project_security_override);\n\n    let mut context_with_secret = HashMap::new();\n    context_with_secret.insert(\"projectId\".to_string(), serde_json::json!(project_id));\n    context_with_secret.insert(\"content\".to_string(), serde_json::json!(\"SECRET_KEY=123\"));\n\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context_with_secret);\n    assert!(\n        !result.is_valid,\n        \"Company mandatory policy should NOT be overridable\"\n    );\n}\n\n#[tokio::test]\nasync fn test_rule_type_deny_precedence() {\n    let mut engine = GovernanceEngine::new();\n\n    let company_policy = Policy {\n        id: \"lib-checks\".to_string(),\n        name: \"Lib Checks\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"deny-jquery\".to_string(),\n            rule_type: RuleType::Deny,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"jquery\"),\n            severity: ConstraintSeverity::Block,\n            message: \"JQuery is forbidden\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(company_policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([\"jquery\"]));\n\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context);\n    assert!(!result.is_valid);\n    assert_eq!(result.violations[0].rule_id, \"deny-jquery\");\n}\n\n#[tokio::test]\nasync fn test_layer_hierarchy_order() {\n    let mut engine = GovernanceEngine::new();\n\n    let company_policy = Policy {\n        id: \"layer-test\".to_string(),\n        name: \"Company Layer Test\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![PolicyRule {\n            id: \"layer-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustMatch,\n            value: serde_json::json!(\"company\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Must contain company\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    let org_policy = Policy {\n        id: \"layer-test\".to_string(),\n        name: \"Org Layer Test\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Org,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![PolicyRule {\n            id: \"layer-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustMatch,\n            value: serde_json::json!(\"org\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Must contain org\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(company_policy);\n    engine.add_policy(org_policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"content\".to_string(), serde_json::json!(\"org content here\"));\n\n    let result = engine.validate(KnowledgeLayer::Org, \u0026context);\n    assert!(\n        result.is_valid,\n        \"Org policy should override company for Org layer validation\"\n    );\n\n    let mut context_company = HashMap::new();\n    context_company.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"company content here\"),\n    );\n    let result_company = engine.validate(KnowledgeLayer::Company, \u0026context_company);\n    assert!(\n        result_company.is_valid,\n        \"Company layer validation should only use company policies\"\n    );\n}\n\n#[tokio::test]\nasync fn test_team_layer_inheritance() {\n    let mut engine = GovernanceEngine::new();\n\n    let company_policy = Policy {\n        id: \"company-rule\".to_string(),\n        name: \"Company Rule\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"company-check\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustNotMatch,\n            value: serde_json::json!(\"FORBIDDEN\"),\n            severity: ConstraintSeverity::Block,\n            message: \"FORBIDDEN not allowed\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    let team_policy = Policy {\n        id: \"team-rule\".to_string(),\n        name: \"Team Rule\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Team,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"team-check\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustMatch,\n            value: serde_json::json!(\"team_approved\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Team approval marker needed\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(company_policy);\n    engine.add_policy(team_policy);\n\n    let mut valid_context = HashMap::new();\n    valid_context.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"team_approved content\"),\n    );\n    let result = engine.validate(KnowledgeLayer::Team, \u0026valid_context);\n    assert!(\n        result.is_valid,\n        \"Content meeting both company and team requirements should pass\"\n    );\n\n    let mut forbidden_context = HashMap::new();\n    forbidden_context.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"team_approved FORBIDDEN content\"),\n    );\n    let result = engine.validate(KnowledgeLayer::Team, \u0026forbidden_context);\n    assert!(\n        !result.is_valid,\n        \"Company mandatory policy should still apply at team layer\"\n    );\n\n    let mut missing_marker_context = HashMap::new();\n    missing_marker_context.insert(\"content\".to_string(), serde_json::json!(\"no marker here\"));\n    let result = engine.validate(KnowledgeLayer::Team, \u0026missing_marker_context);\n    assert!(\n        !result.is_valid,\n        \"Team policy should be enforced at team layer\"\n    );\n}\n\n#[tokio::test]\nasync fn test_merge_strategy_merge_accumulates_rules() {\n    let mut engine = GovernanceEngine::new();\n\n    let company_policy = Policy {\n        id: \"multi-rule\".to_string(),\n        name: \"Multi Rule\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"rule-1\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustNotMatch,\n            value: serde_json::json!(\"RULE1_VIOLATION\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Rule 1 violated\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    let org_policy = Policy {\n        id: \"multi-rule\".to_string(),\n        name: \"Multi Rule Org\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Org,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"rule-2\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustNotMatch,\n            value: serde_json::json!(\"RULE2_VIOLATION\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Rule 2 violated\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(company_policy);\n    engine.add_policy(org_policy);\n\n    let mut context_rule1 = HashMap::new();\n    context_rule1.insert(\"content\".to_string(), serde_json::json!(\"RULE1_VIOLATION\"));\n    let result = engine.validate(KnowledgeLayer::Org, \u0026context_rule1);\n    assert!(\n        !result.is_valid,\n        \"Rule 1 from company should still apply after merge\"\n    );\n\n    let mut context_rule2 = HashMap::new();\n    context_rule2.insert(\"content\".to_string(), serde_json::json!(\"RULE2_VIOLATION\"));\n    let result = engine.validate(KnowledgeLayer::Org, \u0026context_rule2);\n    assert!(\n        !result.is_valid,\n        \"Rule 2 from org should be added via merge\"\n    );\n\n    let mut context_both = HashMap::new();\n    context_both.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"RULE1_VIOLATION RULE2_VIOLATION\"),\n    );\n    let result = engine.validate(KnowledgeLayer::Org, \u0026context_both);\n    assert!(!result.is_valid);\n    assert!(\n        result.violations.len() \u003e= 1,\n        \"Both rules should be evaluated\"\n    );\n}\n\n#[tokio::test]\nasync fn test_severity_levels_in_hierarchy() {\n    let mut engine = GovernanceEngine::new();\n\n    let block_policy = Policy {\n        id: \"severity-test\".to_string(),\n        name: \"Severity Test\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![\n            PolicyRule {\n                id: \"block-rule\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Code,\n                operator: ConstraintOperator::MustNotMatch,\n                value: serde_json::json!(\"CRITICAL_ERROR\"),\n                severity: ConstraintSeverity::Block,\n                message: \"Critical error found\".to_string(),\n            },\n            PolicyRule {\n                id: \"warn-rule\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Code,\n                operator: ConstraintOperator::MustNotMatch,\n                value: serde_json::json!(\"MINOR_ISSUE\"),\n                severity: ConstraintSeverity::Warn,\n                message: \"Minor issue found\".to_string(),\n            },\n            PolicyRule {\n                id: \"info-rule\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Code,\n                operator: ConstraintOperator::MustNotMatch,\n                value: serde_json::json!(\"NOTE_THIS\"),\n                severity: ConstraintSeverity::Info,\n                message: \"Note for review\".to_string(),\n            },\n        ],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(block_policy);\n\n    let mut context_block = HashMap::new();\n    context_block.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"CRITICAL_ERROR here\"),\n    );\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context_block);\n    assert!(!result.is_valid);\n    assert_eq!(result.violations[0].severity, ConstraintSeverity::Block);\n\n    let mut context_warn = HashMap::new();\n    context_warn.insert(\"content\".to_string(), serde_json::json!(\"MINOR_ISSUE here\"));\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context_warn);\n    assert!(!result.is_valid);\n    assert_eq!(result.violations[0].severity, ConstraintSeverity::Warn);\n\n    let mut context_info = HashMap::new();\n    context_info.insert(\"content\".to_string(), serde_json::json!(\"NOTE_THIS here\"));\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context_info);\n    assert!(!result.is_valid);\n    assert_eq!(result.violations[0].severity, ConstraintSeverity::Info);\n}\n\n#[tokio::test]\nasync fn test_empty_policy_layers_are_skipped() {\n    let mut engine = GovernanceEngine::new();\n\n    let project_policy = Policy {\n        id: \"project-only\".to_string(),\n        name: \"Project Only\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Project,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"project-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustMatch,\n            value: serde_json::json!(\"project_marker\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Project marker needed\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(project_policy);\n\n    let mut context = HashMap::new();\n    context.insert(\"content\".to_string(), serde_json::json!(\"no marker\"));\n    let result = engine.validate(KnowledgeLayer::Org, \u0026context);\n    assert!(\n        result.is_valid,\n        \"Project policy should not apply at Org layer\"\n    );\n\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context);\n    assert!(\n        !result.is_valid,\n        \"Project policy should apply at Project layer\"\n    );\n}\n\n#[tokio::test]\nasync fn test_multiple_policies_same_layer() {\n    let mut engine = GovernanceEngine::new();\n\n    let policy_a = Policy {\n        id: \"policy-a\".to_string(),\n        name: \"Policy A\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"rule-a\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustNotMatch,\n            value: serde_json::json!(\"VIOLATION_A\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Violation A\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    let policy_b = Policy {\n        id: \"policy-b\".to_string(),\n        name: \"Policy B\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"rule-b\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustNotMatch,\n            value: serde_json::json!(\"VIOLATION_B\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Violation B\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(policy_a);\n    engine.add_policy(policy_b);\n\n    let mut context = HashMap::new();\n    context.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"VIOLATION_A VIOLATION_B\"),\n    );\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context);\n    assert!(!result.is_valid);\n    assert_eq!(\n        result.violations.len(),\n        2,\n        \"Both policies should generate violations\"\n    );\n}\n\n#[tokio::test]\nasync fn test_dependency_constraint_inheritance() {\n    let mut engine = GovernanceEngine::new();\n\n    let company_policy = Policy {\n        id: \"dependency-policy\".to_string(),\n        name: \"Dependency Policy\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"require-security-lib\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"security-lib\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Security library required\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    let org_policy = Policy {\n        id: \"dependency-policy\".to_string(),\n        name: \"Org Dependency Policy\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Org,\n        mode: PolicyMode::Optional,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"require-logging-lib\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"logging-lib\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Logging library recommended\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(company_policy);\n    engine.add_policy(org_policy);\n\n    let mut context_missing_security = HashMap::new();\n    context_missing_security.insert(\n        \"dependencies\".to_string(),\n        serde_json::json!([\"logging-lib\", \"other-lib\"]),\n    );\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context_missing_security);\n    assert!(\n        !result.is_valid,\n        \"Missing mandatory security-lib should fail\"\n    );\n\n    let mut context_has_both = HashMap::new();\n    context_has_both.insert(\n        \"dependencies\".to_string(),\n        serde_json::json!([\"security-lib\", \"logging-lib\"]),\n    );\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context_has_both);\n    assert!(result.is_valid, \"Having both libs should pass\");\n}\n\n#[tokio::test]\nasync fn test_config_constraint_target() {\n    let mut engine = GovernanceEngine::new();\n\n    // Test MustExist: config key must exist in context\n    let config_policy = Policy {\n        id: \"config-policy\".to_string(),\n        name: \"Config Policy\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"require-config\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Config,\n            operator: ConstraintOperator::MustExist,\n            value: serde_json::json!(null), // MustExist checks key presence, value not used\n            severity: ConstraintSeverity::Block,\n            message: \"Config section required\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine.add_policy(config_policy);\n\n    // Context without \"config\" key should fail\n    let context_without_config: HashMap\u003cString, serde_json::Value\u003e = HashMap::new();\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context_without_config);\n    assert!(!result.is_valid, \"Missing config key should fail\");\n\n    // Context with \"config\" key should pass\n    let mut context_with_config = HashMap::new();\n    context_with_config.insert(\"config\".to_string(), serde_json::json!({\"any\": \"value\"}));\n    let result = engine.validate(KnowledgeLayer::Project, \u0026context_with_config);\n    assert!(result.is_valid, \"Config key present should pass\");\n\n    // Test MustNotExist: config key must NOT exist\n    let mut engine2 = GovernanceEngine::new();\n    let no_config_policy = Policy {\n        id: \"no-config-policy\".to_string(),\n        name: \"No Config Policy\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"forbid-config\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Config,\n            operator: ConstraintOperator::MustNotExist,\n            value: serde_json::json!(null),\n            severity: ConstraintSeverity::Block,\n            message: \"Config section forbidden\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    engine2.add_policy(no_config_policy);\n\n    // Context with \"config\" key should fail for MustNotExist\n    let result = engine2.validate(KnowledgeLayer::Project, \u0026context_with_config);\n    assert!(\n        !result.is_valid,\n        \"Config key present should fail with MustNotExist\"\n    );\n\n    // Context without \"config\" key should pass for MustNotExist\n    let result = engine2.validate(KnowledgeLayer::Project, \u0026context_without_config);\n    assert!(\n        result.is_valid,\n        \"Missing config key should pass with MustNotExist\"\n    );\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","backend.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","bridge.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","config.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","ecosystem.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","embedding","mock.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::EmbeddingService;\n\npub struct MockEmbeddingService {\n    dimension: usize\n}\n\nimpl MockEmbeddingService {\n    pub fn new(dimension: usize) -\u003e Self {\n        Self { dimension }\n    }\n\n    fn generate_mock_embedding(text: \u0026str) -\u003e Vec\u003cf32\u003e {\n        let mut embedding = vec![0.0; 384];\n        let text_lower = text.to_lowercase();\n\n        if text_lower.contains(\"rust\") {\n            embedding[0] = 0.8;\n            embedding[1] = 0.6;\n        }\n        if text_lower.contains(\"typescript\") || text_lower.contains(\"javascript\") {\n            embedding[2] = 0.7;\n            embedding[3] = 0.5;\n        }\n        if text_lower.contains(\"python\") {\n            embedding[4] = 0.9;\n            embedding[5] = 0.4;\n        }\n        if text_lower.contains(\"database\") {\n            embedding[6] = 0.6;\n            embedding[7] = 0.7;\n        }\n        if text_lower.contains(\"api\") {\n            embedding[8] = 0.5;\n            embedding[9] = 0.8;\n        }\n\n        let length_factor = (text.len() as f32).min(1000.0) / 1000.0;\n        embedding[10] = length_factor;\n\n        embedding\n    }\n}\n\n#[async_trait]\nimpl EmbeddingService for MockEmbeddingService {\n    type Error = Box\u003cdyn std::error::Error + Send + Sync\u003e;\n\n    async fn embed(\u0026self, text: \u0026str) -\u003e Result\u003cVec\u003cf32\u003e, Self::Error\u003e {\n        Ok(Self::generate_mock_embedding(text))\n    }\n\n    fn dimension(\u0026self) -\u003e usize {\n        self.dimension\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_mock_embedding_service() {\n        let service = MockEmbeddingService::new(384);\n\n        let embedding1 = service.embed(\"Rust programming language\").await.unwrap();\n        assert_eq!(embedding1.len(), 384);\n        assert!(embedding1[0] \u003e 0.0);\n        assert!(embedding1[1] \u003e 0.0);\n\n        let embedding2 = service.embed(\"Python data science\").await.unwrap();\n        assert_eq!(embedding2.len(), 384);\n        assert!(embedding2[4] \u003e 0.0);\n        assert!(embedding2[5] \u003e 0.0);\n\n        assert_ne!(embedding1, embedding2);\n    }\n\n    #[tokio::test]\n    async fn test_mock_embedding_service_batch() {\n        let service = MockEmbeddingService::new(384);\n\n        let texts = vec![\n            \"Rust programming\".to_string(),\n            \"Python scripting\".to_string(),\n            \"Database management\".to_string(),\n        ];\n\n        let embeddings = service.embed_batch(\u0026texts).await.unwrap();\n        assert_eq!(embeddings.len(), 3);\n        for embedding in embeddings {\n            assert_eq!(embedding.len(), 384);\n        }\n    }\n}\n","traces":[{"line":9,"address":[],"length":0,"stats":{"Line":4}},{"line":13,"address":[],"length":0,"stats":{"Line":8}},{"line":14,"address":[],"length":0,"stats":{"Line":16}},{"line":15,"address":[],"length":0,"stats":{"Line":24}},{"line":17,"address":[],"length":0,"stats":{"Line":12}},{"line":18,"address":[],"length":0,"stats":{"Line":8}},{"line":19,"address":[],"length":0,"stats":{"Line":4}},{"line":21,"address":[],"length":0,"stats":{"Line":16}},{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":23,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":10}},{"line":26,"address":[],"length":0,"stats":{"Line":4}},{"line":27,"address":[],"length":0,"stats":{"Line":2}},{"line":29,"address":[],"length":0,"stats":{"Line":9}},{"line":30,"address":[],"length":0,"stats":{"Line":2}},{"line":31,"address":[],"length":0,"stats":{"Line":1}},{"line":33,"address":[],"length":0,"stats":{"Line":8}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[],"length":0,"stats":{"Line":16}},{"line":39,"address":[],"length":0,"stats":{"Line":8}},{"line":41,"address":[],"length":0,"stats":{"Line":8}},{"line":49,"address":[],"length":0,"stats":{"Line":8}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}}],"covered":19,"coverable":25},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","embedding","mod.rs"],"content":"pub mod mock;\npub mod openai;\n\npub use mock::MockEmbeddingService;\npub use openai::OpenAIEmbeddingService;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","embedding","openai.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::EmbeddingService;\nuse std::sync::Arc;\nuse storage::redis::RedisStorage;\nuse tokio::sync::RwLock;\n\npub struct OpenAIEmbeddingService {\n    client: async_openai::Client\u003casync_openai::config::OpenAIConfig\u003e,\n    model: String,\n    dimension: usize,\n    cache: Arc\u003cRwLock\u003clru::LruCache\u003cString, Vec\u003cf32\u003e\u003e\u003e\u003e,\n    redis: Option\u003cArc\u003cRwLock\u003cRedisStorage\u003e\u003e\u003e\n}\n\nimpl OpenAIEmbeddingService {\n    pub fn new(api_key: String, model: \u0026str) -\u003e Self {\n        let config = async_openai::config::OpenAIConfig::new().with_api_key(api_key);\n        let client = async_openai::Client::with_config(config);\n\n        let dimension = match model {\n            \"text-embedding-ada-002\" =\u003e 1536,\n            \"text-embedding-3-small\" =\u003e 1536,\n            \"text-embedding-3-large\" =\u003e 3072,\n            _ =\u003e 1536\n        };\n\n        Self {\n            client,\n            model: model.to_string(),\n            dimension,\n            cache: Arc::new(RwLock::new(lru::LruCache::new(\n                std::num::NonZeroUsize::new(1000).unwrap()\n            ))),\n            redis: None\n        }\n    }\n\n    pub fn with_redis(mut self, redis: Arc\u003cRwLock\u003cRedisStorage\u003e\u003e) -\u003e Self {\n        self.redis = Some(redis);\n        self\n    }\n\n    pub fn with_cache_size(api_key: String, model: \u0026str, cache_size: usize) -\u003e Self {\n        let config = async_openai::config::OpenAIConfig::new().with_api_key(api_key);\n        let client = async_openai::Client::with_config(config);\n\n        let dimension = match model {\n            \"text-embedding-ada-002\" =\u003e 1536,\n            \"text-embedding-3-small\" =\u003e 1536,\n            \"text-embedding-3-large\" =\u003e 3072,\n            _ =\u003e 1536\n        };\n\n        Self {\n            client,\n            model: model.to_string(),\n            dimension,\n            cache: Arc::new(RwLock::new(lru::LruCache::new(\n                std::num::NonZeroUsize::new(cache_size).unwrap()\n            ))),\n            redis: None\n        }\n    }\n\n    pub fn with_default_model(api_key: String) -\u003e Self {\n        Self::new(api_key, \"text-embedding-ada-002\")\n    }\n}\n\n#[async_trait]\nimpl EmbeddingService for OpenAIEmbeddingService {\n    type Error = Box\u003cdyn std::error::Error + Send + Sync\u003e;\n\n    async fn embed(\u0026self, text: \u0026str) -\u003e Result\u003cVec\u003cf32\u003e, Self::Error\u003e {\n        {\n            let mut cache = self.cache.write().await;\n            if let Some(cached) = cache.get(text) {\n                return Ok(cached.clone());\n            }\n        }\n\n        if let Some(redis) = \u0026self.redis {\n            let redis = redis.write().await;\n            let key = format!(\"emb:{}:{}\", self.model, text);\n            if let Ok(Some(cached_json)) = redis.get(\u0026key).await {\n                if let Ok(embedding) = serde_json::from_str::\u003cVec\u003cf32\u003e\u003e(\u0026cached_json) {\n                    let mut cache = self.cache.write().await;\n                    cache.put(text.to_string(), embedding.clone());\n                    return Ok(embedding);\n                }\n            }\n        }\n\n        let request = async_openai::types::CreateEmbeddingRequestArgs::default()\n            .model(\u0026self.model)\n            .input(text)\n            .build()?;\n\n        let response = self.client.embeddings().create(request).await?;\n\n        let embedding = response\n            .data\n            .first()\n            .ok_or(\"No embedding returned\")?\n            .embedding\n            .clone();\n\n        {\n            let mut cache = self.cache.write().await;\n            cache.put(text.to_string(), embedding.clone());\n        }\n\n        if let Some(redis) = \u0026self.redis {\n            let redis = redis.write().await;\n            let key = format!(\"emb:{}:{}\", self.model, text);\n            if let Ok(json) = serde_json::to_string(\u0026embedding) {\n                let _ = redis.set(\u0026key, \u0026json, Some(86400)).await;\n            }\n        }\n\n        Ok(embedding)\n    }\n\n    fn dimension(\u0026self) -\u003e usize {\n        self.dimension\n    }\n\n    async fn embed_batch(\u0026self, texts: \u0026[String]) -\u003e Result\u003cVec\u003cVec\u003cf32\u003e\u003e, Self::Error\u003e {\n        let mut results = Vec::with_capacity(texts.len());\n        let mut uncached_texts = Vec::new();\n        let mut uncached_indices = Vec::new();\n\n        let mut cache = self.cache.write().await;\n\n        for (i, text) in texts.iter().enumerate() {\n            if let Some(cached) = cache.get(text) {\n                results.push(cached.clone());\n            } else {\n                results.push(Vec::new());\n                uncached_texts.push(text.clone());\n                uncached_indices.push(i);\n            }\n        }\n\n        if !uncached_texts.is_empty() {\n            let request = async_openai::types::CreateEmbeddingRequestArgs::default()\n                .model(\u0026self.model)\n                .input(uncached_texts.clone())\n                .build()?;\n\n            let response = self.client.embeddings().create(request).await?;\n\n            for (i, embedding_data) in response.data.into_iter().enumerate() {\n                let idx = uncached_indices[i];\n                let text: \u0026String = \u0026uncached_texts[i];\n                let embedding = embedding_data.embedding;\n\n                cache.put(text.clone(), embedding.clone());\n                results[idx] = embedding;\n            }\n        }\n\n        Ok(results)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[tokio::test]\n    #[ignore = \"Requires OpenAI API key\"]\n    async fn test_openai_embedding_service() {\n        let api_key = std::env::var(\"OPENAI_API_KEY\").unwrap_or_default();\n        if api_key.is_empty() {\n            return;\n        }\n\n        let service = OpenAIEmbeddingService::with_default_model(api_key);\n\n        let embedding = service.embed(\"Test text\").await.unwrap();\n        assert_eq!(embedding.len(), 1536);\n        assert!(service.dimension() == 1536);\n\n        let texts = vec![\"First text\".to_string(), \"Second text\".to_string()];\n        let embeddings = service.embed_batch(\u0026texts).await.unwrap();\n        assert_eq!(embeddings.len(), 2);\n        for embedding in embeddings {\n            assert_eq!(embedding.len(), 1536);\n        }\n    }\n\n    #[tokio::test]\n    async fn test_lru_cache_hit() {\n        let service = OpenAIEmbeddingService::with_cache_size(\n            \"sk-fake-key\".to_string(),\n            \"text-embedding-ada-002\",\n            10\n        );\n\n        let mut cache = service.cache.write().await;\n\n        let test_vector = vec![0.1; 1536];\n        cache.put(\"test_text\".to_string(), test_vector.clone());\n\n        let cached = cache.get(\"test_text\");\n        assert!(cached.is_some(), \"Cached value should be found\");\n        assert_eq!(*cached.unwrap(), *test_vector, \"Cached vector should match\");\n    }\n\n    #[tokio::test]\n    async fn test_lru_cache_miss() {\n        let service = OpenAIEmbeddingService::with_cache_size(\n            \"sk-fake-key\".to_string(),\n            \"text-embedding-ada-002\",\n            10\n        );\n\n        let mut cache = service.cache.write().await;\n\n        let cached = cache.get(\"nonexistent_text\");\n        assert!(cached.is_none(), \"Should return None for nonexistent key\");\n    }\n\n    #[test]\n    fn test_dimension_configuration() {\n        let service = OpenAIEmbeddingService::new(\"sk-test\".to_string(), \"text-embedding-ada-002\");\n        assert_eq!(\n            service.dimension(),\n            1536,\n            \"ada-002 should have 1536 dimensions\"\n        );\n\n        let service = OpenAIEmbeddingService::new(\"sk-test\".to_string(), \"text-embedding-3-small\");\n        assert_eq!(\n            service.dimension(),\n            1536,\n            \"3-small should have 1536 dimensions\"\n        );\n\n        let service = OpenAIEmbeddingService::new(\"sk-test\".to_string(), \"text-embedding-3-large\");\n        assert_eq!(\n            service.dimension(),\n            3072,\n            \"3-large should have 3072 dimensions\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_custom_cache_size() {\n        let service = OpenAIEmbeddingService::with_cache_size(\n            \"sk-test\".to_string(),\n            \"text-embedding-ada-002\",\n            500\n        );\n\n        let cache = service.cache.read().await;\n        assert_eq!(cache.cap().get(), 500, \"Cache capacity should be 500\");\n    }\n}\n","traces":[{"line":16,"address":[],"length":0,"stats":{"Line":3}},{"line":17,"address":[],"length":0,"stats":{"Line":12}},{"line":18,"address":[],"length":0,"stats":{"Line":9}},{"line":20,"address":[],"length":0,"stats":{"Line":6}},{"line":21,"address":[],"length":0,"stats":{"Line":4}},{"line":22,"address":[],"length":0,"stats":{"Line":3}},{"line":23,"address":[],"length":0,"stats":{"Line":2}},{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":29,"address":[],"length":0,"stats":{"Line":9}},{"line":31,"address":[],"length":0,"stats":{"Line":12}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":3}},{"line":44,"address":[],"length":0,"stats":{"Line":12}},{"line":45,"address":[],"length":0,"stats":{"Line":9}},{"line":47,"address":[],"length":0,"stats":{"Line":6}},{"line":48,"address":[],"length":0,"stats":{"Line":6}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":9}},{"line":58,"address":[],"length":0,"stats":{"Line":12}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":3}},{"line":125,"address":[],"length":0,"stats":{"Line":3}},{"line":128,"address":[],"length":0,"stats":{"Line":0}}],"covered":18,"coverable":29},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","episodic.rs"],"content":"\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","error.rs"],"content":"use thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum MemoryError {\n    #[error(\"Provider error: {0}\")]\n    ProviderError(String),\n\n    #[error(\"Embedding error: {0}\")]\n    EmbeddingError(String),\n\n    #[error(\"Validation error: {0}\")]\n    ValidationError(String),\n\n    #[error(\"Storage error: {0}\")]\n    StorageError(String),\n\n    #[error(\"Network error: {0}\")]\n    NetworkError(String),\n\n    #[error(\"Timeout error: {0}\")]\n    TimeoutError(String),\n\n    #[error(\"Configuration error: {0}\")]\n    ConfigError(String),\n\n    #[error(\"Serialization error: {0}\")]\n    SerializationError(String),\n\n    #[error(\"Resource not found: {0}\")]\n    NotFound(String),\n\n    #[error(\"Unauthorized access: {0}\")]\n    Unauthorized(String),\n\n    #[error(\"Rate limited: {0}\")]\n    RateLimited(String),\n\n    #[error(\"Internal error: {0}\")]\n    InternalError(String)\n}\n\nimpl MemoryError {\n    pub fn is_retryable(\u0026self) -\u003e bool {\n        match self {\n            MemoryError::NetworkError(_)\n            | MemoryError::TimeoutError(_)\n            | MemoryError::RateLimited(_)\n            | MemoryError::ProviderError(_) =\u003e true,\n            _ =\u003e false\n        }\n    }\n\n    pub fn should_backoff(\u0026self) -\u003e bool {\n        match self {\n            MemoryError::RateLimited(_) =\u003e true,\n            _ =\u003e false\n        }\n    }\n\n    pub fn backoff_duration(\u0026self) -\u003e Option\u003cstd::time::Duration\u003e {\n        match self {\n            MemoryError::RateLimited(_) =\u003e Some(std::time::Duration::from_secs(5)),\n            MemoryError::NetworkError(_) =\u003e Some(std::time::Duration::from_secs(1)),\n            _ =\u003e None\n        }\n    }\n}\n\npub type MemoryResult\u003cT\u003e = Result\u003cT, MemoryError\u003e;\n\n#[allow(async_fn_in_trait)]\npub trait WithRetry {\n    type Output;\n\n    async fn with_retry\u003cF, Fut\u003e(operation: F) -\u003e MemoryResult\u003cSelf::Output\u003e\n    where\n        F: Fn() -\u003e Fut,\n        Fut: std::future::Future\u003cOutput = MemoryResult\u003cSelf::Output\u003e\u003e;\n}\n\npub struct RetryConfig {\n    pub max_retries: usize,\n    pub initial_backoff: std::time::Duration,\n    pub max_backoff: std::time::Duration,\n    pub backoff_multiplier: f32,\n    pub jitter: bool\n}\n\nimpl Default for RetryConfig {\n    fn default() -\u003e Self {\n        Self {\n            max_retries: 3,\n            initial_backoff: std::time::Duration::from_millis(100),\n            max_backoff: std::time::Duration::from_secs(10),\n            backoff_multiplier: 2.0,\n            jitter: true\n        }\n    }\n}\n\npub async fn with_retry\u003cF, Fut, T\u003e(operation: F, config: RetryConfig) -\u003e MemoryResult\u003cT\u003e\nwhere\n    F: Fn() -\u003e Fut,\n    Fut: std::future::Future\u003cOutput = MemoryResult\u003cT\u003e\u003e\n{\n    let mut last_error = None;\n    let mut backoff = config.initial_backoff;\n\n    for attempt in 0..=config.max_retries {\n        match operation().await {\n            Ok(result) =\u003e return Ok(result),\n            Err(err) =\u003e {\n                last_error = Some(err);\n\n                if attempt == config.max_retries {\n                    break;\n                }\n\n                let current_error = last_error.as_ref().unwrap();\n\n                if !current_error.is_retryable() {\n                    break;\n                }\n\n                if let Some(error_backoff) = current_error.backoff_duration() {\n                    tokio::time::sleep(error_backoff).await;\n                } else {\n                    let mut actual_backoff = backoff;\n\n                    if config.jitter {\n                        let jitter = rand::random::\u003cf32\u003e() * 0.3 + 0.85;\n                        actual_backoff = std::time::Duration::from_millis(\n                            (actual_backoff.as_millis() as f32 * jitter) as u64\n                        );\n                    }\n\n                    tokio::time::sleep(actual_backoff).await;\n\n                    backoff = std::time::Duration::from_millis(\n                        (backoff.as_millis() as f32 * config.backoff_multiplier) as u64\n                    )\n                    .min(config.max_backoff);\n                }\n            }\n        }\n    }\n\n    Err(last_error.unwrap_or_else(|| {\n        MemoryError::InternalError(\"Operation failed after retries\".to_string())\n    }))\n}\n\npub async fn with_exponential_backoff\u003cF, Fut, T\u003e(\n    operation: F,\n    max_retries: usize\n) -\u003e MemoryResult\u003cT\u003e\nwhere\n    F: Fn() -\u003e Fut,\n    Fut: std::future::Future\u003cOutput = MemoryResult\u003cT\u003e\u003e\n{\n    with_retry(\n        operation,\n        RetryConfig {\n            max_retries,\n            ..Default::default()\n        }\n    )\n    .await\n}\n\npub struct CircuitBreaker {\n    state: std::sync::Arc\u003ctokio::sync::RwLock\u003cCircuitState\u003e\u003e,\n    failure_threshold: usize,\n    reset_timeout: std::time::Duration,\n    _half_open_timeout: std::time::Duration\n}\n\nenum CircuitState {\n    Closed { failure_count: usize },\n    Open { opened_at: std::time::Instant },\n    HalfOpen\n}\n\nimpl CircuitBreaker {\n    pub fn new(failure_threshold: usize, reset_timeout: std::time::Duration) -\u003e Self {\n        Self {\n            state: std::sync::Arc::new(tokio::sync::RwLock::new(CircuitState::Closed {\n                failure_count: 0\n            })),\n            failure_threshold,\n            reset_timeout,\n            _half_open_timeout: reset_timeout / 2\n        }\n    }\n\n    pub async fn execute\u003cF, Fut, T\u003e(\u0026self, operation: F) -\u003e MemoryResult\u003cT\u003e\n    where\n        F: Fn() -\u003e Fut,\n        Fut: std::future::Future\u003cOutput = MemoryResult\u003cT\u003e\u003e\n    {\n        let state = self.state.read().await;\n\n        match *state {\n            CircuitState::Open { opened_at } =\u003e {\n                if opened_at.elapsed() \u003e= self.reset_timeout {\n                    drop(state);\n                    let mut state = self.state.write().await;\n                    *state = CircuitState::HalfOpen;\n                } else {\n                    return Err(MemoryError::NetworkError(\n                        \"Circuit breaker is open\".to_string()\n                    ));\n                }\n            }\n            CircuitState::HalfOpen =\u003e {\n                drop(state);\n            }\n            CircuitState::Closed { .. } =\u003e {\n                drop(state);\n            }\n        }\n\n        let result = operation().await;\n\n        let mut state = self.state.write().await;\n        match *state {\n            CircuitState::HalfOpen =\u003e {\n                if result.is_ok() {\n                    *state = CircuitState::Closed { failure_count: 0 };\n                } else {\n                    *state = CircuitState::Open {\n                        opened_at: std::time::Instant::now()\n                    };\n                }\n            }\n            CircuitState::Closed {\n                ref mut failure_count\n            } =\u003e {\n                if result.is_ok() {\n                    *failure_count = 0;\n                } else {\n                    *failure_count += 1;\n                    if *failure_count \u003e= self.failure_threshold {\n                        *state = CircuitState::Open {\n                            opened_at: std::time::Instant::now()\n                        };\n                    }\n                }\n            }\n            _ =\u003e {}\n        }\n\n        result\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::sync::atomic::{AtomicUsize, Ordering};\n\n    #[tokio::test]\n    async fn test_retry_success() {\n        let counter = AtomicUsize::new(0);\n\n        let result = with_retry(\n            || async {\n                let count = counter.fetch_add(1, Ordering::SeqCst);\n                if count \u003c 2 {\n                    Err(MemoryError::NetworkError(\"Temporary failure\".to_string()))\n                } else {\n                    Ok(\"success\")\n                }\n            },\n            RetryConfig::default()\n        )\n        .await;\n\n        assert_eq!(result.unwrap(), \"success\");\n        assert_eq!(counter.load(Ordering::SeqCst), 3);\n    }\n\n    #[tokio::test]\n    async fn test_retry_non_retryable_error() {\n        let counter = AtomicUsize::new(0);\n\n        let result: Result\u003c\u0026str, _\u003e = with_retry(\n            || async {\n                counter.fetch_add(1, Ordering::SeqCst);\n                Err(MemoryError::ValidationError(\n                    \"Permanent failure\".to_string()\n                ))\n            },\n            RetryConfig::default()\n        )\n        .await;\n\n        assert!(result.is_err());\n        assert_eq!(counter.load(Ordering::SeqCst), 1);\n    }\n\n    #[test]\n    fn test_memory_error_retryable() {\n        assert!(MemoryError::NetworkError(\"\".into()).is_retryable());\n        assert!(MemoryError::TimeoutError(\"\".into()).is_retryable());\n        assert!(MemoryError::RateLimited(\"\".into()).is_retryable());\n        assert!(MemoryError::ProviderError(\"\".into()).is_retryable());\n        assert!(!MemoryError::ValidationError(\"\".into()).is_retryable());\n    }\n\n    #[test]\n    fn test_memory_error_backoff() {\n        assert!(MemoryError::RateLimited(\"\".into()).should_backoff());\n        assert!(!MemoryError::NetworkError(\"\".into()).should_backoff());\n\n        assert!(\n            MemoryError::RateLimited(\"\".into())\n                .backoff_duration()\n                .is_some()\n        );\n        assert!(\n            MemoryError::NetworkError(\"\".into())\n                .backoff_duration()\n                .is_some()\n        );\n        assert!(\n            MemoryError::InternalError(\"\".into())\n                .backoff_duration()\n                .is_none()\n        );\n    }\n\n    #[tokio::test]\n    async fn test_with_exponential_backoff() {\n        let counter = AtomicUsize::new(0);\n        let result = with_exponential_backoff(\n            || async {\n                let c = counter.fetch_add(1, Ordering::SeqCst);\n                if c \u003c 1 {\n                    Err(MemoryError::NetworkError(\"\".into()))\n                } else {\n                    Ok(\"ok\")\n                }\n            },\n            2\n        )\n        .await;\n        assert_eq!(result.unwrap(), \"ok\");\n        assert_eq!(counter.load(Ordering::SeqCst), 2);\n    }\n\n    #[tokio::test]\n    async fn test_circuit_breaker_half_open_failure() {\n        let breaker = CircuitBreaker::new(1, std::time::Duration::from_millis(50));\n\n        // Open it\n        let _: Result\u003c(), _\u003e = breaker\n            .execute(|| async { Err(MemoryError::NetworkError(\"\".into())) })\n            .await;\n\n        // Wait for reset timeout\n        tokio::time::sleep(std::time::Duration::from_millis(60)).await;\n\n        // Half-open attempt fails -\u003e goes back to Open\n        let _: Result\u003c(), _\u003e = breaker\n            .execute(|| async { Err(MemoryError::InternalError(\"\".into())) })\n            .await;\n\n        // Next call should be blocked immediately\n        let result = breaker.execute(|| async { Ok(\"should be blocked\") }).await;\n        assert!(\n            matches!(result, Err(MemoryError::NetworkError(msg)) if msg.contains(\"Circuit breaker is open\"))\n        );\n    }\n\n    #[tokio::test]\n    async fn test_circuit_breaker_half_open_success() {\n        let breaker = CircuitBreaker::new(2, std::time::Duration::from_millis(50));\n\n        // Open it with 2 failures\n        let _: Result\u003c(), _\u003e = breaker\n            .execute(|| async { Err(MemoryError::NetworkError(\"\".into())) })\n            .await;\n        let _: Result\u003c(), _\u003e = breaker\n            .execute(|| async { Err(MemoryError::NetworkError(\"\".into())) })\n            .await;\n\n        // Wait for reset timeout\n        tokio::time::sleep(std::time::Duration::from_millis(60)).await;\n\n        // Half-open attempt succeeds -\u003e goes back to Closed\n        let result = breaker.execute(|| async { Ok(\"success\") }).await;\n        assert_eq!(result.unwrap(), \"success\");\n\n        // Should be closed now, can make another successful call\n        let result = breaker.execute(|| async { Ok(\"another success\") }).await;\n        assert_eq!(result.unwrap(), \"another success\");\n    }\n\n    #[tokio::test]\n    async fn test_circuit_breaker_closed_state_reset_on_success() {\n        let breaker = CircuitBreaker::new(3, std::time::Duration::from_millis(100));\n\n        // Fail once\n        let _: Result\u003c(), _\u003e = breaker\n            .execute(|| async { Err(MemoryError::NetworkError(\"\".into())) })\n            .await;\n\n        // Success should reset failure count\n        let result = breaker.execute(|| async { Ok(\"reset\") }).await;\n        assert_eq!(result.unwrap(), \"reset\");\n\n        // Should still be closed, not open\n        let result = breaker.execute(|| async { Ok(\"still working\") }).await;\n        assert_eq!(result.unwrap(), \"still working\");\n    }\n\n    #[test]\n    fn test_all_error_variants_display() {\n        // Test that all error variants can be formatted\n        let errors = vec![\n            MemoryError::ProviderError(\"test\".to_string()),\n            MemoryError::EmbeddingError(\"test\".to_string()),\n            MemoryError::ValidationError(\"test\".to_string()),\n            MemoryError::StorageError(\"test\".to_string()),\n            MemoryError::NetworkError(\"test\".to_string()),\n            MemoryError::TimeoutError(\"test\".to_string()),\n            MemoryError::ConfigError(\"test\".to_string()),\n            MemoryError::SerializationError(\"test\".to_string()),\n            MemoryError::NotFound(\"test\".to_string()),\n            MemoryError::Unauthorized(\"test\".to_string()),\n            MemoryError::RateLimited(\"test\".to_string()),\n            MemoryError::InternalError(\"test\".to_string()),\n        ];\n\n        for error in errors {\n            let display = error.to_string();\n            assert!(!display.is_empty());\n            assert!(display.contains(\"test\"));\n        }\n    }\n\n    #[tokio::test]\n    async fn test_with_retry_jitter_calculation() {\n        let counter = AtomicUsize::new(0);\n\n        let config = RetryConfig {\n            max_retries: 2,\n            initial_backoff: std::time::Duration::from_millis(100),\n            max_backoff: std::time::Duration::from_secs(1),\n            backoff_multiplier: 2.0,\n            jitter: true\n        };\n\n        let result = with_retry(\n            || async {\n                let count = counter.fetch_add(1, Ordering::SeqCst);\n                if count \u003c 2 {\n                    Err(MemoryError::NetworkError(\"Temporary\".to_string()))\n                } else {\n                    Ok(\"success with jitter\")\n                }\n            },\n            config\n        )\n        .await;\n\n        assert_eq!(result.unwrap(), \"success with jitter\");\n        assert_eq!(counter.load(Ordering::SeqCst), 3);\n    }\n\n    #[tokio::test]\n    async fn test_with_retry_error_backoff_takes_precedence() {\n        let counter = AtomicUsize::new(0);\n\n        let result: Result\u003c\u0026str, _\u003e = with_retry(\n            || async {\n                let count = counter.fetch_add(1, Ordering::SeqCst);\n                // RateLimited has its own backoff duration (5 seconds)\n                Err(MemoryError::RateLimited(format!(\"Attempt {}\", count)))\n            },\n            RetryConfig::default()\n        )\n        .await;\n\n        assert!(result.is_err());\n        // Should fail immediately after max retries since RateLimited has\n        // error-specific backoff\n        assert!(counter.load(Ordering::SeqCst) \u003e 0);\n    }\n\n    // Test implementation of WithRetry trait\n    struct TestRetryable;\n\n    impl WithRetry for TestRetryable {\n        type Output = String;\n\n        async fn with_retry\u003cF, Fut\u003e(operation: F) -\u003e MemoryResult\u003cSelf::Output\u003e\n        where\n            F: Fn() -\u003e Fut,\n            Fut: std::future::Future\u003cOutput = MemoryResult\u003cSelf::Output\u003e\u003e\n        {\n            with_retry(operation, RetryConfig::default()).await\n        }\n    }\n\n    #[tokio::test]\n    async fn test_with_retry_trait_implementation() {\n        let counter = AtomicUsize::new(0);\n\n        let result = TestRetryable::with_retry(|| async {\n            let count = counter.fetch_add(1, Ordering::SeqCst);\n            if count \u003c 1 {\n                Err(MemoryError::NetworkError(\"Temporary\".to_string()))\n            } else {\n                Ok(\"trait success\".to_string())\n            }\n        })\n        .await;\n\n        assert_eq!(result.unwrap(), \"trait success\");\n        assert_eq!(counter.load(Ordering::SeqCst), 2);\n    }\n}\n","traces":[{"line":43,"address":[],"length":0,"stats":{"Line":15}},{"line":44,"address":[],"length":0,"stats":{"Line":15}},{"line":48,"address":[],"length":0,"stats":{"Line":13}},{"line":49,"address":[],"length":0,"stats":{"Line":2}},{"line":53,"address":[],"length":0,"stats":{"Line":2}},{"line":54,"address":[],"length":0,"stats":{"Line":2}},{"line":55,"address":[],"length":0,"stats":{"Line":1}},{"line":56,"address":[],"length":0,"stats":{"Line":1}},{"line":60,"address":[],"length":0,"stats":{"Line":12}},{"line":61,"address":[],"length":0,"stats":{"Line":12}},{"line":62,"address":[],"length":0,"stats":{"Line":4}},{"line":63,"address":[],"length":0,"stats":{"Line":7}},{"line":64,"address":[],"length":0,"stats":{"Line":1}},{"line":90,"address":[],"length":0,"stats":{"Line":5}},{"line":93,"address":[],"length":0,"stats":{"Line":5}},{"line":94,"address":[],"length":0,"stats":{"Line":5}},{"line":101,"address":[],"length":0,"stats":{"Line":6}},{"line":106,"address":[],"length":0,"stats":{"Line":12}},{"line":107,"address":[],"length":0,"stats":{"Line":12}},{"line":109,"address":[],"length":0,"stats":{"Line":21}},{"line":110,"address":[],"length":0,"stats":{"Line":30}},{"line":111,"address":[],"length":0,"stats":{"Line":8}},{"line":112,"address":[],"length":0,"stats":{"Line":11}},{"line":113,"address":[],"length":0,"stats":{"Line":22}},{"line":115,"address":[],"length":0,"stats":{"Line":11}},{"line":116,"address":[],"length":0,"stats":{"Line":1}},{"line":119,"address":[],"length":0,"stats":{"Line":40}},{"line":121,"address":[],"length":0,"stats":{"Line":10}},{"line":122,"address":[],"length":0,"stats":{"Line":1}},{"line":125,"address":[],"length":0,"stats":{"Line":18}},{"line":126,"address":[],"length":0,"stats":{"Line":18}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":4}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":1}},{"line":162,"address":[],"length":0,"stats":{"Line":2}},{"line":163,"address":[],"length":0,"stats":{"Line":1}},{"line":164,"address":[],"length":0,"stats":{"Line":1}},{"line":165,"address":[],"length":0,"stats":{"Line":1}},{"line":168,"address":[],"length":0,"stats":{"Line":1}},{"line":185,"address":[],"length":0,"stats":{"Line":3}},{"line":187,"address":[],"length":0,"stats":{"Line":12}},{"line":192,"address":[],"length":0,"stats":{"Line":3}},{"line":196,"address":[],"length":0,"stats":{"Line":10}},{"line":201,"address":[],"length":0,"stats":{"Line":20}},{"line":203,"address":[],"length":0,"stats":{"Line":10}},{"line":204,"address":[],"length":0,"stats":{"Line":3}},{"line":205,"address":[],"length":0,"stats":{"Line":3}},{"line":206,"address":[],"length":0,"stats":{"Line":4}},{"line":207,"address":[],"length":0,"stats":{"Line":4}},{"line":208,"address":[],"length":0,"stats":{"Line":2}},{"line":210,"address":[],"length":0,"stats":{"Line":1}},{"line":211,"address":[],"length":0,"stats":{"Line":1}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":7}},{"line":219,"address":[],"length":0,"stats":{"Line":7}},{"line":223,"address":[],"length":0,"stats":{"Line":18}},{"line":225,"address":[],"length":0,"stats":{"Line":18}},{"line":226,"address":[],"length":0,"stats":{"Line":9}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":5}},{"line":229,"address":[],"length":0,"stats":{"Line":1}},{"line":231,"address":[],"length":0,"stats":{"Line":1}},{"line":232,"address":[],"length":0,"stats":{"Line":1}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":7}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":17}},{"line":240,"address":[],"length":0,"stats":{"Line":3}},{"line":242,"address":[],"length":0,"stats":{"Line":4}},{"line":243,"address":[],"length":0,"stats":{"Line":6}},{"line":244,"address":[],"length":0,"stats":{"Line":2}},{"line":245,"address":[],"length":0,"stats":{"Line":2}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":9}}],"covered":68,"coverable":84},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","governance.rs"],"content":"use serde_json::Value;\n\npub struct GovernanceService {}\n\nimpl GovernanceService {\n    pub fn new() -\u003e Self {\n        Self {}\n    }\n\n    pub fn redact_pii(\u0026self, content: \u0026str) -\u003e String {\n        utils::redact_pii(content)\n    }\n\n    pub fn is_sensitive(\u0026self, metadata: \u0026Value) -\u003e bool {\n        if let Some(obj) = metadata.as_object() {\n            if let Some(sensitive) = obj.get(\"sensitive\") {\n                if let Some(b) = sensitive.as_bool() {\n                    if b {\n                        return true;\n                    }\n                }\n            }\n            if let Some(private) = obj.get(\"private\") {\n                if let Some(b) = private.as_bool() {\n                    if b {\n                        return true;\n                    }\n                }\n            }\n        }\n        false\n    }\n\n    pub fn can_promote(\u0026self, _content: \u0026str, metadata: \u0026Value) -\u003e bool {\n        if self.is_sensitive(metadata) {\n            return false;\n        }\n        true\n    }\n}\n\nimpl Default for GovernanceService {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use serde_json::json;\n\n    #[test]\n    fn test_pii_redaction() {\n        let service = GovernanceService::new();\n        let content = \"Contact me at user@example.com for details.\";\n        let redacted = service.redact_pii(content);\n        assert_eq!(redacted, \"Contact me at [REDACTED_EMAIL] for details.\");\n    }\n\n    #[test]\n    fn test_sensitivity_check() {\n        let service = GovernanceService::new();\n\n        let metadata_sensitive = json!({ \"sensitive\": true });\n        assert!(service.is_sensitive(\u0026metadata_sensitive));\n\n        let metadata_private = json!({ \"private\": true });\n        assert!(service.is_sensitive(\u0026metadata_private));\n\n        let metadata_safe = json!({ \"tags\": [\"rust\"] });\n        assert!(!service.is_sensitive(\u0026metadata_safe));\n    }\n\n    #[test]\n    fn test_can_promote() {\n        let service = GovernanceService::new();\n        let content = \"Safe content\";\n        let metadata = json!({ \"sensitive\": false });\n        assert!(service.can_promote(content, \u0026metadata));\n\n        let metadata_sensitive = json!({ \"sensitive\": true });\n        assert!(!service.can_promote(content, \u0026metadata_sensitive));\n    }\n\n    #[test]\n    fn test_governance_default() {\n        let _ = GovernanceService::default();\n    }\n\n    #[test]\n    fn test_is_sensitive_non_object() {\n        let service = GovernanceService::new();\n        assert!(!service.is_sensitive(\u0026json!(\"not an object\")));\n        assert!(!service.is_sensitive(\u0026json!(null)));\n    }\n\n    #[test]\n    fn test_is_sensitive_mixed_types() {\n        let service = GovernanceService::new();\n        assert!(!service.is_sensitive(\u0026json!({ \"sensitive\": \"true\" })));\n        assert!(!service.is_sensitive(\u0026json!({ \"private\": 123 })));\n    }\n}\n","traces":[{"line":6,"address":[],"length":0,"stats":{"Line":98}},{"line":10,"address":[],"length":0,"stats":{"Line":1050}},{"line":11,"address":[],"length":0,"stats":{"Line":2100}},{"line":14,"address":[],"length":0,"stats":{"Line":17}},{"line":15,"address":[],"length":0,"stats":{"Line":32}},{"line":16,"address":[],"length":0,"stats":{"Line":35}},{"line":17,"address":[],"length":0,"stats":{"Line":9}},{"line":18,"address":[],"length":0,"stats":{"Line":4}},{"line":19,"address":[],"length":0,"stats":{"Line":3}},{"line":23,"address":[],"length":0,"stats":{"Line":26}},{"line":24,"address":[],"length":0,"stats":{"Line":3}},{"line":25,"address":[],"length":0,"stats":{"Line":1}},{"line":26,"address":[],"length":0,"stats":{"Line":1}},{"line":31,"address":[],"length":0,"stats":{"Line":13}},{"line":34,"address":[],"length":0,"stats":{"Line":10}},{"line":35,"address":[],"length":0,"stats":{"Line":30}},{"line":36,"address":[],"length":0,"stats":{"Line":2}},{"line":38,"address":[],"length":0,"stats":{"Line":8}},{"line":43,"address":[],"length":0,"stats":{"Line":1}},{"line":44,"address":[],"length":0,"stats":{"Line":1}}],"covered":20,"coverable":20},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","hot_reload.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","lib.rs"],"content":"//! # Memory System\n//!\n//! Implementation of hierarchical memory storage and retrieval.\n\npub mod embedding;\npub mod episodic;\npub mod error;\npub mod governance;\npub mod llm;\npub mod manager;\npub mod procedural;\npub mod promotion;\npub mod providers;\npub mod telemetry;\npub mod working;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","llm","mock.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::LlmService;\nuse mk_core::types::{Policy, ValidationResult};\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\npub struct MockLlmService {\n    responses: Arc\u003cRwLock\u003cstd::collections::HashMap\u003cString, String\u003e\u003e\u003e\n}\n\nimpl MockLlmService {\n    pub fn new() -\u003e Self {\n        Self {\n            responses: Arc::new(RwLock::new(std::collections::HashMap::new()))\n        }\n    }\n\n    pub async fn add_response(\u0026self, prompt: String, response: String) {\n        let mut responses = self.responses.write().await;\n        responses.insert(prompt, response);\n    }\n}\n\n#[async_trait]\nimpl LlmService for MockLlmService {\n    type Error = anyhow::Error;\n\n    async fn generate(\u0026self, prompt: \u0026str) -\u003e Result\u003cString, Self::Error\u003e {\n        let responses = self.responses.read().await;\n        if let Some(response) = responses.get(prompt) {\n            Ok(response.clone())\n        } else {\n            Ok(format!(\"Mock response for: {}\", prompt))\n        }\n    }\n\n    async fn analyze_drift(\n        \u0026self,\n        content: \u0026str,\n        policies: \u0026[Policy]\n    ) -\u003e Result\u003cValidationResult, Self::Error\u003e {\n        let mut is_valid = true;\n        let mut violations = Vec::new();\n\n        for policy in policies {\n            for rule in \u0026policy.rules {\n                if content.contains(\u0026format!(\"violate:{}\", rule.id)) {\n                    is_valid = false;\n                    violations.push(mk_core::types::PolicyViolation {\n                        rule_id: rule.id.clone(),\n                        policy_id: policy.id.clone(),\n                        severity: rule.severity,\n                        message: format!(\n                            \"Semantic violation of rule {}: {}\",\n                            rule.id, rule.message\n                        ),\n                        context: std::collections::HashMap::new()\n                    });\n                }\n            }\n        }\n\n        Ok(ValidationResult {\n            is_valid,\n            violations\n        })\n    }\n}\n","traces":[{"line":12,"address":[],"length":0,"stats":{"Line":5}},{"line":14,"address":[],"length":0,"stats":{"Line":10}},{"line":18,"address":[],"length":0,"stats":{"Line":0}},{"line":19,"address":[],"length":0,"stats":{"Line":0}},{"line":20,"address":[],"length":0,"stats":{"Line":0}},{"line":28,"address":[],"length":0,"stats":{"Line":0}}],"covered":2,"coverable":6},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","llm","mod.rs"],"content":"pub mod mock;\npub mod openai;\n\npub use mock::MockLlmService;\npub use openai::OpenAILlmService;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","llm","openai.rs"],"content":"use async_openai::types::{\n    ChatCompletionRequestSystemMessageArgs, ChatCompletionRequestUserMessageArgs,\n    CreateChatCompletionRequestArgs\n};\nuse async_trait::async_trait;\nuse mk_core::traits::LlmService;\nuse mk_core::types::{Policy, ValidationResult};\nuse std::num::NonZeroUsize;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\npub struct OpenAILlmService {\n    client: async_openai::Client\u003casync_openai::config::OpenAIConfig\u003e,\n    model: String,\n    cache: Arc\u003cRwLock\u003clru::LruCache\u003cString, String\u003e\u003e\u003e\n}\n\nimpl OpenAILlmService {\n    pub fn new(api_key: String, model: String) -\u003e Self {\n        let config = async_openai::config::OpenAIConfig::new().with_api_key(api_key);\n        let client = async_openai::Client::with_config(config);\n        let cache = lru::LruCache::new(NonZeroUsize::new(100).unwrap());\n\n        Self {\n            client,\n            model,\n            cache: Arc::new(RwLock::new(cache))\n        }\n    }\n}\n\n#[async_trait]\nimpl LlmService for OpenAILlmService {\n    type Error = anyhow::Error;\n\n    async fn generate(\u0026self, prompt: \u0026str) -\u003e Result\u003cString, Self::Error\u003e {\n        {\n            let mut cache = self.cache.write().await;\n            if let Some(cached) = cache.get(prompt) {\n                return Ok(cached.clone());\n            }\n        }\n\n        let request = CreateChatCompletionRequestArgs::default()\n            .model(\u0026self.model)\n            .messages([ChatCompletionRequestUserMessageArgs::default()\n                .content(prompt)\n                .build()?\n                .into()])\n            .build()?;\n\n        let response = self.client.chat().create(request).await?;\n        let content = response\n            .choices\n            .first()\n            .and_then(|choice| choice.message.content.clone())\n            .unwrap_or_default();\n\n        {\n            let mut cache = self.cache.write().await;\n            cache.put(prompt.to_string(), content.clone());\n        }\n\n        Ok(content)\n    }\n\n    async fn analyze_drift(\n        \u0026self,\n        content: \u0026str,\n        policies: \u0026[Policy]\n    ) -\u003e Result\u003cValidationResult, Self::Error\u003e {\n        let policies_json = serde_json::to_string_pretty(policies)?;\n        let prompt = format!(\n            \"Analyze the following content against the provided governance policies.\\nReturn a \\\n             JSON object with 'isValid' (boolean) and 'violations' (array of PolicyViolation \\\n             objects).\\nPolicyViolation schema: {{ 'ruleId': string, 'policyId': string, \\\n             'severity': 'info'|'warn'|'block', 'message': string, 'context': object \\\n             }}\\n\\nContent:\\n{}\\n\\nPolicies:\\n{}\",\n            content, policies_json\n        );\n\n        let system_prompt = \"You are a governance analysis engine. You strictly evaluate content \\\n                             against policies and return structured JSON results.\";\n\n        let request = CreateChatCompletionRequestArgs::default()\n            .model(\u0026self.model)\n            .messages([\n                ChatCompletionRequestSystemMessageArgs::default()\n                    .content(system_prompt)\n                    .build()?\n                    .into(),\n                ChatCompletionRequestUserMessageArgs::default()\n                    .content(\u0026*prompt)\n                    .build()?\n                    .into()\n            ])\n            .response_format(async_openai::types::ResponseFormat::JsonObject)\n            .build()?;\n\n        let response = self.client.chat().create(request).await?;\n        let result_json = response\n            .choices\n            .first()\n            .and_then(|choice| choice.message.content.clone())\n            .ok_or_else(|| anyhow::anyhow!(\"Empty response from OpenAI\"))?;\n\n        let result: ValidationResult = serde_json::from_str(\u0026result_json)?;\n        Ok(result)\n    }\n}\n","traces":[{"line":19,"address":[],"length":0,"stats":{"Line":0}},{"line":20,"address":[],"length":0,"stats":{"Line":0}},{"line":21,"address":[],"length":0,"stats":{"Line":0}},{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":9},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","loader.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","manager.rs"],"content":"use crate::governance::GovernanceService;\nuse crate::telemetry::MemoryTelemetry;\nuse mk_core::traits::MemoryProviderAdapter;\nuse mk_core::traits::{AuthorizationService, EmbeddingService};\nuse mk_core::types::{MemoryEntry, MemoryLayer};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\npub type ProviderMap = HashMap\u003c\n    MemoryLayer,\n    Box\u003cdyn MemoryProviderAdapter\u003cError = Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e + Send + Sync\u003e\n\u003e;\n\npub struct MemoryManager {\n    providers: Arc\u003cRwLock\u003cProviderMap\u003e\u003e,\n    embedding_service: Option\u003c\n        Arc\u003cdyn EmbeddingService\u003cError = Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e + Send + Sync\u003e\n    \u003e,\n    governance_service: Arc\u003cGovernanceService\u003e,\n    auth_service: Option\u003c\n        Arc\u003c\n            dyn AuthorizationService\u003cError = Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e\n                + Send\n                + Sync\n        \u003e\n    \u003e,\n    telemetry: Arc\u003cMemoryTelemetry\u003e,\n    config: config::MemoryConfig\n}\n\nimpl MemoryManager {\n    pub fn new() -\u003e Self {\n        Self {\n            providers: Arc::new(RwLock::new(HashMap::new())),\n            embedding_service: None,\n            governance_service: Arc::new(GovernanceService::new()),\n            auth_service: None,\n            telemetry: Arc::new(MemoryTelemetry::new()),\n            config: config::MemoryConfig::default()\n        }\n    }\n\n    pub fn with_config(mut self, config: config::MemoryConfig) -\u003e Self {\n        self.config = config;\n        self\n    }\n\n    pub fn with_embedding_service(\n        mut self,\n        embedding_service: Arc\u003c\n            dyn EmbeddingService\u003cError = Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e + Send + Sync\n        \u003e\n    ) -\u003e Self {\n        self.embedding_service = Some(embedding_service);\n        self\n    }\n\n    pub fn with_auth_service(\n        mut self,\n        auth_service: Arc\u003c\n            dyn AuthorizationService\u003cError = Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e\n                + Send\n                + Sync\n        \u003e\n    ) -\u003e Self {\n        self.auth_service = Some(auth_service);\n        self\n    }\n\n    pub fn with_telemetry(mut self, telemetry: Arc\u003cMemoryTelemetry\u003e) -\u003e Self {\n        self.telemetry = telemetry;\n        self\n    }\n}\n\nimpl Default for MemoryManager {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\nimpl MemoryManager {\n    pub async fn register_provider(\n        \u0026self,\n        layer: MemoryLayer,\n        provider: Box\u003c\n            dyn MemoryProviderAdapter\u003cError = Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e\n                + Send\n                + Sync\n        \u003e\n    ) {\n        let mut providers = self.providers.write().await;\n        providers.insert(layer, provider);\n    }\n\n    pub async fn search_hierarchical(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        query_vector: Vec\u003cf32\u003e,\n        limit: usize,\n        filters: HashMap\u003cString, serde_json::Value\u003e\n    ) -\u003e Result\u003cVec\u003cMemoryEntry\u003e, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        if let Some(auth) = \u0026self.auth_service {\n            if !auth\n                .check_permission(\u0026ctx, \"memory:read\", \"hierarchical\")\n                .await?\n            {\n                return Err(\"Unauthorized to search hierarchical memory\".into());\n            }\n        }\n\n        let start = std::time::Instant::now();\n        let providers = self.providers.read().await;\n        let mut all_results = Vec::new();\n\n        for (layer, provider) in providers.iter() {\n            let layer_str = format!(\"{:?}\", layer);\n            let _span = self.telemetry.record_operation_start(\"search\", \u0026layer_str);\n            match provider\n                .search(ctx.clone(), query_vector.clone(), limit, filters.clone())\n                .await\n            {\n                Ok(results) =\u003e {\n                    self.telemetry.record_operation_success(\n                        \"search\",\n                        \u0026layer_str,\n                        start.elapsed().as_millis() as f64\n                    );\n                    for mut entry in results {\n                        entry.layer = *layer;\n                        all_results.push(entry);\n                    }\n                }\n                Err(e) =\u003e {\n                    self.telemetry\n                        .record_operation_failure(\"search\", \u0026layer_str, \u0026e.to_string());\n                    tracing::error!(\"Error searching layer {:?}: {}\", layer, e)\n                }\n            }\n        }\n\n        all_results.sort_by(|a, b| a.layer.precedence().cmp(\u0026b.layer.precedence()));\n\n        let final_results: Vec\u003cMemoryEntry\u003e = all_results.into_iter().take(limit).collect();\n        self.telemetry\n            .record_search_operation(final_results.len(), query_vector.len());\n        Ok(final_results)\n    }\n\n    pub async fn search_with_threshold(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        query_vector: Vec\u003cf32\u003e,\n        limit: usize,\n        threshold: f32,\n        filters: HashMap\u003cString, serde_json::Value\u003e\n    ) -\u003e Result\u003cVec\u003cMemoryEntry\u003e, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let providers = self.providers.read().await;\n        let mut all_results = Vec::new();\n\n        for (layer, provider) in providers.iter() {\n            match provider\n                .search(ctx.clone(), query_vector.clone(), limit, filters.clone())\n                .await\n            {\n                Ok(results) =\u003e {\n                    for mut entry in results {\n                        let score = entry\n                            .metadata\n                            .get(\"score\")\n                            .and_then(|s| s.as_f64())\n                            .map(|s| s as f32)\n                            .unwrap_or(1.0);\n\n                        if score \u003e= threshold {\n                            entry.layer = *layer;\n                            all_results.push(entry);\n                        }\n                    }\n                }\n                Err(e) =\u003e tracing::error!(\"Error searching layer {:?}: {}\", layer, e)\n            }\n        }\n\n        all_results.sort_by(|a, b| a.layer.precedence().cmp(\u0026b.layer.precedence()));\n\n        Ok(all_results.into_iter().take(limit).collect())\n    }\n\n    pub async fn search_text_with_threshold(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        query_text: \u0026str,\n        limit: usize,\n        threshold: f32,\n        filters: HashMap\u003cString, serde_json::Value\u003e\n    ) -\u003e Result\u003cVec\u003cMemoryEntry\u003e, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let embedding_service = self\n            .embedding_service\n            .as_ref()\n            .ok_or(\"Embedding service not configured\")?;\n\n        let query_vector = embedding_service.embed(query_text).await?;\n\n        self.search_with_threshold(ctx, query_vector, limit, threshold, filters)\n            .await\n    }\n\n    pub async fn add_to_layer(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer,\n        mut entry: MemoryEntry\n    ) -\u003e Result\u003cString, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        if let Some(auth) = \u0026self.auth_service {\n            if !auth\n                .check_permission(\u0026ctx, \"memory:write\", \u0026format!(\"layer:{:?}\", layer))\n                .await?\n            {\n                return Err(\"Unauthorized to write to this memory layer\".into());\n            }\n        }\n\n        let start = std::time::Instant::now();\n        let layer_str = format!(\"{:?}\", layer);\n        let _span = self.telemetry.record_operation_start(\"add\", \u0026layer_str);\n\n        let original_content = entry.content.clone();\n        entry.content = self.governance_service.redact_pii(\u0026entry.content);\n        if entry.content != original_content {\n            self.telemetry.record_governance_redaction(\u0026layer_str);\n        }\n\n        let providers = self.providers.read().await;\n        let provider = providers\n            .get(\u0026layer)\n            .ok_or(\"No provider registered for layer\")?;\n\n        match provider.add(ctx, entry).await {\n            Ok(id) =\u003e {\n                self.telemetry.record_operation_success(\n                    \"add\",\n                    \u0026layer_str,\n                    start.elapsed().as_millis() as f64\n                );\n                Ok(id)\n            }\n            Err(e) =\u003e {\n                self.telemetry\n                    .record_operation_failure(\"add\", \u0026layer_str, \u0026e.to_string());\n                Err(e)\n            }\n        }\n    }\n\n    pub async fn delete_from_layer(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer,\n        id: \u0026str\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let providers = self.providers.read().await;\n        let provider = providers\n            .get(\u0026layer)\n            .ok_or(\"No provider registered for layer\")?;\n        provider.delete(ctx, id).await\n    }\n\n    pub async fn get_from_layer(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer,\n        id: \u0026str\n    ) -\u003e Result\u003cOption\u003cMemoryEntry\u003e, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let providers = self.providers.read().await;\n        let provider = providers\n            .get(\u0026layer)\n            .ok_or(\"No provider registered for layer\")?;\n\n        let entry = provider.get(ctx.clone(), id).await?;\n\n        if let Some(mut entry) = entry {\n            let now = chrono::Utc::now().timestamp();\n            let count = entry\n                .metadata\n                .get(\"access_count\")\n                .and_then(|v| v.as_u64())\n                .unwrap_or(0)\n                + 1;\n\n            entry\n                .metadata\n                .insert(\"access_count\".to_string(), serde_json::json!(count));\n            entry\n                .metadata\n                .insert(\"last_accessed_at\".to_string(), serde_json::json!(now));\n            entry.updated_at = now;\n\n            provider.update(ctx, entry.clone()).await?;\n            Ok(Some(entry))\n        } else {\n            Ok(None)\n        }\n    }\n\n    pub async fn list_all_from_layer(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer\n    ) -\u003e Result\u003cVec\u003cMemoryEntry\u003e, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let providers = self.providers.read().await;\n        let provider = providers\n            .get(\u0026layer)\n            .ok_or(\"No provider registered for layer\")?;\n\n        let (result, _) = provider.list(ctx, layer, 1000, None).await?;\n        Ok(result)\n    }\n\n    pub async fn promote_memory(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        id: \u0026str,\n        source_layer: MemoryLayer,\n        target_layer: MemoryLayer\n    ) -\u003e Result\u003cString, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let entry = self\n            .get_from_layer(ctx.clone(), source_layer, id)\n            .await?\n            .ok_or_else(|| format!(\"Memory {} not found in layer {:?}\", id, source_layer))?;\n\n        let mut promoted_entry = entry.clone();\n        promoted_entry.id = format!(\"{}_promoted\", entry.id);\n        promoted_entry.layer = target_layer;\n\n        let now = chrono::Utc::now().timestamp();\n        promoted_entry.metadata.insert(\n            \"original_memory_id\".to_string(),\n            serde_json::json!(entry.id)\n        );\n        promoted_entry\n            .metadata\n            .insert(\"promoted_at\".to_string(), serde_json::json!(now));\n\n        self.add_to_layer(ctx, target_layer, promoted_entry).await\n    }\n\n    pub async fn promote_important_memories(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer\n    ) -\u003e Result\u003cVec\u003cString\u003e, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        use crate::promotion::PromotionService;\n        let promotion_service = PromotionService::new(Arc::new(MemoryManager {\n            providers: self.providers.clone(),\n            embedding_service: self.embedding_service.clone(),\n            governance_service: self.governance_service.clone(),\n            auth_service: self.auth_service.clone(),\n            telemetry: self.telemetry.clone(),\n            config: self.config.clone()\n        }))\n        .with_config(self.config.clone())\n        .with_telemetry(self.telemetry.clone());\n\n        promotion_service\n            .promote_layer_memories(ctx, layer, \u0026mk_core::types::LayerIdentifiers::default())\n            .await\n            .map_err(|e| {\n                Box::new(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    e.to_string()\n                )) as Box\u003cdyn std::error::Error + Send + Sync\u003e\n            })\n    }\n\n    pub async fn close_session(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        session_id: \u0026str\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        tracing::info!(\"Closing session: {}\", session_id);\n\n        self.promote_important_memories(ctx.clone(), MemoryLayer::Session)\n            .await?;\n\n        self.delete_from_layer(ctx, MemoryLayer::Session, session_id)\n            .await?;\n\n        Ok(())\n    }\n\n    pub async fn close_agent(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        agent_id: \u0026str\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        tracing::info!(\"Closing agent: {}\", agent_id);\n\n        self.promote_important_memories(ctx.clone(), MemoryLayer::Agent)\n            .await?;\n\n        self.delete_from_layer(ctx, MemoryLayer::Agent, agent_id)\n            .await?;\n\n        Ok(())\n    }\n}\n\n#[cfg(test)]\npub(crate) mod tests {\n    use super::*;\n    use crate::providers::MockProvider;\n    use mk_core::types::TenantContext;\n\n    pub(crate) fn test_ctx() -\u003e TenantContext {\n        use std::str::FromStr;\n        TenantContext {\n            tenant_id: mk_core::types::TenantId::from_str(\"test-tenant\").unwrap(),\n            user_id: mk_core::types::UserId::from_str(\"test-user\").unwrap(),\n            agent_id: None\n        }\n    }\n\n    #[tokio::test]\n    async fn test_hierarchical_search() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let agent_provider = Box::new(MockProvider::new());\n        let session_provider = Box::new(MockProvider::new());\n\n        manager\n            .register_provider(MemoryLayer::Agent, agent_provider)\n            .await;\n        manager\n            .register_provider(MemoryLayer::Session, session_provider)\n            .await;\n\n        let agent_entry = MemoryEntry {\n            id: \"agent_1\".to_string(),\n            content: \"agent content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        let session_entry = MemoryEntry {\n            id: \"session_1\".to_string(),\n            content: \"session content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Agent, agent_entry)\n            .await\n            .unwrap();\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Session, session_entry)\n            .await\n            .unwrap();\n\n        let results = manager\n            .search_hierarchical(ctx, vec![], 10, HashMap::new())\n            .await\n            .unwrap();\n\n        assert_eq!(results.len(), 2);\n        assert_eq!(results[0].id, \"agent_1\");\n        assert_eq!(results[1].id, \"session_1\");\n    }\n\n    #[tokio::test]\n    async fn test_search_with_threshold() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let provider = Box::new(MockProvider::new());\n\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let entry_high_score = MemoryEntry {\n            id: \"high_score\".to_string(),\n            content: \"high score content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: {\n                let mut map = HashMap::new();\n                map.insert(\"score\".to_string(), serde_json::json!(0.9));\n                map\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n\n        let entry_low_score = MemoryEntry {\n            id: \"low_score\".to_string(),\n            content: \"low score content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: {\n                let mut map = HashMap::new();\n                map.insert(\"score\".to_string(), serde_json::json!(0.5));\n                map\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry_high_score)\n            .await\n            .unwrap();\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry_low_score)\n            .await\n            .unwrap();\n\n        let results = manager\n            .search_with_threshold(ctx.clone(), vec![], 10, 0.7, HashMap::new())\n            .await\n            .unwrap();\n\n        assert_eq!(results.len(), 1);\n        assert_eq!(results[0].id, \"high_score\");\n\n        let results = manager\n            .search_with_threshold(ctx, vec![], 10, 0.3, HashMap::new())\n            .await\n            .unwrap();\n\n        assert_eq!(results.len(), 2);\n    }\n\n    #[tokio::test]\n    async fn test_search_with_threshold_no_score_in_metadata() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let provider = Box::new(MockProvider::new());\n\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let entry = MemoryEntry {\n            id: \"no_score\".to_string(),\n            content: \"no score content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n            .await\n            .unwrap();\n\n        let results = manager\n            .search_with_threshold(ctx, vec![], 10, 0.8, HashMap::new())\n            .await\n            .unwrap();\n\n        assert_eq!(results.len(), 1);\n        assert_eq!(results[0].id, \"no_score\");\n    }\n\n    #[tokio::test]\n    async fn test_add_to_layer_with_governance() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let provider = Box::new(MockProvider::new());\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let entry = MemoryEntry {\n            id: \"mem_1\".to_string(),\n            content: \"Contact user@example.com\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n            .await\n            .unwrap();\n\n        let retrieved = manager\n            .get_from_layer(ctx, MemoryLayer::User, \"mem_1\")\n            .await\n            .unwrap()\n            .unwrap();\n        assert_eq!(retrieved.content, \"Contact [REDACTED_EMAIL]\");\n    }\n\n    #[tokio::test]\n    async fn test_delete_from_layer() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let provider = Box::new(MockProvider::new());\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let entry = MemoryEntry {\n            id: \"mem_1\".to_string(),\n            content: \"test\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n            .await\n            .unwrap();\n        manager\n            .delete_from_layer(ctx.clone(), MemoryLayer::User, \"mem_1\")\n            .await\n            .unwrap();\n\n        let retrieved = manager\n            .get_from_layer(ctx, MemoryLayer::User, \"mem_1\")\n            .await\n            .unwrap();\n        assert!(retrieved.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_promote_memory_manual() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let mock_session = Box::new(MockProvider::new());\n        let mock_project = Box::new(MockProvider::new());\n        manager\n            .register_provider(MemoryLayer::Session, mock_session)\n            .await;\n        manager\n            .register_provider(MemoryLayer::Project, mock_project)\n            .await;\n\n        let entry = MemoryEntry {\n            id: \"session_mem\".to_string(),\n            content: \"to be promoted\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Session, entry)\n            .await\n            .unwrap();\n        manager\n            .promote_memory(\n                ctx.clone(),\n                \"session_mem\",\n                MemoryLayer::Session,\n                MemoryLayer::Project\n            )\n            .await\n            .unwrap();\n\n        let promoted = manager\n            .get_from_layer(ctx, MemoryLayer::Project, \"session_mem_promoted\")\n            .await\n            .unwrap();\n        assert!(promoted.is_some());\n    }\n\n    #[tokio::test]\n    async fn test_search_precedence_ordering() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let agent_provider = Box::new(MockProvider::new());\n        let user_provider = Box::new(MockProvider::new());\n\n        manager\n            .register_provider(MemoryLayer::Agent, agent_provider)\n            .await;\n        manager\n            .register_provider(MemoryLayer::User, user_provider)\n            .await;\n\n        let agent_entry = MemoryEntry {\n            id: \"agent_high_priority\".to_string(),\n            content: \"agent content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: {\n                let mut map = HashMap::new();\n                map.insert(\"score\".to_string(), serde_json::json!(0.5));\n                map\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n\n        let user_entry = MemoryEntry {\n            id: \"user_high_similarity\".to_string(),\n            content: \"user content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: {\n                let mut map = HashMap::new();\n                map.insert(\"score\".to_string(), serde_json::json!(0.9));\n                map\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Agent, agent_entry)\n            .await\n            .unwrap();\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, user_entry)\n            .await\n            .unwrap();\n\n        let results = manager\n            .search_hierarchical(ctx, vec![], 10, HashMap::new())\n            .await\n            .unwrap();\n\n        assert_eq!(results.len(), 2);\n        assert_eq!(results[0].id, \"agent_high_priority\");\n        assert_eq!(results[1].id, \"user_high_similarity\");\n    }\n\n    #[tokio::test]\n    async fn test_close_session_triggers_promotion() {\n        let manager = MemoryManager::new().with_config(config::MemoryConfig {\n            promotion_threshold: 0.5\n        });\n        let ctx = test_ctx();\n        let mock_session = Box::new(MockProvider::new());\n        let mock_project = Box::new(MockProvider::new());\n        manager\n            .register_provider(MemoryLayer::Session, mock_session)\n            .await;\n        manager\n            .register_provider(MemoryLayer::Project, mock_project)\n            .await;\n\n        let entry = MemoryEntry {\n            id: \"important\".to_string(),\n            content: \"highly important\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(1.0));\n                m\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Session, entry)\n            .await\n            .unwrap();\n        manager.close_session(ctx.clone(), \"some_id\").await.unwrap();\n\n        let promoted = manager\n            .list_all_from_layer(ctx, MemoryLayer::Project)\n            .await\n            .unwrap();\n        assert!(!promoted.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_search_text_with_threshold_requires_embedding_service() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let provider = Box::new(MockProvider::new());\n\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let result = manager\n            .search_text_with_threshold(ctx, \"test query\", 10, 0.7, HashMap::new())\n            .await;\n\n        assert!(result.is_err());\n        assert!(\n            result\n                .unwrap_err()\n                .to_string()\n                .contains(\"Embedding service not configured\")\n        );\n    }\n\n    #[tokio::test]\n    async fn test_hierarchical_search_provider_error() {\n        struct FailingProvider;\n        #[async_trait::async_trait]\n        impl mk_core::traits::MemoryProviderAdapter for FailingProvider {\n            type Error = Box\u003cdyn std::error::Error + Send + Sync\u003e;\n            async fn add(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry\n            ) -\u003e Result\u003cString, Self::Error\u003e {\n                Ok(\"id\".to_string())\n            }\n            async fn get(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _id: \u0026str\n            ) -\u003e Result\u003cOption\u003cMemoryEntry\u003e, Self::Error\u003e {\n                Ok(None)\n            }\n            async fn search(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _v: Vec\u003cf32\u003e,\n                _l: usize,\n                _f: HashMap\u003cString, serde_json::Value\u003e\n            ) -\u003e Result\u003cVec\u003cMemoryEntry\u003e, Self::Error\u003e {\n                Err(\"search failed\".into())\n            }\n            async fn update(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Ok(())\n            }\n            async fn delete(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _id: \u0026str\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Ok(())\n            }\n            async fn list(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _l: MemoryLayer,\n                _lim: usize,\n                _c: Option\u003cString\u003e\n            ) -\u003e Result\u003c(Vec\u003cMemoryEntry\u003e, Option\u003cString\u003e), Self::Error\u003e {\n                Ok((vec![], None))\n            }\n        }\n\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        manager\n            .register_provider(MemoryLayer::Agent, Box::new(FailingProvider))\n            .await;\n\n        let results = manager\n            .search_hierarchical(ctx, vec![0.0], 10, HashMap::new())\n            .await\n            .unwrap();\n        assert!(results.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_close_agent_triggers_promotion() {\n        let manager = MemoryManager::new().with_config(config::MemoryConfig {\n            promotion_threshold: 0.5,\n            ..Default::default()\n        });\n        let ctx = test_ctx();\n        let mock_agent = Box::new(MockProvider::new());\n        let mock_user = Box::new(MockProvider::new());\n        manager\n            .register_provider(MemoryLayer::Agent, mock_agent)\n            .await;\n        manager\n            .register_provider(MemoryLayer::User, mock_user)\n            .await;\n\n        let entry = MemoryEntry {\n            id: \"agent_mem\".to_string(),\n            content: \"agent memory content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(1.0));\n                m\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Agent, entry)\n            .await\n            .unwrap();\n        manager.close_agent(ctx.clone(), \"agent_id\").await.unwrap();\n\n        let promoted = manager\n            .list_all_from_layer(ctx, MemoryLayer::User)\n            .await\n            .unwrap();\n        assert!(!promoted.is_empty());\n        assert_eq!(\n            promoted[0].metadata.get(\"original_memory_id\").unwrap(),\n            \"agent_mem\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_search_text_with_threshold_success() {\n        use crate::embedding::mock::MockEmbeddingService;\n        let manager =\n            MemoryManager::new().with_embedding_service(Arc::new(MockEmbeddingService::new(1536)));\n        let ctx = test_ctx();\n\n        let provider = Box::new(MockProvider::new());\n        manager.register_provider(MemoryLayer::User, provider).await;\n\n        let entry = MemoryEntry {\n            id: \"text_mem\".to_string(),\n            content: \"some text content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(0.9));\n                m\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::User, entry)\n            .await\n            .unwrap();\n\n        let results = manager\n            .search_text_with_threshold(ctx, \"query\", 10, 0.5, HashMap::new())\n            .await\n            .unwrap();\n        assert_eq!(results.len(), 1);\n        assert_eq!(results[0].id, \"text_mem\");\n    }\n\n    #[tokio::test]\n    async fn test_with_telemetry_and_default() {\n        let telemetry = Arc::new(MemoryTelemetry::new());\n        let manager = MemoryManager::default().with_telemetry(telemetry);\n        assert!(manager.embedding_service.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_add_to_layer_no_provider() {\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        let entry = MemoryEntry {\n            id: \"test\".to_string(),\n            content: \"test\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        let result = manager.add_to_layer(ctx, MemoryLayer::User, entry).await;\n        assert!(result.is_err());\n        assert_eq!(\n            result.unwrap_err().to_string(),\n            \"No provider registered for layer\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_search_with_threshold_provider_error() {\n        struct FailingProvider;\n        #[async_trait::async_trait]\n        impl mk_core::traits::MemoryProviderAdapter for FailingProvider {\n            type Error = Box\u003cdyn std::error::Error + Send + Sync\u003e;\n            async fn add(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry\n            ) -\u003e Result\u003cString, Self::Error\u003e {\n                Ok(\"id\".into())\n            }\n            async fn get(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _id: \u0026str\n            ) -\u003e Result\u003cOption\u003cMemoryEntry\u003e, Self::Error\u003e {\n                Ok(None)\n            }\n            async fn search(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _v: Vec\u003cf32\u003e,\n                _l: usize,\n                _f: HashMap\u003cString, serde_json::Value\u003e\n            ) -\u003e Result\u003cVec\u003cMemoryEntry\u003e, Self::Error\u003e {\n                Err(\"search failed\".into())\n            }\n            async fn update(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Ok(())\n            }\n            async fn delete(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _id: \u0026str\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Ok(())\n            }\n            async fn list(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _l: MemoryLayer,\n                _lim: usize,\n                _c: Option\u003cString\u003e\n            ) -\u003e Result\u003c(Vec\u003cMemoryEntry\u003e, Option\u003cString\u003e), Self::Error\u003e {\n                Ok((vec![], None))\n            }\n        }\n\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        manager\n            .register_provider(MemoryLayer::User, Box::new(FailingProvider))\n            .await;\n\n        let results = manager\n            .search_with_threshold(ctx, vec![0.0], 10, 0.5, HashMap::new())\n            .await\n            .unwrap();\n        assert!(results.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_promote_important_memories_error_mapping() {\n        struct ErrorProvider;\n        #[async_trait::async_trait]\n        impl mk_core::traits::MemoryProviderAdapter for ErrorProvider {\n            type Error = Box\u003cdyn std::error::Error + Send + Sync\u003e;\n            async fn add(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry\n            ) -\u003e Result\u003cString, Self::Error\u003e {\n                Ok(\"id\".into())\n            }\n            async fn get(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _id: \u0026str\n            ) -\u003e Result\u003cOption\u003cMemoryEntry\u003e, Self::Error\u003e {\n                Ok(None)\n            }\n            async fn search(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _v: Vec\u003cf32\u003e,\n                _l: usize,\n                _f: HashMap\u003cString, serde_json::Value\u003e\n            ) -\u003e Result\u003cVec\u003cMemoryEntry\u003e, Self::Error\u003e {\n                Err(\"list failed\".into())\n            }\n            async fn update(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Ok(())\n            }\n            async fn delete(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _id: \u0026str\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Ok(())\n            }\n            async fn list(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _l: MemoryLayer,\n                _lim: usize,\n                _c: Option\u003cString\u003e\n            ) -\u003e Result\u003c(Vec\u003cMemoryEntry\u003e, Option\u003cString\u003e), Self::Error\u003e {\n                Err(\"list failed\".into())\n            }\n        }\n\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        manager\n            .register_provider(MemoryLayer::Session, Box::new(ErrorProvider))\n            .await;\n\n        let result = manager\n            .promote_important_memories(ctx, MemoryLayer::Session)\n            .await;\n        assert!(result.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_add_to_layer_provider_error() {\n        struct FailingAddProvider;\n        #[async_trait::async_trait]\n        impl mk_core::traits::MemoryProviderAdapter for FailingAddProvider {\n            type Error = Box\u003cdyn std::error::Error + Send + Sync\u003e;\n            async fn add(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry\n            ) -\u003e Result\u003cString, Self::Error\u003e {\n                Err(\"add failed\".into())\n            }\n            async fn get(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _id: \u0026str\n            ) -\u003e Result\u003cOption\u003cMemoryEntry\u003e, Self::Error\u003e {\n                Ok(None)\n            }\n            async fn search(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _v: Vec\u003cf32\u003e,\n                _l: usize,\n                _f: HashMap\u003cString, serde_json::Value\u003e\n            ) -\u003e Result\u003cVec\u003cMemoryEntry\u003e, Self::Error\u003e {\n                Ok(vec![])\n            }\n            async fn update(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _e: MemoryEntry\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Ok(())\n            }\n            async fn delete(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _id: \u0026str\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Ok(())\n            }\n            async fn list(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _l: MemoryLayer,\n                _lim: usize,\n                _c: Option\u003cString\u003e\n            ) -\u003e Result\u003c(Vec\u003cMemoryEntry\u003e, Option\u003cString\u003e), Self::Error\u003e {\n                Ok((vec![], None))\n            }\n        }\n\n        let manager = MemoryManager::new();\n        let ctx = test_ctx();\n        manager\n            .register_provider(MemoryLayer::User, Box::new(FailingAddProvider))\n            .await;\n\n        let entry = MemoryEntry {\n            id: \"test\".to_string(),\n            content: \"test\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        let result = manager.add_to_layer(ctx, MemoryLayer::User, entry).await;\n        assert!(result.is_err());\n        assert_eq!(result.unwrap_err().to_string(), \"add failed\");\n    }\n}\n","traces":[{"line":33,"address":[],"length":0,"stats":{"Line":82}},{"line":35,"address":[],"length":0,"stats":{"Line":328}},{"line":37,"address":[],"length":0,"stats":{"Line":246}},{"line":39,"address":[],"length":0,"stats":{"Line":164}},{"line":40,"address":[],"length":0,"stats":{"Line":82}},{"line":44,"address":[],"length":0,"stats":{"Line":2}},{"line":45,"address":[],"length":0,"stats":{"Line":2}},{"line":46,"address":[],"length":0,"stats":{"Line":2}},{"line":49,"address":[],"length":0,"stats":{"Line":2}},{"line":55,"address":[],"length":0,"stats":{"Line":4}},{"line":56,"address":[],"length":0,"stats":{"Line":2}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":1}},{"line":72,"address":[],"length":0,"stats":{"Line":2}},{"line":73,"address":[],"length":0,"stats":{"Line":1}},{"line":78,"address":[],"length":0,"stats":{"Line":1}},{"line":79,"address":[],"length":0,"stats":{"Line":1}},{"line":84,"address":[],"length":0,"stats":{"Line":50}},{"line":93,"address":[],"length":0,"stats":{"Line":100}},{"line":94,"address":[],"length":0,"stats":{"Line":150}},{"line":97,"address":[],"length":0,"stats":{"Line":3}},{"line":104,"address":[],"length":0,"stats":{"Line":3}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":6}},{"line":114,"address":[],"length":0,"stats":{"Line":6}},{"line":115,"address":[],"length":0,"stats":{"Line":6}},{"line":117,"address":[],"length":0,"stats":{"Line":16}},{"line":118,"address":[],"length":0,"stats":{"Line":15}},{"line":119,"address":[],"length":0,"stats":{"Line":20}},{"line":120,"address":[],"length":0,"stats":{"Line":5}},{"line":121,"address":[],"length":0,"stats":{"Line":40}},{"line":122,"address":[],"length":0,"stats":{"Line":5}},{"line":124,"address":[],"length":0,"stats":{"Line":4}},{"line":125,"address":[],"length":0,"stats":{"Line":12}},{"line":127,"address":[],"length":0,"stats":{"Line":8}},{"line":128,"address":[],"length":0,"stats":{"Line":4}},{"line":130,"address":[],"length":0,"stats":{"Line":16}},{"line":131,"address":[],"length":0,"stats":{"Line":8}},{"line":132,"address":[],"length":0,"stats":{"Line":8}},{"line":135,"address":[],"length":0,"stats":{"Line":1}},{"line":136,"address":[],"length":0,"stats":{"Line":2}},{"line":137,"address":[],"length":0,"stats":{"Line":4}},{"line":138,"address":[],"length":0,"stats":{"Line":1}},{"line":143,"address":[],"length":0,"stats":{"Line":12}},{"line":145,"address":[],"length":0,"stats":{"Line":21}},{"line":146,"address":[],"length":0,"stats":{"Line":6}},{"line":147,"address":[],"length":0,"stats":{"Line":12}},{"line":148,"address":[],"length":0,"stats":{"Line":3}},{"line":151,"address":[],"length":0,"stats":{"Line":7}},{"line":159,"address":[],"length":0,"stats":{"Line":14}},{"line":160,"address":[],"length":0,"stats":{"Line":14}},{"line":162,"address":[],"length":0,"stats":{"Line":28}},{"line":163,"address":[],"length":0,"stats":{"Line":7}},{"line":164,"address":[],"length":0,"stats":{"Line":56}},{"line":165,"address":[],"length":0,"stats":{"Line":7}},{"line":167,"address":[],"length":0,"stats":{"Line":6}},{"line":168,"address":[],"length":0,"stats":{"Line":20}},{"line":169,"address":[],"length":0,"stats":{"Line":14}},{"line":170,"address":[],"length":0,"stats":{"Line":7}},{"line":172,"address":[],"length":0,"stats":{"Line":17}},{"line":173,"address":[],"length":0,"stats":{"Line":12}},{"line":176,"address":[],"length":0,"stats":{"Line":13}},{"line":177,"address":[],"length":0,"stats":{"Line":12}},{"line":178,"address":[],"length":0,"stats":{"Line":12}},{"line":182,"address":[],"length":0,"stats":{"Line":2}},{"line":186,"address":[],"length":0,"stats":{"Line":17}},{"line":188,"address":[],"length":0,"stats":{"Line":28}},{"line":191,"address":[],"length":0,"stats":{"Line":6}},{"line":199,"address":[],"length":0,"stats":{"Line":9}},{"line":200,"address":[],"length":0,"stats":{"Line":6}},{"line":204,"address":[],"length":0,"stats":{"Line":9}},{"line":206,"address":[],"length":0,"stats":{"Line":21}},{"line":207,"address":[],"length":0,"stats":{"Line":3}},{"line":210,"address":[],"length":0,"stats":{"Line":1044}},{"line":216,"address":[],"length":0,"stats":{"Line":1044}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":221,"address":[],"length":0,"stats":{"Line":0}},{"line":225,"address":[],"length":0,"stats":{"Line":2088}},{"line":226,"address":[],"length":0,"stats":{"Line":3132}},{"line":227,"address":[],"length":0,"stats":{"Line":4176}},{"line":229,"address":[],"length":0,"stats":{"Line":3132}},{"line":230,"address":[],"length":0,"stats":{"Line":3132}},{"line":231,"address":[],"length":0,"stats":{"Line":1045}},{"line":232,"address":[],"length":0,"stats":{"Line":2}},{"line":235,"address":[],"length":0,"stats":{"Line":2088}},{"line":236,"address":[],"length":0,"stats":{"Line":3131}},{"line":237,"address":[],"length":0,"stats":{"Line":1044}},{"line":240,"address":[],"length":0,"stats":{"Line":5215}},{"line":241,"address":[],"length":0,"stats":{"Line":1042}},{"line":242,"address":[],"length":0,"stats":{"Line":3126}},{"line":244,"address":[],"length":0,"stats":{"Line":2084}},{"line":245,"address":[],"length":0,"stats":{"Line":1042}},{"line":247,"address":[],"length":0,"stats":{"Line":1042}},{"line":249,"address":[],"length":0,"stats":{"Line":1}},{"line":250,"address":[],"length":0,"stats":{"Line":2}},{"line":251,"address":[],"length":0,"stats":{"Line":4}},{"line":252,"address":[],"length":0,"stats":{"Line":1}},{"line":257,"address":[],"length":0,"stats":{"Line":16}},{"line":263,"address":[],"length":0,"stats":{"Line":32}},{"line":264,"address":[],"length":0,"stats":{"Line":42}},{"line":265,"address":[],"length":0,"stats":{"Line":16}},{"line":267,"address":[],"length":0,"stats":{"Line":40}},{"line":270,"address":[],"length":0,"stats":{"Line":1016}},{"line":276,"address":[],"length":0,"stats":{"Line":2032}},{"line":277,"address":[],"length":0,"stats":{"Line":3048}},{"line":278,"address":[],"length":0,"stats":{"Line":1016}},{"line":281,"address":[],"length":0,"stats":{"Line":6096}},{"line":283,"address":[],"length":0,"stats":{"Line":2028}},{"line":284,"address":[],"length":0,"stats":{"Line":3036}},{"line":285,"address":[],"length":0,"stats":{"Line":2024}},{"line":286,"address":[],"length":0,"stats":{"Line":1012}},{"line":287,"address":[],"length":0,"stats":{"Line":2024}},{"line":288,"address":[],"length":0,"stats":{"Line":1016}},{"line":289,"address":[],"length":0,"stats":{"Line":1012}},{"line":292,"address":[],"length":0,"stats":{"Line":1012}},{"line":293,"address":[],"length":0,"stats":{"Line":1012}},{"line":294,"address":[],"length":0,"stats":{"Line":4048}},{"line":295,"address":[],"length":0,"stats":{"Line":1012}},{"line":296,"address":[],"length":0,"stats":{"Line":1012}},{"line":297,"address":[],"length":0,"stats":{"Line":4048}},{"line":298,"address":[],"length":0,"stats":{"Line":1012}},{"line":300,"address":[],"length":0,"stats":{"Line":5060}},{"line":301,"address":[],"length":0,"stats":{"Line":1012}},{"line":303,"address":[],"length":0,"stats":{"Line":4}},{"line":307,"address":[],"length":0,"stats":{"Line":5}},{"line":312,"address":[],"length":0,"stats":{"Line":10}},{"line":313,"address":[],"length":0,"stats":{"Line":15}},{"line":314,"address":[],"length":0,"stats":{"Line":5}},{"line":317,"address":[],"length":0,"stats":{"Line":30}},{"line":318,"address":[],"length":0,"stats":{"Line":4}},{"line":321,"address":[],"length":0,"stats":{"Line":1}},{"line":328,"address":[],"length":0,"stats":{"Line":3}},{"line":329,"address":[],"length":0,"stats":{"Line":5}},{"line":330,"address":[],"length":0,"stats":{"Line":1}},{"line":331,"address":[],"length":0,"stats":{"Line":1}},{"line":333,"address":[],"length":0,"stats":{"Line":3}},{"line":334,"address":[],"length":0,"stats":{"Line":3}},{"line":335,"address":[],"length":0,"stats":{"Line":1}},{"line":337,"address":[],"length":0,"stats":{"Line":3}},{"line":338,"address":[],"length":0,"stats":{"Line":2}},{"line":339,"address":[],"length":0,"stats":{"Line":2}},{"line":340,"address":[],"length":0,"stats":{"Line":1}},{"line":342,"address":[],"length":0,"stats":{"Line":1}},{"line":343,"address":[],"length":0,"stats":{"Line":1}},{"line":344,"address":[],"length":0,"stats":{"Line":4}},{"line":346,"address":[],"length":0,"stats":{"Line":5}},{"line":349,"address":[],"length":0,"stats":{"Line":3}},{"line":355,"address":[],"length":0,"stats":{"Line":12}},{"line":356,"address":[],"length":0,"stats":{"Line":9}},{"line":357,"address":[],"length":0,"stats":{"Line":9}},{"line":358,"address":[],"length":0,"stats":{"Line":9}},{"line":359,"address":[],"length":0,"stats":{"Line":9}},{"line":360,"address":[],"length":0,"stats":{"Line":9}},{"line":361,"address":[],"length":0,"stats":{"Line":3}},{"line":363,"address":[],"length":0,"stats":{"Line":9}},{"line":364,"address":[],"length":0,"stats":{"Line":9}},{"line":366,"address":[],"length":0,"stats":{"Line":6}},{"line":367,"address":[],"length":0,"stats":{"Line":12}},{"line":368,"address":[],"length":0,"stats":{"Line":3}},{"line":369,"address":[],"length":0,"stats":{"Line":4}},{"line":370,"address":[],"length":0,"stats":{"Line":3}},{"line":371,"address":[],"length":0,"stats":{"Line":2}},{"line":372,"address":[],"length":0,"stats":{"Line":2}},{"line":373,"address":[],"length":0,"stats":{"Line":1}},{"line":377,"address":[],"length":0,"stats":{"Line":1}},{"line":382,"address":[],"length":0,"stats":{"Line":1}},{"line":384,"address":[],"length":0,"stats":{"Line":5}},{"line":385,"address":[],"length":0,"stats":{"Line":1}},{"line":387,"address":[],"length":0,"stats":{"Line":5}},{"line":388,"address":[],"length":0,"stats":{"Line":1}},{"line":390,"address":[],"length":0,"stats":{"Line":1}},{"line":393,"address":[],"length":0,"stats":{"Line":1}},{"line":398,"address":[],"length":0,"stats":{"Line":1}},{"line":400,"address":[],"length":0,"stats":{"Line":5}},{"line":401,"address":[],"length":0,"stats":{"Line":1}},{"line":403,"address":[],"length":0,"stats":{"Line":5}},{"line":404,"address":[],"length":0,"stats":{"Line":1}},{"line":406,"address":[],"length":0,"stats":{"Line":1}}],"covered":174,"coverable":185},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","opencode.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","pointer.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","pool.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","postgres.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","procedural.rs"],"content":"\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","promotion","mod.rs"],"content":"use crate::governance::GovernanceService;\nuse crate::manager::MemoryManager;\nuse crate::telemetry::MemoryTelemetry;\nuse anyhow::{Context, Result};\nuse mk_core::types::{MemoryEntry, MemoryLayer};\nuse std::sync::Arc;\n\npub struct PromotionService {\n    memory_manager: Arc\u003cMemoryManager\u003e,\n    governance_service: Arc\u003cGovernanceService\u003e,\n    telemetry: Arc\u003cMemoryTelemetry\u003e,\n    config: config::MemoryConfig,\n    promote_important: bool,\n    cleanup_after_promotion: bool\n}\n\nimpl PromotionService {\n    pub fn new(memory_manager: Arc\u003cMemoryManager\u003e) -\u003e Self {\n        Self {\n            memory_manager,\n            governance_service: Arc::new(GovernanceService::new()),\n            telemetry: Arc::new(MemoryTelemetry::new()),\n            config: config::MemoryConfig::default(),\n            promote_important: true,\n            cleanup_after_promotion: false\n        }\n    }\n\n    pub fn with_config(mut self, config: config::MemoryConfig) -\u003e Self {\n        self.config = config;\n        self\n    }\n\n    pub fn with_telemetry(mut self, telemetry: Arc\u003cMemoryTelemetry\u003e) -\u003e Self {\n        self.telemetry = telemetry;\n        self\n    }\n\n    pub fn with_promote_important(mut self, promote: bool) -\u003e Self {\n        self.promote_important = promote;\n        self\n    }\n\n    pub fn with_cleanup(mut self, cleanup: bool) -\u003e Self {\n        self.cleanup_after_promotion = cleanup;\n        self\n    }\n\n    pub async fn evaluate_and_promote(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        entry: \u0026MemoryEntry\n    ) -\u003e Result\u003cOption\u003cString\u003e\u003e {\n        if !self.promote_important {\n            return Ok(None);\n        }\n\n        let metadata_value = serde_json::to_value(\u0026entry.metadata).unwrap_or(serde_json::json!({}));\n        if !self\n            .governance_service\n            .can_promote(\u0026entry.content, \u0026metadata_value)\n        {\n            tracing::info!(\"Memory {} promotion blocked by governance\", entry.id);\n            self.telemetry\n                .record_promotion_blocked(\u0026format!(\"{:?}\", entry.layer), \"governance\");\n            return Ok(None);\n        }\n\n        let score = self.calculate_importance_score(entry);\n\n        if score \u003e= self.config.promotion_threshold {\n            if let Some(target) = self.determine_target_layer(entry.layer) {\n                self.telemetry.record_promotion_attempt(\n                    \u0026format!(\"{:?}\", entry.layer),\n                    \u0026format!(\"{:?}\", target)\n                );\n                tracing::info!(\n                    \"Promoting memory {} from {:?} to {:?} (score: {:.2})\",\n                    entry.id,\n                    entry.layer,\n                    target,\n                    score\n                );\n\n                let mut promoted_entry = entry.clone();\n                promoted_entry.id = format!(\"{}_promoted\", entry.id);\n                promoted_entry.layer = target;\n                let original_content = entry.content.clone();\n                promoted_entry.content = self.governance_service.redact_pii(\u0026entry.content);\n\n                if promoted_entry.content != original_content {\n                    self.telemetry\n                        .record_governance_redaction(\u0026format!(\"{:?}\", target));\n                }\n\n                promoted_entry.metadata.insert(\n                    \"original_memory_id\".to_string(),\n                    serde_json::json!(entry.id)\n                );\n                promoted_entry.metadata.insert(\n                    \"promoted_at\".to_string(),\n                    serde_json::json!(chrono::Utc::now().timestamp())\n                );\n                promoted_entry\n                    .metadata\n                    .insert(\"promotion_score\".to_string(), serde_json::json!(score));\n\n                let new_id = self\n                    .memory_manager\n                    .add_to_layer(ctx.clone(), target, promoted_entry)\n                    .await\n                    .map_err(|e| anyhow::anyhow!(e))\n                    .context(\"Failed to add promoted memory to target layer\")?;\n\n                if self.cleanup_after_promotion {\n                    self.memory_manager\n                        .delete_from_layer(ctx, entry.layer, \u0026entry.id)\n                        .await\n                        .map_err(|e| anyhow::anyhow!(e))\n                        .context(\"Failed to cleanup source memory after promotion\")?;\n                    tracing::info!(\n                        \"Cleaned up source memory {} from {:?}\",\n                        entry.id,\n                        entry.layer\n                    );\n                }\n\n                self.telemetry.record_promotion_success(\n                    \u0026format!(\"{:?}\", entry.layer),\n                    \u0026format!(\"{:?}\", target)\n                );\n                return Ok(Some(new_id));\n            }\n        }\n\n        Ok(None)\n    }\n\n    fn calculate_importance_score(\u0026self, entry: \u0026MemoryEntry) -\u003e f32 {\n        let explicit_score = entry\n            .metadata\n            .get(\"score\")\n            .and_then(|v| v.as_f64())\n            .map(|v| v as f32)\n            .unwrap_or(0.0);\n\n        let access_count = entry\n            .metadata\n            .get(\"access_count\")\n            .and_then(|v| v.as_u64())\n            .unwrap_or(1) as f32;\n\n        let last_accessed = entry\n            .metadata\n            .get(\"last_accessed_at\")\n            .and_then(|v| v.as_i64())\n            .unwrap_or_else(|| chrono::Utc::now().timestamp()) as f32;\n\n        let now_ts = chrono::Utc::now().timestamp() as f32;\n        let days_since_last_access = (now_ts - last_accessed).max(0.0) / 86400.0;\n        let recency_score = (1.0f32 - days_since_last_access).max(0.0f32);\n\n        let frequency_score = (access_count / 10.0).min(1.0);\n\n        (explicit_score * 0.6) + (frequency_score * 0.3) + (recency_score * 0.1)\n    }\n\n    pub async fn promote_layer_memories(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer,\n        _identifiers: \u0026mk_core::types::LayerIdentifiers\n    ) -\u003e Result\u003cVec\u003cString\u003e\u003e {\n        let entries = self\n            .memory_manager\n            .list_all_from_layer(ctx.clone(), layer)\n            .await\n            .map_err(|e| anyhow::anyhow!(e))?;\n\n        let mut promoted_ids = Vec::new();\n        for entry in entries {\n            if let Some(new_id) = self.evaluate_and_promote(ctx.clone(), \u0026entry).await? {\n                promoted_ids.push(new_id);\n            }\n        }\n        Ok(promoted_ids)\n    }\n\n    fn determine_target_layer(\u0026self, current_layer: MemoryLayer) -\u003e Option\u003cMemoryLayer\u003e {\n        match current_layer {\n            MemoryLayer::Agent =\u003e Some(MemoryLayer::User),\n            MemoryLayer::Session =\u003e Some(MemoryLayer::Project),\n            _ =\u003e None\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::manager::tests::test_ctx;\n    use crate::providers::MockProvider;\n    use mk_core::types::MemoryEntry;\n    use std::collections::HashMap;\n\n    #[tokio::test]\n    async fn test_evaluate_and_promote_high_score() {\n        let manager = Arc::new(MemoryManager::new());\n        let ctx = test_ctx();\n        let mock_session = Box::new(MockProvider::new());\n        let mock_project = Box::new(MockProvider::new());\n\n        manager\n            .register_provider(MemoryLayer::Session, mock_session)\n            .await;\n        manager\n            .register_provider(MemoryLayer::Project, mock_project)\n            .await;\n\n        let service = PromotionService::new(manager.clone()).with_config(config::MemoryConfig {\n            promotion_threshold: 0.7\n        });\n\n        let entry = MemoryEntry {\n            id: \"mem_1\".to_string(),\n            content: \"important stuff\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(1.0));\n                m.insert(\"access_count\".to_string(), serde_json::json!(10));\n                m.insert(\n                    \"last_accessed_at\".to_string(),\n                    serde_json::json!(chrono::Utc::now().timestamp())\n                );\n                m\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n\n        let result = service\n            .evaluate_and_promote(ctx.clone(), \u0026entry)\n            .await\n            .unwrap();\n        assert!(result.is_some());\n        assert!(result.unwrap().contains(\"mem_1_promoted\"));\n\n        let promoted = manager\n            .get_from_layer(ctx.clone(), MemoryLayer::Project, \"mem_1_promoted\")\n            .await\n            .unwrap();\n        assert!(promoted.is_some());\n        assert_eq!(\n            promoted\n                .unwrap()\n                .metadata\n                .get(\"original_memory_id\")\n                .unwrap(),\n            \"mem_1\"\n        );\n    }\n\n    #[tokio::test]\n    async fn test_evaluate_and_promote_low_score() {\n        let manager = Arc::new(MemoryManager::new());\n        let ctx = test_ctx();\n        let service = PromotionService::new(manager).with_config(config::MemoryConfig {\n            promotion_threshold: 0.8\n        });\n\n        let entry = MemoryEntry {\n            id: \"mem_low\".to_string(),\n            content: \"boring stuff\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(0.2));\n                m\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n\n        let result = service.evaluate_and_promote(ctx, \u0026entry).await.unwrap();\n        assert!(result.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_promotion_blocked_by_governance() {\n        let manager = Arc::new(MemoryManager::new());\n        let ctx = test_ctx();\n        let service = PromotionService::new(manager);\n\n        let entry = MemoryEntry {\n            id: \"mem_sensitive\".to_string(),\n            content: \"secret stuff\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"score\".to_string(), serde_json::json!(1.0));\n                m.insert(\"sensitive\".to_string(), serde_json::json!(true));\n                m\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n\n        let result = service.evaluate_and_promote(ctx, \u0026entry).await.unwrap();\n        assert!(result.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_promotion_redacts_pii() {\n        let manager = Arc::new(MemoryManager::new());\n        let ctx = test_ctx();\n        let mock_session = Box::new(MockProvider::new());\n        let mock_project = Box::new(MockProvider::new());\n        manager\n            .register_provider(MemoryLayer::Session, mock_session)\n            .await;\n        manager\n            .register_provider(MemoryLayer::Project, mock_project)\n            .await;\n\n        let service = PromotionService::new(manager.clone()).with_config(config::MemoryConfig {\n            promotion_threshold: 0.0\n        });\n\n        let entry = MemoryEntry {\n            id: \"mem_pii\".to_string(),\n            content: \"Contact user@example.com\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        let result = service\n            .evaluate_and_promote(ctx.clone(), \u0026entry)\n            .await\n            .unwrap();\n        assert!(result.is_some());\n\n        let promoted = manager\n            .get_from_layer(ctx, MemoryLayer::Project, result.unwrap().as_str())\n            .await\n            .unwrap()\n            .unwrap();\n        assert_eq!(promoted.content, \"Contact [REDACTED_EMAIL]\");\n    }\n\n    #[tokio::test]\n    async fn test_promotion_cleanup() {\n        let manager = Arc::new(MemoryManager::new());\n        let ctx = test_ctx();\n        let mock_session = Box::new(MockProvider::new());\n        let mock_project = Box::new(MockProvider::new());\n        manager\n            .register_provider(MemoryLayer::Session, mock_session)\n            .await;\n        manager\n            .register_provider(MemoryLayer::Project, mock_project)\n            .await;\n\n        let service = PromotionService::new(manager.clone())\n            .with_config(config::MemoryConfig {\n                promotion_threshold: 0.0\n            })\n            .with_cleanup(true);\n\n        let entry = MemoryEntry {\n            id: \"mem_cleanup\".to_string(),\n            content: \"cleanup test\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        manager\n            .add_to_layer(ctx.clone(), MemoryLayer::Session, entry.clone())\n            .await\n            .unwrap();\n\n        let result = service\n            .evaluate_and_promote(ctx.clone(), \u0026entry)\n            .await\n            .unwrap();\n        assert!(result.is_some());\n\n        let promoted = manager\n            .get_from_layer(ctx.clone(), MemoryLayer::Project, result.unwrap().as_str())\n            .await\n            .unwrap();\n        assert!(promoted.is_some());\n\n        let original = manager\n            .get_from_layer(ctx, MemoryLayer::Session, \"mem_cleanup\")\n            .await\n            .unwrap();\n        assert!(original.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_with_promote_important_false() {\n        let manager = Arc::new(MemoryManager::new());\n        let ctx = test_ctx();\n        let service = PromotionService::new(manager).with_promote_important(false);\n\n        let entry = MemoryEntry {\n            id: \"test\".to_string(),\n            content: \"test\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Session,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        let result = service.evaluate_and_promote(ctx, \u0026entry).await.unwrap();\n        assert!(result.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_determine_target_layer_none() {\n        let manager = Arc::new(MemoryManager::new());\n        let ctx = test_ctx();\n        let service = PromotionService::new(manager);\n\n        let entry = MemoryEntry {\n            id: \"test\".to_string(),\n            content: \"test\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::User,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        let result = service.evaluate_and_promote(ctx, \u0026entry).await.unwrap();\n        assert!(result.is_none());\n    }\n}\n","traces":[{"line":18,"address":[],"length":0,"stats":{"Line":10}},{"line":21,"address":[],"length":0,"stats":{"Line":30}},{"line":22,"address":[],"length":0,"stats":{"Line":20}},{"line":23,"address":[],"length":0,"stats":{"Line":10}},{"line":29,"address":[],"length":0,"stats":{"Line":7}},{"line":30,"address":[],"length":0,"stats":{"Line":7}},{"line":31,"address":[],"length":0,"stats":{"Line":7}},{"line":34,"address":[],"length":0,"stats":{"Line":3}},{"line":35,"address":[],"length":0,"stats":{"Line":6}},{"line":36,"address":[],"length":0,"stats":{"Line":3}},{"line":39,"address":[],"length":0,"stats":{"Line":1}},{"line":40,"address":[],"length":0,"stats":{"Line":1}},{"line":41,"address":[],"length":0,"stats":{"Line":1}},{"line":44,"address":[],"length":0,"stats":{"Line":1}},{"line":45,"address":[],"length":0,"stats":{"Line":1}},{"line":46,"address":[],"length":0,"stats":{"Line":1}},{"line":49,"address":[],"length":0,"stats":{"Line":9}},{"line":54,"address":[],"length":0,"stats":{"Line":9}},{"line":55,"address":[],"length":0,"stats":{"Line":1}},{"line":58,"address":[],"length":0,"stats":{"Line":40}},{"line":59,"address":[],"length":0,"stats":{"Line":16}},{"line":60,"address":[],"length":0,"stats":{"Line":16}},{"line":61,"address":[],"length":0,"stats":{"Line":16}},{"line":63,"address":[],"length":0,"stats":{"Line":1}},{"line":64,"address":[],"length":0,"stats":{"Line":2}},{"line":65,"address":[],"length":0,"stats":{"Line":2}},{"line":66,"address":[],"length":0,"stats":{"Line":1}},{"line":69,"address":[],"length":0,"stats":{"Line":28}},{"line":71,"address":[],"length":0,"stats":{"Line":7}},{"line":72,"address":[],"length":0,"stats":{"Line":15}},{"line":73,"address":[],"length":0,"stats":{"Line":15}},{"line":74,"address":[],"length":0,"stats":{"Line":10}},{"line":75,"address":[],"length":0,"stats":{"Line":5}},{"line":77,"address":[],"length":0,"stats":{"Line":5}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":15}},{"line":86,"address":[],"length":0,"stats":{"Line":15}},{"line":87,"address":[],"length":0,"stats":{"Line":5}},{"line":88,"address":[],"length":0,"stats":{"Line":15}},{"line":89,"address":[],"length":0,"stats":{"Line":15}},{"line":91,"address":[],"length":0,"stats":{"Line":6}},{"line":92,"address":[],"length":0,"stats":{"Line":2}},{"line":93,"address":[],"length":0,"stats":{"Line":2}},{"line":96,"address":[],"length":0,"stats":{"Line":10}},{"line":97,"address":[],"length":0,"stats":{"Line":10}},{"line":98,"address":[],"length":0,"stats":{"Line":5}},{"line":100,"address":[],"length":0,"stats":{"Line":10}},{"line":101,"address":[],"length":0,"stats":{"Line":10}},{"line":102,"address":[],"length":0,"stats":{"Line":15}},{"line":104,"address":[],"length":0,"stats":{"Line":5}},{"line":105,"address":[],"length":0,"stats":{"Line":5}},{"line":106,"address":[],"length":0,"stats":{"Line":20}},{"line":108,"address":[],"length":0,"stats":{"Line":15}},{"line":109,"address":[],"length":0,"stats":{"Line":10}},{"line":110,"address":[],"length":0,"stats":{"Line":20}},{"line":111,"address":[],"length":0,"stats":{"Line":5}},{"line":112,"address":[],"length":0,"stats":{"Line":5}},{"line":115,"address":[],"length":0,"stats":{"Line":5}},{"line":116,"address":[],"length":0,"stats":{"Line":2}},{"line":117,"address":[],"length":0,"stats":{"Line":3}},{"line":118,"address":[],"length":0,"stats":{"Line":1}},{"line":119,"address":[],"length":0,"stats":{"Line":1}},{"line":121,"address":[],"length":0,"stats":{"Line":1}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":15}},{"line":129,"address":[],"length":0,"stats":{"Line":10}},{"line":130,"address":[],"length":0,"stats":{"Line":5}},{"line":132,"address":[],"length":0,"stats":{"Line":5}},{"line":136,"address":[],"length":0,"stats":{"Line":2}},{"line":139,"address":[],"length":0,"stats":{"Line":7}},{"line":140,"address":[],"length":0,"stats":{"Line":14}},{"line":141,"address":[],"length":0,"stats":{"Line":7}},{"line":143,"address":[],"length":0,"stats":{"Line":15}},{"line":144,"address":[],"length":0,"stats":{"Line":11}},{"line":147,"address":[],"length":0,"stats":{"Line":14}},{"line":148,"address":[],"length":0,"stats":{"Line":7}},{"line":149,"address":[],"length":0,"stats":{"Line":14}},{"line":150,"address":[],"length":0,"stats":{"Line":9}},{"line":151,"address":[],"length":0,"stats":{"Line":7}},{"line":153,"address":[],"length":0,"stats":{"Line":14}},{"line":154,"address":[],"length":0,"stats":{"Line":7}},{"line":155,"address":[],"length":0,"stats":{"Line":14}},{"line":156,"address":[],"length":0,"stats":{"Line":9}},{"line":157,"address":[],"length":0,"stats":{"Line":19}},{"line":159,"address":[],"length":0,"stats":{"Line":14}},{"line":160,"address":[],"length":0,"stats":{"Line":14}},{"line":161,"address":[],"length":0,"stats":{"Line":21}},{"line":163,"address":[],"length":0,"stats":{"Line":21}},{"line":165,"address":[],"length":0,"stats":{"Line":7}},{"line":168,"address":[],"length":0,"stats":{"Line":3}},{"line":174,"address":[],"length":0,"stats":{"Line":8}},{"line":175,"address":[],"length":0,"stats":{"Line":6}},{"line":176,"address":[],"length":0,"stats":{"Line":9}},{"line":177,"address":[],"length":0,"stats":{"Line":3}},{"line":178,"address":[],"length":0,"stats":{"Line":6}},{"line":180,"address":[],"length":0,"stats":{"Line":4}},{"line":181,"address":[],"length":0,"stats":{"Line":6}},{"line":182,"address":[],"length":0,"stats":{"Line":14}},{"line":183,"address":[],"length":0,"stats":{"Line":4}},{"line":186,"address":[],"length":0,"stats":{"Line":2}},{"line":189,"address":[],"length":0,"stats":{"Line":5}},{"line":190,"address":[],"length":0,"stats":{"Line":5}},{"line":191,"address":[],"length":0,"stats":{"Line":1}},{"line":192,"address":[],"length":0,"stats":{"Line":4}},{"line":193,"address":[],"length":0,"stats":{"Line":0}}],"covered":102,"coverable":105},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","providers","mod.rs"],"content":"pub mod qdrant;\n\nuse async_trait::async_trait;\nuse mk_core::traits::MemoryProviderAdapter;\nuse mk_core::types::{MemoryEntry, MemoryLayer};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\npub struct MockProvider {\n    entries: Arc\u003cRwLock\u003cHashMap\u003cString, MemoryEntry\u003e\u003e\u003e\n}\n\nimpl MockProvider {\n    pub fn new() -\u003e Self {\n        Self {\n            entries: Arc::new(RwLock::new(HashMap::new()))\n        }\n    }\n}\n\nimpl Default for MockProvider {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\n#[async_trait]\nimpl MemoryProviderAdapter for MockProvider {\n    type Error = Box\u003cdyn std::error::Error + Send + Sync\u003e;\n\n    async fn add(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        entry: MemoryEntry\n    ) -\u003e Result\u003cString, Self::Error\u003e {\n        let mut entries = self.entries.write().await;\n        let id = entry.id.clone();\n        let mut entry = entry;\n        entry\n            .metadata\n            .insert(\"tenant_id\".to_string(), serde_json::json!(ctx.tenant_id));\n        entries.insert(id.clone(), entry);\n        Ok(id)\n    }\n\n    async fn search(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        _query_vector: Vec\u003cf32\u003e,\n        limit: usize,\n        filters: HashMap\u003cString, serde_json::Value\u003e\n    ) -\u003e Result\u003cVec\u003cMemoryEntry\u003e, Self::Error\u003e {\n        let entries = self.entries.read().await;\n        let results: Vec\u003cMemoryEntry\u003e = entries\n            .values()\n            .filter(|entry| {\n                // Ensure tenant isolation in mock search\n                if entry.metadata.get(\"tenant_id\") != Some(\u0026serde_json::json!(ctx.tenant_id)) {\n                    return false;\n                }\n                for (key, val) in \u0026filters {\n                    if entry.metadata.get(key) != Some(val) {\n                        return false;\n                    }\n                }\n                true\n            })\n            .take(limit)\n            .cloned()\n            .collect();\n        Ok(results)\n    }\n\n    async fn get(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        id: \u0026str\n    ) -\u003e Result\u003cOption\u003cMemoryEntry\u003e, Self::Error\u003e {\n        let entries = self.entries.read().await;\n        if let Some(entry) = entries.get(id) {\n            if entry.metadata.get(\"tenant_id\") == Some(\u0026serde_json::json!(ctx.tenant_id)) {\n                return Ok(Some(entry.clone()));\n            }\n        }\n        Ok(None)\n    }\n\n    async fn update(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        entry: MemoryEntry\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        let mut entries = self.entries.write().await;\n        if let Some(existing) = entries.get(\u0026entry.id) {\n            if existing.metadata.get(\"tenant_id\") == Some(\u0026serde_json::json!(ctx.tenant_id)) {\n                let mut entry = entry;\n                entry\n                    .metadata\n                    .insert(\"tenant_id\".to_string(), serde_json::json!(ctx.tenant_id));\n                entries.insert(entry.id.clone(), entry);\n                return Ok(());\n            }\n        }\n        Err(\"Entry not found or access denied\".into())\n    }\n\n    async fn delete(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        id: \u0026str\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        let mut entries = self.entries.write().await;\n        if let Some(existing) = entries.get(id) {\n            if existing.metadata.get(\"tenant_id\") == Some(\u0026serde_json::json!(ctx.tenant_id)) {\n                entries.remove(id);\n            }\n        }\n        Ok(())\n    }\n\n    async fn list(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        layer: MemoryLayer,\n        limit: usize,\n        cursor: Option\u003cString\u003e\n    ) -\u003e Result\u003c(Vec\u003cMemoryEntry\u003e, Option\u003cString\u003e), Self::Error\u003e {\n        let entries = self.entries.read().await;\n        let mut results: Vec\u003cMemoryEntry\u003e = entries\n            .values()\n            .filter(|e| {\n                e.layer == layer\n                    \u0026\u0026 e.metadata.get(\"tenant_id\") == Some(\u0026serde_json::json!(ctx.tenant_id))\n            })\n            .collect::\u003cVec\u003c_\u003e\u003e()\n            .into_iter()\n            .cloned()\n            .collect();\n\n        results.sort_by(|a, b| a.id.cmp(\u0026b.id));\n\n        let start_index = if let Some(c) = cursor {\n            results\n                .iter()\n                .position(|e| e.id == c)\n                .map(|p| p + 1)\n                .unwrap_or(0)\n        } else {\n            0\n        };\n\n        let page = results\n            .iter()\n            .skip(start_index)\n            .take(limit)\n            .cloned()\n            .collect::\u003cVec\u003c_\u003e\u003e();\n        let next_cursor = if page.len() == limit \u0026\u0026 results.len() \u003e start_index + limit {\n            page.last().map(|e| e.id.clone())\n        } else {\n            None\n        };\n\n        Ok((page, next_cursor))\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::{MemoryLayer, TenantContext};\n\n    fn test_ctx() -\u003e TenantContext {\n        use std::str::FromStr;\n        TenantContext {\n            tenant_id: mk_core::types::TenantId::from_str(\"test-tenant\").unwrap(),\n            user_id: mk_core::types::UserId::from_str(\"test-user\").unwrap(),\n            agent_id: None\n        }\n    }\n\n    #[tokio::test]\n    async fn test_mock_provider_basic_ops() {\n        let provider = MockProvider::new();\n        let ctx = test_ctx();\n        let entry = MemoryEntry {\n            id: \"test1\".to_string(),\n            content: \"hello world\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n\n        provider.add(ctx.clone(), entry.clone()).await.unwrap();\n\n        let retrieved = provider.get(ctx.clone(), \"test1\").await.unwrap().unwrap();\n        assert_eq!(retrieved.content, \"hello world\");\n\n        let mut updated = entry.clone();\n        updated.content = \"updated\".to_string();\n        provider.update(ctx.clone(), updated).await.unwrap();\n        assert_eq!(\n            provider\n                .get(ctx.clone(), \"test1\")\n                .await\n                .unwrap()\n                .unwrap()\n                .content,\n            \"updated\"\n        );\n\n        let (list, _) = provider\n            .list(ctx.clone(), MemoryLayer::Agent, 10, None)\n            .await\n            .unwrap();\n        assert_eq!(list.len(), 1);\n\n        provider.delete(ctx.clone(), \"test1\").await.unwrap();\n        assert!(provider.get(ctx.clone(), \"test1\").await.unwrap().is_none());\n    }\n\n    #[tokio::test]\n    async fn test_mock_provider_update_nonexistent() {\n        let provider = MockProvider::new();\n        let ctx = test_ctx();\n        let entry = MemoryEntry {\n            id: \"ghost\".to_string(),\n            content: \"ghost\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: HashMap::new(),\n            created_at: 0,\n            updated_at: 0\n        };\n        assert!(provider.update(ctx, entry).await.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_mock_provider_search() {\n        let provider = MockProvider::new();\n        let ctx = test_ctx();\n        let entry1 = MemoryEntry {\n            id: \"1\".to_string(),\n            content: \"one\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"type\".to_string(), serde_json::json!(\"a\"));\n                m\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n        let entry2 = MemoryEntry {\n            id: \"2\".to_string(),\n            content: \"two\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: {\n                let mut m = HashMap::new();\n                m.insert(\"type\".to_string(), serde_json::json!(\"b\"));\n                m\n            },\n            created_at: 0,\n            updated_at: 0\n        };\n\n        provider.add(ctx.clone(), entry1).await.unwrap();\n        provider.add(ctx.clone(), entry2).await.unwrap();\n\n        let mut filters = HashMap::new();\n        filters.insert(\"type\".to_string(), serde_json::json!(\"a\"));\n\n        let results = provider.search(ctx, vec![], 10, filters).await.unwrap();\n        assert_eq!(results.len(), 1);\n        assert_eq!(results[0].id, \"1\");\n    }\n\n    #[tokio::test]\n    async fn test_mock_provider_list_pagination() {\n        let provider = MockProvider::new();\n        let ctx = test_ctx();\n        for i in 0..5 {\n            let entry = MemoryEntry {\n                id: format!(\"{}\", i),\n                content: format!(\"content {}\", i),\n                embedding: None,\n                layer: MemoryLayer::Agent,\n                metadata: HashMap::new(),\n                created_at: 0,\n                updated_at: 0\n            };\n            provider.add(ctx.clone(), entry).await.unwrap();\n        }\n\n        let (page1, cursor) = provider\n            .list(ctx.clone(), MemoryLayer::Agent, 2, None)\n            .await\n            .unwrap();\n        assert_eq!(page1.len(), 2);\n        assert!(cursor.is_some());\n\n        let (page2, cursor2) = provider\n            .list(ctx.clone(), MemoryLayer::Agent, 2, cursor)\n            .await\n            .unwrap();\n        assert_eq!(page2.len(), 2);\n        assert!(cursor2.is_some());\n\n        let (page3, cursor3) = provider\n            .list(ctx.clone(), MemoryLayer::Agent, 2, cursor2)\n            .await\n            .unwrap();\n        assert_eq!(page3.len(), 1);\n        assert!(cursor3.is_none());\n    }\n}\n","traces":[{"line":15,"address":[],"length":0,"stats":{"Line":50}},{"line":17,"address":[],"length":0,"stats":{"Line":100}},{"line":23,"address":[],"length":0,"stats":{"Line":0}},{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":13}},{"line":59,"address":[],"length":0,"stats":{"Line":26}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":18}},{"line":63,"address":[],"length":0,"stats":{"Line":4}},{"line":64,"address":[],"length":0,"stats":{"Line":1}},{"line":67,"address":[],"length":0,"stats":{"Line":12}},{"line":132,"address":[],"length":0,"stats":{"Line":20}},{"line":133,"address":[],"length":0,"stats":{"Line":20}},{"line":134,"address":[],"length":0,"stats":{"Line":40}},{"line":141,"address":[],"length":0,"stats":{"Line":81}},{"line":146,"address":[],"length":0,"stats":{"Line":12}},{"line":147,"address":[],"length":0,"stats":{"Line":2}},{"line":160,"address":[],"length":0,"stats":{"Line":4}}],"covered":15,"coverable":18},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","providers","qdrant.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::MemoryProviderAdapter;\nuse mk_core::types::{MemoryEntry, MemoryLayer};\nuse qdrant_client::{\n    Qdrant,\n    qdrant::{\n        Distance, PointId, PointStruct, ScoredPoint, Value as QdrantValue, VectorParams,\n        VectorsConfig, point_id::PointIdOptions, vectors_config::Config\n    }\n};\nuse serde_json::{Value, json};\n\nuse std::collections::HashMap;\nuse std::sync::Arc;\n\npub struct QdrantProvider {\n    client: Arc\u003cQdrant\u003e,\n    collection_name: String,\n    embedding_dimension: usize\n}\n\nimpl QdrantProvider {\n    pub fn new(client: Qdrant, collection_name: String, embedding_dimension: usize) -\u003e Self {\n        Self {\n            client: Arc::new(client),\n            collection_name,\n            embedding_dimension\n        }\n    }\n\n    pub async fn ensure_collection(\u0026self) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let collections_list = self.client.list_collections().await?;\n        let collection_exists = collections_list\n            .collections\n            .iter()\n            .any(|c| c.name == self.collection_name);\n\n        if !collection_exists {\n            use qdrant_client::qdrant::CreateCollectionBuilder;\n            let request = CreateCollectionBuilder::new(self.collection_name.clone())\n                .vectors_config(VectorsConfig {\n                    config: Some(Config::Params(VectorParams {\n                        size: self.embedding_dimension as u64,\n                        distance: Distance::Cosine.into(),\n                        ..Default::default()\n                    }))\n                });\n\n            self.client.create_collection(request).await?;\n        }\n\n        Ok(())\n    }\n\n    fn entry_to_point(\n        \u0026self,\n        entry: \u0026MemoryEntry\n    ) -\u003e Result\u003cPointStruct, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let embedding = entry.embedding.as_ref().ok_or(\"Entry missing embedding\")?;\n\n        let mut payload: HashMap\u003cString, QdrantValue\u003e = HashMap::from([\n            (\"id\".to_string(), entry.id.clone().into()),\n            (\"content\".to_string(), entry.content.clone().into()),\n            (\n                \"layer\".to_string(),\n                serde_json::to_string(\u0026entry.layer)?.into()\n            ),\n            (\"created_at\".to_string(), entry.created_at.into()),\n            (\"updated_at\".to_string(), entry.updated_at.into())\n        ]);\n\n        payload.insert(\n            \"metadata\".to_string(),\n            serde_json::to_string(\u0026entry.metadata)?.into()\n        );\n\n        Ok(PointStruct {\n            id: Some(PointId::from(entry.id.clone())),\n            vectors: Some(embedding.clone().into()),\n            payload\n        })\n    }\n\n    fn point_to_entry(\n        \u0026self,\n        point: ScoredPoint\n    ) -\u003e Result\u003cMemoryEntry, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let payload = point.payload;\n\n        let metadata_str = payload\n            .get(\"metadata\")\n            .and_then(|v| {\n                let v: Value = v.clone().into();\n                if v.is_string() {\n                    v.as_str().map(|s| s.to_string())\n                } else {\n                    None\n                }\n            })\n            .ok_or(\"Missing metadata in payload\")?;\n\n        let mut metadata: HashMap\u003cString, Value\u003e = serde_json::from_str(\u0026metadata_str)?;\n        metadata.insert(\"score\".to_string(), json!(point.score));\n\n        let vector = match point.vectors {\n            Some(v) =\u003e v\n                .get_vector()\n                .and_then(|vec| match vec {\n                    qdrant_client::qdrant::vector_output::Vector::Dense(dense) =\u003e Some(dense.data),\n                    _ =\u003e None\n                })\n                .ok_or(\"Unsupported or missing vector format\")?,\n            None =\u003e return Err(\"Point missing vector\".into())\n        };\n\n        let layer_str = payload\n            .get(\"layer\")\n            .and_then(|v| {\n                let v: Value = v.clone().into();\n                if v.is_string() {\n                    v.as_str().map(|s| s.to_string())\n                } else {\n                    None\n                }\n            })\n            .ok_or(\"Missing layer\")?;\n        let layer: MemoryLayer = serde_json::from_str(\u0026layer_str)?;\n\n        let id = payload\n            .get(\"id\")\n            .and_then(|v| {\n                let v: Value = v.clone().into();\n                v.as_str().map(|s| s.to_string())\n            })\n            .ok_or(\"Missing id\")?;\n\n        let content = payload\n            .get(\"content\")\n            .and_then(|v| {\n                let v: Value = v.clone().into();\n                v.as_str().map(|s| s.to_string())\n            })\n            .ok_or(\"Missing content\")?;\n\n        let created_at = payload\n            .get(\"created_at\")\n            .and_then(|v| {\n                let v: Value = v.clone().into();\n                v.as_i64()\n            })\n            .ok_or(\"Missing created_at\")?;\n\n        let updated_at = payload\n            .get(\"updated_at\")\n            .and_then(|v| {\n                let v: Value = v.clone().into();\n                v.as_i64()\n            })\n            .ok_or(\"Missing updated_at\")?;\n\n        Ok(MemoryEntry {\n            id,\n            content,\n            embedding: Some(vector),\n            layer,\n            metadata,\n            created_at,\n            updated_at\n        })\n    }\n}\n\n#[async_trait]\nimpl MemoryProviderAdapter for QdrantProvider {\n    type Error = Box\u003cdyn std::error::Error + Send + Sync\u003e;\n\n    async fn add(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        entry: MemoryEntry\n    ) -\u003e Result\u003cString, Self::Error\u003e {\n        self.ensure_collection().await?;\n        let mut entry = entry;\n\n        entry\n            .metadata\n            .insert(\"tenant_id\".to_string(), json!(ctx.tenant_id.as_str()));\n        entry\n            .metadata\n            .insert(\"user_id\".to_string(), json!(ctx.user_id.as_str()));\n\n        if let Some(agent_id) = \u0026ctx.agent_id {\n            entry\n                .metadata\n                .insert(\"agent_id\".to_string(), json!(agent_id));\n        }\n\n        let point = self.entry_to_point(\u0026entry)?;\n        use qdrant_client::qdrant::UpsertPointsBuilder;\n        let request = UpsertPointsBuilder::new(self.collection_name.clone(), vec![point]);\n        self.client.upsert_points(request).await?;\n        Ok(entry.id)\n    }\n\n    async fn search(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        query_vector: Vec\u003cf32\u003e,\n        limit: usize,\n        _filters: HashMap\u003cString, Value\u003e\n    ) -\u003e Result\u003cVec\u003cMemoryEntry\u003e, Self::Error\u003e {\n        self.ensure_collection().await?;\n        use qdrant_client::qdrant::{Condition, Filter, SearchPointsBuilder};\n\n        let filter = Filter::all(vec![Condition::matches(\n            \"tenant_id\",\n            ctx.tenant_id.as_str().to_string()\n        )]);\n\n        let request =\n            SearchPointsBuilder::new(self.collection_name.clone(), query_vector, limit as u64)\n                .with_payload(true)\n                .with_vectors(true)\n                .filter(filter);\n\n        let result = self.client.search_points(request).await?;\n        result\n            .result\n            .into_iter()\n            .map(|p| self.point_to_entry(p))\n            .collect()\n    }\n\n    async fn get(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        id: \u0026str\n    ) -\u003e Result\u003cOption\u003cMemoryEntry\u003e, Self::Error\u003e {\n        self.ensure_collection().await?;\n        use qdrant_client::qdrant::GetPointsBuilder;\n\n        tracing::debug!(tenant_id = %ctx.tenant_id, \"Qdrant get point\");\n\n        let request = GetPointsBuilder::new(\n            self.collection_name.clone(),\n            vec![PointId::from(id.to_string())]\n        )\n        .with_payload(true)\n        .with_vectors(true);\n\n        let result = self.client.get_points(request).await?;\n        if let Some(point) = result.result.into_iter().next() {\n            let entry = self.point_to_entry(ScoredPoint {\n                id: point.id,\n                version: 0,\n                score: 1.0,\n                payload: point.payload,\n                vectors: point.vectors,\n                order_value: None,\n                shard_key: None\n            })?;\n\n            if entry.metadata.get(\"tenant_id\").and_then(|t| t.as_str())\n                != Some(ctx.tenant_id.as_str())\n            {\n                return Ok(None);\n            }\n\n            Ok(Some(entry))\n        } else {\n            Ok(None)\n        }\n    }\n\n    async fn update(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        entry: MemoryEntry\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        self.add(ctx, entry).await?;\n        Ok(())\n    }\n\n    async fn delete(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        id: \u0026str\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        self.ensure_collection().await?;\n\n        if self.get(ctx.clone(), id).await?.is_none() {\n            return Ok(());\n        }\n\n        tracing::debug!(tenant_id = %ctx.tenant_id, \"Qdrant delete point\");\n\n        use qdrant_client::qdrant::DeletePointsBuilder;\n        let request = DeletePointsBuilder::new(self.collection_name.clone())\n            .points(vec![PointId::from(id.to_string())]);\n        self.client.delete_points(request).await?;\n        Ok(())\n    }\n\n    async fn list(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        _layer: MemoryLayer,\n        limit: usize,\n        cursor: Option\u003cString\u003e\n    ) -\u003e Result\u003c(Vec\u003cMemoryEntry\u003e, Option\u003cString\u003e), Self::Error\u003e {\n        self.ensure_collection().await?;\n\n        tracing::debug!(tenant_id = %ctx.tenant_id, \"Qdrant list points\");\n\n        use qdrant_client::qdrant::{Condition, Filter};\n        let filter = Filter::all(vec![Condition::matches(\n            \"tenant_id\",\n            ctx.tenant_id.as_str().to_string()\n        )]);\n\n        let scroll_request = qdrant_client::qdrant::ScrollPoints {\n            collection_name: self.collection_name.clone(),\n            limit: Some(limit as u32),\n            with_payload: Some(true.into()),\n            with_vectors: Some(true.into()),\n            offset: cursor.map(|c| PointId::from(c)),\n            filter: Some(filter),\n            ..Default::default()\n        };\n\n        let result = self.client.scroll(scroll_request).await?;\n        let entries: Result\u003cVec\u003cMemoryEntry\u003e, _\u003e = result\n            .result\n            .into_iter()\n            .map(|p| {\n                self.point_to_entry(ScoredPoint {\n                    id: p.id,\n                    version: 0,\n                    score: 1.0,\n                    payload: p.payload,\n                    vectors: p.vectors,\n                    order_value: None,\n                    shard_key: None\n                })\n            })\n            .collect();\n\n        let next_cursor = result.next_page_offset.map(|id| match id.point_id_options {\n            Some(PointIdOptions::Uuid(u)) =\u003e u,\n            Some(PointIdOptions::Num(n)) =\u003e n.to_string(),\n            None =\u003e String::new()\n        });\n        Ok((entries?, next_cursor))\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::MemoryLayer;\n\n    use qdrant_client::qdrant::vectors_output::VectorsOptions;\n    use qdrant_client::qdrant::{VectorOutput, VectorsOutput};\n\n    fn setup_provider() -\u003e QdrantProvider {\n        let client = Qdrant::from_url(\"http://localhost:6334\").build().unwrap();\n        QdrantProvider::new(client, \"test_collection\".to_string(), 3)\n    }\n\n    #[test]\n    fn test_point_to_entry_conversion() {\n        let provider = setup_provider();\n        let mut payload = HashMap::new();\n        payload.insert(\"id\".to_string(), \"test-id\".to_string().into());\n        payload.insert(\"content\".to_string(), \"test content\".to_string().into());\n        payload.insert(\n            \"layer\".to_string(),\n            serde_json::to_string(\u0026MemoryLayer::Agent).unwrap().into()\n        );\n        payload.insert(\n            \"metadata\".to_string(),\n            serde_json::to_string(\u0026HashMap::\u003cString, Value\u003e::new())\n                .unwrap()\n                .into()\n        );\n        payload.insert(\"created_at\".to_string(), 1000.into());\n        payload.insert(\"updated_at\".to_string(), 2000.into());\n\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload,\n            vectors: Some(VectorsOutput {\n                vectors_options: Some(VectorsOptions::Vector(VectorOutput {\n                    vector: Some(qdrant_client::qdrant::vector_output::Vector::Dense(\n                        qdrant_client::qdrant::DenseVector {\n                            data: vec![0.1, 0.2, 0.3]\n                        }\n                    )),\n                    ..Default::default()\n                }))\n            }),\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None\n        };\n\n        let entry = provider.point_to_entry(point).unwrap();\n\n        assert_eq!(entry.id, \"test-id\");\n        assert_eq!(entry.content, \"test content\");\n        assert_eq!(entry.layer, MemoryLayer::Agent);\n        assert_eq!(entry.created_at, 1000);\n        assert_eq!(entry.updated_at, 2000);\n        assert_eq!(entry.embedding, Some(vec![0.1, 0.2, 0.3]));\n    }\n\n    #[test]\n    fn test_point_to_entry_with_metadata() {\n        let provider = setup_provider();\n        let mut payload = HashMap::new();\n        payload.insert(\"id\".to_string(), \"test-id\".to_string().into());\n        payload.insert(\"content\".to_string(), \"test content\".to_string().into());\n        payload.insert(\n            \"layer\".to_string(),\n            serde_json::to_string(\u0026MemoryLayer::Agent).unwrap().into()\n        );\n        payload.insert(\n            \"metadata\".to_string(),\n            serde_json::to_string(\u0026HashMap::from([(\"key\".to_string(), json!(\"value\"))]))\n                .unwrap()\n                .into()\n        );\n        payload.insert(\"created_at\".to_string(), 1000.into());\n        payload.insert(\"updated_at\".to_string(), 2000.into());\n\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload,\n            vectors: Some(VectorsOutput {\n                vectors_options: Some(VectorsOptions::Vector(VectorOutput {\n                    vector: Some(qdrant_client::qdrant::vector_output::Vector::Dense(\n                        qdrant_client::qdrant::DenseVector {\n                            data: vec![0.1, 0.2, 0.3]\n                        }\n                    )),\n                    ..Default::default()\n                }))\n            }),\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None\n        };\n\n        let entry = provider.point_to_entry(point).unwrap();\n\n        assert_eq!(entry.id, \"test-id\");\n        assert_eq!(entry.content, \"test content\");\n        assert_eq!(entry.embedding.unwrap(), vec![0.1, 0.2, 0.3]);\n        assert_eq!(entry.layer, MemoryLayer::Agent);\n        assert_eq!(entry.metadata.get(\"key\").unwrap(), \u0026json!(\"value\"));\n        // Use approx comparison for floating point\n        let score_value = entry.metadata.get(\"score\").unwrap().as_f64().unwrap();\n        assert!((score_value - 0.95).abs() \u003c 0.0001);\n        assert_eq!(entry.created_at, 1000);\n        assert_eq!(entry.updated_at, 2000);\n    }\n\n    #[test]\n    fn test_entry_to_point_missing_embedding() {\n        let provider = setup_provider();\n        let entry = MemoryEntry {\n            id: \"test-id\".to_string(),\n            content: \"test content\".to_string(),\n            embedding: None,\n            layer: MemoryLayer::Agent,\n            metadata: HashMap::new(),\n            created_at: 1000,\n            updated_at: 2000\n        };\n\n        let result = provider.entry_to_point(\u0026entry);\n        assert!(result.is_err());\n        assert_eq!(result.unwrap_err().to_string(), \"Entry missing embedding\");\n    }\n\n    #[test]\n    fn test_point_to_entry_missing_payload_fields() {\n        let provider = setup_provider();\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload: HashMap::new(),\n            vectors: Some(VectorsOutput {\n                vectors_options: Some(VectorsOptions::Vector(VectorOutput {\n                    vector: Some(qdrant_client::qdrant::vector_output::Vector::Dense(\n                        qdrant_client::qdrant::DenseVector {\n                            data: vec![0.1, 0.2, 0.3]\n                        }\n                    )),\n                    ..Default::default()\n                }))\n            }),\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None\n        };\n\n        let result = provider.point_to_entry(point);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_point_to_entry_invalid_layer() {\n        let provider = setup_provider();\n        let mut payload = HashMap::new();\n        payload.insert(\"id\".to_string(), \"test-id\".to_string().into());\n        payload.insert(\"content\".to_string(), \"test content\".to_string().into());\n        payload.insert(\"layer\".to_string(), \"\\\"InvalidLayer\\\"\".to_string().into());\n        payload.insert(\"metadata\".to_string(), \"{}\".to_string().into());\n        payload.insert(\"created_at\".to_string(), 1000.into());\n        payload.insert(\"updated_at\".to_string(), 2000.into());\n\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload,\n            vectors: Some(VectorsOutput {\n                vectors_options: Some(VectorsOptions::Vector(VectorOutput {\n                    vector: Some(qdrant_client::qdrant::vector_output::Vector::Dense(\n                        qdrant_client::qdrant::DenseVector {\n                            data: vec![0.1, 0.2, 0.3]\n                        }\n                    )),\n                    ..Default::default()\n                }))\n            }),\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None\n        };\n\n        let result = provider.point_to_entry(point);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_point_to_entry_missing_metadata() {\n        let provider = setup_provider();\n        let mut payload = HashMap::new();\n        payload.insert(\"id\".to_string(), \"test-id\".to_string().into());\n        payload.insert(\"content\".to_string(), \"test content\".to_string().into());\n        payload.insert(\n            \"layer\".to_string(),\n            serde_json::to_string(\u0026MemoryLayer::Agent).unwrap().into()\n        );\n        payload.insert(\"created_at\".to_string(), 1000.into());\n        payload.insert(\"updated_at\".to_string(), 2000.into());\n\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload,\n            vectors: Some(VectorsOutput {\n                vectors_options: Some(VectorsOptions::Vector(VectorOutput {\n                    vector: Some(qdrant_client::qdrant::vector_output::Vector::Dense(\n                        qdrant_client::qdrant::DenseVector {\n                            data: vec![0.1, 0.2, 0.3]\n                        }\n                    )),\n                    ..Default::default()\n                }))\n            }),\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None\n        };\n\n        let result = provider.point_to_entry(point);\n        assert!(result.is_err());\n        assert_eq!(\n            result.unwrap_err().to_string(),\n            \"Missing metadata in payload\"\n        );\n    }\n\n    #[test]\n    fn test_point_to_entry_unsupported_vector() {\n        let provider = setup_provider();\n        let mut payload = HashMap::new();\n        payload.insert(\"id\".to_string(), \"test-id\".to_string().into());\n        payload.insert(\"content\".to_string(), \"test content\".to_string().into());\n        payload.insert(\n            \"layer\".to_string(),\n            serde_json::to_string(\u0026MemoryLayer::Agent).unwrap().into()\n        );\n        payload.insert(\"metadata\".to_string(), \"{}\".to_string().into());\n        payload.insert(\"created_at\".to_string(), 1000.into());\n        payload.insert(\"updated_at\".to_string(), 2000.into());\n\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload,\n            vectors: Some(VectorsOutput {\n                vectors_options: None\n            }),\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None\n        };\n\n        let result = provider.point_to_entry(point);\n        assert!(result.is_err());\n        assert_eq!(\n            result.unwrap_err().to_string(),\n            \"Unsupported or missing vector format\"\n        );\n    }\n\n    #[test]\n    fn test_point_to_entry_invalid_metadata_json() {\n        let provider = setup_provider();\n        let mut payload = HashMap::new();\n        payload.insert(\"id\".to_string(), \"test-id\".to_string().into());\n        payload.insert(\"content\".to_string(), \"test content\".to_string().into());\n        payload.insert(\n            \"layer\".to_string(),\n            serde_json::to_string(\u0026MemoryLayer::Agent).unwrap().into()\n        );\n        payload.insert(\"metadata\".to_string(), \"invalid-json\".to_string().into());\n        payload.insert(\"created_at\".to_string(), 1000.into());\n        payload.insert(\"updated_at\".to_string(), 2000.into());\n\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload,\n            vectors: Some(VectorsOutput {\n                vectors_options: Some(VectorsOptions::Vector(VectorOutput {\n                    vector: Some(qdrant_client::qdrant::vector_output::Vector::Dense(\n                        qdrant_client::qdrant::DenseVector {\n                            data: vec![0.1, 0.2, 0.3]\n                        }\n                    )),\n                    ..Default::default()\n                }))\n            }),\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None\n        };\n\n        let result = provider.point_to_entry(point);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_point_to_entry_missing_vector() {\n        let provider = setup_provider();\n        let mut payload = HashMap::new();\n        payload.insert(\"id\".to_string(), \"test-id\".to_string().into());\n        payload.insert(\"content\".to_string(), \"test content\".to_string().into());\n        payload.insert(\n            \"layer\".to_string(),\n            serde_json::to_string(\u0026MemoryLayer::Agent).unwrap().into()\n        );\n        payload.insert(\"metadata\".to_string(), \"{}\".to_string().into());\n        payload.insert(\"created_at\".to_string(), 1000.into());\n        payload.insert(\"updated_at\".to_string(), 2000.into());\n\n        let point = ScoredPoint {\n            id: Some(PointId::from(\"test-id\".to_string())),\n            payload,\n            vectors: None,\n            score: 0.95,\n            version: 1,\n            order_value: None,\n            shard_key: None\n        };\n\n        let result = provider.point_to_entry(point);\n        assert!(result.is_err());\n        assert_eq!(result.unwrap_err().to_string(), \"Point missing vector\");\n    }\n}\n","traces":[{"line":23,"address":[],"length":0,"stats":{"Line":9}},{"line":25,"address":[],"length":0,"stats":{"Line":27}},{"line":31,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":42,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":1}},{"line":59,"address":[],"length":0,"stats":{"Line":4}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":8}},{"line":88,"address":[],"length":0,"stats":{"Line":16}},{"line":90,"address":[],"length":0,"stats":{"Line":14}},{"line":92,"address":[],"length":0,"stats":{"Line":14}},{"line":93,"address":[],"length":0,"stats":{"Line":30}},{"line":94,"address":[],"length":0,"stats":{"Line":12}},{"line":95,"address":[],"length":0,"stats":{"Line":30}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":23}},{"line":103,"address":[],"length":0,"stats":{"Line":25}},{"line":105,"address":[],"length":0,"stats":{"Line":8}},{"line":106,"address":[],"length":0,"stats":{"Line":8}},{"line":108,"address":[],"length":0,"stats":{"Line":7}},{"line":109,"address":[],"length":0,"stats":{"Line":6}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":1}},{"line":116,"address":[],"length":0,"stats":{"Line":6}},{"line":118,"address":[],"length":0,"stats":{"Line":6}},{"line":119,"address":[],"length":0,"stats":{"Line":15}},{"line":120,"address":[],"length":0,"stats":{"Line":6}},{"line":121,"address":[],"length":0,"stats":{"Line":15}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":11}},{"line":129,"address":[],"length":0,"stats":{"Line":4}},{"line":131,"address":[],"length":0,"stats":{"Line":4}},{"line":132,"address":[],"length":0,"stats":{"Line":10}},{"line":133,"address":[],"length":0,"stats":{"Line":10}},{"line":137,"address":[],"length":0,"stats":{"Line":4}},{"line":139,"address":[],"length":0,"stats":{"Line":4}},{"line":140,"address":[],"length":0,"stats":{"Line":10}},{"line":141,"address":[],"length":0,"stats":{"Line":10}},{"line":145,"address":[],"length":0,"stats":{"Line":4}},{"line":147,"address":[],"length":0,"stats":{"Line":4}},{"line":148,"address":[],"length":0,"stats":{"Line":10}},{"line":149,"address":[],"length":0,"stats":{"Line":4}},{"line":153,"address":[],"length":0,"stats":{"Line":4}},{"line":155,"address":[],"length":0,"stats":{"Line":4}},{"line":156,"address":[],"length":0,"stats":{"Line":10}},{"line":157,"address":[],"length":0,"stats":{"Line":4}},{"line":161,"address":[],"length":0,"stats":{"Line":2}},{"line":162,"address":[],"length":0,"stats":{"Line":4}},{"line":163,"address":[],"length":0,"stats":{"Line":4}},{"line":164,"address":[],"length":0,"stats":{"Line":4}},{"line":165,"address":[],"length":0,"stats":{"Line":4}},{"line":166,"address":[],"length":0,"stats":{"Line":4}},{"line":167,"address":[],"length":0,"stats":{"Line":2}},{"line":168,"address":[],"length":0,"stats":{"Line":2}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":335,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":337,"address":[],"length":0,"stats":{"Line":0}},{"line":338,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":342,"address":[],"length":0,"stats":{"Line":0}},{"line":343,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":0}},{"line":350,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}}],"covered":48,"coverable":95},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","redis.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","repository.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","state.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","telemetry.rs"],"content":"use metrics::{counter, gauge, histogram};\nuse opentelemetry::global;\nuse opentelemetry::global::{BoxedSpan, BoxedTracer};\nuse opentelemetry::metrics::Meter;\nuse opentelemetry::trace::Tracer;\n\n#[derive(Debug)]\npub struct MemoryTelemetry {\n    tracer: BoxedTracer\n}\n\nimpl MemoryTelemetry {\n    pub fn new() -\u003e Self {\n        let tracer = global::tracer(\"memory_system\");\n\n        Self { tracer }\n    }\n\n    pub fn with_tracer(tracer: BoxedTracer) -\u003e Self {\n        Self { tracer }\n    }\n\n    pub fn with_meter(_meter: Meter) -\u003e Self {\n        let tracer = global::tracer(\"memory_system\");\n\n        Self { tracer }\n    }\n\n    pub fn record_operation_start(\u0026self, operation: \u0026str, layer: \u0026str) -\u003e BoxedSpan {\n        self.tracer\n            .span_builder(format!(\"memory.{}\", operation))\n            .with_attributes(vec![\n                opentelemetry::KeyValue::new(\"layer\", layer.to_string()),\n                opentelemetry::KeyValue::new(\"operation\", operation.to_string()),\n            ])\n            .start(\u0026self.tracer)\n    }\n\n    pub fn record_operation_success(\u0026self, operation: \u0026str, layer: \u0026str, duration_ms: f64) {\n        counter!(\"memory_operations_total\", 1,\n            \"operation\" =\u003e operation.to_string(),\n            \"layer\" =\u003e layer.to_string(),\n            \"status\" =\u003e \"success\"\n        );\n\n        histogram!(\"memory_operation_duration_seconds\", duration_ms / 1000.0,\n            \"operation\" =\u003e operation.to_string(),\n            \"layer\" =\u003e layer.to_string()\n        );\n    }\n\n    pub fn record_operation_failure(\u0026self, operation: \u0026str, layer: \u0026str, error: \u0026str) {\n        counter!(\"memory_operations_total\", 1,\n            \"operation\" =\u003e operation.to_string(),\n            \"layer\" =\u003e layer.to_string(),\n            \"status\" =\u003e \"failure\",\n            \"error\" =\u003e error.to_string()\n        );\n\n        counter!(\"memory_operation_errors_total\", 1,\n            \"operation\" =\u003e operation.to_string(),\n            \"layer\" =\u003e layer.to_string(),\n            \"error_type\" =\u003e error.to_string()\n        );\n    }\n\n    pub fn record_embedding_generation(\u0026self, dimension: usize, duration_ms: f64) {\n        counter!(\"memory_embeddings_generated_total\", 1,\n            \"dimension\" =\u003e dimension.to_string()\n        );\n\n        histogram!(\"memory_embedding_generation_duration_seconds\", duration_ms / 1000.0,\n            \"dimension\" =\u003e dimension.to_string()\n        );\n\n        gauge!(\"memory_embedding_dimension\", dimension as f64);\n    }\n\n    pub fn record_search_operation(\u0026self, results_count: usize, query_dimension: usize) {\n        counter!(\"memory_searches_total\", 1);\n        histogram!(\"memory_search_results_count\", results_count as f64);\n        gauge!(\"memory_search_query_dimension\", query_dimension as f64);\n    }\n\n    pub fn record_storage_metrics(\u0026self, entries_count: usize, total_size_bytes: usize) {\n        gauge!(\"memory_entries_total\", entries_count as f64);\n        gauge!(\"memory_storage_size_bytes\", total_size_bytes as f64);\n    }\n\n    pub fn record_cache_metrics(\u0026self, hit_count: usize, miss_count: usize, cache_size: usize) {\n        counter!(\"memory_cache_hits_total\", hit_count as u64);\n        counter!(\"memory_cache_misses_total\", miss_count as u64);\n        gauge!(\"memory_cache_size\", cache_size as f64);\n\n        let total = hit_count + miss_count;\n        if total \u003e 0 {\n            let hit_rate = (hit_count as f64) / (total as f64);\n            gauge!(\"memory_cache_hit_rate\", hit_rate);\n        }\n    }\n\n    pub fn record_promotion_attempt(\u0026self, from_layer: \u0026str, target_layer: \u0026str) {\n        counter!(\"memory_promotion_attempts_total\", 1,\n            \"from_layer\" =\u003e from_layer.to_string(),\n            \"target_layer\" =\u003e target_layer.to_string()\n        );\n    }\n\n    pub fn record_promotion_success(\u0026self, from_layer: \u0026str, target_layer: \u0026str) {\n        counter!(\"memory_promotion_success_total\", 1,\n            \"from_layer\" =\u003e from_layer.to_string(),\n            \"target_layer\" =\u003e target_layer.to_string()\n        );\n    }\n\n    pub fn record_promotion_blocked(\u0026self, from_layer: \u0026str, reason: \u0026str) {\n        counter!(\"memory_promotion_blocked_total\", 1,\n            \"from_layer\" =\u003e from_layer.to_string(),\n            \"reason\" =\u003e reason.to_string()\n        );\n    }\n\n    pub fn record_governance_redaction(\u0026self, layer: \u0026str) {\n        counter!(\"memory_governance_redactions_total\", 1,\n            \"layer\" =\u003e layer.to_string()\n        );\n    }\n}\n\npub fn init_telemetry() -\u003e Result\u003cMemoryTelemetry, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    let telemetry = MemoryTelemetry::new();\n\n    metrics_exporter_prometheus::PrometheusBuilder::new()\n        .with_http_listener(([0, 0, 0, 0], 9090))\n        .install()?;\n\n    Ok(telemetry)\n}\n\npub fn init_telemetry_with_endpoint(\n    endpoint: std::net::SocketAddr\n) -\u003e Result\u003cMemoryTelemetry, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    let telemetry = MemoryTelemetry::new();\n\n    metrics_exporter_prometheus::PrometheusBuilder::new()\n        .with_http_listener(endpoint)\n        .install()?;\n\n    Ok(telemetry)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use metrics_util::debugging::DebuggingRecorder;\n\n    #[test]\n    fn test_telemetry_creation() {\n        use opentelemetry::trace::Span as _;\n        use opentelemetry::trace::TracerProvider as _;\n        use opentelemetry_sdk::trace::TracerProvider;\n\n        let provider = TracerProvider::default();\n        let tracer = provider.tracer(\"test\");\n        let telemetry =\n            MemoryTelemetry::with_tracer(opentelemetry::global::BoxedTracer::new(Box::new(tracer)));\n\n        let mut span = telemetry.record_operation_start(\"add\", \"agent\");\n        assert!(span.span_context().is_valid());\n        span.end();\n    }\n\n    #[test]\n    fn test_metrics_recording() {\n        let recorder = DebuggingRecorder::new();\n        let static_recorder: \u0026'static DebuggingRecorder = Box::leak(Box::new(recorder));\n        metrics::set_recorder(static_recorder).ok();\n\n        let telemetry = MemoryTelemetry::new();\n\n        telemetry.record_operation_success(\"add\", \"agent\", 150.0);\n        telemetry.record_operation_failure(\"search\", \"session\", \"not_found\");\n        telemetry.record_embedding_generation(1536, 250.0);\n        telemetry.record_search_operation(5, 1536);\n        telemetry.record_storage_metrics(100, 1024000);\n        telemetry.record_cache_metrics(75, 25, 100);\n        telemetry.record_promotion_attempt(\"agent\", \"user\");\n        telemetry.record_promotion_success(\"agent\", \"user\");\n        telemetry.record_promotion_blocked(\"agent\", \"governance\");\n        telemetry.record_governance_redaction(\"user\");\n    }\n\n    #[test]\n    fn test_with_meter() {\n        use opentelemetry::metrics::MeterProvider;\n        use opentelemetry_sdk::metrics::MeterProvider as SdkMeterProvider;\n\n        let provider = SdkMeterProvider::default();\n        let meter = provider.meter(\"test\");\n\n        // Test that with_meter creates telemetry instance\n        let telemetry = MemoryTelemetry::with_meter(meter);\n\n        // Verify telemetry instance was created\n        // The meter parameter is ignored in the implementation, but we test the method\n        // exists\n        assert!(std::mem::size_of_val(\u0026telemetry) \u003e 0);\n    }\n\n    #[test]\n    fn test_init_telemetry() {\n        // Test that init_telemetry returns a Result\n        // The function might succeed or fail depending on port availability\n        let result = init_telemetry();\n\n        // Verify it returns a Result (either Ok or Err)\n        // We can't guarantee it will fail because port 9090 might be available\n        match result {\n            Ok(telemetry) =\u003e {\n                // If it succeeds, verify we got a telemetry instance\n                assert!(std::mem::size_of_val(\u0026telemetry) \u003e 0);\n            }\n            Err(e) =\u003e {\n                // If it fails, verify the error is related to binding\n                let error_str = e.to_string();\n                assert!(\n                    error_str.contains(\"address already in use\")\n                        || error_str.contains(\"bind\")\n                        || error_str.contains(\"port\")\n                        || error_str.contains(\"Permission denied\")\n                );\n            }\n        }\n    }\n\n    #[test]\n    fn test_init_telemetry_with_endpoint() {\n        use std::net::{IpAddr, Ipv4Addr, SocketAddr};\n\n        // Create a test endpoint (port 0 means OS will assign a free port)\n        let endpoint = SocketAddr::new(IpAddr::V4(Ipv4Addr::new(127, 0, 0, 1)), 0);\n\n        // Test that init_telemetry_with_endpoint returns a Result\n        let result = init_telemetry_with_endpoint(endpoint);\n\n        // The function should work with port 0 (OS-assigned port)\n        // But metrics initialization might still fail for other reasons\n        // We just verify it returns a Result\n        assert!(result.is_err() || result.is_ok());\n\n        // If it fails, verify it's not a bind error\n        if let Err(e) = result {\n            let error_str = e.to_string();\n            // Should not be a bind error with port 0\n            assert!(!error_str.contains(\"address already in use\"));\n        }\n    }\n}\n","traces":[{"line":13,"address":[],"length":0,"stats":{"Line":96}},{"line":14,"address":[],"length":0,"stats":{"Line":192}},{"line":19,"address":[],"length":0,"stats":{"Line":1}},{"line":23,"address":[],"length":0,"stats":{"Line":1}},{"line":24,"address":[],"length":0,"stats":{"Line":2}},{"line":29,"address":[],"length":0,"stats":{"Line":1050}},{"line":30,"address":[],"length":0,"stats":{"Line":1050}},{"line":31,"address":[],"length":0,"stats":{"Line":3150}},{"line":32,"address":[],"length":0,"stats":{"Line":2100}},{"line":33,"address":[],"length":0,"stats":{"Line":3150}},{"line":34,"address":[],"length":0,"stats":{"Line":3150}},{"line":36,"address":[],"length":0,"stats":{"Line":2100}},{"line":39,"address":[],"length":0,"stats":{"Line":1047}},{"line":40,"address":[],"length":0,"stats":{"Line":1047}},{"line":41,"address":[],"length":0,"stats":{"Line":2}},{"line":42,"address":[],"length":0,"stats":{"Line":2}},{"line":46,"address":[],"length":0,"stats":{"Line":1048}},{"line":47,"address":[],"length":0,"stats":{"Line":2}},{"line":48,"address":[],"length":0,"stats":{"Line":2}},{"line":52,"address":[],"length":0,"stats":{"Line":3}},{"line":53,"address":[],"length":0,"stats":{"Line":3}},{"line":54,"address":[],"length":0,"stats":{"Line":2}},{"line":55,"address":[],"length":0,"stats":{"Line":2}},{"line":57,"address":[],"length":0,"stats":{"Line":2}},{"line":60,"address":[],"length":0,"stats":{"Line":3}},{"line":61,"address":[],"length":0,"stats":{"Line":2}},{"line":62,"address":[],"length":0,"stats":{"Line":2}},{"line":63,"address":[],"length":0,"stats":{"Line":2}},{"line":67,"address":[],"length":0,"stats":{"Line":1}},{"line":68,"address":[],"length":0,"stats":{"Line":1}},{"line":69,"address":[],"length":0,"stats":{"Line":2}},{"line":72,"address":[],"length":0,"stats":{"Line":2}},{"line":73,"address":[],"length":0,"stats":{"Line":2}},{"line":76,"address":[],"length":0,"stats":{"Line":2}},{"line":79,"address":[],"length":0,"stats":{"Line":4}},{"line":80,"address":[],"length":0,"stats":{"Line":4}},{"line":81,"address":[],"length":0,"stats":{"Line":5}},{"line":82,"address":[],"length":0,"stats":{"Line":5}},{"line":85,"address":[],"length":0,"stats":{"Line":1}},{"line":86,"address":[],"length":0,"stats":{"Line":2}},{"line":87,"address":[],"length":0,"stats":{"Line":2}},{"line":90,"address":[],"length":0,"stats":{"Line":1}},{"line":91,"address":[],"length":0,"stats":{"Line":2}},{"line":92,"address":[],"length":0,"stats":{"Line":2}},{"line":93,"address":[],"length":0,"stats":{"Line":2}},{"line":95,"address":[],"length":0,"stats":{"Line":2}},{"line":96,"address":[],"length":0,"stats":{"Line":1}},{"line":97,"address":[],"length":0,"stats":{"Line":2}},{"line":98,"address":[],"length":0,"stats":{"Line":2}},{"line":102,"address":[],"length":0,"stats":{"Line":6}},{"line":103,"address":[],"length":0,"stats":{"Line":6}},{"line":104,"address":[],"length":0,"stats":{"Line":2}},{"line":105,"address":[],"length":0,"stats":{"Line":2}},{"line":109,"address":[],"length":0,"stats":{"Line":6}},{"line":110,"address":[],"length":0,"stats":{"Line":6}},{"line":111,"address":[],"length":0,"stats":{"Line":2}},{"line":112,"address":[],"length":0,"stats":{"Line":2}},{"line":116,"address":[],"length":0,"stats":{"Line":2}},{"line":117,"address":[],"length":0,"stats":{"Line":2}},{"line":118,"address":[],"length":0,"stats":{"Line":2}},{"line":119,"address":[],"length":0,"stats":{"Line":2}},{"line":123,"address":[],"length":0,"stats":{"Line":3}},{"line":124,"address":[],"length":0,"stats":{"Line":3}},{"line":125,"address":[],"length":0,"stats":{"Line":2}},{"line":130,"address":[],"length":0,"stats":{"Line":1}},{"line":131,"address":[],"length":0,"stats":{"Line":2}},{"line":133,"address":[],"length":0,"stats":{"Line":1}},{"line":134,"address":[],"length":0,"stats":{"Line":2}},{"line":137,"address":[],"length":0,"stats":{"Line":1}},{"line":140,"address":[],"length":0,"stats":{"Line":1}},{"line":143,"address":[],"length":0,"stats":{"Line":2}},{"line":145,"address":[],"length":0,"stats":{"Line":1}},{"line":146,"address":[],"length":0,"stats":{"Line":2}},{"line":149,"address":[],"length":0,"stats":{"Line":0}}],"covered":73,"coverable":74},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","tools.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","validator.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","src","working.rs"],"content":"\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","tests","qdrant_testcontainers.rs"],"content":"//! Integration tests for Qdrant provider using testcontainers\n\nuse memory::providers::qdrant::QdrantProvider;\nuse mk_core::traits::MemoryProviderAdapter;\nuse mk_core::types::{MemoryEntry, MemoryLayer, TenantContext};\nuse qdrant_client::{Qdrant, config::QdrantConfig};\nuse std::collections::HashMap;\nuse testcontainers::{\n    GenericImage,\n    core::{ContainerPort, WaitFor},\n    runners::AsyncRunner\n};\n\nfn test_ctx() -\u003e TenantContext {\n    TenantContext::default()\n}\n\n#[tokio::test]\nasync fn test_qdrant_full_lifecycle() {\n    let container = match GenericImage::new(\"qdrant/qdrant\", \"latest\")\n        .with_exposed_port(ContainerPort::Tcp(6334))\n        .with_wait_for(WaitFor::message_on_stdout(\n            \"Qdrant is ready to accept connections\"\n        ))\n        .start()\n        .await\n    {\n        Ok(c) =\u003e c,\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Qdrant test: Docker not available\");\n            return;\n        }\n    };\n\n    let host = container.get_host().await.unwrap();\n    let port = container.get_host_port_ipv4(6334).await.unwrap();\n    let connection_url = format!(\"http://{}:{}\", host, port);\n\n    let client = Qdrant::new(QdrantConfig::from_url(\u0026connection_url))\n        .expect(\"Failed to create Qdrant client\");\n\n    let provider = QdrantProvider::new(client, \"lifecycle_test\".to_string(), 128);\n\n    provider\n        .ensure_collection()\n        .await\n        .expect(\"Failed to create collection\");\n\n    let ctx = test_ctx();\n\n    for i in 0..5 {\n        let entry = MemoryEntry {\n            id: format!(\"id_{}\", i),\n            content: format!(\"Content {}\", i),\n            embedding: Some(vec![i as f32 * 0.1; 128]),\n            layer: MemoryLayer::User,\n            metadata: HashMap::new(),\n            created_at: 1000 + i as i64,\n            updated_at: 1000 + i as i64\n        };\n        provider\n            .add(ctx.clone(), entry)\n            .await\n            .expect(\"Failed to add entry\");\n    }\n\n    let query = vec![0.25; 128];\n    let search_results = provider\n        .search(ctx.clone(), query, 10, HashMap::new())\n        .await\n        .expect(\"Search failed\");\n    assert!(search_results.len() \u003e= 2);\n\n    let first_id = \u0026search_results[0].id;\n    assert!(first_id == \"id_2\" || first_id == \"id_3\");\n\n    let entry = provider\n        .get(ctx.clone(), \"id_0\")\n        .await\n        .expect(\"Get failed\")\n        .expect(\"Entry not found\");\n    assert_eq!(entry.content, \"Content 0\");\n\n    let mut entry_to_update = entry;\n    entry_to_update.content = \"Updated content\".to_string();\n    provider\n        .update(ctx.clone(), entry_to_update)\n        .await\n        .expect(\"Update failed\");\n\n    let updated = provider\n        .get(ctx.clone(), \"id_0\")\n        .await\n        .expect(\"Get failed\")\n        .expect(\"Entry not found\");\n    assert_eq!(updated.content, \"Updated content\");\n\n    let (list, next_cursor) = provider\n        .list(ctx.clone(), MemoryLayer::User, 2, None)\n        .await\n        .expect(\"List failed\");\n    assert_eq!(list.len(), 2);\n    assert!(next_cursor.is_some());\n\n    provider\n        .delete(ctx.clone(), \"id_0\")\n        .await\n        .expect(\"Delete failed\");\n    let deleted = provider.get(ctx, \"id_0\").await.expect(\"Get failed\");\n    assert!(deleted.is_none());\n}\n\n#[tokio::test]\nasync fn test_qdrant_error_conditions() {\n    let container = match GenericImage::new(\"qdrant/qdrant\", \"latest\")\n        .with_exposed_port(ContainerPort::Tcp(6334))\n        .with_wait_for(WaitFor::message_on_stdout(\n            \"Qdrant is ready to accept connections\"\n        ))\n        .start()\n        .await\n    {\n        Ok(c) =\u003e c,\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Qdrant test: Docker not available\");\n            return;\n        }\n    };\n\n    let host = container.get_host().await.unwrap();\n    let port = container.get_host_port_ipv4(6334).await.unwrap();\n    let connection_url = format!(\"http://{}:{}\", host, port);\n\n    let client = Qdrant::new(QdrantConfig::from_url(\u0026connection_url))\n        .expect(\"Failed to create Qdrant client\");\n\n    let provider = QdrantProvider::new(client, \"error_test\".to_string(), 128);\n\n    let entry_no_emb = MemoryEntry {\n        id: \"no_emb\".to_string(),\n        content: \"No embedding\".to_string(),\n        embedding: None,\n        layer: MemoryLayer::User,\n        metadata: HashMap::new(),\n        created_at: 0,\n        updated_at: 0\n    };\n    let ctx = test_ctx();\n    let result = provider.add(ctx, entry_no_emb).await;\n    assert!(result.is_err());\n    assert!(\n        result\n            .unwrap_err()\n            .to_string()\n            .contains(\"missing embedding\")\n    );\n\n    provider.ensure_collection().await.unwrap();\n    let ctx = test_ctx();\n    let wrong_dim_query = vec![1.0; 64];\n    let result = provider\n        .search(ctx, wrong_dim_query, 10, HashMap::new())\n        .await;\n    assert!(result.is_err());\n}\n\n#[tokio::test]\nasync fn test_qdrant_complex_metadata() {\n    let container = match GenericImage::new(\"qdrant/qdrant\", \"latest\")\n        .with_exposed_port(ContainerPort::Tcp(6334))\n        .with_wait_for(WaitFor::message_on_stdout(\n            \"Qdrant is ready to accept connections\"\n        ))\n        .start()\n        .await\n    {\n        Ok(c) =\u003e c,\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Qdrant test: Docker not available\");\n            return;\n        }\n    };\n\n    let host = container.get_host().await.unwrap();\n    let port = container.get_host_port_ipv4(6334).await.unwrap();\n    let connection_url = format!(\"http://{}:{}\", host, port);\n\n    let client = Qdrant::new(QdrantConfig::from_url(\u0026connection_url))\n        .expect(\"Failed to create Qdrant client\");\n\n    let provider = QdrantProvider::new(client, \"metadata_test\".to_string(), 128);\n\n    let mut metadata = HashMap::new();\n    metadata.insert(\"tags\".to_string(), serde_json::json!([\"rust\", \"ai\"]));\n    metadata.insert(\"nested\".to_string(), serde_json::json!({\"key\": \"value\"}));\n    metadata.insert(\"priority\".to_string(), serde_json::json!(5));\n\n    let entry = MemoryEntry {\n        id: \"meta_1\".to_string(),\n        content: \"Metadata test\".to_string(),\n        embedding: Some(vec![0.1; 128]),\n        layer: MemoryLayer::Session,\n        metadata,\n        created_at: 123456789,\n        updated_at: 123456789\n    };\n\n    let ctx = test_ctx();\n    provider\n        .add(ctx.clone(), entry.clone())\n        .await\n        .expect(\"Failed to add entry with metadata\");\n\n    let retrieved = provider\n        .get(ctx, \"meta_1\")\n        .await\n        .expect(\"Get failed\")\n        .unwrap();\n    assert_eq!(\n        retrieved\n            .metadata\n            .get(\"priority\")\n            .unwrap()\n            .as_i64()\n            .unwrap(),\n        5\n    );\n    assert_eq!(\n        retrieved\n            .metadata\n            .get(\"tags\")\n            .unwrap()\n            .as_array()\n            .unwrap()\n            .len(),\n        2\n    );\n    assert_eq!(\n        retrieved\n            .metadata\n            .get(\"nested\")\n            .unwrap()\n            .as_object()\n            .unwrap()\n            .get(\"key\")\n            .unwrap()\n            .as_str()\n            .unwrap(),\n        \"value\"\n    );\n\n    if let MemoryLayer::Session = retrieved.layer {\n        assert!(true);\n    } else {\n        panic!(\"Layer was not preserved correctly\");\n    }\n}\n\n#[tokio::test]\nasync fn test_qdrant_collection_management() {\n    let container = match GenericImage::new(\"qdrant/qdrant\", \"latest\")\n        .with_exposed_port(ContainerPort::Tcp(6334))\n        .with_wait_for(WaitFor::message_on_stdout(\n            \"Qdrant is ready to accept connections\"\n        ))\n        .start()\n        .await\n    {\n        Ok(c) =\u003e c,\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Qdrant test: Docker not available\");\n            return;\n        }\n    };\n\n    let host = container.get_host().await.unwrap();\n    let port = container.get_host_port_ipv4(6334).await.unwrap();\n    let connection_url = format!(\"http://{}:{}\", host, port);\n\n    let client = Qdrant::new(QdrantConfig::from_url(\u0026connection_url))\n        .expect(\"Failed to create Qdrant client\");\n\n    let provider = QdrantProvider::new(client, \"mgmt_test\".to_string(), 384);\n\n    provider\n        .ensure_collection()\n        .await\n        .expect(\"First creation failed\");\n    provider\n        .ensure_collection()\n        .await\n        .expect(\"Idempotent creation failed\");\n}\n","traces":[{"line":14,"address":[],"length":0,"stats":{"Line":0}},{"line":15,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":2},{"path":["/","Users","christian.klat","dev","git","aeterna","memory","tests","system_integration.rs"],"content":"//! System Integration Test for Aeterna Memory System\n//!\n//! Coordinates PostgreSQL, Redis, and Qdrant using testcontainers\n//! to verify the full memory lifecycle across different storage layers.\n\nuse memory::manager::MemoryManager;\nuse memory::providers::qdrant::QdrantProvider;\nuse mk_core::types::{MemoryEntry, MemoryLayer, TenantContext};\nuse qdrant_client::{Qdrant, config::QdrantConfig};\nuse std::collections::HashMap;\nuse storage::postgres::PostgresBackend;\nuse storage::redis::RedisStorage;\nuse testcontainers::{\n    ContainerAsync, GenericImage,\n    core::{ContainerPort, WaitFor},\n    runners::AsyncRunner,\n};\nuse testcontainers_modules::postgres::Postgres;\nuse testcontainers_modules::redis::Redis;\n\nfn test_ctx() -\u003e TenantContext {\n    TenantContext::default()\n}\n\nasync fn setup_postgres() -\u003e Result\u003c(ContainerAsync\u003cPostgres\u003e, String), Box\u003cdyn std::error::Error\u003e\u003e\n{\n    let container = Postgres::default()\n        .with_db_name(\"aeterna_test\")\n        .with_user(\"aeterna\")\n        .with_password(\"aeterna\")\n        .start()\n        .await?;\n    let port = container.get_host_port_ipv4(5432).await?;\n    let url = format!(\"postgres://aeterna:aeterna@localhost:{}/aeterna_test\", port);\n    Ok((container, url))\n}\n\nasync fn setup_redis() -\u003e Result\u003c(ContainerAsync\u003cRedis\u003e, String), Box\u003cdyn std::error::Error\u003e\u003e {\n    let container = Redis::default().start().await?;\n    let port = container.get_host_port_ipv4(6379).await?;\n    let url = format!(\"redis://localhost:{}\", port);\n    Ok((container, url))\n}\n\nasync fn setup_qdrant() -\u003e Result\u003c(ContainerAsync\u003cGenericImage\u003e, String), Box\u003cdyn std::error::Error\u003e\u003e\n{\n    let container = GenericImage::new(\"qdrant/qdrant\", \"latest\")\n        .with_exposed_port(ContainerPort::Tcp(6334))\n        .with_wait_for(WaitFor::message_on_stdout(\n            \"Qdrant is ready to accept connections\",\n        ))\n        .start()\n        .await?;\n    let port = container.get_host_port_ipv4(6334).await?;\n    let url = format!(\"http://localhost:{}\", port);\n    Ok((container, url))\n}\n\n#[tokio::test]\n#[ignore = \"requires Docker with PostgreSQL, Redis, and Qdrant containers\"]\nasync fn test_system_wide_memory_flow() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n    let postgres_setup = setup_postgres().await;\n    let redis_setup = setup_redis().await;\n    let qdrant_setup = setup_qdrant().await;\n\n    let (_pg_container, pg_url) = match postgres_setup {\n        Ok(res) =\u003e res,\n        Err(_) =\u003e {\n            eprintln!(\"Skipping system test: Docker not available\");\n            return Ok(());\n        }\n    };\n    let (_redis_container, redis_url) = redis_setup?;\n    let (_qdrant_container, qdrant_url) = qdrant_setup?;\n\n    let pg_backend = PostgresBackend::new(\u0026pg_url).await?;\n    pg_backend.initialize_schema().await?;\n\n    let _redis_storage = RedisStorage::new(\u0026redis_url).await?;\n\n    let qdrant_client = Qdrant::new(QdrantConfig::from_url(\u0026qdrant_url))?;\n    let qdrant_provider = QdrantProvider::new(qdrant_client, \"system_test\".to_string(), 128);\n    qdrant_provider\n        .ensure_collection()\n        .await\n        .map_err(|e| e.to_string())?;\n\n    let manager = MemoryManager::new();\n    manager\n        .register_provider(MemoryLayer::User, Box::new(qdrant_provider))\n        .await;\n\n    let entry = MemoryEntry {\n        id: \"system_msg_1\".to_string(),\n        content: \"System integration test content\".to_string(),\n        embedding: Some(vec![0.1; 128]),\n        layer: MemoryLayer::User,\n        metadata: HashMap::new(),\n        created_at: 1736400000,\n        updated_at: 1736400000,\n    };\n\n    let ctx = test_ctx();\n\n    manager\n        .add_to_layer(ctx.clone(), MemoryLayer::User, entry.clone())\n        .await\n        .map_err(|e| e.to_string())?;\n\n    let retrieved = manager\n        .get_from_layer(ctx.clone(), MemoryLayer::User, \"system_msg_1\")\n        .await\n        .map_err(|e| e.to_string())?;\n    assert!(retrieved.is_some());\n    let retrieved = retrieved.unwrap();\n    assert_eq!(retrieved.content, entry.content);\n\n    let search_results = manager\n        .search_hierarchical(ctx.clone(), vec![0.1; 128], 1, HashMap::new())\n        .await\n        .map_err(|e| e.to_string())?;\n    assert_eq!(search_results.len(), 1);\n    assert_eq!(search_results[0].id, \"system_msg_1\");\n\n    let session_entry = MemoryEntry {\n        id: \"session_important\".to_string(),\n        content: \"Important session content for promotion\".to_string(),\n        embedding: Some(vec![0.2; 128]),\n        layer: MemoryLayer::Session,\n        metadata: {\n            let mut m = HashMap::new();\n            m.insert(\"score\".to_string(), serde_json::json!(1.0));\n            m.insert(\"access_count\".to_string(), serde_json::json!(10));\n            m.insert(\n                \"last_accessed_at\".to_string(),\n                serde_json::json!(chrono::Utc::now().timestamp()),\n            );\n            m\n        },\n        created_at: 1736400000,\n        updated_at: 1736400000,\n    };\n\n    let session_qdrant_client = Qdrant::new(QdrantConfig::from_url(\u0026qdrant_url))?;\n    let session_provider =\n        QdrantProvider::new(session_qdrant_client, \"session_test\".to_string(), 128);\n    session_provider\n        .ensure_collection()\n        .await\n        .map_err(|e| e.to_string())?;\n\n    let project_qdrant_client = Qdrant::new(QdrantConfig::from_url(\u0026qdrant_url))?;\n    let project_provider =\n        QdrantProvider::new(project_qdrant_client, \"project_test\".to_string(), 128);\n    project_provider\n        .ensure_collection()\n        .await\n        .map_err(|e| e.to_string())?;\n\n    manager\n        .register_provider(MemoryLayer::Session, Box::new(session_provider))\n        .await;\n    manager\n        .register_provider(MemoryLayer::Project, Box::new(project_provider))\n        .await;\n\n    manager\n        .add_to_layer(ctx.clone(), MemoryLayer::Session, session_entry)\n        .await\n        .map_err(|e| e.to_string())?;\n\n    let promoted_ids = manager\n        .promote_important_memories(ctx.clone(), MemoryLayer::Session)\n        .await\n        .map_err(|e| e.to_string())?;\n    assert_eq!(promoted_ids.len(), 1);\n    assert!(promoted_ids[0].contains(\"session_important_promoted\"));\n\n    let promoted_entry = manager\n        .get_from_layer(ctx, MemoryLayer::Project, \u0026promoted_ids[0])\n        .await\n        .map_err(|e| e.to_string())?;\n    assert!(promoted_entry.is_some());\n    assert_eq!(\n        promoted_entry.unwrap().content,\n        \"Important session content for promotion\"\n    );\n\n    Ok(())\n}\n","traces":[{"line":21,"address":[],"length":0,"stats":{"Line":0}},{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":42,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":48,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":22},{"path":["/","Users","christian.klat","dev","git","aeterna","mk_core","src","lib.rs"],"content":"//! # Memory-Knowledge System Core\n//!\n//! Shared types, traits, and utilities for the Memory-Knowledge system.\n//!\n//! This crate provides:\n//! - Type definitions for memory and knowledge systems\n//! - Core traits for adapters and providers\n//! - Error types with proper handling\n//! - Validation utilities\n//!\n//! # Best Practices\n//!\n//! - Follows Microsoft Pragmatic Rust Guidelines\n//! - Uses Rust Edition 2024 (never back)\n//! - Comprehensive error handling with `thiserror`\n//! - M-CANONICAL-DOCS documentation format\n\npub mod traits;\npub mod types;\n\n// Re-export commonly used types for convenience\npub use types::{\n    ConstraintOperator, ConstraintSeverity, ConstraintTarget, HierarchyPath, KnowledgeLayer,\n    KnowledgeType, MemoryLayer, TenantContext, TenantId, UserId\n};\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","mk_core","src","traits.rs"],"content":"//! Core traits for memory-knowledge system\n\nuse async_trait::async_trait;\nuse serde::{Deserialize, Serialize};\n\n/// Storage backend trait for extensible storage implementations\n#[async_trait]\npub trait StorageBackend: Send + Sync {\n    type Error;\n\n    async fn store(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        key: \u0026str,\n        value: \u0026[u8]\n    ) -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn retrieve(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        key: \u0026str\n    ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e;\n\n    async fn delete(\u0026self, ctx: crate::types::TenantContext, key: \u0026str) -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn exists(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        key: \u0026str\n    ) -\u003e Result\u003cbool, Self::Error\u003e;\n\n    async fn get_ancestors(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        unit_id: \u0026str\n    ) -\u003e Result\u003cVec\u003ccrate::types::OrganizationalUnit\u003e, Self::Error\u003e;\n\n    async fn get_descendants(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        unit_id: \u0026str\n    ) -\u003e Result\u003cVec\u003ccrate::types::OrganizationalUnit\u003e, Self::Error\u003e;\n\n    async fn get_unit_policies(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        unit_id: \u0026str\n    ) -\u003e Result\u003cVec\u003ccrate::types::Policy\u003e, Self::Error\u003e;\n\n    async fn create_unit(\u0026self, unit: \u0026crate::types::OrganizationalUnit)\n    -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn add_unit_policy(\n        \u0026self,\n        ctx: \u0026crate::types::TenantContext,\n        unit_id: \u0026str,\n        policy: \u0026crate::types::Policy\n    ) -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn assign_role(\n        \u0026self,\n        user_id: \u0026crate::types::UserId,\n        tenant_id: \u0026crate::types::TenantId,\n        unit_id: \u0026str,\n        role: crate::types::Role\n    ) -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn remove_role(\n        \u0026self,\n        user_id: \u0026crate::types::UserId,\n        tenant_id: \u0026crate::types::TenantId,\n        unit_id: \u0026str,\n        role: crate::types::Role\n    ) -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn store_drift_result(\n        \u0026self,\n        result: crate::types::DriftResult\n    ) -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn get_latest_drift_result(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        project_id: \u0026str\n    ) -\u003e Result\u003cOption\u003ccrate::types::DriftResult\u003e, Self::Error\u003e;\n\n    async fn list_all_units(\u0026self) -\u003e Result\u003cVec\u003ccrate::types::OrganizationalUnit\u003e, Self::Error\u003e;\n    async fn record_job_status(\n        \u0026self,\n        job_name: \u0026str,\n        tenant_id: \u0026str,\n        status: \u0026str,\n        message: Option\u003c\u0026str\u003e,\n        started_at: i64,\n        finished_at: Option\u003ci64\u003e\n    ) -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn get_governance_events(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        since_timestamp: i64,\n        limit: usize\n    ) -\u003e Result\u003cVec\u003ccrate::types::GovernanceEvent\u003e, Self::Error\u003e;\n}\n\n/// Health check capability for service monitoring\npub trait HealthCheck: Send + Sync {\n    fn health_check(\u0026self) -\u003e Result\u003cHealthStatus, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e;\n}\n\n/// Health status for service monitoring\n#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]\npub enum HealthStatus {\n    Healthy,\n    Degraded,\n    Unhealthy\n}\n\n#[async_trait]\npub trait MemoryProviderAdapter: Send + Sync {\n    type Error;\n\n    async fn add(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        entry: crate::types::MemoryEntry\n    ) -\u003e Result\u003cString, Self::Error\u003e;\n\n    async fn search(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        query_vector: Vec\u003cf32\u003e,\n        limit: usize,\n        filters: std::collections::HashMap\u003cString, serde_json::Value\u003e\n    ) -\u003e Result\u003cVec\u003ccrate::types::MemoryEntry\u003e, Self::Error\u003e;\n\n    async fn get(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        id: \u0026str\n    ) -\u003e Result\u003cOption\u003ccrate::types::MemoryEntry\u003e, Self::Error\u003e;\n\n    async fn update(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        entry: crate::types::MemoryEntry\n    ) -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn delete(\u0026self, ctx: crate::types::TenantContext, id: \u0026str) -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn list(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        layer: crate::types::MemoryLayer,\n        limit: usize,\n        cursor: Option\u003cString\u003e\n    ) -\u003e Result\u003c(Vec\u003ccrate::types::MemoryEntry\u003e, Option\u003cString\u003e), Self::Error\u003e;\n}\n\n#[async_trait]\npub trait KnowledgeRepository: Send + Sync {\n    type Error;\n\n    async fn get(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        layer: crate::types::KnowledgeLayer,\n        path: \u0026str\n    ) -\u003e Result\u003cOption\u003ccrate::types::KnowledgeEntry\u003e, Self::Error\u003e;\n\n    async fn store(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        entry: crate::types::KnowledgeEntry,\n        message: \u0026str\n    ) -\u003e Result\u003cString, Self::Error\u003e;\n\n    async fn list(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        layer: crate::types::KnowledgeLayer,\n        prefix: \u0026str\n    ) -\u003e Result\u003cVec\u003ccrate::types::KnowledgeEntry\u003e, Self::Error\u003e;\n\n    async fn delete(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        layer: crate::types::KnowledgeLayer,\n        path: \u0026str,\n        message: \u0026str\n    ) -\u003e Result\u003cString, Self::Error\u003e;\n\n    async fn get_head_commit(\n        \u0026self,\n        ctx: crate::types::TenantContext\n    ) -\u003e Result\u003cOption\u003cString\u003e, Self::Error\u003e;\n\n    async fn get_affected_items(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        since_commit: \u0026str\n    ) -\u003e Result\u003cVec\u003c(crate::types::KnowledgeLayer, String)\u003e, Self::Error\u003e;\n\n    async fn search(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        query: \u0026str,\n        layers: Vec\u003ccrate::types::KnowledgeLayer\u003e,\n        limit: usize\n    ) -\u003e Result\u003cVec\u003ccrate::types::KnowledgeEntry\u003e, Self::Error\u003e;\n\n    fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e;\n}\n\n#[async_trait]\npub trait AuthorizationService: Send + Sync {\n    type Error;\n\n    async fn check_permission(\n        \u0026self,\n        ctx: \u0026crate::types::TenantContext,\n        action: \u0026str,\n        resource: \u0026str\n    ) -\u003e Result\u003cbool, Self::Error\u003e;\n\n    async fn get_user_roles(\n        \u0026self,\n        ctx: \u0026crate::types::TenantContext\n    ) -\u003e Result\u003cVec\u003ccrate::types::Role\u003e, Self::Error\u003e;\n\n    async fn assign_role(\n        \u0026self,\n        ctx: \u0026crate::types::TenantContext,\n        user_id: \u0026crate::types::UserId,\n        role: crate::types::Role\n    ) -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn remove_role(\n        \u0026self,\n        ctx: \u0026crate::types::TenantContext,\n        user_id: \u0026crate::types::UserId,\n        role: crate::types::Role\n    ) -\u003e Result\u003c(), Self::Error\u003e;\n}\n\n#[async_trait]\npub trait ContextHooks: Send + Sync {\n    async fn on_session_start(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        session_id: \u0026str\n    ) -\u003e anyhow::Result\u003c()\u003e;\n    async fn on_session_end(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        session_id: \u0026str\n    ) -\u003e anyhow::Result\u003c()\u003e;\n    async fn on_message(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        session_id: \u0026str,\n        message: \u0026str\n    ) -\u003e anyhow::Result\u003c()\u003e;\n    async fn on_tool_use(\n        \u0026self,\n        ctx: crate::types::TenantContext,\n        session_id: \u0026str,\n        tool_name: \u0026str,\n        params: serde_json::Value\n    ) -\u003e anyhow::Result\u003c()\u003e;\n}\n\n#[async_trait]\npub trait EmbeddingService: Send + Sync {\n    type Error;\n\n    async fn embed(\u0026self, text: \u0026str) -\u003e Result\u003cVec\u003cf32\u003e, Self::Error\u003e;\n\n    fn dimension(\u0026self) -\u003e usize;\n\n    async fn embed_batch(\u0026self, texts: \u0026[String]) -\u003e Result\u003cVec\u003cVec\u003cf32\u003e\u003e, Self::Error\u003e {\n        let mut results = Vec::with_capacity(texts.len());\n        for text in texts {\n            results.push(self.embed(text).await?);\n        }\n        Ok(results)\n    }\n}\n\n#[async_trait]\npub trait EventPublisher: Send + Sync {\n    type Error;\n\n    async fn publish(\u0026self, event: crate::types::GovernanceEvent) -\u003e Result\u003c(), Self::Error\u003e;\n\n    async fn subscribe(\n        \u0026self,\n        channels: \u0026[\u0026str]\n    ) -\u003e Result\u003ctokio::sync::mpsc::Receiver\u003ccrate::types::GovernanceEvent\u003e, Self::Error\u003e;\n}\n\n/// LLM service trait for text generation and reasoning\n#[async_trait]\npub trait LlmService: Send + Sync {\n    type Error;\n\n    /// Generates text based on a prompt\n    async fn generate(\u0026self, prompt: \u0026str) -\u003e Result\u003cString, Self::Error\u003e;\n\n    /// Analyzes content against a set of policies\n    async fn analyze_drift(\n        \u0026self,\n        content: \u0026str,\n        policies: \u0026[crate::types::Policy]\n    ) -\u003e Result\u003ccrate::types::ValidationResult, Self::Error\u003e;\n}\n","traces":[{"line":281,"address":[],"length":0,"stats":{"Line":1}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":284,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}}],"covered":1,"coverable":5},{"path":["/","Users","christian.klat","dev","git","aeterna","mk_core","src","types.rs"],"content":"use schemars::JsonSchema;\nuse serde::{Deserialize, Serialize};\nuse strum::{Display, EnumString};\nuse utoipa::ToSchema;\nuse validator::Validate;\n\n#[derive(\n    Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize, ToSchema, EnumString, Display,\n)]\n#[serde(rename_all = \"camelCase\")]\npub enum Role {\n    Developer,\n    TechLead,\n    Architect,\n    Admin,\n    Agent,\n}\n\n#[derive(\n    Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, ToSchema, EnumString, Display,\n)]\n#[serde(rename_all = \"camelCase\")]\n#[strum(serialize_all = \"camelCase\")]\npub enum UnitType {\n    Company,\n    Organization,\n    Team,\n    Project,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct OrganizationalUnit {\n    pub id: String,\n    pub name: String,\n    pub unit_type: UnitType,\n    pub parent_id: Option\u003cString\u003e,\n    pub tenant_id: TenantId,\n    pub metadata: std::collections::HashMap\u003cString, serde_json::Value\u003e,\n    pub created_at: i64,\n    pub updated_at: i64,\n}\n\n#[derive(\n    Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize, ToSchema, JsonSchema, PartialOrd, Ord,\n)]\n#[serde(transparent)]\npub struct TenantId(String);\n\nimpl TenantId {\n    pub fn new(id: String) -\u003e Option\u003cSelf\u003e {\n        if id.is_empty() || id.len() \u003e 100 {\n            None\n        } else {\n            Some(Self(id))\n        }\n    }\n\n    pub fn as_str(\u0026self) -\u003e \u0026str {\n        \u0026self.0\n    }\n\n    pub fn into_inner(self) -\u003e String {\n        self.0\n    }\n}\n\nimpl std::fmt::Display for TenantId {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        write!(f, \"{}\", self.0)\n    }\n}\n\nimpl Default for TenantId {\n    fn default() -\u003e Self {\n        Self(\"default\".to_string())\n    }\n}\n\nimpl std::str::FromStr for TenantId {\n    type Err = anyhow::Error;\n    fn from_str(s: \u0026str) -\u003e Result\u003cSelf, Self::Err\u003e {\n        Self::new(s.to_string()).ok_or_else(|| anyhow::anyhow!(\"Invalid tenant ID\"))\n    }\n}\n\nimpl Default for TenantContext {\n    fn default() -\u003e Self {\n        Self {\n            tenant_id: TenantId::default(),\n            user_id: UserId::default(),\n            agent_id: None,\n        }\n    }\n}\n\n#[derive(\n    Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize, ToSchema, JsonSchema, PartialOrd, Ord,\n)]\n#[serde(transparent)]\npub struct UserId(String);\n\nimpl UserId {\n    pub fn new(id: String) -\u003e Option\u003cSelf\u003e {\n        if id.is_empty() || id.len() \u003e 100 {\n            None\n        } else {\n            Some(Self(id))\n        }\n    }\n\n    pub fn as_str(\u0026self) -\u003e \u0026str {\n        \u0026self.0\n    }\n\n    pub fn into_inner(self) -\u003e String {\n        self.0\n    }\n}\n\nimpl std::fmt::Display for UserId {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        write!(f, \"{}\", self.0)\n    }\n}\n\nimpl std::str::FromStr for UserId {\n    type Err = anyhow::Error;\n    fn from_str(s: \u0026str) -\u003e Result\u003cSelf, Self::Err\u003e {\n        Self::new(s.to_string()).ok_or_else(|| anyhow::anyhow!(\"Invalid user ID\"))\n    }\n}\n\nimpl Default for UserId {\n    fn default() -\u003e Self {\n        Self(\"default\".to_string())\n    }\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\npub struct TenantContext {\n    pub tenant_id: TenantId,\n    pub user_id: UserId,\n    pub agent_id: Option\u003cString\u003e,\n}\n\nimpl TenantContext {\n    pub fn new(tenant_id: TenantId, user_id: UserId) -\u003e Self {\n        Self {\n            tenant_id,\n            user_id,\n            agent_id: None,\n        }\n    }\n\n    pub fn with_agent(tenant_id: TenantId, user_id: UserId, agent_id: String) -\u003e Self {\n        Self {\n            tenant_id,\n            user_id,\n            agent_id: Some(agent_id),\n        }\n    }\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\npub struct HierarchyPath {\n    pub company: String,\n    pub org: Option\u003cString\u003e,\n    pub team: Option\u003cString\u003e,\n    pub project: Option\u003cString\u003e,\n}\n\nimpl HierarchyPath {\n    pub fn company(id: String) -\u003e Self {\n        Self {\n            company: id,\n            org: None,\n            team: None,\n            project: None,\n        }\n    }\n\n    pub fn org(company: String, id: String) -\u003e Self {\n        Self {\n            company,\n            org: Some(id),\n            team: None,\n            project: None,\n        }\n    }\n\n    pub fn team(company: String, org: String, id: String) -\u003e Self {\n        Self {\n            company,\n            org: Some(org),\n            team: Some(id),\n            project: None,\n        }\n    }\n\n    pub fn project(company: String, org: String, team: String, id: String) -\u003e Self {\n        Self {\n            company,\n            org: Some(org),\n            team: Some(team),\n            project: Some(id),\n        }\n    }\n\n    pub fn depth(\u0026self) -\u003e usize {\n        if self.project.is_some() {\n            4\n        } else if self.team.is_some() {\n            3\n        } else if self.org.is_some() {\n            2\n        } else {\n            1\n        }\n    }\n\n    pub fn path_string(\u0026self) -\u003e String {\n        let mut parts = vec![self.company.clone()];\n        if let Some(o) = \u0026self.org {\n            parts.push(o.clone());\n        }\n        if let Some(t) = \u0026self.team {\n            parts.push(t.clone());\n        }\n        if let Some(p) = \u0026self.project {\n            parts.push(p.clone());\n        }\n        parts.join(\" \u003e \")\n    }\n}\n\nimpl Role {\n    #[must_use]\n    pub fn precedence(\u0026self) -\u003e u8 {\n        match self {\n            Role::Admin =\u003e 4,\n            Role::Architect =\u003e 3,\n            Role::TechLead =\u003e 2,\n            Role::Developer =\u003e 1,\n            Role::Agent =\u003e 0,\n        }\n    }\n\n    #[must_use]\n    pub fn display_name(\u0026self) -\u003e \u0026'static str {\n        match self {\n            Role::Developer =\u003e \"Developer\",\n            Role::TechLead =\u003e \"Tech Lead\",\n            Role::Architect =\u003e \"Architect\",\n            Role::Admin =\u003e \"Admin\",\n            Role::Agent =\u003e \"Agent\",\n        }\n    }\n}\n\n/// Knowledge types\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub enum KnowledgeType {\n    Adr,\n    Policy,\n    Pattern,\n    Spec,\n}\n\n/// Knowledge status\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub enum KnowledgeStatus {\n    Draft,\n    Proposed,\n    Accepted,\n    Deprecated,\n    Superseded,\n}\n\n#[derive(\n    Debug,\n    Clone,\n    Copy,\n    PartialEq,\n    Eq,\n    Hash,\n    Serialize,\n    Deserialize,\n    ToSchema,\n    PartialOrd,\n    Ord,\n    JsonSchema,\n)]\n#[serde(rename_all = \"camelCase\")]\npub enum KnowledgeLayer {\n    Company,\n    Org,\n    Team,\n    Project,\n}\n\n/// Constraint severity levels\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub enum ConstraintSeverity {\n    Info,\n    Warn,\n    Block,\n}\n\n/// Constraint operators\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub enum ConstraintOperator {\n    MustUse,\n    MustNotUse,\n    MustMatch,\n    MustNotMatch,\n    MustExist,\n    MustNotExist,\n}\n\n/// Constraint targets\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub enum ConstraintTarget {\n    File,\n    Code,\n    Dependency,\n    Import,\n    Config,\n}\n\n/// Memory layers for hierarchical storage\n#[derive(\n    Debug,\n    Clone,\n    Copy,\n    PartialEq,\n    Eq,\n    Hash,\n    Serialize,\n    Deserialize,\n    JsonSchema,\n    strum::EnumString,\n    strum::Display,\n    ToSchema,\n)]\n#[serde(rename_all = \"camelCase\")]\npub enum MemoryLayer {\n    Agent,\n    User,\n    Session,\n    Project,\n    Team,\n    Org,\n    Company,\n}\n\nimpl MemoryLayer {\n    #[must_use]\n    pub fn precedence(\u0026self) -\u003e u8 {\n        match self {\n            MemoryLayer::Agent =\u003e 1,\n            MemoryLayer::User =\u003e 2,\n            MemoryLayer::Session =\u003e 3,\n            MemoryLayer::Project =\u003e 4,\n            MemoryLayer::Team =\u003e 5,\n            MemoryLayer::Org =\u003e 6,\n            MemoryLayer::Company =\u003e 7,\n        }\n    }\n\n    #[must_use]\n    pub fn display_name(\u0026self) -\u003e \u0026'static str {\n        match self {\n            MemoryLayer::Agent =\u003e \"Agent\",\n            MemoryLayer::User =\u003e \"User\",\n            MemoryLayer::Session =\u003e \"Session\",\n            MemoryLayer::Project =\u003e \"Project\",\n            MemoryLayer::Team =\u003e \"Team\",\n            MemoryLayer::Org =\u003e \"Organization\",\n            MemoryLayer::Company =\u003e \"Company\",\n        }\n    }\n}\n\n#[derive(\n    Debug, Clone, PartialEq, Serialize, Deserialize, JsonSchema, Validate, Default, ToSchema,\n)]\n#[serde(rename_all = \"camelCase\")]\npub struct LayerIdentifiers {\n    #[validate(custom(function = \"validate_agent_id\"))]\n    pub agent_id: Option\u003cString\u003e,\n    #[validate(custom(function = \"validate_user_id\"))]\n    pub user_id: Option\u003cString\u003e,\n    #[validate(custom(function = \"validate_session_id\"))]\n    pub session_id: Option\u003cString\u003e,\n    #[validate(custom(function = \"validate_project_id\"))]\n    pub project_id: Option\u003cString\u003e,\n    #[validate(custom(function = \"validate_team_id\"))]\n    pub team_id: Option\u003cString\u003e,\n    #[validate(custom(function = \"validate_org_id\"))]\n    pub org_id: Option\u003cString\u003e,\n    #[validate(custom(function = \"validate_company_id\"))]\n    pub company_id: Option\u003cString\u003e,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct MemoryEntry {\n    pub id: String,\n    pub content: String,\n    pub embedding: Option\u003cVec\u003cf32\u003e\u003e,\n    pub layer: MemoryLayer,\n    pub metadata: std::collections::HashMap\u003cString, serde_json::Value\u003e,\n    pub created_at: i64,\n    pub updated_at: i64,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct KnowledgeEntry {\n    pub path: String,\n    pub content: String,\n    pub layer: KnowledgeLayer,\n    pub kind: KnowledgeType,\n    pub status: KnowledgeStatus,\n    pub metadata: std::collections::HashMap\u003cString, serde_json::Value\u003e,\n    pub commit_hash: Option\u003cString\u003e,\n    pub author: Option\u003cString\u003e,\n    pub updated_at: i64,\n}\n\n#[derive(\n    Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, JsonSchema, Default, ToSchema,\n)]\n#[serde(rename_all = \"camelCase\")]\npub enum PolicyMode {\n    #[default]\n    Optional,\n    Mandatory,\n}\n\n#[derive(\n    Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, JsonSchema, Default, ToSchema,\n)]\n#[serde(rename_all = \"camelCase\")]\npub enum RuleMergeStrategy {\n    #[default]\n    Override,\n    Merge,\n    Intersect,\n}\n\n#[derive(\n    Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, JsonSchema, Default, ToSchema,\n)]\n#[serde(rename_all = \"camelCase\")]\npub enum RuleType {\n    #[default]\n    Allow,\n    Deny,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct Policy {\n    pub id: String,\n    pub name: String,\n    pub description: Option\u003cString\u003e,\n    pub layer: KnowledgeLayer,\n    #[serde(default)]\n    pub mode: PolicyMode,\n    #[serde(default)]\n    pub merge_strategy: RuleMergeStrategy,\n    pub rules: Vec\u003cPolicyRule\u003e,\n    pub metadata: std::collections::HashMap\u003cString, serde_json::Value\u003e,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct PolicyRule {\n    pub id: String,\n    #[serde(default)]\n    pub rule_type: RuleType,\n    pub target: ConstraintTarget,\n    pub operator: ConstraintOperator,\n    pub value: serde_json::Value,\n    pub severity: ConstraintSeverity,\n    pub message: String,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, JsonSchema, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct ValidationResult {\n    pub is_valid: bool,\n    pub violations: Vec\u003cPolicyViolation\u003e,\n}\n\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema, JsonSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct PolicyViolation {\n    pub rule_id: String,\n    pub policy_id: String,\n    pub severity: ConstraintSeverity,\n    pub message: String,\n    pub context: std::collections::HashMap\u003cString, serde_json::Value\u003e,\n}\n\n/// Governance event types for auditing and real-time updates\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub enum GovernanceEvent {\n    /// New organizational unit created\n    UnitCreated {\n        unit_id: String,\n        unit_type: UnitType,\n        tenant_id: TenantId,\n        parent_id: Option\u003cString\u003e,\n        timestamp: i64,\n    },\n\n    /// Organizational unit updated\n    UnitUpdated {\n        unit_id: String,\n        tenant_id: TenantId,\n        timestamp: i64,\n    },\n\n    /// Organizational unit deleted\n    UnitDeleted {\n        unit_id: String,\n        tenant_id: TenantId,\n        timestamp: i64,\n    },\n\n    /// Role assigned to a user for a specific unit\n    RoleAssigned {\n        user_id: UserId,\n        unit_id: String,\n        role: Role,\n        tenant_id: TenantId,\n        timestamp: i64,\n    },\n\n    /// Role removed from a user\n    RoleRemoved {\n        user_id: UserId,\n        unit_id: String,\n        role: Role,\n        tenant_id: TenantId,\n        timestamp: i64,\n    },\n\n    /// Policy created or updated\n    PolicyUpdated {\n        policy_id: String,\n        layer: KnowledgeLayer,\n        tenant_id: TenantId,\n        timestamp: i64,\n    },\n\n    /// Policy deleted\n    PolicyDeleted {\n        policy_id: String,\n        tenant_id: TenantId,\n        timestamp: i64,\n    },\n\n    /// Drift detected in a project\n    DriftDetected {\n        project_id: String,\n        tenant_id: TenantId,\n        drift_score: f32,\n        timestamp: i64,\n    },\n}\n\nimpl GovernanceEvent {\n    #[must_use]\n    pub fn tenant_id(\u0026self) -\u003e \u0026TenantId {\n        match self {\n            GovernanceEvent::UnitCreated { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::UnitUpdated { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::UnitDeleted { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::RoleAssigned { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::RoleRemoved { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::PolicyUpdated { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::PolicyDeleted { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::DriftDetected { tenant_id, .. } =\u003e tenant_id,\n        }\n    }\n}\n\n/// Drift analysis result\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize, ToSchema)]\n#[serde(rename_all = \"camelCase\")]\npub struct DriftResult {\n    pub project_id: String,\n    pub tenant_id: TenantId,\n    pub drift_score: f32,\n    pub violations: Vec\u003cPolicyViolation\u003e,\n    pub timestamp: i64,\n}\n\npub fn validate_user_id(id: \u0026\u0026String) -\u003e Result\u003c(), validator::ValidationError\u003e {\n    if id.is_empty() {\n        return Err(validator::ValidationError::new(\"User ID cannot be empty\"));\n    }\n    if id.len() \u003e 100 {\n        return Err(validator::ValidationError::new(\"User ID is too long\"));\n    }\n    Ok(())\n}\n\npub fn validate_session_id(id: \u0026\u0026String) -\u003e Result\u003c(), validator::ValidationError\u003e {\n    if id.is_empty() {\n        return Err(validator::ValidationError::new(\n            \"Session ID cannot be empty\",\n        ));\n    }\n    Ok(())\n}\n\npub fn validate_project_id(id: \u0026\u0026String) -\u003e Result\u003c(), validator::ValidationError\u003e {\n    if id.is_empty() {\n        return Err(validator::ValidationError::new(\n            \"Project ID cannot be empty\",\n        ));\n    }\n    Ok(())\n}\n\npub fn validate_team_id(id: \u0026\u0026String) -\u003e Result\u003c(), validator::ValidationError\u003e {\n    if id.is_empty() {\n        return Err(validator::ValidationError::new(\"Team ID cannot be empty\"));\n    }\n    Ok(())\n}\n\npub fn validate_org_id(id: \u0026\u0026String) -\u003e Result\u003c(), validator::ValidationError\u003e {\n    if id.is_empty() {\n        return Err(validator::ValidationError::new(\"Org ID cannot be empty\"));\n    }\n    Ok(())\n}\n\npub fn validate_company_id(id: \u0026\u0026String) -\u003e Result\u003c(), validator::ValidationError\u003e {\n    if id.is_empty() {\n        return Err(validator::ValidationError::new(\n            \"Company ID cannot be empty\",\n        ));\n    }\n    Ok(())\n}\n\npub fn validate_agent_id(id: \u0026\u0026String) -\u003e Result\u003c(), validator::ValidationError\u003e {\n    if id.is_empty() {\n        return Err(validator::ValidationError::new(\"Agent ID cannot be empty\"));\n    }\n    if id.len() \u003e 100 {\n        return Err(validator::ValidationError::new(\"Agent ID is too long\"));\n    }\n    Ok(())\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use validator::Validate;\n\n    #[test]\n    fn test_knowledge_type_serialization() {\n        let adr = KnowledgeType::Adr;\n        let json = serde_json::to_string(\u0026adr).unwrap();\n        assert_eq!(json, \"\\\"adr\\\"\");\n\n        let deserialized: KnowledgeType = serde_json::from_str(\u0026json).unwrap();\n        assert_eq!(deserialized, KnowledgeType::Adr);\n    }\n\n    #[test]\n    fn test_knowledge_layer_serialization() {\n        let company = KnowledgeLayer::Company;\n        let json = serde_json::to_string(\u0026company).unwrap();\n        assert_eq!(json, \"\\\"company\\\"\");\n\n        let deserialized: KnowledgeLayer = serde_json::from_str(\u0026json).unwrap();\n        assert_eq!(deserialized, KnowledgeLayer::Company);\n    }\n\n    #[test]\n    fn test_memory_layer_precedence() {\n        assert_eq!(MemoryLayer::Agent.precedence(), 1);\n        assert_eq!(MemoryLayer::User.precedence(), 2);\n        assert_eq!(MemoryLayer::Session.precedence(), 3);\n        assert_eq!(MemoryLayer::Project.precedence(), 4);\n        assert_eq!(MemoryLayer::Team.precedence(), 5);\n        assert_eq!(MemoryLayer::Org.precedence(), 6);\n        assert_eq!(MemoryLayer::Company.precedence(), 7);\n    }\n\n    #[test]\n    fn test_memory_layer_serialization() {\n        let agent = MemoryLayer::Agent;\n        let json = serde_json::to_string(\u0026agent).unwrap();\n        assert_eq!(json, \"\\\"agent\\\"\");\n\n        let deserialized: MemoryLayer = serde_json::from_str(\u0026json).unwrap();\n        assert_eq!(deserialized, MemoryLayer::Agent);\n    }\n\n    #[test]\n    fn test_constraint_severity_serialization() {\n        let block = ConstraintSeverity::Block;\n        let json = serde_json::to_string(\u0026block).unwrap();\n        assert_eq!(json, \"\\\"block\\\"\");\n\n        let deserialized: ConstraintSeverity = serde_json::from_str(\u0026json).unwrap();\n        assert_eq!(deserialized, ConstraintSeverity::Block);\n    }\n\n    #[test]\n    fn test_constraint_operator_serialization() {\n        let must_use = ConstraintOperator::MustUse;\n        let json = serde_json::to_string(\u0026must_use).unwrap();\n        assert_eq!(json, \"\\\"mustUse\\\"\");\n\n        let deserialized: ConstraintOperator = serde_json::from_str(\u0026json).unwrap();\n        assert_eq!(deserialized, ConstraintOperator::MustUse);\n    }\n\n    #[test]\n    fn test_constraint_target_serialization() {\n        let file = ConstraintTarget::File;\n        let json = serde_json::to_string(\u0026file).unwrap();\n        assert_eq!(json, \"\\\"file\\\"\");\n\n        let deserialized: ConstraintTarget = serde_json::from_str(\u0026json).unwrap();\n        assert_eq!(deserialized, ConstraintTarget::File);\n    }\n\n    #[test]\n    fn test_memory_entry_creation() {\n        let entry = MemoryEntry {\n            id: \"test_id\".to_string(),\n            content: \"Test content\".to_string(),\n            embedding: Some(vec![0.1, 0.2, 0.3]),\n            layer: MemoryLayer::User,\n            metadata: std::collections::HashMap::new(),\n            created_at: 1234567890,\n            updated_at: 1234567890,\n        };\n\n        assert_eq!(entry.id, \"test_id\");\n        assert_eq!(entry.content, \"Test content\");\n        assert_eq!(entry.layer, MemoryLayer::User);\n        assert_eq!(entry.embedding.unwrap().len(), 3);\n    }\n\n    #[test]\n    fn test_knowledge_entry_creation() {\n        let entry = KnowledgeEntry {\n            path: \"docs/adr/001.md\".to_string(),\n            content: \"# ADR 001: Use Rust\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Adr,\n            metadata: std::collections::HashMap::new(),\n            commit_hash: Some(\"abc123\".to_string()),\n            author: Some(\"Alice\".to_string()),\n            status: KnowledgeStatus::Accepted,\n            updated_at: 1234567890,\n        };\n\n        assert_eq!(entry.path, \"docs/adr/001.md\");\n        assert_eq!(entry.layer, KnowledgeLayer::Project);\n        assert_eq!(entry.kind, KnowledgeType::Adr);\n        assert_eq!(entry.commit_hash.unwrap(), \"abc123\");\n    }\n\n    #[test]\n    fn test_policy_creation() {\n        let rule = PolicyRule {\n            id: \"rule_1\".to_string(),\n            rule_type: RuleType::Deny,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustNotUse,\n            value: serde_json::json!(\"unsafe-lib\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Do not use unsafe libraries\".to_string(),\n        };\n\n        let policy = Policy {\n            id: \"policy_1\".to_string(),\n            name: \"Security Policy\".to_string(),\n            description: Some(\"Security constraints\".to_string()),\n            layer: KnowledgeLayer::Company,\n            mode: PolicyMode::Mandatory,\n            merge_strategy: RuleMergeStrategy::Merge,\n            rules: vec![rule],\n            metadata: std::collections::HashMap::new(),\n        };\n\n        assert_eq!(policy.id, \"policy_1\");\n        assert_eq!(policy.layer, KnowledgeLayer::Company);\n        assert_eq!(policy.rules.len(), 1);\n        assert_eq!(policy.rules[0].target, ConstraintTarget::Dependency);\n    }\n\n    #[test]\n    fn test_validation_result_creation() {\n        let violation = PolicyViolation {\n            rule_id: \"rule_1\".to_string(),\n            policy_id: \"policy_1\".to_string(),\n            severity: ConstraintSeverity::Warn,\n            message: \"Warning message\".to_string(),\n            context: std::collections::HashMap::new(),\n        };\n\n        let result = ValidationResult {\n            is_valid: false,\n            violations: vec![violation],\n        };\n\n        assert!(!result.is_valid);\n        assert_eq!(result.violations.len(), 1);\n        assert_eq!(result.violations[0].severity, ConstraintSeverity::Warn);\n    }\n\n    #[test]\n    fn test_validate_user_id_valid() {\n        let user_id = \"user_123\".to_string();\n        let result = validate_user_id(\u0026\u0026user_id);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_validate_user_id_empty() {\n        let user_id = \"\".to_string();\n        let result = validate_user_id(\u0026\u0026user_id);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_validate_user_id_too_long() {\n        let user_id = \"a\".repeat(101);\n        let result = validate_user_id(\u0026\u0026user_id);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_validate_session_id_valid() {\n        let session_id = \"session_456\".to_string();\n        let result = validate_session_id(\u0026\u0026session_id);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_validate_project_id_valid() {\n        let project_id = \"project_789\".to_string();\n        let result = validate_project_id(\u0026\u0026project_id);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_validate_team_id_valid() {\n        let team_id = \"team_abc\".to_string();\n        let result = validate_team_id(\u0026\u0026team_id);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_validate_org_id_valid() {\n        let org_id = \"org_xyz\".to_string();\n        let result = validate_org_id(\u0026\u0026org_id);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_validate_company_id_valid() {\n        let company_id = \"company_123\".to_string();\n        let result = validate_company_id(\u0026\u0026company_id);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_layer_identifiers_validation() {\n        let identifiers = LayerIdentifiers {\n            agent_id: Some(\"agent_1\".to_string()),\n            user_id: Some(\"user_123\".to_string()),\n            session_id: Some(\"session_456\".to_string()),\n            project_id: Some(\"project_789\".to_string()),\n            team_id: Some(\"team_abc\".to_string()),\n            org_id: Some(\"org_xyz\".to_string()),\n            company_id: Some(\"company_123\".to_string()),\n        };\n\n        let result = identifiers.validate();\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_layer_identifiers_invalid_user_id() {\n        let identifiers = LayerIdentifiers {\n            agent_id: Some(\"agent_1\".to_string()),\n            user_id: Some(\"\".to_string()),\n            session_id: None,\n            project_id: None,\n            team_id: None,\n            org_id: None,\n            company_id: None,\n        };\n\n        let result = identifiers.validate();\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_memory_layer_display_name() {\n        assert_eq!(MemoryLayer::Agent.display_name(), \"Agent\");\n        assert_eq!(MemoryLayer::User.display_name(), \"User\");\n        assert_eq!(MemoryLayer::Session.display_name(), \"Session\");\n        assert_eq!(MemoryLayer::Project.display_name(), \"Project\");\n        assert_eq!(MemoryLayer::Team.display_name(), \"Team\");\n        assert_eq!(MemoryLayer::Org.display_name(), \"Organization\");\n        assert_eq!(MemoryLayer::Company.display_name(), \"Company\");\n    }\n\n    #[test]\n    fn test_validate_agent_id_valid() {\n        let agent_id = \"agent_123\".to_string();\n        let result = validate_agent_id(\u0026\u0026agent_id);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_validate_agent_id_empty() {\n        let agent_id = \"\".to_string();\n        let result = validate_agent_id(\u0026\u0026agent_id);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_validate_agent_id_too_long() {\n        let agent_id = \"a\".repeat(101);\n        let result = validate_agent_id(\u0026\u0026agent_id);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_validate_session_id_empty() {\n        let id = \"\".to_string();\n        assert!(validate_session_id(\u0026\u0026id).is_err());\n    }\n\n    #[test]\n    fn test_validate_project_id_empty() {\n        let id = \"\".to_string();\n        assert!(validate_project_id(\u0026\u0026id).is_err());\n    }\n\n    #[test]\n    fn test_validate_team_id_empty() {\n        let id = \"\".to_string();\n        assert!(validate_team_id(\u0026\u0026id).is_err());\n    }\n\n    #[test]\n    fn test_validate_org_id_empty() {\n        let id = \"\".to_string();\n        assert!(validate_org_id(\u0026\u0026id).is_err());\n    }\n\n    #[test]\n    fn test_validate_company_id_empty() {\n        let id = \"\".to_string();\n        assert!(validate_company_id(\u0026\u0026id).is_err());\n    }\n\n    #[test]\n    fn test_memory_layer_from_str() {\n        use std::str::FromStr;\n        assert_eq!(MemoryLayer::from_str(\"Agent\").unwrap(), MemoryLayer::Agent);\n        assert_eq!(\n            MemoryLayer::from_str(\"Session\").unwrap(),\n            MemoryLayer::Session\n        );\n        assert!(MemoryLayer::from_str(\"Invalid\").is_err());\n    }\n\n    #[test]\n    fn test_memory_layer_display() {\n        assert_eq!(format!(\"{}\", MemoryLayer::Agent), \"Agent\");\n        assert_eq!(format!(\"{}\", MemoryLayer::User), \"User\");\n        assert_eq!(format!(\"{}\", MemoryLayer::Session), \"Session\");\n        assert_eq!(format!(\"{}\", MemoryLayer::Project), \"Project\");\n        assert_eq!(format!(\"{}\", MemoryLayer::Team), \"Team\");\n        assert_eq!(format!(\"{}\", MemoryLayer::Org), \"Org\");\n        assert_eq!(format!(\"{}\", MemoryLayer::Company), \"Company\");\n    }\n\n    #[test]\n    fn test_role_serialization() {\n        let architect = Role::Architect;\n        let json = serde_json::to_string(\u0026architect).unwrap();\n        assert_eq!(json, \"\\\"architect\\\"\");\n\n        let deserialized: Role = serde_json::from_str(\u0026json).unwrap();\n        assert_eq!(deserialized, Role::Architect);\n    }\n\n    #[test]\n    fn test_role_precedence() {\n        assert_eq!(Role::Admin.precedence(), 4);\n        assert_eq!(Role::Architect.precedence(), 3);\n        assert_eq!(Role::TechLead.precedence(), 2);\n        assert_eq!(Role::Developer.precedence(), 1);\n        assert_eq!(Role::Agent.precedence(), 0);\n    }\n\n    #[test]\n    fn test_role_display_name() {\n        assert_eq!(Role::Developer.display_name(), \"Developer\");\n        assert_eq!(Role::TechLead.display_name(), \"Tech Lead\");\n        assert_eq!(Role::Architect.display_name(), \"Architect\");\n        assert_eq!(Role::Admin.display_name(), \"Admin\");\n        assert_eq!(Role::Agent.display_name(), \"Agent\");\n    }\n\n    #[test]\n    fn test_tenant_id_validation() {\n        assert!(TenantId::new(\"comp_123\".to_string()).is_some());\n        assert!(TenantId::new(\"\".to_string()).is_none());\n        assert!(TenantId::new(\"a\".repeat(101)).is_none());\n    }\n\n    #[test]\n    fn test_user_id_validation() {\n        assert!(UserId::new(\"user_456\".to_string()).is_some());\n        assert!(UserId::new(\"\".to_string()).is_none());\n        assert!(UserId::new(\"a\".repeat(101)).is_none());\n    }\n\n    #[test]\n    fn test_hierarchy_path_depth() {\n        let company = HierarchyPath::company(\"c1\".to_string());\n        assert_eq!(company.depth(), 1);\n\n        let org = HierarchyPath::org(\"c1\".to_string(), \"o1\".to_string());\n        assert_eq!(org.depth(), 2);\n\n        let team = HierarchyPath::team(\"c1\".to_string(), \"o1\".to_string(), \"t1\".to_string());\n        assert_eq!(team.depth(), 3);\n\n        let project = HierarchyPath::project(\n            \"c1\".to_string(),\n            \"o1\".to_string(),\n            \"t1\".to_string(),\n            \"p1\".to_string(),\n        );\n        assert_eq!(project.depth(), 4);\n    }\n\n    #[test]\n    fn test_hierarchy_path_string() {\n        let project = HierarchyPath::project(\n            \"c1\".to_string(),\n            \"o1\".to_string(),\n            \"t1\".to_string(),\n            \"p1\".to_string(),\n        );\n        assert_eq!(project.path_string(), \"c1 \u003e o1 \u003e t1 \u003e p1\");\n    }\n\n    #[test]\n    fn test_tenant_context_creation() {\n        let tenant_id = TenantId::new(\"c1\".to_string()).unwrap();\n        let user_id = UserId::new(\"u1\".to_string()).unwrap();\n        let ctx = TenantContext::new(tenant_id, user_id);\n\n        assert_eq!(ctx.tenant_id.as_str(), \"c1\");\n        assert_eq!(ctx.user_id.as_str(), \"u1\");\n        assert!(ctx.agent_id.is_none());\n    }\n\n    #[test]\n    fn test_tenant_context_with_agent() {\n        let tenant_id = TenantId::new(\"c1\".to_string()).unwrap();\n        let user_id = UserId::new(\"u1\".to_string()).unwrap();\n        let ctx = TenantContext::with_agent(tenant_id, user_id, \"a1\".to_string());\n\n        assert_eq!(ctx.agent_id.unwrap(), \"a1\");\n    }\n\n    #[test]\n    fn test_tenant_id_display() {\n        let id = TenantId::new(\"c1\".to_string()).unwrap();\n        assert_eq!(format!(\"{}\", id), \"c1\");\n    }\n\n    #[test]\n    fn test_user_id_display() {\n        let id = UserId::new(\"u1\".to_string()).unwrap();\n        assert_eq!(format!(\"{}\", id), \"u1\");\n    }\n\n    #[test]\n    fn test_tenant_id_from_str() {\n        use std::str::FromStr;\n        let id = TenantId::from_str(\"c1\").unwrap();\n        assert_eq!(id.as_str(), \"c1\");\n        assert!(TenantId::from_str(\"\").is_err());\n    }\n\n    #[test]\n    fn test_user_id_from_str() {\n        use std::str::FromStr;\n        let id = UserId::from_str(\"u1\").unwrap();\n        assert_eq!(id.as_str(), \"u1\");\n        assert!(UserId::from_str(\"\").is_err());\n    }\n\n    #[test]\n    fn test_tenant_id_into_inner() {\n        let id = TenantId::new(\"c1\".to_string()).unwrap();\n        assert_eq!(id.into_inner(), \"c1\");\n    }\n\n    #[test]\n    fn test_user_id_into_inner() {\n        let id = UserId::new(\"u1\".to_string()).unwrap();\n        assert_eq!(id.into_inner(), \"u1\");\n    }\n}\n","traces":[{"line":51,"address":[],"length":0,"stats":{"Line":185}},{"line":52,"address":[],"length":0,"stats":{"Line":553}},{"line":53,"address":[],"length":0,"stats":{"Line":3}},{"line":55,"address":[],"length":0,"stats":{"Line":182}},{"line":59,"address":[],"length":0,"stats":{"Line":156}},{"line":60,"address":[],"length":0,"stats":{"Line":156}},{"line":63,"address":[],"length":0,"stats":{"Line":1}},{"line":64,"address":[],"length":0,"stats":{"Line":1}},{"line":69,"address":[],"length":0,"stats":{"Line":1}},{"line":70,"address":[],"length":0,"stats":{"Line":3}},{"line":75,"address":[],"length":0,"stats":{"Line":1070}},{"line":76,"address":[],"length":0,"stats":{"Line":1070}},{"line":82,"address":[],"length":0,"stats":{"Line":52}},{"line":83,"address":[],"length":0,"stats":{"Line":210}},{"line":88,"address":[],"length":0,"stats":{"Line":1047}},{"line":90,"address":[],"length":0,"stats":{"Line":2094}},{"line":91,"address":[],"length":0,"stats":{"Line":1047}},{"line":104,"address":[],"length":0,"stats":{"Line":129}},{"line":105,"address":[],"length":0,"stats":{"Line":385}},{"line":106,"address":[],"length":0,"stats":{"Line":3}},{"line":108,"address":[],"length":0,"stats":{"Line":126}},{"line":112,"address":[],"length":0,"stats":{"Line":212}},{"line":113,"address":[],"length":0,"stats":{"Line":212}},{"line":116,"address":[],"length":0,"stats":{"Line":1}},{"line":117,"address":[],"length":0,"stats":{"Line":1}},{"line":122,"address":[],"length":0,"stats":{"Line":1}},{"line":123,"address":[],"length":0,"stats":{"Line":3}},{"line":129,"address":[],"length":0,"stats":{"Line":32}},{"line":130,"address":[],"length":0,"stats":{"Line":130}},{"line":135,"address":[],"length":0,"stats":{"Line":1092}},{"line":136,"address":[],"length":0,"stats":{"Line":1092}},{"line":148,"address":[],"length":0,"stats":{"Line":134}},{"line":156,"address":[],"length":0,"stats":{"Line":2}},{"line":160,"address":[],"length":0,"stats":{"Line":2}},{"line":174,"address":[],"length":0,"stats":{"Line":1}},{"line":183,"address":[],"length":0,"stats":{"Line":1}},{"line":186,"address":[],"length":0,"stats":{"Line":2}},{"line":192,"address":[],"length":0,"stats":{"Line":1}},{"line":195,"address":[],"length":0,"stats":{"Line":2}},{"line":196,"address":[],"length":0,"stats":{"Line":1}},{"line":201,"address":[],"length":0,"stats":{"Line":2}},{"line":204,"address":[],"length":0,"stats":{"Line":4}},{"line":205,"address":[],"length":0,"stats":{"Line":2}},{"line":206,"address":[],"length":0,"stats":{"Line":2}},{"line":210,"address":[],"length":0,"stats":{"Line":4}},{"line":211,"address":[],"length":0,"stats":{"Line":8}},{"line":212,"address":[],"length":0,"stats":{"Line":1}},{"line":213,"address":[],"length":0,"stats":{"Line":6}},{"line":214,"address":[],"length":0,"stats":{"Line":1}},{"line":215,"address":[],"length":0,"stats":{"Line":4}},{"line":216,"address":[],"length":0,"stats":{"Line":1}},{"line":218,"address":[],"length":0,"stats":{"Line":1}},{"line":222,"address":[],"length":0,"stats":{"Line":1}},{"line":223,"address":[],"length":0,"stats":{"Line":4}},{"line":224,"address":[],"length":0,"stats":{"Line":3}},{"line":225,"address":[],"length":0,"stats":{"Line":3}},{"line":227,"address":[],"length":0,"stats":{"Line":3}},{"line":228,"address":[],"length":0,"stats":{"Line":3}},{"line":230,"address":[],"length":0,"stats":{"Line":3}},{"line":231,"address":[],"length":0,"stats":{"Line":3}},{"line":233,"address":[],"length":0,"stats":{"Line":2}},{"line":239,"address":[],"length":0,"stats":{"Line":5}},{"line":240,"address":[],"length":0,"stats":{"Line":5}},{"line":241,"address":[],"length":0,"stats":{"Line":1}},{"line":242,"address":[],"length":0,"stats":{"Line":1}},{"line":243,"address":[],"length":0,"stats":{"Line":1}},{"line":244,"address":[],"length":0,"stats":{"Line":1}},{"line":245,"address":[],"length":0,"stats":{"Line":1}},{"line":250,"address":[],"length":0,"stats":{"Line":5}},{"line":251,"address":[],"length":0,"stats":{"Line":5}},{"line":252,"address":[],"length":0,"stats":{"Line":1}},{"line":253,"address":[],"length":0,"stats":{"Line":1}},{"line":254,"address":[],"length":0,"stats":{"Line":1}},{"line":255,"address":[],"length":0,"stats":{"Line":1}},{"line":256,"address":[],"length":0,"stats":{"Line":1}},{"line":364,"address":[],"length":0,"stats":{"Line":13}},{"line":365,"address":[],"length":0,"stats":{"Line":13}},{"line":366,"address":[],"length":0,"stats":{"Line":3}},{"line":367,"address":[],"length":0,"stats":{"Line":4}},{"line":368,"address":[],"length":0,"stats":{"Line":2}},{"line":369,"address":[],"length":0,"stats":{"Line":1}},{"line":370,"address":[],"length":0,"stats":{"Line":1}},{"line":371,"address":[],"length":0,"stats":{"Line":1}},{"line":372,"address":[],"length":0,"stats":{"Line":1}},{"line":377,"address":[],"length":0,"stats":{"Line":7}},{"line":378,"address":[],"length":0,"stats":{"Line":7}},{"line":379,"address":[],"length":0,"stats":{"Line":1}},{"line":380,"address":[],"length":0,"stats":{"Line":1}},{"line":381,"address":[],"length":0,"stats":{"Line":1}},{"line":382,"address":[],"length":0,"stats":{"Line":1}},{"line":383,"address":[],"length":0,"stats":{"Line":1}},{"line":384,"address":[],"length":0,"stats":{"Line":1}},{"line":385,"address":[],"length":0,"stats":{"Line":1}},{"line":584,"address":[],"length":0,"stats":{"Line":0}},{"line":585,"address":[],"length":0,"stats":{"Line":0}},{"line":586,"address":[],"length":0,"stats":{"Line":0}},{"line":587,"address":[],"length":0,"stats":{"Line":0}},{"line":588,"address":[],"length":0,"stats":{"Line":0}},{"line":589,"address":[],"length":0,"stats":{"Line":0}},{"line":590,"address":[],"length":0,"stats":{"Line":0}},{"line":591,"address":[],"length":0,"stats":{"Line":0}},{"line":592,"address":[],"length":0,"stats":{"Line":0}},{"line":593,"address":[],"length":0,"stats":{"Line":0}},{"line":609,"address":[],"length":0,"stats":{"Line":5}},{"line":610,"address":[],"length":0,"stats":{"Line":10}},{"line":611,"address":[],"length":0,"stats":{"Line":2}},{"line":613,"address":[],"length":0,"stats":{"Line":3}},{"line":614,"address":[],"length":0,"stats":{"Line":1}},{"line":616,"address":[],"length":0,"stats":{"Line":2}},{"line":619,"address":[],"length":0,"stats":{"Line":3}},{"line":620,"address":[],"length":0,"stats":{"Line":6}},{"line":621,"address":[],"length":0,"stats":{"Line":1}},{"line":622,"address":[],"length":0,"stats":{"Line":1}},{"line":625,"address":[],"length":0,"stats":{"Line":2}},{"line":628,"address":[],"length":0,"stats":{"Line":3}},{"line":629,"address":[],"length":0,"stats":{"Line":6}},{"line":630,"address":[],"length":0,"stats":{"Line":1}},{"line":631,"address":[],"length":0,"stats":{"Line":1}},{"line":634,"address":[],"length":0,"stats":{"Line":2}},{"line":637,"address":[],"length":0,"stats":{"Line":3}},{"line":638,"address":[],"length":0,"stats":{"Line":6}},{"line":639,"address":[],"length":0,"stats":{"Line":1}},{"line":641,"address":[],"length":0,"stats":{"Line":2}},{"line":644,"address":[],"length":0,"stats":{"Line":3}},{"line":645,"address":[],"length":0,"stats":{"Line":6}},{"line":646,"address":[],"length":0,"stats":{"Line":1}},{"line":648,"address":[],"length":0,"stats":{"Line":2}},{"line":651,"address":[],"length":0,"stats":{"Line":3}},{"line":652,"address":[],"length":0,"stats":{"Line":6}},{"line":653,"address":[],"length":0,"stats":{"Line":1}},{"line":654,"address":[],"length":0,"stats":{"Line":1}},{"line":657,"address":[],"length":0,"stats":{"Line":2}},{"line":660,"address":[],"length":0,"stats":{"Line":5}},{"line":661,"address":[],"length":0,"stats":{"Line":10}},{"line":662,"address":[],"length":0,"stats":{"Line":1}},{"line":664,"address":[],"length":0,"stats":{"Line":4}},{"line":665,"address":[],"length":0,"stats":{"Line":1}},{"line":667,"address":[],"length":0,"stats":{"Line":3}}],"covered":128,"coverable":138},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","src","events.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::EventPublisher;\nuse mk_core::types::GovernanceEvent;\nuse redis::AsyncCommands;\nuse std::sync::Arc;\nuse thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum EventError {\n    #[error(\"Redis error: {0}\")]\n    Redis(#[from] redis::RedisError),\n    #[error(\"Serialization error: {0}\")]\n    Serialization(#[from] serde_json::Error),\n    #[error(\"Internal error: {0}\")]\n    Internal(String),\n}\n\npub struct RedisPublisher {\n    client: Arc\u003credis::Client\u003e,\n    stream_name: String,\n}\n\nimpl RedisPublisher {\n    pub fn new(connection_url: \u0026str, stream_name: \u0026str) -\u003e Result\u003cSelf, EventError\u003e {\n        let client = redis::Client::open(connection_url)?;\n        Ok(Self {\n            client: Arc::new(client),\n            stream_name: stream_name.to_string(),\n        })\n    }\n}\n\n#[async_trait]\nimpl EventPublisher for RedisPublisher {\n    type Error = EventError;\n\n    async fn publish(\u0026self, event: GovernanceEvent) -\u003e Result\u003c(), Self::Error\u003e {\n        let mut conn = self.client.get_connection_manager().await?;\n        let event_json = serde_json::to_string(\u0026event)?;\n\n        let _: String = conn\n            .xadd(\u0026self.stream_name, \"*\", \u0026[(\"event\", event_json)])\n            .await?;\n\n        Ok(())\n    }\n\n    async fn subscribe(\n        \u0026self,\n        _channels: \u0026[\u0026str],\n    ) -\u003e Result\u003ctokio::sync::mpsc::Receiver\u003cGovernanceEvent\u003e, Self::Error\u003e {\n        let client = self.client.clone();\n        let stream_name = self.stream_name.clone();\n        let (tx, rx) = tokio::sync::mpsc::channel(100);\n\n        tokio::spawn(async move {\n            if let Ok(mut conn) = client.get_connection_manager().await {\n                let mut last_id = \"0\".to_string();\n\n                loop {\n                    let opts = redis::streams::StreamReadOptions::default()\n                        .block(0)\n                        .count(10);\n\n                    let result: Result\u003credis::streams::StreamReadReply, redis::RedisError\u003e = conn\n                        .xread_options(\u0026[\u0026stream_name], \u0026[\u0026last_id], \u0026opts)\n                        .await;\n\n                    match result {\n                        Ok(reply) =\u003e {\n                            for stream in reply.keys {\n                                for record in stream.ids {\n                                    if let Some(event_json) = record.map.get(\"event\") {\n                                        let event_str: String =\n                                            redis::from_redis_value(event_json.clone())\n                                                .unwrap_or_default();\n                                        if let Ok(event) =\n                                            serde_json::from_str::\u003cGovernanceEvent\u003e(\u0026event_str)\n                                        {\n                                            if tx.send(event).await.is_err() {\n                                                return;\n                                            }\n                                        }\n                                    }\n                                    last_id = record.id;\n                                }\n                            }\n                        }\n                        Err(e) =\u003e {\n                            tracing::error!(\"Redis subscription error: {}\", e);\n                            tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;\n                        }\n                    }\n                }\n            }\n        });\n\n        Ok(rx)\n    }\n}\n\npub struct MultiPublisher\u003cE: std::error::Error + Send + Sync + 'static\u003e {\n    publishers: Vec\u003cBox\u003cdyn EventPublisher\u003cError = E\u003e + Send + Sync\u003e\u003e,\n}\n\nimpl\u003cE: std::error::Error + Send + Sync + 'static\u003e MultiPublisher\u003cE\u003e {\n    pub fn new(publishers: Vec\u003cBox\u003cdyn EventPublisher\u003cError = E\u003e + Send + Sync\u003e\u003e) -\u003e Self {\n        Self { publishers }\n    }\n}\n\n#[async_trait]\nimpl\u003cE: std::error::Error + Send + Sync + 'static\u003e EventPublisher for MultiPublisher\u003cE\u003e {\n    type Error = E;\n\n    async fn publish(\u0026self, event: GovernanceEvent) -\u003e Result\u003c(), Self::Error\u003e {\n        for publisher in \u0026self.publishers {\n            publisher.publish(event.clone()).await?;\n        }\n        Ok(())\n    }\n\n    async fn subscribe(\n        \u0026self,\n        _channels: \u0026[\u0026str],\n    ) -\u003e Result\u003ctokio::sync::mpsc::Receiver\u003cGovernanceEvent\u003e, Self::Error\u003e {\n        panic!(\"Subscribe not implemented for multi-publisher\")\n    }\n}\n","traces":[{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":28,"address":[],"length":0,"stats":{"Line":0}},{"line":37,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":37},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","src","lib.rs"],"content":"pub mod events;\npub mod postgres;\npub mod redis;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","src","postgres.rs"],"content":"use async_trait::async_trait;\nuse mk_core::traits::StorageBackend;\nuse mk_core::types::{OrganizationalUnit, TenantContext, UnitType};\nuse sqlx::{Pool, Postgres, Row};\nuse thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum PostgresError {\n    #[error(\"Database error: {0}\")]\n    Database(#[from] sqlx::Error),\n    #[error(\"Serialization error: {0}\")]\n    Serialization(#[from] serde_json::Error),\n    #[error(\"Unit not found: {0}\")]\n    NotFound(String),\n}\n\npub struct PostgresBackend {\n    pool: Pool\u003cPostgres\u003e,\n}\n\nimpl PostgresBackend {\n    pub fn pool(\u0026self) -\u003e \u0026Pool\u003cPostgres\u003e {\n        \u0026self.pool\n    }\n\n    pub async fn new(connection_url: \u0026str) -\u003e Result\u003cSelf, PostgresError\u003e {\n        let pool = Pool::connect(connection_url).await?;\n        Ok(Self { pool })\n    }\n\n    pub async fn initialize_schema(\u0026self) -\u003e Result\u003c(), PostgresError\u003e {\n        // Enable pgcrypto extension for gen_random_uuid()\n        sqlx::query(\"CREATE EXTENSION IF NOT EXISTS pgcrypto\")\n            .execute(\u0026self.pool)\n            .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS sync_state (\n                id TEXT NOT NULL,\n                tenant_id TEXT NOT NULL,\n                data JSONB NOT NULL,\n                updated_at BIGINT NOT NULL,\n                PRIMARY KEY (id, tenant_id)\n            )\",\n        )\n        .execute(\u0026self.pool)\n        .await?;\n\n        sqlx::query(\"CREATE INDEX IF NOT EXISTS idx_sync_state_tenant_id ON sync_state(tenant_id)\")\n            .execute(\u0026self.pool)\n            .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS organizational_units (\n                id TEXT PRIMARY KEY,\n                name TEXT NOT NULL,\n                type TEXT NOT NULL, -- 'company', 'organization', 'team', 'project'\n                parent_id TEXT REFERENCES organizational_units(id),\n                tenant_id TEXT NOT NULL,\n                metadata JSONB DEFAULT '{}',\n                created_at BIGINT NOT NULL,\n                updated_at BIGINT NOT NULL\n            )\",\n        )\n        .execute(\u0026self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS user_roles (\n                user_id TEXT NOT NULL,\n                tenant_id TEXT NOT NULL,\n                unit_id TEXT NOT NULL REFERENCES organizational_units(id),\n                role TEXT NOT NULL,\n                created_at BIGINT NOT NULL,\n                PRIMARY KEY (user_id, tenant_id, unit_id, role)\n            )\",\n        )\n        .execute(\u0026self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS unit_policies (\n                id TEXT PRIMARY KEY,\n                unit_id TEXT NOT NULL REFERENCES organizational_units(id),\n                policy JSONB NOT NULL,\n                created_at BIGINT NOT NULL,\n                updated_at BIGINT NOT NULL\n            )\",\n        )\n        .execute(\u0026self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS governance_events (\n                id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n                event_type TEXT NOT NULL,\n                tenant_id TEXT NOT NULL,\n                payload JSONB NOT NULL,\n                timestamp BIGINT NOT NULL\n            )\",\n        )\n        .execute(\u0026self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS drift_results (\n                project_id TEXT NOT NULL,\n                tenant_id TEXT NOT NULL,\n                drift_score REAL NOT NULL,\n                violations JSONB NOT NULL,\n                timestamp BIGINT NOT NULL,\n                PRIMARY KEY (project_id, tenant_id, timestamp)\n            )\",\n        )\n        .execute(\u0026self.pool)\n        .await?;\n\n        sqlx::query(\n            \"CREATE TABLE IF NOT EXISTS job_status (\n                id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n                job_name TEXT NOT NULL,\n                tenant_id TEXT NOT NULL,\n                status TEXT NOT NULL, -- 'running', 'completed', 'failed'\n                message TEXT,\n                started_at BIGINT NOT NULL,\n                finished_at BIGINT,\n                duration_ms BIGINT\n            )\",\n        )\n        .execute(\u0026self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    pub async fn create_unit(\u0026self, unit: \u0026OrganizationalUnit) -\u003e Result\u003c(), PostgresError\u003e {\n        if let Some(ref parent_id) = unit.parent_id {\n            let parent = self\n                .get_unit_by_id(parent_id)\n                .await?\n                .ok_or_else(|| PostgresError::NotFound(parent_id.clone()))?;\n\n            match (parent.unit_type, unit.unit_type) {\n                (UnitType::Company, UnitType::Organization) =\u003e {}\n                (UnitType::Organization, UnitType::Team) =\u003e {}\n                (UnitType::Team, UnitType::Project) =\u003e {}\n                _ =\u003e {\n                    return Err(PostgresError::Database(sqlx::Error::Decode(\n                        format!(\n                            \"Invalid hierarchy: cannot create {:?} under {:?}\",\n                            unit.unit_type, parent.unit_type\n                        )\n                        .into(),\n                    )));\n                }\n            }\n        } else if unit.unit_type != UnitType::Company {\n            return Err(PostgresError::Database(sqlx::Error::Decode(\n                \"Only Company units can be root units (no parent)\".into(),\n            )));\n        }\n\n        sqlx::query(\n            \"INSERT INTO organizational_units (id, name, type, parent_id, tenant_id, metadata, \\\n             created_at, updated_at)\n             VALUES ($1, $2, $3, $4, $5, $6, $7, $8)\",\n        )\n        .bind(\u0026unit.id)\n        .bind(\u0026unit.name)\n        .bind(unit.unit_type.to_string().to_lowercase())\n        .bind(\u0026unit.parent_id)\n        .bind(unit.tenant_id.as_str())\n        .bind(serde_json::to_value(\u0026unit.metadata)?)\n        .bind(unit.created_at)\n        .bind(unit.updated_at)\n        .execute(\u0026self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    async fn get_unit_by_id(\u0026self, id: \u0026str) -\u003e Result\u003cOption\u003cOrganizationalUnit\u003e, PostgresError\u003e {\n        let row = sqlx::query(\n            \"SELECT id, name, type, parent_id, tenant_id, metadata, created_at, updated_at \n             FROM organizational_units WHERE id = $1\",\n        )\n        .bind(id)\n        .fetch_optional(\u0026self.pool)\n        .await?;\n\n        if let Some(row) = row {\n            let unit_type_str: String = row.get(\"type\");\n            let unit_type = match unit_type_str.as_str() {\n                \"company\" =\u003e UnitType::Company,\n                \"organization\" =\u003e UnitType::Organization,\n                \"team\" =\u003e UnitType::Team,\n                \"project\" =\u003e UnitType::Project,\n                _ =\u003e {\n                    return Err(PostgresError::Database(sqlx::Error::Decode(\n                        \"Invalid unit type\".into(),\n                    )));\n                }\n            };\n\n            Ok(Some(OrganizationalUnit {\n                id: row.get(\"id\"),\n                name: row.get(\"name\"),\n                unit_type,\n                parent_id: row.get(\"parent_id\"),\n                tenant_id: row.get::\u003cString, _\u003e(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                metadata: serde_json::from_value(row.get(\"metadata\"))?,\n                created_at: row.get(\"created_at\"),\n                updated_at: row.get(\"updated_at\"),\n            }))\n        } else {\n            Ok(None)\n        }\n    }\n\n    pub async fn get_unit(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cOrganizationalUnit\u003e, PostgresError\u003e {\n        let row = sqlx::query(\n            \"SELECT id, name, type, parent_id, tenant_id, metadata, created_at, updated_at \n             FROM organizational_units WHERE id = $1 AND tenant_id = $2\",\n        )\n        .bind(id)\n        .bind(ctx.tenant_id.as_str())\n        .fetch_optional(\u0026self.pool)\n        .await?;\n\n        if let Some(row) = row {\n            let unit_type_str: String = row.get(\"type\");\n            let unit_type = match unit_type_str.as_str() {\n                \"company\" =\u003e UnitType::Company,\n                \"organization\" =\u003e UnitType::Organization,\n                \"team\" =\u003e UnitType::Team,\n                \"project\" =\u003e UnitType::Project,\n                _ =\u003e {\n                    return Err(PostgresError::Database(sqlx::Error::Decode(\n                        \"Invalid unit type\".into(),\n                    )));\n                }\n            };\n\n            Ok(Some(OrganizationalUnit {\n                id: row.get(\"id\"),\n                name: row.get(\"name\"),\n                unit_type,\n                parent_id: row.get(\"parent_id\"),\n                tenant_id: row.get::\u003cString, _\u003e(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                metadata: serde_json::from_value(row.get(\"metadata\"))?,\n                created_at: row.get(\"created_at\"),\n                updated_at: row.get(\"updated_at\"),\n            }))\n        } else {\n            Ok(None)\n        }\n    }\n\n    pub async fn list_children(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        parent_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, PostgresError\u003e {\n        let rows = sqlx::query(\n            \"SELECT id, name, type, parent_id, tenant_id, metadata, created_at, updated_at \n             FROM organizational_units WHERE parent_id = $1 AND tenant_id = $2\",\n        )\n        .bind(parent_id)\n        .bind(ctx.tenant_id.as_str())\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        let mut units = Vec::new();\n        for row in rows {\n            let unit_type_str: String = row.get(\"type\");\n            let unit_type = match unit_type_str.as_str() {\n                \"company\" =\u003e UnitType::Company,\n                \"organization\" =\u003e UnitType::Organization,\n                \"team\" =\u003e UnitType::Team,\n                \"project\" =\u003e UnitType::Project,\n                _ =\u003e continue,\n            };\n\n            units.push(OrganizationalUnit {\n                id: row.get(\"id\"),\n                name: row.get(\"name\"),\n                unit_type,\n                parent_id: row.get(\"parent_id\"),\n                tenant_id: row.get::\u003cString, _\u003e(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                metadata: serde_json::from_value(row.get(\"metadata\"))?,\n                created_at: row.get(\"created_at\"),\n                updated_at: row.get(\"updated_at\"),\n            });\n        }\n\n        Ok(units)\n    }\n\n    pub async fn get_ancestors(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, PostgresError\u003e {\n        let rows = sqlx::query(\n            \"WITH RECURSIVE ancestors AS (\n                SELECT id, name, type, parent_id, tenant_id, metadata, created_at, updated_at\n                FROM organizational_units\n                WHERE id = $1 AND tenant_id = $2\n                UNION ALL\n                SELECT u.id, u.name, u.type, u.parent_id, u.tenant_id, u.metadata, u.created_at, \\\n             u.updated_at\n                FROM organizational_units u\n                INNER JOIN ancestors a ON u.id = a.parent_id AND u.tenant_id = a.tenant_id\n            )\n            SELECT * FROM ancestors WHERE id != $1\",\n        )\n        .bind(id)\n        .bind(ctx.tenant_id.as_str())\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        let mut units = Vec::new();\n        for row in rows {\n            let unit_type_str: String = row.get(\"type\");\n            let unit_type = match unit_type_str.as_str() {\n                \"company\" =\u003e UnitType::Company,\n                \"organization\" =\u003e UnitType::Organization,\n                \"team\" =\u003e UnitType::Team,\n                \"project\" =\u003e UnitType::Project,\n                _ =\u003e continue,\n            };\n\n            units.push(OrganizationalUnit {\n                id: row.get(\"id\"),\n                name: row.get(\"name\"),\n                unit_type,\n                parent_id: row.get(\"parent_id\"),\n                tenant_id: row.get::\u003cString, _\u003e(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                metadata: serde_json::from_value(row.get(\"metadata\"))?,\n                created_at: row.get(\"created_at\"),\n                updated_at: row.get(\"updated_at\"),\n            });\n        }\n\n        Ok(units)\n    }\n\n    pub async fn get_unit_ancestors(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, PostgresError\u003e {\n        self.get_ancestors(ctx, id).await\n    }\n\n    pub async fn get_unit_descendants(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, PostgresError\u003e {\n        let rows = sqlx::query(\n            \"WITH RECURSIVE descendants AS (\n                SELECT id, name, type, parent_id, tenant_id, metadata, created_at, updated_at\n                FROM organizational_units\n                WHERE id = $1 AND tenant_id = $2\n                UNION ALL\n                SELECT u.id, u.name, u.type, u.parent_id, u.tenant_id, u.metadata, u.created_at, \\\n             u.updated_at\n                FROM organizational_units u\n                INNER JOIN descendants d ON u.parent_id = d.id AND u.tenant_id = d.tenant_id\n            )\n            SELECT * FROM descendants WHERE id != $1\",\n        )\n        .bind(id)\n        .bind(ctx.tenant_id.as_str())\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        let mut units = Vec::new();\n        for row in rows {\n            let unit_type_str: String = row.get(\"type\");\n            let unit_type = match unit_type_str.as_str() {\n                \"company\" =\u003e UnitType::Company,\n                \"organization\" =\u003e UnitType::Organization,\n                \"team\" =\u003e UnitType::Team,\n                \"project\" =\u003e UnitType::Project,\n                _ =\u003e continue,\n            };\n\n            units.push(OrganizationalUnit {\n                id: row.get(\"id\"),\n                name: row.get(\"name\"),\n                unit_type,\n                parent_id: row.get(\"parent_id\"),\n                tenant_id: row.get::\u003cString, _\u003e(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                metadata: serde_json::from_value(row.get(\"metadata\"))?,\n                created_at: row.get(\"created_at\"),\n                updated_at: row.get(\"updated_at\"),\n            });\n        }\n\n        Ok(units)\n    }\n\n    pub async fn update_unit(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        unit: \u0026OrganizationalUnit,\n    ) -\u003e Result\u003c(), PostgresError\u003e {\n        sqlx::query(\n            \"UPDATE organizational_units \n             SET name = $3, type = $4, parent_id = $5, metadata = $6, updated_at = $7\n             WHERE id = $1 AND tenant_id = $2\",\n        )\n        .bind(\u0026unit.id)\n        .bind(ctx.tenant_id.as_str())\n        .bind(\u0026unit.name)\n        .bind(unit.unit_type.to_string().to_lowercase())\n        .bind(\u0026unit.parent_id)\n        .bind(serde_json::to_value(\u0026unit.metadata)?)\n        .bind(unit.updated_at)\n        .execute(\u0026self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    pub async fn delete_unit(\u0026self, ctx: \u0026TenantContext, id: \u0026str) -\u003e Result\u003c(), PostgresError\u003e {\n        sqlx::query(\"DELETE FROM organizational_units WHERE id = $1 AND tenant_id = $2\")\n            .bind(id)\n            .bind(ctx.tenant_id.as_str())\n            .execute(\u0026self.pool)\n            .await?;\n\n        Ok(())\n    }\n\n    pub async fn add_unit_policy(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        unit_id: \u0026str,\n        policy: \u0026mk_core::types::Policy,\n    ) -\u003e Result\u003c(), PostgresError\u003e {\n        let exists: Option\u003c(i64,)\u003e =\n            sqlx::query_as(\"SELECT 1 FROM organizational_units WHERE id = $1 AND tenant_id = $2\")\n                .bind(unit_id)\n                .bind(ctx.tenant_id.as_str())\n                .fetch_optional(\u0026self.pool)\n                .await?;\n\n        if exists.is_none() {\n            return Err(PostgresError::NotFound(unit_id.to_string()));\n        }\n\n        sqlx::query(\n            \"INSERT INTO unit_policies (id, unit_id, policy, created_at, updated_at)\n             VALUES ($1, $2, $3, $4, $5)\n             ON CONFLICT (id) DO UPDATE SET policy = $3, updated_at = $5\",\n        )\n        .bind(\u0026policy.id)\n        .bind(unit_id)\n        .bind(serde_json::to_value(policy)?)\n        .bind(chrono::Utc::now().timestamp())\n        .bind(chrono::Utc::now().timestamp())\n        .execute(\u0026self.pool)\n        .await?;\n        Ok(())\n    }\n\n    pub async fn get_unit_policies(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::Policy\u003e, PostgresError\u003e {\n        let rows = sqlx::query(\n            \"SELECT p.policy \n             FROM unit_policies p\n             JOIN organizational_units u ON p.unit_id = u.id\n             WHERE p.unit_id = $1 AND u.tenant_id = $2\",\n        )\n        .bind(unit_id)\n        .bind(ctx.tenant_id.as_str())\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        let mut policies = Vec::new();\n        for row in rows {\n            let policy: mk_core::types::Policy = serde_json::from_value(row.get(\"policy\"))?;\n            policies.push(policy);\n        }\n        Ok(policies)\n    }\n\n    pub async fn assign_role(\n        \u0026self,\n        user_id: \u0026mk_core::types::UserId,\n        tenant_id: \u0026mk_core::types::TenantId,\n        unit_id: \u0026str,\n        role: mk_core::types::Role,\n    ) -\u003e Result\u003c(), PostgresError\u003e {\n        sqlx::query(\n            \"INSERT INTO user_roles (user_id, tenant_id, unit_id, role, created_at)\n             VALUES ($1, $2, $3, $4, $5)\n             ON CONFLICT (user_id, tenant_id, unit_id, role) DO NOTHING\",\n        )\n        .bind(user_id.as_str())\n        .bind(tenant_id.as_str())\n        .bind(unit_id)\n        .bind(role.to_string().to_lowercase())\n        .bind(chrono::Utc::now().timestamp())\n        .execute(\u0026self.pool)\n        .await?;\n        Ok(())\n    }\n\n    pub async fn remove_role(\n        \u0026self,\n        user_id: \u0026mk_core::types::UserId,\n        tenant_id: \u0026mk_core::types::TenantId,\n        unit_id: \u0026str,\n        role: mk_core::types::Role,\n    ) -\u003e Result\u003c(), PostgresError\u003e {\n        sqlx::query(\n            \"DELETE FROM user_roles \n             WHERE user_id = $1 AND tenant_id = $2 AND unit_id = $3 AND role = $4\",\n        )\n        .bind(user_id.as_str())\n        .bind(tenant_id.as_str())\n        .bind(unit_id)\n        .bind(role.to_string().to_lowercase())\n        .execute(\u0026self.pool)\n        .await?;\n        Ok(())\n    }\n\n    pub async fn get_user_roles(\n        \u0026self,\n        user_id: \u0026mk_core::types::UserId,\n        tenant_id: \u0026mk_core::types::TenantId,\n    ) -\u003e Result\u003cVec\u003c(String, mk_core::types::Role)\u003e, PostgresError\u003e {\n        let rows = sqlx::query(\n            \"SELECT unit_id, role FROM user_roles WHERE user_id = $1 AND tenant_id = $2\",\n        )\n        .bind(user_id.as_str())\n        .bind(tenant_id.as_str())\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        let mut roles = Vec::new();\n        for row in rows {\n            let unit_id: String = row.get(\"unit_id\");\n            let role_str: String = row.get(\"role\");\n            if let Ok(role) = role_str.parse() {\n                roles.push((unit_id, role));\n            }\n        }\n        Ok(roles)\n    }\n    pub async fn log_event(\n        \u0026self,\n        event: \u0026mk_core::types::GovernanceEvent,\n    ) -\u003e Result\u003c(), PostgresError\u003e {\n        let (event_type, tenant_id, timestamp) = match event {\n            mk_core::types::GovernanceEvent::UnitCreated {\n                unit_id: _,\n                unit_type: _,\n                tenant_id,\n                parent_id: _,\n                timestamp,\n            } =\u003e (\"unit_created\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::UnitUpdated {\n                unit_id: _,\n                tenant_id,\n                timestamp,\n            } =\u003e (\"unit_updated\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::UnitDeleted {\n                unit_id: _,\n                tenant_id,\n                timestamp,\n            } =\u003e (\"unit_deleted\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::RoleAssigned {\n                user_id: _,\n                unit_id: _,\n                role: _,\n                tenant_id,\n                timestamp,\n            } =\u003e (\"role_assigned\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::RoleRemoved {\n                user_id: _,\n                unit_id: _,\n                role: _,\n                tenant_id,\n                timestamp,\n            } =\u003e (\"role_removed\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::PolicyUpdated {\n                policy_id: _,\n                layer: _,\n                tenant_id,\n                timestamp,\n            } =\u003e (\"policy_updated\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::PolicyDeleted {\n                policy_id: _,\n                tenant_id,\n                timestamp,\n            } =\u003e (\"policy_deleted\", tenant_id, *timestamp),\n            mk_core::types::GovernanceEvent::DriftDetected {\n                project_id: _,\n                tenant_id,\n                drift_score: _,\n                timestamp,\n            } =\u003e (\"drift_detected\", tenant_id, *timestamp),\n        };\n\n        sqlx::query(\n            \"INSERT INTO governance_events (event_type, tenant_id, payload, timestamp)\n             VALUES ($1, $2, $3, $4)\",\n        )\n        .bind(event_type)\n        .bind(tenant_id.as_str())\n        .bind(serde_json::to_value(event)?)\n        .bind(timestamp)\n        .execute(\u0026self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    pub async fn get_governance_events_internal(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        since_timestamp: i64,\n        limit: usize,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e, PostgresError\u003e {\n        let rows = sqlx::query(\n            \"SELECT payload FROM governance_events \n             WHERE tenant_id = $1 AND timestamp \u003e $2 \n             ORDER BY timestamp ASC LIMIT $3\",\n        )\n        .bind(ctx.tenant_id.as_str())\n        .bind(since_timestamp)\n        .bind(limit as i64)\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        let mut events = Vec::new();\n        for row in rows {\n            use sqlx::Row;\n            let payload: serde_json::Value = row.get(\"payload\");\n            let event: mk_core::types::GovernanceEvent = serde_json::from_value(payload)?;\n            events.push(event);\n        }\n        Ok(events)\n    }\n}\n\n#[async_trait]\nimpl mk_core::traits::EventPublisher for PostgresBackend {\n    type Error = PostgresError;\n\n    async fn publish(\u0026self, event: mk_core::types::GovernanceEvent) -\u003e Result\u003c(), Self::Error\u003e {\n        self.log_event(\u0026event).await\n    }\n\n    async fn subscribe(\n        \u0026self,\n        _channels: \u0026[\u0026str],\n    ) -\u003e Result\u003ctokio::sync::mpsc::Receiver\u003cmk_core::types::GovernanceEvent\u003e, Self::Error\u003e {\n        Err(PostgresError::Database(sqlx::Error::Decode(\n            \"Subscribe not implemented for Postgres backend\".into(),\n        )))\n    }\n}\n\n#[async_trait]\nimpl StorageBackend for PostgresBackend {\n    type Error = PostgresError;\n\n    async fn store(\u0026self, ctx: TenantContext, key: \u0026str, value: \u0026[u8]) -\u003e Result\u003c(), Self::Error\u003e {\n        sqlx::query(\n            \"INSERT INTO sync_state (id, tenant_id, data, updated_at)\n             VALUES ($1, $2, $3, $4)\n             ON CONFLICT (id, tenant_id) DO UPDATE SET data = $3, updated_at = $4\",\n        )\n        .bind(key)\n        .bind(ctx.tenant_id.as_str())\n        .bind(serde_json::from_slice::\u003cserde_json::Value\u003e(value).unwrap_or_default())\n        .bind(chrono::Utc::now().timestamp())\n        .execute(\u0026self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    async fn retrieve(\n        \u0026self,\n        ctx: TenantContext,\n        key: \u0026str,\n    ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e {\n        let row: Option\u003c(serde_json::Value,)\u003e =\n            sqlx::query_as(\"SELECT data FROM sync_state WHERE id = $1 AND tenant_id = $2\")\n                .bind(key)\n                .bind(ctx.tenant_id.as_str())\n                .fetch_optional(\u0026self.pool)\n                .await?;\n\n        Ok(row.and_then(|(v,)| serde_json::to_vec(\u0026v).ok()))\n    }\n\n    async fn delete(\u0026self, ctx: TenantContext, key: \u0026str) -\u003e Result\u003c(), Self::Error\u003e {\n        sqlx::query(\"DELETE FROM sync_state WHERE id = $1 AND tenant_id = $2\")\n            .bind(key)\n            .bind(ctx.tenant_id.as_str())\n            .execute(\u0026self.pool)\n            .await?;\n\n        Ok(())\n    }\n\n    async fn exists(\u0026self, ctx: TenantContext, key: \u0026str) -\u003e Result\u003cbool, Self::Error\u003e {\n        let row: Option\u003c(i32,)\u003e =\n            sqlx::query_as(\"SELECT 1 FROM sync_state WHERE id = $1 AND tenant_id = $2\")\n                .bind(key)\n                .bind(ctx.tenant_id.as_str())\n                .fetch_optional(\u0026self.pool)\n                .await?;\n\n        Ok(row.is_some())\n    }\n\n    async fn get_ancestors(\n        \u0026self,\n        ctx: TenantContext,\n        unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, Self::Error\u003e {\n        self.get_unit_ancestors(\u0026ctx, unit_id).await\n    }\n\n    async fn get_descendants(\n        \u0026self,\n        ctx: TenantContext,\n        unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, Self::Error\u003e {\n        self.get_unit_descendants(\u0026ctx, unit_id).await\n    }\n\n    async fn get_unit_policies(\n        \u0026self,\n        ctx: TenantContext,\n        unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::Policy\u003e, Self::Error\u003e {\n        self.get_unit_policies(\u0026ctx, unit_id).await\n    }\n\n    async fn create_unit(\u0026self, unit: \u0026OrganizationalUnit) -\u003e Result\u003c(), Self::Error\u003e {\n        self.create_unit(unit).await\n    }\n\n    async fn add_unit_policy(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        unit_id: \u0026str,\n        policy: \u0026mk_core::types::Policy,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        self.add_unit_policy(ctx, unit_id, policy).await\n    }\n\n    async fn assign_role(\n        \u0026self,\n        user_id: \u0026mk_core::types::UserId,\n        tenant_id: \u0026mk_core::types::TenantId,\n        unit_id: \u0026str,\n        role: mk_core::types::Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        self.assign_role(user_id, tenant_id, unit_id, role).await\n    }\n\n    async fn remove_role(\n        \u0026self,\n        user_id: \u0026mk_core::types::UserId,\n        tenant_id: \u0026mk_core::types::TenantId,\n        unit_id: \u0026str,\n        role: mk_core::types::Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        self.remove_role(user_id, tenant_id, unit_id, role).await\n    }\n\n    async fn store_drift_result(\n        \u0026self,\n        result: mk_core::types::DriftResult,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        sqlx::query(\n            \"INSERT INTO drift_results (project_id, tenant_id, drift_score, violations, timestamp)\n             VALUES ($1, $2, $3, $4, $5)\",\n        )\n        .bind(\u0026result.project_id)\n        .bind(result.tenant_id.as_str())\n        .bind(result.drift_score)\n        .bind(serde_json::to_value(\u0026result.violations)?)\n        .bind(result.timestamp)\n        .execute(\u0026self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    async fn get_latest_drift_result(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        project_id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cmk_core::types::DriftResult\u003e, Self::Error\u003e {\n        let row = sqlx::query(\n            \"SELECT project_id, tenant_id, drift_score, violations, timestamp \n             FROM drift_results \n             WHERE project_id = $1 AND tenant_id = $2 \n             ORDER BY timestamp DESC LIMIT 1\",\n        )\n        .bind(project_id)\n        .bind(ctx.tenant_id.as_str())\n        .fetch_optional(\u0026self.pool)\n        .await?;\n\n        if let Some(row) = row {\n            Ok(Some(mk_core::types::DriftResult {\n                project_id: row.get(\"project_id\"),\n                tenant_id: row.get::\u003cString, _\u003e(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                drift_score: row.get(\"drift_score\"),\n                violations: serde_json::from_value(row.get(\"violations\"))?,\n                timestamp: row.get(\"timestamp\"),\n            }))\n        } else {\n            Ok(None)\n        }\n    }\n\n    async fn record_job_status(\n        \u0026self,\n        job_name: \u0026str,\n        tenant_id: \u0026str,\n        status: \u0026str,\n        message: Option\u003c\u0026str\u003e,\n        started_at: i64,\n        finished_at: Option\u003ci64\u003e,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        let duration_ms = finished_at.map(|f| (f - started_at) * 1000);\n\n        sqlx::query(\n            \"INSERT INTO job_status (job_name, tenant_id, status, message, started_at, \\\n             finished_at, duration_ms)\n             VALUES ($1, $2, $3, $4, $5, $6, $7)\",\n        )\n        .bind(job_name)\n        .bind(tenant_id)\n        .bind(status)\n        .bind(message)\n        .bind(started_at)\n        .bind(finished_at)\n        .bind(duration_ms)\n        .execute(\u0026self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    async fn get_governance_events(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        since_timestamp: i64,\n        limit: usize,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e, Self::Error\u003e {\n        self.get_governance_events_internal(ctx, since_timestamp, limit)\n            .await\n    }\n\n    async fn list_all_units(\u0026self) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        let rows = sqlx::query(\n            \"SELECT id, name, type, parent_id, tenant_id, metadata, created_at, updated_at \n             FROM organizational_units\",\n        )\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        let mut units = Vec::new();\n        for row in rows {\n            let unit_type_str: String = row.get(\"type\");\n            let unit_type = match unit_type_str.as_str() {\n                \"company\" =\u003e UnitType::Company,\n                \"organization\" =\u003e UnitType::Organization,\n                \"team\" =\u003e UnitType::Team,\n                \"project\" =\u003e UnitType::Project,\n                _ =\u003e continue,\n            };\n\n            units.push(mk_core::types::OrganizationalUnit {\n                id: row.get(\"id\"),\n                name: row.get(\"name\"),\n                unit_type,\n                parent_id: row.get(\"parent_id\"),\n                tenant_id: row.get::\u003cString, _\u003e(\"tenant_id\").parse().map_err(|e| {\n                    PostgresError::Database(sqlx::Error::Decode(\n                        format!(\"Invalid tenant_id: {}\", e).into(),\n                    ))\n                })?,\n                metadata: serde_json::from_value(row.get(\"metadata\"))?,\n                created_at: row.get(\"created_at\"),\n                updated_at: row.get(\"updated_at\"),\n            });\n        }\n\n        Ok(units)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use chrono::Datelike;\n    use serde_json::json;\n\n    // Test PostgresError display\n    #[test]\n    fn test_postgres_error_display() {\n        let error = PostgresError::Database(sqlx::Error::Configuration(\n            \"Invalid connection string\".into(),\n        ));\n\n        assert!(error.to_string().contains(\"Database error\"));\n        assert!(error.to_string().contains(\"Invalid connection string\"));\n    }\n\n    // Test error conversion from sqlx::Error\n    #[test]\n    fn test_postgres_error_from_sqlx() {\n        let sqlx_error = sqlx::Error::Configuration(\"test\".into());\n        let pg_error: PostgresError = sqlx_error.into();\n\n        match pg_error {\n            PostgresError::Database(_) =\u003e (),\n            PostgresError::Serialization(_) =\u003e (),\n            PostgresError::NotFound(_) =\u003e (),\n        }\n    }\n\n    // Test PostgresBackend struct (compile-time checks)\n    #[test]\n    fn test_postgres_backend_struct() {\n        // Verify the struct has expected fields\n        struct TestBackend {\n            _pool: Pool\u003cPostgres\u003e,\n        }\n\n        // This is a compile-time test - if it compiles, PostgresBackend has the right\n        // structure We can't instantiate it without a real database connection\n        let _backend_type = std::any::type_name::\u003cPostgresBackend\u003e();\n        assert_eq!(_backend_type, \"storage::postgres::PostgresBackend\");\n    }\n\n    // Test StorageBackend trait implementation\n    #[test]\n    fn test_storage_backend_trait_implementation() {\n        use mk_core::traits::StorageBackend;\n\n        // Compile-time check that PostgresBackend implements StorageBackend\n        fn assert_implements_storage_backend\u003cT: StorageBackend\u003e() {}\n\n        assert_implements_storage_backend::\u003cPostgresBackend\u003e();\n    }\n\n    // Test JSON serialization patterns used in the code\n    #[test]\n    fn test_json_serialization_patterns() {\n        // Test the serialization pattern used in store() method\n        let value = json!({\"key\": \"value\", \"number\": 42});\n        let bytes = serde_json::to_vec(\u0026value).unwrap();\n\n        // Test deserialization pattern used in retrieve() method\n        let deserialized: serde_json::Value = serde_json::from_slice(\u0026bytes).unwrap();\n        assert_eq!(deserialized[\"key\"], \"value\");\n        assert_eq!(deserialized[\"number\"], 42);\n\n        // Test default fallback used in store()\n        let invalid_bytes = b\"not json\";\n        let default_value =\n            serde_json::from_slice::\u003cserde_json::Value\u003e(invalid_bytes).unwrap_or_default();\n        assert!(default_value.is_null() || default_value == json!({}));\n    }\n\n    // Test timestamp generation pattern\n    #[test]\n    fn test_timestamp_generation() {\n        use chrono::Utc;\n\n        let timestamp = Utc::now().timestamp();\n        assert!(timestamp \u003e 0); // Should be positive (after 1970)\n\n        // Verify it's a reasonable timestamp (not in distant future)\n        let current_year = Utc::now().year();\n        let timestamp_year = chrono::DateTime::from_timestamp(timestamp, 0)\n            .map(|dt| dt.year())\n            .unwrap_or(1970);\n\n        // Should be within 10 years of current year\n        assert!((timestamp_year - current_year).abs() \u003c= 10);\n    }\n\n    // Test SQL query patterns for correctness\n    #[test]\n    fn test_sql_query_patterns() {\n        // Verify the SQL queries are syntactically correct\n        let create_table_query = \"CREATE TABLE IF NOT EXISTS sync_state (\n                id TEXT PRIMARY KEY,\n                data JSONB NOT NULL,\n                updated_at BIGINT NOT NULL\n            )\";\n\n        let insert_query = \"INSERT INTO sync_state (id, data, updated_at)\n             VALUES ($1, $2, $3)\n             ON CONFLICT (id) DO UPDATE SET data = $2, updated_at = $3\";\n\n        let select_query = \"SELECT data FROM sync_state WHERE id = $1\";\n        let delete_query = \"DELETE FROM sync_state WHERE id = $1\";\n        let exists_query = \"SELECT 1 FROM sync_state WHERE id = $1\";\n\n        // Just verify they're non-empty strings\n        assert!(!create_table_query.is_empty());\n        assert!(!insert_query.is_empty());\n        assert!(!select_query.is_empty());\n        assert!(!delete_query.is_empty());\n        assert!(!exists_query.is_empty());\n\n        // Verify they contain expected keywords\n        assert!(create_table_query.contains(\"CREATE TABLE\"));\n        assert!(insert_query.contains(\"INSERT INTO\"));\n        assert!(select_query.contains(\"SELECT\"));\n        assert!(delete_query.contains(\"DELETE\"));\n        assert!(exists_query.contains(\"SELECT 1\"));\n    }\n}\n","traces":[{"line":22,"address":[],"length":0,"stats":{"Line":1}},{"line":23,"address":[],"length":0,"stats":{"Line":1}},{"line":26,"address":[],"length":0,"stats":{"Line":50}},{"line":27,"address":[],"length":0,"stats":{"Line":75}},{"line":28,"address":[],"length":0,"stats":{"Line":24}},{"line":31,"address":[],"length":0,"stats":{"Line":22}},{"line":33,"address":[],"length":0,"stats":{"Line":22}},{"line":34,"address":[],"length":0,"stats":{"Line":22}},{"line":35,"address":[],"length":0,"stats":{"Line":11}},{"line":46,"address":[],"length":0,"stats":{"Line":22}},{"line":47,"address":[],"length":0,"stats":{"Line":11}},{"line":49,"address":[],"length":0,"stats":{"Line":22}},{"line":50,"address":[],"length":0,"stats":{"Line":22}},{"line":51,"address":[],"length":0,"stats":{"Line":11}},{"line":65,"address":[],"length":0,"stats":{"Line":22}},{"line":66,"address":[],"length":0,"stats":{"Line":11}},{"line":78,"address":[],"length":0,"stats":{"Line":22}},{"line":79,"address":[],"length":0,"stats":{"Line":11}},{"line":90,"address":[],"length":0,"stats":{"Line":22}},{"line":91,"address":[],"length":0,"stats":{"Line":11}},{"line":102,"address":[],"length":0,"stats":{"Line":22}},{"line":103,"address":[],"length":0,"stats":{"Line":11}},{"line":115,"address":[],"length":0,"stats":{"Line":22}},{"line":116,"address":[],"length":0,"stats":{"Line":11}},{"line":130,"address":[],"length":0,"stats":{"Line":22}},{"line":131,"address":[],"length":0,"stats":{"Line":11}},{"line":133,"address":[],"length":0,"stats":{"Line":11}},{"line":136,"address":[],"length":0,"stats":{"Line":30}},{"line":137,"address":[],"length":0,"stats":{"Line":26}},{"line":138,"address":[],"length":0,"stats":{"Line":33}},{"line":139,"address":[],"length":0,"stats":{"Line":22}},{"line":140,"address":[],"length":0,"stats":{"Line":11}},{"line":141,"address":[],"length":0,"stats":{"Line":11}},{"line":143,"address":[],"length":0,"stats":{"Line":22}},{"line":144,"address":[],"length":0,"stats":{"Line":3}},{"line":145,"address":[],"length":0,"stats":{"Line":3}},{"line":146,"address":[],"length":0,"stats":{"Line":3}},{"line":148,"address":[],"length":0,"stats":{"Line":2}},{"line":149,"address":[],"length":0,"stats":{"Line":4}},{"line":150,"address":[],"length":0,"stats":{"Line":2}},{"line":151,"address":[],"length":0,"stats":{"Line":2}},{"line":153,"address":[],"length":0,"stats":{"Line":2}},{"line":157,"address":[],"length":0,"stats":{"Line":4}},{"line":158,"address":[],"length":0,"stats":{"Line":1}},{"line":159,"address":[],"length":0,"stats":{"Line":1}},{"line":168,"address":[],"length":0,"stats":{"Line":24}},{"line":169,"address":[],"length":0,"stats":{"Line":24}},{"line":170,"address":[],"length":0,"stats":{"Line":24}},{"line":171,"address":[],"length":0,"stats":{"Line":24}},{"line":172,"address":[],"length":0,"stats":{"Line":36}},{"line":173,"address":[],"length":0,"stats":{"Line":36}},{"line":174,"address":[],"length":0,"stats":{"Line":24}},{"line":175,"address":[],"length":0,"stats":{"Line":24}},{"line":176,"address":[],"length":0,"stats":{"Line":24}},{"line":177,"address":[],"length":0,"stats":{"Line":12}},{"line":179,"address":[],"length":0,"stats":{"Line":12}},{"line":182,"address":[],"length":0,"stats":{"Line":22}},{"line":187,"address":[],"length":0,"stats":{"Line":33}},{"line":188,"address":[],"length":0,"stats":{"Line":22}},{"line":189,"address":[],"length":0,"stats":{"Line":11}},{"line":191,"address":[],"length":0,"stats":{"Line":22}},{"line":192,"address":[],"length":0,"stats":{"Line":44}},{"line":193,"address":[],"length":0,"stats":{"Line":22}},{"line":194,"address":[],"length":0,"stats":{"Line":15}},{"line":195,"address":[],"length":0,"stats":{"Line":11}},{"line":196,"address":[],"length":0,"stats":{"Line":6}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":22}},{"line":207,"address":[],"length":0,"stats":{"Line":22}},{"line":208,"address":[],"length":0,"stats":{"Line":11}},{"line":209,"address":[],"length":0,"stats":{"Line":22}},{"line":210,"address":[],"length":0,"stats":{"Line":22}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":33}},{"line":216,"address":[],"length":0,"stats":{"Line":22}},{"line":217,"address":[],"length":0,"stats":{"Line":22}},{"line":220,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":235,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":240,"address":[],"length":0,"stats":{"Line":0}},{"line":241,"address":[],"length":0,"stats":{"Line":0}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":0}},{"line":254,"address":[],"length":0,"stats":{"Line":0}},{"line":255,"address":[],"length":0,"stats":{"Line":0}},{"line":256,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":264,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":298,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":1}},{"line":333,"address":[],"length":0,"stats":{"Line":3}},{"line":334,"address":[],"length":0,"stats":{"Line":4}},{"line":335,"address":[],"length":0,"stats":{"Line":2}},{"line":336,"address":[],"length":0,"stats":{"Line":1}},{"line":338,"address":[],"length":0,"stats":{"Line":2}},{"line":339,"address":[],"length":0,"stats":{"Line":7}},{"line":340,"address":[],"length":0,"stats":{"Line":12}},{"line":341,"address":[],"length":0,"stats":{"Line":6}},{"line":342,"address":[],"length":0,"stats":{"Line":4}},{"line":343,"address":[],"length":0,"stats":{"Line":3}},{"line":344,"address":[],"length":0,"stats":{"Line":2}},{"line":345,"address":[],"length":0,"stats":{"Line":0}},{"line":346,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":6}},{"line":350,"address":[],"length":0,"stats":{"Line":6}},{"line":351,"address":[],"length":0,"stats":{"Line":6}},{"line":352,"address":[],"length":0,"stats":{"Line":3}},{"line":353,"address":[],"length":0,"stats":{"Line":6}},{"line":354,"address":[],"length":0,"stats":{"Line":6}},{"line":355,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":0}},{"line":359,"address":[],"length":0,"stats":{"Line":9}},{"line":360,"address":[],"length":0,"stats":{"Line":6}},{"line":361,"address":[],"length":0,"stats":{"Line":6}},{"line":365,"address":[],"length":0,"stats":{"Line":1}},{"line":368,"address":[],"length":0,"stats":{"Line":1}},{"line":373,"address":[],"length":0,"stats":{"Line":4}},{"line":376,"address":[],"length":0,"stats":{"Line":2}},{"line":394,"address":[],"length":0,"stats":{"Line":6}},{"line":395,"address":[],"length":0,"stats":{"Line":8}},{"line":396,"address":[],"length":0,"stats":{"Line":4}},{"line":397,"address":[],"length":0,"stats":{"Line":2}},{"line":399,"address":[],"length":0,"stats":{"Line":4}},{"line":400,"address":[],"length":0,"stats":{"Line":12}},{"line":401,"address":[],"length":0,"stats":{"Line":20}},{"line":402,"address":[],"length":0,"stats":{"Line":10}},{"line":403,"address":[],"length":0,"stats":{"Line":5}},{"line":404,"address":[],"length":0,"stats":{"Line":6}},{"line":405,"address":[],"length":0,"stats":{"Line":6}},{"line":406,"address":[],"length":0,"stats":{"Line":4}},{"line":407,"address":[],"length":0,"stats":{"Line":0}},{"line":410,"address":[],"length":0,"stats":{"Line":10}},{"line":411,"address":[],"length":0,"stats":{"Line":10}},{"line":412,"address":[],"length":0,"stats":{"Line":10}},{"line":413,"address":[],"length":0,"stats":{"Line":5}},{"line":414,"address":[],"length":0,"stats":{"Line":10}},{"line":415,"address":[],"length":0,"stats":{"Line":10}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":417,"address":[],"length":0,"stats":{"Line":0}},{"line":420,"address":[],"length":0,"stats":{"Line":15}},{"line":421,"address":[],"length":0,"stats":{"Line":10}},{"line":422,"address":[],"length":0,"stats":{"Line":10}},{"line":426,"address":[],"length":0,"stats":{"Line":2}},{"line":429,"address":[],"length":0,"stats":{"Line":0}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":441,"address":[],"length":0,"stats":{"Line":0}},{"line":442,"address":[],"length":0,"stats":{"Line":0}},{"line":443,"address":[],"length":0,"stats":{"Line":0}},{"line":444,"address":[],"length":0,"stats":{"Line":0}},{"line":445,"address":[],"length":0,"stats":{"Line":0}},{"line":446,"address":[],"length":0,"stats":{"Line":0}},{"line":447,"address":[],"length":0,"stats":{"Line":0}},{"line":449,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":453,"address":[],"length":0,"stats":{"Line":0}},{"line":454,"address":[],"length":0,"stats":{"Line":0}},{"line":455,"address":[],"length":0,"stats":{"Line":0}},{"line":456,"address":[],"length":0,"stats":{"Line":0}},{"line":457,"address":[],"length":0,"stats":{"Line":0}},{"line":459,"address":[],"length":0,"stats":{"Line":0}},{"line":462,"address":[],"length":0,"stats":{"Line":0}},{"line":468,"address":[],"length":0,"stats":{"Line":0}},{"line":469,"address":[],"length":0,"stats":{"Line":0}},{"line":470,"address":[],"length":0,"stats":{"Line":0}},{"line":471,"address":[],"length":0,"stats":{"Line":0}},{"line":472,"address":[],"length":0,"stats":{"Line":0}},{"line":473,"address":[],"length":0,"stats":{"Line":0}},{"line":475,"address":[],"length":0,"stats":{"Line":0}},{"line":476,"address":[],"length":0,"stats":{"Line":0}},{"line":484,"address":[],"length":0,"stats":{"Line":0}},{"line":485,"address":[],"length":0,"stats":{"Line":0}},{"line":486,"address":[],"length":0,"stats":{"Line":0}},{"line":487,"address":[],"length":0,"stats":{"Line":0}},{"line":488,"address":[],"length":0,"stats":{"Line":0}},{"line":489,"address":[],"length":0,"stats":{"Line":0}},{"line":490,"address":[],"length":0,"stats":{"Line":0}},{"line":491,"address":[],"length":0,"stats":{"Line":0}},{"line":494,"address":[],"length":0,"stats":{"Line":0}},{"line":505,"address":[],"length":0,"stats":{"Line":0}},{"line":506,"address":[],"length":0,"stats":{"Line":0}},{"line":507,"address":[],"length":0,"stats":{"Line":0}},{"line":508,"address":[],"length":0,"stats":{"Line":0}},{"line":510,"address":[],"length":0,"stats":{"Line":0}},{"line":511,"address":[],"length":0,"stats":{"Line":0}},{"line":512,"address":[],"length":0,"stats":{"Line":0}},{"line":513,"address":[],"length":0,"stats":{"Line":0}},{"line":515,"address":[],"length":0,"stats":{"Line":0}},{"line":518,"address":[],"length":0,"stats":{"Line":0}},{"line":530,"address":[],"length":0,"stats":{"Line":0}},{"line":531,"address":[],"length":0,"stats":{"Line":0}},{"line":532,"address":[],"length":0,"stats":{"Line":0}},{"line":533,"address":[],"length":0,"stats":{"Line":0}},{"line":534,"address":[],"length":0,"stats":{"Line":0}},{"line":535,"address":[],"length":0,"stats":{"Line":0}},{"line":536,"address":[],"length":0,"stats":{"Line":0}},{"line":537,"address":[],"length":0,"stats":{"Line":0}},{"line":540,"address":[],"length":0,"stats":{"Line":0}},{"line":551,"address":[],"length":0,"stats":{"Line":0}},{"line":552,"address":[],"length":0,"stats":{"Line":0}},{"line":553,"address":[],"length":0,"stats":{"Line":0}},{"line":554,"address":[],"length":0,"stats":{"Line":0}},{"line":555,"address":[],"length":0,"stats":{"Line":0}},{"line":556,"address":[],"length":0,"stats":{"Line":0}},{"line":557,"address":[],"length":0,"stats":{"Line":0}},{"line":560,"address":[],"length":0,"stats":{"Line":0}},{"line":568,"address":[],"length":0,"stats":{"Line":0}},{"line":569,"address":[],"length":0,"stats":{"Line":0}},{"line":570,"address":[],"length":0,"stats":{"Line":0}},{"line":571,"address":[],"length":0,"stats":{"Line":0}},{"line":573,"address":[],"length":0,"stats":{"Line":0}},{"line":574,"address":[],"length":0,"stats":{"Line":0}},{"line":575,"address":[],"length":0,"stats":{"Line":0}},{"line":576,"address":[],"length":0,"stats":{"Line":0}},{"line":577,"address":[],"length":0,"stats":{"Line":0}},{"line":578,"address":[],"length":0,"stats":{"Line":0}},{"line":581,"address":[],"length":0,"stats":{"Line":0}},{"line":583,"address":[],"length":0,"stats":{"Line":0}},{"line":587,"address":[],"length":0,"stats":{"Line":0}},{"line":591,"address":[],"length":0,"stats":{"Line":0}},{"line":593,"address":[],"length":0,"stats":{"Line":0}},{"line":594,"address":[],"length":0,"stats":{"Line":0}},{"line":597,"address":[],"length":0,"stats":{"Line":0}},{"line":598,"address":[],"length":0,"stats":{"Line":0}},{"line":599,"address":[],"length":0,"stats":{"Line":0}},{"line":602,"address":[],"length":0,"stats":{"Line":0}},{"line":603,"address":[],"length":0,"stats":{"Line":0}},{"line":604,"address":[],"length":0,"stats":{"Line":0}},{"line":609,"address":[],"length":0,"stats":{"Line":0}},{"line":610,"address":[],"length":0,"stats":{"Line":0}},{"line":611,"address":[],"length":0,"stats":{"Line":0}},{"line":616,"address":[],"length":0,"stats":{"Line":0}},{"line":617,"address":[],"length":0,"stats":{"Line":0}},{"line":618,"address":[],"length":0,"stats":{"Line":0}},{"line":622,"address":[],"length":0,"stats":{"Line":0}},{"line":623,"address":[],"length":0,"stats":{"Line":0}},{"line":624,"address":[],"length":0,"stats":{"Line":0}},{"line":627,"address":[],"length":0,"stats":{"Line":0}},{"line":628,"address":[],"length":0,"stats":{"Line":0}},{"line":629,"address":[],"length":0,"stats":{"Line":0}},{"line":632,"address":[],"length":0,"stats":{"Line":0}},{"line":634,"address":[],"length":0,"stats":{"Line":0}},{"line":635,"address":[],"length":0,"stats":{"Line":0}},{"line":642,"address":[],"length":0,"stats":{"Line":0}},{"line":643,"address":[],"length":0,"stats":{"Line":0}},{"line":644,"address":[],"length":0,"stats":{"Line":0}},{"line":645,"address":[],"length":0,"stats":{"Line":0}},{"line":646,"address":[],"length":0,"stats":{"Line":0}},{"line":647,"address":[],"length":0,"stats":{"Line":0}},{"line":649,"address":[],"length":0,"stats":{"Line":0}},{"line":652,"address":[],"length":0,"stats":{"Line":0}},{"line":663,"address":[],"length":0,"stats":{"Line":0}},{"line":664,"address":[],"length":0,"stats":{"Line":0}},{"line":665,"address":[],"length":0,"stats":{"Line":0}},{"line":666,"address":[],"length":0,"stats":{"Line":0}},{"line":667,"address":[],"length":0,"stats":{"Line":0}},{"line":669,"address":[],"length":0,"stats":{"Line":0}},{"line":670,"address":[],"length":0,"stats":{"Line":0}},{"line":672,"address":[],"length":0,"stats":{"Line":0}},{"line":673,"address":[],"length":0,"stats":{"Line":0}},{"line":674,"address":[],"length":0,"stats":{"Line":0}},{"line":676,"address":[],"length":0,"stats":{"Line":0}},{"line":684,"address":[],"length":0,"stats":{"Line":0}},{"line":702,"address":[],"length":0,"stats":{"Line":8}},{"line":730,"address":[],"length":0,"stats":{"Line":15}},{"line":733,"address":[],"length":0,"stats":{"Line":2}},{"line":743,"address":[],"length":0,"stats":{"Line":6}},{"line":778,"address":[],"length":0,"stats":{"Line":0}},{"line":849,"address":[],"length":0,"stats":{"Line":0}},{"line":850,"address":[],"length":0,"stats":{"Line":0}},{"line":851,"address":[],"length":0,"stats":{"Line":0}},{"line":872,"address":[],"length":0,"stats":{"Line":1}},{"line":902,"address":[],"length":0,"stats":{"Line":0}},{"line":926,"address":[],"length":0,"stats":{"Line":0}},{"line":927,"address":[],"length":0,"stats":{"Line":0}},{"line":928,"address":[],"length":0,"stats":{"Line":0}}],"covered":126,"coverable":318},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","src","redis.rs"],"content":"use async_trait::async_trait;\nuse errors::StorageError;\nuse mk_core::traits::EventPublisher;\nuse mk_core::types::GovernanceEvent;\nuse redis::AsyncCommands;\nuse std::sync::Arc;\n\npub struct RedisStorage {\n    client: Arc\u003credis::Client\u003e,\n    connection_manager: redis::aio::ConnectionManager\n}\n\nimpl RedisStorage {\n    pub async fn new(connection_string: \u0026str) -\u003e Result\u003cSelf, StorageError\u003e {\n        let client =\n            redis::Client::open(connection_string).map_err(|e| StorageError::ConnectionError {\n                backend: \"Redis\".to_string(),\n                reason: e.to_string()\n            })?;\n\n        let connection_manager =\n            client\n                .get_connection_manager()\n                .await\n                .map_err(|e| StorageError::ConnectionError {\n                    backend: \"Redis\".to_string(),\n                    reason: e.to_string()\n                })?;\n\n        Ok(Self {\n            client: Arc::new(client),\n            connection_manager\n        })\n    }\n\n    pub async fn get(\u0026self, key: \u0026str) -\u003e Result\u003cOption\u003cString\u003e, StorageError\u003e {\n        let mut conn = self.connection_manager.clone();\n        conn.get(key).await.map_err(|e| StorageError::QueryError {\n            backend: \"Redis\".to_string(),\n            reason: e.to_string()\n        })\n    }\n\n    pub async fn set(\n        \u0026self,\n        key: \u0026str,\n        value: \u0026str,\n        ttl_seconds: Option\u003cusize\u003e\n    ) -\u003e Result\u003c(), StorageError\u003e {\n        let mut conn = self.connection_manager.clone();\n        if let Some(ttl) = ttl_seconds {\n            conn.set_ex(key, value, ttl as u64)\n                .await\n                .map_err(|e| StorageError::QueryError {\n                    backend: \"Redis\".to_string(),\n                    reason: e.to_string()\n                })\n        } else {\n            conn.set(key, value)\n                .await\n                .map_err(|e| StorageError::QueryError {\n                    backend: \"Redis\".to_string(),\n                    reason: e.to_string()\n                })\n        }\n    }\n\n    pub async fn delete_key(\u0026self, key: \u0026str) -\u003e Result\u003c(), StorageError\u003e {\n        let mut conn = self.connection_manager.clone();\n        conn.del(key).await.map_err(|e| StorageError::QueryError {\n            backend: \"Redis\".to_string(),\n            reason: e.to_string()\n        })\n    }\n\n    pub async fn exists_key(\u0026self, key: \u0026str) -\u003e Result\u003cbool, StorageError\u003e {\n        let mut conn = self.connection_manager.clone();\n        conn.exists(key)\n            .await\n            .map_err(|e| StorageError::QueryError {\n                backend: \"Redis\".to_string(),\n                reason: e.to_string()\n            })\n    }\n    pub fn scoped_key(\u0026self, ctx: \u0026mk_core::types::TenantContext, key: \u0026str) -\u003e String {\n        format!(\"{}:{}\", ctx.tenant_id.as_str(), key)\n    }\n}\n\n#[async_trait]\nimpl EventPublisher for RedisStorage {\n    type Error = StorageError;\n\n    async fn publish(\u0026self, event: GovernanceEvent) -\u003e Result\u003c(), Self::Error\u003e {\n        let mut conn = self.connection_manager.clone();\n        let event_json =\n            serde_json::to_string(\u0026event).map_err(|e| StorageError::SerializationError {\n                error_type: \"JSON\".to_string(),\n                reason: e.to_string()\n            })?;\n\n        let stream_key = format!(\"governance:events:{}\", event.tenant_id());\n        let _: String = conn\n            .xadd(stream_key, \"*\", \u0026[(\"event\", event_json)])\n            .await\n            .map_err(|e| StorageError::QueryError {\n                backend: \"Redis\".to_string(),\n                reason: e.to_string()\n            })?;\n\n        Ok(())\n    }\n\n    async fn subscribe(\n        \u0026self,\n        channels: \u0026[\u0026str]\n    ) -\u003e Result\u003ctokio::sync::mpsc::Receiver\u003cGovernanceEvent\u003e, Self::Error\u003e {\n        let (tx, rx) = tokio::sync::mpsc::channel(100);\n        let client = self.client.clone();\n        let stream_keys: Vec\u003cString\u003e = channels.iter().map(|s| s.to_string()).collect();\n\n        tokio::spawn(async move {\n            if let Ok(mut conn) = client.get_connection_manager().await {\n                let mut last_ids: Vec\u003cString\u003e = vec![\"$\".to_string(); stream_keys.len()];\n\n                loop {\n                    let opts = redis::streams::StreamReadOptions::default()\n                        .block(0)\n                        .count(10);\n\n                    let result: Result\u003credis::streams::StreamReadReply, redis::RedisError\u003e =\n                        conn.xread_options(\u0026stream_keys, \u0026last_ids, \u0026opts).await;\n\n                    match result {\n                        Ok(reply) =\u003e {\n                            for (i, stream) in reply.keys.into_iter().enumerate() {\n                                for record in stream.ids {\n                                    if let Some(event_json) = record.map.get(\"event\") {\n                                        if let Ok(event_str) =\n                                            redis::from_redis_value::\u003cString\u003e(event_json.clone())\n                                        {\n                                            if let Ok(event) =\n                                                serde_json::from_str::\u003cGovernanceEvent\u003e(\u0026event_str)\n                                            {\n                                                if tx.send(event).await.is_err() {\n                                                    return;\n                                                }\n                                            }\n                                        }\n                                    }\n                                    last_ids[i] = record.id;\n                                }\n                            }\n                        }\n                        Err(_) =\u003e {\n                            tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;\n                        }\n                    }\n                }\n            }\n        });\n\n        Ok(rx)\n    }\n}\n\n#[async_trait]\nimpl mk_core::traits::StorageBackend for RedisStorage {\n    type Error = StorageError;\n\n    async fn store(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        key: \u0026str,\n        value: \u0026[u8]\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        let mut conn = self.connection_manager.clone();\n        let scoped_key = self.scoped_key(\u0026ctx, key);\n        conn.set(scoped_key, value)\n            .await\n            .map_err(|e| StorageError::QueryError {\n                backend: \"Redis\".to_string(),\n                reason: e.to_string()\n            })\n    }\n\n    async fn retrieve(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        key: \u0026str\n    ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e {\n        let mut conn = self.connection_manager.clone();\n        let scoped_key = self.scoped_key(\u0026ctx, key);\n        conn.get(scoped_key)\n            .await\n            .map_err(|e| StorageError::QueryError {\n                backend: \"Redis\".to_string(),\n                reason: e.to_string()\n            })\n    }\n\n    async fn delete(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        key: \u0026str\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        let scoped_key = self.scoped_key(\u0026ctx, key);\n        self.delete_key(\u0026scoped_key).await\n    }\n\n    async fn exists(\n        \u0026self,\n        ctx: mk_core::types::TenantContext,\n        key: \u0026str\n    ) -\u003e Result\u003cbool, Self::Error\u003e {\n        let scoped_key = self.scoped_key(\u0026ctx, key);\n        self.exists_key(\u0026scoped_key).await\n    }\n\n    async fn get_ancestors(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _unit_id: \u0026str\n    ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn get_unit_policies(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _unit_id: \u0026str\n    ) -\u003e Result\u003cVec\u003cmk_core::types::Policy\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn create_unit(\n        \u0026self,\n        _unit: \u0026mk_core::types::OrganizationalUnit\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn add_unit_policy(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _unit_id: \u0026str,\n        _policy: \u0026mk_core::types::Policy\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn assign_role(\n        \u0026self,\n        _user_id: \u0026mk_core::types::UserId,\n        _tenant_id: \u0026mk_core::types::TenantId,\n        _unit_id: \u0026str,\n        _role: mk_core::types::Role\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn remove_role(\n        \u0026self,\n        _user_id: \u0026mk_core::types::UserId,\n        _tenant_id: \u0026mk_core::types::TenantId,\n        _unit_id: \u0026str,\n        _role: mk_core::types::Role\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn get_descendants(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _unit_id: \u0026str\n    ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn store_drift_result(\n        \u0026self,\n        _result: mk_core::types::DriftResult\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn get_latest_drift_result(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _project_id: \u0026str\n    ) -\u003e Result\u003cOption\u003cmk_core::types::DriftResult\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n\n    async fn list_all_units(\u0026self) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn record_job_status(\n        \u0026self,\n        _job_name: \u0026str,\n        _tenant_id: \u0026str,\n        _status: \u0026str,\n        _message: Option\u003c\u0026str\u003e,\n        _started_at: i64,\n        _finished_at: Option\u003ci64\u003e\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn get_governance_events(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _since_timestamp: i64,\n        _limit: usize\n    ) -\u003e Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use errors::StorageError;\n\n    // Test error type conversions and patterns\n    #[test]\n    fn test_storage_error_display() {\n        let conn_error = StorageError::ConnectionError {\n            backend: \"Redis\".to_string(),\n            reason: \"Connection refused\".to_string()\n        };\n\n        let query_error = StorageError::QueryError {\n            backend: \"Redis\".to_string(),\n            reason: \"Command failed\".to_string()\n        };\n\n        assert_eq!(\n            conn_error.to_string(),\n            \"Connection to Redis failed: Connection refused\"\n        );\n\n        assert_eq!(\n            query_error.to_string(),\n            \"Query on Redis failed: Command failed\"\n        );\n    }\n\n    // Test RedisStorage struct creation (without actual connection)\n    #[tokio::test]\n    async fn test_redis_storage_error_handling() {\n        // This test verifies that invalid connection strings produce appropriate errors\n        // Note: We can't easily mock the redis client, but we can verify error types\n\n        // Test with obviously invalid URL\n        let result = RedisStorage::new(\"not-a-valid-url\").await;\n        assert!(result.is_err());\n\n        if let Err(StorageError::ConnectionError { backend, .. }) = result {\n            assert_eq!(backend, \"Redis\");\n        } else {\n            panic!(\"Expected ConnectionError for invalid URL\");\n        }\n    }\n\n    // Test StorageBackend trait implementation consistency\n    #[test]\n    fn test_storage_backend_trait_bounds() {\n        use mk_core::traits::StorageBackend;\n\n        // This is a compile-time test to ensure RedisStorage implements StorageBackend\n        fn assert_storage_backend\u003cT: StorageBackend\u003e() {}\n\n        // If this compiles, RedisStorage implements StorageBackend\n        assert_storage_backend::\u003cRedisStorage\u003e();\n    }\n\n    // Test error message formatting for different scenarios\n    #[test]\n    fn test_error_messages_include_backend_name() {\n        let errors = vec![\n            StorageError::ConnectionError {\n                backend: \"Redis\".to_string(),\n                reason: \"test\".to_string()\n            },\n            StorageError::QueryError {\n                backend: \"Redis\".to_string(),\n                reason: \"test\".to_string()\n            },\n            StorageError::SerializationError {\n                error_type: \"JSON\".to_string(),\n                reason: \"test\".to_string()\n            },\n            StorageError::NotFound {\n                backend: \"Redis\".to_string(),\n                id: \"key123\".to_string()\n            },\n            StorageError::TransactionError {\n                backend: \"Redis\".to_string(),\n                reason: \"test\".to_string()\n            },\n        ];\n\n        for error in errors {\n            let msg = error.to_string();\n            assert!(\n                msg.contains(\"Redis\") || msg.contains(\"JSON\"),\n                \"Error message should contain backend or error type: {}\",\n                msg\n            );\n        }\n    }\n\n    // Test that RedisStorage methods have correct signatures\n    #[test]\n    fn test_method_signatures() {\n        // This is a compile-time check\n\n        // Verify RedisStorage has the expected method signature\n        // The existence of the method is verified by compilation\n        // We can't easily test async method signatures in a unit test\n        let _ = RedisStorage::new;\n    }\n}\n","traces":[{"line":14,"address":[],"length":0,"stats":{"Line":12}},{"line":15,"address":[],"length":0,"stats":{"Line":5}},{"line":16,"address":[],"length":0,"stats":{"Line":18}},{"line":17,"address":[],"length":0,"stats":{"Line":2}},{"line":18,"address":[],"length":0,"stats":{"Line":2}},{"line":21,"address":[],"length":0,"stats":{"Line":4}},{"line":22,"address":[],"length":0,"stats":{"Line":10}},{"line":24,"address":[],"length":0,"stats":{"Line":5}},{"line":25,"address":[],"length":0,"stats":{"Line":5}},{"line":26,"address":[],"length":0,"stats":{"Line":2}},{"line":27,"address":[],"length":0,"stats":{"Line":2}},{"line":30,"address":[],"length":0,"stats":{"Line":4}},{"line":31,"address":[],"length":0,"stats":{"Line":8}},{"line":32,"address":[],"length":0,"stats":{"Line":4}},{"line":36,"address":[],"length":0,"stats":{"Line":4}},{"line":37,"address":[],"length":0,"stats":{"Line":6}},{"line":38,"address":[],"length":0,"stats":{"Line":8}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":3}},{"line":50,"address":[],"length":0,"stats":{"Line":9}},{"line":51,"address":[],"length":0,"stats":{"Line":5}},{"line":52,"address":[],"length":0,"stats":{"Line":10}},{"line":53,"address":[],"length":0,"stats":{"Line":2}},{"line":54,"address":[],"length":0,"stats":{"Line":2}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":4}},{"line":60,"address":[],"length":0,"stats":{"Line":1}},{"line":61,"address":[],"length":0,"stats":{"Line":1}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":2}},{"line":69,"address":[],"length":0,"stats":{"Line":3}},{"line":70,"address":[],"length":0,"stats":{"Line":4}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":10}},{"line":77,"address":[],"length":0,"stats":{"Line":15}},{"line":78,"address":[],"length":0,"stats":{"Line":15}},{"line":79,"address":[],"length":0,"stats":{"Line":5}},{"line":80,"address":[],"length":0,"stats":{"Line":5}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}}],"covered":34,"coverable":78},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","tests","governance_integration.rs"],"content":"//! Integration tests for the governance event system and multi-publisher.\n\nuse mk_core::traits::{AuthorizationService, EventPublisher, StorageBackend};\nuse mk_core::types::{GovernanceEvent, TenantContext, TenantId, UserId};\nuse std::sync::Arc;\nuse storage::events::RedisPublisher;\nuse storage::postgres::PostgresBackend;\nuse testcontainers::ContainerAsync;\nuse testcontainers::runners::AsyncRunner;\nuse testcontainers_modules::postgres::Postgres;\nuse testcontainers_modules::redis::Redis;\n\n#[tokio::test]\n#[ignore = \"Flaky: Redis pub/sub timing sensitive with testcontainers\"]\nasync fn test_governance_event_propagation() {\n    let result: Result\u003c\n        (\n            String,\n            String,\n            ContainerAsync\u003cPostgres\u003e,\n            ContainerAsync\u003cRedis\u003e,\n        ),\n        Box\u003cdyn std::error::Error\u003e,\n    \u003e = async {\n        let (_pg_container, pg_url) = setup_postgres_test().await?;\n        let (_redis_container, redis_url) = setup_redis_test().await?;\n        Ok((pg_url, redis_url, _pg_container, _redis_container))\n    }\n    .await;\n\n    match result {\n        Ok((pg_url, redis_url, _pg_container, _redis_container)) =\u003e {\n            let pg_backend = Arc::new(PostgresBackend::new(\u0026pg_url).await.unwrap());\n            pg_backend.initialize_schema().await.unwrap();\n\n            let redis_publisher = Arc::new(RedisPublisher::new(\u0026redis_url, \"gov_events\").unwrap());\n\n            let mut rx = redis_publisher.subscribe(\u0026[\"gov_events\"]).await.unwrap();\n\n            tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;\n\n            let tenant_id = TenantId::new(\"tenant-1\".to_string()).unwrap();\n            let event = GovernanceEvent::DriftDetected {\n                project_id: \"project-1\".to_string(),\n                tenant_id: tenant_id.clone(),\n                drift_score: 0.75,\n                timestamp: chrono::Utc::now().timestamp(),\n            };\n\n            pg_backend.publish(event.clone()).await.unwrap();\n            redis_publisher.publish(event.clone()).await.unwrap();\n\n            let received = tokio::time::timeout(tokio::time::Duration::from_secs(5), rx.recv())\n                .await\n                .expect(\"Timeout waiting for event\")\n                .expect(\"Channel closed\");\n\n            if let GovernanceEvent::DriftDetected { drift_score, .. } = received {\n                assert_eq!(drift_score, 0.75);\n            } else {\n                panic!(\"Wrong event type received\");\n            }\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping governance integration test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_full_governance_workflow() {\n    let result: Result\u003c(String, ContainerAsync\u003cPostgres\u003e), Box\u003cdyn std::error::Error\u003e\u003e = async {\n        let (_pg_container, pg_url) = setup_postgres_test().await?;\n        Ok((pg_url, _pg_container))\n    }\n    .await;\n\n    match result {\n        Ok((pg_url, _pg_container)) =\u003e {\n            let pg_backend = Arc::new(PostgresBackend::new(\u0026pg_url).await.unwrap());\n            pg_backend.initialize_schema().await.unwrap();\n\n            let tenant_id = TenantId::new(\"comp1\".to_string()).unwrap();\n            let user_id = UserId::new(\"user1\".to_string()).unwrap();\n            let agent_id = \"agent1\".to_string();\n\n            let company = mk_core::types::OrganizationalUnit {\n                id: \"comp1\".into(),\n                name: \"Company 1\".into(),\n                unit_type: mk_core::types::UnitType::Company,\n                parent_id: None,\n                tenant_id: tenant_id.clone(),\n                metadata: std::collections::HashMap::new(),\n                created_at: chrono::Utc::now().timestamp(),\n                updated_at: chrono::Utc::now().timestamp(),\n            };\n            pg_backend.create_unit(\u0026company).await.unwrap();\n\n            let org = mk_core::types::OrganizationalUnit {\n                id: \"org1\".into(),\n                name: \"Organization 1\".into(),\n                unit_type: mk_core::types::UnitType::Organization,\n                parent_id: Some(\"comp1\".into()),\n                tenant_id: tenant_id.clone(),\n                metadata: std::collections::HashMap::new(),\n                created_at: chrono::Utc::now().timestamp(),\n                updated_at: chrono::Utc::now().timestamp(),\n            };\n            pg_backend.create_unit(\u0026org).await.unwrap();\n\n            let team = mk_core::types::OrganizationalUnit {\n                id: \"team1\".into(),\n                name: \"Team 1\".into(),\n                unit_type: mk_core::types::UnitType::Team,\n                parent_id: Some(\"org1\".into()),\n                tenant_id: tenant_id.clone(),\n                metadata: std::collections::HashMap::new(),\n                created_at: chrono::Utc::now().timestamp(),\n                updated_at: chrono::Utc::now().timestamp(),\n            };\n            pg_backend.create_unit(\u0026team).await.unwrap();\n\n            let project = mk_core::types::OrganizationalUnit {\n                id: \"proj1\".into(),\n                name: \"Project 1\".into(),\n                unit_type: mk_core::types::UnitType::Project,\n                parent_id: Some(\"team1\".into()),\n                tenant_id: tenant_id.clone(),\n                metadata: std::collections::HashMap::new(),\n                created_at: chrono::Utc::now().timestamp(),\n                updated_at: chrono::Utc::now().timestamp(),\n            };\n            pg_backend.create_unit(\u0026project).await.unwrap();\n\n            let cedar_policies = r#\"\n                permit(principal == User::\"agent1\", action == Action::\"ActAs\", resource == User::\"user1\");\n                permit(principal == User::\"user1\", action == Action::\"Update\", resource == Unit::\"proj1\");\n            \"#;\n            let cedar_schema = \"{}\";\n            let authorizer =\n                adapters::auth::cedar::CedarAuthorizer::new(cedar_policies, cedar_schema).unwrap();\n\n            let ctx = TenantContext::with_agent(tenant_id.clone(), user_id.clone(), agent_id);\n            let allowed = authorizer\n                .check_permission(\u0026ctx, \"Update\", \"Unit::\\\"proj1\\\"\")\n                .await\n                .unwrap();\n            assert!(allowed);\n\n            pg_backend\n                .record_job_status(\n                    \"drift_scan\",\n                    tenant_id.as_str(),\n                    \"completed\",\n                    None,\n                    chrono::Utc::now().timestamp() - 100,\n                    Some(chrono::Utc::now().timestamp()),\n                )\n                .await\n                .unwrap();\n\n            let drift = mk_core::types::DriftResult {\n                project_id: \"proj1\".to_string(),\n                tenant_id: tenant_id.clone(),\n                drift_score: 0.2,\n                violations: vec![],\n                timestamp: chrono::Utc::now().timestamp(),\n            };\n            pg_backend.store_drift_result(drift).await.unwrap();\n\n            let engine = Arc::new(\n                knowledge::governance::GovernanceEngine::new().with_storage(pg_backend.clone()),\n            );\n            let deployment_config = config::DeploymentConfig::default();\n            let api = Arc::new(knowledge::api::GovernanceDashboardApi::new(\n                engine,\n                pg_backend.clone(),\n                deployment_config,\n            ));\n\n            let drift_status = knowledge::api::get_drift_status(api.clone(), \u0026ctx, \"proj1\")\n                .await\n                .unwrap();\n            assert!(drift_status.is_some());\n            assert_eq!(drift_status.unwrap().drift_score, 0.2);\n\n            let jobs = knowledge::api::get_job_status(api, \u0026ctx, Some(\"drift_scan\"))\n                .await\n                .unwrap();\n            assert!(jobs.as_array().unwrap().len() \u003e= 1);\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping governance workflow test: Docker not available\");\n        }\n    }\n}\n\nasync fn setup_postgres_test()\n-\u003e Result\u003c(ContainerAsync\u003cPostgres\u003e, String), Box\u003cdyn std::error::Error\u003e\u003e {\n    let container = Postgres::default()\n        .with_db_name(\"govdb\")\n        .with_user(\"govuser\")\n        .with_password(\"govpass\")\n        .start()\n        .await?;\n\n    let url = format!(\n        \"postgres://govuser:govpass@localhost:{}/govdb\",\n        container.get_host_port_ipv4(5432).await?\n    );\n    Ok((container, url))\n}\n\nasync fn setup_redis_test() -\u003e Result\u003c(ContainerAsync\u003cRedis\u003e, String), Box\u003cdyn std::error::Error\u003e\u003e {\n    let container = Redis::default().start().await?;\n    let url = format!(\n        \"redis://localhost:{}\",\n        container.get_host_port_ipv4(6379).await?\n    );\n    Ok((container, url))\n}\n","traces":[{"line":198,"address":[],"length":0,"stats":{"Line":1}},{"line":200,"address":[],"length":0,"stats":{"Line":3}},{"line":205,"address":[],"length":0,"stats":{"Line":1}},{"line":207,"address":[],"length":0,"stats":{"Line":2}},{"line":209,"address":[],"length":0,"stats":{"Line":1}},{"line":211,"address":[],"length":0,"stats":{"Line":1}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":0}}],"covered":6,"coverable":11},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","tests","hierarchy_integration.rs"],"content":"//! Integration tests for organizational hierarchy in PostgreSQL storage backend\n//!\n//! These tests verify the strict hierarchy enforcement and recursive navigation\n//! logic.\n\nuse mk_core::types::{OrganizationalUnit, TenantContext, TenantId, UnitType, UserId};\nuse std::collections::HashMap;\nuse storage::postgres::PostgresBackend;\nuse testcontainers::ContainerAsync;\nuse testcontainers::runners::AsyncRunner;\nuse testcontainers_modules::postgres::Postgres;\n\nasync fn setup_postgres_container()\n-\u003e Result\u003c(ContainerAsync\u003cPostgres\u003e, String), Box\u003cdyn std::error::Error\u003e\u003e {\n    let container = Postgres::default()\n        .with_db_name(\"testdb\")\n        .with_user(\"testuser\")\n        .with_password(\"testpass\")\n        .start()\n        .await?;\n\n    let connection_url = format!(\n        \"postgres://testuser:testpass@localhost:{}/testdb\",\n        container.get_host_port_ipv4(5432).await?\n    );\n\n    Ok((container, connection_url))\n}\n\nfn create_test_unit(\n    id: \u0026str,\n    name: \u0026str,\n    unit_type: UnitType,\n    parent_id: Option\u003cString\u003e,\n    tenant_id: \u0026str\n) -\u003e OrganizationalUnit {\n    OrganizationalUnit {\n        id: id.to_string(),\n        name: name.to_string(),\n        unit_type,\n        parent_id,\n        tenant_id: TenantId::new(tenant_id.to_string()).unwrap(),\n        metadata: HashMap::new(),\n        created_at: chrono::Utc::now().timestamp(),\n        updated_at: chrono::Utc::now().timestamp()\n    }\n}\n\n#[tokio::test]\nasync fn test_hierarchy_strict_enforcement() {\n    match setup_postgres_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let backend = PostgresBackend::new(\u0026connection_url).await.unwrap();\n            backend.initialize_schema().await.unwrap();\n\n            let tenant_id = \"tenant-1\";\n\n            // 1. Root must be a Company\n            let org_root =\n                create_test_unit(\"org-1\", \"Org Root\", UnitType::Organization, None, tenant_id);\n            let result = backend.create_unit(\u0026org_root).await;\n            assert!(result.is_err(), \"Root unit must be a Company\");\n\n            let company =\n                create_test_unit(\"comp-1\", \"Comp Root\", UnitType::Company, None, tenant_id);\n            backend\n                .create_unit(\u0026company)\n                .await\n                .expect(\"Company can be root\");\n\n            // 2. Organization must be under Company\n            let team_under_comp = create_test_unit(\n                \"team-1\",\n                \"Team Under Comp\",\n                UnitType::Team,\n                Some(\"comp-1\".to_string()),\n                tenant_id\n            );\n            let result = backend.create_unit(\u0026team_under_comp).await;\n            assert!(result.is_err(), \"Team cannot be directly under Company\");\n\n            let org = create_test_unit(\n                \"org-1\",\n                \"Org\",\n                UnitType::Organization,\n                Some(\"comp-1\".to_string()),\n                tenant_id\n            );\n            backend\n                .create_unit(\u0026org)\n                .await\n                .expect(\"Organization can be under Company\");\n\n            // 3. Team must be under Organization\n            let project_under_org = create_test_unit(\n                \"proj-1\",\n                \"Proj Under Org\",\n                UnitType::Project,\n                Some(\"org-1\".to_string()),\n                tenant_id\n            );\n            let result = backend.create_unit(\u0026project_under_org).await;\n            assert!(\n                result.is_err(),\n                \"Project cannot be directly under Organization\"\n            );\n\n            let team = create_test_unit(\n                \"team-1\",\n                \"Team\",\n                UnitType::Team,\n                Some(\"org-1\".to_string()),\n                tenant_id\n            );\n            backend\n                .create_unit(\u0026team)\n                .await\n                .expect(\"Team can be under Organization\");\n\n            // 4. Project must be under Team\n            let project = create_test_unit(\n                \"proj-1\",\n                \"Project\",\n                UnitType::Project,\n                Some(\"team-1\".to_string()),\n                tenant_id\n            );\n            backend\n                .create_unit(\u0026project)\n                .await\n                .expect(\"Project can be under Team\");\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping PostgreSQL hierarchy test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_recursive_hierarchy_navigation() {\n    match setup_postgres_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let backend = PostgresBackend::new(\u0026connection_url).await.unwrap();\n            backend.initialize_schema().await.unwrap();\n\n            let tenant_id = \"tenant-1\";\n            let ctx = TenantContext::new(\n                TenantId::new(tenant_id.to_string()).unwrap(),\n                UserId::default()\n            );\n\n            // Build hierarchy: Comp -\u003e Org -\u003e Team -\u003e Proj\n            let company = create_test_unit(\"comp-1\", \"Comp\", UnitType::Company, None, tenant_id);\n            let org = create_test_unit(\n                \"org-1\",\n                \"Org\",\n                UnitType::Organization,\n                Some(\"comp-1\".to_string()),\n                tenant_id\n            );\n            let team = create_test_unit(\n                \"team-1\",\n                \"Team\",\n                UnitType::Team,\n                Some(\"org-1\".to_string()),\n                tenant_id\n            );\n            let project = create_test_unit(\n                \"proj-1\",\n                \"Proj\",\n                UnitType::Project,\n                Some(\"team-1\".to_string()),\n                tenant_id\n            );\n\n            backend.create_unit(\u0026company).await.unwrap();\n            backend.create_unit(\u0026org).await.unwrap();\n            backend.create_unit(\u0026team).await.unwrap();\n            backend.create_unit(\u0026project).await.unwrap();\n\n            // Test Ancestors of Project\n            let ancestors = backend.get_unit_ancestors(\u0026ctx, \"proj-1\").await.unwrap();\n            assert_eq!(ancestors.len(), 3);\n            assert_eq!(ancestors[0].id, \"team-1\");\n            assert_eq!(ancestors[1].id, \"org-1\");\n            assert_eq!(ancestors[2].id, \"comp-1\");\n\n            // Test Descendants of Company\n            let descendants = backend.get_unit_descendants(\u0026ctx, \"comp-1\").await.unwrap();\n            assert_eq!(descendants.len(), 3);\n            assert_eq!(descendants[0].id, \"org-1\");\n            assert_eq!(descendants[1].id, \"team-1\");\n            assert_eq!(descendants[2].id, \"proj-1\");\n\n            // Test Descendants of Organization\n            let descendants_org = backend.get_unit_descendants(\u0026ctx, \"org-1\").await.unwrap();\n            assert_eq!(descendants_org.len(), 2);\n            assert_eq!(descendants_org[0].id, \"team-1\");\n            assert_eq!(descendants_org[1].id, \"proj-1\");\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping PostgreSQL hierarchy test: Docker not available\");\n        }\n    }\n}\n","traces":[{"line":13,"address":[],"length":0,"stats":{"Line":2}},{"line":15,"address":[],"length":0,"stats":{"Line":6}},{"line":20,"address":[],"length":0,"stats":{"Line":2}},{"line":22,"address":[],"length":0,"stats":{"Line":4}},{"line":24,"address":[],"length":0,"stats":{"Line":2}},{"line":27,"address":[],"length":0,"stats":{"Line":2}},{"line":30,"address":[],"length":0,"stats":{"Line":11}},{"line":38,"address":[],"length":0,"stats":{"Line":33}},{"line":39,"address":[],"length":0,"stats":{"Line":33}},{"line":42,"address":[],"length":0,"stats":{"Line":55}},{"line":43,"address":[],"length":0,"stats":{"Line":22}},{"line":44,"address":[],"length":0,"stats":{"Line":33}},{"line":45,"address":[],"length":0,"stats":{"Line":11}}],"covered":13,"coverable":13},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","tests","postgres_test.rs"],"content":"//! Integration tests for PostgreSQL storage backend\n//!\n//! These tests use testcontainers to spin up a PostgreSQL instance.\n\nuse mk_core::traits::StorageBackend;\nuse mk_core::types::{TenantContext, TenantId, UserId};\nuse storage::postgres::{PostgresBackend, PostgresError};\nuse testcontainers::ContainerAsync;\nuse testcontainers::runners::AsyncRunner;\nuse testcontainers_modules::postgres::Postgres;\n\nasync fn setup_postgres_container()\n-\u003e Result\u003c(ContainerAsync\u003cPostgres\u003e, String), Box\u003cdyn std::error::Error\u003e\u003e {\n    let container = Postgres::default()\n        .with_db_name(\"testdb\")\n        .with_user(\"testuser\")\n        .with_password(\"testpass\")\n        .start()\n        .await?;\n\n    let connection_url = format!(\n        \"postgres://testuser:testpass@localhost:{}/testdb\",\n        container.get_host_port_ipv4(5432).await?\n    );\n\n    Ok((container, connection_url))\n}\n\n#[tokio::test]\nasync fn test_postgres_backend_new() {\n    match setup_postgres_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let backend = PostgresBackend::new(\u0026connection_url).await;\n            assert!(backend.is_ok(), \"Should connect to PostgreSQL\");\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping PostgreSQL test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_postgres_backend_initialize_schema() {\n    match setup_postgres_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let backend = PostgresBackend::new(\u0026connection_url).await.unwrap();\n            let result = backend.initialize_schema().await;\n            assert!(result.is_ok(), \"Should initialize schema\");\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping PostgreSQL test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_postgres_backend_store_and_retrieve() {\n    match setup_postgres_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let backend = PostgresBackend::new(\u0026connection_url).await.unwrap();\n            backend.initialize_schema().await.unwrap();\n\n            let ctx = TenantContext::new(\n                TenantId::new(\"test-tenant\".to_string()).unwrap(),\n                UserId::default(),\n            );\n            let key = \"test_key\";\n            let value = b\"{\\\"test\\\": \\\"data\\\"}\";\n            let store_result = backend.store(ctx.clone(), key, value).await;\n            assert!(store_result.is_ok(), \"Should store data\");\n\n            let retrieve_result = backend.retrieve(ctx, key).await;\n            assert!(retrieve_result.is_ok(), \"Should retrieve data\");\n            let retrieved = retrieve_result.unwrap();\n            assert!(retrieved.is_some(), \"Should have retrieved data\");\n            let retrieved_json: serde_json::Value =\n                serde_json::from_slice(\u0026retrieved.unwrap()).unwrap();\n            let expected_json: serde_json::Value = serde_json::from_slice(value).unwrap();\n            assert_eq!(\n                retrieved_json, expected_json,\n                \"Retrieved JSON should match semantically\"\n            );\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping PostgreSQL test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_postgres_backend_store_update() {\n    match setup_postgres_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let backend = PostgresBackend::new(\u0026connection_url).await.unwrap();\n            backend.initialize_schema().await.unwrap();\n\n            let ctx = TenantContext::new(\n                TenantId::new(\"test-tenant\".to_string()).unwrap(),\n                UserId::default(),\n            );\n            let key = \"update_key\";\n            let value1 = b\"{\\\"version\\\": 1}\";\n            backend.store(ctx.clone(), key, value1).await.unwrap();\n\n            let value2 = b\"{\\\"version\\\": 2}\";\n            backend.store(ctx.clone(), key, value2).await.unwrap();\n\n            let retrieved = backend.retrieve(ctx, key).await.unwrap().unwrap();\n            let retrieved_json: serde_json::Value = serde_json::from_slice(\u0026retrieved).unwrap();\n            let expected_json: serde_json::Value = serde_json::from_slice(value2).unwrap();\n            assert_eq!(\n                retrieved_json, expected_json,\n                \"Should retrieve updated value\"\n            );\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping PostgreSQL test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_postgres_backend_delete() {\n    match setup_postgres_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let backend = PostgresBackend::new(\u0026connection_url).await.unwrap();\n            backend.initialize_schema().await.unwrap();\n\n            let ctx = TenantContext::new(\n                TenantId::new(\"test-tenant\".to_string()).unwrap(),\n                UserId::default(),\n            );\n            let key = \"delete_key\";\n            let value = b\"{\\\"to_delete\\\": true}\";\n            backend.store(ctx.clone(), key, value).await.unwrap();\n\n            let exists_before = backend.exists(ctx.clone(), key).await.unwrap();\n            assert!(exists_before, \"Key should exist before delete\");\n\n            let delete_result = backend.delete(ctx.clone(), key).await;\n            assert!(delete_result.is_ok(), \"Should delete data\");\n\n            let exists_after = backend.exists(ctx.clone(), key).await.unwrap();\n            assert!(!exists_after, \"Key should not exist after delete\");\n\n            let retrieved = backend.retrieve(ctx, key).await.unwrap();\n            assert!(retrieved.is_none(), \"Should return None for deleted key\");\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping PostgreSQL test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_postgres_backend_exists() {\n    match setup_postgres_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let backend = PostgresBackend::new(\u0026connection_url).await.unwrap();\n            backend.initialize_schema().await.unwrap();\n\n            let ctx = TenantContext::new(\n                TenantId::new(\"test-tenant\".to_string()).unwrap(),\n                UserId::default(),\n            );\n            let exists = backend.exists(ctx.clone(), \"nonexistent\").await.unwrap();\n            assert!(!exists, \"Nonexistent key should not exist\");\n\n            let key = \"exists_key\";\n            let value = b\"{\\\"exists\\\": true}\";\n            backend.store(ctx.clone(), key, value).await.unwrap();\n\n            let exists = backend.exists(ctx, key).await.unwrap();\n            assert!(exists, \"Stored key should exist\");\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping PostgreSQL test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_postgres_backend_retrieve_nonexistent() {\n    match setup_postgres_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let backend = PostgresBackend::new(\u0026connection_url).await.unwrap();\n            backend.initialize_schema().await.unwrap();\n\n            let ctx = TenantContext::new(\n                TenantId::new(\"test-tenant\".to_string()).unwrap(),\n                UserId::default(),\n            );\n            let result = backend.retrieve(ctx, \"nonexistent_key\").await;\n            assert!(result.is_ok(), \"Should handle nonexistent key\");\n            assert!(\n                result.unwrap().is_none(),\n                \"Should return None for nonexistent key\"\n            );\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping PostgreSQL test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_postgres_backend_invalid_json() {\n    match setup_postgres_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let backend = PostgresBackend::new(\u0026connection_url).await.unwrap();\n            backend.initialize_schema().await.unwrap();\n\n            let ctx = TenantContext::new(\n                TenantId::new(\"test-tenant\".to_string()).unwrap(),\n                UserId::default(),\n            );\n            let key = \"invalid_json_key\";\n            let invalid_json = b\"not valid json\";\n            let result = backend.store(ctx.clone(), key, invalid_json).await;\n            assert!(result.is_ok(), \"Should handle invalid JSON gracefully\");\n\n            let retrieved = backend.retrieve(ctx, key).await.unwrap();\n            assert!(retrieved.is_some(), \"Should retrieve something\");\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping PostgreSQL test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_postgres_backend_tenant_isolation() {\n    match setup_postgres_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let backend = PostgresBackend::new(\u0026connection_url).await.unwrap();\n            backend.initialize_schema().await.unwrap();\n\n            let ctx1 = TenantContext::new(\n                TenantId::new(\"tenant-1\".to_string()).unwrap(),\n                UserId::default(),\n            );\n            let ctx2 = TenantContext::new(\n                TenantId::new(\"tenant-2\".to_string()).unwrap(),\n                UserId::default(),\n            );\n            let key = \"shared-key\";\n            let val1 = b\"{\\\"tenant\\\": 1}\";\n            let val2 = b\"{\\\"tenant\\\": 2}\";\n\n            // Tenant 1 stores data\n            backend.store(ctx1.clone(), key, val1).await.unwrap();\n\n            // Tenant 2 should NOT see it\n            let res2 = backend.retrieve(ctx2.clone(), key).await.unwrap();\n            assert!(res2.is_none(), \"Tenant 2 should not see Tenant 1 data\");\n\n            // Tenant 2 stores different data for same key\n            backend.store(ctx2.clone(), key, val2).await.unwrap();\n\n            // Both should now see their own data\n            let res1 = backend.retrieve(ctx1.clone(), key).await.unwrap();\n            let res1_json: serde_json::Value = serde_json::from_slice(\u0026res1.unwrap()).unwrap();\n            let val1_json: serde_json::Value = serde_json::from_slice(val1).unwrap();\n            assert_eq!(res1_json, val1_json);\n\n            let res2 = backend.retrieve(ctx2.clone(), key).await.unwrap();\n            let res2_json: serde_json::Value = serde_json::from_slice(\u0026res2.unwrap()).unwrap();\n            let val2_json: serde_json::Value = serde_json::from_slice(val2).unwrap();\n            assert_eq!(res2_json, val2_json);\n\n            // Deleting from Tenant 1 should NOT affect Tenant 2\n            backend.delete(ctx1.clone(), key).await.unwrap();\n            assert!(!backend.exists(ctx1, key).await.unwrap());\n            assert!(backend.exists(ctx2, key).await.unwrap());\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping PostgreSQL test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_postgres_backend_connection_error() {\n    let result = PostgresBackend::new(\"postgres://invalid:5432/invalid\").await;\n    assert!(result.is_err(), \"Should fail with invalid connection\");\n\n    match result {\n        Err(PostgresError::Database(_)) =\u003e {}\n        _ =\u003e {\n            panic!(\"Expected PostgresError::Database\");\n        }\n    }\n}\n","traces":[{"line":12,"address":[],"length":0,"stats":{"Line":9}},{"line":14,"address":[],"length":0,"stats":{"Line":27}},{"line":19,"address":[],"length":0,"stats":{"Line":9}},{"line":21,"address":[],"length":0,"stats":{"Line":18}},{"line":23,"address":[],"length":0,"stats":{"Line":9}},{"line":26,"address":[],"length":0,"stats":{"Line":9}}],"covered":6,"coverable":6},{"path":["/","Users","christian.klat","dev","git","aeterna","storage","tests","redis_test.rs"],"content":"//! Integration tests for Redis storage backend\n//!\n//! These tests use testcontainers to spin up a Redis instance.\n\nuse errors::StorageError;\nuse storage::redis::RedisStorage;\nuse testcontainers::ContainerAsync;\nuse testcontainers::runners::AsyncRunner;\nuse testcontainers_modules::redis::Redis;\n\nasync fn setup_redis_container()\n-\u003e Result\u003c(ContainerAsync\u003cRedis\u003e, String), Box\u003cdyn std::error::Error\u003e\u003e {\n    let container = Redis::default().start().await?;\n\n    let port = container.get_host_port_ipv4(6379).await?;\n    let connection_url = format!(\"redis://localhost:{}\", port);\n\n    Ok((container, connection_url))\n}\n\n#[tokio::test]\nasync fn test_redis_basic_operations() {\n    match setup_redis_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let redis = RedisStorage::new(\u0026connection_url)\n                .await\n                .expect(\"Failed to create Redis storage\");\n\n            let set_result = redis.set(\"test_key\", \"test_value\", Some(60)).await;\n            assert!(set_result.is_ok(), \"Set operation should succeed\");\n\n            let get_result = redis.get(\"test_key\").await;\n            assert!(get_result.is_ok(), \"Get operation should succeed\");\n            assert_eq!(\n                get_result.unwrap(),\n                Some(\"test_value\".to_string()),\n                \"Retrieved value should match\"\n            );\n\n            let exists_result = redis.exists_key(\"test_key\").await;\n            assert!(exists_result.is_ok(), \"Exists operation should succeed\");\n            assert!(exists_result.unwrap(), \"Key should exist\");\n\n            let delete_result = redis.delete_key(\"test_key\").await;\n            assert!(delete_result.is_ok(), \"Delete operation should succeed\");\n\n            let exists_after_delete = redis.exists_key(\"test_key\").await;\n            assert!(\n                exists_after_delete.is_ok(),\n                \"Exists operation should succeed\"\n            );\n            assert!(\n                !exists_after_delete.unwrap(),\n                \"Key should not exist after delete\"\n            );\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Redis test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_redis_ttl_expiration() {\n    match setup_redis_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let redis = RedisStorage::new(\u0026connection_url)\n                .await\n                .expect(\"Failed to create Redis storage\");\n\n            let set_result = redis.set(\"ttl_key\", \"ttl_value\", Some(1)).await;\n            assert!(set_result.is_ok(), \"Set with TTL should succeed\");\n\n            let exists_immediately = redis.exists_key(\"ttl_key\").await;\n            assert!(\n                exists_immediately.is_ok() \u0026\u0026 exists_immediately.unwrap(),\n                \"Key should exist immediately\"\n            );\n\n            tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;\n\n            let exists_after_ttl = redis.exists_key(\"ttl_key\").await;\n            assert!(\n                exists_after_ttl.is_ok() \u0026\u0026 !exists_after_ttl.unwrap(),\n                \"Key should not exist after TTL\"\n            );\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Redis test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_redis_without_ttl() {\n    match setup_redis_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let redis = RedisStorage::new(\u0026connection_url)\n                .await\n                .expect(\"Failed to create Redis storage\");\n\n            let set_result = redis.set(\"no_ttl_key\", \"persistent_value\", None).await;\n            assert!(set_result.is_ok(), \"Set without TTL should succeed\");\n\n            let exists_result = redis.exists_key(\"no_ttl_key\").await;\n            assert!(\n                exists_result.is_ok() \u0026\u0026 exists_result.unwrap(),\n                \"Key should exist\"\n            );\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Redis test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_redis_get_nonexistent_key() {\n    match setup_redis_container().await {\n        Ok((_container, connection_url)) =\u003e {\n            let redis = RedisStorage::new(\u0026connection_url)\n                .await\n                .expect(\"Failed to create Redis storage\");\n\n            let get_result = redis.get(\"nonexistent_key\").await;\n            assert!(get_result.is_ok(), \"Get operation should succeed\");\n            assert_eq!(\n                get_result.unwrap(),\n                None,\n                \"Should return None for nonexistent key\"\n            );\n        }\n        Err(_) =\u003e {\n            eprintln!(\"Skipping Redis test: Docker not available\");\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_redis_connection_error() {\n    let result = RedisStorage::new(\"redis://invalid:6379\").await;\n\n    assert!(result.is_err(), \"Should fail with invalid connection\");\n\n    match result {\n        Err(StorageError::ConnectionError { backend, .. }) =\u003e {\n            assert_eq!(backend, \"Redis\", \"Error should be for Redis backend\");\n        }\n        _ =\u003e {\n            panic!(\"Expected ConnectionError\");\n        }\n    }\n}\n","traces":[{"line":11,"address":[],"length":0,"stats":{"Line":4}},{"line":13,"address":[],"length":0,"stats":{"Line":12}},{"line":15,"address":[],"length":0,"stats":{"Line":8}},{"line":16,"address":[],"length":0,"stats":{"Line":12}},{"line":18,"address":[],"length":0,"stats":{"Line":4}}],"covered":5,"coverable":5},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","bridge.rs"],"content":"use crate::error::{Result, SyncError};\nuse crate::pointer::{KnowledgePointer, KnowledgePointerMetadata, map_layer};\nuse crate::state::{FederationConflict, SyncConflict, SyncFailure, SyncState, SyncTrigger};\nuse crate::state_persister::SyncStatePersister;\nuse config::config::DeploymentConfig;\nuse knowledge::federation::FederationProvider;\nuse knowledge::governance::GovernanceEngine;\nuse knowledge::governance_client::{GovernanceClient, RemoteGovernanceClient};\nuse memory::manager::MemoryManager;\nuse mk_core::traits::KnowledgeRepository;\nuse mk_core::types::{KnowledgeEntry, KnowledgeLayer, MemoryEntry, TenantContext};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\n#[derive(Debug, Clone, PartialEq, Default)]\npub struct DeltaResult {\n    pub added: Vec\u003cKnowledgeEntry\u003e,\n    pub updated: Vec\u003cKnowledgeEntry\u003e,\n    pub deleted: Vec\u003cString\u003e,\n    pub unchanged: Vec\u003cString\u003e,\n}\n\npub struct SyncManager {\n    memory_manager: Arc\u003cMemoryManager\u003e,\n    knowledge_repo: Arc\u003cdyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e\u003e,\n    governance_engine: Arc\u003cGovernanceEngine\u003e,\n    governance_client: Option\u003cArc\u003cdyn GovernanceClient\u003e\u003e,\n    deployment_config: DeploymentConfig,\n    federation_manager: Option\u003cArc\u003cdyn FederationProvider\u003e\u003e,\n    persister: Arc\u003cdyn SyncStatePersister\u003e,\n    states: Arc\u003cRwLock\u003cHashMap\u003cmk_core::types::TenantId, SyncState\u003e\u003e\u003e,\n    checkpoints: Arc\u003cRwLock\u003cHashMap\u003cmk_core::types::TenantId, SyncState\u003e\u003e\u003e,\n}\n\nimpl SyncManager {\n    #[tracing::instrument(skip(\n        memory_manager,\n        knowledge_repo,\n        governance_engine,\n        federation_manager,\n        persister\n    ))]\n    pub async fn new(\n        memory_manager: Arc\u003cMemoryManager\u003e,\n        knowledge_repo: Arc\u003c\n            dyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e,\n        \u003e,\n        governance_engine: Arc\u003cGovernanceEngine\u003e,\n        deployment_config: DeploymentConfig,\n        federation_manager: Option\u003cArc\u003cdyn FederationProvider\u003e\u003e,\n        persister: Arc\u003cdyn SyncStatePersister\u003e,\n    ) -\u003e Result\u003cSelf\u003e {\n        let governance_client =\n            if deployment_config.mode == \"hybrid\" || deployment_config.mode == \"remote\" {\n                deployment_config.remote_url.as_ref().map(|url: \u0026String| {\n                    Arc::new(RemoteGovernanceClient::new(url.clone())) as Arc\u003cdyn GovernanceClient\u003e\n                })\n            } else {\n                None\n            };\n\n        let states = HashMap::new();\n        let checkpoints = HashMap::new();\n\n        Ok(Self {\n            memory_manager,\n            knowledge_repo,\n            governance_engine,\n            governance_client,\n            deployment_config,\n            federation_manager,\n            persister,\n            states: Arc::new(RwLock::new(states)),\n            checkpoints: Arc::new(RwLock::new(checkpoints)),\n        })\n    }\n\n    async fn get_or_load_state(\u0026self, tenant_id: \u0026mk_core::types::TenantId) -\u003e Result\u003cSyncState\u003e {\n        {\n            let states = self.states.read().await;\n            if let Some(state) = states.get(tenant_id) {\n                return Ok(state.clone());\n            }\n        }\n\n        let state = self\n            .persister\n            .load(tenant_id)\n            .await\n            .map_err(|e| SyncError::Persistence(e.to_string()))?;\n\n        let mut states = self.states.write().await;\n        states.insert(tenant_id.clone(), state.clone());\n        Ok(state)\n    }\n\n    async fn update_state(\u0026self, tenant_id: \u0026mk_core::types::TenantId, state: SyncState) {\n        let mut states = self.states.write().await;\n        states.insert(tenant_id.clone(), state);\n    }\n\n    #[tracing::instrument(skip(self))]\n    pub async fn initialize(\u0026self, ctx: TenantContext) -\u003e Result\u003c()\u003e {\n        tracing::info!(\"Initializing SyncManager for tenant: {}\", ctx.tenant_id);\n\n        self.knowledge_repo\n            .get_head_commit(ctx.clone())\n            .await\n            .map_err(|e| {\n                tracing::error!(\n                    \"Failed to access knowledge repository during initialization: {}\",\n                    e\n                );\n                SyncError::Internal(format!(\"Repo access failed: {}\", e))\n            })?;\n\n        let state = self.get_or_load_state(\u0026ctx.tenant_id).await?;\n        tracing::info!(\n            \"SyncManager initialized for tenant {} with version {}, last sync: {:?}\",\n            ctx.tenant_id,\n            state.version,\n            state.last_sync_at\n        );\n\n        Ok(())\n    }\n\n    #[tracing::instrument(skip(self))]\n    pub async fn shutdown(\u0026self) -\u003e Result\u003c()\u003e {\n        tracing::info!(\"Shutting down SyncManager\");\n        let states = self.states.read().await;\n        for (tenant_id, state) in states.iter() {\n            self.persister.save(tenant_id, state).await.map_err(|e| {\n                tracing::error!(\"Failed to persist state for tenant {}: {}\", tenant_id, e);\n                SyncError::Persistence(e.to_string())\n            })?;\n        }\n        tracing::info!(\"SyncManager states persisted successfully\");\n        Ok(())\n    }\n\n    #[tracing::instrument(skip(self))]\n    pub async fn scheduled_sync(\n        \u0026self,\n        ctx: TenantContext,\n        staleness_threshold_mins: u32,\n    ) -\u003e Result\u003c()\u003e {\n        if let Some(trigger) = self\n            .check_triggers(ctx.clone(), staleness_threshold_mins)\n            .await?\n        {\n            tracing::info!(\"Scheduled sync triggered by {:?}\", trigger);\n            self.run_sync_cycle(ctx, staleness_threshold_mins as u64)\n                .await?;\n        }\n        Ok(())\n    }\n}\n\nimpl SyncManager {\n    #[tracing::instrument(skip(self))]\n    pub async fn run_sync_cycle(\u0026self, ctx: TenantContext, interval_secs: u64) -\u003e Result\u003c()\u003e {\n        if self.deployment_config.mode == \"hybrid\" \u0026\u0026 !self.deployment_config.sync_enabled {\n            tracing::info!(\"Sync disabled in Hybrid mode for tenant: {}\", ctx.tenant_id);\n            return Ok(());\n        }\n\n        if let Some(trigger) = self\n            .check_triggers(ctx.clone(), (interval_secs / 60) as u32)\n            .await?\n        {\n            tracing::info!(\"Sync triggered by {:?}\", trigger);\n\n            self.create_checkpoint(\u0026ctx.tenant_id).await?;\n\n            if let Some(fed_manager) = \u0026self.federation_manager {\n                let fed_start = std::time::Instant::now();\n                if let Err(e) = self\n                    .sync_federation(ctx.clone(), fed_manager.as_ref())\n                    .await\n                {\n                    tracing::error!(\"Federation sync failed, rolling back: {}\", e);\n                    metrics::counter!(\"sync.federation.failures\", 1);\n                    self.rollback(\u0026ctx.tenant_id).await?;\n                    return Err(e);\n                }\n                metrics::histogram!(\n                    \"sync.federation.duration_ms\",\n                    fed_start.elapsed().as_millis() as f64\n                );\n            }\n\n            let inc_start = std::time::Instant::now();\n            let mut retry_count = 0;\n            let max_retries = 3;\n            let mut sync_result = self.sync_incremental(ctx.clone()).await;\n\n            while let Err(e) = sync_result {\n                if retry_count \u003e= max_retries {\n                    tracing::error!(\n                        \"Incremental sync failed after {} retries, rolling back: {}\",\n                        max_retries,\n                        e\n                    );\n                    metrics::counter!(\"sync.incremental.failures\", 1);\n                    self.rollback(\u0026ctx.tenant_id).await?;\n                    return Err(e);\n                }\n\n                retry_count += 1;\n                let backoff_ms = 100 * 2u64.pow(retry_count);\n                tracing::warn!(\n                    \"Sync failed, retrying in {}ms (attempt {}/{}): {}\",\n                    backoff_ms,\n                    retry_count,\n                    max_retries,\n                    e\n                );\n                tokio::time::sleep(std::time::Duration::from_millis(backoff_ms)).await;\n                sync_result = self.sync_incremental(ctx.clone()).await;\n            }\n\n            metrics::histogram!(\n                \"sync.incremental.duration_ms\",\n                inc_start.elapsed().as_millis() as f64\n            );\n\n            self.prune_failed_items(ctx.clone(), 30).await?;\n\n            let conflicts = self.detect_conflicts(ctx.clone()).await?;\n            if !conflicts.is_empty() {\n                tracing::info!(\"Found {} conflicts during sync cycle\", conflicts.len());\n                metrics::counter!(\"sync.conflicts.detected\", conflicts.len() as u64);\n                let mut state = self.get_or_load_state(\u0026ctx.tenant_id).await?;\n                state.stats.total_conflicts += conflicts.len() as u64;\n                self.update_state(\u0026ctx.tenant_id, state).await;\n\n                let tenant_id = ctx.tenant_id.clone();\n                if let Err(e) = self.resolve_conflicts(ctx, conflicts).await {\n                    tracing::error!(\"Conflict resolution failed, rolling back: {}\", e);\n                    metrics::counter!(\"sync.conflicts.resolution_failures\", 1);\n                    self.rollback(\u0026tenant_id).await?;\n                    return Err(e);\n                }\n                metrics::counter!(\"sync.conflicts.resolved\", 1);\n            }\n        }\n\n        Ok(())\n    }\n\n    pub async fn create_checkpoint(\u0026self, tenant_id: \u0026mk_core::types::TenantId) -\u003e Result\u003c()\u003e {\n        let mut checkpoints = self.checkpoints.write().await;\n        let state = self.get_or_load_state(tenant_id).await?;\n        checkpoints.insert(tenant_id.clone(), state);\n        tracing::debug!(\"Sync checkpoint created for tenant: {}\", tenant_id);\n        Ok(())\n    }\n\n    pub async fn rollback(\u0026self, tenant_id: \u0026mk_core::types::TenantId) -\u003e Result\u003c()\u003e {\n        let mut checkpoints = self.checkpoints.write().await;\n        if let Some(old_state) = checkpoints.remove(tenant_id) {\n            let mut states = self.states.write().await;\n            states.insert(tenant_id.clone(), old_state.clone());\n            self.persister\n                .save(tenant_id, \u0026old_state)\n                .await\n                .map_err(|e| {\n                    metrics::counter!(\"sync.persistence.rollback_failures\", 1);\n                    SyncError::Persistence(e.to_string())\n                })?;\n            tracing::info!(\n                \"Sync state rolled back to checkpoint for tenant: {}\",\n                tenant_id\n            );\n            Ok(())\n        } else {\n            tracing::warn!(\n                \"Rollback requested but no checkpoint found for tenant: {}\",\n                tenant_id\n            );\n            Ok(())\n        }\n    }\n\n    pub async fn sync_federation(\n        \u0026self,\n        ctx: TenantContext,\n        fed: \u0026dyn FederationProvider,\n    ) -\u003e Result\u003c()\u003e {\n        tracing::info!(\"Starting federation sync for tenant: {}\", ctx.tenant_id);\n        let mut state = self.get_or_load_state(\u0026ctx.tenant_id).await?;\n        let upstreams = fed.config().upstreams.clone();\n\n        for upstream in upstreams {\n            let upstream_id = upstream.id.clone();\n\n            let target_path = self\n                .knowledge_repo\n                .root_path()\n                .unwrap_or_else(|| std::path::PathBuf::from(\"data/knowledge\"))\n                .join(\"federated\")\n                .join(\u0026upstream_id);\n\n            match fed.sync_upstream(\u0026upstream_id, \u0026target_path).await {\n                Ok(_) =\u003e {\n                    tracing::info!(\"Successfully synced upstream: {}\", upstream_id);\n                    state\n                        .federation_conflicts\n                        .retain(|c| c.upstream_id != upstream_id);\n                }\n                Err(knowledge::repository::RepositoryError::InvalidPath(msg))\n                    if msg.contains(\"conflict\") || msg.contains(\"upstream\") =\u003e\n                {\n                    tracing::error!(\"Federation conflict for upstream {}: {}\", upstream_id, msg);\n                    state\n                        .federation_conflicts\n                        .retain(|c| c.upstream_id != upstream_id);\n                    state.federation_conflicts.push(FederationConflict {\n                        upstream_id: upstream_id.clone(),\n                        reason: msg,\n                        detected_at: chrono::Utc::now().timestamp(),\n                    });\n                }\n                Err(e) =\u003e {\n                    tracing::error!(\"Error syncing upstream {}: {}\", upstream_id, e);\n                }\n            }\n        }\n\n        self.persister\n            .save(\u0026ctx.tenant_id, \u0026state)\n            .await\n            .map_err(|e| SyncError::Persistence(e.to_string()))?;\n        self.update_state(\u0026ctx.tenant_id, state).await;\n        Ok(())\n    }\n\n    pub async fn get_state(\u0026self, tenant_id: \u0026mk_core::types::TenantId) -\u003e Result\u003cSyncState\u003e {\n        self.get_or_load_state(tenant_id).await\n    }\n\n    #[tracing::instrument(skip(self))]\n    pub async fn sync_incremental(\u0026self, ctx: TenantContext) -\u003e Result\u003c()\u003e {\n        let mut state = self.get_or_load_state(\u0026ctx.tenant_id).await?;\n        let start_time = std::time::Instant::now();\n\n        let last_commit = match \u0026state.last_knowledge_commit {\n            Some(c) =\u003e c.clone(),\n            None =\u003e return self.sync_all_internal(ctx, \u0026mut state, start_time).await,\n        };\n\n        let head_commit = self.knowledge_repo.get_head_commit(ctx.clone()).await?;\n        if let Some(head) = \u0026head_commit\n            \u0026\u0026 head == \u0026last_commit\n        {\n            return Ok(());\n        }\n\n        let mut sync_errors = Vec::new();\n        let affected_items = self\n            .knowledge_repo\n            .get_affected_items(ctx.clone(), \u0026last_commit)\n            .await?;\n\n        for (layer, path) in affected_items {\n            let entry = match self.knowledge_repo.get(ctx.clone(), layer, \u0026path).await {\n                Ok(Some(e)) =\u003e e,\n                Ok(None) =\u003e {\n                    if let Some(memory_id) = self.find_memory_id_by_knowledge_id(\u0026path, \u0026state) {\n                        self.memory_manager\n                            .delete_from_layer(ctx.clone(), map_layer(layer), \u0026memory_id)\n                            .await?;\n                        state.knowledge_hashes.remove(\u0026path);\n                        state.pointer_mapping.remove(\u0026memory_id);\n                        state.knowledge_layers.remove(\u0026path);\n                    }\n                    continue;\n                }\n                Err(e) =\u003e {\n                    sync_errors.push(SyncFailure {\n                        knowledge_id: path,\n                        error: e.to_string(),\n                        failed_at: chrono::Utc::now().timestamp(),\n                        retry_count: 0,\n                    });\n                    continue;\n                }\n            };\n\n            if let Err(e) = self.sync_entry(ctx.clone(), \u0026entry, \u0026mut state).await {\n                sync_errors.push(SyncFailure {\n                    knowledge_id: entry.path.clone(),\n                    error: e.to_string(),\n                    failed_at: chrono::Utc::now().timestamp(),\n                    retry_count: 0,\n                });\n            }\n        }\n\n        state.last_sync_at = Some(chrono::Utc::now().timestamp());\n        state.last_knowledge_commit = head_commit;\n        state.failed_items.extend(sync_errors);\n        state.stats.total_syncs += 1;\n        let duration = start_time.elapsed().as_millis() as u64;\n        state.stats.avg_sync_duration_ms = duration;\n\n        metrics::counter!(\"sync.cycles.total\", 1);\n        metrics::histogram!(\"sync.cycle.duration_ms\", duration as f64);\n        metrics::gauge!(\"sync.items.failed\", state.failed_items.len() as f64);\n\n        self.persister\n            .save(\u0026ctx.tenant_id, \u0026state)\n            .await\n            .map_err(|e| SyncError::Persistence(e.to_string()))?;\n        self.update_state(\u0026ctx.tenant_id, state).await;\n\n        Ok(())\n    }\n\n    #[tracing::instrument(skip(self))]\n    pub async fn sync_all(\u0026self, ctx: TenantContext) -\u003e Result\u003c()\u003e {\n        let mut state = self.get_or_load_state(\u0026ctx.tenant_id).await?;\n        let start_time = std::time::Instant::now();\n        self.sync_all_internal(ctx, \u0026mut state, start_time).await\n    }\n\n    async fn sync_all_internal(\n        \u0026self,\n        ctx: TenantContext,\n        state: \u0026mut SyncState,\n        start_time: std::time::Instant,\n    ) -\u003e Result\u003c()\u003e {\n        let head_commit = self.knowledge_repo.get_head_commit(ctx.clone()).await?;\n        let mut sync_errors = Vec::new();\n\n        for layer in [\n            mk_core::types::KnowledgeLayer::Company,\n            mk_core::types::KnowledgeLayer::Org,\n            mk_core::types::KnowledgeLayer::Team,\n            mk_core::types::KnowledgeLayer::Project,\n        ] {\n            let entries = match self.knowledge_repo.list(ctx.clone(), layer, \"\").await {\n                Ok(e) =\u003e e,\n                Err(e) =\u003e {\n                    sync_errors.push(SyncFailure {\n                        knowledge_id: format!(\"layer:{layer:?}\"),\n                        error: e.to_string(),\n                        failed_at: chrono::Utc::now().timestamp(),\n                        retry_count: 0,\n                    });\n                    continue;\n                }\n            };\n\n            for entry in entries {\n                if let Err(e) = self.sync_entry(ctx.clone(), \u0026entry, state).await {\n                    sync_errors.push(SyncFailure {\n                        knowledge_id: entry.path.clone(),\n                        error: e.to_string(),\n                        failed_at: chrono::Utc::now().timestamp(),\n                        retry_count: 0,\n                    });\n                }\n            }\n        }\n\n        state.last_sync_at = Some(chrono::Utc::now().timestamp());\n        state.last_knowledge_commit = head_commit;\n        state.failed_items.extend(sync_errors);\n        state.stats.total_syncs += 1;\n        let duration = start_time.elapsed().as_millis() as u64;\n        state.stats.avg_sync_duration_ms = duration;\n\n        metrics::counter!(\"sync.cycles.total\", 1);\n        metrics::histogram!(\"sync.cycle.duration_ms\", duration as f64);\n        metrics::gauge!(\"sync.items.failed\", state.failed_items.len() as f64);\n\n        self.persister\n            .save(\u0026ctx.tenant_id, state)\n            .await\n            .map_err(|e| SyncError::Persistence(e.to_string()))?;\n\n        self.update_state(\u0026ctx.tenant_id, state.clone()).await;\n\n        Ok(())\n    }\n\n    pub async fn check_triggers(\n        \u0026self,\n        ctx: TenantContext,\n        staleness_threshold_mins: u32,\n    ) -\u003e Result\u003cOption\u003cSyncTrigger\u003e\u003e {\n        if self.deployment_config.mode == \"remote\" {\n            return Ok(Some(SyncTrigger::Manual));\n        }\n\n        let state = self.get_or_load_state(\u0026ctx.tenant_id).await?;\n\n        let head_commit = self.knowledge_repo.get_head_commit(ctx).await?;\n        if let Some(head) = head_commit {\n            if let Some(last) = \u0026state.last_knowledge_commit {\n                if head != *last {\n                    return Ok(Some(SyncTrigger::CommitMismatch {\n                        last_commit: last.clone(),\n                        head_commit: head,\n                    }));\n                }\n            } else {\n                return Ok(Some(SyncTrigger::CommitMismatch {\n                    last_commit: \"none\".to_string(),\n                    head_commit: head,\n                }));\n            }\n        }\n\n        if let Some(last_sync) = state.last_sync_at {\n            let now = chrono::Utc::now().timestamp();\n            let elapsed_mins = (now - last_sync) / 60;\n            if elapsed_mins \u003e= staleness_threshold_mins as i64 {\n                return Ok(Some(SyncTrigger::Staleness {\n                    last_sync_at: last_sync,\n                    threshold_mins: staleness_threshold_mins,\n                }));\n            }\n        } else {\n            return Ok(Some(SyncTrigger::Manual));\n        }\n\n        Ok(None)\n    }\n\n    pub async fn resolve_federation_conflict(\n        \u0026self,\n        tenant_id: mk_core::types::TenantId,\n        upstream_id: \u0026str,\n        resolution: \u0026str,\n    ) -\u003e Result\u003c()\u003e {\n        let mut state = self.get_or_load_state(\u0026tenant_id).await?;\n\n        state\n            .federation_conflicts\n            .retain(|c| c.upstream_id != upstream_id);\n\n        tracing::info!(\n            \"Resolved federation conflict for tenant {} upstream {}: {}\",\n            tenant_id,\n            upstream_id,\n            resolution\n        );\n\n        self.persister\n            .save(\u0026tenant_id, \u0026state)\n            .await\n            .map_err(|e| SyncError::Persistence(e.to_string()))?;\n        self.update_state(\u0026tenant_id, state).await;\n        Ok(())\n    }\n\n    pub async fn resolve_conflicts(\n        \u0026self,\n        ctx: TenantContext,\n        conflicts: Vec\u003cSyncConflict\u003e,\n    ) -\u003e Result\u003c()\u003e {\n        let mut state = self.get_or_load_state(\u0026ctx.tenant_id).await?;\n\n        for conflict in conflicts {\n            match conflict {\n                SyncConflict::HashMismatch { knowledge_id, .. }\n                | SyncConflict::MissingPointer { knowledge_id, .. } =\u003e {\n                    state.knowledge_hashes.remove(\u0026knowledge_id);\n                    let layer = state\n                        .knowledge_layers\n                        .get(\u0026knowledge_id)\n                        .cloned()\n                        .unwrap_or(mk_core::types::KnowledgeLayer::Company);\n                    if let Some(entry) = self\n                        .knowledge_repo\n                        .get(ctx.clone(), layer, \u0026knowledge_id)\n                        .await?\n                    {\n                        self.sync_entry(ctx.clone(), \u0026entry, \u0026mut state).await?;\n                        metrics::counter!(\"sync.conflicts.resolved.hash_mismatch\", 1);\n                    }\n                }\n                SyncConflict::OrphanedPointer {\n                    memory_id,\n                    knowledge_id,\n                } =\u003e {\n                    for layer in [\n                        mk_core::types::MemoryLayer::Company,\n                        mk_core::types::MemoryLayer::Org,\n                        mk_core::types::MemoryLayer::Team,\n                        mk_core::types::MemoryLayer::Project,\n                    ] {\n                        let _ = self\n                            .memory_manager\n                            .delete_from_layer(ctx.clone(), layer, \u0026memory_id)\n                            .await;\n                    }\n                    state.knowledge_hashes.remove(\u0026knowledge_id);\n                    state.pointer_mapping.remove(\u0026memory_id);\n                    state.knowledge_layers.remove(\u0026knowledge_id);\n                    metrics::counter!(\"sync.conflicts.resolved.orphaned\", 1);\n                }\n                SyncConflict::DuplicatePointer {\n                    knowledge_id,\n                    mut memory_ids,\n                } =\u003e {\n                    memory_ids.sort();\n                    let _to_keep = memory_ids.remove(0);\n\n                    for mid in memory_ids {\n                        for layer in [\n                            mk_core::types::MemoryLayer::Company,\n                            mk_core::types::MemoryLayer::Org,\n                            mk_core::types::MemoryLayer::Team,\n                            mk_core::types::MemoryLayer::Project,\n                        ] {\n                            let _ = self\n                                .memory_manager\n                                .delete_from_layer(ctx.clone(), layer, \u0026mid)\n                                .await;\n                        }\n                        state.pointer_mapping.remove(\u0026mid);\n                    }\n\n                    let layer = state\n                        .knowledge_layers\n                        .get(\u0026knowledge_id)\n                        .cloned()\n                        .unwrap_or(mk_core::types::KnowledgeLayer::Company);\n                    if let Some(entry) = self\n                        .knowledge_repo\n                        .get(ctx.clone(), layer, \u0026knowledge_id)\n                        .await?\n                    {\n                        self.sync_entry(ctx.clone(), \u0026entry, \u0026mut state).await?;\n                    }\n                    metrics::counter!(\"sync.conflicts.resolved.duplicate\", 1);\n                }\n                SyncConflict::StatusChange {\n                    knowledge_id,\n                    memory_id,\n                    ..\n                } =\u003e {\n                    let layer = state\n                        .knowledge_layers\n                        .get(\u0026knowledge_id)\n                        .cloned()\n                        .unwrap_or(mk_core::types::KnowledgeLayer::Company);\n                    if let Some(entry) = self\n                        .knowledge_repo\n                        .get(ctx.clone(), layer, \u0026knowledge_id)\n                        .await?\n                    {\n                        self.sync_entry(ctx.clone(), \u0026entry, \u0026mut state).await?;\n                    }\n                    tracing::info!(\n                        \"Resolved status_change conflict for {} (memory: {})\",\n                        knowledge_id,\n                        memory_id\n                    );\n                    metrics::counter!(\"sync.conflicts.resolved.status_change\", 1);\n                }\n                SyncConflict::LayerMismatch {\n                    knowledge_id,\n                    memory_id,\n                    expected_layer,\n                    actual_layer,\n                } =\u003e {\n                    let old_memory_layer = map_layer(expected_layer);\n                    let _ = self\n                        .memory_manager\n                        .delete_from_layer(ctx.clone(), old_memory_layer, \u0026memory_id)\n                        .await;\n\n                    state.knowledge_hashes.remove(\u0026knowledge_id);\n                    state.pointer_mapping.remove(\u0026memory_id);\n                    state.knowledge_layers.remove(\u0026knowledge_id);\n\n                    if let Some(entry) = self\n                        .knowledge_repo\n                        .get(ctx.clone(), actual_layer, \u0026knowledge_id)\n                        .await?\n                    {\n                        self.sync_entry(ctx.clone(), \u0026entry, \u0026mut state).await?;\n                    }\n\n                    tracing::info!(\n                        \"Resolved layer_mismatch conflict for {}: {:?} -\u003e {:?}\",\n                        knowledge_id,\n                        expected_layer,\n                        actual_layer\n                    );\n                    metrics::counter!(\"sync.conflicts.resolved.layer_mismatch\", 1);\n                }\n                SyncConflict::DetectionError { target_id, error } =\u003e {\n                    tracing::warn!(\n                        \"Skipping resolution for detection error on {}: {}\",\n                        target_id,\n                        error\n                    );\n                }\n            }\n        }\n\n        self.persister\n            .save(\u0026ctx.tenant_id, \u0026state)\n            .await\n            .map_err(|e| SyncError::Persistence(e.to_string()))?;\n        self.update_state(\u0026ctx.tenant_id, state).await;\n        Ok(())\n    }\n\n    pub async fn detect_conflicts(\u0026self, ctx: TenantContext) -\u003e Result\u003cVec\u003cSyncConflict\u003e\u003e {\n        let state = self.get_or_load_state(\u0026ctx.tenant_id).await?;\n        let mut conflicts = Vec::new();\n\n        let mut knowledge_to_memories: HashMap\u003cString, Vec\u003cString\u003e\u003e = HashMap::new();\n        for (memory_id, knowledge_id) in \u0026state.pointer_mapping {\n            knowledge_to_memories\n                .entry(knowledge_id.clone())\n                .or_default()\n                .push(memory_id.clone());\n        }\n\n        for (knowledge_id, memory_ids) in knowledge_to_memories {\n            if memory_ids.len() \u003e 1 {\n                conflicts.push(SyncConflict::DuplicatePointer {\n                    knowledge_id,\n                    memory_ids,\n                });\n            }\n        }\n\n        for (memory_id, knowledge_id) in \u0026state.pointer_mapping {\n            println!(\n                \"Checking pointer mapping: {} -\u003e {}\",\n                memory_id, knowledge_id\n            );\n            let layer = state\n                .knowledge_layers\n                .get(knowledge_id)\n                .cloned()\n                .unwrap_or(mk_core::types::KnowledgeLayer::Company);\n            println!(\"Expected layer for {}: {:?}\", knowledge_id, layer);\n\n            let entry_res = self\n                .knowledge_repo\n                .get(ctx.clone(), layer, knowledge_id)\n                .await;\n            if let Ok(Some(ref entry)) = entry_res {\n                println!(\n                    \"Got entry from repo: {:?} at layer {:?}\",\n                    entry.path, entry.layer\n                );\n            } else if let Ok(None) = entry_res {\n                println!(\"Entry not found in repo at layer {:?}\", layer);\n            } else if let Err(ref e) = entry_res {\n                println!(\"Error getting entry from repo: {}\", e);\n            }\n\n            match entry_res {\n                Ok(Some(k_entry)) =\u003e {\n                    let expected_hash = state.knowledge_hashes.get(knowledge_id);\n                    let actual_hash = utils::compute_content_hash(\u0026k_entry.content);\n\n                    if let Some(exp) = expected_hash\n                        \u0026\u0026 exp != \u0026actual_hash\n                    {\n                        conflicts.push(SyncConflict::HashMismatch {\n                            knowledge_id: knowledge_id.clone(),\n                            memory_id: memory_id.clone(),\n                            expected_hash: exp.clone(),\n                            actual_hash,\n                        });\n                    }\n\n                    if k_entry.status == mk_core::types::KnowledgeStatus::Deprecated\n                        || k_entry.status == mk_core::types::KnowledgeStatus::Superseded\n                    {\n                        conflicts.push(SyncConflict::StatusChange {\n                            knowledge_id: knowledge_id.clone(),\n                            memory_id: memory_id.clone(),\n                            new_status: k_entry.status,\n                        });\n                    }\n\n                    if k_entry.layer != layer {\n                        conflicts.push(SyncConflict::LayerMismatch {\n                            knowledge_id: knowledge_id.clone(),\n                            memory_id: memory_id.clone(),\n                            expected_layer: layer,\n                            actual_layer: k_entry.layer,\n                        });\n                    }\n\n                    let m_layer = map_layer(k_entry.layer);\n                    match self\n                        .memory_manager\n                        .get_from_layer(ctx.clone(), m_layer, memory_id)\n                        .await\n                    {\n                        Ok(None) =\u003e {\n                            conflicts.push(SyncConflict::MissingPointer {\n                                knowledge_id: knowledge_id.clone(),\n                                expected_memory_id: memory_id.clone(),\n                            });\n                        }\n                        Ok(Some(m_entry)) =\u003e {\n                            let mut content = k_entry.content.clone();\n                            content = utils::redact_pii(\u0026content);\n                            let expected_content =\n                                self.generate_summary_internal(\u0026k_entry, \u0026content);\n                            if m_entry.content != expected_content {\n                                conflicts.push(SyncConflict::HashMismatch {\n                                    knowledge_id: knowledge_id.clone(),\n                                    memory_id: memory_id.clone(),\n                                    expected_hash: \"summary_mismatch\".to_string(),\n                                    actual_hash: \"summary_mismatch\".to_string(),\n                                });\n                            }\n                        }\n                        Err(e) =\u003e {\n                            conflicts.push(SyncConflict::DetectionError {\n                                target_id: memory_id.clone(),\n                                error: e.to_string(),\n                            });\n                            tracing::warn!(\"Failed to check memory entry {}: {}\", memory_id, e)\n                        }\n                    }\n                }\n                Ok(None) =\u003e {\n                    let mut found_elsewhere = false;\n                    for other_layer in [\n                        mk_core::types::KnowledgeLayer::Company,\n                        mk_core::types::KnowledgeLayer::Org,\n                        mk_core::types::KnowledgeLayer::Team,\n                        mk_core::types::KnowledgeLayer::Project,\n                    ] {\n                        if other_layer == layer {\n                            continue;\n                        }\n\n                        if let Ok(Some(_actual_entry)) = self\n                            .knowledge_repo\n                            .get(ctx.clone(), other_layer, knowledge_id)\n                            .await\n                        {\n                            conflicts.push(SyncConflict::LayerMismatch {\n                                knowledge_id: knowledge_id.clone(),\n                                memory_id: memory_id.clone(),\n                                expected_layer: layer,\n                                actual_layer: other_layer,\n                            });\n                            found_elsewhere = true;\n                            break;\n                        }\n                    }\n\n                    if !found_elsewhere {\n                        conflicts.push(SyncConflict::OrphanedPointer {\n                            memory_id: memory_id.clone(),\n                            knowledge_id: knowledge_id.clone(),\n                        });\n                    }\n                }\n                Err(e) =\u003e {\n                    conflicts.push(SyncConflict::DetectionError {\n                        target_id: knowledge_id.clone(),\n                        error: e.to_string(),\n                    });\n                    tracing::error!(\n                        \"Error fetching knowledge {} for conflict detection: {}\",\n                        knowledge_id,\n                        e\n                    )\n                }\n            }\n        }\n\n        Ok(conflicts)\n    }\n\n    fn find_memory_id_by_knowledge_id(\n        \u0026self,\n        knowledge_id: \u0026str,\n        state: \u0026SyncState,\n    ) -\u003e Option\u003cString\u003e {\n        state\n            .pointer_mapping\n            .iter()\n            .find(|(_, kid)| *kid == knowledge_id)\n            .map(|(mid, _)| mid.clone())\n    }\n\n    pub async fn sync_entry(\n        \u0026self,\n        ctx: TenantContext,\n        entry: \u0026KnowledgeEntry,\n        state: \u0026mut SyncState,\n    ) -\u003e Result\u003c()\u003e {\n        let mut content = entry.content.clone();\n        content = utils::redact_pii(\u0026content);\n\n        let mut context = HashMap::new();\n        context.insert(\"path\".to_string(), serde_json::json!(entry.path));\n        context.insert(\"content\".to_string(), serde_json::json!(content));\n\n        if self.deployment_config.mode == \"hybrid\" || self.deployment_config.mode == \"remote\" {\n            if let Some(client) = \u0026self.governance_client {\n                let validation = client\n                    .validate(\u0026ctx, entry.layer, \u0026context)\n                    .await\n                    .map_err(|e| SyncError::Internal(format!(\"Remote validation failed: {}\", e)))?;\n\n                if !validation.is_valid {\n                    state.stats.total_governance_blocks += 1;\n                    metrics::counter!(\"sync.governance.blocks\", 1);\n                    for violation in validation.violations {\n                        if violation.severity == mk_core::types::ConstraintSeverity::Block {\n                            state.failed_items.push(SyncFailure {\n                                knowledge_id: entry.path.clone(),\n                                error: format!(\n                                    \"Remote governance violation (BLOCK): {}\",\n                                    violation.message\n                                ),\n                                failed_at: chrono::Utc::now().timestamp(),\n                                retry_count: 0,\n                            });\n                            return Err(SyncError::GovernanceBlock(violation.message));\n                        }\n                        tracing::warn!(\n                            \"Remote governance violation ({:?}) for {}: {}\",\n                            violation.severity,\n                            entry.path,\n                            violation.message\n                        );\n                    }\n                }\n            }\n        }\n\n        if self.deployment_config.mode != \"remote\" {\n            let validation = self.governance_engine.validate(entry.layer, \u0026context);\n            if !validation.is_valid {\n                state.stats.total_governance_blocks += 1;\n                metrics::counter!(\"sync.governance.blocks\", 1);\n                for violation in validation.violations {\n                    if violation.severity == mk_core::types::ConstraintSeverity::Block {\n                        state.failed_items.push(SyncFailure {\n                            knowledge_id: entry.path.clone(),\n                            error: format!(\"Governance violation (BLOCK): {}\", violation.message),\n                            failed_at: chrono::Utc::now().timestamp(),\n                            retry_count: 0,\n                        });\n                        return Err(SyncError::GovernanceBlock(violation.message));\n                    }\n                    tracing::warn!(\n                        \"Governance violation ({:?}) for {}: {}\",\n                        violation.severity,\n                        entry.path,\n                        violation.message\n                    );\n                }\n            }\n        }\n\n        let content_hash = utils::compute_content_hash(\u0026content);\n        let knowledge_id = \u0026entry.path;\n\n        if let Some(prev_hash) = state.knowledge_hashes.get(knowledge_id)\n            \u0026\u0026 prev_hash == \u0026content_hash\n        {\n            return Ok(());\n        }\n\n        let memory_layer = map_layer(entry.layer);\n        let pointer = KnowledgePointer {\n            source_type: entry.kind,\n            source_id: knowledge_id.clone(),\n            content_hash: content_hash.clone(),\n            synced_at: chrono::Utc::now().timestamp(),\n            source_layer: entry.layer,\n            is_orphaned: false,\n        };\n\n        let metadata = KnowledgePointerMetadata {\n            kind: \"knowledge_pointer\".to_string(),\n            knowledge_pointer: pointer,\n            tags: Vec::new(),\n        };\n\n        let metadata_map = match serde_json::to_value(metadata)? {\n            serde_json::Value::Object(map) =\u003e {\n                let mut hmap = HashMap::new();\n                for (k, v) in map {\n                    hmap.insert(k, v);\n                }\n                hmap\n            }\n            _ =\u003e {\n                return Err(SyncError::Internal(\n                    \"Failed to serialize metadata\".to_string(),\n                ));\n            }\n        };\n\n        let memory_entry = MemoryEntry {\n            id: format!(\"ptr_{knowledge_id}\"),\n            content: self.generate_summary_internal(entry, \u0026content),\n            embedding: None,\n            layer: memory_layer,\n            metadata: metadata_map,\n            created_at: chrono::Utc::now().timestamp(),\n            updated_at: chrono::Utc::now().timestamp(),\n        };\n\n        self.memory_manager\n            .add_to_layer(ctx, memory_layer, memory_entry)\n            .await?;\n\n        tracing::info!(\"Synced entry: {}\", entry.path);\n\n        state\n            .knowledge_hashes\n            .insert(knowledge_id.clone(), content_hash);\n        state\n            .pointer_mapping\n            .insert(format!(\"ptr_{knowledge_id}\"), knowledge_id.clone());\n        state\n            .knowledge_layers\n            .insert(knowledge_id.clone(), entry.layer);\n        state.stats.total_items_synced += 1;\n        metrics::counter!(\"sync.items.synced\", 1);\n\n        Ok(())\n    }\n\n    pub fn generate_summary(\u0026self, entry: \u0026KnowledgeEntry) -\u003e String {\n        self.generate_summary_internal(entry, \u0026entry.content)\n    }\n\n    fn generate_summary_internal(\u0026self, entry: \u0026KnowledgeEntry, content: \u0026str) -\u003e String {\n        let mut summary = format!(\n            \"[{:?}] [{:?}] {}\\n\\n{}\",\n            entry.kind,\n            entry.status,\n            entry.path,\n            content.lines().next().unwrap_or(\"\")\n        );\n\n        let mut context = HashMap::new();\n        context.insert(\"path\".to_string(), serde_json::json!(entry.path));\n        context.insert(\"content\".to_string(), serde_json::json!(content));\n\n        let validation = self.governance_engine.validate(entry.layer, \u0026context);\n        if !validation.is_valid {\n            let blocks: Vec\u003c_\u003e = validation\n                .violations\n                .iter()\n                .filter(|v| v.severity == mk_core::types::ConstraintSeverity::Block)\n                .map(|v| v.message.as_str())\n                .collect();\n\n            if !blocks.is_empty() {\n                summary.push_str(\"\\n\\nGOVERNANCE BLOCKS:\\n- \");\n                summary.push_str(\u0026blocks.join(\"\\n- \"));\n            }\n        }\n\n        summary\n    }\n\n    pub async fn prune_failed_items(\u0026self, ctx: TenantContext, days_old: i64) -\u003e Result\u003c()\u003e {\n        let mut state = self.get_or_load_state(\u0026ctx.tenant_id).await?;\n        let now = chrono::Utc::now().timestamp();\n        let threshold = days_old * 24 * 60 * 60;\n\n        let before_count = state.failed_items.len();\n        state\n            .failed_items\n            .retain(|f| (now - f.failed_at) \u003c threshold);\n\n        let pruned = before_count - state.failed_items.len();\n        if pruned \u003e 0 {\n            tracing::info!(\n                \"Pruned {} failed items older than {} days for tenant: {}\",\n                pruned,\n                days_old,\n                ctx.tenant_id\n            );\n            self.persister\n                .save(\u0026ctx.tenant_id, \u0026state)\n                .await\n                .map_err(|e| SyncError::Persistence(e.to_string()))?;\n            self.update_state(\u0026ctx.tenant_id, state).await;\n        }\n\n        Ok(())\n    }\n\n    pub fn find_memory_id_by_knowledge_id_for_test(\n        \u0026self,\n        knowledge_id: \u0026str,\n        state: \u0026SyncState,\n    ) -\u003e Option\u003cString\u003e {\n        self.find_memory_id_by_knowledge_id(knowledge_id, state)\n    }\n\n    pub async fn detect_delta(\u0026self, ctx: TenantContext, state: \u0026SyncState) -\u003e Result\u003cDeltaResult\u003e {\n        let mut delta = DeltaResult::default();\n        let layers = [\n            KnowledgeLayer::Company,\n            KnowledgeLayer::Org,\n            KnowledgeLayer::Team,\n            KnowledgeLayer::Project,\n        ];\n\n        for layer in layers {\n            let entries = self.knowledge_repo.list(ctx.clone(), layer, \"\").await?;\n            for entry in entries {\n                let knowledge_id = \u0026entry.path;\n                let content_hash = utils::compute_content_hash(\u0026utils::redact_pii(\u0026entry.content));\n\n                match state.knowledge_hashes.get(knowledge_id) {\n                    Some(prev_hash) if prev_hash == \u0026content_hash =\u003e {\n                        delta.unchanged.push(knowledge_id.clone());\n                    }\n                    Some(_) =\u003e {\n                        delta.updated.push(entry);\n                    }\n                    None =\u003e {\n                        delta.added.push(entry);\n                    }\n                }\n            }\n        }\n\n        for (knowledge_id, _) in \u0026state.knowledge_hashes {\n            if !delta.unchanged.contains(knowledge_id)\n                \u0026\u0026 !delta.updated.iter().any(|e| \u0026e.path == knowledge_id)\n            {\n                delta.deleted.push(knowledge_id.clone());\n            }\n        }\n\n        Ok(delta)\n    }\n\n    #[tracing::instrument(skip(self, rx))]\n    pub async fn start_background_sync(\n        self: Arc\u003cSelf\u003e,\n        ctx: TenantContext,\n        interval_secs: u64,\n        staleness_threshold_mins: u32,\n        mut rx: tokio::sync::watch::Receiver\u003cbool\u003e,\n    ) -\u003e tokio::task::JoinHandle\u003c()\u003e {\n        tokio::spawn(async move {\n            let mut interval = tokio::time::interval(std::time::Duration::from_secs(interval_secs));\n            loop {\n                tokio::select! {\n                    _ = interval.tick() =\u003e {\n                        if let Err(e) = self.run_sync_cycle(ctx.clone(), staleness_threshold_mins as u64).await {\n                            metrics::counter!(\"sync.background.errors\", 1);\n                            tracing::error!(\"Background sync error for tenant {}: {}\", ctx.tenant_id, e);\n                        }\n                    }\n                    _ = rx.changed() =\u003e {\n                        if *rx.borrow() {\n                            tracing::info!(\"Background sync shutting down for tenant: {}\", ctx.tenant_id);\n                            break;\n                        }\n                    }\n                }\n            }\n        })\n    }\n}\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::TenantId;\n    use mk_core::types::{KnowledgeEntry, KnowledgeLayer, KnowledgeStatus, KnowledgeType};\n    use std::collections::HashMap;\n    use std::time::Instant;\n\n    struct MockPersister;\n    #[async_trait::async_trait]\n    impl SyncStatePersister for MockPersister {\n        async fn load(\n            \u0026self,\n            _tenant_id: \u0026mk_core::types::TenantId,\n        ) -\u003e std::result::Result\u003cSyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n            Ok(SyncState::default())\n        }\n        async fn save(\n            \u0026self,\n            _tenant_id: \u0026mk_core::types::TenantId,\n            _s: \u0026SyncState,\n        ) -\u003e std::result::Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n            Ok(())\n        }\n    }\n\n    struct MockKnowledgeRepository;\n    impl MockKnowledgeRepository {\n        fn new() -\u003e Self {\n            Self\n        }\n    }\n    #[async_trait::async_trait]\n    impl KnowledgeRepository for MockKnowledgeRepository {\n        type Error = knowledge::repository::RepositoryError;\n        async fn store(\n            \u0026self,\n            _ctx: TenantContext,\n            _e: KnowledgeEntry,\n            _m: \u0026str,\n        ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n            Ok(\"hash\".to_string())\n        }\n        async fn get(\n            \u0026self,\n            _ctx: TenantContext,\n            _l: KnowledgeLayer,\n            _p: \u0026str,\n        ) -\u003e std::result::Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(None)\n        }\n        async fn list(\n            \u0026self,\n            _ctx: TenantContext,\n            _l: KnowledgeLayer,\n            _p: \u0026str,\n        ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(Vec::new())\n        }\n        async fn delete(\n            \u0026self,\n            _ctx: TenantContext,\n            _l: KnowledgeLayer,\n            _p: \u0026str,\n            _m: \u0026str,\n        ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n            Ok(\"hash\".to_string())\n        }\n        async fn get_head_commit(\n            \u0026self,\n            _ctx: TenantContext,\n        ) -\u003e std::result::Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n            Ok(None)\n        }\n        async fn get_affected_items(\n            \u0026self,\n            _ctx: TenantContext,\n            _f: \u0026str,\n        ) -\u003e std::result::Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n            Ok(Vec::new())\n        }\n        async fn search(\n            \u0026self,\n            _ctx: TenantContext,\n            _q: \u0026str,\n            _l: Vec\u003cKnowledgeLayer\u003e,\n            _li: usize,\n        ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(Vec::new())\n        }\n        fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n            None\n        }\n    }\n\n    /// Helper to create a SyncManager with pre-populated state for a specific\n    /// tenant\n    fn create_sync_manager_with_state(\n        memory_manager: Arc\u003cMemoryManager\u003e,\n        knowledge_repo: Arc\u003c\n            dyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e,\n        \u003e,\n        state: SyncState,\n        tenant_id: \u0026mk_core::types::TenantId,\n    ) -\u003e SyncManager {\n        let mut states_map = HashMap::new();\n        states_map.insert(tenant_id.clone(), state);\n        SyncManager {\n            memory_manager,\n            knowledge_repo,\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(states_map)),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        }\n    }\n\n    #[test]\n    fn test_generate_summary() {\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let entry = KnowledgeEntry {\n            path: \"test.md\".to_string(),\n            content: \"First line\\nSecond line\\nThird line\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 1234567890,\n        };\n\n        let summary = sync_manager.generate_summary(\u0026entry);\n        assert_eq!(summary, \"[Spec] [Accepted] test.md\\n\\nFirst line\");\n    }\n\n    #[tokio::test]\n    async fn test_generate_summary_empty_content() {\n        let _ctx = TenantContext::default();\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let entry = KnowledgeEntry {\n            path: \"empty.md\".to_string(),\n            content: \"\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Adr,\n            status: KnowledgeStatus::Draft,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 1234567890,\n        };\n\n        let summary = sync_manager.generate_summary(\u0026entry);\n        assert_eq!(summary, \"[Adr] [Draft] empty.md\\n\\n\");\n    }\n\n    #[test]\n    fn test_find_memory_id_by_knowledge_id() {\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let mut state = SyncState::default();\n        state\n            .pointer_mapping\n            .insert(\"ptr_test\".to_string(), \"test.md\".to_string());\n        state\n            .pointer_mapping\n            .insert(\"ptr_other\".to_string(), \"other.md\".to_string());\n\n        let memory_id = sync_manager.find_memory_id_by_knowledge_id(\"test.md\", \u0026state);\n        assert_eq!(memory_id, Some(\"ptr_test\".to_string()));\n\n        let memory_id = sync_manager.find_memory_id_by_knowledge_id(\"nonexistent.md\", \u0026state);\n        assert_eq!(memory_id, None);\n    }\n\n    struct MockRepoWithEntries {\n        entries: Vec\u003cKnowledgeEntry\u003e,\n    }\n    impl MockRepoWithEntries {\n        fn new() -\u003e Self {\n            Self {\n                entries: Vec::new(),\n            }\n        }\n        fn add_entry(\u0026mut self, e: KnowledgeEntry) {\n            self.entries.push(e);\n        }\n    }\n    #[async_trait::async_trait]\n    impl KnowledgeRepository for MockRepoWithEntries {\n        type Error = knowledge::repository::RepositoryError;\n        async fn store(\n            \u0026self,\n            _ctx: TenantContext,\n            _e: KnowledgeEntry,\n            _m: \u0026str,\n        ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n            Ok(\"hash\".to_string())\n        }\n        async fn get(\n            \u0026self,\n            _ctx: TenantContext,\n            l: KnowledgeLayer,\n            p: \u0026str,\n        ) -\u003e std::result::Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(self\n                .entries\n                .iter()\n                .find(|e| e.path == p \u0026\u0026 e.layer == l)\n                .cloned())\n        }\n        async fn list(\n            \u0026self,\n            _ctx: TenantContext,\n            l: KnowledgeLayer,\n            _p: \u0026str,\n        ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(self\n                .entries\n                .iter()\n                .filter(|e| e.layer == l)\n                .cloned()\n                .collect())\n        }\n        async fn delete(\n            \u0026self,\n            _ctx: TenantContext,\n            _l: KnowledgeLayer,\n            _p: \u0026str,\n            _m: \u0026str,\n        ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n            Ok(\"hash\".to_string())\n        }\n        async fn get_head_commit(\n            \u0026self,\n            _ctx: TenantContext,\n        ) -\u003e std::result::Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n            Ok(None)\n        }\n        async fn get_affected_items(\n            \u0026self,\n            _ctx: TenantContext,\n            _f: \u0026str,\n        ) -\u003e std::result::Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n            Ok(Vec::new())\n        }\n        async fn search(\n            \u0026self,\n            _ctx: TenantContext,\n            _q: \u0026str,\n            _l: Vec\u003cKnowledgeLayer\u003e,\n            _li: usize,\n        ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(Vec::new())\n        }\n        fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n            None\n        }\n    }\n\n    #[tokio::test]\n    async fn test_detect_conflicts_layer_mismatch() {\n        let mut state = SyncState::default();\n        let k_id = \"moved_item.md\".to_string();\n        let m_id = format!(\"ptr_{}\", k_id);\n        let ctx = TenantContext::default();\n\n        state.pointer_mapping.insert(m_id.clone(), k_id.clone());\n        state\n            .knowledge_hashes\n            .insert(k_id.clone(), utils::compute_content_hash(\"content\"));\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: k_id.clone(),\n            content: \"content\".to_string(),\n            layer: KnowledgeLayer::Org,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n        });\n\n        let memory = Arc::new(MemoryManager::new());\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Org,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        memory\n            .add_to_layer(\n                ctx.clone(),\n                mk_core::types::MemoryLayer::Project,\n                MemoryEntry {\n                    id: m_id.clone(),\n                    content: \"[Spec] [Accepted] moved_item.md\\n\\ncontent\".to_string(),\n                    embedding: None,\n                    layer: mk_core::types::MemoryLayer::Project,\n                    metadata: HashMap::new(),\n                    created_at: 0,\n                    updated_at: 0,\n                },\n            )\n            .await\n            .unwrap();\n\n        let sync_manager =\n            create_sync_manager_with_state(memory, Arc::new(repo), state, \u0026ctx.tenant_id);\n\n        let conflicts = sync_manager.detect_conflicts(ctx).await.unwrap();\n\n        let layer_mismatch = conflicts\n            .iter()\n            .find(|c| matches!(c, SyncConflict::LayerMismatch { .. }));\n\n        assert!(\n            layer_mismatch.is_some(),\n            \"Expected LayerMismatch conflict, found: {:?}\",\n            conflicts\n        );\n\n        if let Some(SyncConflict::LayerMismatch {\n            knowledge_id,\n            expected_layer,\n            actual_layer,\n            ..\n        }) = layer_mismatch\n        {\n            assert_eq!(knowledge_id, \"moved_item.md\");\n            assert_eq!(expected_layer, \u0026KnowledgeLayer::Project);\n            assert_eq!(actual_layer, \u0026KnowledgeLayer::Org);\n        }\n    }\n\n    #[tokio::test]\n    async fn test_detect_conflicts_performance() {\n        let count = 1000;\n        let mut state = SyncState::default();\n        let mut repo = MockRepoWithEntries::new();\n\n        for i in 0..count {\n            let k_id = format!(\"item_{}.md\", i);\n            let m_id = format!(\"ptr_{}\", k_id);\n            state.pointer_mapping.insert(m_id.clone(), k_id.clone());\n            state\n                .knowledge_hashes\n                .insert(k_id.clone(), utils::compute_content_hash(\"content\"));\n            state\n                .knowledge_layers\n                .insert(k_id.clone(), KnowledgeLayer::Project);\n\n            repo.add_entry(KnowledgeEntry {\n                path: k_id.clone(),\n                content: \"content\".to_string(),\n                layer: KnowledgeLayer::Project,\n                kind: KnowledgeType::Spec,\n                status: KnowledgeStatus::Accepted,\n                metadata: HashMap::new(),\n                commit_hash: None,\n                author: None,\n                updated_at: 0,\n            });\n        }\n\n        let memory = Arc::new(MemoryManager::new());\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        for i in 0..count {\n            let k_id = format!(\"item_{}.md\", i);\n            let m_id = format!(\"ptr_{}\", k_id);\n            memory\n                .add_to_layer(\n                    mk_core::types::TenantContext::default(),\n                    mk_core::types::MemoryLayer::Project,\n                    MemoryEntry {\n                        id: m_id,\n                        content: \"[Spec] [Accepted] item.md\\n\\ncontent\".to_string(),\n                        embedding: None,\n                        layer: mk_core::types::MemoryLayer::Project,\n                        metadata: HashMap::new(),\n                        created_at: 0,\n                        updated_at: 0,\n                    },\n                )\n                .await\n                .unwrap();\n        }\n\n        let ctx = TenantContext::default();\n        let sync_manager =\n            create_sync_manager_with_state(memory, Arc::new(repo), state, \u0026ctx.tenant_id);\n\n        let start = Instant::now();\n        let _ = sync_manager.detect_conflicts(ctx).await.unwrap();\n        let duration = start.elapsed();\n\n        println!(\n            \"Conflict detection for {} items took: {:?}\",\n            count, duration\n        );\n        assert!(duration.as_secs() \u003c 5);\n    }\n\n    #[tokio::test]\n    async fn test_sync_federation_general_error() {\n        let ctx = TenantContext::default();\n        let sync_manager = SyncManager::new(\n            Arc::new(MemoryManager::new()),\n            Arc::new(MockKnowledgeRepository::new()),\n            Arc::new(GovernanceEngine::new()),\n            DeploymentConfig::default(),\n            None,\n            Arc::new(MockPersister),\n        )\n        .await\n        .unwrap();\n\n        struct ErrorFed {\n            config: knowledge::federation::FederationConfig,\n        }\n        impl ErrorFed {\n            fn new() -\u003e Self {\n                Self {\n                    config: knowledge::federation::FederationConfig {\n                        upstreams: vec![knowledge::federation::UpstreamConfig {\n                            id: \"upstream1\".to_string(),\n                            url: \"http://test\".to_string(),\n                            branch: \"main\".to_string(),\n                            auth_token: None,\n                        }],\n                        sync_interval_secs: 60,\n                    },\n                }\n            }\n        }\n        #[async_trait::async_trait]\n        impl FederationProvider for ErrorFed {\n            fn config(\u0026self) -\u003e \u0026knowledge::federation::FederationConfig {\n                \u0026self.config\n            }\n            async fn fetch_upstream_manifest(\n                \u0026self,\n                _id: \u0026str,\n            ) -\u003e std::result::Result\u003c\n                knowledge::federation::KnowledgeManifest,\n                knowledge::repository::RepositoryError,\n            \u003e {\n                Ok(knowledge::federation::KnowledgeManifest {\n                    version: \"1\".to_string(),\n                    items: HashMap::new(),\n                })\n            }\n            async fn sync_upstream(\n                \u0026self,\n                _id: \u0026str,\n                _p: \u0026std::path::Path,\n            ) -\u003e std::result::Result\u003c(), knowledge::repository::RepositoryError\u003e {\n                Err(knowledge::repository::RepositoryError::InvalidPath(\n                    \"something went wrong\".to_string(),\n                ))\n            }\n        }\n\n        let fed = ErrorFed::new();\n        let result = sync_manager.sync_federation(ctx, \u0026fed).await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_background_sync_shutdown_with_receiver() {\n        let ctx = TenantContext::default();\n        let sync_manager = Arc::new(SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        });\n\n        let (tx, rx) = tokio::sync::watch::channel(false);\n        let handle = sync_manager.start_background_sync(ctx, 1, 60, rx).await;\n\n        tokio::time::sleep(std::time::Duration::from_millis(100)).await;\n        tx.send(true).unwrap();\n\n        let result = tokio::time::timeout(std::time::Duration::from_secs(2), handle).await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_background_sync_runs_cycle() {\n        let ctx = TenantContext::default();\n        let sync_manager = Arc::new(\n            SyncManager::new(\n                Arc::new(MemoryManager::new()),\n                Arc::new(MockKnowledgeRepository::new()),\n                Arc::new(GovernanceEngine::new()),\n                DeploymentConfig::default(),\n                None,\n                Arc::new(MockPersister),\n            )\n            .await\n            .unwrap(),\n        );\n\n        let (tx, rx) = tokio::sync::watch::channel(false);\n        let handle = sync_manager.start_background_sync(ctx, 1, 0, rx).await;\n\n        tokio::time::sleep(std::time::Duration::from_millis(1500)).await;\n        tx.send(true).unwrap();\n        handle.await.unwrap();\n    }\n\n    #[tokio::test]\n    async fn test_initialize_shutdown() {\n        let ctx = TenantContext::default();\n        let sync_manager = SyncManager::new(\n            Arc::new(MemoryManager::new()),\n            Arc::new(MockKnowledgeRepository::new()),\n            Arc::new(GovernanceEngine::new()),\n            DeploymentConfig::default(),\n            None,\n            Arc::new(MockPersister),\n        )\n        .await\n        .unwrap();\n\n        sync_manager.initialize(ctx).await.unwrap();\n        sync_manager.shutdown().await.unwrap();\n    }\n\n    #[tokio::test]\n    async fn test_checkpoint_rollback() {\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let tenant_id = TenantId::default();\n\n        // Set initial state with version \"before\"\n        let mut initial_state = SyncState::default();\n        initial_state.version = \"before\".to_string();\n        sync_manager.update_state(\u0026tenant_id, initial_state).await;\n\n        sync_manager.create_checkpoint(\u0026tenant_id).await.unwrap();\n\n        // Modify state to version \"after\"\n        let mut modified_state = sync_manager.get_or_load_state(\u0026tenant_id).await.unwrap();\n        modified_state.version = \"after\".to_string();\n        sync_manager.update_state(\u0026tenant_id, modified_state).await;\n\n        sync_manager.rollback(\u0026tenant_id).await.unwrap();\n\n        let state = sync_manager.get_or_load_state(\u0026tenant_id).await.unwrap();\n        assert_eq!(state.version, \"before\");\n    }\n\n    #[tokio::test]\n    async fn test_sync_entry_governance_block() {\n        use mk_core::types::{\n            ConstraintOperator, ConstraintSeverity, ConstraintTarget, Policy, PolicyMode,\n            PolicyRule, RuleMergeStrategy, RuleType,\n        };\n\n        let ctx = TenantContext::default();\n        let mut engine = GovernanceEngine::new();\n        engine.add_policy(Policy {\n            id: \"p1\".to_string(),\n            name: \"Banned Word\".to_string(),\n            description: None,\n            layer: KnowledgeLayer::Company,\n            mode: PolicyMode::Mandatory,\n            merge_strategy: RuleMergeStrategy::Merge,\n            rules: vec![PolicyRule {\n                id: \"r1\".to_string(),\n                rule_type: RuleType::Deny,\n                target: ConstraintTarget::Code,\n                operator: ConstraintOperator::MustMatch,\n                value: serde_json::json!(\"BANNED\"),\n                severity: ConstraintSeverity::Block,\n                message: \"BANNED word found\".to_string(),\n            }],\n            metadata: HashMap::new(),\n        });\n\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(engine),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let entry = KnowledgeEntry {\n            path: \"test.md\".to_string(),\n            content: \"This is BANNED content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n        };\n\n        let mut state = SyncState::default();\n        let result = sync_manager.sync_entry(ctx, \u0026entry, \u0026mut state).await;\n\n        assert!(matches!(result, Err(SyncError::GovernanceBlock(_))));\n        assert_eq!(state.stats.total_governance_blocks, 1);\n    }\n\n    #[tokio::test]\n    async fn test_check_triggers_manual() {\n        let ctx = TenantContext::default();\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let trigger = sync_manager.check_triggers(ctx, 60).await.unwrap();\n        assert!(matches!(trigger, Some(SyncTrigger::Manual)));\n    }\n\n    #[tokio::test]\n    async fn test_detect_delta_comprehensive() {\n        let ctx = TenantContext::default();\n        let mut state = SyncState::default();\n        state.knowledge_hashes.insert(\n            \"unchanged.md\".to_string(),\n            utils::compute_content_hash(\"content\"),\n        );\n        state\n            .knowledge_hashes\n            .insert(\"updated.md\".to_string(), \"old_hash\".to_string());\n        state\n            .knowledge_hashes\n            .insert(\"deleted.md\".to_string(), \"some_hash\".to_string());\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: \"unchanged.md\".to_string(),\n            content: \"content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n        });\n        repo.add_entry(KnowledgeEntry {\n            path: \"updated.md\".to_string(),\n            content: \"new_content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n        });\n        repo.add_entry(KnowledgeEntry {\n            path: \"added.md\".to_string(),\n            content: \"new\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n        });\n\n        let sync_manager = create_sync_manager_with_state(\n            Arc::new(MemoryManager::new()),\n            Arc::new(repo),\n            state.clone(),\n            \u0026ctx.tenant_id,\n        );\n\n        let delta = sync_manager.detect_delta(ctx, \u0026state).await.unwrap();\n        assert_eq!(delta.added.len(), 1);\n        assert_eq!(delta.updated.len(), 1);\n        assert_eq!(delta.deleted.len(), 1);\n        assert_eq!(delta.unchanged.len(), 1);\n    }\n\n    #[tokio::test]\n    async fn test_sync_all_basic() {\n        let ctx = TenantContext::default();\n        let memory = Arc::new(MemoryManager::new());\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: \"test.md\".to_string(),\n            content: \"content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n        });\n\n        let sync_manager = SyncManager {\n            memory_manager: memory.clone(),\n            knowledge_repo: Arc::new(repo),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        sync_manager.sync_all(ctx.clone()).await.unwrap();\n\n        let state = sync_manager\n            .get_or_load_state(\u0026ctx.tenant_id)\n            .await\n            .unwrap();\n        assert!(state.pointer_mapping.contains_key(\"ptr_test.md\"));\n    }\n\n    #[tokio::test]\n    async fn test_resolve_orphaned_conflict() {\n        let ctx = TenantContext::default();\n        let memory = Arc::new(MemoryManager::new());\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        let m_id = \"ptr_orphaned\".to_string();\n        memory\n            .add_to_layer(\n                ctx.clone(),\n                mk_core::types::MemoryLayer::Project,\n                MemoryEntry {\n                    id: m_id.clone(),\n                    content: \"content\".to_string(),\n                    embedding: None,\n                    layer: mk_core::types::MemoryLayer::Project,\n                    metadata: HashMap::new(),\n                    created_at: 0,\n                    updated_at: 0,\n                },\n            )\n            .await\n            .unwrap();\n\n        let mut state = SyncState::default();\n        state\n            .pointer_mapping\n            .insert(m_id.clone(), \"old.md\".to_string());\n        state\n            .knowledge_layers\n            .insert(\"old.md\".to_string(), KnowledgeLayer::Project);\n\n        let sync_manager = create_sync_manager_with_state(\n            memory.clone(),\n            Arc::new(MockKnowledgeRepository::new()),\n            state,\n            \u0026ctx.tenant_id,\n        );\n\n        let conflicts = vec![SyncConflict::OrphanedPointer {\n            memory_id: m_id.clone(),\n            knowledge_id: \"old.md\".to_string(),\n        }];\n\n        sync_manager\n            .resolve_conflicts(ctx.clone(), conflicts)\n            .await\n            .unwrap();\n\n        let state = sync_manager\n            .get_or_load_state(\u0026ctx.tenant_id)\n            .await\n            .unwrap();\n        assert!(!state.pointer_mapping.contains_key(\u0026m_id));\n    }\n\n    #[tokio::test]\n    async fn test_resolve_hash_mismatch_conflict() {\n        let ctx = TenantContext::default();\n        let memory = Arc::new(MemoryManager::new());\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        let k_id = \"mismatch.md\".to_string();\n        let m_id = format!(\"ptr_{}\", k_id);\n\n        let mut state = SyncState::default();\n        state.pointer_mapping.insert(m_id.clone(), k_id.clone());\n        state\n            .knowledge_hashes\n            .insert(k_id.clone(), \"old_hash\".to_string());\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: k_id.clone(),\n            content: \"new content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n        });\n\n        let sync_manager =\n            create_sync_manager_with_state(memory.clone(), Arc::new(repo), state, \u0026ctx.tenant_id);\n\n        let conflicts = vec![SyncConflict::HashMismatch {\n            knowledge_id: k_id.clone(),\n            memory_id: m_id.clone(),\n            expected_hash: \"old_hash\".to_string(),\n            actual_hash: utils::compute_content_hash(\"new content\"),\n        }];\n\n        sync_manager\n            .resolve_conflicts(ctx.clone(), conflicts)\n            .await\n            .unwrap();\n\n        let state = sync_manager\n            .get_or_load_state(\u0026ctx.tenant_id)\n            .await\n            .unwrap();\n        assert_eq!(\n            state.knowledge_hashes.get(\u0026k_id).unwrap(),\n            \u0026utils::compute_content_hash(\"new content\")\n        );\n    }\n\n    #[tokio::test]\n    async fn test_resolve_missing_pointer_conflict() {\n        let ctx = TenantContext::default();\n        let memory = Arc::new(MemoryManager::new());\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        let k_id = \"missing.md\".to_string();\n        let m_id = format!(\"ptr_{}\", k_id);\n\n        let mut state = SyncState::default();\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: k_id.clone(),\n            content: \"content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n        });\n\n        let sync_manager =\n            create_sync_manager_with_state(memory.clone(), Arc::new(repo), state, \u0026ctx.tenant_id);\n\n        let conflicts = vec![SyncConflict::MissingPointer {\n            knowledge_id: k_id.clone(),\n            expected_memory_id: m_id.clone(),\n        }];\n\n        sync_manager\n            .resolve_conflicts(ctx.clone(), conflicts)\n            .await\n            .unwrap();\n\n        let state = sync_manager\n            .get_or_load_state(\u0026ctx.tenant_id)\n            .await\n            .unwrap();\n        assert!(state.pointer_mapping.contains_key(\u0026m_id));\n    }\n\n    #[tokio::test]\n    async fn test_prune_failed_items() {\n        let mut state = SyncState::default();\n        state.failed_items.push(SyncFailure {\n            knowledge_id: \"old_fail.md\".to_string(),\n            error: \"err\".to_string(),\n            failed_at: chrono::Utc::now().timestamp() - (40 * 24 * 60 * 60),\n            retry_count: 0,\n        });\n        state.failed_items.push(SyncFailure {\n            knowledge_id: \"new_fail.md\".to_string(),\n            error: \"err\".to_string(),\n            failed_at: chrono::Utc::now().timestamp(),\n            retry_count: 0,\n        });\n\n        let ctx = TenantContext::default();\n        let sync_manager = create_sync_manager_with_state(\n            Arc::new(MemoryManager::new()),\n            Arc::new(MockKnowledgeRepository::new()),\n            state,\n            \u0026ctx.tenant_id,\n        );\n\n        sync_manager\n            .prune_failed_items(ctx.clone(), 30)\n            .await\n            .unwrap();\n\n        let state = sync_manager\n            .get_or_load_state(\u0026ctx.tenant_id)\n            .await\n            .unwrap();\n        assert_eq!(state.failed_items.len(), 1);\n        assert_eq!(state.failed_items[0].knowledge_id, \"new_fail.md\");\n    }\n\n    #[tokio::test]\n    async fn test_resolve_detection_error() {\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let conflicts = vec![SyncConflict::DetectionError {\n            target_id: \"test\".to_string(),\n            error: \"some error\".to_string(),\n        }];\n\n        let result = sync_manager\n            .resolve_conflicts(TenantContext::default(), conflicts)\n            .await;\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_scheduled_sync_no_trigger() {\n        let mut state = SyncState::default();\n        state.last_sync_at = Some(chrono::Utc::now().timestamp());\n        state.last_knowledge_commit = Some(\"commit\".to_string());\n\n        let ctx = TenantContext::default();\n        let sync_manager = create_sync_manager_with_state(\n            Arc::new(MemoryManager::new()),\n            Arc::new(MockKnowledgeRepository::new()),\n            state,\n            \u0026ctx.tenant_id,\n        );\n\n        sync_manager.scheduled_sync(ctx, 120).await.unwrap();\n    }\n\n    #[tokio::test]\n    async fn test_sync_incremental_with_changes() {\n        let memory = Arc::new(MemoryManager::new());\n        let ctx = TenantContext::default();\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        let k_id = \"existing.md\".to_string();\n        let m_id = format!(\"ptr_{}\", k_id);\n\n        let mut state = SyncState::default();\n        state.last_knowledge_commit = Some(\"old_commit\".to_string());\n        state.last_sync_at = Some(chrono::Utc::now().timestamp() - 3600);\n        state.pointer_mapping.insert(m_id.clone(), k_id.clone());\n        state\n            .knowledge_hashes\n            .insert(k_id.clone(), \"old_hash\".to_string());\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        memory\n            .add_to_layer(\n                ctx.clone(),\n                mk_core::types::MemoryLayer::Project,\n                MemoryEntry {\n                    id: m_id.clone(),\n                    content: \"old\".to_string(),\n                    embedding: None,\n                    layer: mk_core::types::MemoryLayer::Project,\n                    metadata: HashMap::new(),\n                    created_at: 0,\n                    updated_at: 0,\n                },\n            )\n            .await\n            .unwrap();\n\n        struct IncrementalRepo;\n        #[async_trait::async_trait]\n        impl KnowledgeRepository for IncrementalRepo {\n            type Error = knowledge::repository::RepositoryError;\n            async fn store(\n                \u0026self,\n                _ctx: TenantContext,\n                _e: KnowledgeEntry,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"\".to_string())\n            }\n            async fn get(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                p: \u0026str,\n            ) -\u003e std::result::Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                if p == \"existing.md\" {\n                    Ok(Some(KnowledgeEntry {\n                        path: p.to_string(),\n                        content: \"updated content\".to_string(),\n                        layer: KnowledgeLayer::Project,\n                        kind: KnowledgeType::Spec,\n                        status: KnowledgeStatus::Accepted,\n                        metadata: HashMap::new(),\n                        commit_hash: None,\n                        author: None,\n                        updated_at: 0,\n                    }))\n                } else {\n                    Ok(None)\n                }\n            }\n            async fn list(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            async fn delete(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"\".to_string())\n            }\n            async fn get_head_commit(\n                \u0026self,\n                _ctx: TenantContext,\n            ) -\u003e std::result::Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n                Ok(Some(\"new_commit\".to_string()))\n            }\n            async fn get_affected_items(\n                \u0026self,\n                _ctx: TenantContext,\n                _f: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n                Ok(vec![(KnowledgeLayer::Project, \"existing.md\".to_string())])\n            }\n            async fn search(\n                \u0026self,\n                _ctx: TenantContext,\n                _q: \u0026str,\n                _l: Vec\u003cKnowledgeLayer\u003e,\n                _li: usize,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n                None\n            }\n        }\n\n        let sync_manager = create_sync_manager_with_state(\n            memory.clone(),\n            Arc::new(IncrementalRepo),\n            state,\n            \u0026ctx.tenant_id,\n        );\n\n        sync_manager.sync_incremental(ctx.clone()).await.unwrap();\n\n        let state = sync_manager\n            .get_or_load_state(\u0026ctx.tenant_id)\n            .await\n            .unwrap();\n        assert_eq!(state.last_knowledge_commit, Some(\"new_commit\".to_string()));\n    }\n\n    #[tokio::test]\n    async fn test_sync_incremental_deletion() {\n        let memory = Arc::new(MemoryManager::new());\n        let ctx = TenantContext::default();\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        let k_id = \"deleted.md\".to_string();\n        let m_id = format!(\"ptr_{}\", k_id);\n\n        let mut state = SyncState::default();\n        state.last_knowledge_commit = Some(\"old_commit\".to_string());\n        state.pointer_mapping.insert(m_id.clone(), k_id.clone());\n        state\n            .knowledge_hashes\n            .insert(k_id.clone(), \"hash\".to_string());\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        memory\n            .add_to_layer(\n                ctx.clone(),\n                mk_core::types::MemoryLayer::Project,\n                MemoryEntry {\n                    id: m_id.clone(),\n                    content: \"content\".to_string(),\n                    embedding: None,\n                    layer: mk_core::types::MemoryLayer::Project,\n                    metadata: HashMap::new(),\n                    created_at: 0,\n                    updated_at: 0,\n                },\n            )\n            .await\n            .unwrap();\n\n        struct DeletingRepo;\n        #[async_trait::async_trait]\n        impl KnowledgeRepository for DeletingRepo {\n            type Error = knowledge::repository::RepositoryError;\n            async fn store(\n                \u0026self,\n                _ctx: TenantContext,\n                _e: KnowledgeEntry,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"\".to_string())\n            }\n            async fn get(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n            ) -\u003e std::result::Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(None)\n            }\n            async fn list(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            async fn delete(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"\".to_string())\n            }\n            async fn get_head_commit(\n                \u0026self,\n                _ctx: TenantContext,\n            ) -\u003e std::result::Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n                Ok(Some(\"new_commit\".to_string()))\n            }\n            async fn get_affected_items(\n                \u0026self,\n                _ctx: TenantContext,\n                _f: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n                Ok(vec![(KnowledgeLayer::Project, \"deleted.md\".to_string())])\n            }\n            async fn search(\n                \u0026self,\n                _ctx: TenantContext,\n                _q: \u0026str,\n                _l: Vec\u003cKnowledgeLayer\u003e,\n                _li: usize,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n                None\n            }\n        }\n\n        let sync_manager = create_sync_manager_with_state(\n            memory.clone(),\n            Arc::new(DeletingRepo),\n            state,\n            \u0026ctx.tenant_id,\n        );\n\n        sync_manager.sync_incremental(ctx.clone()).await.unwrap();\n\n        let state = sync_manager\n            .get_or_load_state(\u0026ctx.tenant_id)\n            .await\n            .unwrap();\n        assert!(!state.pointer_mapping.contains_key(\u0026m_id));\n        assert!(!state.knowledge_hashes.contains_key(\u0026k_id));\n    }\n\n    #[tokio::test]\n    async fn test_resolve_federation_conflict() {\n        let mut state = SyncState::default();\n        state\n            .federation_conflicts\n            .push(crate::state::FederationConflict {\n                upstream_id: \"upstream1\".to_string(),\n                reason: \"conflict\".to_string(),\n                detected_at: 0,\n            });\n\n        let ctx = TenantContext::default();\n        let sync_manager = create_sync_manager_with_state(\n            Arc::new(MemoryManager::new()),\n            Arc::new(MockKnowledgeRepository::new()),\n            state,\n            \u0026ctx.tenant_id,\n        );\n\n        sync_manager\n            .resolve_federation_conflict(ctx.tenant_id.clone(), \"upstream1\", \"manual fix\")\n            .await\n            .unwrap();\n\n        let state = sync_manager\n            .get_or_load_state(\u0026ctx.tenant_id)\n            .await\n            .unwrap();\n        assert!(state.federation_conflicts.is_empty());\n    }\n\n    #[tokio::test]\n    async fn test_check_triggers_commit_mismatch() {\n        struct RepoWithHead(String);\n        #[async_trait::async_trait]\n        impl KnowledgeRepository for RepoWithHead {\n            type Error = knowledge::repository::RepositoryError;\n            async fn store(\n                \u0026self,\n                _ctx: TenantContext,\n                _e: KnowledgeEntry,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"\".to_string())\n            }\n            async fn get(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n            ) -\u003e std::result::Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(None)\n            }\n            async fn list(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            async fn delete(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"\".to_string())\n            }\n            async fn get_head_commit(\n                \u0026self,\n                _ctx: TenantContext,\n            ) -\u003e std::result::Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n                Ok(Some(self.0.clone()))\n            }\n            async fn get_affected_items(\n                \u0026self,\n                _ctx: TenantContext,\n                _f: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            async fn search(\n                \u0026self,\n                _ctx: TenantContext,\n                _q: \u0026str,\n                _l: Vec\u003cKnowledgeLayer\u003e,\n                _li: usize,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n                None\n            }\n        }\n\n        let mut state = SyncState::default();\n        state.last_knowledge_commit = Some(\"old\".to_string());\n        state.last_sync_at = Some(chrono::Utc::now().timestamp());\n\n        let ctx = TenantContext::default();\n        let sync_manager = create_sync_manager_with_state(\n            Arc::new(MemoryManager::new()),\n            Arc::new(RepoWithHead(\"new\".to_string())),\n            state,\n            \u0026ctx.tenant_id,\n        );\n\n        let trigger = sync_manager.check_triggers(ctx, 120).await.unwrap();\n        assert!(matches!(trigger, Some(SyncTrigger::CommitMismatch { .. })));\n    }\n\n    #[tokio::test]\n    async fn test_check_triggers_staleness() {\n        struct RepoWithHead(String);\n        #[async_trait::async_trait]\n        impl KnowledgeRepository for RepoWithHead {\n            type Error = knowledge::repository::RepositoryError;\n            async fn store(\n                \u0026self,\n                _ctx: TenantContext,\n                _e: KnowledgeEntry,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"\".to_string())\n            }\n            async fn get(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n            ) -\u003e std::result::Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(None)\n            }\n            async fn list(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            async fn delete(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"\".to_string())\n            }\n            async fn get_head_commit(\n                \u0026self,\n                _ctx: TenantContext,\n            ) -\u003e std::result::Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n                Ok(Some(self.0.clone()))\n            }\n            async fn get_affected_items(\n                \u0026self,\n                _ctx: TenantContext,\n                _f: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            async fn search(\n                \u0026self,\n                _ctx: TenantContext,\n                _q: \u0026str,\n                _l: Vec\u003cKnowledgeLayer\u003e,\n                _li: usize,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n                None\n            }\n        }\n\n        let mut state = SyncState::default();\n        state.last_knowledge_commit = Some(\"same\".to_string());\n        state.last_sync_at = Some(chrono::Utc::now().timestamp() - 3600);\n\n        let ctx = TenantContext::default();\n        let sync_manager = create_sync_manager_with_state(\n            Arc::new(MemoryManager::new()),\n            Arc::new(RepoWithHead(\"same\".to_string())),\n            state,\n            \u0026ctx.tenant_id,\n        );\n\n        let trigger = sync_manager.check_triggers(ctx, 30).await.unwrap();\n        assert!(matches!(trigger, Some(SyncTrigger::Staleness { .. })));\n    }\n\n    #[tokio::test]\n    async fn test_run_sync_cycle_with_trigger() {\n        let memory = Arc::new(MemoryManager::new());\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        let sync_manager = SyncManager {\n            memory_manager: memory,\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let ctx = TenantContext::default();\n        sync_manager.run_sync_cycle(ctx.clone(), 60).await.unwrap();\n\n        let state = sync_manager\n            .get_or_load_state(\u0026ctx.tenant_id)\n            .await\n            .unwrap();\n        assert!(state.last_sync_at.is_some());\n    }\n\n    #[tokio::test]\n    async fn test_resolve_status_change_conflict() {\n        let memory = Arc::new(MemoryManager::new());\n        let ctx = TenantContext::default();\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        let k_id = \"deprecated.md\".to_string();\n        let m_id = format!(\"ptr_{}\", k_id);\n\n        let mut state = SyncState::default();\n        state.pointer_mapping.insert(m_id.clone(), k_id.clone());\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: k_id.clone(),\n            content: \"content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Deprecated,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n        });\n\n        let sync_manager =\n            create_sync_manager_with_state(memory.clone(), Arc::new(repo), state, \u0026ctx.tenant_id);\n\n        let conflicts = vec![SyncConflict::StatusChange {\n            knowledge_id: k_id.clone(),\n            memory_id: m_id.clone(),\n            new_status: KnowledgeStatus::Deprecated,\n        }];\n\n        sync_manager\n            .resolve_conflicts(ctx.clone(), conflicts)\n            .await\n            .unwrap();\n\n        let mem_entry = memory\n            .get_from_layer(ctx, mk_core::types::MemoryLayer::Project, \u0026m_id)\n            .await\n            .unwrap()\n            .unwrap();\n        assert!(mem_entry.content.contains(\"[Deprecated]\"));\n    }\n\n    #[tokio::test]\n    async fn test_resolve_layer_mismatch_conflict() {\n        let memory = Arc::new(MemoryManager::new());\n        let ctx = TenantContext::default();\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Org,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        let k_id = \"moved.md\".to_string();\n        let m_id = format!(\"ptr_{}\", k_id);\n\n        let mut state = SyncState::default();\n        state.pointer_mapping.insert(m_id.clone(), k_id.clone());\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        memory\n            .add_to_layer(\n                ctx.clone(),\n                mk_core::types::MemoryLayer::Project,\n                MemoryEntry {\n                    id: m_id.clone(),\n                    content: \"old\".to_string(),\n                    embedding: None,\n                    layer: mk_core::types::MemoryLayer::Project,\n                    metadata: HashMap::new(),\n                    created_at: 0,\n                    updated_at: 0,\n                },\n            )\n            .await\n            .unwrap();\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: k_id.clone(),\n            content: \"content\".to_string(),\n            layer: KnowledgeLayer::Org,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n        });\n\n        let sync_manager =\n            create_sync_manager_with_state(memory.clone(), Arc::new(repo), state, \u0026ctx.tenant_id);\n\n        let conflicts = vec![SyncConflict::LayerMismatch {\n            knowledge_id: k_id.clone(),\n            memory_id: m_id.clone(),\n            expected_layer: KnowledgeLayer::Project,\n            actual_layer: KnowledgeLayer::Org,\n        }];\n\n        sync_manager\n            .resolve_conflicts(ctx.clone(), conflicts)\n            .await\n            .unwrap();\n\n        assert!(\n            memory\n                .get_from_layer(ctx.clone(), mk_core::types::MemoryLayer::Project, \u0026m_id)\n                .await\n                .unwrap()\n                .is_none()\n        );\n        assert!(\n            memory\n                .get_from_layer(ctx, mk_core::types::MemoryLayer::Org, \u0026m_id)\n                .await\n                .unwrap()\n                .is_some()\n        );\n    }\n\n    #[tokio::test]\n    async fn test_resolve_duplicate_pointer_conflict() {\n        let memory = Arc::new(MemoryManager::new());\n        let ctx = TenantContext::default();\n        memory\n            .register_provider(\n                mk_core::types::MemoryLayer::Project,\n                Box::new(memory::providers::MockProvider::new()),\n            )\n            .await;\n\n        let k_id = \"duplicate.md\".to_string();\n        let m_id1 = \"ptr_1\".to_string();\n        let m_id2 = \"ptr_2\".to_string();\n\n        let mut state = SyncState::default();\n        state.pointer_mapping.insert(m_id1.clone(), k_id.clone());\n        state.pointer_mapping.insert(m_id2.clone(), k_id.clone());\n        state\n            .knowledge_layers\n            .insert(k_id.clone(), KnowledgeLayer::Project);\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: k_id.clone(),\n            content: \"content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: None,\n            author: None,\n            updated_at: 0,\n        });\n\n        let sync_manager =\n            create_sync_manager_with_state(memory.clone(), Arc::new(repo), state, \u0026ctx.tenant_id);\n\n        let conflicts = vec![SyncConflict::DuplicatePointer {\n            knowledge_id: k_id.clone(),\n            memory_ids: vec![m_id1.clone(), m_id2.clone()],\n        }];\n\n        sync_manager\n            .resolve_conflicts(ctx.clone(), conflicts)\n            .await\n            .unwrap();\n\n        let state = sync_manager\n            .get_or_load_state(\u0026ctx.tenant_id)\n            .await\n            .unwrap();\n        assert!(state.pointer_mapping.contains_key(\u0026format!(\"ptr_{}\", k_id)));\n    }\n\n    #[tokio::test]\n    async fn test_check_triggers_no_last_commit() {\n        // Given: State with no last_knowledge_commit and no last_sync_at\n        let state = SyncState::default();\n\n        let mut repo = MockRepoWithEntries::new();\n        repo.add_entry(KnowledgeEntry {\n            path: \"test.md\".to_string(),\n            content: \"content\".to_string(),\n            layer: KnowledgeLayer::Project,\n            kind: KnowledgeType::Spec,\n            status: KnowledgeStatus::Accepted,\n            metadata: HashMap::new(),\n            commit_hash: Some(\"abc123\".to_string()),\n            author: None,\n            updated_at: 0,\n        });\n\n        struct MockRepoWithCommit;\n        #[async_trait::async_trait]\n        impl KnowledgeRepository for MockRepoWithCommit {\n            type Error = knowledge::repository::RepositoryError;\n            async fn store(\n                \u0026self,\n                _ctx: TenantContext,\n                _e: KnowledgeEntry,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"hash\".to_string())\n            }\n            async fn get(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n            ) -\u003e std::result::Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(None)\n            }\n            async fn list(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            async fn delete(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"hash\".to_string())\n            }\n            async fn get_head_commit(\n                \u0026self,\n                _ctx: TenantContext,\n            ) -\u003e std::result::Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n                Ok(Some(\"abc123\".to_string()))\n            }\n            async fn get_affected_items(\n                \u0026self,\n                _ctx: TenantContext,\n                _f: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            async fn search(\n                \u0026self,\n                _ctx: TenantContext,\n                _q: \u0026str,\n                _l: Vec\u003cKnowledgeLayer\u003e,\n                _li: usize,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n                None\n            }\n        }\n\n        let ctx = TenantContext::default();\n        let sync_manager = create_sync_manager_with_state(\n            Arc::new(MemoryManager::new()),\n            Arc::new(MockRepoWithCommit),\n            state,\n            \u0026ctx.tenant_id,\n        );\n\n        let trigger = sync_manager.check_triggers(ctx, 60).await.unwrap();\n\n        assert!(matches!(\n            trigger,\n            Some(SyncTrigger::CommitMismatch {\n                last_commit,\n                head_commit\n            }) if last_commit == \"none\" \u0026\u0026 head_commit == \"abc123\"\n        ));\n    }\n\n    #[tokio::test]\n    async fn test_find_memory_id_wrapper() {\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let mut state = SyncState::default();\n        state\n            .pointer_mapping\n            .insert(\"ptr_test\".to_string(), \"test.md\".to_string());\n\n        // When: calling the test wrapper\n        let result = sync_manager.find_memory_id_by_knowledge_id_for_test(\"test.md\", \u0026state);\n\n        // Then: Should find the mapping\n        assert_eq!(result, Some(\"ptr_test\".to_string()));\n    }\n\n    #[tokio::test]\n    async fn test_sync_all_with_list_error() {\n        struct MockRepoListError;\n        #[async_trait::async_trait]\n        impl KnowledgeRepository for MockRepoListError {\n            type Error = knowledge::repository::RepositoryError;\n            async fn store(\n                \u0026self,\n                _ctx: TenantContext,\n                _e: KnowledgeEntry,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"hash\".to_string())\n            }\n            async fn get(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n            ) -\u003e std::result::Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(None)\n            }\n            async fn list(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Err(knowledge::repository::RepositoryError::InvalidPath(\n                    \"test error\".to_string(),\n                ))\n            }\n            async fn delete(\n                \u0026self,\n                _ctx: TenantContext,\n                _l: KnowledgeLayer,\n                _p: \u0026str,\n                _m: \u0026str,\n            ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n                Ok(\"hash\".to_string())\n            }\n            async fn get_head_commit(\n                \u0026self,\n                _ctx: TenantContext,\n            ) -\u003e std::result::Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n                Ok(Some(\"abc\".to_string()))\n            }\n            async fn get_affected_items(\n                \u0026self,\n                _ctx: TenantContext,\n                _f: \u0026str,\n            ) -\u003e std::result::Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            async fn search(\n                \u0026self,\n                _ctx: TenantContext,\n                _q: \u0026str,\n                _l: Vec\u003cKnowledgeLayer\u003e,\n                _li: usize,\n            ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n                Ok(Vec::new())\n            }\n            fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n                None\n            }\n        }\n\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockRepoListError),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let ctx = TenantContext::default();\n\n        // When: sync_all is called with repo returning list errors\n        sync_manager.sync_all(ctx.clone()).await.unwrap();\n\n        // Then: State should contain failed items for each layer\n        let state = sync_manager\n            .get_or_load_state(\u0026ctx.tenant_id)\n            .await\n            .unwrap();\n        assert!(\n            state.failed_items.len() \u003e= 4,\n            \"Expected failed items for each layer, got {}\",\n            state.failed_items.len()\n        );\n    }\n\n    #[tokio::test]\n    async fn test_rollback_no_checkpoint() {\n        let sync_manager = SyncManager {\n            memory_manager: Arc::new(MemoryManager::new()),\n            knowledge_repo: Arc::new(MockKnowledgeRepository::new()),\n            governance_engine: Arc::new(GovernanceEngine::new()),\n            governance_client: None,\n            deployment_config: DeploymentConfig::default(),\n            federation_manager: None,\n            persister: Arc::new(MockPersister),\n            states: Arc::new(RwLock::new(HashMap::new())),\n            checkpoints: Arc::new(RwLock::new(HashMap::new())),\n        };\n\n        let tenant_id = TenantId::default();\n\n        // When: rollback is called with no checkpoint\n        let result = sync_manager.rollback(\u0026tenant_id).await;\n\n        // Then: Should succeed (no-op)\n        assert!(result.is_ok());\n    }\n}\n","traces":[{"line":44,"address":[],"length":0,"stats":{"Line":26}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":160}},{"line":81,"address":[],"length":0,"stats":{"Line":160}},{"line":82,"address":[],"length":0,"stats":{"Line":226}},{"line":83,"address":[],"length":0,"stats":{"Line":66}},{"line":87,"address":[],"length":0,"stats":{"Line":42}},{"line":88,"address":[],"length":0,"stats":{"Line":28}},{"line":89,"address":[],"length":0,"stats":{"Line":14}},{"line":90,"address":[],"length":0,"stats":{"Line":14}},{"line":91,"address":[],"length":0,"stats":{"Line":14}},{"line":93,"address":[],"length":0,"stats":{"Line":28}},{"line":94,"address":[],"length":0,"stats":{"Line":70}},{"line":95,"address":[],"length":0,"stats":{"Line":14}},{"line":98,"address":[],"length":0,"stats":{"Line":58}},{"line":99,"address":[],"length":0,"stats":{"Line":58}},{"line":100,"address":[],"length":0,"stats":{"Line":116}},{"line":104,"address":[],"length":0,"stats":{"Line":2}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":2}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":1}},{"line":163,"address":[],"length":0,"stats":{"Line":12}},{"line":253,"address":[],"length":0,"stats":{"Line":14}},{"line":254,"address":[],"length":0,"stats":{"Line":14}},{"line":255,"address":[],"length":0,"stats":{"Line":28}},{"line":256,"address":[],"length":0,"stats":{"Line":28}},{"line":257,"address":[],"length":0,"stats":{"Line":7}},{"line":258,"address":[],"length":0,"stats":{"Line":7}},{"line":261,"address":[],"length":0,"stats":{"Line":4}},{"line":262,"address":[],"length":0,"stats":{"Line":4}},{"line":263,"address":[],"length":0,"stats":{"Line":5}},{"line":264,"address":[],"length":0,"stats":{"Line":2}},{"line":265,"address":[],"length":0,"stats":{"Line":5}},{"line":266,"address":[],"length":0,"stats":{"Line":2}},{"line":267,"address":[],"length":0,"stats":{"Line":2}},{"line":268,"address":[],"length":0,"stats":{"Line":1}},{"line":269,"address":[],"length":0,"stats":{"Line":1}},{"line":270,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":1}},{"line":274,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":1}},{"line":279,"address":[],"length":0,"stats":{"Line":1}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":1}},{"line":287,"address":[],"length":0,"stats":{"Line":2}},{"line":292,"address":[],"length":0,"stats":{"Line":2}},{"line":293,"address":[],"length":0,"stats":{"Line":8}},{"line":294,"address":[],"length":0,"stats":{"Line":6}},{"line":296,"address":[],"length":0,"stats":{"Line":6}},{"line":297,"address":[],"length":0,"stats":{"Line":6}},{"line":299,"address":[],"length":0,"stats":{"Line":4}},{"line":300,"address":[],"length":0,"stats":{"Line":2}},{"line":302,"address":[],"length":0,"stats":{"Line":3}},{"line":304,"address":[],"length":0,"stats":{"Line":4}},{"line":306,"address":[],"length":0,"stats":{"Line":10}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":1}},{"line":314,"address":[],"length":0,"stats":{"Line":5}},{"line":316,"address":[],"length":0,"stats":{"Line":1}},{"line":317,"address":[],"length":0,"stats":{"Line":1}},{"line":318,"address":[],"length":0,"stats":{"Line":1}},{"line":319,"address":[],"length":0,"stats":{"Line":1}},{"line":320,"address":[],"length":0,"stats":{"Line":3}},{"line":321,"address":[],"length":0,"stats":{"Line":3}},{"line":322,"address":[],"length":0,"stats":{"Line":2}},{"line":323,"address":[],"length":0,"stats":{"Line":1}},{"line":326,"address":[],"length":0,"stats":{"Line":1}},{"line":327,"address":[],"length":0,"stats":{"Line":1}},{"line":332,"address":[],"length":0,"stats":{"Line":4}},{"line":333,"address":[],"length":0,"stats":{"Line":4}},{"line":334,"address":[],"length":0,"stats":{"Line":2}},{"line":335,"address":[],"length":0,"stats":{"Line":2}},{"line":336,"address":[],"length":0,"stats":{"Line":8}},{"line":337,"address":[],"length":0,"stats":{"Line":2}},{"line":340,"address":[],"length":0,"stats":{"Line":6}},{"line":341,"address":[],"length":0,"stats":{"Line":9}},{"line":345,"address":[],"length":0,"stats":{"Line":20}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":423,"address":[],"length":0,"stats":{"Line":8}},{"line":429,"address":[],"length":0,"stats":{"Line":10}},{"line":435,"address":[],"length":0,"stats":{"Line":40}},{"line":436,"address":[],"length":0,"stats":{"Line":20}},{"line":438,"address":[],"length":0,"stats":{"Line":40}},{"line":439,"address":[],"length":0,"stats":{"Line":10}},{"line":440,"address":[],"length":0,"stats":{"Line":10}},{"line":441,"address":[],"length":0,"stats":{"Line":10}},{"line":442,"address":[],"length":0,"stats":{"Line":10}},{"line":444,"address":[],"length":0,"stats":{"Line":276}},{"line":445,"address":[],"length":0,"stats":{"Line":72}},{"line":446,"address":[],"length":0,"stats":{"Line":4}},{"line":447,"address":[],"length":0,"stats":{"Line":12}},{"line":448,"address":[],"length":0,"stats":{"Line":12}},{"line":449,"address":[],"length":0,"stats":{"Line":12}},{"line":450,"address":[],"length":0,"stats":{"Line":4}},{"line":451,"address":[],"length":0,"stats":{"Line":4}},{"line":453,"address":[],"length":0,"stats":{"Line":4}},{"line":457,"address":[],"length":0,"stats":{"Line":46}},{"line":458,"address":[],"length":0,"stats":{"Line":37}},{"line":459,"address":[],"length":0,"stats":{"Line":3}},{"line":460,"address":[],"length":0,"stats":{"Line":3}},{"line":461,"address":[],"length":0,"stats":{"Line":3}},{"line":462,"address":[],"length":0,"stats":{"Line":1}},{"line":463,"address":[],"length":0,"stats":{"Line":1}},{"line":469,"address":[],"length":0,"stats":{"Line":10}},{"line":470,"address":[],"length":0,"stats":{"Line":20}},{"line":471,"address":[],"length":0,"stats":{"Line":30}},{"line":472,"address":[],"length":0,"stats":{"Line":10}},{"line":473,"address":[],"length":0,"stats":{"Line":20}},{"line":474,"address":[],"length":0,"stats":{"Line":10}},{"line":476,"address":[],"length":0,"stats":{"Line":10}},{"line":477,"address":[],"length":0,"stats":{"Line":10}},{"line":478,"address":[],"length":0,"stats":{"Line":10}},{"line":480,"address":[],"length":0,"stats":{"Line":20}},{"line":481,"address":[],"length":0,"stats":{"Line":20}},{"line":482,"address":[],"length":0,"stats":{"Line":10}},{"line":483,"address":[],"length":0,"stats":{"Line":10}},{"line":485,"address":[],"length":0,"stats":{"Line":50}},{"line":487,"address":[],"length":0,"stats":{"Line":10}},{"line":490,"address":[],"length":0,"stats":{"Line":11}},{"line":495,"address":[],"length":0,"stats":{"Line":11}},{"line":496,"address":[],"length":0,"stats":{"Line":0}},{"line":499,"address":[],"length":0,"stats":{"Line":44}},{"line":501,"address":[],"length":0,"stats":{"Line":33}},{"line":502,"address":[],"length":0,"stats":{"Line":16}},{"line":503,"address":[],"length":0,"stats":{"Line":8}},{"line":504,"address":[],"length":0,"stats":{"Line":3}},{"line":505,"address":[],"length":0,"stats":{"Line":1}},{"line":506,"address":[],"length":0,"stats":{"Line":2}},{"line":507,"address":[],"length":0,"stats":{"Line":1}},{"line":511,"address":[],"length":0,"stats":{"Line":2}},{"line":512,"address":[],"length":0,"stats":{"Line":4}},{"line":513,"address":[],"length":0,"stats":{"Line":2}},{"line":518,"address":[],"length":0,"stats":{"Line":12}},{"line":519,"address":[],"length":0,"stats":{"Line":12}},{"line":520,"address":[],"length":0,"stats":{"Line":8}},{"line":521,"address":[],"length":0,"stats":{"Line":4}},{"line":522,"address":[],"length":0,"stats":{"Line":3}},{"line":523,"address":[],"length":0,"stats":{"Line":3}},{"line":524,"address":[],"length":0,"stats":{"Line":3}},{"line":528,"address":[],"length":0,"stats":{"Line":4}},{"line":531,"address":[],"length":0,"stats":{"Line":1}},{"line":534,"address":[],"length":0,"stats":{"Line":1}},{"line":540,"address":[],"length":0,"stats":{"Line":4}},{"line":542,"address":[],"length":0,"stats":{"Line":1}},{"line":543,"address":[],"length":0,"stats":{"Line":1}},{"line":544,"address":[],"length":0,"stats":{"Line":3}},{"line":546,"address":[],"length":0,"stats":{"Line":1}},{"line":547,"address":[],"length":0,"stats":{"Line":0}},{"line":553,"address":[],"length":0,"stats":{"Line":2}},{"line":554,"address":[],"length":0,"stats":{"Line":2}},{"line":555,"address":[],"length":0,"stats":{"Line":1}},{"line":556,"address":[],"length":0,"stats":{"Line":1}},{"line":557,"address":[],"length":0,"stats":{"Line":4}},{"line":558,"address":[],"length":0,"stats":{"Line":1}},{"line":561,"address":[],"length":0,"stats":{"Line":9}},{"line":566,"address":[],"length":0,"stats":{"Line":36}},{"line":568,"address":[],"length":0,"stats":{"Line":29}},{"line":569,"address":[],"length":0,"stats":{"Line":10}},{"line":570,"address":[],"length":0,"stats":{"Line":3}},{"line":571,"address":[],"length":0,"stats":{"Line":2}},{"line":572,"address":[],"length":0,"stats":{"Line":15}},{"line":573,"address":[],"length":0,"stats":{"Line":10}},{"line":574,"address":[],"length":0,"stats":{"Line":5}},{"line":575,"address":[],"length":0,"stats":{"Line":10}},{"line":577,"address":[],"length":0,"stats":{"Line":10}},{"line":578,"address":[],"length":0,"stats":{"Line":15}},{"line":579,"address":[],"length":0,"stats":{"Line":10}},{"line":580,"address":[],"length":0,"stats":{"Line":20}},{"line":581,"address":[],"length":0,"stats":{"Line":5}},{"line":583,"address":[],"length":0,"stats":{"Line":30}},{"line":584,"address":[],"length":0,"stats":{"Line":5}},{"line":588,"address":[],"length":0,"stats":{"Line":1}},{"line":589,"address":[],"length":0,"stats":{"Line":1}},{"line":591,"address":[],"length":0,"stats":{"Line":4}},{"line":592,"address":[],"length":0,"stats":{"Line":1}},{"line":593,"address":[],"length":0,"stats":{"Line":1}},{"line":594,"address":[],"length":0,"stats":{"Line":1}},{"line":595,"address":[],"length":0,"stats":{"Line":1}},{"line":597,"address":[],"length":0,"stats":{"Line":8}},{"line":598,"address":[],"length":0,"stats":{"Line":8}},{"line":599,"address":[],"length":0,"stats":{"Line":16}},{"line":600,"address":[],"length":0,"stats":{"Line":4}},{"line":602,"address":[],"length":0,"stats":{"Line":3}},{"line":603,"address":[],"length":0,"stats":{"Line":3}},{"line":604,"address":[],"length":0,"stats":{"Line":3}},{"line":605,"address":[],"length":0,"stats":{"Line":1}},{"line":608,"address":[],"length":0,"stats":{"Line":1}},{"line":609,"address":[],"length":0,"stats":{"Line":1}},{"line":611,"address":[],"length":0,"stats":{"Line":1}},{"line":612,"address":[],"length":0,"stats":{"Line":3}},{"line":614,"address":[],"length":0,"stats":{"Line":3}},{"line":615,"address":[],"length":0,"stats":{"Line":4}},{"line":616,"address":[],"length":0,"stats":{"Line":1}},{"line":617,"address":[],"length":0,"stats":{"Line":1}},{"line":618,"address":[],"length":0,"stats":{"Line":1}},{"line":619,"address":[],"length":0,"stats":{"Line":1}},{"line":621,"address":[],"length":0,"stats":{"Line":8}},{"line":622,"address":[],"length":0,"stats":{"Line":8}},{"line":623,"address":[],"length":0,"stats":{"Line":16}},{"line":624,"address":[],"length":0,"stats":{"Line":4}},{"line":626,"address":[],"length":0,"stats":{"Line":3}},{"line":629,"address":[],"length":0,"stats":{"Line":2}},{"line":630,"address":[],"length":0,"stats":{"Line":1}},{"line":631,"address":[],"length":0,"stats":{"Line":2}},{"line":633,"address":[],"length":0,"stats":{"Line":2}},{"line":634,"address":[],"length":0,"stats":{"Line":3}},{"line":635,"address":[],"length":0,"stats":{"Line":2}},{"line":636,"address":[],"length":0,"stats":{"Line":4}},{"line":637,"address":[],"length":0,"stats":{"Line":1}},{"line":639,"address":[],"length":0,"stats":{"Line":6}},{"line":641,"address":[],"length":0,"stats":{"Line":1}},{"line":644,"address":[],"length":0,"stats":{"Line":1}},{"line":645,"address":[],"length":0,"stats":{"Line":1}},{"line":648,"address":[],"length":0,"stats":{"Line":2}},{"line":649,"address":[],"length":0,"stats":{"Line":1}},{"line":650,"address":[],"length":0,"stats":{"Line":2}},{"line":652,"address":[],"length":0,"stats":{"Line":2}},{"line":653,"address":[],"length":0,"stats":{"Line":3}},{"line":654,"address":[],"length":0,"stats":{"Line":2}},{"line":655,"address":[],"length":0,"stats":{"Line":4}},{"line":656,"address":[],"length":0,"stats":{"Line":1}},{"line":658,"address":[],"length":0,"stats":{"Line":6}},{"line":660,"address":[],"length":0,"stats":{"Line":1}},{"line":661,"address":[],"length":0,"stats":{"Line":0}},{"line":665,"address":[],"length":0,"stats":{"Line":1}},{"line":668,"address":[],"length":0,"stats":{"Line":1}},{"line":669,"address":[],"length":0,"stats":{"Line":1}},{"line":670,"address":[],"length":0,"stats":{"Line":1}},{"line":671,"address":[],"length":0,"stats":{"Line":1}},{"line":673,"address":[],"length":0,"stats":{"Line":3}},{"line":674,"address":[],"length":0,"stats":{"Line":2}},{"line":675,"address":[],"length":0,"stats":{"Line":2}},{"line":676,"address":[],"length":0,"stats":{"Line":4}},{"line":677,"address":[],"length":0,"stats":{"Line":1}},{"line":679,"address":[],"length":0,"stats":{"Line":3}},{"line":680,"address":[],"length":0,"stats":{"Line":3}},{"line":681,"address":[],"length":0,"stats":{"Line":3}},{"line":683,"address":[],"length":0,"stats":{"Line":3}},{"line":684,"address":[],"length":0,"stats":{"Line":2}},{"line":685,"address":[],"length":0,"stats":{"Line":4}},{"line":686,"address":[],"length":0,"stats":{"Line":1}},{"line":688,"address":[],"length":0,"stats":{"Line":6}},{"line":691,"address":[],"length":0,"stats":{"Line":1}},{"line":692,"address":[],"length":0,"stats":{"Line":0}},{"line":697,"address":[],"length":0,"stats":{"Line":1}},{"line":699,"address":[],"length":0,"stats":{"Line":2}},{"line":700,"address":[],"length":0,"stats":{"Line":1}},{"line":701,"address":[],"length":0,"stats":{"Line":0}},{"line":709,"address":[],"length":0,"stats":{"Line":18}},{"line":710,"address":[],"length":0,"stats":{"Line":18}},{"line":711,"address":[],"length":0,"stats":{"Line":9}},{"line":712,"address":[],"length":0,"stats":{"Line":9}},{"line":713,"address":[],"length":0,"stats":{"Line":36}},{"line":714,"address":[],"length":0,"stats":{"Line":9}},{"line":717,"address":[],"length":0,"stats":{"Line":22}},{"line":718,"address":[],"length":0,"stats":{"Line":44}},{"line":719,"address":[],"length":0,"stats":{"Line":22}},{"line":721,"address":[],"length":0,"stats":{"Line":33}},{"line":722,"address":[],"length":0,"stats":{"Line":4035}},{"line":723,"address":[],"length":0,"stats":{"Line":3018}},{"line":724,"address":[],"length":0,"stats":{"Line":4024}},{"line":726,"address":[],"length":0,"stats":{"Line":2012}},{"line":729,"address":[],"length":0,"stats":{"Line":3029}},{"line":730,"address":[],"length":0,"stats":{"Line":1006}},{"line":731,"address":[],"length":0,"stats":{"Line":0}},{"line":732,"address":[],"length":0,"stats":{"Line":0}},{"line":733,"address":[],"length":0,"stats":{"Line":0}},{"line":738,"address":[],"length":0,"stats":{"Line":3029}},{"line":739,"address":[],"length":0,"stats":{"Line":1006}},{"line":740,"address":[],"length":0,"stats":{"Line":1006}},{"line":743,"address":[],"length":0,"stats":{"Line":2012}},{"line":744,"address":[],"length":0,"stats":{"Line":1006}},{"line":745,"address":[],"length":0,"stats":{"Line":2012}},{"line":747,"address":[],"length":0,"stats":{"Line":2012}},{"line":748,"address":[],"length":0,"stats":{"Line":2012}},{"line":750,"address":[],"length":0,"stats":{"Line":3018}},{"line":751,"address":[],"length":0,"stats":{"Line":2012}},{"line":752,"address":[],"length":0,"stats":{"Line":4024}},{"line":753,"address":[],"length":0,"stats":{"Line":1006}},{"line":754,"address":[],"length":0,"stats":{"Line":3016}},{"line":755,"address":[],"length":0,"stats":{"Line":1005}},{"line":756,"address":[],"length":0,"stats":{"Line":1005}},{"line":757,"address":[],"length":0,"stats":{"Line":1005}},{"line":759,"address":[],"length":0,"stats":{"Line":1007}},{"line":760,"address":[],"length":0,"stats":{"Line":1}},{"line":761,"address":[],"length":0,"stats":{"Line":1}},{"line":762,"address":[],"length":0,"stats":{"Line":0}},{"line":765,"address":[],"length":0,"stats":{"Line":1006}},{"line":766,"address":[],"length":0,"stats":{"Line":1005}},{"line":767,"address":[],"length":0,"stats":{"Line":4020}},{"line":768,"address":[],"length":0,"stats":{"Line":3015}},{"line":770,"address":[],"length":0,"stats":{"Line":2010}},{"line":771,"address":[],"length":0,"stats":{"Line":1005}},{"line":773,"address":[],"length":0,"stats":{"Line":3}},{"line":774,"address":[],"length":0,"stats":{"Line":3}},{"line":775,"address":[],"length":0,"stats":{"Line":3}},{"line":776,"address":[],"length":0,"stats":{"Line":2}},{"line":777,"address":[],"length":0,"stats":{"Line":1}},{"line":781,"address":[],"length":0,"stats":{"Line":1005}},{"line":782,"address":[],"length":0,"stats":{"Line":1005}},{"line":784,"address":[],"length":0,"stats":{"Line":0}},{"line":785,"address":[],"length":0,"stats":{"Line":0}},{"line":786,"address":[],"length":0,"stats":{"Line":0}},{"line":787,"address":[],"length":0,"stats":{"Line":0}},{"line":791,"address":[],"length":0,"stats":{"Line":1005}},{"line":792,"address":[],"length":0,"stats":{"Line":0}},{"line":793,"address":[],"length":0,"stats":{"Line":0}},{"line":794,"address":[],"length":0,"stats":{"Line":0}},{"line":795,"address":[],"length":0,"stats":{"Line":0}},{"line":796,"address":[],"length":0,"stats":{"Line":0}},{"line":800,"address":[],"length":0,"stats":{"Line":3015}},{"line":801,"address":[],"length":0,"stats":{"Line":2010}},{"line":802,"address":[],"length":0,"stats":{"Line":2010}},{"line":803,"address":[],"length":0,"stats":{"Line":4020}},{"line":804,"address":[],"length":0,"stats":{"Line":1005}},{"line":806,"address":[],"length":0,"stats":{"Line":1}},{"line":807,"address":[],"length":0,"stats":{"Line":3}},{"line":808,"address":[],"length":0,"stats":{"Line":3}},{"line":809,"address":[],"length":0,"stats":{"Line":1}},{"line":812,"address":[],"length":0,"stats":{"Line":1004}},{"line":813,"address":[],"length":0,"stats":{"Line":3012}},{"line":814,"address":[],"length":0,"stats":{"Line":3012}},{"line":815,"address":[],"length":0,"stats":{"Line":1004}},{"line":816,"address":[],"length":0,"stats":{"Line":4016}},{"line":817,"address":[],"length":0,"stats":{"Line":2005}},{"line":818,"address":[],"length":0,"stats":{"Line":3003}},{"line":819,"address":[],"length":0,"stats":{"Line":3003}},{"line":820,"address":[],"length":0,"stats":{"Line":3003}},{"line":821,"address":[],"length":0,"stats":{"Line":3003}},{"line":822,"address":[],"length":0,"stats":{"Line":1001}},{"line":826,"address":[],"length":0,"stats":{"Line":0}},{"line":827,"address":[],"length":0,"stats":{"Line":0}},{"line":828,"address":[],"length":0,"stats":{"Line":0}},{"line":829,"address":[],"length":0,"stats":{"Line":0}},{"line":831,"address":[],"length":0,"stats":{"Line":0}},{"line":836,"address":[],"length":0,"stats":{"Line":2}},{"line":837,"address":[],"length":0,"stats":{"Line":2}},{"line":838,"address":[],"length":0,"stats":{"Line":1}},{"line":839,"address":[],"length":0,"stats":{"Line":1}},{"line":840,"address":[],"length":0,"stats":{"Line":1}},{"line":841,"address":[],"length":0,"stats":{"Line":1}},{"line":843,"address":[],"length":0,"stats":{"Line":2}},{"line":844,"address":[],"length":0,"stats":{"Line":0}},{"line":847,"address":[],"length":0,"stats":{"Line":5}},{"line":848,"address":[],"length":0,"stats":{"Line":4}},{"line":849,"address":[],"length":0,"stats":{"Line":8}},{"line":850,"address":[],"length":0,"stats":{"Line":2}},{"line":852,"address":[],"length":0,"stats":{"Line":3}},{"line":853,"address":[],"length":0,"stats":{"Line":3}},{"line":854,"address":[],"length":0,"stats":{"Line":3}},{"line":855,"address":[],"length":0,"stats":{"Line":1}},{"line":856,"address":[],"length":0,"stats":{"Line":1}},{"line":858,"address":[],"length":0,"stats":{"Line":1}},{"line":859,"address":[],"length":0,"stats":{"Line":1}},{"line":863,"address":[],"length":0,"stats":{"Line":1}},{"line":864,"address":[],"length":0,"stats":{"Line":0}},{"line":865,"address":[],"length":0,"stats":{"Line":0}},{"line":866,"address":[],"length":0,"stats":{"Line":0}},{"line":870,"address":[],"length":0,"stats":{"Line":0}},{"line":871,"address":[],"length":0,"stats":{"Line":0}},{"line":872,"address":[],"length":0,"stats":{"Line":0}},{"line":873,"address":[],"length":0,"stats":{"Line":0}},{"line":875,"address":[],"length":0,"stats":{"Line":0}},{"line":884,"address":[],"length":0,"stats":{"Line":11}},{"line":887,"address":[],"length":0,"stats":{"Line":4}},{"line":892,"address":[],"length":0,"stats":{"Line":4}},{"line":893,"address":[],"length":0,"stats":{"Line":4}},{"line":895,"address":[],"length":0,"stats":{"Line":16}},{"line":896,"address":[],"length":0,"stats":{"Line":10}},{"line":899,"address":[],"length":0,"stats":{"Line":16}},{"line":905,"address":[],"length":0,"stats":{"Line":48}},{"line":906,"address":[],"length":0,"stats":{"Line":48}},{"line":908,"address":[],"length":0,"stats":{"Line":32}},{"line":909,"address":[],"length":0,"stats":{"Line":80}},{"line":910,"address":[],"length":0,"stats":{"Line":80}},{"line":912,"address":[],"length":0,"stats":{"Line":32}},{"line":913,"address":[],"length":0,"stats":{"Line":0}},{"line":914,"address":[],"length":0,"stats":{"Line":0}},{"line":915,"address":[],"length":0,"stats":{"Line":0}},{"line":916,"address":[],"length":0,"stats":{"Line":0}},{"line":917,"address":[],"length":0,"stats":{"Line":0}},{"line":919,"address":[],"length":0,"stats":{"Line":0}},{"line":920,"address":[],"length":0,"stats":{"Line":0}},{"line":921,"address":[],"length":0,"stats":{"Line":0}},{"line":922,"address":[],"length":0,"stats":{"Line":0}},{"line":923,"address":[],"length":0,"stats":{"Line":0}},{"line":924,"address":[],"length":0,"stats":{"Line":0}},{"line":925,"address":[],"length":0,"stats":{"Line":0}},{"line":926,"address":[],"length":0,"stats":{"Line":0}},{"line":927,"address":[],"length":0,"stats":{"Line":0}},{"line":928,"address":[],"length":0,"stats":{"Line":0}},{"line":930,"address":[],"length":0,"stats":{"Line":0}},{"line":931,"address":[],"length":0,"stats":{"Line":0}},{"line":933,"address":[],"length":0,"stats":{"Line":0}},{"line":935,"address":[],"length":0,"stats":{"Line":0}},{"line":936,"address":[],"length":0,"stats":{"Line":0}},{"line":946,"address":[],"length":0,"stats":{"Line":16}},{"line":947,"address":[],"length":0,"stats":{"Line":64}},{"line":948,"address":[],"length":0,"stats":{"Line":16}},{"line":949,"address":[],"length":0,"stats":{"Line":3}},{"line":950,"address":[],"length":0,"stats":{"Line":3}},{"line":951,"address":[],"length":0,"stats":{"Line":6}},{"line":952,"address":[],"length":0,"stats":{"Line":3}},{"line":953,"address":[],"length":0,"stats":{"Line":9}},{"line":954,"address":[],"length":0,"stats":{"Line":9}},{"line":955,"address":[],"length":0,"stats":{"Line":9}},{"line":956,"address":[],"length":0,"stats":{"Line":3}},{"line":957,"address":[],"length":0,"stats":{"Line":3}},{"line":959,"address":[],"length":0,"stats":{"Line":3}},{"line":961,"address":[],"length":0,"stats":{"Line":0}},{"line":962,"address":[],"length":0,"stats":{"Line":0}},{"line":971,"address":[],"length":0,"stats":{"Line":39}},{"line":972,"address":[],"length":0,"stats":{"Line":26}},{"line":974,"address":[],"length":0,"stats":{"Line":27}},{"line":975,"address":[],"length":0,"stats":{"Line":1}},{"line":977,"address":[],"length":0,"stats":{"Line":0}},{"line":980,"address":[],"length":0,"stats":{"Line":39}},{"line":982,"address":[],"length":0,"stats":{"Line":26}},{"line":983,"address":[],"length":0,"stats":{"Line":39}},{"line":984,"address":[],"length":0,"stats":{"Line":39}},{"line":985,"address":[],"length":0,"stats":{"Line":26}},{"line":986,"address":[],"length":0,"stats":{"Line":13}},{"line":991,"address":[],"length":0,"stats":{"Line":39}},{"line":993,"address":[],"length":0,"stats":{"Line":13}},{"line":996,"address":[],"length":0,"stats":{"Line":39}},{"line":997,"address":[],"length":0,"stats":{"Line":13}},{"line":998,"address":[],"length":0,"stats":{"Line":26}},{"line":999,"address":[],"length":0,"stats":{"Line":169}},{"line":1000,"address":[],"length":0,"stats":{"Line":117}},{"line":1002,"address":[],"length":0,"stats":{"Line":13}},{"line":1005,"address":[],"length":0,"stats":{"Line":0}},{"line":1006,"address":[],"length":0,"stats":{"Line":0}},{"line":1012,"address":[],"length":0,"stats":{"Line":39}},{"line":1013,"address":[],"length":0,"stats":{"Line":65}},{"line":1017,"address":[],"length":0,"stats":{"Line":39}},{"line":1018,"address":[],"length":0,"stats":{"Line":13}},{"line":1021,"address":[],"length":0,"stats":{"Line":26}},{"line":1022,"address":[],"length":0,"stats":{"Line":39}},{"line":1023,"address":[],"length":0,"stats":{"Line":13}},{"line":1025,"address":[],"length":0,"stats":{"Line":13}},{"line":1027,"address":[],"length":0,"stats":{"Line":13}},{"line":1028,"address":[],"length":0,"stats":{"Line":13}},{"line":1029,"address":[],"length":0,"stats":{"Line":52}},{"line":1030,"address":[],"length":0,"stats":{"Line":13}},{"line":1031,"address":[],"length":0,"stats":{"Line":13}},{"line":1032,"address":[],"length":0,"stats":{"Line":65}},{"line":1033,"address":[],"length":0,"stats":{"Line":13}},{"line":1034,"address":[],"length":0,"stats":{"Line":13}},{"line":1035,"address":[],"length":0,"stats":{"Line":52}},{"line":1036,"address":[],"length":0,"stats":{"Line":13}},{"line":1037,"address":[],"length":0,"stats":{"Line":13}},{"line":1039,"address":[],"length":0,"stats":{"Line":13}},{"line":1042,"address":[],"length":0,"stats":{"Line":2}},{"line":1043,"address":[],"length":0,"stats":{"Line":8}},{"line":1046,"address":[],"length":0,"stats":{"Line":1019}},{"line":1047,"address":[],"length":0,"stats":{"Line":2038}},{"line":1052,"address":[],"length":0,"stats":{"Line":4076}},{"line":1055,"address":[],"length":0,"stats":{"Line":2038}},{"line":1056,"address":[],"length":0,"stats":{"Line":5095}},{"line":1057,"address":[],"length":0,"stats":{"Line":5095}},{"line":1059,"address":[],"length":0,"stats":{"Line":4076}},{"line":1060,"address":[],"length":0,"stats":{"Line":1019}},{"line":1061,"address":[],"length":0,"stats":{"Line":0}},{"line":1062,"address":[],"length":0,"stats":{"Line":0}},{"line":1064,"address":[],"length":0,"stats":{"Line":0}},{"line":1065,"address":[],"length":0,"stats":{"Line":0}},{"line":1068,"address":[],"length":0,"stats":{"Line":0}},{"line":1069,"address":[],"length":0,"stats":{"Line":0}},{"line":1070,"address":[],"length":0,"stats":{"Line":0}},{"line":1074,"address":[],"length":0,"stats":{"Line":1019}},{"line":1077,"address":[],"length":0,"stats":{"Line":14}},{"line":1078,"address":[],"length":0,"stats":{"Line":28}},{"line":1079,"address":[],"length":0,"stats":{"Line":21}},{"line":1080,"address":[],"length":0,"stats":{"Line":14}},{"line":1082,"address":[],"length":0,"stats":{"Line":21}},{"line":1083,"address":[],"length":0,"stats":{"Line":7}},{"line":1084,"address":[],"length":0,"stats":{"Line":7}},{"line":1085,"address":[],"length":0,"stats":{"Line":11}},{"line":1087,"address":[],"length":0,"stats":{"Line":21}},{"line":1088,"address":[],"length":0,"stats":{"Line":7}},{"line":1089,"address":[],"length":0,"stats":{"Line":1}},{"line":1090,"address":[],"length":0,"stats":{"Line":0}},{"line":1095,"address":[],"length":0,"stats":{"Line":2}},{"line":1096,"address":[],"length":0,"stats":{"Line":2}},{"line":1097,"address":[],"length":0,"stats":{"Line":1}},{"line":1098,"address":[],"length":0,"stats":{"Line":1}},{"line":1099,"address":[],"length":0,"stats":{"Line":4}},{"line":1102,"address":[],"length":0,"stats":{"Line":7}},{"line":1105,"address":[],"length":0,"stats":{"Line":1}},{"line":1110,"address":[],"length":0,"stats":{"Line":4}},{"line":1113,"address":[],"length":0,"stats":{"Line":2}},{"line":1114,"address":[],"length":0,"stats":{"Line":2}},{"line":1115,"address":[],"length":0,"stats":{"Line":2}},{"line":1116,"address":[],"length":0,"stats":{"Line":2}},{"line":1117,"address":[],"length":0,"stats":{"Line":2}},{"line":1118,"address":[],"length":0,"stats":{"Line":1}},{"line":1119,"address":[],"length":0,"stats":{"Line":1}},{"line":1122,"address":[],"length":0,"stats":{"Line":9}},{"line":1123,"address":[],"length":0,"stats":{"Line":24}},{"line":1124,"address":[],"length":0,"stats":{"Line":10}},{"line":1125,"address":[],"length":0,"stats":{"Line":6}},{"line":1126,"address":[],"length":0,"stats":{"Line":9}},{"line":1128,"address":[],"length":0,"stats":{"Line":9}},{"line":1129,"address":[],"length":0,"stats":{"Line":5}},{"line":1130,"address":[],"length":0,"stats":{"Line":3}},{"line":1132,"address":[],"length":0,"stats":{"Line":1}},{"line":1133,"address":[],"length":0,"stats":{"Line":2}},{"line":1135,"address":[],"length":0,"stats":{"Line":1}},{"line":1136,"address":[],"length":0,"stats":{"Line":2}},{"line":1142,"address":[],"length":0,"stats":{"Line":7}},{"line":1143,"address":[],"length":0,"stats":{"Line":6}},{"line":1144,"address":[],"length":0,"stats":{"Line":8}},{"line":1146,"address":[],"length":0,"stats":{"Line":3}},{"line":1150,"address":[],"length":0,"stats":{"Line":1}},{"line":1154,"address":[],"length":0,"stats":{"Line":3}},{"line":1161,"address":[],"length":0,"stats":{"Line":3}},{"line":1162,"address":[],"length":0,"stats":{"Line":12}},{"line":1164,"address":[],"length":0,"stats":{"Line":7}},{"line":1165,"address":[],"length":0,"stats":{"Line":14}},{"line":1166,"address":[],"length":0,"stats":{"Line":20}},{"line":1167,"address":[],"length":0,"stats":{"Line":0}},{"line":1168,"address":[],"length":0,"stats":{"Line":0}},{"line":1171,"address":[],"length":0,"stats":{"Line":14}},{"line":1172,"address":[],"length":0,"stats":{"Line":2}},{"line":1173,"address":[],"length":0,"stats":{"Line":2}},{"line":1174,"address":[],"length":0,"stats":{"Line":2}}],"covered":452,"coverable":537},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","error.rs"],"content":"use thiserror::Error;\n\n#[derive(Debug, Error)]\npub enum SyncError {\n    #[error(\"Governance violation: {0}\")]\n    GovernanceBlock(String),\n    #[error(\"Knowledge repository error: {0}\")]\n    Repository(#[from] knowledge::repository::RepositoryError),\n    #[error(\"Memory manager error: {0}\")]\n    Memory(#[from] memory::error::MemoryError),\n    #[error(\"Serialization error: {0}\")]\n    Serialization(#[from] serde_json::Error),\n    #[error(\"IO error: {0}\")]\n    Io(#[from] std::io::Error),\n    #[error(\"Conflict detection failed: {0}\")]\n    ConflictDetection(String),\n    #[error(\"State persistence failed: {0}\")]\n    Persistence(String),\n    #[error(\"Internal error: {0}\")]\n    Internal(String),\n    #[error(\"Other error: {0}\")]\n    Other(String)\n}\n\nimpl From\u003cBox\u003cdyn std::error::Error + Send + Sync\u003e\u003e for SyncError {\n    fn from(err: Box\u003cdyn std::error::Error + Send + Sync\u003e) -\u003e Self {\n        SyncError::Other(err.to_string())\n    }\n}\n\npub type Result\u003cT\u003e = std::result::Result\u003cT, SyncError\u003e;\n","traces":[{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":2},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","lib.rs"],"content":"//! # Sync Bridge\n//!\n//! Pointer-based synchronization between memory and knowledge.\n\npub mod bridge;\npub mod error;\npub mod pointer;\npub mod state;\npub mod state_persister;\n\n#[cfg(test)]\nmod proptests;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","pointer.rs"],"content":"use mk_core::types::{KnowledgeLayer, KnowledgeType, MemoryLayer};\nuse serde::{Deserialize, Serialize};\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct KnowledgePointer {\n    pub source_type: KnowledgeType,\n    pub source_id: String,\n    pub content_hash: String,\n    pub synced_at: i64,\n    pub source_layer: KnowledgeLayer,\n    pub is_orphaned: bool\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct KnowledgePointerMetadata {\n    #[serde(rename = \"type\")]\n    pub kind: String,\n    pub knowledge_pointer: KnowledgePointer,\n    pub tags: Vec\u003cString\u003e\n}\n\nimpl Default for KnowledgePointerMetadata {\n    fn default() -\u003e Self {\n        Self {\n            kind: \"knowledge_pointer\".to_string(),\n            knowledge_pointer: KnowledgePointer {\n                source_type: KnowledgeType::Adr,\n                source_id: String::new(),\n                content_hash: String::new(),\n                synced_at: 0,\n                source_layer: KnowledgeLayer::Company,\n                is_orphaned: false\n            },\n            tags: Vec::new()\n        }\n    }\n}\n\npub fn map_layer(knowledge_layer: KnowledgeLayer) -\u003e MemoryLayer {\n    match knowledge_layer {\n        KnowledgeLayer::Company =\u003e MemoryLayer::Company,\n        KnowledgeLayer::Org =\u003e MemoryLayer::Org,\n        KnowledgeLayer::Team =\u003e MemoryLayer::Team,\n        KnowledgeLayer::Project =\u003e MemoryLayer::Project\n    }\n}\n","traces":[{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":28,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":1020}},{"line":42,"address":[],"length":0,"stats":{"Line":1020}},{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":1}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":1019}}],"covered":4,"coverable":10},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","proptests.rs"],"content":"#[cfg(test)]\nmod proptests {\n    use proptest::prelude::*;\n\n    proptest! {\n        #[test]\n        fn test_hash_consistency(content in \"\\\\PC*\") {\n            let hash1 = utils::compute_content_hash(\u0026content);\n            let hash2 = utils::compute_content_hash(\u0026content);\n            prop_assert_eq!(hash1, hash2);\n        }\n\n        #[test]\n        fn test_hash_different_for_different_content(c1 in \"\\\\PC*\", c2 in \"\\\\PC*\") {\n            if c1 != c2 {\n                let hash1 = utils::compute_content_hash(\u0026c1);\n                let hash2 = utils::compute_content_hash(\u0026c2);\n                prop_assert_ne!(hash1, hash2);\n            }\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","state.rs"],"content":"use serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct SyncState {\n    pub version: String,\n    pub last_sync_at: Option\u003ci64\u003e,\n    pub last_knowledge_commit: Option\u003cString\u003e,\n    pub knowledge_hashes: HashMap\u003cString, String\u003e,\n    pub pointer_mapping: HashMap\u003cString, String\u003e,\n    pub knowledge_layers: HashMap\u003cString, mk_core::types::KnowledgeLayer\u003e,\n    pub failed_items: Vec\u003cSyncFailure\u003e,\n    pub federation_conflicts: Vec\u003cFederationConflict\u003e,\n    pub upstream_commits: HashMap\u003cString, String\u003e,\n    pub stats: SyncStats\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct FederationConflict {\n    pub upstream_id: String,\n    pub reason: String,\n    pub detected_at: i64\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct SyncFailure {\n    pub knowledge_id: String,\n    pub error: String,\n    pub failed_at: i64,\n    pub retry_count: u32\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\npub enum SyncConflict {\n    HashMismatch {\n        knowledge_id: String,\n        memory_id: String,\n        expected_hash: String,\n        actual_hash: String\n    },\n    OrphanedPointer {\n        memory_id: String,\n        knowledge_id: String\n    },\n    MissingPointer {\n        knowledge_id: String,\n        expected_memory_id: String\n    },\n    DuplicatePointer {\n        knowledge_id: String,\n        memory_ids: Vec\u003cString\u003e\n    },\n    StatusChange {\n        knowledge_id: String,\n        memory_id: String,\n        new_status: mk_core::types::KnowledgeStatus\n    },\n    LayerMismatch {\n        knowledge_id: String,\n        memory_id: String,\n        expected_layer: mk_core::types::KnowledgeLayer,\n        actual_layer: mk_core::types::KnowledgeLayer\n    },\n    DetectionError {\n        target_id: String,\n        error: String\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\npub enum SyncTrigger {\n    Staleness {\n        last_sync_at: i64,\n        threshold_mins: u32\n    },\n    CommitMismatch {\n        last_commit: String,\n        head_commit: String\n    },\n    Manual\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, Default, PartialEq)]\n#[serde(rename_all = \"camelCase\")]\npub struct SyncStats {\n    pub total_syncs: u64,\n    pub total_items_synced: u64,\n    pub total_conflicts: u64,\n    pub total_governance_blocks: u64,\n    pub avg_sync_duration_ms: u64,\n    pub drift_score: f32,\n    pub policy_violations: u64\n}\n\nimpl Default for SyncState {\n    fn default() -\u003e Self {\n        Self {\n            version: \"1.0\".to_string(),\n            last_sync_at: None,\n            last_knowledge_commit: None,\n            knowledge_hashes: HashMap::new(),\n            pointer_mapping: HashMap::new(),\n            knowledge_layers: HashMap::new(),\n            failed_items: Vec::new(),\n            federation_conflicts: Vec::new(),\n            upstream_commits: HashMap::new(),\n            stats: SyncStats::default()\n        }\n    }\n}\n","traces":[{"line":99,"address":[],"length":0,"stats":{"Line":47}},{"line":101,"address":[],"length":0,"stats":{"Line":141}},{"line":104,"address":[],"length":0,"stats":{"Line":94}},{"line":105,"address":[],"length":0,"stats":{"Line":94}},{"line":106,"address":[],"length":0,"stats":{"Line":94}},{"line":107,"address":[],"length":0,"stats":{"Line":94}},{"line":108,"address":[],"length":0,"stats":{"Line":94}},{"line":109,"address":[],"length":0,"stats":{"Line":47}},{"line":110,"address":[],"length":0,"stats":{"Line":47}}],"covered":9,"coverable":9},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","src","state_persister.rs"],"content":"use crate::state::SyncState;\nuse async_trait::async_trait;\nuse mk_core::traits::StorageBackend;\nuse std::path::PathBuf;\nuse std::sync::Arc;\n\n#[async_trait]\npub trait SyncStatePersister: Send + Sync {\n    async fn load(\n        \u0026self,\n        tenant_id: \u0026mk_core::types::TenantId,\n    ) -\u003e Result\u003cSyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e;\n    async fn save(\n        \u0026self,\n        tenant_id: \u0026mk_core::types::TenantId,\n        state: \u0026SyncState,\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e;\n}\n\npub struct FilePersister {\n    base_path: PathBuf,\n}\n\nimpl FilePersister {\n    pub fn new(base_path: PathBuf) -\u003e Self {\n        Self { base_path }\n    }\n\n    fn get_path(\u0026self, tenant_id: \u0026mk_core::types::TenantId) -\u003e PathBuf {\n        self.base_path\n            .join(format!(\"sync_state_{}.json\", tenant_id.as_str()))\n    }\n}\n\n#[async_trait]\nimpl SyncStatePersister for FilePersister {\n    async fn load(\n        \u0026self,\n        tenant_id: \u0026mk_core::types::TenantId,\n    ) -\u003e Result\u003cSyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let path = self.get_path(tenant_id);\n        match tokio::fs::read(\u0026path).await {\n            Ok(data) =\u003e Ok(serde_json::from_slice(\u0026data)?),\n            Err(e) if e.kind() == std::io::ErrorKind::NotFound =\u003e Ok(SyncState::default()),\n            Err(e) =\u003e Err(e.into()),\n        }\n    }\n\n    async fn save(\n        \u0026self,\n        tenant_id: \u0026mk_core::types::TenantId,\n        state: \u0026SyncState,\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let path = self.get_path(tenant_id);\n        let data = serde_json::to_vec_pretty(state)?;\n        if let Some(parent) = path.parent() {\n            tokio::fs::create_dir_all(parent).await?;\n        }\n        tokio::fs::write(\u0026path, data).await?;\n        Ok(())\n    }\n}\n\npub struct DatabasePersister\u003cS: StorageBackend\u003e {\n    storage: Arc\u003cS\u003e,\n    key_prefix: String,\n}\n\nimpl\u003cS: StorageBackend\u003e DatabasePersister\u003cS\u003e {\n    pub fn new(storage: Arc\u003cS\u003e, key_prefix: String) -\u003e Self {\n        Self {\n            storage,\n            key_prefix,\n        }\n    }\n\n    fn get_key(\u0026self, tenant_id: \u0026mk_core::types::TenantId) -\u003e String {\n        format!(\"{}:{}\", self.key_prefix, tenant_id.as_str())\n    }\n}\n\n#[async_trait]\nimpl\u003cS: StorageBackend\u003e SyncStatePersister for DatabasePersister\u003cS\u003e\nwhere\n    S::Error: std::error::Error + Send + Sync + 'static,\n{\n    async fn load(\n        \u0026self,\n        tenant_id: \u0026mk_core::types::TenantId,\n    ) -\u003e Result\u003cSyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let key = self.get_key(tenant_id);\n        let ctx = mk_core::types::TenantContext::new(\n            tenant_id.clone(),\n            mk_core::types::UserId::default(),\n        );\n        match self.storage.retrieve(ctx, \u0026key).await? {\n            Some(data) =\u003e Ok(serde_json::from_slice(\u0026data)?),\n            None =\u003e Ok(SyncState::default()),\n        }\n    }\n\n    async fn save(\n        \u0026self,\n        tenant_id: \u0026mk_core::types::TenantId,\n        state: \u0026SyncState,\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let key = self.get_key(tenant_id);\n        let data = serde_json::to_vec(state)?;\n        let ctx = mk_core::types::TenantContext::new(\n            tenant_id.clone(),\n            mk_core::types::UserId::default(),\n        );\n        self.storage.store(ctx, \u0026key, \u0026data).await?;\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use async_trait::async_trait;\n    use std::collections::HashMap;\n    use std::sync::Arc;\n    use tokio::sync::RwLock;\n\n    struct MockStorage {\n        data: Arc\u003cRwLock\u003cHashMap\u003cString, Vec\u003cu8\u003e\u003e\u003e\u003e,\n    }\n\n    impl MockStorage {\n        fn new() -\u003e Self {\n            Self {\n                data: Arc::new(RwLock::new(HashMap::new())),\n            }\n        }\n    }\n\n    #[async_trait]\n    impl StorageBackend for MockStorage {\n        type Error = std::io::Error;\n\n        async fn store(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            key: \u0026str,\n            value: \u0026[u8],\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            self.data\n                .write()\n                .await\n                .insert(key.to_string(), value.to_vec());\n            Ok(())\n        }\n\n        async fn retrieve(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            key: \u0026str,\n        ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e {\n            Ok(self.data.read().await.get(key).cloned())\n        }\n\n        async fn delete(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            key: \u0026str,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            self.data.write().await.remove(key);\n            Ok(())\n        }\n\n        async fn exists(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            key: \u0026str,\n        ) -\u003e Result\u003cbool, Self::Error\u003e {\n            Ok(self.data.read().await.contains_key(key))\n        }\n\n        async fn get_ancestors(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _unit_id: \u0026str,\n        ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n\n        async fn get_descendants(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _unit_id: \u0026str,\n        ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n\n        async fn get_unit_policies(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _unit_id: \u0026str,\n        ) -\u003e Result\u003cVec\u003cmk_core::types::Policy\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n\n        async fn create_unit(\n            \u0026self,\n            _unit: \u0026mk_core::types::OrganizationalUnit,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n\n        async fn add_unit_policy(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n            _unit_id: \u0026str,\n            _policy: \u0026mk_core::types::Policy,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n\n        async fn assign_role(\n            \u0026self,\n            _user_id: \u0026mk_core::types::UserId,\n            _tenant_id: \u0026mk_core::types::TenantId,\n            _unit_id: \u0026str,\n            _role: mk_core::types::Role,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n\n        async fn remove_role(\n            \u0026self,\n            _user_id: \u0026mk_core::types::UserId,\n            _tenant_id: \u0026mk_core::types::TenantId,\n            _unit_id: \u0026str,\n            _role: mk_core::types::Role,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n\n        async fn store_drift_result(\n            \u0026self,\n            _result: mk_core::types::DriftResult,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n\n        async fn get_latest_drift_result(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _project_id: \u0026str,\n        ) -\u003e Result\u003cOption\u003cmk_core::types::DriftResult\u003e, Self::Error\u003e {\n            Ok(None)\n        }\n\n        async fn list_all_units(\n            \u0026self,\n        ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n\n        async fn record_job_status(\n            \u0026self,\n            _job_name: \u0026str,\n            _tenant_id: \u0026str,\n            _status: \u0026str,\n            _message: Option\u003c\u0026str\u003e,\n            _started_at: i64,\n            _finished_at: Option\u003ci64\u003e,\n        ) -\u003e Result\u003c(), Self::Error\u003e {\n            Ok(())\n        }\n\n        async fn get_governance_events(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _since_timestamp: i64,\n            _limit: usize,\n        ) -\u003e Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n    }\n\n    #[tokio::test]\n    async fn test_file_persister_save_and_load() {\n        let temp_dir = tempfile::tempdir().unwrap();\n        let base_path = temp_dir.path().to_path_buf();\n        let persister = FilePersister::new(base_path);\n        let tenant_id = mk_core::types::TenantId::default();\n\n        let mut state = SyncState::default();\n        state.stats.total_syncs = 10;\n\n        persister.save(\u0026tenant_id, \u0026state).await.unwrap();\n\n        let loaded_state = persister.load(\u0026tenant_id).await.unwrap();\n        assert_eq!(loaded_state.stats.total_syncs, 10);\n    }\n\n    #[tokio::test]\n    async fn test_file_persister_load_default() {\n        let temp_dir = tempfile::tempdir().unwrap();\n        let base_path = temp_dir.path().to_path_buf();\n        let persister = FilePersister::new(base_path);\n        let tenant_id = mk_core::types::TenantId::default();\n\n        let state = persister.load(\u0026tenant_id).await.unwrap();\n        assert_eq!(state, SyncState::default());\n    }\n\n    #[tokio::test]\n    async fn test_database_persister_new() {\n        let storage = Arc::new(MockStorage::new());\n        let persister = DatabasePersister::new(storage, \"test_key\".to_string());\n        assert_eq!(persister.key_prefix, \"test_key\");\n    }\n\n    #[tokio::test]\n    async fn test_database_persister_load_default() {\n        let storage = Arc::new(MockStorage::new());\n        let persister = DatabasePersister::new(storage, \"test_key\".to_string());\n        let tenant_id = mk_core::types::TenantId::default();\n\n        let state = persister.load(\u0026tenant_id).await.unwrap();\n        assert_eq!(state, SyncState::default());\n    }\n\n    #[tokio::test]\n    async fn test_database_persister_save_and_load() {\n        let storage = Arc::new(MockStorage::new());\n        let persister = DatabasePersister::new(storage, \"test_key\".to_string());\n        let tenant_id = mk_core::types::TenantId::default();\n\n        let mut state = SyncState::default();\n        state.stats.total_syncs = 5;\n        state.stats.total_items_synced = 42;\n\n        persister.save(\u0026tenant_id, \u0026state).await.unwrap();\n\n        let loaded_state = persister.load(\u0026tenant_id).await.unwrap();\n        assert_eq!(loaded_state.stats.total_syncs, 5);\n        assert_eq!(loaded_state.stats.total_items_synced, 42);\n    }\n\n    #[tokio::test]\n    async fn test_database_persister_save_overwrites() {\n        let storage = Arc::new(MockStorage::new());\n        let persister = DatabasePersister::new(storage, \"test_key\".to_string());\n        let tenant_id = mk_core::types::TenantId::default();\n\n        let mut state1 = SyncState::default();\n        state1.stats.total_syncs = 1;\n\n        let mut state2 = SyncState::default();\n        state2.stats.total_syncs = 2;\n\n        persister.save(\u0026tenant_id, \u0026state1).await.unwrap();\n        persister.save(\u0026tenant_id, \u0026state2).await.unwrap();\n\n        let loaded_state = persister.load(\u0026tenant_id).await.unwrap();\n        assert_eq!(loaded_state.stats.total_syncs, 2);\n    }\n\n    #[tokio::test]\n    async fn test_database_persister_different_keys() {\n        let storage = Arc::new(MockStorage::new());\n        let persister1 = DatabasePersister::new(storage.clone(), \"key1\".to_string());\n        let persister2 = DatabasePersister::new(storage, \"key2\".to_string());\n        let tenant_id = mk_core::types::TenantId::default();\n\n        let mut state1 = SyncState::default();\n        state1.stats.total_syncs = 100;\n\n        let mut state2 = SyncState::default();\n        state2.stats.total_syncs = 200;\n\n        persister1.save(\u0026tenant_id, \u0026state1).await.unwrap();\n        persister2.save(\u0026tenant_id, \u0026state2).await.unwrap();\n\n        let loaded1 = persister1.load(\u0026tenant_id).await.unwrap();\n        let loaded2 = persister2.load(\u0026tenant_id).await.unwrap();\n\n        assert_eq!(loaded1.stats.total_syncs, 100);\n        assert_eq!(loaded2.stats.total_syncs, 200);\n    }\n\n    #[tokio::test]\n    async fn test_database_persister_storage_error() {\n        struct ErrorStorage;\n\n        #[async_trait]\n        impl StorageBackend for ErrorStorage {\n            type Error = std::io::Error;\n\n            async fn store(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _key: \u0026str,\n                _value: \u0026[u8],\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn retrieve(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _key: \u0026str,\n            ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn delete(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _key: \u0026str,\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn exists(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _key: \u0026str,\n            ) -\u003e Result\u003cbool, Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn get_ancestors(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _unit_id: \u0026str,\n            ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn get_descendants(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _unit_id: \u0026str,\n            ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn get_unit_policies(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _unit_id: \u0026str,\n            ) -\u003e Result\u003cVec\u003cmk_core::types::Policy\u003e, Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn create_unit(\n                \u0026self,\n                _unit: \u0026mk_core::types::OrganizationalUnit,\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn add_unit_policy(\n                \u0026self,\n                _ctx: \u0026mk_core::types::TenantContext,\n                _unit_id: \u0026str,\n                _policy: \u0026mk_core::types::Policy,\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn assign_role(\n                \u0026self,\n                _user_id: \u0026mk_core::types::UserId,\n                _tenant_id: \u0026mk_core::types::TenantId,\n                _unit_id: \u0026str,\n                _role: mk_core::types::Role,\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn remove_role(\n                \u0026self,\n                _user_id: \u0026mk_core::types::UserId,\n                _tenant_id: \u0026mk_core::types::TenantId,\n                _unit_id: \u0026str,\n                _role: mk_core::types::Role,\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn store_drift_result(\n                \u0026self,\n                _result: mk_core::types::DriftResult,\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn get_latest_drift_result(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _project_id: \u0026str,\n            ) -\u003e Result\u003cOption\u003cmk_core::types::DriftResult\u003e, Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn list_all_units(\n                \u0026self,\n            ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn record_job_status(\n                \u0026self,\n                _job_name: \u0026str,\n                _tenant_id: \u0026str,\n                _status: \u0026str,\n                _message: Option\u003c\u0026str\u003e,\n                _started_at: i64,\n                _finished_at: Option\u003ci64\u003e,\n            ) -\u003e Result\u003c(), Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n\n            async fn get_governance_events(\n                \u0026self,\n                _ctx: mk_core::types::TenantContext,\n                _since_timestamp: i64,\n                _limit: usize,\n            ) -\u003e Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e, Self::Error\u003e {\n                Err(std::io::Error::new(\n                    std::io::ErrorKind::Other,\n                    \"storage error\",\n                ))\n            }\n        }\n\n        let storage = Arc::new(ErrorStorage);\n        let persister = DatabasePersister::new(storage, \"test_key\".to_string());\n        let tenant_id = mk_core::types::TenantId::default();\n\n        let state = SyncState::default();\n        let save_result = persister.save(\u0026tenant_id, \u0026state).await;\n        assert!(save_result.is_err());\n\n        let load_result = persister.load(\u0026tenant_id).await;\n        assert!(load_result.is_err());\n    }\n}\n","traces":[{"line":25,"address":[],"length":0,"stats":{"Line":2}},{"line":29,"address":[],"length":0,"stats":{"Line":3}},{"line":30,"address":[],"length":0,"stats":{"Line":6}},{"line":31,"address":[],"length":0,"stats":{"Line":12}},{"line":70,"address":[],"length":0,"stats":{"Line":8}},{"line":77,"address":[],"length":0,"stats":{"Line":12}},{"line":78,"address":[],"length":0,"stats":{"Line":48}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}}],"covered":7,"coverable":19},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","tests","federation_tests.rs"],"content":"use knowledge::federation::{\n    FederationConfig, FederationProvider, KnowledgeManifest, UpstreamConfig,\n};\nuse knowledge::governance::GovernanceEngine;\nuse knowledge::repository::RepositoryError;\nuse memory::manager::MemoryManager;\nuse mk_core::traits::KnowledgeRepository;\nuse mk_core::types::{\n    ConstraintOperator, ConstraintSeverity, ConstraintTarget, KnowledgeEntry, KnowledgeLayer,\n    KnowledgeStatus, KnowledgeType, Policy, PolicyMode, PolicyRule, RuleMergeStrategy, RuleType,\n    TenantContext, TenantId,\n};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse sync::bridge::SyncManager;\nuse sync::state::SyncState;\nuse sync::state_persister::SyncStatePersister;\n\nstruct MockFedProvider {\n    config: FederationConfig,\n    should_fail: bool,\n}\n\n#[async_trait::async_trait]\nimpl FederationProvider for MockFedProvider {\n    fn config(\u0026self) -\u003e \u0026FederationConfig {\n        \u0026self.config\n    }\n\n    async fn fetch_upstream_manifest(\n        \u0026self,\n        _id: \u0026str,\n    ) -\u003e Result\u003cKnowledgeManifest, RepositoryError\u003e {\n        Ok(KnowledgeManifest {\n            version: \"1.0\".to_string(),\n            items: HashMap::new(),\n        })\n    }\n\n    async fn sync_upstream(\n        \u0026self,\n        _id: \u0026str,\n        _path: \u0026std::path::Path,\n    ) -\u003e Result\u003c(), RepositoryError\u003e {\n        if self.should_fail {\n            return Err(RepositoryError::InvalidPath(\n                \"Local changes conflict with upstream\".to_string(),\n            ));\n        }\n        Ok(())\n    }\n}\n\nstruct MockRepo;\n\n#[async_trait::async_trait]\nimpl KnowledgeRepository for MockRepo {\n    type Error = RepositoryError;\n    async fn store(\n        \u0026self,\n        _ctx: TenantContext,\n        _e: KnowledgeEntry,\n        _m: \u0026str,\n    ) -\u003e Result\u003cString, Self::Error\u003e {\n        Ok(\"hash\".into())\n    }\n    async fn get(\n        \u0026self,\n        _ctx: TenantContext,\n        _l: KnowledgeLayer,\n        _p: \u0026str,\n    ) -\u003e Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n    async fn list(\n        \u0026self,\n        _ctx: TenantContext,\n        _l: KnowledgeLayer,\n        _p: \u0026str,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n    async fn delete(\n        \u0026self,\n        _ctx: TenantContext,\n        _l: KnowledgeLayer,\n        _p: \u0026str,\n        _m: \u0026str,\n    ) -\u003e Result\u003cString, Self::Error\u003e {\n        Ok(\"hash\".into())\n    }\n    async fn get_head_commit(\u0026self, _ctx: TenantContext) -\u003e Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n        Ok(Some(\"head\".into()))\n    }\n    async fn get_affected_items(\n        \u0026self,\n        _ctx: TenantContext,\n        _f: \u0026str,\n    ) -\u003e Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n    async fn search(\n        \u0026self,\n        _ctx: TenantContext,\n        _q: \u0026str,\n        _l: Vec\u003cKnowledgeLayer\u003e,\n        _li: usize,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n    fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n        Some(\"data/test\".into())\n    }\n}\n\nstruct MockPersister;\n#[async_trait::async_trait]\nimpl SyncStatePersister for MockPersister {\n    async fn load(\n        \u0026self,\n        _tenant_id: \u0026TenantId,\n    ) -\u003e Result\u003cSyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        Ok(SyncState::default())\n    }\n    async fn save(\n        \u0026self,\n        _tenant_id: \u0026TenantId,\n        _s: \u0026SyncState,\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        Ok(())\n    }\n}\n\n#[tokio::test]\nasync fn test_sync_federation_conflict_recording() {\n    let memory = Arc::new(MemoryManager::new());\n    let repo = Arc::new(MockRepo);\n    let gov = Arc::new(GovernanceEngine::new());\n    let fed_config = FederationConfig {\n        upstreams: vec![UpstreamConfig {\n            id: \"hub-1\".to_string(),\n            url: \"http://test\".to_string(),\n            branch: \"main\".to_string(),\n            auth_token: None,\n        }],\n        sync_interval_secs: 60,\n    };\n    let fed = Arc::new(MockFedProvider {\n        config: fed_config,\n        should_fail: true,\n    });\n    let persister = Arc::new(MockPersister);\n\n    let sync_manager = SyncManager::new(\n        memory,\n        repo,\n        gov,\n        config::config::DeploymentConfig::default(),\n        Some(fed.clone() as Arc\u003cdyn FederationProvider\u003e),\n        persister,\n    )\n    .await\n    .unwrap();\n\n    sync_manager\n        .sync_federation(TenantContext::default(), fed.as_ref())\n        .await\n        .unwrap();\n\n    let ctx = TenantContext::default();\n    let state = sync_manager.get_state(\u0026ctx.tenant_id).await.unwrap();\n    assert_eq!(state.federation_conflicts.len(), 1);\n    assert_eq!(state.federation_conflicts[0].upstream_id, \"hub-1\");\n    assert!(state.federation_conflicts[0].reason.contains(\"conflict\"));\n}\n\n#[tokio::test]\nasync fn test_sync_governance_telemetry() {\n    let memory = Arc::new(MemoryManager::new());\n    let repo = Arc::new(MockRepo);\n    let mut gov = GovernanceEngine::new();\n\n    gov.add_policy(Policy {\n        id: \"p-test\".to_string(),\n        name: \"Test Policy\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Project,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"r-test\".to_string(),\n            rule_type: RuleType::Deny,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustMatch,\n            value: serde_json::json!(\"forbidden\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Forbidden content detected\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    });\n\n    let gov = Arc::new(gov);\n    let persister = Arc::new(MockPersister);\n\n    let sync_manager = SyncManager::new(\n        memory,\n        repo,\n        gov,\n        config::config::DeploymentConfig::default(),\n        None,\n        persister,\n    )\n    .await\n    .unwrap();\n\n    let entry = KnowledgeEntry {\n        path: \"forbidden.md\".to_string(),\n        content: \"this is forbidden\".to_string(),\n        layer: KnowledgeLayer::Project,\n        kind: KnowledgeType::Spec,\n        metadata: HashMap::new(),\n        status: KnowledgeStatus::Accepted,\n        commit_hash: None,\n        author: None,\n        updated_at: chrono::Utc::now().timestamp(),\n    };\n\n    let mut state = SyncState::default();\n    let _ = sync_manager\n        .sync_entry(TenantContext::default(), \u0026entry, \u0026mut state)\n        .await;\n\n    assert_eq!(state.stats.total_governance_blocks, 1);\n    assert_eq!(state.failed_items.len(), 1);\n    assert!(\n        state.failed_items[0]\n            .error\n            .contains(\"Governance violation (BLOCK)\")\n    );\n}\n","traces":[{"line":26,"address":[],"length":0,"stats":{"Line":1}},{"line":27,"address":[],"length":0,"stats":{"Line":1}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":1}},{"line":112,"address":[],"length":0,"stats":{"Line":1}}],"covered":4,"coverable":5},{"path":["/","Users","christian.klat","dev","git","aeterna","sync","tests","sync_integration.rs"],"content":"use async_trait::async_trait;\nuse knowledge::governance::GovernanceEngine;\nuse knowledge::repository::GitRepository;\nuse memory::manager::MemoryManager;\nuse memory::providers::MockProvider;\nuse mk_core::traits::{KnowledgeRepository, StorageBackend};\nuse mk_core::types::{\n    KnowledgeEntry, KnowledgeLayer, KnowledgeStatus, KnowledgeType, MemoryLayer, TenantContext,\n    TenantId,\n};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse sync::bridge::SyncManager;\nuse sync::state::SyncState;\nuse sync::state_persister::SyncStatePersister;\nuse tokio::sync::RwLock;\n\nstruct MockStorage {\n    data: Arc\u003cRwLock\u003cHashMap\u003cString, Vec\u003cu8\u003e\u003e\u003e\u003e,\n}\n\nimpl MockStorage {\n    fn new() -\u003e Self {\n        Self {\n            data: Arc::new(RwLock::new(HashMap::new())),\n        }\n    }\n}\n\n#[async_trait]\nimpl StorageBackend for MockStorage {\n    type Error = std::io::Error;\n\n    async fn store(\u0026self, _ctx: TenantContext, key: \u0026str, value: \u0026[u8]) -\u003e Result\u003c(), Self::Error\u003e {\n        self.data\n            .write()\n            .await\n            .insert(key.to_string(), value.to_vec());\n        Ok(())\n    }\n\n    async fn retrieve(\n        \u0026self,\n        _ctx: TenantContext,\n        key: \u0026str,\n    ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e {\n        Ok(self.data.read().await.get(key).cloned())\n    }\n\n    async fn delete(\u0026self, _ctx: TenantContext, key: \u0026str) -\u003e Result\u003c(), Self::Error\u003e {\n        self.data.write().await.remove(key);\n        Ok(())\n    }\n\n    async fn exists(\u0026self, _ctx: TenantContext, key: \u0026str) -\u003e Result\u003cbool, Self::Error\u003e {\n        Ok(self.data.read().await.contains_key(key))\n    }\n\n    async fn get_ancestors(\n        \u0026self,\n        _ctx: TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn get_descendants(\n        \u0026self,\n        _ctx: TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn get_unit_policies(\n        \u0026self,\n        _ctx: TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::Policy\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn create_unit(\n        \u0026self,\n        _unit: \u0026mk_core::types::OrganizationalUnit,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn add_unit_policy(\n        \u0026self,\n        _ctx: \u0026TenantContext,\n        _unit_id: \u0026str,\n        _policy: \u0026mk_core::types::Policy,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn assign_role(\n        \u0026self,\n        _user_id: \u0026mk_core::types::UserId,\n        _tenant_id: \u0026mk_core::types::TenantId,\n        _unit_id: \u0026str,\n        _role: mk_core::types::Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn remove_role(\n        \u0026self,\n        _user_id: \u0026mk_core::types::UserId,\n        _tenant_id: \u0026mk_core::types::TenantId,\n        _unit_id: \u0026str,\n        _role: mk_core::types::Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn store_drift_result(\n        \u0026self,\n        _result: mk_core::types::DriftResult,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn get_latest_drift_result(\n        \u0026self,\n        _ctx: TenantContext,\n        _project_id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cmk_core::types::DriftResult\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n\n    async fn list_all_units(\u0026self) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn record_job_status(\n        \u0026self,\n        _job_name: \u0026str,\n        _tenant_id: \u0026str,\n        _status: \u0026str,\n        _message: Option\u003c\u0026str\u003e,\n        _started_at: i64,\n        _finished_at: Option\u003ci64\u003e,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn get_governance_events(\n        \u0026self,\n        _ctx: TenantContext,\n        _since_timestamp: i64,\n        _limit: usize,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n}\n\npub struct SimplePersister {\n    storage: Arc\u003cMockStorage\u003e,\n}\n\n#[async_trait]\nimpl SyncStatePersister for SimplePersister {\n    async fn load(\n        \u0026self,\n        tenant_id: \u0026TenantId,\n    ) -\u003e Result\u003cSyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let ctx = TenantContext::new(tenant_id.clone(), mk_core::types::UserId::default());\n        match self.storage.retrieve(ctx, \"sync_state\").await? {\n            Some(data) =\u003e Ok(serde_json::from_slice(\u0026data)?),\n            None =\u003e Ok(SyncState::default()),\n        }\n    }\n\n    async fn save(\n        \u0026self,\n        tenant_id: \u0026TenantId,\n        state: \u0026SyncState,\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let ctx = TenantContext::new(tenant_id.clone(), mk_core::types::UserId::default());\n        let data = serde_json::to_vec(state)?;\n        self.storage.store(ctx, \"sync_state\", \u0026data).await?;\n        Ok(())\n    }\n}\n\n#[tokio::test]\nasync fn test_sync_persistence_and_delta() -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    let repo_dir = tempfile::tempdir()?;\n    let knowledge_repo = Arc::new(GitRepository::new(repo_dir.path())?);\n    let governance_engine = Arc::new(GovernanceEngine::new());\n\n    let memory_manager = Arc::new(MemoryManager::new());\n    let mock_provider = MockProvider::new();\n    memory_manager\n        .register_provider(MemoryLayer::Project, Box::new(mock_provider))\n        .await;\n\n    let storage = Arc::new(MockStorage::new());\n    let persister = Arc::new(SimplePersister {\n        storage: storage.clone(),\n    });\n\n    let sync_manager = SyncManager::new(\n        memory_manager.clone(),\n        knowledge_repo.clone(),\n        governance_engine.clone(),\n        config::DeploymentConfig::default(),\n        None,\n        persister.clone(),\n    )\n    .await?;\n\n    let entry = KnowledgeEntry {\n        path: \"test.md\".to_string(),\n        content: \"initial content\".to_string(),\n        layer: KnowledgeLayer::Project,\n        kind: KnowledgeType::Spec,\n        status: KnowledgeStatus::Accepted,\n        metadata: HashMap::new(),\n        commit_hash: None,\n        author: None,\n        updated_at: chrono::Utc::now().timestamp(),\n    };\n    knowledge_repo\n        .store(TenantContext::default(), entry.clone(), \"first commit\")\n        .await?;\n\n    sync_manager.sync_all(TenantContext::default()).await?;\n\n    let ctx = TenantContext::default();\n    assert!(storage.exists(ctx, \"sync_state\").await?);\n    let tenant_id = TenantId::default();\n    let state = persister.load(\u0026tenant_id).await?;\n    assert_eq!(state.stats.total_items_synced, 1);\n    assert!(state.last_knowledge_commit.is_some());\n\n    let updated_entry = KnowledgeEntry {\n        content: \"updated content\".to_string(),\n        ..entry.clone()\n    };\n    knowledge_repo\n        .store(TenantContext::default(), updated_entry, \"second commit\")\n        .await?;\n\n    sync_manager\n        .sync_incremental(TenantContext::default())\n        .await?;\n\n    let state = persister.load(\u0026tenant_id).await?;\n    assert_eq!(state.stats.total_syncs, 2);\n\n    sync_manager\n        .run_sync_cycle(TenantContext::default(), 0)\n        .await?;\n\n    let _ = sync_manager\n        .detect_conflicts(TenantContext::default())\n        .await?;\n\n    let memory_id = format!(\"ptr_{}\", entry.path);\n    memory_manager\n        .delete_from_layer(TenantContext::default(), MemoryLayer::Project, \u0026memory_id)\n        .await?;\n\n    let conflicts = sync_manager\n        .detect_conflicts(TenantContext::default())\n        .await?;\n    assert_eq!(conflicts.len(), 1);\n\n    sync_manager\n        .resolve_conflicts(TenantContext::default(), conflicts)\n        .await?;\n\n    let conflicts = sync_manager\n        .detect_conflicts(TenantContext::default())\n        .await?;\n    if !conflicts.is_empty() {\n        println!(\"Final conflicts: {:?}\", conflicts);\n    }\n    assert!(conflicts.is_empty());\n\n    Ok(())\n}\n\n#[tokio::test]\nasync fn test_background_sync_trigger() -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    let repo_dir = tempfile::tempdir()?;\n    let knowledge_repo = Arc::new(GitRepository::new(repo_dir.path())?);\n    let governance_engine = Arc::new(GovernanceEngine::new());\n    let memory_manager = Arc::new(MemoryManager::new());\n    let mock_provider = MockProvider::new();\n    memory_manager\n        .register_provider(MemoryLayer::Project, Box::new(mock_provider))\n        .await;\n\n    let storage = Arc::new(MockStorage::new());\n    let persister = Arc::new(SimplePersister {\n        storage: storage.clone(),\n    });\n\n    let sync_manager = Arc::new(\n        SyncManager::new(\n            memory_manager.clone(),\n            knowledge_repo.clone(),\n            governance_engine.clone(),\n            config::DeploymentConfig::default(),\n            None,\n            persister.clone(),\n        )\n        .await?,\n    );\n\n    let entry = KnowledgeEntry {\n        path: \"bg_test.md\".to_string(),\n        content: \"initial content\".to_string(),\n        layer: KnowledgeLayer::Project,\n        kind: KnowledgeType::Spec,\n        status: KnowledgeStatus::Accepted,\n        metadata: HashMap::new(),\n        commit_hash: None,\n        author: None,\n        updated_at: chrono::Utc::now().timestamp(),\n    };\n    knowledge_repo\n        .store(TenantContext::default(), entry.clone(), \"first commit\")\n        .await?;\n\n    let (_tx, rx) = tokio::sync::watch::channel(false);\n    let handle = sync_manager\n        .clone()\n        .start_background_sync(TenantContext::default(), 1, 0, rx)\n        .await;\n\n    let mut synced = false;\n    let tenant_id = TenantId::default();\n    for _ in 0..10 {\n        tokio::time::sleep(std::time::Duration::from_millis(500)).await;\n        let state = persister.load(\u0026tenant_id).await?;\n        if state.stats.total_items_synced \u003e 0 {\n            synced = true;\n            break;\n        }\n    }\n\n    handle.abort();\n    assert!(synced, \"Background sync should have picked up the change\");\n\n    Ok(())\n}\n\n#[tokio::test]\nasync fn test_governance_blocking_sync() -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    let repo_dir = tempfile::tempdir()?;\n    let knowledge_repo = Arc::new(GitRepository::new(repo_dir.path())?);\n    let mut governance_engine = GovernanceEngine::new();\n\n    governance_engine.add_policy(mk_core::types::Policy {\n        id: \"p1\".to_string(),\n        name: \"No Secrets\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: mk_core::types::PolicyMode::Mandatory,\n        merge_strategy: mk_core::types::RuleMergeStrategy::Override,\n        rules: vec![mk_core::types::PolicyRule {\n            id: \"r1\".to_string(),\n            rule_type: mk_core::types::RuleType::Allow,\n            target: mk_core::types::ConstraintTarget::Code,\n            operator: mk_core::types::ConstraintOperator::MustNotMatch,\n            value: serde_json::json!(\"SECRET\"),\n            severity: mk_core::types::ConstraintSeverity::Block,\n            message: \"No secrets allowed\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    });\n\n    let memory_manager = Arc::new(MemoryManager::new());\n    let mock_provider = MockProvider::new();\n    memory_manager\n        .register_provider(MemoryLayer::Project, Box::new(mock_provider))\n        .await;\n\n    let storage = Arc::new(MockStorage::new());\n    let persister = Arc::new(SimplePersister {\n        storage: storage.clone(),\n    });\n\n    let sync_manager = SyncManager::new(\n        memory_manager.clone(),\n        knowledge_repo.clone(),\n        Arc::new(governance_engine),\n        config::DeploymentConfig::default(),\n        None,\n        persister.clone(),\n    )\n    .await?;\n\n    let entry = KnowledgeEntry {\n        path: \"secret.md\".to_string(),\n        content: \"My SECRET is 12345\".to_string(),\n        layer: KnowledgeLayer::Project,\n        kind: KnowledgeType::Spec,\n        status: KnowledgeStatus::Accepted,\n        metadata: HashMap::new(),\n        commit_hash: None,\n        author: None,\n        updated_at: chrono::Utc::now().timestamp(),\n    };\n    knowledge_repo\n        .store(TenantContext::default(), entry, \"secret commit\")\n        .await?;\n\n    sync_manager.sync_all(TenantContext::default()).await?;\n\n    let tenant_id = TenantId::default();\n    let state = persister.load(\u0026tenant_id).await?;\n    assert_eq!(state.stats.total_items_synced, 0);\n    assert!(state.stats.total_governance_blocks \u003e 0);\n\n    Ok(())\n}\n","traces":[{"line":23,"address":[],"length":0,"stats":{"Line":3}},{"line":25,"address":[],"length":0,"stats":{"Line":6}},{"line":34,"address":[],"length":0,"stats":{"Line":6}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":1}},{"line":134,"address":[],"length":0,"stats":{"Line":0}}],"covered":4,"coverable":6},{"path":["/","Users","christian.klat","dev","git","aeterna","test-project","src","main.rs"],"content":"fn main() {\n    println!(\"Hello, world!\");\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","backend.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","bridge.rs"],"content":"use crate::tools::Tool;\nuse async_trait::async_trait;\nuse mk_core::types::TenantContext;\nuse schemars::JsonSchema;\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Value, json};\nuse std::sync::Arc;\nuse sync::bridge::SyncManager;\nuse validator::Validate;\n\npub struct SyncNowTool {\n    sync_manager: Arc\u003cSyncManager\u003e\n}\n\nimpl SyncNowTool {\n    pub fn new(sync_manager: Arc\u003cSyncManager\u003e) -\u003e Self {\n        Self { sync_manager }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct SyncNowparams {\n    #[serde(default)]\n    pub force: bool,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[async_trait]\nimpl Tool for SyncNowTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"sync_now\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Trigger manual synchronization between memory and knowledge systems.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"force\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Force full sync (ignore delta detection)\",\n                    \"default\": false\n                },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            }\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: SyncNowparams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        if p.force {\n            self.sync_manager.sync_all(ctx).await?;\n        } else {\n            self.sync_manager.sync_incremental(ctx).await?;\n        }\n\n        Ok(json!({\n            \"success\": true,\n            \"message\": \"Synchronization completed\"\n        }))\n    }\n}\n\npub struct SyncStatusTool {\n    sync_manager: Arc\u003cSyncManager\u003e\n}\n\nimpl SyncStatusTool {\n    pub fn new(sync_manager: Arc\u003cSyncManager\u003e) -\u003e Self {\n        Self { sync_manager }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct SyncStatusParams {\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[async_trait]\nimpl Tool for SyncStatusTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"sync_status\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Check the current sync status, including last sync time and health.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            }\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: SyncStatusParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let state = self.sync_manager.get_state(\u0026ctx.tenant_id).await?;\n\n        Ok(json!({\n            \"success\": true,\n            \"healthy\": state.failed_items.is_empty() \u0026\u0026 state.federation_conflicts.is_empty(),\n            \"lastSyncAt\": state.last_sync_at,\n            \"failedItems\": state.failed_items.len(),\n            \"federationConflicts\": state.federation_conflicts,\n            \"stats\": {\n                \"totalSyncs\": state.stats.total_syncs,\n                \"totalItemsSynced\": state.stats.total_items_synced,\n                \"totalConflicts\": state.stats.total_conflicts,\n                \"totalGovernanceBlocks\": state.stats.total_governance_blocks,\n                \"avgSyncDurationMs\": state.stats.avg_sync_duration_ms,\n                \"driftScore\": state.stats.drift_score,\n                \"policyViolations\": state.stats.policy_violations\n            }\n        }))\n    }\n}\n\npub struct ResolveFederationConflictTool {\n    sync_manager: Arc\u003cSyncManager\u003e\n}\n\nimpl ResolveFederationConflictTool {\n    pub fn new(sync_manager: Arc\u003cSyncManager\u003e) -\u003e Self {\n        Self { sync_manager }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct ResolveFederationConflictParams {\n    pub upstream_id: String,\n    pub resolution: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[async_trait]\nimpl Tool for ResolveFederationConflictTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"knowledge_resolve_conflict\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Resolve a federation conflict by choosing a resolution strategy (ours, theirs, manual).\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"upstream_id\": {\n                    \"type\": \"string\",\n                    \"description\": \"ID of the upstream with conflict\"\n                },\n                \"resolution\": {\n                    \"type\": \"string\",\n                    \"description\": \"Resolution strategy: ours, theirs, or manual\",\n                    \"enum\": [\"ours\", \"theirs\", \"manual\"]\n                },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"upstream_id\", \"resolution\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: ResolveFederationConflictParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        self.sync_manager\n            .resolve_federation_conflict(ctx.tenant_id, \u0026p.upstream_id, \u0026p.resolution)\n            .await?;\n\n        Ok(json!({\n            \"success\": true,\n            \"message\": format!(\"Conflict for {} resolved as {}\", p.upstream_id, p.resolution)\n        }))\n    }\n}\n","traces":[{"line":16,"address":[],"length":0,"stats":{"Line":19}},{"line":31,"address":[],"length":0,"stats":{"Line":23}},{"line":32,"address":[],"length":0,"stats":{"Line":23}},{"line":35,"address":[],"length":0,"stats":{"Line":5}},{"line":36,"address":[],"length":0,"stats":{"Line":5}},{"line":39,"address":[],"length":0,"stats":{"Line":5}},{"line":40,"address":[],"length":0,"stats":{"Line":5}},{"line":41,"address":[],"length":0,"stats":{"Line":5}},{"line":42,"address":[],"length":0,"stats":{"Line":5}},{"line":43,"address":[],"length":0,"stats":{"Line":5}},{"line":44,"address":[],"length":0,"stats":{"Line":5}},{"line":45,"address":[],"length":0,"stats":{"Line":5}},{"line":46,"address":[],"length":0,"stats":{"Line":5}},{"line":48,"address":[],"length":0,"stats":{"Line":10}},{"line":53,"address":[],"length":0,"stats":{"Line":1}},{"line":77,"address":[],"length":0,"stats":{"Line":19}},{"line":90,"address":[],"length":0,"stats":{"Line":23}},{"line":91,"address":[],"length":0,"stats":{"Line":23}},{"line":94,"address":[],"length":0,"stats":{"Line":5}},{"line":95,"address":[],"length":0,"stats":{"Line":5}},{"line":98,"address":[],"length":0,"stats":{"Line":5}},{"line":99,"address":[],"length":0,"stats":{"Line":5}},{"line":100,"address":[],"length":0,"stats":{"Line":5}},{"line":101,"address":[],"length":0,"stats":{"Line":5}},{"line":102,"address":[],"length":0,"stats":{"Line":10}},{"line":107,"address":[],"length":0,"stats":{"Line":2}},{"line":139,"address":[],"length":0,"stats":{"Line":18}},{"line":154,"address":[],"length":0,"stats":{"Line":23}},{"line":155,"address":[],"length":0,"stats":{"Line":23}},{"line":158,"address":[],"length":0,"stats":{"Line":5}},{"line":159,"address":[],"length":0,"stats":{"Line":5}},{"line":162,"address":[],"length":0,"stats":{"Line":5}},{"line":163,"address":[],"length":0,"stats":{"Line":5}},{"line":164,"address":[],"length":0,"stats":{"Line":5}},{"line":165,"address":[],"length":0,"stats":{"Line":5}},{"line":166,"address":[],"length":0,"stats":{"Line":5}},{"line":167,"address":[],"length":0,"stats":{"Line":5}},{"line":168,"address":[],"length":0,"stats":{"Line":5}},{"line":170,"address":[],"length":0,"stats":{"Line":5}},{"line":171,"address":[],"length":0,"stats":{"Line":5}},{"line":172,"address":[],"length":0,"stats":{"Line":5}},{"line":173,"address":[],"length":0,"stats":{"Line":5}},{"line":175,"address":[],"length":0,"stats":{"Line":10}},{"line":177,"address":[],"length":0,"stats":{"Line":5}},{"line":181,"address":[],"length":0,"stats":{"Line":0}}],"covered":44,"coverable":45},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","config.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","ecosystem.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","episodic.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","governance.rs"],"content":"use crate::tools::Tool;\nuse async_trait::async_trait;\nuse knowledge::governance::GovernanceEngine;\nuse mk_core::types::{GovernanceEvent, OrganizationalUnit, Role, TenantContext, UnitType};\nuse schemars::JsonSchema;\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Value, json};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse validator::Validate;\n\n/// Tool to create a new organizational unit.\npub struct UnitCreateTool {\n    backend: Arc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e,\n    governance_engine: Arc\u003cGovernanceEngine\u003e\n}\n\nimpl UnitCreateTool {\n    pub fn new(\n        backend: Arc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e,\n        governance_engine: Arc\u003cGovernanceEngine\u003e\n    ) -\u003e Self {\n        Self {\n            backend,\n            governance_engine\n        }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct UnitCreateParams {\n    pub name: String,\n    pub unit_type: String,\n    pub parent_id: Option\u003cString\u003e,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e,\n    #[serde(default)]\n    pub metadata: HashMap\u003cString, Value\u003e\n}\n\n#[async_trait]\nimpl Tool for UnitCreateTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"governance_unit_create\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Create a new organizational unit (Company, Organization, Team, or Project).\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"name\": { \"type\": \"string\", \"description\": \"Name of the unit\" },\n                \"unit_type\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"company\", \"organization\", \"team\", \"project\"],\n                    \"description\": \"Type of the unit\"\n                },\n                \"parent_id\": { \"type\": \"string\", \"description\": \"Parent unit ID\" },\n                \"metadata\": { \"type\": \"object\", \"description\": \"Optional metadata\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"name\", \"unit_type\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: UnitCreateParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let unit_type = match p.unit_type.as_str() {\n            \"company\" =\u003e UnitType::Company,\n            \"organization\" =\u003e UnitType::Organization,\n            \"team\" =\u003e UnitType::Team,\n            \"project\" =\u003e UnitType::Project,\n            _ =\u003e return Err(\"Invalid unit type\".into())\n        };\n\n        let unit = OrganizationalUnit {\n            id: uuid::Uuid::new_v4().to_string(),\n            name: p.name,\n            unit_type,\n            parent_id: p.parent_id,\n            tenant_id: ctx.tenant_id.clone(),\n            metadata: p.metadata,\n            created_at: chrono::Utc::now().timestamp(),\n            updated_at: chrono::Utc::now().timestamp()\n        };\n\n        self.backend.create_unit(\u0026unit).await?;\n\n        let _ = self\n            .governance_engine\n            .publish_event(GovernanceEvent::UnitCreated {\n                unit_id: unit.id.clone(),\n                unit_type: unit.unit_type,\n                tenant_id: ctx.tenant_id.clone(),\n                parent_id: unit.parent_id.clone(),\n                timestamp: chrono::Utc::now().timestamp()\n            })\n            .await;\n\n        Ok(json!({\n            \"success\": true,\n            \"unit_id\": unit.id\n        }))\n    }\n}\n\n/// Tool to add a policy to an organizational unit.\npub struct UnitPolicyAddTool {\n    backend: Arc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e,\n    governance_engine: Arc\u003cGovernanceEngine\u003e\n}\n\nimpl UnitPolicyAddTool {\n    pub fn new(\n        backend: Arc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e,\n        governance_engine: Arc\u003cGovernanceEngine\u003e\n    ) -\u003e Self {\n        Self {\n            backend,\n            governance_engine\n        }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct UnitPolicyAddParams {\n    pub unit_id: String,\n    pub policy: mk_core::types::Policy,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[async_trait]\nimpl Tool for UnitPolicyAddTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"governance_policy_add\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Add or update a policy for an organizational unit.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"unit_id\": { \"type\": \"string\", \"description\": \"Unit ID to attach policy to\" },\n                \"policy\": { \"type\": \"object\", \"description\": \"Policy definition\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"unit_id\", \"policy\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: UnitPolicyAddParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        self.backend\n            .add_unit_policy(\u0026ctx, \u0026p.unit_id, \u0026p.policy)\n            .await?;\n\n        let _ = self\n            .governance_engine\n            .publish_event(GovernanceEvent::PolicyUpdated {\n                policy_id: p.policy.id.clone(),\n                layer: p.policy.layer,\n                tenant_id: ctx.tenant_id.clone(),\n                timestamp: chrono::Utc::now().timestamp()\n            })\n            .await;\n\n        Ok(json!({\n            \"success\": true,\n            \"policy_id\": p.policy.id\n        }))\n    }\n}\n\n/// Tool to assign a role to a user within an organizational unit.\npub struct UserRoleAssignTool {\n    backend: Arc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e,\n    governance_engine: Arc\u003cGovernanceEngine\u003e\n}\n\nimpl UserRoleAssignTool {\n    pub fn new(\n        backend: Arc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e,\n        governance_engine: Arc\u003cGovernanceEngine\u003e\n    ) -\u003e Self {\n        Self {\n            backend,\n            governance_engine\n        }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct UserRoleAssignParams {\n    pub user_id: String,\n    pub unit_id: String,\n    pub role: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[async_trait]\nimpl Tool for UserRoleAssignTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"governance_role_assign\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Assign a role to a user within a specific organizational unit.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"user_id\": { \"type\": \"string\", \"description\": \"User ID\" },\n                \"unit_id\": { \"type\": \"string\", \"description\": \"Unit ID\" },\n                \"role\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"developer\", \"techlead\", \"architect\", \"admin\", \"agent\"],\n                    \"description\": \"Role to assign\"\n                },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"user_id\", \"unit_id\", \"role\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: UserRoleAssignParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n        let user_id = mk_core::types::UserId::new(p.user_id).ok_or(\"Invalid user ID\")?;\n        let role: Role = p.role.parse()?;\n\n        self.backend\n            .assign_role(\u0026user_id, \u0026ctx.tenant_id, \u0026p.unit_id, role.clone())\n            .await?;\n\n        let _ = self\n            .governance_engine\n            .publish_event(GovernanceEvent::RoleAssigned {\n                user_id: user_id.clone(),\n                unit_id: p.unit_id.clone(),\n                role,\n                tenant_id: ctx.tenant_id.clone(),\n                timestamp: chrono::Utc::now().timestamp()\n            })\n            .await;\n\n        Ok(json!({\n            \"success\": true\n        }))\n    }\n}\n\n/// Tool to remove a role from a user within an organizational unit.\npub struct UserRoleRemoveTool {\n    backend: Arc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e,\n    governance_engine: Arc\u003cGovernanceEngine\u003e\n}\n\nimpl UserRoleRemoveTool {\n    pub fn new(\n        backend: Arc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e,\n        governance_engine: Arc\u003cGovernanceEngine\u003e\n    ) -\u003e Self {\n        Self {\n            backend,\n            governance_engine\n        }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct UserRoleRemoveParams {\n    pub user_id: String,\n    pub unit_id: String,\n    pub role: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[async_trait]\nimpl Tool for UserRoleRemoveTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"governance_role_remove\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Remove a role from a user within a specific organizational unit.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"user_id\": { \"type\": \"string\", \"description\": \"User ID\" },\n                \"unit_id\": { \"type\": \"string\", \"description\": \"Unit ID\" },\n                \"role\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"developer\", \"techlead\", \"architect\", \"admin\", \"agent\"],\n                    \"description\": \"Role to remove\"\n                },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"user_id\", \"unit_id\", \"role\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: UserRoleRemoveParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n        let user_id = mk_core::types::UserId::new(p.user_id).ok_or(\"Invalid user ID\")?;\n        let role: Role = p.role.parse()?;\n\n        self.backend\n            .remove_role(\u0026user_id, \u0026ctx.tenant_id, \u0026p.unit_id, role.clone())\n            .await?;\n\n        let _ = self\n            .governance_engine\n            .publish_event(GovernanceEvent::RoleRemoved {\n                user_id: user_id.clone(),\n                unit_id: p.unit_id.clone(),\n                role,\n                tenant_id: ctx.tenant_id.clone(),\n                timestamp: chrono::Utc::now().timestamp()\n            })\n            .await;\n\n        Ok(json!({\n            \"success\": true\n        }))\n    }\n}\n\npub struct HierarchyNavigateTool {\n    backend: Arc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e\n}\n\nimpl HierarchyNavigateTool {\n    pub fn new(\n        backend: Arc\u003cdyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e\u003e\n    ) -\u003e Self {\n        Self { backend }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct HierarchyNavigateParams {\n    pub unit_id: String,\n    pub direction: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[async_trait]\nimpl Tool for HierarchyNavigateTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"governance_hierarchy_navigate\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Navigate the organizational hierarchy (ancestors or descendants) for a unit.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"unit_id\": { \"type\": \"string\", \"description\": \"Starting Unit ID\" },\n                \"direction\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"ancestors\", \"descendants\"],\n                    \"description\": \"Navigation direction\"\n                },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"unit_id\", \"direction\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: HierarchyNavigateParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let units = match p.direction.as_str() {\n            \"ancestors\" =\u003e self.backend.get_ancestors(ctx, \u0026p.unit_id).await?,\n            \"descendants\" =\u003e self.backend.get_descendants(ctx, \u0026p.unit_id).await?,\n            _ =\u003e return Err(\"Invalid direction\".into())\n        };\n\n        Ok(json!({\n            \"success\": true,\n            \"units\": units\n        }))\n    }\n}\n","traces":[{"line":19,"address":[],"length":0,"stats":{"Line":18}},{"line":43,"address":[],"length":0,"stats":{"Line":23}},{"line":44,"address":[],"length":0,"stats":{"Line":23}},{"line":47,"address":[],"length":0,"stats":{"Line":5}},{"line":48,"address":[],"length":0,"stats":{"Line":5}},{"line":51,"address":[],"length":0,"stats":{"Line":5}},{"line":52,"address":[],"length":0,"stats":{"Line":5}},{"line":53,"address":[],"length":0,"stats":{"Line":5}},{"line":54,"address":[],"length":0,"stats":{"Line":5}},{"line":55,"address":[],"length":0,"stats":{"Line":15}},{"line":56,"address":[],"length":0,"stats":{"Line":5}},{"line":57,"address":[],"length":0,"stats":{"Line":5}},{"line":58,"address":[],"length":0,"stats":{"Line":5}},{"line":59,"address":[],"length":0,"stats":{"Line":5}},{"line":61,"address":[],"length":0,"stats":{"Line":15}},{"line":62,"address":[],"length":0,"stats":{"Line":15}},{"line":63,"address":[],"length":0,"stats":{"Line":10}},{"line":65,"address":[],"length":0,"stats":{"Line":5}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":18}},{"line":142,"address":[],"length":0,"stats":{"Line":23}},{"line":143,"address":[],"length":0,"stats":{"Line":23}},{"line":146,"address":[],"length":0,"stats":{"Line":5}},{"line":147,"address":[],"length":0,"stats":{"Line":5}},{"line":150,"address":[],"length":0,"stats":{"Line":5}},{"line":151,"address":[],"length":0,"stats":{"Line":5}},{"line":152,"address":[],"length":0,"stats":{"Line":5}},{"line":153,"address":[],"length":0,"stats":{"Line":5}},{"line":154,"address":[],"length":0,"stats":{"Line":15}},{"line":155,"address":[],"length":0,"stats":{"Line":15}},{"line":156,"address":[],"length":0,"stats":{"Line":10}},{"line":158,"address":[],"length":0,"stats":{"Line":5}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":18}},{"line":218,"address":[],"length":0,"stats":{"Line":23}},{"line":219,"address":[],"length":0,"stats":{"Line":23}},{"line":222,"address":[],"length":0,"stats":{"Line":5}},{"line":223,"address":[],"length":0,"stats":{"Line":5}},{"line":226,"address":[],"length":0,"stats":{"Line":5}},{"line":227,"address":[],"length":0,"stats":{"Line":5}},{"line":228,"address":[],"length":0,"stats":{"Line":5}},{"line":229,"address":[],"length":0,"stats":{"Line":5}},{"line":230,"address":[],"length":0,"stats":{"Line":15}},{"line":231,"address":[],"length":0,"stats":{"Line":15}},{"line":232,"address":[],"length":0,"stats":{"Line":5}},{"line":233,"address":[],"length":0,"stats":{"Line":5}},{"line":234,"address":[],"length":0,"stats":{"Line":5}},{"line":235,"address":[],"length":0,"stats":{"Line":5}},{"line":237,"address":[],"length":0,"stats":{"Line":10}},{"line":239,"address":[],"length":0,"stats":{"Line":5}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":18}},{"line":301,"address":[],"length":0,"stats":{"Line":23}},{"line":302,"address":[],"length":0,"stats":{"Line":23}},{"line":305,"address":[],"length":0,"stats":{"Line":5}},{"line":306,"address":[],"length":0,"stats":{"Line":5}},{"line":309,"address":[],"length":0,"stats":{"Line":5}},{"line":310,"address":[],"length":0,"stats":{"Line":5}},{"line":311,"address":[],"length":0,"stats":{"Line":5}},{"line":312,"address":[],"length":0,"stats":{"Line":5}},{"line":313,"address":[],"length":0,"stats":{"Line":15}},{"line":314,"address":[],"length":0,"stats":{"Line":15}},{"line":315,"address":[],"length":0,"stats":{"Line":5}},{"line":316,"address":[],"length":0,"stats":{"Line":5}},{"line":317,"address":[],"length":0,"stats":{"Line":5}},{"line":318,"address":[],"length":0,"stats":{"Line":5}},{"line":320,"address":[],"length":0,"stats":{"Line":10}},{"line":322,"address":[],"length":0,"stats":{"Line":5}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":360,"address":[],"length":0,"stats":{"Line":18}},{"line":377,"address":[],"length":0,"stats":{"Line":23}},{"line":378,"address":[],"length":0,"stats":{"Line":23}},{"line":381,"address":[],"length":0,"stats":{"Line":5}},{"line":382,"address":[],"length":0,"stats":{"Line":5}},{"line":385,"address":[],"length":0,"stats":{"Line":5}},{"line":386,"address":[],"length":0,"stats":{"Line":5}},{"line":387,"address":[],"length":0,"stats":{"Line":5}},{"line":388,"address":[],"length":0,"stats":{"Line":5}},{"line":389,"address":[],"length":0,"stats":{"Line":15}},{"line":390,"address":[],"length":0,"stats":{"Line":5}},{"line":391,"address":[],"length":0,"stats":{"Line":5}},{"line":392,"address":[],"length":0,"stats":{"Line":5}},{"line":393,"address":[],"length":0,"stats":{"Line":5}},{"line":395,"address":[],"length":0,"stats":{"Line":10}},{"line":397,"address":[],"length":0,"stats":{"Line":5}},{"line":401,"address":[],"length":0,"stats":{"Line":0}}],"covered":81,"coverable":86},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","hot_reload.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","knowledge.rs"],"content":"use crate::tools::Tool;\nuse async_trait::async_trait;\nuse memory::manager::MemoryManager;\nuse mk_core::traits::KnowledgeRepository;\nuse mk_core::types::{MemoryEntry, TenantContext};\nuse schemars::JsonSchema;\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Value, json};\nuse std::sync::Arc;\nuse validator::Validate;\n\npub struct KnowledgeGetTool {\n    repo: Arc\u003cdyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e\u003e\n}\n\nimpl KnowledgeGetTool {\n    pub fn new(\n        repo: Arc\u003cdyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e\u003e\n    ) -\u003e Self {\n        Self { repo }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct KnowledgeGetParams {\n    pub path: String,\n    pub layer: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct KnowledgeListParams {\n    pub layer: String,\n    #[serde(default)]\n    pub prefix: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct KnowledgeQueryParams {\n    pub query: String,\n    #[serde(default)]\n    pub layers: Vec\u003cString\u003e,\n    pub limit: Option\u003cusize\u003e,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[async_trait]\nimpl Tool for KnowledgeGetTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"knowledge_get\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Retrieve a specific knowledge entry by path and layer.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"path\": { \"type\": \"string\" },\n                \"layer\": { \"type\": \"string\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"path\", \"layer\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: KnowledgeGetParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let layer = match p.layer.to_lowercase().as_str() {\n            \"company\" =\u003e mk_core::types::KnowledgeLayer::Company,\n            \"org\" =\u003e mk_core::types::KnowledgeLayer::Org,\n            \"team\" =\u003e mk_core::types::KnowledgeLayer::Team,\n            \"project\" =\u003e mk_core::types::KnowledgeLayer::Project,\n            _ =\u003e return Err(format!(\"Unknown layer: {}\", p.layer).into())\n        };\n\n        let entry = self.repo.get(ctx, layer, \u0026p.path).await?;\n        Ok(json!({ \"success\": true, \"entry\": entry }))\n    }\n}\n\npub struct KnowledgeListTool {\n    repo: Arc\u003cdyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e\u003e\n}\n\nimpl KnowledgeListTool {\n    pub fn new(\n        repo: Arc\u003cdyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e\u003e\n    ) -\u003e Self {\n        Self { repo }\n    }\n}\n\n#[async_trait]\nimpl Tool for KnowledgeListTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"knowledge_list\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"List knowledge entries in a specific layer, optionally filtered by prefix.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"layer\": { \"type\": \"string\" },\n                \"prefix\": { \"type\": \"string\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"layer\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: KnowledgeListParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let layer = match p.layer.to_lowercase().as_str() {\n            \"company\" =\u003e mk_core::types::KnowledgeLayer::Company,\n            \"org\" =\u003e mk_core::types::KnowledgeLayer::Org,\n            \"team\" =\u003e mk_core::types::KnowledgeLayer::Team,\n            \"project\" =\u003e mk_core::types::KnowledgeLayer::Project,\n            _ =\u003e return Err(format!(\"Unknown layer: {}\", p.layer).into())\n        };\n\n        let entries = self.repo.list(ctx, layer, \u0026p.prefix).await?;\n        Ok(json!({ \"success\": true, \"entries\": entries }))\n    }\n}\n\npub struct KnowledgeQueryTool {\n    memory_manager: Arc\u003cMemoryManager\u003e,\n    repo: Arc\u003cdyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e\u003e\n}\n\nimpl KnowledgeQueryTool {\n    pub fn new(\n        memory_manager: Arc\u003cMemoryManager\u003e,\n        repo: Arc\u003cdyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e\u003e\n    ) -\u003e Self {\n        Self {\n            memory_manager,\n            repo\n        }\n    }\n}\n\n#[async_trait]\nimpl Tool for KnowledgeQueryTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"knowledge_query\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Search for knowledge entries across layers using semantic or keyword search.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": { \"type\": \"string\" },\n                \"layers\": { \"type\": \"array\", \"items\": { \"type\": \"string\" } },\n                \"limit\": { \"type\": \"integer\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"query\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: KnowledgeQueryParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let mut layers = Vec::new();\n        if p.layers.is_empty() {\n            layers = vec![\n                mk_core::types::KnowledgeLayer::Company,\n                mk_core::types::KnowledgeLayer::Org,\n                mk_core::types::KnowledgeLayer::Team,\n                mk_core::types::KnowledgeLayer::Project,\n            ];\n        } else {\n            for l in \u0026p.layers {\n                let layer = match l.to_lowercase().as_str() {\n                    \"company\" =\u003e mk_core::types::KnowledgeLayer::Company,\n                    \"org\" =\u003e mk_core::types::KnowledgeLayer::Org,\n                    \"team\" =\u003e mk_core::types::KnowledgeLayer::Team,\n                    \"project\" =\u003e mk_core::types::KnowledgeLayer::Project,\n                    _ =\u003e continue\n                };\n                layers.push(layer);\n            }\n        }\n\n        let vector_results: Vec\u003cMemoryEntry\u003e = self\n            .memory_manager\n            .search_text_with_threshold(\n                ctx.clone(),\n                \u0026p.query,\n                p.limit.unwrap_or(10),\n                0.7,\n                std::collections::HashMap::new()\n            )\n            .await\n            .unwrap_or_default();\n\n        let repo_results = self\n            .repo\n            .search(ctx, \u0026p.query, layers, p.limit.unwrap_or(10))\n            .await?;\n\n        Ok(json!({\n            \"success\": true,\n            \"results\": {\n                \"semantic\": vector_results,\n                \"keyword\": repo_results\n            }\n        }))\n    }\n}\n","traces":[{"line":17,"address":[],"length":0,"stats":{"Line":19}},{"line":53,"address":[],"length":0,"stats":{"Line":23}},{"line":54,"address":[],"length":0,"stats":{"Line":23}},{"line":57,"address":[],"length":0,"stats":{"Line":5}},{"line":58,"address":[],"length":0,"stats":{"Line":5}},{"line":61,"address":[],"length":0,"stats":{"Line":5}},{"line":62,"address":[],"length":0,"stats":{"Line":5}},{"line":63,"address":[],"length":0,"stats":{"Line":5}},{"line":64,"address":[],"length":0,"stats":{"Line":5}},{"line":65,"address":[],"length":0,"stats":{"Line":10}},{"line":66,"address":[],"length":0,"stats":{"Line":10}},{"line":67,"address":[],"length":0,"stats":{"Line":10}},{"line":69,"address":[],"length":0,"stats":{"Line":5}},{"line":73,"address":[],"length":0,"stats":{"Line":2}},{"line":97,"address":[],"length":0,"stats":{"Line":18}},{"line":106,"address":[],"length":0,"stats":{"Line":23}},{"line":107,"address":[],"length":0,"stats":{"Line":23}},{"line":110,"address":[],"length":0,"stats":{"Line":5}},{"line":111,"address":[],"length":0,"stats":{"Line":5}},{"line":114,"address":[],"length":0,"stats":{"Line":5}},{"line":115,"address":[],"length":0,"stats":{"Line":5}},{"line":116,"address":[],"length":0,"stats":{"Line":5}},{"line":117,"address":[],"length":0,"stats":{"Line":5}},{"line":118,"address":[],"length":0,"stats":{"Line":10}},{"line":119,"address":[],"length":0,"stats":{"Line":10}},{"line":120,"address":[],"length":0,"stats":{"Line":10}},{"line":122,"address":[],"length":0,"stats":{"Line":5}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":19}},{"line":164,"address":[],"length":0,"stats":{"Line":23}},{"line":165,"address":[],"length":0,"stats":{"Line":23}},{"line":168,"address":[],"length":0,"stats":{"Line":5}},{"line":169,"address":[],"length":0,"stats":{"Line":5}},{"line":172,"address":[],"length":0,"stats":{"Line":5}},{"line":173,"address":[],"length":0,"stats":{"Line":5}},{"line":174,"address":[],"length":0,"stats":{"Line":5}},{"line":175,"address":[],"length":0,"stats":{"Line":5}},{"line":176,"address":[],"length":0,"stats":{"Line":10}},{"line":177,"address":[],"length":0,"stats":{"Line":20}},{"line":178,"address":[],"length":0,"stats":{"Line":10}},{"line":179,"address":[],"length":0,"stats":{"Line":10}},{"line":181,"address":[],"length":0,"stats":{"Line":5}},{"line":185,"address":[],"length":0,"stats":{"Line":2}}],"covered":42,"coverable":43},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","lib.rs"],"content":"//! # MCP Tools Interface\n//!\n//! 8 MCP tools for memory-knowledge system.\n\npub mod bridge;\npub mod governance;\npub mod knowledge;\npub mod memory;\npub mod redis_publisher;\npub mod server;\npub mod tools;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","loader.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","memory.rs"],"content":"use crate::tools::Tool;\nuse async_trait::async_trait;\nuse memory::manager::MemoryManager;\nuse mk_core::types::TenantContext;\nuse schemars::JsonSchema;\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Value, json};\nuse std::sync::Arc;\nuse validator::Validate;\n\npub struct MemoryAddTool {\n    memory_manager: Arc\u003cMemoryManager\u003e\n}\n\nimpl MemoryAddTool {\n    pub fn new(memory_manager: Arc\u003cMemoryManager\u003e) -\u003e Self {\n        Self { memory_manager }\n    }\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct MemoryAddParams {\n    pub content: String,\n    pub layer: String,\n    #[serde(default)]\n    pub metadata: serde_json::Map\u003cString, Value\u003e,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct MemorySearchParams {\n    pub query: String,\n    pub limit: Option\u003cusize\u003e,\n    pub threshold: Option\u003cf32\u003e,\n    #[serde(default)]\n    pub filters: serde_json::Map\u003cString, Value\u003e,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct MemoryDeleteParams {\n    pub memory_id: String,\n    pub layer: String,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Debug)]\n#[serde(rename_all = \"camelCase\")]\npub enum CloseTarget {\n    Session,\n    Agent\n}\n\n#[derive(Serialize, Deserialize, JsonSchema, Validate)]\npub struct MemoryCloseParams {\n    pub id: String,\n    pub target: CloseTarget,\n    #[serde(rename = \"tenantContext\")]\n    pub tenant_context: Option\u003cTenantContext\u003e\n}\n\n#[async_trait]\nimpl Tool for MemoryAddTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"memory_add\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Store a piece of information in memory for future reference.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"content\": { \"type\": \"string\" },\n                \"layer\": { \"type\": \"string\" },\n                \"metadata\": { \"type\": \"object\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"content\", \"layer\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: MemoryAddParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let layer = match p.layer.to_lowercase().as_str() {\n            \"agent\" =\u003e mk_core::types::MemoryLayer::Agent,\n            \"user\" =\u003e mk_core::types::MemoryLayer::User,\n            \"session\" =\u003e mk_core::types::MemoryLayer::Session,\n            \"project\" =\u003e mk_core::types::MemoryLayer::Project,\n            \"team\" =\u003e mk_core::types::MemoryLayer::Team,\n            \"org\" =\u003e mk_core::types::MemoryLayer::Org,\n            \"company\" =\u003e mk_core::types::MemoryLayer::Company,\n            _ =\u003e return Err(format!(\"Unknown layer: {}\", p.layer).into())\n        };\n        let entry = mk_core::types::MemoryEntry {\n            id: uuid::Uuid::new_v4().to_string(),\n            content: p.content,\n            embedding: None,\n            layer,\n            metadata: p.metadata.into_iter().collect(),\n            created_at: chrono::Utc::now().timestamp(),\n            updated_at: chrono::Utc::now().timestamp()\n        };\n\n        let id = self.memory_manager.add_to_layer(ctx, layer, entry).await?;\n        Ok(json!({ \"success\": true, \"memoryId\": id }))\n    }\n}\n\npub struct MemorySearchTool {\n    memory_manager: Arc\u003cMemoryManager\u003e\n}\n\nimpl MemorySearchTool {\n    pub fn new(memory_manager: Arc\u003cMemoryManager\u003e) -\u003e Self {\n        Self { memory_manager }\n    }\n}\n\n#[async_trait]\nimpl Tool for MemorySearchTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"memory_search\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Search for memories across layers.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": { \"type\": \"string\" },\n                \"limit\": { \"type\": \"integer\" },\n                \"threshold\": { \"type\": \"number\" },\n                \"filters\": { \"type\": \"object\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"query\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: MemorySearchParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let limit = p.limit.unwrap_or(10);\n        let threshold = p.threshold.unwrap_or(0.0);\n        let filters: std::collections::HashMap\u003cString, Value\u003e = p.filters.into_iter().collect();\n\n        let results = self\n            .memory_manager\n            .search_text_with_threshold(ctx, \u0026p.query, limit, threshold, filters)\n            .await?;\n\n        Ok(json!({\n            \"success\": true,\n            \"results\": results,\n            \"totalCount\": results.len()\n        }))\n    }\n}\n\npub struct MemoryDeleteTool {\n    memory_manager: Arc\u003cMemoryManager\u003e\n}\n\nimpl MemoryDeleteTool {\n    pub fn new(memory_manager: Arc\u003cMemoryManager\u003e) -\u003e Self {\n        Self { memory_manager }\n    }\n}\n\n#[async_trait]\nimpl Tool for MemoryDeleteTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"memory_delete\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Delete a memory from a specific layer.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"id\": { \"type\": \"string\" },\n                \"layer\": { \"type\": \"string\" },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"id\", \"layer\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: MemoryDeleteParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        let layer = match p.layer.to_lowercase().as_str() {\n            \"agent\" =\u003e mk_core::types::MemoryLayer::Agent,\n            \"user\" =\u003e mk_core::types::MemoryLayer::User,\n            \"session\" =\u003e mk_core::types::MemoryLayer::Session,\n            \"project\" =\u003e mk_core::types::MemoryLayer::Project,\n            \"team\" =\u003e mk_core::types::MemoryLayer::Team,\n            \"org\" =\u003e mk_core::types::MemoryLayer::Org,\n            \"company\" =\u003e mk_core::types::MemoryLayer::Company,\n            _ =\u003e return Err(format!(\"Unknown layer: {}\", p.layer).into())\n        };\n        self.memory_manager\n            .delete_from_layer(ctx, layer, \u0026p.memory_id)\n            .await?;\n        Ok(json!({ \"success\": true }))\n    }\n}\n\npub struct MemoryCloseTool {\n    memory_manager: Arc\u003cMemoryManager\u003e\n}\n\nimpl MemoryCloseTool {\n    pub fn new(memory_manager: Arc\u003cMemoryManager\u003e) -\u003e Self {\n        Self { memory_manager }\n    }\n}\n\n#[async_trait]\nimpl Tool for MemoryCloseTool {\n    fn name(\u0026self) -\u003e \u0026str {\n        \"memory_close\"\n    }\n\n    fn description(\u0026self) -\u003e \u0026str {\n        \"Close a session or agent, triggering memory promotion and cleanup.\"\n    }\n\n    fn input_schema(\u0026self) -\u003e Value {\n        json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"id\": { \"type\": \"string\", \"description\": \"Session or Agent ID\" },\n                \"target\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"session\", \"agent\"],\n                    \"description\": \"What to close\"\n                },\n                \"tenantContext\": { \"$ref\": \"#/definitions/TenantContext\" }\n            },\n            \"required\": [\"id\", \"target\"]\n        })\n    }\n\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let p: MemoryCloseParams = serde_json::from_value(params)?;\n        p.validate()?;\n\n        let ctx = p.tenant_context.ok_or(\"Missing tenant context\")?;\n\n        match p.target {\n            CloseTarget::Session =\u003e self.memory_manager.close_session(ctx, \u0026p.id).await?,\n            CloseTarget::Agent =\u003e self.memory_manager.close_agent(ctx, \u0026p.id).await?\n        }\n\n        Ok(json!({\n            \"success\": true,\n            \"message\": format!(\"{:?} closed successfully\", p.target)\n        }))\n    }\n}\n","traces":[{"line":16,"address":[],"length":0,"stats":{"Line":19}},{"line":67,"address":[],"length":0,"stats":{"Line":23}},{"line":68,"address":[],"length":0,"stats":{"Line":23}},{"line":71,"address":[],"length":0,"stats":{"Line":5}},{"line":72,"address":[],"length":0,"stats":{"Line":5}},{"line":75,"address":[],"length":0,"stats":{"Line":5}},{"line":76,"address":[],"length":0,"stats":{"Line":5}},{"line":77,"address":[],"length":0,"stats":{"Line":5}},{"line":78,"address":[],"length":0,"stats":{"Line":5}},{"line":79,"address":[],"length":0,"stats":{"Line":10}},{"line":80,"address":[],"length":0,"stats":{"Line":10}},{"line":81,"address":[],"length":0,"stats":{"Line":10}},{"line":82,"address":[],"length":0,"stats":{"Line":10}},{"line":84,"address":[],"length":0,"stats":{"Line":5}},{"line":88,"address":[],"length":0,"stats":{"Line":4}},{"line":124,"address":[],"length":0,"stats":{"Line":19}},{"line":131,"address":[],"length":0,"stats":{"Line":23}},{"line":132,"address":[],"length":0,"stats":{"Line":23}},{"line":135,"address":[],"length":0,"stats":{"Line":5}},{"line":136,"address":[],"length":0,"stats":{"Line":5}},{"line":139,"address":[],"length":0,"stats":{"Line":5}},{"line":140,"address":[],"length":0,"stats":{"Line":5}},{"line":141,"address":[],"length":0,"stats":{"Line":5}},{"line":142,"address":[],"length":0,"stats":{"Line":5}},{"line":143,"address":[],"length":0,"stats":{"Line":10}},{"line":144,"address":[],"length":0,"stats":{"Line":10}},{"line":145,"address":[],"length":0,"stats":{"Line":10}},{"line":146,"address":[],"length":0,"stats":{"Line":10}},{"line":147,"address":[],"length":0,"stats":{"Line":10}},{"line":149,"address":[],"length":0,"stats":{"Line":5}},{"line":153,"address":[],"length":0,"stats":{"Line":2}},{"line":181,"address":[],"length":0,"stats":{"Line":19}},{"line":188,"address":[],"length":0,"stats":{"Line":23}},{"line":189,"address":[],"length":0,"stats":{"Line":23}},{"line":192,"address":[],"length":0,"stats":{"Line":5}},{"line":193,"address":[],"length":0,"stats":{"Line":5}},{"line":196,"address":[],"length":0,"stats":{"Line":5}},{"line":197,"address":[],"length":0,"stats":{"Line":5}},{"line":198,"address":[],"length":0,"stats":{"Line":5}},{"line":199,"address":[],"length":0,"stats":{"Line":5}},{"line":200,"address":[],"length":0,"stats":{"Line":10}},{"line":201,"address":[],"length":0,"stats":{"Line":10}},{"line":202,"address":[],"length":0,"stats":{"Line":10}},{"line":204,"address":[],"length":0,"stats":{"Line":5}},{"line":208,"address":[],"length":0,"stats":{"Line":1}},{"line":236,"address":[],"length":0,"stats":{"Line":18}},{"line":243,"address":[],"length":0,"stats":{"Line":23}},{"line":244,"address":[],"length":0,"stats":{"Line":23}},{"line":247,"address":[],"length":0,"stats":{"Line":5}},{"line":248,"address":[],"length":0,"stats":{"Line":5}},{"line":251,"address":[],"length":0,"stats":{"Line":5}},{"line":252,"address":[],"length":0,"stats":{"Line":5}},{"line":253,"address":[],"length":0,"stats":{"Line":5}},{"line":254,"address":[],"length":0,"stats":{"Line":5}},{"line":255,"address":[],"length":0,"stats":{"Line":15}},{"line":256,"address":[],"length":0,"stats":{"Line":5}},{"line":257,"address":[],"length":0,"stats":{"Line":5}},{"line":258,"address":[],"length":0,"stats":{"Line":5}},{"line":259,"address":[],"length":0,"stats":{"Line":5}},{"line":261,"address":[],"length":0,"stats":{"Line":10}},{"line":263,"address":[],"length":0,"stats":{"Line":5}},{"line":267,"address":[],"length":0,"stats":{"Line":0}}],"covered":61,"coverable":62},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","opencode.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","pointer.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","pool.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","postgres.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","procedural.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","providers.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","qdrant.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","redis.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","redis_publisher.rs"],"content":"use mk_core::types::{GovernanceEvent, TenantId};\nuse tokio::sync::mpsc::UnboundedReceiver;\nuse tracing::{error, info};\n\n/// Redis publisher for governance events with tenant isolation.\n///\n/// Listens for governance events on a channel and publishes them to Redis\n/// Streams with per-tenant isolation. Routes events to the correct\n/// tenant stream based on the tenant_id in each event.\npub struct RedisPublisher {\n    redis_url: String,\n    base_stream_key: String,\n}\n\nimpl RedisPublisher {\n    /// Creates a new Redis publisher with tenant isolation.\n    ///\n    /// Events will be published to streams named\n    /// `{base_stream_key}:{tenant_id}`.\n    pub fn new_with_tenant_isolation(redis_url: String, base_stream_key: String) -\u003e Self {\n        Self {\n            redis_url,\n            base_stream_key,\n        }\n    }\n\n    /// Creates a new Redis publisher for a specific tenant (legacy API).\n    pub fn new_for_tenant(redis_url: String, tenant_id: \u0026TenantId) -\u003e Self {\n        let base_stream_key = format!(\"governance:events:{}\", tenant_id.as_str());\n        Self {\n            redis_url,\n            base_stream_key,\n        }\n    }\n\n    /// Creates a new Redis publisher with a custom stream key (no tenant\n    /// isolation).\n    pub fn new(redis_url: String, stream_key: String) -\u003e Self {\n        Self {\n            redis_url,\n            base_stream_key: stream_key,\n        }\n    }\n\n    /// Starts the Redis publisher task.\n    ///\n    /// This spawns a Tokio task that listens for events and publishes them to\n    /// Redis. Returns a channel sender that can be used to send events.\n    pub fn start(\n        self,\n    ) -\u003e (\n        tokio::sync::mpsc::UnboundedSender\u003cGovernanceEvent\u003e,\n        tokio::task::JoinHandle\u003c()\u003e,\n    ) {\n        let (event_tx, event_rx) = tokio::sync::mpsc::unbounded_channel();\n\n        let handle = tokio::spawn(async move {\n            if let Err(e) = self.run(event_rx).await {\n                error!(\"Redis publisher task failed: {}\", e);\n            }\n        });\n\n        (event_tx, handle)\n    }\n\n    /// Main loop for the Redis publisher.\n    async fn run(\n        self,\n        mut event_rx: UnboundedReceiver\u003cGovernanceEvent\u003e,\n    ) -\u003e Result\u003c(), anyhow::Error\u003e {\n        info!(\n            \"Starting Redis publisher with tenant isolation, base stream: {}\",\n            self.base_stream_key\n        );\n\n        let redis_url = self.redis_url.clone();\n        let base_stream_key = self.base_stream_key.clone();\n\n        let client = redis::Client::open(redis_url)?;\n        let mut con = client.get_connection_manager().await?;\n\n        while let Some(event) = event_rx.recv().await {\n            match Self::publish_event(\u0026base_stream_key, \u0026mut con, \u0026event).await {\n                Ok(_) =\u003e {\n                    info!(\"Published governance event: {:?}\", event);\n                }\n                Err(e) =\u003e {\n                    error!(\"Failed to publish event to Redis: {}\", e);\n                }\n            }\n        }\n\n        info!(\"Redis publisher shutting down\");\n        Ok(())\n    }\n\n    /// Publishes a single event to the appropriate tenant stream.\n    async fn publish_event(\n        base_stream_key: \u0026str,\n        con: \u0026mut redis::aio::ConnectionManager,\n        event: \u0026GovernanceEvent,\n    ) -\u003e Result\u003c(), anyhow::Error\u003e {\n        let tenant_id = match event {\n            GovernanceEvent::UnitCreated { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::UnitUpdated { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::UnitDeleted { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::PolicyUpdated { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::PolicyDeleted { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::RoleAssigned { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::RoleRemoved { tenant_id, .. } =\u003e tenant_id,\n            GovernanceEvent::DriftDetected { tenant_id, .. } =\u003e tenant_id,\n        };\n\n        let stream_key = format!(\"{}:{}\", base_stream_key, tenant_id.as_str());\n\n        println!(\"DEBUG: Publishing to stream key: {}\", stream_key);\n        let event_json = serde_json::to_string(event)?;\n\n        let _: String = redis::cmd(\"XADD\")\n            .arg(\u0026stream_key)\n            .arg(\"*\")\n            .arg(\"event\")\n            .arg(\u0026event_json)\n            .query_async(con)\n            .await?;\n\n        Ok(())\n    }\n}\n\n/// Creates a Redis publisher with tenant isolation and returns the event\n/// channel sender.\n///\n/// Events will be routed to per-tenant streams:\n/// `governance:events:{tenant_id}`. Caller should use the returned sender to\n/// create GovernanceEngine: ```rust\n/// let (event_tx, publisher_handle) =\n///     create_redis_publisher_with_tenant_isolation(\"redis://localhost:6379\".\n/// to_string()); let governance_engine =\n/// GovernanceEngine::new().with_events(event_tx); ```\npub fn create_redis_publisher_with_tenant_isolation(\n    redis_url: String,\n) -\u003e (\n    tokio::sync::mpsc::UnboundedSender\u003cGovernanceEvent\u003e,\n    tokio::task::JoinHandle\u003c()\u003e,\n) {\n    let publisher =\n        RedisPublisher::new_with_tenant_isolation(redis_url, \"governance:events\".to_string());\n    publisher.start()\n}\n\n/// Creates a Redis publisher for a specific tenant (legacy API).\npub fn create_redis_publisher_for_tenant(\n    redis_url: String,\n    tenant_id: \u0026TenantId,\n) -\u003e (\n    tokio::sync::mpsc::UnboundedSender\u003cGovernanceEvent\u003e,\n    tokio::task::JoinHandle\u003c()\u003e,\n) {\n    let publisher = RedisPublisher::new_for_tenant(redis_url, tenant_id);\n    publisher.start()\n}\n\n/// Creates a Redis publisher with a custom stream key (no tenant isolation).\npub fn create_redis_publisher(\n    redis_url: String,\n    stream_key: String,\n) -\u003e (\n    tokio::sync::mpsc::UnboundedSender\u003cGovernanceEvent\u003e,\n    tokio::task::JoinHandle\u003c()\u003e,\n) {\n    let publisher = RedisPublisher::new(redis_url, stream_key);\n    publisher.start()\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use mk_core::types::{KnowledgeLayer, Role, UnitType, UserId};\n\n    #[test]\n    fn test_redis_publisher_tenant_isolation() {\n        let tenant_id1 = TenantId::new(\"tenant-1\".to_string()).unwrap();\n        let tenant_id2 = TenantId::new(\"tenant-2\".to_string()).unwrap();\n\n        let publisher = RedisPublisher::new_with_tenant_isolation(\n            \"redis://localhost:6379\".to_string(),\n            \"governance:events\".to_string(),\n        );\n\n        let event1 = GovernanceEvent::UnitCreated {\n            unit_id: \"unit-1\".to_string(),\n            unit_type: UnitType::Company,\n            tenant_id: tenant_id1.clone(),\n            parent_id: None,\n            timestamp: 1234567890,\n        };\n\n        let event2 = GovernanceEvent::UnitCreated {\n            unit_id: \"unit-2\".to_string(),\n            unit_type: UnitType::Team,\n            tenant_id: tenant_id2.clone(),\n            parent_id: Some(\"unit-1\".to_string()),\n            timestamp: 1234567891,\n        };\n\n        let _legacy_publisher =\n            RedisPublisher::new_for_tenant(\"redis://localhost:6379\".to_string(), \u0026tenant_id1);\n\n        assert!(true);\n    }\n\n    #[test]\n    fn test_event_tenant_id_extraction() {\n        let tenant_id = TenantId::new(\"test-tenant\".to_string()).unwrap();\n        let user_id = UserId::new(\"user-1\".to_string()).unwrap();\n\n        let events = vec![\n            GovernanceEvent::UnitCreated {\n                unit_id: \"unit-1\".to_string(),\n                unit_type: UnitType::Company,\n                tenant_id: tenant_id.clone(),\n                parent_id: None,\n                timestamp: 1234567890,\n            },\n            GovernanceEvent::PolicyUpdated {\n                policy_id: \"policy-1\".to_string(),\n                layer: KnowledgeLayer::Company,\n                tenant_id: tenant_id.clone(),\n                timestamp: 1234567891,\n            },\n            GovernanceEvent::RoleAssigned {\n                user_id: user_id.clone(),\n                unit_id: \"unit-1\".to_string(),\n                role: Role::Admin,\n                tenant_id: tenant_id.clone(),\n                timestamp: 1234567892,\n            },\n            GovernanceEvent::DriftDetected {\n                project_id: \"project-1\".to_string(),\n                tenant_id: tenant_id.clone(),\n                drift_score: 0.5,\n                timestamp: 1234567893,\n            },\n        ];\n\n        for event in events {\n            let extracted_tenant_id = match \u0026event {\n                GovernanceEvent::UnitCreated { tenant_id, .. } =\u003e tenant_id,\n                GovernanceEvent::UnitUpdated { tenant_id, .. } =\u003e tenant_id,\n                GovernanceEvent::UnitDeleted { tenant_id, .. } =\u003e tenant_id,\n                GovernanceEvent::PolicyUpdated { tenant_id, .. } =\u003e tenant_id,\n                GovernanceEvent::PolicyDeleted { tenant_id, .. } =\u003e tenant_id,\n                GovernanceEvent::RoleAssigned { tenant_id, .. } =\u003e tenant_id,\n                GovernanceEvent::RoleRemoved { tenant_id, .. } =\u003e tenant_id,\n                GovernanceEvent::DriftDetected { tenant_id, .. } =\u003e tenant_id,\n            };\n            assert_eq!(extracted_tenant_id, \u0026tenant_id);\n        }\n    }\n}\n","traces":[{"line":20,"address":[],"length":0,"stats":{"Line":1}},{"line":28,"address":[],"length":0,"stats":{"Line":1}},{"line":29,"address":[],"length":0,"stats":{"Line":5}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":0}}],"covered":3,"coverable":54},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","repository.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","server.rs"],"content":"use crate::bridge::{ResolveFederationConflictTool, SyncNowTool, SyncStatusTool};\nuse crate::governance::{\n    HierarchyNavigateTool, UnitCreateTool, UnitPolicyAddTool, UserRoleAssignTool,\n    UserRoleRemoveTool,\n};\nuse crate::knowledge::{KnowledgeGetTool, KnowledgeListTool, KnowledgeQueryTool};\nuse crate::memory::{MemoryAddTool, MemoryCloseTool, MemoryDeleteTool, MemorySearchTool};\nuse crate::tools::{ToolDefinition, ToolRegistry};\nuse knowledge::governance::GovernanceEngine;\nuse memory::manager::MemoryManager;\nuse mk_core::traits::{AuthorizationService, EventPublisher, KnowledgeRepository};\nuse serde::{Deserialize, Serialize};\nuse serde_json::Value;\nuse std::sync::Arc;\nuse std::time::Duration;\nuse storage::events::EventError;\nuse sync::bridge::SyncManager;\nuse tokio::time::timeout;\nuse tracing::{Span, debug, error, info, instrument};\n\n/// MCP JSON-RPC server for tool orchestration.\n///\n/// Handles tool discovery and execution with integrated timeouts and tracing.\npub struct McpServer {\n    registry: ToolRegistry,\n    auth_service: Arc\u003cdyn AuthorizationService\u003cError = anyhow::Error\u003e\u003e,\n    event_publisher: Option\u003cArc\u003cdyn EventPublisher\u003cError = EventError\u003e\u003e\u003e,\n    timeout_duration: Duration,\n}\n\nimpl McpServer {\n    /// Creates a new McpServer with initialized core tools.\n    pub fn new(\n        memory_manager: Arc\u003cMemoryManager\u003e,\n        sync_manager: Arc\u003cSyncManager\u003e,\n        knowledge_repository: Arc\u003c\n            dyn KnowledgeRepository\u003cError = knowledge::repository::RepositoryError\u003e,\n        \u003e,\n        storage_backend: Arc\u003c\n            dyn mk_core::traits::StorageBackend\u003cError = storage::postgres::PostgresError\u003e,\n        \u003e,\n        governance_engine: Arc\u003cGovernanceEngine\u003e,\n        auth_service: Arc\u003cdyn AuthorizationService\u003cError = anyhow::Error\u003e\u003e,\n        event_publisher: Option\u003cArc\u003cdyn EventPublisher\u003cError = EventError\u003e\u003e\u003e,\n    ) -\u003e Self {\n        let mut registry = ToolRegistry::new();\n\n        registry.register(Box::new(MemoryAddTool::new(memory_manager.clone())));\n        registry.register(Box::new(MemorySearchTool::new(memory_manager.clone())));\n        registry.register(Box::new(MemoryDeleteTool::new(memory_manager.clone())));\n        registry.register(Box::new(MemoryCloseTool::new(memory_manager.clone())));\n\n        registry.register(Box::new(KnowledgeGetTool::new(\n            knowledge_repository.clone(),\n        )));\n        registry.register(Box::new(KnowledgeListTool::new(\n            knowledge_repository.clone(),\n        )));\n        registry.register(Box::new(KnowledgeQueryTool::new(\n            memory_manager.clone(),\n            knowledge_repository.clone(),\n        )));\n\n        registry.register(Box::new(SyncNowTool::new(sync_manager.clone())));\n        registry.register(Box::new(SyncStatusTool::new(sync_manager.clone())));\n        registry.register(Box::new(ResolveFederationConflictTool::new(sync_manager)));\n\n        registry.register(Box::new(UnitCreateTool::new(\n            storage_backend.clone(),\n            governance_engine.clone(),\n        )));\n        registry.register(Box::new(UnitPolicyAddTool::new(\n            storage_backend.clone(),\n            governance_engine.clone(),\n        )));\n        registry.register(Box::new(UserRoleAssignTool::new(\n            storage_backend.clone(),\n            governance_engine.clone(),\n        )));\n        registry.register(Box::new(UserRoleRemoveTool::new(\n            storage_backend.clone(),\n            governance_engine,\n        )));\n        registry.register(Box::new(HierarchyNavigateTool::new(storage_backend)));\n\n        Self {\n            registry,\n            auth_service,\n            event_publisher,\n            timeout_duration: Duration::from_secs(30),\n        }\n    }\n\n    pub fn with_timeout(mut self, duration: Duration) -\u003e Self {\n        self.timeout_duration = duration;\n        self\n    }\n\n    pub fn registry(\u0026self) -\u003e \u0026ToolRegistry {\n        \u0026self.registry\n    }\n\n    pub fn list_tools(\u0026self) -\u003e Vec\u003cToolDefinition\u003e {\n        self.registry.list_tools()\n    }\n\n    #[instrument(skip(self, request), fields(method = %request.method, request_id = ?request.id))]\n    pub async fn handle_request(\u0026self, request: JsonRpcRequest) -\u003e JsonRpcResponse {\n        debug!(method = %request.method, \"Handling JSON-RPC request\");\n\n        let timeout_duration = self.timeout_duration;\n\n        let result = timeout(timeout_duration, self.dispatch(request)).await;\n\n        match result {\n            Ok(response) =\u003e response,\n            Err(_) =\u003e {\n                error!(\"Request timed out\");\n                JsonRpcResponse {\n                    jsonrpc: \"2.0\".to_string(),\n                    id: Value::Null,\n                    result: None,\n                    error: Some(JsonRpcError::request_timeout(\"Request timed out\")),\n                }\n            }\n        }\n    }\n\n    async fn dispatch(\u0026self, request: JsonRpcRequest) -\u003e JsonRpcResponse {\n        match request.method.as_str() {\n            \"initialize\" =\u003e JsonRpcResponse {\n                jsonrpc: \"2.0\".to_string(),\n                id: request.id,\n                result: Some(serde_json::json!({\n                    \"protocolVersion\": \"2024-11-05\",\n                    \"capabilities\": {\n                        \"tools\": {\n                            \"listChanged\": false\n                        }\n                    },\n                    \"serverInfo\": {\n                        \"name\": \"aeterna-tools\",\n                        \"version\": \"0.1.0\"\n                    }\n                })),\n                error: None,\n            },\n            \"tools/list\" =\u003e {\n                let tools = self.registry.list_tools();\n                JsonRpcResponse {\n                    jsonrpc: \"2.0\".to_string(),\n                    id: request.id,\n                    result: Some(serde_json::to_value(tools).unwrap()),\n                    error: None,\n                }\n            }\n            \"tools/call\" =\u003e {\n                let params = match request.params {\n                    Some(p) =\u003e p,\n                    None =\u003e {\n                        return JsonRpcResponse {\n                            jsonrpc: \"2.0\".to_string(),\n                            id: request.id,\n                            result: None,\n                            error: Some(JsonRpcError::invalid_params(\"Invalid params\")),\n                        };\n                    }\n                };\n\n                let tenant_context: mk_core::types::TenantContext =\n                    match serde_json::from_value(params[\"tenantContext\"].clone()) {\n                        Ok(ctx) =\u003e ctx,\n                        Err(_) =\u003e {\n                            return JsonRpcResponse {\n                                jsonrpc: \"2.0\".to_string(),\n                                id: request.id,\n                                result: None,\n                                error: Some(JsonRpcError::invalid_params(\n                                    \"Missing or invalid tenant context\",\n                                )),\n                            };\n                        }\n                    };\n\n                let (name, tool_params) = match self.extract_call_params(\u0026params, \u0026tenant_context) {\n                    Ok(res) =\u003e res,\n                    Err(e) =\u003e {\n                        return JsonRpcResponse {\n                            jsonrpc: \"2.0\".to_string(),\n                            id: request.id,\n                            result: None,\n                            error: Some(JsonRpcError::invalid_params(e)),\n                        };\n                    }\n                };\n\n                Span::current().record(\"tool_name\", \u0026name);\n                info!(tool = %name, \"Calling tool\");\n\n                let auth_result = self\n                    .auth_service\n                    .check_permission(\u0026tenant_context, \"call_tool\", \u0026name)\n                    .await;\n\n                match auth_result {\n                    Ok(allowed) =\u003e {\n                        if !allowed {\n                            error!(tool = %name, \"Authorization denied\");\n                            return JsonRpcResponse {\n                                jsonrpc: \"2.0\".to_string(),\n                                id: request.id,\n                                result: None,\n                                error: Some(JsonRpcError {\n                                    code: -32002,\n                                    message: format!(\n                                        \"Authorization error: access denied for tool {}\",\n                                        name\n                                    ),\n                                    data: None,\n                                }),\n                            };\n                        }\n                    }\n                    Err(e) =\u003e {\n                        error!(tool = %name, error = %e, \"Authorization check failed\");\n                        return JsonRpcResponse {\n                            jsonrpc: \"2.0\".to_string(),\n                            id: request.id,\n                            result: None,\n                            error: Some(JsonRpcError {\n                                code: -32002,\n                                message: format!(\"Authorization error: {}\", e),\n                                data: None,\n                            }),\n                        };\n                    }\n                }\n\n                let call_result = self.registry.call(\u0026name, tool_params).await;\n\n                match call_result {\n                    Ok(result) =\u003e {\n                        info!(tool = %name, \"Tool call successful\");\n\n                        if let Some(ref publisher) = self.event_publisher {\n                            let timestamp = chrono::Utc::now().timestamp();\n                            let event = match name.as_str() {\n                                \"unit_create\" =\u003e {\n                                    Some(mk_core::types::GovernanceEvent::UnitCreated {\n                                        unit_id: result[\"unit_id\"]\n                                            .as_str()\n                                            .unwrap_or_default()\n                                            .to_string(),\n                                        unit_type: serde_json::from_value(\n                                            result[\"unit_type\"].clone(),\n                                        )\n                                        .unwrap_or(mk_core::types::UnitType::Project),\n                                        tenant_id: tenant_context.tenant_id.clone(),\n                                        parent_id: result[\"parent_id\"]\n                                            .as_str()\n                                            .map(|s| s.to_string()),\n                                        timestamp,\n                                    })\n                                }\n                                \"role_assign\" =\u003e {\n                                    Some(mk_core::types::GovernanceEvent::RoleAssigned {\n                                        user_id: serde_json::from_value(result[\"user_id\"].clone())\n                                            .unwrap_or_default(),\n                                        unit_id: result[\"unit_id\"]\n                                            .as_str()\n                                            .unwrap_or_default()\n                                            .to_string(),\n                                        role: serde_json::from_value(result[\"role\"].clone())\n                                            .unwrap_or(mk_core::types::Role::Developer),\n                                        tenant_id: tenant_context.tenant_id.clone(),\n                                        timestamp,\n                                    })\n                                }\n                                \"role_remove\" =\u003e {\n                                    Some(mk_core::types::GovernanceEvent::RoleRemoved {\n                                        user_id: serde_json::from_value(result[\"user_id\"].clone())\n                                            .unwrap_or_default(),\n                                        unit_id: result[\"unit_id\"]\n                                            .as_str()\n                                            .unwrap_or_default()\n                                            .to_string(),\n                                        role: serde_json::from_value(result[\"role\"].clone())\n                                            .unwrap_or(mk_core::types::Role::Developer),\n                                        tenant_id: tenant_context.tenant_id.clone(),\n                                        timestamp,\n                                    })\n                                }\n                                \"unit_policy_add\" =\u003e {\n                                    Some(mk_core::types::GovernanceEvent::PolicyUpdated {\n                                        policy_id: result[\"policy_id\"]\n                                            .as_str()\n                                            .unwrap_or_default()\n                                            .to_string(),\n                                        layer: serde_json::from_value(result[\"layer\"].clone())\n                                            .unwrap_or(mk_core::types::KnowledgeLayer::Project),\n                                        tenant_id: tenant_context.tenant_id.clone(),\n                                        timestamp,\n                                    })\n                                }\n                                _ =\u003e None,\n                            };\n\n                            if let Some(event) = event {\n                                if let Err(e) = publisher.publish(event).await {\n                                    error!(error = %e, \"Failed to publish governance event\");\n                                }\n                            }\n                        }\n\n                        JsonRpcResponse {\n                            jsonrpc: \"2.0\".to_string(),\n                            id: request.id,\n                            result: Some(result),\n                            error: None,\n                        }\n                    }\n                    Err(e) =\u003e {\n                        let error_str = e.to_string();\n                        error!(tool = %name, error = %error_str, \"Tool call failed\");\n                        let rpc_error = if error_str.contains(\"not found\") {\n                            JsonRpcError::method_not_found(error_str)\n                        } else if e.is::\u003cserde_json::Error\u003e()\n                            || error_str.contains(\"Validation error\")\n                        {\n                            JsonRpcError::invalid_params(error_str)\n                        } else {\n                            JsonRpcError::internal_error(error_str)\n                        };\n\n                        JsonRpcResponse {\n                            jsonrpc: \"2.0\".to_string(),\n                            id: request.id,\n                            result: None,\n                            error: Some(rpc_error),\n                        }\n                    }\n                }\n            }\n            _ =\u003e {\n                debug!(method = %request.method, \"Method not found\");\n                JsonRpcResponse {\n                    jsonrpc: \"2.0\".to_string(),\n                    id: request.id,\n                    result: None,\n                    error: Some(JsonRpcError::method_not_found(\"Method not found\")),\n                }\n            }\n        }\n    }\n\n    fn extract_call_params(\n        \u0026self,\n        params: \u0026Value,\n        tenant_context: \u0026mk_core::types::TenantContext,\n    ) -\u003e Result\u003c(String, Value), String\u003e {\n        let name = match params[\"name\"].as_str() {\n            Some(n) =\u003e n.to_string(),\n            None =\u003e return Err(\"Missing tool name\".to_string()),\n        };\n\n        let mut tool_params = params[\"arguments\"].clone();\n        if tool_params.is_null() {\n            tool_params = serde_json::json!({});\n        }\n\n        if let Some(obj) = tool_params.as_object_mut() {\n            obj.insert(\n                \"tenant_context\".to_string(),\n                serde_json::to_value(tenant_context).unwrap(),\n            );\n            obj.insert(\n                \"tenantContext\".to_string(),\n                serde_json::to_value(tenant_context).unwrap(),\n            );\n        } else {\n            tool_params = serde_json::json!({\n                \"tenant_context\": tenant_context,\n                \"tenantContext\": tenant_context\n            });\n        }\n\n        Ok((name, tool_params))\n    }\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct JsonRpcResponse {\n    pub jsonrpc: String,\n    pub id: Value,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub result: Option\u003cValue\u003e,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub error: Option\u003cJsonRpcError\u003e,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct JsonRpcError {\n    pub code: i32,\n    pub message: String,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub data: Option\u003cValue\u003e,\n}\n\nimpl JsonRpcError {\n    pub fn invalid_params(message: impl Into\u003cString\u003e) -\u003e Self {\n        Self {\n            code: -32602,\n            message: message.into(),\n            data: None,\n        }\n    }\n\n    pub fn method_not_found(message: impl Into\u003cString\u003e) -\u003e Self {\n        Self {\n            code: -32601,\n            message: message.into(),\n            data: None,\n        }\n    }\n\n    pub fn internal_error(message: impl Into\u003cString\u003e) -\u003e Self {\n        Self {\n            code: -32000,\n            message: message.into(),\n            data: None,\n        }\n    }\n\n    pub fn request_timeout(message: impl Into\u003cString\u003e) -\u003e Self {\n        Self {\n            code: -32001,\n            message: message.into(),\n            data: None,\n        }\n    }\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct JsonRpcRequest {\n    pub jsonrpc: String,\n    pub id: Value,\n    pub method: String,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub params: Option\u003cValue\u003e,\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use memory::manager::MemoryManager;\n    use mk_core::traits::KnowledgeRepository;\n    use mk_core::types::{KnowledgeEntry, KnowledgeLayer};\n    use serde_json::json;\n    use sync::bridge::SyncManager;\n    use sync::state_persister::SyncStatePersister;\n    use testcontainers::ContainerAsync;\n    use testcontainers::runners::AsyncRunner;\n    use testcontainers_modules::postgres::Postgres;\n\n    struct MockRepo;\n    #[async_trait::async_trait]\n    impl KnowledgeRepository for MockRepo {\n        type Error = knowledge::repository::RepositoryError;\n        async fn store(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: KnowledgeEntry,\n            _: \u0026str,\n        ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n            Ok(\"hash\".into())\n        }\n        async fn get(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: KnowledgeLayer,\n            _: \u0026str,\n        ) -\u003e std::result::Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(None)\n        }\n        async fn list(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: KnowledgeLayer,\n            _: \u0026str,\n        ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n        async fn delete(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: KnowledgeLayer,\n            _: \u0026str,\n            _: \u0026str,\n        ) -\u003e std::result::Result\u003cString, Self::Error\u003e {\n            Ok(\"hash\".into())\n        }\n        async fn get_head_commit(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n        ) -\u003e std::result::Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n            Ok(None)\n        }\n        async fn get_affected_items(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: \u0026str,\n        ) -\u003e std::result::Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n        async fn search(\n            \u0026self,\n            _ctx: mk_core::types::TenantContext,\n            _: \u0026str,\n            _: Vec\u003cKnowledgeLayer\u003e,\n            _: usize,\n        ) -\u003e std::result::Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n            Ok(vec![])\n        }\n        fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n            None\n        }\n    }\n\n    struct MockPersister;\n    #[async_trait::async_trait]\n    impl SyncStatePersister for MockPersister {\n        async fn load(\n            \u0026self,\n            _tenant_id: \u0026mk_core::types::TenantId,\n        ) -\u003e std::result::Result\u003csync::state::SyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e\n        {\n            Ok(sync::state::SyncState::default())\n        }\n        async fn save(\n            \u0026self,\n            _tenant_id: \u0026mk_core::types::TenantId,\n            _: \u0026sync::state::SyncState,\n        ) -\u003e std::result::Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n            Ok(())\n        }\n    }\n\n    struct MockAuthService;\n    #[async_trait::async_trait]\n    impl mk_core::traits::AuthorizationService for MockAuthService {\n        type Error = anyhow::Error;\n        async fn check_permission(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n            _action: \u0026str,\n            _resource: \u0026str,\n        ) -\u003e anyhow::Result\u003cbool\u003e {\n            Ok(true)\n        }\n        async fn get_user_roles(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n        ) -\u003e anyhow::Result\u003cVec\u003cmk_core::types::Role\u003e\u003e {\n            Ok(vec![])\n        }\n        async fn assign_role(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n            _user_id: \u0026mk_core::types::UserId,\n            _role: mk_core::types::Role,\n        ) -\u003e anyhow::Result\u003c()\u003e {\n            Ok(())\n        }\n        async fn remove_role(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n            _user_id: \u0026mk_core::types::UserId,\n            _role: mk_core::types::Role,\n        ) -\u003e anyhow::Result\u003c()\u003e {\n            Ok(())\n        }\n    }\n\n    async fn setup_postgres_container()\n    -\u003e Result\u003c(ContainerAsync\u003cPostgres\u003e, String), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let container = Postgres::default()\n            .with_db_name(\"testdb\")\n            .with_user(\"testuser\")\n            .with_password(\"testpass\")\n            .start()\n            .await\n            .map_err(|e| Box::new(e) as Box\u003cdyn std::error::Error + Send + Sync\u003e)?;\n\n        let connection_url = format!(\n            \"postgres://testuser:testpass@localhost:{}/testdb\",\n            container\n                .get_host_port_ipv4(5432)\n                .await\n                .map_err(|e| Box::new(e) as Box\u003cdyn std::error::Error + Send + Sync\u003e)?\n        );\n\n        Ok((container, connection_url))\n    }\n\n    async fn setup_server() -\u003e McpServer {\n        let memory_manager = Arc::new(MemoryManager::new());\n        let repo = Arc::new(MockRepo);\n        let governance = Arc::new(knowledge::governance::GovernanceEngine::new());\n        let sync_manager = Arc::new(\n            SyncManager::new(\n                memory_manager.clone(),\n                repo.clone(),\n                governance.clone(),\n                config::config::DeploymentConfig::default(),\n                None,\n                Arc::new(MockPersister),\n            )\n            .await\n            .unwrap(),\n        );\n\n        let (container, connection_url) = setup_postgres_container()\n            .await\n            .expect(\"Failed to setup PostgreSQL test container. Make sure Docker is running.\");\n\n        let backend = storage::postgres::PostgresBackend::new(\u0026connection_url)\n            .await\n            .expect(\"Failed to connect to PostgreSQL test container\");\n\n        let _container = container;\n\n        McpServer::new(\n            memory_manager,\n            sync_manager,\n            repo,\n            Arc::new(backend),\n            governance,\n            Arc::new(MockAuthService),\n            None,\n        )\n    }\n\n    #[tokio::test]\n    async fn test_server_initialize() {\n        let server = setup_server().await;\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"initialize\".to_string(),\n            params: None,\n        };\n\n        let response = server.handle_request(request).await;\n        assert!(response.result.is_some());\n        let result = response.result.unwrap();\n        assert_eq!(result[\"protocolVersion\"], \"2024-11-05\");\n    }\n\n    #[tokio::test]\n    async fn test_server_list_tools() {\n        let server = setup_server().await;\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"tools/list\".to_string(),\n            params: None,\n        };\n\n        let response = server.handle_request(request).await;\n        assert!(response.result.is_some());\n        let tools = response.result.unwrap();\n        assert!(tools.as_array().unwrap().len() \u003e= 8);\n    }\n\n    #[tokio::test]\n    async fn test_server_method_not_found() {\n        let server = setup_server().await;\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"unknown_method\".to_string(),\n            params: None,\n        };\n\n        let response = server.handle_request(request).await;\n        assert!(response.error.is_some());\n        assert_eq!(response.error.unwrap().code, -32601);\n    }\n\n    #[tokio::test]\n    async fn test_server_invalid_params() {\n        let server = setup_server().await;\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"tools/call\".to_string(),\n            params: None,\n        };\n\n        let response = server.handle_request(request).await;\n        assert!(response.error.is_some());\n        assert_eq!(response.error.unwrap().code, -32602);\n    }\n\n    #[tokio::test]\n    async fn test_server_tool_not_found() {\n        let server = setup_server().await;\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"tools/call\".to_string(),\n            params: Some(json!({\n                \"tenantContext\": {\n                    \"tenant_id\": \"c1\",\n                    \"user_id\": \"u1\"\n                },\n                \"name\": \"non_existent_tool\",\n                \"arguments\": {}\n            })),\n        };\n\n        let response = server.handle_request(request).await;\n        assert!(response.error.is_some());\n        assert_eq!(response.error.unwrap().code, -32601);\n    }\n\n    #[tokio::test]\n    async fn test_extract_tenant_context() {\n        let server = setup_server().await;\n\n        let params = json!({\n            \"tenantContext\": {\n                \"tenantId\": \"company_1\",\n                \"userId\": \"user_1\"\n            },\n            \"name\": \"memory_add\",\n            \"arguments\": {\n                \"content\": \"test\"\n            }\n        });\n\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"tools/call\".to_string(),\n            params: Some(params),\n        };\n\n        let _response = server.handle_request(request).await;\n    }\n\n    #[tokio::test]\n    async fn test_extract_tenant_context_missing() {\n        let server = setup_server().await;\n\n        let params = json!({\n            \"name\": \"memory_add\",\n            \"arguments\": {\n                \"content\": \"test\"\n            }\n        });\n\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"tools/call\".to_string(),\n            params: Some(params),\n        };\n\n        let response = server.handle_request(request).await;\n        assert!(response.error.is_some());\n        let err = response.error.unwrap();\n        assert_eq!(err.code, -32602);\n        assert!(err.message.contains(\"Missing or invalid tenant context\"));\n    }\n\n    #[tokio::test]\n    async fn test_server_timeout() {\n        let server = setup_server().await.with_timeout(Duration::from_millis(1));\n\n        let request = JsonRpcRequest {\n            jsonrpc: \"2.0\".to_string(),\n            id: json!(1),\n            method: \"initialize\".to_string(),\n            params: None,\n        };\n\n        let _response = server.handle_request(request).await;\n    }\n}\n","traces":[{"line":33,"address":[],"length":0,"stats":{"Line":18}},{"line":46,"address":[],"length":0,"stats":{"Line":36}},{"line":48,"address":[],"length":0,"stats":{"Line":90}},{"line":49,"address":[],"length":0,"stats":{"Line":90}},{"line":50,"address":[],"length":0,"stats":{"Line":90}},{"line":51,"address":[],"length":0,"stats":{"Line":90}},{"line":53,"address":[],"length":0,"stats":{"Line":90}},{"line":54,"address":[],"length":0,"stats":{"Line":18}},{"line":56,"address":[],"length":0,"stats":{"Line":90}},{"line":57,"address":[],"length":0,"stats":{"Line":18}},{"line":59,"address":[],"length":0,"stats":{"Line":90}},{"line":60,"address":[],"length":0,"stats":{"Line":54}},{"line":61,"address":[],"length":0,"stats":{"Line":18}},{"line":64,"address":[],"length":0,"stats":{"Line":90}},{"line":65,"address":[],"length":0,"stats":{"Line":90}},{"line":66,"address":[],"length":0,"stats":{"Line":72}},{"line":68,"address":[],"length":0,"stats":{"Line":90}},{"line":69,"address":[],"length":0,"stats":{"Line":36}},{"line":70,"address":[],"length":0,"stats":{"Line":18}},{"line":72,"address":[],"length":0,"stats":{"Line":90}},{"line":73,"address":[],"length":0,"stats":{"Line":36}},{"line":74,"address":[],"length":0,"stats":{"Line":18}},{"line":76,"address":[],"length":0,"stats":{"Line":90}},{"line":77,"address":[],"length":0,"stats":{"Line":36}},{"line":78,"address":[],"length":0,"stats":{"Line":18}},{"line":80,"address":[],"length":0,"stats":{"Line":90}},{"line":81,"address":[],"length":0,"stats":{"Line":18}},{"line":82,"address":[],"length":0,"stats":{"Line":18}},{"line":84,"address":[],"length":0,"stats":{"Line":72}},{"line":90,"address":[],"length":0,"stats":{"Line":18}},{"line":94,"address":[],"length":0,"stats":{"Line":2}},{"line":95,"address":[],"length":0,"stats":{"Line":2}},{"line":96,"address":[],"length":0,"stats":{"Line":2}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":4}},{"line":104,"address":[],"length":0,"stats":{"Line":8}},{"line":108,"address":[],"length":0,"stats":{"Line":30}},{"line":111,"address":[],"length":0,"stats":{"Line":15}},{"line":129,"address":[],"length":0,"stats":{"Line":30}},{"line":130,"address":[],"length":0,"stats":{"Line":15}},{"line":132,"address":[],"length":0,"stats":{"Line":6}},{"line":133,"address":[],"length":0,"stats":{"Line":4}},{"line":134,"address":[],"length":0,"stats":{"Line":4}},{"line":148,"address":[],"length":0,"stats":{"Line":13}},{"line":149,"address":[],"length":0,"stats":{"Line":3}},{"line":151,"address":[],"length":0,"stats":{"Line":3}},{"line":152,"address":[],"length":0,"stats":{"Line":2}},{"line":153,"address":[],"length":0,"stats":{"Line":2}},{"line":157,"address":[],"length":0,"stats":{"Line":12}},{"line":158,"address":[],"length":0,"stats":{"Line":21}},{"line":159,"address":[],"length":0,"stats":{"Line":20}},{"line":161,"address":[],"length":0,"stats":{"Line":1}},{"line":162,"address":[],"length":0,"stats":{"Line":3}},{"line":163,"address":[],"length":0,"stats":{"Line":2}},{"line":164,"address":[],"length":0,"stats":{"Line":1}},{"line":165,"address":[],"length":0,"stats":{"Line":1}},{"line":170,"address":[],"length":0,"stats":{"Line":16}},{"line":171,"address":[],"length":0,"stats":{"Line":20}},{"line":172,"address":[],"length":0,"stats":{"Line":16}},{"line":174,"address":[],"length":0,"stats":{"Line":2}},{"line":175,"address":[],"length":0,"stats":{"Line":6}},{"line":176,"address":[],"length":0,"stats":{"Line":4}},{"line":177,"address":[],"length":0,"stats":{"Line":2}},{"line":178,"address":[],"length":0,"stats":{"Line":2}},{"line":179,"address":[],"length":0,"stats":{"Line":2}},{"line":185,"address":[],"length":0,"stats":{"Line":40}},{"line":186,"address":[],"length":0,"stats":{"Line":16}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":32}},{"line":198,"address":[],"length":0,"stats":{"Line":8}},{"line":200,"address":[],"length":0,"stats":{"Line":24}},{"line":201,"address":[],"length":0,"stats":{"Line":16}},{"line":202,"address":[],"length":0,"stats":{"Line":24}},{"line":203,"address":[],"length":0,"stats":{"Line":8}},{"line":205,"address":[],"length":0,"stats":{"Line":8}},{"line":206,"address":[],"length":0,"stats":{"Line":8}},{"line":207,"address":[],"length":0,"stats":{"Line":8}},{"line":208,"address":[],"length":0,"stats":{"Line":2}},{"line":209,"address":[],"length":0,"stats":{"Line":2}},{"line":210,"address":[],"length":0,"stats":{"Line":6}},{"line":211,"address":[],"length":0,"stats":{"Line":4}},{"line":212,"address":[],"length":0,"stats":{"Line":4}},{"line":213,"address":[],"length":0,"stats":{"Line":2}},{"line":214,"address":[],"length":0,"stats":{"Line":2}},{"line":215,"address":[],"length":0,"stats":{"Line":4}},{"line":216,"address":[],"length":0,"stats":{"Line":2}},{"line":217,"address":[],"length":0,"stats":{"Line":2}},{"line":219,"address":[],"length":0,"stats":{"Line":2}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":225,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":231,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":30}},{"line":241,"address":[],"length":0,"stats":{"Line":6}},{"line":242,"address":[],"length":0,"stats":{"Line":5}},{"line":243,"address":[],"length":0,"stats":{"Line":5}},{"line":245,"address":[],"length":0,"stats":{"Line":5}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":0}},{"line":252,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":0}},{"line":254,"address":[],"length":0,"stats":{"Line":0}},{"line":255,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":0}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":270,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":272,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":274,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":276,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":284,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":298,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":15}},{"line":317,"address":[],"length":0,"stats":{"Line":10}},{"line":318,"address":[],"length":0,"stats":{"Line":5}},{"line":322,"address":[],"length":0,"stats":{"Line":1}},{"line":323,"address":[],"length":0,"stats":{"Line":3}},{"line":324,"address":[],"length":0,"stats":{"Line":1}},{"line":325,"address":[],"length":0,"stats":{"Line":2}},{"line":326,"address":[],"length":0,"stats":{"Line":2}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":3}},{"line":337,"address":[],"length":0,"stats":{"Line":2}},{"line":339,"address":[],"length":0,"stats":{"Line":1}},{"line":345,"address":[],"length":0,"stats":{"Line":1}},{"line":347,"address":[],"length":0,"stats":{"Line":3}},{"line":348,"address":[],"length":0,"stats":{"Line":2}},{"line":350,"address":[],"length":0,"stats":{"Line":1}},{"line":356,"address":[],"length":0,"stats":{"Line":8}},{"line":361,"address":[],"length":0,"stats":{"Line":16}},{"line":362,"address":[],"length":0,"stats":{"Line":24}},{"line":363,"address":[],"length":0,"stats":{"Line":0}},{"line":366,"address":[],"length":0,"stats":{"Line":24}},{"line":367,"address":[],"length":0,"stats":{"Line":16}},{"line":368,"address":[],"length":0,"stats":{"Line":0}},{"line":371,"address":[],"length":0,"stats":{"Line":24}},{"line":372,"address":[],"length":0,"stats":{"Line":24}},{"line":373,"address":[],"length":0,"stats":{"Line":24}},{"line":374,"address":[],"length":0,"stats":{"Line":32}},{"line":376,"address":[],"length":0,"stats":{"Line":24}},{"line":377,"address":[],"length":0,"stats":{"Line":24}},{"line":378,"address":[],"length":0,"stats":{"Line":16}},{"line":381,"address":[],"length":0,"stats":{"Line":0}},{"line":382,"address":[],"length":0,"stats":{"Line":0}},{"line":383,"address":[],"length":0,"stats":{"Line":0}},{"line":387,"address":[],"length":0,"stats":{"Line":8}},{"line":410,"address":[],"length":0,"stats":{"Line":3}},{"line":412,"address":[],"length":0,"stats":{"Line":3}},{"line":413,"address":[],"length":0,"stats":{"Line":6}},{"line":418,"address":[],"length":0,"stats":{"Line":2}},{"line":420,"address":[],"length":0,"stats":{"Line":2}},{"line":421,"address":[],"length":0,"stats":{"Line":4}},{"line":426,"address":[],"length":0,"stats":{"Line":0}},{"line":428,"address":[],"length":0,"stats":{"Line":0}},{"line":429,"address":[],"length":0,"stats":{"Line":0}},{"line":434,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":0}}],"covered":125,"coverable":211},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","state.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","tools.rs"],"content":"use async_trait::async_trait;\nuse serde::{Deserialize, Serialize};\nuse serde_json::Value;\nuse std::collections::HashMap;\n\n/// Core trait for implementing MCP (Model Context Protocol) tools.\n///\n/// Tools provide a standardized interface for AI agents to interact with system\n/// capabilities. Each tool defines its name, description, input schema, and\n/// execution logic.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Defines the contract that all tools must implement to be registered and\n/// invoked through the tool registry. Enables pluggable, type-safe tool\n/// execution with JSON Schema validation.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use async_trait::async_trait;\n/// use serde_json::Value;\n/// use tools::tools::Tool;\n///\n/// struct MyCustomTool;\n///\n/// #[async_trait]\n/// impl Tool for MyCustomTool {\n///     fn name(\u0026self) -\u003e \u0026str {\n///         \"my_custom_tool\"\n///     }\n///\n///     fn description(\u0026self) -\u003e \u0026str {\n///         \"Does something useful\"\n///     }\n///\n///     fn input_schema(\u0026self) -\u003e Value {\n///         serde_json::json!({\n///             \"type\": \"object\",\n///             \"properties\": {\n///                 \"input\": { \"type\": \"string\" }\n///             },\n///             \"required\": [\"input\"]\n///         })\n///     }\n///\n///     async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n///         // Process params and return result\n///         Ok(serde_json::json!({ \"result\": \"success\" }))\n///     }\n/// }\n/// ```\n///\n/// ## Methods\n/// - `name`: Unique identifier for the tool\n/// - `description`: Human-readable description of what the tool does\n/// - `input_schema`: JSON Schema defining valid input parameters\n/// - `call`: Async execution method that processes input and returns output\n#[async_trait]\npub trait Tool: Send + Sync {\n    fn name(\u0026self) -\u003e \u0026str;\n    fn description(\u0026self) -\u003e \u0026str;\n    fn input_schema(\u0026self) -\u003e Value;\n    async fn call(\u0026self, params: Value) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e;\n}\n\n/// Error codes for tool execution failures.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Provides standardized error classification for tool operations, enabling\n/// proper error handling and retry logic.\n///\n/// ## Variants\n/// - `InvalidInput`: Input validation failed (non-retryable)\n/// - `NotFound`: Requested resource not found (non-retryable)\n/// - `ProviderError`: External provider or service failure (retryable)\n/// - `RateLimited`: Request rate limit exceeded (retryable)\n/// - `Unauthorized`: Authentication/authorization failure (non-retryable)\n/// - `Timeout`: Operation timed out (retryable)\n/// - `Conflict`: Concurrent modification or state conflict (retryable)\n/// - `InternalError`: Unexpected system error (non-retryable)\n#[derive(Serialize, Deserialize)]\n#[serde(rename_all = \"SCREAMING_SNAKE_CASE\")]\npub enum ToolErrorCode {\n    InvalidInput,\n    NotFound,\n    ProviderError,\n    RateLimited,\n    Unauthorized,\n    Timeout,\n    Conflict,\n    InternalError\n}\n\n/// Generic response wrapper for tool execution results.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Provides a consistent response format for all tool operations, enabling\n/// success/failure detection and structured error handling across all tools.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use serde_json::json;\n/// use tools::tools::{ToolError, ToolErrorCode, ToolResponse};\n///\n/// // Success response\n/// let success = ToolResponse::\u003cString\u003e {\n///     success: true,\n///     data: Some(\"result data\".to_string()),\n///     error: None\n/// };\n///\n/// // Error response\n/// let error = ToolResponse::\u003c()\u003e {\n///     success: false,\n///     data: None,\n///     error: Some(ToolError::new(ToolErrorCode::NotFound, \"Not found\"))\n/// };\n/// ```\n///\n/// ## Fields\n/// - `success`: Indicates whether the operation succeeded\n/// - `data`: Result data on success (omitted on failure)\n/// - `error`: Error details on failure (omitted on success)\n#[derive(Serialize, Deserialize)]\npub struct ToolResponse\u003cT\u003e {\n    pub success: bool,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub data: Option\u003cT\u003e,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub error: Option\u003cToolError\u003e\n}\n\n/// Detailed error information for tool failures.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Encapsulates error details including error code, message, retryability\n/// status, and optional context. Enables consumers to make informed decisions\n/// about error handling and retries.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use tools::tools::{ToolError, ToolErrorCode};\n/// use serde_json::json;\n///\n/// // Basic error\n/// let error = ToolError::new(ToolErrorCode::InvalidInput, \"Missing required field\");\n///\n/// // Error with details\n/// let error = ToolError::new(ToolErrorCode::NotFound, \"Resource not found\")\n///     .with_details(json!({ \"resource_id\": \"123\" }));\n///\n/// // Check if retryable\n/// if error.retryable {\n///     // Retry logic\n/// }\n/// ```\n///\n/// ## Fields\n/// - `code`: Standardized error code for classification\n/// - `message`: Human-readable error description\n/// - `retryable`: Whether the operation can be safely retried\n/// - `details`: Additional context for debugging (optional)\n#[derive(Serialize, Deserialize)]\npub struct ToolError {\n    pub code: ToolErrorCode,\n    pub message: String,\n    pub retryable: bool,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub details: Option\u003cValue\u003e\n}\n\nimpl ToolError {\n    pub fn new(code: ToolErrorCode, message: impl Into\u003cString\u003e) -\u003e Self {\n        let retryable = matches!(\n            code,\n            ToolErrorCode::RateLimited | ToolErrorCode::Timeout | ToolErrorCode::ProviderError\n        );\n        Self {\n            code,\n            message: message.into(),\n            retryable,\n            details: None\n        }\n    }\n\n    pub fn with_details(mut self, details: Value) -\u003e Self {\n        self.details = Some(details);\n        self\n    }\n}\n\n/// Central registry for managing and invoking tools.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Provides a centralized mechanism for registering, discovering, and invoking\n/// tools. Enables dynamic tool management and type-safe execution across the\n/// system.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use tools::tools::{ToolRegistry, Tool, ToolDefinition};\n/// use async_trait::async_trait;\n/// use serde_json::{json, Value};\n/// use std::error::Error;\n///\n/// struct MyTool;\n///\n/// #[async_trait]\n/// impl Tool for MyTool {\n///     fn name(\u0026self) -\u003e \u0026str { \"my_tool\" }\n///     fn description(\u0026self) -\u003e \u0026str { \"My example tool\" }\n///     fn input_schema(\u0026self) -\u003e Value { json!({}) }\n///     async fn call(\u0026self, _params: Value) -\u003e Result\u003cValue, Box\u003cdyn Error + Send + Sync\u003e\u003e {\n///         Ok(json!({ \"result\": \"success\" }))\n///     }\n/// }\n///\n/// // Create registry\n/// let mut registry = ToolRegistry::new();\n///\n/// // Register tools\n/// registry.register(Box::new(MyTool));\n///\n/// // List available tools\n/// let tools: Vec\u003cToolDefinition\u003e = registry.list_tools();\n/// ```\n///\n/// ## Methods\n/// - `new`: Creates an empty tool registry\n/// - `register`: Registers a tool by its unique name\n/// - `call`: Invokes a registered tool with the given parameters\n/// - `list_tools`: Returns metadata for all registered tools\npub struct ToolRegistry {\n    tools: HashMap\u003cString, Box\u003cdyn Tool\u003e\u003e\n}\n\n#[allow(clippy::new_without_default)]\nimpl Default for ToolRegistry {\n    fn default() -\u003e Self {\n        Self {\n            tools: HashMap::new()\n        }\n    }\n}\n\nimpl ToolRegistry {\n    pub fn new() -\u003e Self {\n        Self::default()\n    }\n\n    pub fn register(\u0026mut self, tool: Box\u003cdyn Tool\u003e) {\n        self.tools.insert(tool.name().to_string(), tool);\n    }\n\n    pub async fn call(\n        \u0026self,\n        name: \u0026str,\n        params: Value\n    ) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        let tool = self\n            .tools\n            .get(name)\n            .ok_or(format!(\"Tool {} not found\", name))?;\n        tool.call(params).await\n    }\n\n    pub fn list_tools(\u0026self) -\u003e Vec\u003cToolDefinition\u003e {\n        self.tools\n            .values()\n            .map(|t| ToolDefinition {\n                name: t.name().to_string(),\n                description: t.description().to_string(),\n                input_schema: t.input_schema()\n            })\n            .collect()\n    }\n}\n\n/// Metadata definition for a registered tool.\n///\n/// # M-CANONICAL-DOCS\n///\n/// ## Purpose\n/// Provides tool discovery information without exposing implementation details.\n/// Used for tool listing, documentation generation, and client UI.\n///\n/// ## Usage\n/// ```rust,no_run\n/// use tools::tools::ToolDefinition;\n/// use serde_json::json;\n///\n/// let definition = ToolDefinition {\n///     name: \"my_tool\".to_string(),\n///     description: \"Does something useful\".to_string(),\n///     input_schema: json!({\n///         \"type\": \"object\",\n///         \"properties\": {\n///             \"input\": { \"type\": \"string\" }\n///         },\n///         \"required\": [\"input\"]\n///     }),\n/// };\n/// ```\n///\n/// ## Fields\n/// - `name`: Unique tool identifier used for invocation\n/// - `description`: Human-readable description of tool purpose\n/// - `input_schema`: JSON Schema defining valid input parameters\n#[derive(Serialize, Deserialize)]\npub struct ToolDefinition {\n    pub name: String,\n    pub description: String,\n    pub input_schema: Value\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    struct TestTool {\n        name: String\n    }\n\n    #[async_trait]\n    impl Tool for TestTool {\n        fn name(\u0026self) -\u003e \u0026str {\n            \u0026self.name\n        }\n        fn description(\u0026self) -\u003e \u0026str {\n            \"Test tool\"\n        }\n        fn input_schema(\u0026self) -\u003e Value {\n            serde_json::json!({})\n        }\n        async fn call(\n            \u0026self,\n            _params: Value\n        ) -\u003e Result\u003cValue, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n            Ok(serde_json::json!({\"result\": \"success\"}))\n        }\n    }\n\n    #[tokio::test]\n    async fn test_tool_registry_operations() {\n        let mut registry = ToolRegistry::new();\n\n        registry.register(Box::new(TestTool {\n            name: \"tool1\".to_string()\n        }));\n        registry.register(Box::new(TestTool {\n            name: \"tool2\".to_string()\n        }));\n\n        let tools = registry.list_tools();\n        assert_eq!(tools.len(), 2);\n        assert!(tools.iter().any(|t| t.name == \"tool1\"));\n        assert!(tools.iter().any(|t| t.name == \"tool2\"));\n\n        let result = registry.call(\"tool1\", serde_json::json!({})).await.unwrap();\n        assert_eq!(result[\"result\"], \"success\");\n\n        let err = registry.call(\"nonexistent\", serde_json::json!({})).await;\n        assert!(err.is_err());\n        assert!(err.unwrap_err().to_string().contains(\"not found\"));\n    }\n\n    #[test]\n    fn test_tool_registry_duplicate_registration() {\n        let mut registry = ToolRegistry::new();\n\n        registry.register(Box::new(TestTool {\n            name: \"same\".to_string()\n        }));\n        registry.register(Box::new(TestTool {\n            name: \"same\".to_string()\n        }));\n\n        let tools = registry.list_tools();\n        assert_eq!(tools.len(), 1);\n    }\n\n    #[test]\n    fn test_tool_error_retryability() {\n        let err = ToolError::new(ToolErrorCode::RateLimited, \"Too many requests\");\n        assert!(err.retryable);\n\n        let err = ToolError::new(ToolErrorCode::InvalidInput, \"Bad params\");\n        assert!(!err.retryable);\n\n        let err = ToolError::new(ToolErrorCode::NotFound, \"Not found\");\n        assert!(!err.retryable);\n\n        let err = ToolError::new(ToolErrorCode::Timeout, \"Timed out\");\n        assert!(err.retryable);\n    }\n}\n","traces":[{"line":180,"address":[],"length":0,"stats":{"Line":4}},{"line":181,"address":[],"length":0,"stats":{"Line":6}},{"line":182,"address":[],"length":0,"stats":{"Line":4}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":12}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":20}},{"line":250,"address":[],"length":0,"stats":{"Line":20}},{"line":256,"address":[],"length":0,"stats":{"Line":20}},{"line":257,"address":[],"length":0,"stats":{"Line":20}},{"line":260,"address":[],"length":0,"stats":{"Line":274}},{"line":261,"address":[],"length":0,"stats":{"Line":1370}},{"line":264,"address":[],"length":0,"stats":{"Line":8}},{"line":269,"address":[],"length":0,"stats":{"Line":14}},{"line":270,"address":[],"length":0,"stats":{"Line":8}},{"line":271,"address":[],"length":0,"stats":{"Line":16}},{"line":272,"address":[],"length":0,"stats":{"Line":26}},{"line":273,"address":[],"length":0,"stats":{"Line":18}},{"line":276,"address":[],"length":0,"stats":{"Line":7}},{"line":277,"address":[],"length":0,"stats":{"Line":7}},{"line":279,"address":[],"length":0,"stats":{"Line":7}},{"line":280,"address":[],"length":0,"stats":{"Line":156}},{"line":281,"address":[],"length":0,"stats":{"Line":156}},{"line":282,"address":[],"length":0,"stats":{"Line":156}}],"covered":22,"coverable":26},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","validator.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","src","working.rs"],"content":"","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","tests","bridge_tools.rs"],"content":"use async_trait::async_trait;\nuse knowledge::repository::GitRepository;\nuse memory::manager::MemoryManager;\nuse mk_core::traits::KnowledgeRepository;\nuse mk_core::types::{KnowledgeEntry, KnowledgeLayer, KnowledgeStatus, KnowledgeType, TenantId};\nuse serde_json::json;\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse sync::bridge::SyncManager;\nuse sync::state::SyncState;\nuse sync::state_persister::SyncStatePersister;\nuse tools::bridge::{SyncNowTool, SyncStatusTool};\nuse tools::tools::Tool;\n\nstruct MockPersister;\n\n#[async_trait]\nimpl SyncStatePersister for MockPersister {\n    async fn load(\n        \u0026self,\n        _tenant_id: \u0026TenantId,\n    ) -\u003e Result\u003cSyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        Ok(SyncState::default())\n    }\n    async fn save(\n        \u0026self,\n        _tenant_id: \u0026TenantId,\n        _state: \u0026SyncState,\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        Ok(())\n    }\n}\n\n#[tokio::test]\nasync fn test_sync_tools() -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    // GIVEN a SyncManager and tools\n    let repo_dir = tempfile::tempdir()?;\n    let knowledge_repo = Arc::new(GitRepository::new(repo_dir.path())?);\n    let memory_manager = Arc::new(MemoryManager::new());\n\n    use memory::providers::MockProvider;\n    memory_manager\n        .register_provider(\n            mk_core::types::MemoryLayer::Project,\n            Box::new(MockProvider::new()),\n        )\n        .await;\n\n    let persister = Arc::new(MockPersister);\n\n    let sync_manager = Arc::new(\n        SyncManager::new(\n            memory_manager,\n            knowledge_repo.clone(),\n            Arc::new(knowledge::governance::GovernanceEngine::new()),\n            config::config::DeploymentConfig::default(),\n            None,\n            persister,\n        )\n        .await?,\n    );\n\n    let sync_now_tool = SyncNowTool::new(sync_manager.clone());\n    let sync_status_tool = SyncStatusTool::new(sync_manager.clone());\n\n    let tenant_id = mk_core::types::TenantId::new(\"t1\".into()).unwrap();\n    let user_id = mk_core::types::UserId::new(\"u1\".into()).unwrap();\n    let ctx = mk_core::types::TenantContext::new(tenant_id, user_id);\n\n    // WHEN initial sync status is requested\n    let status_resp = sync_status_tool\n        .call(json!({\n            \"tenantContext\": {\n                \"tenant_id\": \"t1\",\n                \"user_id\": \"u1\"\n            }\n        }))\n        .await?;\n\n    // THEN it should be healthy and have zero stats\n    assert!(status_resp[\"success\"].as_bool().unwrap());\n    assert!(status_resp[\"healthy\"].as_bool().unwrap());\n    assert_eq!(status_resp[\"stats\"][\"totalSyncs\"], 0);\n\n    // WHEN adding knowledge and triggering sync_now\n    let entry = KnowledgeEntry {\n        path: \"test.md\".to_string(),\n        content: \"test content\".to_string(),\n        layer: KnowledgeLayer::Project,\n        kind: KnowledgeType::Spec,\n        metadata: HashMap::new(),\n        status: KnowledgeStatus::Accepted,\n        commit_hash: None,\n        author: None,\n        updated_at: chrono::Utc::now().timestamp(),\n    };\n    knowledge_repo.store(ctx, entry, \"commit\").await?;\n\n    let sync_resp = sync_now_tool\n        .call(json!({\n            \"force\": false,\n            \"tenantContext\": {\n                \"tenant_id\": \"t1\",\n                \"user_id\": \"u1\"\n            }\n        }))\n        .await?;\n    assert!(sync_resp[\"success\"].as_bool().unwrap());\n\n    // THEN status should reflect the sync\n    let status_resp = sync_status_tool\n        .call(json!({\n            \"tenantContext\": {\n                \"tenant_id\": \"t1\",\n                \"user_id\": \"u1\"\n            }\n        }))\n        .await?;\n    assert_eq!(status_resp[\"stats\"][\"totalSyncs\"], 1);\n    assert_eq!(status_resp[\"stats\"][\"totalItemsSynced\"], 1);\n\n    Ok(())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","tests","governance_e2e.rs"],"content":"use async_trait::async_trait;\nuse knowledge::governance::GovernanceEngine;\nuse mk_core::traits::StorageBackend;\nuse mk_core::types::{\n    ConstraintOperator, ConstraintSeverity, ConstraintTarget, KnowledgeLayer, OrganizationalUnit,\n    Policy, PolicyMode, PolicyRule, Role, RuleMergeStrategy, RuleType, TenantContext, TenantId,\n    UnitType, UserId,\n};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse storage::postgres::PostgresError;\nuse tokio::sync::RwLock;\n\nstruct MockGovernanceStorage {\n    policies: Arc\u003cRwLock\u003cHashMap\u003cString, Vec\u003cPolicy\u003e\u003e\u003e\u003e,\n    units: Arc\u003cRwLock\u003cHashMap\u003cString, OrganizationalUnit\u003e\u003e\u003e,\n    drift_results: Arc\u003cRwLock\u003cVec\u003cmk_core::types::DriftResult\u003e\u003e\u003e,\n}\n\nimpl MockGovernanceStorage {\n    fn new() -\u003e Self {\n        Self {\n            policies: Arc::new(RwLock::new(HashMap::new())),\n            units: Arc::new(RwLock::new(HashMap::new())),\n            drift_results: Arc::new(RwLock::new(Vec::new())),\n        }\n    }\n\n    async fn add_unit(\u0026self, unit: OrganizationalUnit) {\n        self.units.write().await.insert(unit.id.clone(), unit);\n    }\n\n    async fn add_policy_for_unit(\u0026self, unit_id: \u0026str, policy: Policy) {\n        let mut policies = self.policies.write().await;\n        policies\n            .entry(unit_id.to_string())\n            .or_insert_with(Vec::new)\n            .push(policy);\n    }\n}\n\n#[async_trait]\nimpl StorageBackend for MockGovernanceStorage {\n    type Error = PostgresError;\n\n    async fn store(\n        \u0026self,\n        _ctx: TenantContext,\n        _key: \u0026str,\n        _value: \u0026[u8],\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn retrieve(\n        \u0026self,\n        _ctx: TenantContext,\n        _key: \u0026str,\n    ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n\n    async fn delete(\u0026self, _ctx: TenantContext, _key: \u0026str) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn exists(\u0026self, _ctx: TenantContext, _key: \u0026str) -\u003e Result\u003cbool, Self::Error\u003e {\n        Ok(false)\n    }\n\n    async fn get_ancestors(\n        \u0026self,\n        _ctx: TenantContext,\n        unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, Self::Error\u003e {\n        let units = self.units.read().await;\n        let mut ancestors = Vec::new();\n\n        if let Some(unit) = units.get(unit_id) {\n            let mut current_parent = unit.parent_id.clone();\n            while let Some(parent_id) = current_parent {\n                if let Some(parent) = units.get(\u0026parent_id) {\n                    ancestors.push(parent.clone());\n                    current_parent = parent.parent_id.clone();\n                } else {\n                    break;\n                }\n            }\n        }\n\n        Ok(ancestors)\n    }\n\n    async fn get_descendants(\n        \u0026self,\n        _ctx: TenantContext,\n        unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, Self::Error\u003e {\n        let units = self.units.read().await;\n        let descendants: Vec\u003cOrganizationalUnit\u003e = units\n            .values()\n            .filter(|u| u.parent_id.as_deref() == Some(unit_id))\n            .cloned()\n            .collect();\n        Ok(descendants)\n    }\n\n    async fn get_unit_policies(\n        \u0026self,\n        _ctx: TenantContext,\n        unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cPolicy\u003e, Self::Error\u003e {\n        let policies = self.policies.read().await;\n        Ok(policies.get(unit_id).cloned().unwrap_or_default())\n    }\n\n    async fn add_unit_policy(\n        \u0026self,\n        _ctx: \u0026TenantContext,\n        unit_id: \u0026str,\n        policy: \u0026Policy,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        let mut policies = self.policies.write().await;\n        policies\n            .entry(unit_id.to_string())\n            .or_insert_with(Vec::new)\n            .push(policy.clone());\n        Ok(())\n    }\n\n    async fn assign_role(\n        \u0026self,\n        _user_id: \u0026UserId,\n        _tenant_id: \u0026TenantId,\n        _unit_id: \u0026str,\n        _role: Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn remove_role(\n        \u0026self,\n        _user_id: \u0026UserId,\n        _tenant_id: \u0026TenantId,\n        _unit_id: \u0026str,\n        _role: Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn store_drift_result(\n        \u0026self,\n        result: mk_core::types::DriftResult,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        self.drift_results.write().await.push(result);\n        Ok(())\n    }\n\n    async fn get_latest_drift_result(\n        \u0026self,\n        _ctx: TenantContext,\n        project_id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cmk_core::types::DriftResult\u003e, Self::Error\u003e {\n        let results = self.drift_results.read().await;\n        Ok(results\n            .iter()\n            .filter(|r| r.project_id == project_id)\n            .last()\n            .cloned())\n    }\n\n    async fn list_all_units(\u0026self) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(self.units.read().await.values().cloned().collect())\n    }\n\n    async fn record_job_status(\n        \u0026self,\n        _job_type: \u0026str,\n        _tenant_id: \u0026str,\n        _status: \u0026str,\n        _error: Option\u003c\u0026str\u003e,\n        _started_at: i64,\n        _completed_at: Option\u003ci64\u003e,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn get_governance_events(\n        \u0026self,\n        _ctx: TenantContext,\n        _since_timestamp: i64,\n        _limit: usize,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn create_unit(\u0026self, unit: \u0026OrganizationalUnit) -\u003e Result\u003c(), Self::Error\u003e {\n        self.units\n            .write()\n            .await\n            .insert(unit.id.clone(), unit.clone());\n        Ok(())\n    }\n}\n\nfn create_tenant_context(tenant: \u0026str, user: \u0026str) -\u003e TenantContext {\n    TenantContext::new(\n        TenantId::new(tenant.to_string()).unwrap(),\n        UserId::new(user.to_string()).unwrap(),\n    )\n}\n\nfn create_unit(\n    id: \u0026str,\n    name: \u0026str,\n    unit_type: UnitType,\n    parent: Option\u003c\u0026str\u003e,\n    tenant: \u0026str,\n) -\u003e OrganizationalUnit {\n    OrganizationalUnit {\n        id: id.to_string(),\n        name: name.to_string(),\n        unit_type,\n        parent_id: parent.map(String::from),\n        tenant_id: TenantId::new(tenant.to_string()).unwrap(),\n        metadata: HashMap::new(),\n        created_at: chrono::Utc::now().timestamp(),\n        updated_at: chrono::Utc::now().timestamp(),\n    }\n}\n\n#[tokio::test]\nasync fn test_e2e_complete_governance_workflow() {\n    let storage = Arc::new(MockGovernanceStorage::new());\n\n    let company = create_unit(\n        \"acme-corp\",\n        \"Acme Corporation\",\n        UnitType::Company,\n        None,\n        \"tenant-1\",\n    );\n    let org = create_unit(\n        \"engineering\",\n        \"Engineering Org\",\n        UnitType::Organization,\n        Some(\"acme-corp\"),\n        \"tenant-1\",\n    );\n    let team = create_unit(\n        \"platform-team\",\n        \"Platform Team\",\n        UnitType::Team,\n        Some(\"engineering\"),\n        \"tenant-1\",\n    );\n    let project = create_unit(\n        \"api-gateway\",\n        \"API Gateway\",\n        UnitType::Project,\n        Some(\"platform-team\"),\n        \"tenant-1\",\n    );\n\n    storage.add_unit(company).await;\n    storage.add_unit(org).await;\n    storage.add_unit(team).await;\n    storage.add_unit(project).await;\n\n    let company_policy = Policy {\n        id: \"security-baseline\".to_string(),\n        name: \"Company Security Baseline\".to_string(),\n        description: Some(\"Mandatory security requirements\".to_string()),\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"no-eval\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Code,\n            operator: ConstraintOperator::MustNotMatch,\n            value: serde_json::json!(r\"eval\\s*\\(\"),\n            severity: ConstraintSeverity::Block,\n            message: \"eval() is forbidden for security reasons\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    let team_policy = Policy {\n        id: \"team-standards\".to_string(),\n        name: \"Platform Team Standards\".to_string(),\n        description: Some(\"Team coding standards\".to_string()),\n        layer: KnowledgeLayer::Team,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Merge,\n        rules: vec![PolicyRule {\n            id: \"require-logging\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"tracing\"),\n            severity: ConstraintSeverity::Warn,\n            message: \"Projects should use tracing for observability\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    storage\n        .add_policy_for_unit(\"acme-corp\", company_policy)\n        .await;\n    storage\n        .add_policy_for_unit(\"platform-team\", team_policy)\n        .await;\n\n    let engine = GovernanceEngine::new().with_storage(storage.clone());\n\n    let ctx = create_tenant_context(\"tenant-1\", \"developer-1\");\n\n    let mut context = HashMap::new();\n    context.insert(\"unitId\".to_string(), serde_json::json!(\"api-gateway\"));\n    context.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"function safe() { return 1; }\"),\n    );\n    context.insert(\n        \"dependencies\".to_string(),\n        serde_json::json!([\"tracing\", \"tokio\"]),\n    );\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"api-gateway\", \u0026context)\n        .await\n        .unwrap();\n    assert_eq!(drift_score, 0.0, \"Compliant code should have zero drift\");\n\n    let mut bad_context = HashMap::new();\n    bad_context.insert(\"unitId\".to_string(), serde_json::json!(\"api-gateway\"));\n    bad_context.insert(\n        \"content\".to_string(),\n        serde_json::json!(\"let result = eval('malicious');\"),\n    );\n    bad_context.insert(\"dependencies\".to_string(), serde_json::json!([\"tokio\"]));\n\n    let drift_score = engine\n        .check_drift(\u0026ctx, \"api-gateway\", \u0026bad_context)\n        .await\n        .unwrap();\n    assert!(\n        drift_score \u003e 0.0,\n        \"Violating code should have non-zero drift\"\n    );\n}\n\n#[tokio::test]\nasync fn test_e2e_multi_tenant_isolation() {\n    let storage = Arc::new(MockGovernanceStorage::new());\n\n    let tenant1_company = create_unit(\n        \"company-a\",\n        \"Company A\",\n        UnitType::Company,\n        None,\n        \"tenant-1\",\n    );\n    let tenant2_company = create_unit(\n        \"company-b\",\n        \"Company B\",\n        UnitType::Company,\n        None,\n        \"tenant-2\",\n    );\n\n    storage.add_unit(tenant1_company).await;\n    storage.add_unit(tenant2_company).await;\n\n    let tenant1_policy = Policy {\n        id: \"t1-policy\".to_string(),\n        name: \"Tenant 1 Policy\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![PolicyRule {\n            id: \"t1-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"tenant1-lib\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Tenant 1 requires tenant1-lib\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    let tenant2_policy = Policy {\n        id: \"t2-policy\".to_string(),\n        name: \"Tenant 2 Policy\".to_string(),\n        description: None,\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![PolicyRule {\n            id: \"t2-rule\".to_string(),\n            rule_type: RuleType::Allow,\n            target: ConstraintTarget::Dependency,\n            operator: ConstraintOperator::MustUse,\n            value: serde_json::json!(\"tenant2-lib\"),\n            severity: ConstraintSeverity::Block,\n            message: \"Tenant 2 requires tenant2-lib\".to_string(),\n        }],\n        metadata: HashMap::new(),\n    };\n\n    storage\n        .add_policy_for_unit(\"company-a\", tenant1_policy)\n        .await;\n    storage\n        .add_policy_for_unit(\"company-b\", tenant2_policy)\n        .await;\n\n    let engine = GovernanceEngine::new().with_storage(storage);\n\n    let ctx1 = create_tenant_context(\"tenant-1\", \"user-1\");\n    let ctx2 = create_tenant_context(\"tenant-2\", \"user-2\");\n\n    let mut context1 = HashMap::new();\n    context1.insert(\"unitId\".to_string(), serde_json::json!(\"company-a\"));\n    context1.insert(\n        \"dependencies\".to_string(),\n        serde_json::json!([\"tenant1-lib\"]),\n    );\n\n    let mut context2 = HashMap::new();\n    context2.insert(\"unitId\".to_string(), serde_json::json!(\"company-b\"));\n    context2.insert(\n        \"dependencies\".to_string(),\n        serde_json::json!([\"tenant2-lib\"]),\n    );\n\n    let score1 = engine\n        .check_drift(\u0026ctx1, \"company-a\", \u0026context1)\n        .await\n        .unwrap();\n    let score2 = engine\n        .check_drift(\u0026ctx2, \"company-b\", \u0026context2)\n        .await\n        .unwrap();\n\n    assert_eq!(score1, 0.0, \"Tenant 1 compliant with tenant1-lib\");\n    assert_eq!(score2, 0.0, \"Tenant 2 compliant with tenant2-lib\");\n\n    let mut cross_context = HashMap::new();\n    cross_context.insert(\"unitId\".to_string(), serde_json::json!(\"company-a\"));\n    cross_context.insert(\n        \"dependencies\".to_string(),\n        serde_json::json!([\"tenant2-lib\"]),\n    );\n\n    let cross_score = engine\n        .check_drift(\u0026ctx1, \"company-a\", \u0026cross_context)\n        .await\n        .unwrap();\n    assert!(\n        cross_score \u003e 0.0,\n        \"Tenant 1 should fail without tenant1-lib\"\n    );\n}\n\n#[tokio::test]\nasync fn test_e2e_policy_inheritance_chain() {\n    let storage = Arc::new(MockGovernanceStorage::new());\n\n    let company = create_unit(\"corp\", \"Corporation\", UnitType::Company, None, \"t1\");\n    let org = create_unit(\n        \"org\",\n        \"Organization\",\n        UnitType::Organization,\n        Some(\"corp\"),\n        \"t1\",\n    );\n    let team = create_unit(\"team\", \"Team\", UnitType::Team, Some(\"org\"), \"t1\");\n    let project = create_unit(\"proj\", \"Project\", UnitType::Project, Some(\"team\"), \"t1\");\n\n    storage.add_unit(company).await;\n    storage.add_unit(org).await;\n    storage.add_unit(team).await;\n    storage.add_unit(project).await;\n\n    storage\n        .add_policy_for_unit(\n            \"corp\",\n            Policy {\n                id: \"company-rule\".to_string(),\n                name: \"Company Rule\".to_string(),\n                description: None,\n                layer: KnowledgeLayer::Company,\n                mode: PolicyMode::Mandatory,\n                merge_strategy: RuleMergeStrategy::Merge,\n                rules: vec![PolicyRule {\n                    id: \"req-a\".to_string(),\n                    rule_type: RuleType::Allow,\n                    target: ConstraintTarget::Dependency,\n                    operator: ConstraintOperator::MustUse,\n                    value: serde_json::json!(\"lib-a\"),\n                    severity: ConstraintSeverity::Info,\n                    message: \"Company requires lib-a\".to_string(),\n                }],\n                metadata: HashMap::new(),\n            },\n        )\n        .await;\n\n    storage\n        .add_policy_for_unit(\n            \"org\",\n            Policy {\n                id: \"org-rule\".to_string(),\n                name: \"Org Rule\".to_string(),\n                description: None,\n                layer: KnowledgeLayer::Org,\n                mode: PolicyMode::Mandatory,\n                merge_strategy: RuleMergeStrategy::Merge,\n                rules: vec![PolicyRule {\n                    id: \"req-b\".to_string(),\n                    rule_type: RuleType::Allow,\n                    target: ConstraintTarget::Dependency,\n                    operator: ConstraintOperator::MustUse,\n                    value: serde_json::json!(\"lib-b\"),\n                    severity: ConstraintSeverity::Info,\n                    message: \"Org requires lib-b\".to_string(),\n                }],\n                metadata: HashMap::new(),\n            },\n        )\n        .await;\n\n    storage\n        .add_policy_for_unit(\n            \"team\",\n            Policy {\n                id: \"team-rule\".to_string(),\n                name: \"Team Rule\".to_string(),\n                description: None,\n                layer: KnowledgeLayer::Team,\n                mode: PolicyMode::Mandatory,\n                merge_strategy: RuleMergeStrategy::Merge,\n                rules: vec![PolicyRule {\n                    id: \"req-c\".to_string(),\n                    rule_type: RuleType::Allow,\n                    target: ConstraintTarget::Dependency,\n                    operator: ConstraintOperator::MustUse,\n                    value: serde_json::json!(\"lib-c\"),\n                    severity: ConstraintSeverity::Info,\n                    message: \"Team requires lib-c\".to_string(),\n                }],\n                metadata: HashMap::new(),\n            },\n        )\n        .await;\n\n    let engine = GovernanceEngine::new().with_storage(storage);\n    let ctx = create_tenant_context(\"t1\", \"user\");\n\n    let mut all_libs = HashMap::new();\n    all_libs.insert(\"unitId\".to_string(), serde_json::json!(\"proj\"));\n    all_libs.insert(\n        \"dependencies\".to_string(),\n        serde_json::json!([\"lib-a\", \"lib-b\", \"lib-c\"]),\n    );\n\n    let score = engine.check_drift(\u0026ctx, \"proj\", \u0026all_libs).await.unwrap();\n    assert_eq!(score, 0.0, \"All inherited requirements satisfied\");\n\n    let mut missing_one = HashMap::new();\n    missing_one.insert(\"unitId\".to_string(), serde_json::json!(\"proj\"));\n    missing_one.insert(\n        \"dependencies\".to_string(),\n        serde_json::json!([\"lib-a\", \"lib-b\"]),\n    );\n\n    let score = engine\n        .check_drift(\u0026ctx, \"proj\", \u0026missing_one)\n        .await\n        .unwrap();\n    assert!(score \u003e 0.0, \"Missing lib-c should trigger drift\");\n}\n\n#[tokio::test]\nasync fn test_e2e_drift_result_persistence() {\n    let storage = Arc::new(MockGovernanceStorage::new());\n\n    let project = create_unit(\"test-proj\", \"Test Project\", UnitType::Project, None, \"t1\");\n    storage.add_unit(project).await;\n\n    storage\n        .add_policy_for_unit(\n            \"test-proj\",\n            Policy {\n                id: \"test-policy\".to_string(),\n                name: \"Test Policy\".to_string(),\n                description: None,\n                layer: KnowledgeLayer::Project,\n                mode: PolicyMode::Mandatory,\n                merge_strategy: RuleMergeStrategy::Override,\n                rules: vec![PolicyRule {\n                    id: \"test-rule\".to_string(),\n                    rule_type: RuleType::Allow,\n                    target: ConstraintTarget::Dependency,\n                    operator: ConstraintOperator::MustUse,\n                    value: serde_json::json!(\"required-lib\"),\n                    severity: ConstraintSeverity::Warn,\n                    message: \"Required lib missing\".to_string(),\n                }],\n                metadata: HashMap::new(),\n            },\n        )\n        .await;\n\n    let engine = GovernanceEngine::new().with_storage(storage.clone());\n    let ctx = create_tenant_context(\"t1\", \"user\");\n\n    let mut context = HashMap::new();\n    context.insert(\"unitId\".to_string(), serde_json::json!(\"test-proj\"));\n    context.insert(\"dependencies\".to_string(), serde_json::json!([\"other-lib\"]));\n\n    let _score = engine\n        .check_drift(\u0026ctx, \"test-proj\", \u0026context)\n        .await\n        .unwrap();\n\n    let stored_result = storage\n        .get_latest_drift_result(ctx.clone(), \"test-proj\")\n        .await\n        .unwrap();\n    assert!(stored_result.is_some(), \"Drift result should be persisted\");\n\n    let result = stored_result.unwrap();\n    assert_eq!(result.project_id, \"test-proj\");\n    assert!(\n        !result.violations.is_empty(),\n        \"Violations should be recorded\"\n    );\n}\n\n#[tokio::test]\nasync fn test_e2e_policy_override_at_lower_layer() {\n    let storage = Arc::new(MockGovernanceStorage::new());\n\n    let company = create_unit(\"corp\", \"Corp\", UnitType::Company, None, \"t1\");\n    let project = create_unit(\"proj\", \"Project\", UnitType::Project, Some(\"corp\"), \"t1\");\n\n    storage.add_unit(company).await;\n    storage.add_unit(project).await;\n\n    storage\n        .add_policy_for_unit(\n            \"corp\",\n            Policy {\n                id: \"shared-policy\".to_string(),\n                name: \"Company Policy\".to_string(),\n                description: None,\n                layer: KnowledgeLayer::Company,\n                mode: PolicyMode::Mandatory,\n                merge_strategy: RuleMergeStrategy::Override,\n                rules: vec![PolicyRule {\n                    id: \"company-rule\".to_string(),\n                    rule_type: RuleType::Allow,\n                    target: ConstraintTarget::Dependency,\n                    operator: ConstraintOperator::MustUse,\n                    value: serde_json::json!(\"old-lib\"),\n                    severity: ConstraintSeverity::Block,\n                    message: \"Company requires old-lib\".to_string(),\n                }],\n                metadata: HashMap::new(),\n            },\n        )\n        .await;\n\n    storage\n        .add_policy_for_unit(\n            \"proj\",\n            Policy {\n                id: \"shared-policy\".to_string(),\n                name: \"Project Override\".to_string(),\n                description: None,\n                layer: KnowledgeLayer::Project,\n                mode: PolicyMode::Mandatory,\n                merge_strategy: RuleMergeStrategy::Override,\n                rules: vec![PolicyRule {\n                    id: \"project-rule\".to_string(),\n                    rule_type: RuleType::Allow,\n                    target: ConstraintTarget::Dependency,\n                    operator: ConstraintOperator::MustUse,\n                    value: serde_json::json!(\"new-lib\"),\n                    severity: ConstraintSeverity::Block,\n                    message: \"Project requires new-lib\".to_string(),\n                }],\n                metadata: HashMap::new(),\n            },\n        )\n        .await;\n\n    let engine = GovernanceEngine::new().with_storage(storage);\n    let ctx = create_tenant_context(\"t1\", \"user\");\n\n    let mut context = HashMap::new();\n    context.insert(\"unitId\".to_string(), serde_json::json!(\"proj\"));\n    context.insert(\"dependencies\".to_string(), serde_json::json!([\"new-lib\"]));\n\n    let score = engine.check_drift(\u0026ctx, \"proj\", \u0026context).await.unwrap();\n    assert_eq!(score, 0.0, \"Project override should take precedence\");\n}\n\n#[tokio::test]\nasync fn test_e2e_validation_result_structure() {\n    let mut engine = GovernanceEngine::new();\n\n    engine.add_policy(Policy {\n        id: \"test-policy\".to_string(),\n        name: \"Test Policy\".to_string(),\n        description: Some(\"Test description\".to_string()),\n        layer: KnowledgeLayer::Company,\n        mode: PolicyMode::Mandatory,\n        merge_strategy: RuleMergeStrategy::Override,\n        rules: vec![\n            PolicyRule {\n                id: \"block-rule\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Dependency,\n                operator: ConstraintOperator::MustUse,\n                value: serde_json::json!(\"critical-lib\"),\n                severity: ConstraintSeverity::Block,\n                message: \"Critical lib missing\".to_string(),\n            },\n            PolicyRule {\n                id: \"warn-rule\".to_string(),\n                rule_type: RuleType::Allow,\n                target: ConstraintTarget::Dependency,\n                operator: ConstraintOperator::MustUse,\n                value: serde_json::json!(\"recommended-lib\"),\n                severity: ConstraintSeverity::Warn,\n                message: \"Recommended lib missing\".to_string(),\n            },\n        ],\n        metadata: HashMap::new(),\n    });\n\n    let mut context = HashMap::new();\n    context.insert(\"dependencies\".to_string(), serde_json::json!([]));\n\n    let result = engine.validate(KnowledgeLayer::Company, \u0026context);\n\n    assert!(!result.is_valid, \"Should be invalid with violations\");\n    assert_eq!(result.violations.len(), 2, \"Should have 2 violations\");\n\n    let block_violation = result.violations.iter().find(|v| v.rule_id == \"block-rule\");\n    let warn_violation = result.violations.iter().find(|v| v.rule_id == \"warn-rule\");\n\n    assert!(block_violation.is_some(), \"Should have block violation\");\n    assert!(warn_violation.is_some(), \"Should have warn violation\");\n\n    assert_eq!(block_violation.unwrap().severity, ConstraintSeverity::Block);\n    assert_eq!(warn_violation.unwrap().severity, ConstraintSeverity::Warn);\n}\n\n#[tokio::test]\nasync fn test_e2e_empty_policy_graceful_handling() {\n    let storage = Arc::new(MockGovernanceStorage::new());\n\n    let project = create_unit(\"empty-proj\", \"Empty Project\", UnitType::Project, None, \"t1\");\n    storage.add_unit(project).await;\n\n    let engine = GovernanceEngine::new().with_storage(storage);\n    let ctx = create_tenant_context(\"t1\", \"user\");\n\n    let mut context = HashMap::new();\n    context.insert(\"unitId\".to_string(), serde_json::json!(\"empty-proj\"));\n    context.insert(\"dependencies\".to_string(), serde_json::json!([\"any-lib\"]));\n\n    let result = engine.check_drift(\u0026ctx, \"empty-proj\", \u0026context).await;\n    assert!(result.is_ok(), \"Should handle empty policies gracefully\");\n\n    let score = result.unwrap();\n    assert!(\n        score \u003c= 0.5,\n        \"Should only have missing mandatory policies warning\"\n    );\n}\n","traces":[{"line":21,"address":[],"length":0,"stats":{"Line":6}},{"line":23,"address":[],"length":0,"stats":{"Line":24}},{"line":24,"address":[],"length":0,"stats":{"Line":24}},{"line":25,"address":[],"length":0,"stats":{"Line":12}},{"line":29,"address":[],"length":0,"stats":{"Line":28}},{"line":30,"address":[],"length":0,"stats":{"Line":84}},{"line":33,"address":[],"length":0,"stats":{"Line":20}},{"line":34,"address":[],"length":0,"stats":{"Line":20}},{"line":35,"address":[],"length":0,"stats":{"Line":20}},{"line":36,"address":[],"length":0,"stats":{"Line":20}},{"line":37,"address":[],"length":0,"stats":{"Line":10}},{"line":38,"address":[],"length":0,"stats":{"Line":20}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":2}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":7}},{"line":208,"address":[],"length":0,"stats":{"Line":28}},{"line":209,"address":[],"length":0,"stats":{"Line":28}},{"line":213,"address":[],"length":0,"stats":{"Line":14}},{"line":221,"address":[],"length":0,"stats":{"Line":42}},{"line":222,"address":[],"length":0,"stats":{"Line":42}},{"line":224,"address":[],"length":0,"stats":{"Line":42}},{"line":225,"address":[],"length":0,"stats":{"Line":70}},{"line":226,"address":[],"length":0,"stats":{"Line":28}},{"line":227,"address":[],"length":0,"stats":{"Line":42}},{"line":228,"address":[],"length":0,"stats":{"Line":14}}],"covered":24,"coverable":29},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","tests","integration.rs"],"content":"use adapters::ecosystem::{EcosystemAdapter, OpenCodeAdapter};\nuse adapters::langchain::LangChainAdapter;\nuse async_trait::async_trait;\nuse memory::manager::MemoryManager;\nuse memory::providers::MockProvider;\nuse mk_core::traits::KnowledgeRepository;\nuse mk_core::types::{KnowledgeEntry, KnowledgeLayer, MemoryLayer, TenantId};\nuse serde_json::json;\nuse std::sync::Arc;\nuse sync::bridge::SyncManager;\nuse sync::state::SyncState;\nuse sync::state_persister::SyncStatePersister;\nuse testcontainers::ContainerAsync;\nuse testcontainers::runners::AsyncRunner;\nuse testcontainers_modules::postgres::Postgres;\nuse tools::server::{JsonRpcRequest, McpServer};\n\nstruct MockKnowledgeRepo;\n\n#[async_trait]\nimpl KnowledgeRepository for MockKnowledgeRepo {\n    type Error = knowledge::repository::RepositoryError;\n\n    async fn get(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _layer: KnowledgeLayer,\n        _path: \u0026str,\n    ) -\u003e Result\u003cOption\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n\n    async fn store(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _entry: KnowledgeEntry,\n        _message: \u0026str,\n    ) -\u003e Result\u003cString, Self::Error\u003e {\n        Ok(\"hash\".to_string())\n    }\n\n    async fn list(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _layer: KnowledgeLayer,\n        _prefix: \u0026str,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n\n    async fn delete(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _layer: KnowledgeLayer,\n        _path: \u0026str,\n        _message: \u0026str,\n    ) -\u003e Result\u003cString, Self::Error\u003e {\n        Ok(\"hash\".to_string())\n    }\n\n    async fn get_head_commit(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n    ) -\u003e Result\u003cOption\u003cString\u003e, Self::Error\u003e {\n        Ok(Some(\"head\".to_string()))\n    }\n\n    async fn get_affected_items(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _since_commit: \u0026str,\n    ) -\u003e Result\u003cVec\u003c(KnowledgeLayer, String)\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n\n    async fn search(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _query: \u0026str,\n        _layers: Vec\u003cKnowledgeLayer\u003e,\n        _limit: usize,\n    ) -\u003e Result\u003cVec\u003cKnowledgeEntry\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n\n    fn root_path(\u0026self) -\u003e Option\u003cstd::path::PathBuf\u003e {\n        None\n    }\n}\n\nstruct MockPersister;\n\n#[async_trait]\nimpl SyncStatePersister for MockPersister {\n    async fn load(\n        \u0026self,\n        _tenant_id: \u0026TenantId,\n    ) -\u003e Result\u003cSyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        Ok(SyncState::default())\n    }\n    async fn save(\n        \u0026self,\n        _tenant_id: \u0026TenantId,\n        _state: \u0026SyncState,\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        Ok(())\n    }\n}\n\nstruct MockAuthService;\n#[async_trait]\nimpl mk_core::traits::AuthorizationService for MockAuthService {\n    type Error = anyhow::Error;\n    async fn check_permission(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _action: \u0026str,\n        _resource: \u0026str,\n    ) -\u003e anyhow::Result\u003cbool\u003e {\n        Ok(true)\n    }\n    async fn get_user_roles(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n    ) -\u003e anyhow::Result\u003cVec\u003cmk_core::types::Role\u003e\u003e {\n        Ok(vec![])\n    }\n    async fn assign_role(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _user_id: \u0026mk_core::types::UserId,\n        _role: mk_core::types::Role,\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n    async fn remove_role(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _user_id: \u0026mk_core::types::UserId,\n        _role: mk_core::types::Role,\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n}\n\nasync fn setup_postgres_container()\n-\u003e Result\u003c(ContainerAsync\u003cPostgres\u003e, String), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    let container = Postgres::default()\n        .with_db_name(\"testdb\")\n        .with_user(\"testuser\")\n        .with_password(\"testpass\")\n        .start()\n        .await\n        .map_err(|e| Box::new(e) as Box\u003cdyn std::error::Error + Send + Sync\u003e)?;\n\n    let connection_url = format!(\n        \"postgres://testuser:testpass@localhost:{}/testdb?sslmode=disable\",\n        container\n            .get_host_port_ipv4(5432)\n            .await\n            .map_err(|e| Box::new(e) as Box\u003cdyn std::error::Error + Send + Sync\u003e)?\n    );\n\n    Ok((container, connection_url))\n}\n\n#[tokio::test]\nasync fn test_full_integration_mcp_to_adapters() -\u003e anyhow::Result\u003c()\u003e {\n    let (_container, connection_url) = setup_postgres_container()\n        .await\n        .map_err(|e| anyhow::anyhow!(e))?;\n    let memory_manager = Arc::new(MemoryManager::new());\n    memory_manager\n        .register_provider(MemoryLayer::User, Box::new(MockProvider::new()))\n        .await;\n\n    let knowledge_repo = Arc::new(MockKnowledgeRepo);\n    let sync_manager = Arc::new(\n        SyncManager::new(\n            memory_manager.clone(),\n            knowledge_repo.clone(),\n            Arc::new(knowledge::governance::GovernanceEngine::new()),\n            config::config::DeploymentConfig::default(),\n            None,\n            Arc::new(MockPersister),\n        )\n        .await\n        .map_err(|e| anyhow::anyhow!(e.to_string()))?,\n    );\n\n    let server = Arc::new(McpServer::new(\n        memory_manager,\n        sync_manager,\n        knowledge_repo.clone(),\n        Arc::new(\n            storage::postgres::PostgresBackend::new(\u0026connection_url)\n                .await\n                .map_err(|e| anyhow::anyhow!(e.to_string()))?,\n        ),\n        Arc::new(knowledge::governance::GovernanceEngine::new()),\n        Arc::new(MockAuthService),\n        None,\n    ));\n\n    let opencode = OpenCodeAdapter::new(server.clone());\n    let memory_tools = opencode.get_memory_tools();\n    assert!(!memory_tools.is_empty());\n\n    let langchain = LangChainAdapter::new(server.clone());\n    let lc_tools = langchain.to_langchain_tools();\n    assert_eq!(lc_tools.len(), 15); // 4 memory + 3 knowledge + 3 sync + 5 governance\n\n    let response = langchain\n        .handle_mcp_request(json!({\n            \"tenantContext\": {\n                \"tenant_id\": \"c1\",\n                \"user_id\": \"u1\"\n            },\n            \"name\": \"memory_add\",\n            \"arguments\": {\n                \"content\": \"Integrated test\",\n                \"layer\": \"user\"\n            }\n        }))\n        .await?;\n\n    if let Some(error) = response[\"error\"].as_object() {\n        panic!(\"Tool call failed: {:?}\", error);\n    }\n    assert!(!response[\"result\"].is_null());\n\n    Ok(())\n}\n\n#[tokio::test]\nasync fn test_server_timeout() -\u003e anyhow::Result\u003c()\u003e {\n    let (_container, connection_url) = setup_postgres_container()\n        .await\n        .map_err(|e| anyhow::anyhow!(e))?;\n    let memory_manager = Arc::new(MemoryManager::new());\n    let knowledge_repo = Arc::new(MockKnowledgeRepo);\n    let sync_manager = Arc::new(\n        SyncManager::new(\n            memory_manager.clone(),\n            knowledge_repo.clone(),\n            Arc::new(knowledge::governance::GovernanceEngine::new()),\n            config::config::DeploymentConfig::default(),\n            None,\n            Arc::new(MockPersister),\n        )\n        .await\n        .map_err(|e| anyhow::anyhow!(e.to_string()))?,\n    );\n\n    let _server = McpServer::new(\n        memory_manager.clone(),\n        sync_manager.clone(),\n        knowledge_repo.clone(),\n        Arc::new(\n            storage::postgres::PostgresBackend::new(\u0026connection_url)\n                .await\n                .map_err(|e| anyhow::anyhow!(e.to_string()))?,\n        ),\n        Arc::new(knowledge::governance::GovernanceEngine::new()),\n        Arc::new(MockAuthService),\n        None,\n    )\n    .with_timeout(std::time::Duration::from_millis(1));\n\n    struct DenyAuthService;\n    #[async_trait]\n    impl mk_core::traits::AuthorizationService for DenyAuthService {\n        type Error = anyhow::Error;\n        async fn check_permission(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n            _action: \u0026str,\n            _resource: \u0026str,\n        ) -\u003e anyhow::Result\u003cbool\u003e {\n            Ok(false)\n        }\n        async fn get_user_roles(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n        ) -\u003e anyhow::Result\u003cVec\u003cmk_core::types::Role\u003e\u003e {\n            Ok(vec![])\n        }\n        async fn assign_role(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n            _user_id: \u0026mk_core::types::UserId,\n            _role: mk_core::types::Role,\n        ) -\u003e anyhow::Result\u003c()\u003e {\n            Ok(())\n        }\n        async fn remove_role(\n            \u0026self,\n            _ctx: \u0026mk_core::types::TenantContext,\n            _user_id: \u0026mk_core::types::UserId,\n            _role: mk_core::types::Role,\n        ) -\u003e anyhow::Result\u003c()\u003e {\n            Ok(())\n        }\n    }\n\n    let server = McpServer::new(\n        memory_manager.clone(),\n        sync_manager.clone(),\n        knowledge_repo.clone(),\n        Arc::new(\n            storage::postgres::PostgresBackend::new(\u0026connection_url)\n                .await\n                .map_err(|e| anyhow::anyhow!(e.to_string()))?,\n        ),\n        Arc::new(knowledge::governance::GovernanceEngine::new()),\n        Arc::new(DenyAuthService),\n        None,\n    );\n\n    let request = JsonRpcRequest {\n        jsonrpc: \"2.0\".to_string(),\n        id: json!(1),\n        method: \"tools/call\".to_string(),\n        params: Some(json!({\n            \"tenantContext\": {\n                \"tenant_id\": \"c1\",\n                \"user_id\": \"u1\"\n            },\n            \"name\": \"memory_search\",\n            \"arguments\": {\n                \"query\": \"test\"\n            }\n        })),\n    };\n\n    let response = server.handle_request(request).await;\n\n    assert!(response.error.is_some());\n    let error = response.error.unwrap();\n    assert_eq!(error.code, -32002);\n    assert!(error.message.contains(\"Authorization error\"));\n\n    Ok(())\n}\n","traces":[{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":2}},{"line":148,"address":[],"length":0,"stats":{"Line":6}},{"line":153,"address":[],"length":0,"stats":{"Line":2}},{"line":154,"address":[],"length":0,"stats":{"Line":2}},{"line":156,"address":[],"length":0,"stats":{"Line":4}},{"line":158,"address":[],"length":0,"stats":{"Line":2}},{"line":159,"address":[],"length":0,"stats":{"Line":2}},{"line":160,"address":[],"length":0,"stats":{"Line":2}},{"line":161,"address":[],"length":0,"stats":{"Line":2}},{"line":164,"address":[],"length":0,"stats":{"Line":2}}],"covered":10,"coverable":12},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","tests","knowledge_lifecycle.rs"],"content":"use async_trait::async_trait;\nuse knowledge::repository::GitRepository;\nuse memory::manager::MemoryManager;\nuse memory::providers::MockProvider;\nuse mk_core::traits::{KnowledgeRepository, StorageBackend};\nuse mk_core::types::{KnowledgeEntry, KnowledgeLayer, KnowledgeStatus, KnowledgeType, MemoryLayer};\nuse serde_json::json;\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse sync::bridge::SyncManager;\nuse sync::state_persister::DatabasePersister;\nuse testcontainers::runners::AsyncRunner;\nuse tokio::sync::RwLock;\nuse tools::server::{JsonRpcRequest, McpServer};\n\nstruct MockStorage {\n    data: Arc\u003cRwLock\u003cHashMap\u003cString, Vec\u003cu8\u003e\u003e\u003e\u003e,\n}\n\nimpl MockStorage {\n    fn new() -\u003e Self {\n        Self {\n            data: Arc::new(RwLock::new(HashMap::new())),\n        }\n    }\n}\n\n#[async_trait]\nimpl StorageBackend for MockStorage {\n    type Error = std::io::Error;\n\n    async fn store(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        key: \u0026str,\n        value: \u0026[u8],\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        self.data\n            .write()\n            .await\n            .insert(key.to_string(), value.to_vec());\n        Ok(())\n    }\n\n    async fn retrieve(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        key: \u0026str,\n    ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e {\n        Ok(self.data.read().await.get(key).cloned())\n    }\n\n    async fn delete(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        key: \u0026str,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        self.data.write().await.remove(key);\n        Ok(())\n    }\n\n    async fn exists(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        key: \u0026str,\n    ) -\u003e Result\u003cbool, Self::Error\u003e {\n        Ok(self.data.read().await.contains_key(key))\n    }\n\n    async fn get_ancestors(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn get_descendants(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn get_unit_policies(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::Policy\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn create_unit(\n        \u0026self,\n        _unit: \u0026mk_core::types::OrganizationalUnit,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn add_unit_policy(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _unit_id: \u0026str,\n        _policy: \u0026mk_core::types::Policy,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn assign_role(\n        \u0026self,\n        _user_id: \u0026mk_core::types::UserId,\n        _tenant_id: \u0026mk_core::types::TenantId,\n        _unit_id: \u0026str,\n        _role: mk_core::types::Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn remove_role(\n        \u0026self,\n        _user_id: \u0026mk_core::types::UserId,\n        _tenant_id: \u0026mk_core::types::TenantId,\n        _unit_id: \u0026str,\n        _role: mk_core::types::Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn store_drift_result(\n        \u0026self,\n        _result: mk_core::types::DriftResult,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn get_latest_drift_result(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _project_id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cmk_core::types::DriftResult\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n\n    async fn list_all_units(\u0026self) -\u003e Result\u003cVec\u003cmk_core::types::OrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n\n    async fn record_job_status(\n        \u0026self,\n        _job_name: \u0026str,\n        _tenant_id: \u0026str,\n        _status: \u0026str,\n        _message: Option\u003c\u0026str\u003e,\n        _started_at: i64,\n        _finished_at: Option\u003ci64\u003e,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n\n    async fn get_governance_events(\n        \u0026self,\n        _ctx: mk_core::types::TenantContext,\n        _since_timestamp: i64,\n        _limit: usize,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e, Self::Error\u003e {\n        Ok(Vec::new())\n    }\n}\n\nstruct MockAuthService;\n#[async_trait]\nimpl mk_core::traits::AuthorizationService for MockAuthService {\n    type Error = anyhow::Error;\n    async fn check_permission(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _action: \u0026str,\n        _resource: \u0026str,\n    ) -\u003e anyhow::Result\u003cbool\u003e {\n        Ok(true)\n    }\n    async fn get_user_roles(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n    ) -\u003e anyhow::Result\u003cVec\u003cmk_core::types::Role\u003e\u003e {\n        Ok(vec![])\n    }\n    async fn assign_role(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _user_id: \u0026mk_core::types::UserId,\n        _role: mk_core::types::Role,\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n    async fn remove_role(\n        \u0026self,\n        _ctx: \u0026mk_core::types::TenantContext,\n        _user_id: \u0026mk_core::types::UserId,\n        _role: mk_core::types::Role,\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n}\n\nasync fn setup_postgres_container() -\u003e Result\u003c\n    (\n        testcontainers::ContainerAsync\u003ctestcontainers_modules::postgres::Postgres\u003e,\n        String,\n    ),\n    Box\u003cdyn std::error::Error + Send + Sync\u003e,\n\u003e {\n    let container = testcontainers_modules::postgres::Postgres::default()\n        .with_db_name(\"testdb\")\n        .with_user(\"testuser\")\n        .with_password(\"testpass\")\n        .start()\n        .await\n        .map_err(|e| Box::new(e) as Box\u003cdyn std::error::Error + Send + Sync\u003e)?;\n\n    let connection_url = format!(\n        \"postgres://testuser:testpass@localhost:{}/testdb?sslmode=disable\",\n        container\n            .get_host_port_ipv4(5432)\n            .await\n            .map_err(|e| Box::new(e) as Box\u003cdyn std::error::Error + Send + Sync\u003e)?\n    );\n\n    Ok((container, connection_url))\n}\n\n#[tokio::test]\nasync fn test_knowledge_lifecycle_integration() -\u003e anyhow::Result\u003c()\u003e {\n    let (_container, connection_url) = setup_postgres_container()\n        .await\n        .map_err(|e| anyhow::anyhow!(e))?;\n    let temp_dir = tempfile::tempdir()?;\n    let repo_path = temp_dir.path().join(\"repo\");\n    let repo = Arc::new(GitRepository::new(\u0026repo_path)?);\n\n    let memory_manager = Arc::new(MemoryManager::new());\n    let mock_provider = MockProvider::new();\n    memory_manager\n        .register_provider(MemoryLayer::Project, Box::new(mock_provider))\n        .await;\n\n    let storage = Arc::new(MockStorage::new());\n    let persister = Arc::new(DatabasePersister::new(storage, \"sync_key\".to_string()));\n\n    let sync_manager = Arc::new(\n        SyncManager::new(\n            memory_manager.clone(),\n            repo.clone(),\n            Arc::new(knowledge::governance::GovernanceEngine::new()),\n            config::config::DeploymentConfig::default(),\n            None,\n            persister,\n        )\n        .await\n        .map_err(|e| anyhow::anyhow!(e))?,\n    );\n\n    let server = McpServer::new(\n        memory_manager,\n        sync_manager,\n        repo.clone(),\n        Arc::new(\n            storage::postgres::PostgresBackend::new(\u0026connection_url)\n                .await\n                .map_err(|e| anyhow::anyhow!(e.to_string()))?,\n        ),\n        Arc::new(knowledge::governance::GovernanceEngine::new()),\n        Arc::new(MockAuthService),\n        None,\n    );\n\n    // GIVEN a knowledge entry is stored in the repository\n    let entry = KnowledgeEntry {\n        path: \"specs/auth.md\".to_string(),\n        content: \"Auth spec content\".to_string(),\n        layer: KnowledgeLayer::Project,\n        kind: KnowledgeType::Spec,\n        metadata: HashMap::new(),\n        status: KnowledgeStatus::Accepted,\n        commit_hash: None,\n        author: None,\n        updated_at: chrono::Utc::now().timestamp(),\n    };\n    let tenant_id = mk_core::types::TenantId::new(\"t1\".into()).unwrap();\n    let user_id = mk_core::types::UserId::new(\"u1\".into()).unwrap();\n    let ctx = mk_core::types::TenantContext::new(tenant_id, user_id);\n\n    repo.store(ctx.clone(), entry, \"add auth spec\").await?;\n\n    // WHEN we query knowledge via MCP tool\n    let request = JsonRpcRequest {\n        jsonrpc: \"2.0\".to_string(),\n        id: json!(1),\n        method: \"tools/call\".to_string(),\n        params: Some(json!({\n            \"tenantContext\": {\n                \"tenant_id\": \"t1\",\n                \"user_id\": \"u1\"\n            },\n            \"name\": \"knowledge_query\",\n            \"arguments\": {\n                \"query\": \"Auth\",\n                \"layers\": [\"project\"]\n            }\n        })),\n    };\n\n    let response = server.handle_request(request).await;\n\n    // THEN the query should return the entry\n    assert!(\n        response.error.is_none(),\n        \"Response should not have error: {:?}\",\n        response.error\n    );\n    let result = response.result.unwrap();\n    assert!(result[\"success\"].as_bool().unwrap());\n    assert_eq!(result[\"results\"][\"keyword\"].as_array().unwrap().len(), 1);\n\n    // WHEN we fetch the specific entry via MCP tool\n    let request = JsonRpcRequest {\n        jsonrpc: \"2.0\".to_string(),\n        id: json!(2),\n        method: \"tools/call\".to_string(),\n        params: Some(json!({\n            \"tenantContext\": {\n                \"tenant_id\": \"t1\",\n                \"user_id\": \"u1\"\n            },\n            \"name\": \"knowledge_get\",\n            \"arguments\": {\n                \"path\": \"specs/auth.md\",\n                \"layer\": \"project\"\n            }\n        })),\n    };\n\n    let response = server.handle_request(request).await;\n\n    // THEN the entry content should match\n    assert!(response.error.is_none());\n    let result = response.result.unwrap();\n    assert!(result[\"success\"].as_bool().unwrap());\n    assert_eq!(result[\"entry\"][\"content\"], \"Auth spec content\");\n\n    Ok(())\n}\n","traces":[{"line":21,"address":[],"length":0,"stats":{"Line":1}},{"line":23,"address":[],"length":0,"stats":{"Line":2}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":207,"address":[],"length":0,"stats":{"Line":1}},{"line":214,"address":[],"length":0,"stats":{"Line":3}},{"line":219,"address":[],"length":0,"stats":{"Line":1}},{"line":220,"address":[],"length":0,"stats":{"Line":1}},{"line":222,"address":[],"length":0,"stats":{"Line":2}},{"line":224,"address":[],"length":0,"stats":{"Line":1}},{"line":225,"address":[],"length":0,"stats":{"Line":1}},{"line":226,"address":[],"length":0,"stats":{"Line":1}},{"line":227,"address":[],"length":0,"stats":{"Line":1}},{"line":230,"address":[],"length":0,"stats":{"Line":1}}],"covered":12,"coverable":13},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","tests","knowledge_tools.rs"],"content":"use knowledge::repository::GitRepository;\nuse memory::manager::MemoryManager;\nuse mk_core::types::{KnowledgeEntry, KnowledgeLayer, KnowledgeStatus, KnowledgeType};\nuse serde_json::json;\nuse std::sync::Arc;\nuse tempfile::tempdir;\nuse tools::knowledge::{KnowledgeGetTool, KnowledgeQueryTool};\nuse tools::tools::Tool;\n\n#[tokio::test]\nasync fn test_knowledge_tools() -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    // GIVEN a GitRepository and tools\n    let dir = tempdir()?;\n    let repo = Arc::new(GitRepository::new(dir.path())?);\n    let memory_manager = Arc::new(MemoryManager::new());\n\n    let query_tool = KnowledgeQueryTool::new(memory_manager, repo.clone());\n    let show_tool = KnowledgeGetTool::new(repo.clone());\n\n    // AND some existing knowledge\n    let entry = KnowledgeEntry {\n        path: \"architecture/core.md\".to_string(),\n        content: \"# Core Architecture\\nHierarchical memory system.\".to_string(),\n        layer: KnowledgeLayer::Project,\n        kind: KnowledgeType::Spec,\n        metadata: std::collections::HashMap::new(),\n        status: KnowledgeStatus::Accepted,\n        commit_hash: None,\n        author: None,\n        updated_at: chrono::Utc::now().timestamp(),\n    };\n    let tenant_id = mk_core::types::TenantId::new(\"t1\".into()).unwrap();\n    let user_id = mk_core::types::UserId::new(\"u1\".into()).unwrap();\n    let ctx = mk_core::types::TenantContext::new(tenant_id, user_id);\n\n    mk_core::traits::KnowledgeRepository::store(repo.as_ref(), ctx, entry, \"initial docs\").await?;\n\n    // WHEN querying knowledge\n    let query_resp = query_tool\n        .call(json!({\n            \"tenantContext\": {\n                \"tenant_id\": \"t1\",\n                \"user_id\": \"u1\"\n            },\n            \"query\": \"Architecture\",\n            \"layers\": [\"project\"]\n        }))\n        .await?;\n\n    // THEN it should find the entry\n    assert!(query_resp[\"success\"].as_bool().unwrap());\n    assert!(query_resp[\"results\"][\"keyword\"].as_array().unwrap().len() \u003e= 1);\n    assert_eq!(\n        query_resp[\"results\"][\"keyword\"][0][\"path\"],\n        \"architecture/core.md\"\n    );\n\n    // WHEN showing specific knowledge\n    let show_resp = show_tool\n        .call(json!({\n            \"tenantContext\": {\n                \"tenant_id\": \"t1\",\n                \"user_id\": \"u1\"\n            },\n            \"layer\": \"project\",\n            \"path\": \"architecture/core.md\"\n        }))\n        .await?;\n\n    // THEN it should return the full content\n    assert!(show_resp[\"success\"].as_bool().unwrap());\n    assert_eq!(\n        show_resp[\"entry\"][\"content\"],\n        \"# Core Architecture\\nHierarchical memory system.\"\n    );\n\n    Ok(())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","tests","memory_tools.rs"],"content":"use memory::manager::MemoryManager;\nuse memory::providers::MockProvider;\nuse mk_core::types::MemoryLayer;\nuse serde_json::json;\nuse std::sync::Arc;\nuse tools::memory::{MemoryAddTool, MemoryDeleteTool, MemorySearchTool};\nuse tools::tools::Tool;\n\n#[tokio::test]\nasync fn test_memory_tools() -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    // GIVEN a MemoryManager and tools\n    let memory_manager = Arc::new(\n        MemoryManager::new()\n            .with_embedding_service(Arc::new(memory::embedding::MockEmbeddingService::new(1536))),\n    );\n    memory_manager\n        .register_provider(MemoryLayer::User, Box::new(MockProvider::new()))\n        .await;\n\n    let add_tool = MemoryAddTool::new(memory_manager.clone());\n    let search_tool = MemorySearchTool::new(memory_manager.clone());\n    let delete_tool = MemoryDeleteTool::new(memory_manager.clone());\n\n    let tenant_context = json!({\n        \"tenant_id\": \"test-tenant\",\n        \"user_id\": \"test-user\"\n    });\n\n    // WHEN adding memory\n    let add_resp = add_tool\n        .call(json!({\n            \"content\": \"User prefers Rust\",\n            \"layer\": \"user\",\n            \"identifiers\": {\n                \"user_id\": \"test_user_123\"\n            },\n            \"tags\": [\"coding\"],\n            \"tenantContext\": tenant_context\n        }))\n        .await?;\n\n    // THEN it should succeed\n    assert!(add_resp[\"success\"].as_bool().unwrap());\n    let memory_id = add_resp[\"memoryId\"].as_str().unwrap().to_string();\n\n    // WHEN searching memory\n    let search_resp = search_tool\n        .call(json!({\n            \"query\": \"rust\",\n            \"tenantContext\": tenant_context\n        }))\n        .await?;\n\n    // THEN it should find the entry\n    assert!(search_resp[\"success\"].as_bool().unwrap());\n    assert_eq!(search_resp[\"totalCount\"], 1);\n    assert_eq!(search_resp[\"results\"][0][\"content\"], \"User prefers Rust\");\n\n    // WHEN deleting memory\n    let delete_resp = delete_tool\n        .call(json!({\n            \"memory_id\": memory_id,\n            \"layer\": \"user\",\n            \"tenantContext\": tenant_context\n        }))\n        .await?;\n\n    // THEN it should succeed\n    assert!(delete_resp[\"success\"].as_bool().unwrap());\n\n    // AND search should return empty\n    let search_resp = search_tool\n        .call(json!({\n            \"query\": \"rust\",\n            \"tenantContext\": tenant_context\n        }))\n        .await?;\n    assert_eq!(search_resp[\"totalCount\"], 0);\n\n    Ok(())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","christian.klat","dev","git","aeterna","tools","tests","tenant_isolation_e2e.rs"],"content":"use async_trait::async_trait;\nuse knowledge::repository::GitRepository;\nuse memory::providers::MockProvider;\nuse mk_core::traits::{AuthorizationService, KnowledgeRepository, StorageBackend};\nuse mk_core::types::{\n    KnowledgeEntry, KnowledgeLayer, KnowledgeType, OrganizationalUnit, Policy, Role, TenantContext,\n    TenantId, UserId,\n};\nuse serde_json::json;\nuse std::sync::Arc;\nuse tempfile::tempdir;\nuse tools::server::{JsonRpcRequest, McpServer};\n\nstruct MockAuthService;\n\n#[async_trait]\nimpl AuthorizationService for MockAuthService {\n    type Error = anyhow::Error;\n\n    async fn check_permission(\n        \u0026self,\n        ctx: \u0026TenantContext,\n        _action: \u0026str,\n        _resource: \u0026str,\n    ) -\u003e anyhow::Result\u003cbool\u003e {\n        let tenant_id = ctx.tenant_id.as_str();\n        let user_id = ctx.user_id.as_str();\n\n        // Strict isolation for test\n        if (tenant_id == \"t1\" \u0026\u0026 user_id == \"u1\") || (tenant_id == \"t2\" \u0026\u0026 user_id == \"u2\") {\n            Ok(true)\n        } else {\n            Ok(false)\n        }\n    }\n\n    async fn get_user_roles(\u0026self, _ctx: \u0026TenantContext) -\u003e anyhow::Result\u003cVec\u003cRole\u003e\u003e {\n        Ok(vec![])\n    }\n    async fn assign_role(\n        \u0026self,\n        _ctx: \u0026TenantContext,\n        _user_id: \u0026UserId,\n        _role: Role,\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n    async fn remove_role(\n        \u0026self,\n        _ctx: \u0026TenantContext,\n        _user_id: \u0026UserId,\n        _role: Role,\n    ) -\u003e anyhow::Result\u003c()\u003e {\n        Ok(())\n    }\n}\n\nstruct MockStorage;\n\n#[async_trait]\nimpl StorageBackend for MockStorage {\n    type Error = storage::postgres::PostgresError;\n\n    async fn store(\n        \u0026self,\n        _ctx: TenantContext,\n        _key: \u0026str,\n        _value: \u0026[u8],\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn retrieve(\n        \u0026self,\n        _ctx: TenantContext,\n        _key: \u0026str,\n    ) -\u003e Result\u003cOption\u003cVec\u003cu8\u003e\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n    async fn delete(\u0026self, _ctx: TenantContext, _key: \u0026str) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn exists(\u0026self, _ctx: TenantContext, _key: \u0026str) -\u003e Result\u003cbool, Self::Error\u003e {\n        Ok(false)\n    }\n    async fn get_ancestors(\n        \u0026self,\n        _ctx: TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n    async fn get_descendants(\n        \u0026self,\n        _ctx: TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n    async fn get_unit_policies(\n        \u0026self,\n        _ctx: TenantContext,\n        _unit_id: \u0026str,\n    ) -\u003e Result\u003cVec\u003cPolicy\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n    async fn create_unit(\u0026self, _unit: \u0026OrganizationalUnit) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn add_unit_policy(\n        \u0026self,\n        _ctx: \u0026TenantContext,\n        _unit_id: \u0026str,\n        _policy: \u0026Policy,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn assign_role(\n        \u0026self,\n        _user_id: \u0026UserId,\n        _tenant_id: \u0026TenantId,\n        _unit_id: \u0026str,\n        _role: Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn remove_role(\n        \u0026self,\n        _user_id: \u0026UserId,\n        _tenant_id: \u0026TenantId,\n        _unit_id: \u0026str,\n        _role: Role,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn store_drift_result(\n        \u0026self,\n        _result: mk_core::types::DriftResult,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn get_latest_drift_result(\n        \u0026self,\n        _ctx: TenantContext,\n        _project_id: \u0026str,\n    ) -\u003e Result\u003cOption\u003cmk_core::types::DriftResult\u003e, Self::Error\u003e {\n        Ok(None)\n    }\n    async fn list_all_units(\u0026self) -\u003e Result\u003cVec\u003cOrganizationalUnit\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n    async fn record_job_status(\n        \u0026self,\n        _job_name: \u0026str,\n        _tenant_id: \u0026str,\n        _status: \u0026str,\n        _message: Option\u003c\u0026str\u003e,\n        _started_at: i64,\n        _finished_at: Option\u003ci64\u003e,\n    ) -\u003e Result\u003c(), Self::Error\u003e {\n        Ok(())\n    }\n    async fn get_governance_events(\n        \u0026self,\n        _ctx: TenantContext,\n        _since_timestamp: i64,\n        _limit: usize,\n    ) -\u003e Result\u003cVec\u003cmk_core::types::GovernanceEvent\u003e, Self::Error\u003e {\n        Ok(vec![])\n    }\n}\n\nstruct MockPersister;\n#[async_trait]\nimpl sync::state_persister::SyncStatePersister for MockPersister {\n    async fn load(\n        \u0026self,\n        _tenant_id: \u0026TenantId,\n    ) -\u003e Result\u003csync::state::SyncState, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        Ok(sync::state::SyncState::default())\n    }\n    async fn save(\n        \u0026self,\n        _tenant_id: \u0026TenantId,\n        _state: \u0026sync::state::SyncState,\n    ) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n        Ok(())\n    }\n}\n\n#[tokio::test]\nasync fn test_tenant_isolation_e2e() -\u003e anyhow::Result\u003c()\u003e {\n    // 1. Setup Environment\n    let dir = tempdir()?;\n    let repo = Arc::new(GitRepository::new(dir.path())?);\n    let memory_manager = Arc::new(memory::manager::MemoryManager::new());\n    memory_manager\n        .register_provider(\n            mk_core::types::MemoryLayer::User,\n            Box::new(MockProvider::new()),\n        )\n        .await;\n\n    let governance_engine = Arc::new(knowledge::governance::GovernanceEngine::new());\n\n    let auth_service = Arc::new(MockAuthService);\n    let storage_backend = Arc::new(MockStorage);\n\n    let sync_manager = Arc::new(\n        sync::bridge::SyncManager::new(\n            memory_manager.clone(),\n            repo.clone(),\n            governance_engine.clone(),\n            config::config::DeploymentConfig::default(),\n            None,\n            Arc::new(MockPersister),\n        )\n        .await\n        .map_err(|e| anyhow::anyhow!(e.to_string()))?,\n    );\n\n    let server = McpServer::new(\n        memory_manager,\n        sync_manager,\n        repo,\n        storage_backend,\n        governance_engine,\n        auth_service,\n        None,\n    );\n\n    // 2. Test Success: User u1 calling tool with Tenant t1\n    let success_request = JsonRpcRequest {\n        jsonrpc: \"2.0\".to_string(),\n        id: json!(1),\n        method: \"tools/call\".to_string(),\n        params: Some(json!({\n            \"tenantContext\": {\n                \"tenant_id\": \"t1\",\n                \"user_id\": \"u1\"\n            },\n            \"name\": \"memory_add\",\n            \"arguments\": {\n                \"content\": \"Secret for t1\",\n                \"layer\": \"user\"\n            }\n        })),\n    };\n\n    let response = server.handle_request(success_request).await;\n    assert!(\n        response.error.is_none(),\n        \"Should succeed for authorized user: {:?}\",\n        response.error\n    );\n\n    // 3. Test Failure: User u1 calling tool with Tenant t2 (Cross-tenant attempt)\n    let failure_request = JsonRpcRequest {\n        jsonrpc: \"2.0\".to_string(),\n        id: json!(2),\n        method: \"tools/call\".to_string(),\n        params: Some(json!({\n            \"tenantContext\": {\n                \"tenant_id\": \"t2\",\n                \"user_id\": \"u1\"\n            },\n            \"name\": \"memory_add\",\n            \"arguments\": {\n                \"content\": \"Attempted breach\",\n                \"layer\": \"user\"\n            }\n        })),\n    };\n\n    let response = server.handle_request(failure_request).await;\n    assert!(\n        response.error.is_some(),\n        \"Should fail for cross-tenant access\"\n    );\n    let error = response.error.unwrap();\n    assert_eq!(error.code, -32002); // Authorization error code\n    assert!(error.message.contains(\"Authorization error\"));\n\n    Ok(())\n}\n","traces":[{"line":37,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":5},{"path":["/","Users","christian.klat","dev","git","aeterna","utils","src","lib.rs"],"content":"//! # Memory-Knowledge Utilities\n//!\n//! Common utility functions for hashing, validation, and UUID generation.\n//!\n//! # Best Practices\n//!\n//! - Uses SHA-2 for secure hashing\n//! - Uses UUID v4 with serde support\n//! - Validates inputs with comprehensive error messages\n\nuse sha2::{Digest, Sha256};\nuse uuid::Uuid;\n\n/// Compute SHA-256 hash of content string\n///\n/// # Examples\n///\n/// ```\n/// use utils::compute_content_hash;\n///\n/// let hash = compute_content_hash(\"hello world\");\n/// assert_eq!(hash.len(), 64);\n/// ```\n#[must_use]\npub fn compute_content_hash(content: \u0026str) -\u003e String {\n    let mut hasher = Sha256::new();\n    hasher.update(content.as_bytes());\n    format!(\"{:x}\", hasher.finalize())\n}\n\n/// Compute hash of knowledge item for change detection\n///\n/// Hashes content, constraints, and status fields.\n#[must_use]\npub fn compute_knowledge_hash(item: \u0026serde_json::Value) -\u003e String {\n    let mut hasher = Sha256::new();\n\n    // Extract fields for hashing\n    if let Some(content_str) = item.get(\"content\").and_then(|c| c.as_str()) {\n        hasher.update(content_str.as_bytes());\n    }\n\n    if let Some(constraints) = item.get(\"constraints\") {\n        let constraints_json =\n            serde_json::to_string(constraints).expect(\"Failed to serialize constraints\");\n        hasher.update(constraints_json.as_bytes());\n    }\n\n    if let Some(status_str) = item.get(\"status\").and_then(|s| s.as_str()) {\n        hasher.update(status_str.as_bytes());\n    }\n\n    format!(\"{:x}\", hasher.finalize())\n}\n\n/// Generate UUID v4 string\n#[must_use]\npub fn generate_uuid() -\u003e String {\n    Uuid::new_v4().to_string()\n}\n\n/// Validate memory layer string\n#[must_use]\npub fn is_valid_layer(layer: \u0026str) -\u003e bool {\n    matches!(\n        layer,\n        \"agent\" | \"user\" | \"session\" | \"project\" | \"team\" | \"org\" | \"company\"\n    )\n}\n\n/// Validate knowledge type string\n#[must_use]\npub fn is_valid_knowledge_type(ktype: \u0026str) -\u003e bool {\n    matches!(ktype, \"adr\" | \"policy\" | \"pattern\" | \"spec\")\n}\n\n/// Validate knowledge layer string\n#[must_use]\npub fn is_valid_knowledge_layer(layer: \u0026str) -\u003e bool {\n    matches!(layer, \"company\" | \"org\" | \"team\" | \"project\")\n}\n\n/// Redact PII from content string\n///\n/// Currently redacts emails and simple phone numbers.\n#[must_use]\npub fn redact_pii(content: \u0026str) -\u003e String {\n    let email_re = regex::Regex::new(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\").unwrap();\n    let result = email_re.replace_all(content, \"[REDACTED_EMAIL]\");\n\n    let phone_re = regex::Regex::new(r\"\\d{3}-\\d{3}-\\d{4}\").unwrap();\n    phone_re\n        .replace_all(\u0026result, \"[REDACTED_PHONE]\")\n        .to_string()\n}\n\n/// Get layer precedence value for memory layers\n#[must_use]\npub fn get_layer_precedence(layer: \u0026str) -\u003e u8 {\n    match layer {\n        \"agent\" =\u003e 1,\n        \"user\" =\u003e 2,\n        \"session\" =\u003e 3,\n        \"project\" =\u003e 4,\n        \"team\" =\u003e 5,\n        \"org\" =\u003e 6,\n        \"company\" =\u003e 7,\n        _ =\u003e 7 // Default to lowest precedence\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_compute_content_hash_consistency() {\n        let content = \"test content\";\n        let hash1 = compute_content_hash(content);\n        let hash2 = compute_content_hash(content);\n        assert_eq!(hash1, hash2);\n    }\n\n    #[test]\n    fn test_generate_uuid_uniqueness() {\n        let uuid1 = generate_uuid();\n        let uuid2 = generate_uuid();\n        assert_ne!(uuid1, uuid2);\n    }\n\n    #[test]\n    fn test_layer_validation_valid() {\n        assert!(is_valid_layer(\"agent\"));\n        assert!(is_valid_layer(\"user\"));\n        assert!(is_valid_layer(\"company\"));\n    }\n\n    #[test]\n    fn test_layer_validation_invalid() {\n        assert!(!is_valid_layer(\"invalid\"));\n        assert!(!is_valid_layer(\"agent-user\"));\n    }\n\n    #[test]\n    fn test_redact_pii() {\n        let content = \"Contact alice@example.com at 123-456-7890.\";\n        let redacted = redact_pii(content);\n        assert_eq!(redacted, \"Contact [REDACTED_EMAIL] at [REDACTED_PHONE].\");\n    }\n\n    #[test]\n    fn test_compute_knowledge_hash() {\n        let item = serde_json::json!({\n            \"content\": \"test content\",\n            \"status\": \"accepted\",\n            \"constraints\": [\"rule1\"]\n        });\n        let hash = compute_knowledge_hash(\u0026item);\n        assert_eq!(hash.len(), 64);\n\n        let item2 = serde_json::json!({\n            \"content\": \"test content\",\n            \"status\": \"accepted\",\n            \"constraints\": [\"rule1\"]\n        });\n        assert_eq!(hash, compute_knowledge_hash(\u0026item2));\n\n        let item3 = serde_json::json!({\n            \"content\": \"different content\",\n            \"status\": \"accepted\",\n            \"constraints\": [\"rule1\"]\n        });\n        assert_ne!(hash, compute_knowledge_hash(\u0026item3));\n    }\n\n    #[test]\n    fn test_is_valid_knowledge_type() {\n        assert!(is_valid_knowledge_type(\"adr\"));\n        assert!(is_valid_knowledge_type(\"policy\"));\n        assert!(!is_valid_knowledge_type(\"unknown\"));\n    }\n\n    #[test]\n    fn test_is_valid_knowledge_layer() {\n        assert!(is_valid_knowledge_layer(\"project\"));\n        assert!(is_valid_knowledge_layer(\"company\"));\n        assert!(!is_valid_knowledge_layer(\"user\"));\n    }\n\n    #[test]\n    fn test_get_layer_precedence() {\n        assert_eq!(get_layer_precedence(\"agent\"), 1);\n        assert_eq!(get_layer_precedence(\"company\"), 7);\n        assert_eq!(get_layer_precedence(\"unknown\"), 7);\n    }\n}\n","traces":[{"line":25,"address":[],"length":0,"stats":{"Line":3049}},{"line":26,"address":[],"length":0,"stats":{"Line":6098}},{"line":27,"address":[],"length":0,"stats":{"Line":12196}},{"line":28,"address":[],"length":0,"stats":{"Line":12196}},{"line":35,"address":[],"length":0,"stats":{"Line":3}},{"line":36,"address":[],"length":0,"stats":{"Line":6}},{"line":39,"address":[],"length":0,"stats":{"Line":21}},{"line":40,"address":[],"length":0,"stats":{"Line":9}},{"line":43,"address":[],"length":0,"stats":{"Line":9}},{"line":44,"address":[],"length":0,"stats":{"Line":6}},{"line":45,"address":[],"length":0,"stats":{"Line":15}},{"line":46,"address":[],"length":0,"stats":{"Line":9}},{"line":49,"address":[],"length":0,"stats":{"Line":21}},{"line":50,"address":[],"length":0,"stats":{"Line":9}},{"line":53,"address":[],"length":0,"stats":{"Line":12}},{"line":58,"address":[],"length":0,"stats":{"Line":2}},{"line":59,"address":[],"length":0,"stats":{"Line":4}},{"line":64,"address":[],"length":0,"stats":{"Line":5}},{"line":65,"address":[],"length":0,"stats":{"Line":3}},{"line":66,"address":[],"length":0,"stats":{"Line":5}},{"line":73,"address":[],"length":0,"stats":{"Line":3}},{"line":74,"address":[],"length":0,"stats":{"Line":12}},{"line":79,"address":[],"length":0,"stats":{"Line":3}},{"line":80,"address":[],"length":0,"stats":{"Line":14}},{"line":87,"address":[],"length":0,"stats":{"Line":2074}},{"line":88,"address":[],"length":0,"stats":{"Line":8296}},{"line":89,"address":[],"length":0,"stats":{"Line":8296}},{"line":91,"address":[],"length":0,"stats":{"Line":8296}},{"line":92,"address":[],"length":0,"stats":{"Line":4148}},{"line":93,"address":[],"length":0,"stats":{"Line":2074}},{"line":99,"address":[],"length":0,"stats":{"Line":3}},{"line":100,"address":[],"length":0,"stats":{"Line":3}},{"line":101,"address":[],"length":0,"stats":{"Line":4}},{"line":102,"address":[],"length":0,"stats":{"Line":2}},{"line":103,"address":[],"length":0,"stats":{"Line":2}},{"line":104,"address":[],"length":0,"stats":{"Line":2}},{"line":105,"address":[],"length":0,"stats":{"Line":2}},{"line":106,"address":[],"length":0,"stats":{"Line":2}},{"line":107,"address":[],"length":0,"stats":{"Line":3}},{"line":108,"address":[],"length":0,"stats":{"Line":1}}],"covered":40,"coverable":40}]};
    </script>
    <script crossorigin>/** @license React v16.13.1
 * react.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */
'use strict';(function(d,r){"object"===typeof exports&&"undefined"!==typeof module?r(exports):"function"===typeof define&&define.amd?define(["exports"],r):(d=d||self,r(d.React={}))})(this,function(d){function r(a){for(var b="https://reactjs.org/docs/error-decoder.html?invariant="+a,c=1;c<arguments.length;c++)b+="&args[]="+encodeURIComponent(arguments[c]);return"Minified React error #"+a+"; visit "+b+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}
function w(a,b,c){this.props=a;this.context=b;this.refs=ba;this.updater=c||ca}function da(){}function L(a,b,c){this.props=a;this.context=b;this.refs=ba;this.updater=c||ca}function ea(a,b,c){var g,e={},fa=null,d=null;if(null!=b)for(g in void 0!==b.ref&&(d=b.ref),void 0!==b.key&&(fa=""+b.key),b)ha.call(b,g)&&!ia.hasOwnProperty(g)&&(e[g]=b[g]);var h=arguments.length-2;if(1===h)e.children=c;else if(1<h){for(var k=Array(h),f=0;f<h;f++)k[f]=arguments[f+2];e.children=k}if(a&&a.defaultProps)for(g in h=a.defaultProps,
h)void 0===e[g]&&(e[g]=h[g]);return{$$typeof:x,type:a,key:fa,ref:d,props:e,_owner:M.current}}function va(a,b){return{$$typeof:x,type:a.type,key:b,ref:a.ref,props:a.props,_owner:a._owner}}function N(a){return"object"===typeof a&&null!==a&&a.$$typeof===x}function wa(a){var b={"=":"=0",":":"=2"};return"$"+(""+a).replace(/[=:]/g,function(a){return b[a]})}function ja(a,b,c,g){if(C.length){var e=C.pop();e.result=a;e.keyPrefix=b;e.func=c;e.context=g;e.count=0;return e}return{result:a,keyPrefix:b,func:c,
context:g,count:0}}function ka(a){a.result=null;a.keyPrefix=null;a.func=null;a.context=null;a.count=0;10>C.length&&C.push(a)}function O(a,b,c,g){var e=typeof a;if("undefined"===e||"boolean"===e)a=null;var d=!1;if(null===a)d=!0;else switch(e){case "string":case "number":d=!0;break;case "object":switch(a.$$typeof){case x:case xa:d=!0}}if(d)return c(g,a,""===b?"."+P(a,0):b),1;d=0;b=""===b?".":b+":";if(Array.isArray(a))for(var f=0;f<a.length;f++){e=a[f];var h=b+P(e,f);d+=O(e,h,c,g)}else if(null===a||
"object"!==typeof a?h=null:(h=la&&a[la]||a["@@iterator"],h="function"===typeof h?h:null),"function"===typeof h)for(a=h.call(a),f=0;!(e=a.next()).done;)e=e.value,h=b+P(e,f++),d+=O(e,h,c,g);else if("object"===e)throw c=""+a,Error(r(31,"[object Object]"===c?"object with keys {"+Object.keys(a).join(", ")+"}":c,""));return d}function Q(a,b,c){return null==a?0:O(a,"",b,c)}function P(a,b){return"object"===typeof a&&null!==a&&null!=a.key?wa(a.key):b.toString(36)}function ya(a,b,c){a.func.call(a.context,b,
a.count++)}function za(a,b,c){var g=a.result,e=a.keyPrefix;a=a.func.call(a.context,b,a.count++);Array.isArray(a)?R(a,g,c,function(a){return a}):null!=a&&(N(a)&&(a=va(a,e+(!a.key||b&&b.key===a.key?"":(""+a.key).replace(ma,"$&/")+"/")+c)),g.push(a))}function R(a,b,c,g,e){var d="";null!=c&&(d=(""+c).replace(ma,"$&/")+"/");b=ja(b,d,g,e);Q(a,za,b);ka(b)}function t(){var a=na.current;if(null===a)throw Error(r(321));return a}function S(a,b){var c=a.length;a.push(b);a:for(;;){var g=c-1>>>1,e=a[g];if(void 0!==
e&&0<D(e,b))a[g]=b,a[c]=e,c=g;else break a}}function n(a){a=a[0];return void 0===a?null:a}function E(a){var b=a[0];if(void 0!==b){var c=a.pop();if(c!==b){a[0]=c;a:for(var g=0,e=a.length;g<e;){var d=2*(g+1)-1,f=a[d],h=d+1,k=a[h];if(void 0!==f&&0>D(f,c))void 0!==k&&0>D(k,f)?(a[g]=k,a[h]=c,g=h):(a[g]=f,a[d]=c,g=d);else if(void 0!==k&&0>D(k,c))a[g]=k,a[h]=c,g=h;else break a}}return b}return null}function D(a,b){var c=a.sortIndex-b.sortIndex;return 0!==c?c:a.id-b.id}function F(a){for(var b=n(u);null!==
b;){if(null===b.callback)E(u);else if(b.startTime<=a)E(u),b.sortIndex=b.expirationTime,S(p,b);else break;b=n(u)}}function T(a){y=!1;F(a);if(!v)if(null!==n(p))v=!0,z(U);else{var b=n(u);null!==b&&G(T,b.startTime-a)}}function U(a,b){v=!1;y&&(y=!1,V());H=!0;var c=m;try{F(b);for(l=n(p);null!==l&&(!(l.expirationTime>b)||a&&!W());){var g=l.callback;if(null!==g){l.callback=null;m=l.priorityLevel;var e=g(l.expirationTime<=b);b=q();"function"===typeof e?l.callback=e:l===n(p)&&E(p);F(b)}else E(p);l=n(p)}if(null!==
l)var d=!0;else{var f=n(u);null!==f&&G(T,f.startTime-b);d=!1}return d}finally{l=null,m=c,H=!1}}function oa(a){switch(a){case 1:return-1;case 2:return 250;case 5:return 1073741823;case 4:return 1E4;default:return 5E3}}var f="function"===typeof Symbol&&Symbol.for,x=f?Symbol.for("react.element"):60103,xa=f?Symbol.for("react.portal"):60106,Aa=f?Symbol.for("react.fragment"):60107,Ba=f?Symbol.for("react.strict_mode"):60108,Ca=f?Symbol.for("react.profiler"):60114,Da=f?Symbol.for("react.provider"):60109,
Ea=f?Symbol.for("react.context"):60110,Fa=f?Symbol.for("react.forward_ref"):60112,Ga=f?Symbol.for("react.suspense"):60113,Ha=f?Symbol.for("react.memo"):60115,Ia=f?Symbol.for("react.lazy"):60116,la="function"===typeof Symbol&&Symbol.iterator,pa=Object.getOwnPropertySymbols,Ja=Object.prototype.hasOwnProperty,Ka=Object.prototype.propertyIsEnumerable,I=function(){try{if(!Object.assign)return!1;var a=new String("abc");a[5]="de";if("5"===Object.getOwnPropertyNames(a)[0])return!1;var b={};for(a=0;10>a;a++)b["_"+
String.fromCharCode(a)]=a;if("0123456789"!==Object.getOwnPropertyNames(b).map(function(a){return b[a]}).join(""))return!1;var c={};"abcdefghijklmnopqrst".split("").forEach(function(a){c[a]=a});return"abcdefghijklmnopqrst"!==Object.keys(Object.assign({},c)).join("")?!1:!0}catch(g){return!1}}()?Object.assign:function(a,b){if(null===a||void 0===a)throw new TypeError("Object.assign cannot be called with null or undefined");var c=Object(a);for(var g,e=1;e<arguments.length;e++){var d=Object(arguments[e]);
for(var f in d)Ja.call(d,f)&&(c[f]=d[f]);if(pa){g=pa(d);for(var h=0;h<g.length;h++)Ka.call(d,g[h])&&(c[g[h]]=d[g[h]])}}return c},ca={isMounted:function(a){return!1},enqueueForceUpdate:function(a,b,c){},enqueueReplaceState:function(a,b,c,d){},enqueueSetState:function(a,b,c,d){}},ba={};w.prototype.isReactComponent={};w.prototype.setState=function(a,b){if("object"!==typeof a&&"function"!==typeof a&&null!=a)throw Error(r(85));this.updater.enqueueSetState(this,a,b,"setState")};w.prototype.forceUpdate=
function(a){this.updater.enqueueForceUpdate(this,a,"forceUpdate")};da.prototype=w.prototype;f=L.prototype=new da;f.constructor=L;I(f,w.prototype);f.isPureReactComponent=!0;var M={current:null},ha=Object.prototype.hasOwnProperty,ia={key:!0,ref:!0,__self:!0,__source:!0},ma=/\/+/g,C=[],na={current:null},X;if("undefined"===typeof window||"function"!==typeof MessageChannel){var A=null,qa=null,ra=function(){if(null!==A)try{var a=q();A(!0,a);A=null}catch(b){throw setTimeout(ra,0),b;}},La=Date.now();var q=
function(){return Date.now()-La};var z=function(a){null!==A?setTimeout(z,0,a):(A=a,setTimeout(ra,0))};var G=function(a,b){qa=setTimeout(a,b)};var V=function(){clearTimeout(qa)};var W=function(){return!1};f=X=function(){}}else{var Y=window.performance,sa=window.Date,Ma=window.setTimeout,Na=window.clearTimeout;"undefined"!==typeof console&&(f=window.cancelAnimationFrame,"function"!==typeof window.requestAnimationFrame&&console.error("This browser doesn't support requestAnimationFrame. Make sure that you load a polyfill in older browsers. https://fb.me/react-polyfills"),
"function"!==typeof f&&console.error("This browser doesn't support cancelAnimationFrame. Make sure that you load a polyfill in older browsers. https://fb.me/react-polyfills"));if("object"===typeof Y&&"function"===typeof Y.now)q=function(){return Y.now()};else{var Oa=sa.now();q=function(){return sa.now()-Oa}}var J=!1,K=null,Z=-1,ta=5,ua=0;W=function(){return q()>=ua};f=function(){};X=function(a){0>a||125<a?console.error("forceFrameRate takes a positive int between 0 and 125, forcing framerates higher than 125 fps is not unsupported"):
ta=0<a?Math.floor(1E3/a):5};var B=new MessageChannel,aa=B.port2;B.port1.onmessage=function(){if(null!==K){var a=q();ua=a+ta;try{K(!0,a)?aa.postMessage(null):(J=!1,K=null)}catch(b){throw aa.postMessage(null),b;}}else J=!1};z=function(a){K=a;J||(J=!0,aa.postMessage(null))};G=function(a,b){Z=Ma(function(){a(q())},b)};V=function(){Na(Z);Z=-1}}var p=[],u=[],Pa=1,l=null,m=3,H=!1,v=!1,y=!1,Qa=0;B={ReactCurrentDispatcher:na,ReactCurrentOwner:M,IsSomeRendererActing:{current:!1},assign:I};I(B,{Scheduler:{__proto__:null,
unstable_ImmediatePriority:1,unstable_UserBlockingPriority:2,unstable_NormalPriority:3,unstable_IdlePriority:5,unstable_LowPriority:4,unstable_runWithPriority:function(a,b){switch(a){case 1:case 2:case 3:case 4:case 5:break;default:a=3}var c=m;m=a;try{return b()}finally{m=c}},unstable_next:function(a){switch(m){case 1:case 2:case 3:var b=3;break;default:b=m}var c=m;m=b;try{return a()}finally{m=c}},unstable_scheduleCallback:function(a,b,c){var d=q();if("object"===typeof c&&null!==c){var e=c.delay;
e="number"===typeof e&&0<e?d+e:d;c="number"===typeof c.timeout?c.timeout:oa(a)}else c=oa(a),e=d;c=e+c;a={id:Pa++,callback:b,priorityLevel:a,startTime:e,expirationTime:c,sortIndex:-1};e>d?(a.sortIndex=e,S(u,a),null===n(p)&&a===n(u)&&(y?V():y=!0,G(T,e-d))):(a.sortIndex=c,S(p,a),v||H||(v=!0,z(U)));return a},unstable_cancelCallback:function(a){a.callback=null},unstable_wrapCallback:function(a){var b=m;return function(){var c=m;m=b;try{return a.apply(this,arguments)}finally{m=c}}},unstable_getCurrentPriorityLevel:function(){return m},
unstable_shouldYield:function(){var a=q();F(a);var b=n(p);return b!==l&&null!==l&&null!==b&&null!==b.callback&&b.startTime<=a&&b.expirationTime<l.expirationTime||W()},unstable_requestPaint:f,unstable_continueExecution:function(){v||H||(v=!0,z(U))},unstable_pauseExecution:function(){},unstable_getFirstCallbackNode:function(){return n(p)},get unstable_now(){return q},get unstable_forceFrameRate(){return X},unstable_Profiling:null},SchedulerTracing:{__proto__:null,__interactionsRef:null,__subscriberRef:null,
unstable_clear:function(a){return a()},unstable_getCurrent:function(){return null},unstable_getThreadID:function(){return++Qa},unstable_trace:function(a,b,c){return c()},unstable_wrap:function(a){return a},unstable_subscribe:function(a){},unstable_unsubscribe:function(a){}}});d.Children={map:function(a,b,c){if(null==a)return a;var d=[];R(a,d,null,b,c);return d},forEach:function(a,b,c){if(null==a)return a;b=ja(null,null,b,c);Q(a,ya,b);ka(b)},count:function(a){return Q(a,function(){return null},null)},
toArray:function(a){var b=[];R(a,b,null,function(a){return a});return b},only:function(a){if(!N(a))throw Error(r(143));return a}};d.Component=w;d.Fragment=Aa;d.Profiler=Ca;d.PureComponent=L;d.StrictMode=Ba;d.Suspense=Ga;d.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=B;d.cloneElement=function(a,b,c){if(null===a||void 0===a)throw Error(r(267,a));var d=I({},a.props),e=a.key,f=a.ref,m=a._owner;if(null!=b){void 0!==b.ref&&(f=b.ref,m=M.current);void 0!==b.key&&(e=""+b.key);if(a.type&&a.type.defaultProps)var h=
a.type.defaultProps;for(k in b)ha.call(b,k)&&!ia.hasOwnProperty(k)&&(d[k]=void 0===b[k]&&void 0!==h?h[k]:b[k])}var k=arguments.length-2;if(1===k)d.children=c;else if(1<k){h=Array(k);for(var l=0;l<k;l++)h[l]=arguments[l+2];d.children=h}return{$$typeof:x,type:a.type,key:e,ref:f,props:d,_owner:m}};d.createContext=function(a,b){void 0===b&&(b=null);a={$$typeof:Ea,_calculateChangedBits:b,_currentValue:a,_currentValue2:a,_threadCount:0,Provider:null,Consumer:null};a.Provider={$$typeof:Da,_context:a};return a.Consumer=
a};d.createElement=ea;d.createFactory=function(a){var b=ea.bind(null,a);b.type=a;return b};d.createRef=function(){return{current:null}};d.forwardRef=function(a){return{$$typeof:Fa,render:a}};d.isValidElement=N;d.lazy=function(a){return{$$typeof:Ia,_ctor:a,_status:-1,_result:null}};d.memo=function(a,b){return{$$typeof:Ha,type:a,compare:void 0===b?null:b}};d.useCallback=function(a,b){return t().useCallback(a,b)};d.useContext=function(a,b){return t().useContext(a,b)};d.useDebugValue=function(a,b){};
d.useEffect=function(a,b){return t().useEffect(a,b)};d.useImperativeHandle=function(a,b,c){return t().useImperativeHandle(a,b,c)};d.useLayoutEffect=function(a,b){return t().useLayoutEffect(a,b)};d.useMemo=function(a,b){return t().useMemo(a,b)};d.useReducer=function(a,b,c){return t().useReducer(a,b,c)};d.useRef=function(a){return t().useRef(a)};d.useState=function(a){return t().useState(a)};d.version="16.13.1"});
</script>
    <script crossorigin>/** @license React v16.13.1
 * react-dom.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */
/*
 Modernizr 3.0.0pre (Custom Build) | MIT
*/
'use strict';(function(I,ea){"object"===typeof exports&&"undefined"!==typeof module?ea(exports,require("react")):"function"===typeof define&&define.amd?define(["exports","react"],ea):(I=I||self,ea(I.ReactDOM={},I.React))})(this,function(I,ea){function k(a){for(var b="https://reactjs.org/docs/error-decoder.html?invariant="+a,c=1;c<arguments.length;c++)b+="&args[]="+encodeURIComponent(arguments[c]);return"Minified React error #"+a+"; visit "+b+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}
function ji(a,b,c,d,e,f,g,h,m){yb=!1;gc=null;ki.apply(li,arguments)}function mi(a,b,c,d,e,f,g,h,m){ji.apply(this,arguments);if(yb){if(yb){var n=gc;yb=!1;gc=null}else throw Error(k(198));hc||(hc=!0,pd=n)}}function lf(a,b,c){var d=a.type||"unknown-event";a.currentTarget=mf(c);mi(d,b,void 0,a);a.currentTarget=null}function nf(){if(ic)for(var a in cb){var b=cb[a],c=ic.indexOf(a);if(!(-1<c))throw Error(k(96,a));if(!jc[c]){if(!b.extractEvents)throw Error(k(97,a));jc[c]=b;c=b.eventTypes;for(var d in c){var e=
void 0;var f=c[d],g=b,h=d;if(qd.hasOwnProperty(h))throw Error(k(99,h));qd[h]=f;var m=f.phasedRegistrationNames;if(m){for(e in m)m.hasOwnProperty(e)&&of(m[e],g,h);e=!0}else f.registrationName?(of(f.registrationName,g,h),e=!0):e=!1;if(!e)throw Error(k(98,d,a));}}}}function of(a,b,c){if(db[a])throw Error(k(100,a));db[a]=b;rd[a]=b.eventTypes[c].dependencies}function pf(a){var b=!1,c;for(c in a)if(a.hasOwnProperty(c)){var d=a[c];if(!cb.hasOwnProperty(c)||cb[c]!==d){if(cb[c])throw Error(k(102,c));cb[c]=
d;b=!0}}b&&nf()}function qf(a){if(a=rf(a)){if("function"!==typeof sd)throw Error(k(280));var b=a.stateNode;b&&(b=td(b),sd(a.stateNode,a.type,b))}}function sf(a){eb?fb?fb.push(a):fb=[a]:eb=a}function tf(){if(eb){var a=eb,b=fb;fb=eb=null;qf(a);if(b)for(a=0;a<b.length;a++)qf(b[a])}}function ud(){if(null!==eb||null!==fb)vd(),tf()}function uf(a,b,c){if(wd)return a(b,c);wd=!0;try{return vf(a,b,c)}finally{wd=!1,ud()}}function ni(a){if(wf.call(xf,a))return!0;if(wf.call(yf,a))return!1;if(oi.test(a))return xf[a]=
!0;yf[a]=!0;return!1}function pi(a,b,c,d){if(null!==c&&0===c.type)return!1;switch(typeof b){case "function":case "symbol":return!0;case "boolean":if(d)return!1;if(null!==c)return!c.acceptsBooleans;a=a.toLowerCase().slice(0,5);return"data-"!==a&&"aria-"!==a;default:return!1}}function qi(a,b,c,d){if(null===b||"undefined"===typeof b||pi(a,b,c,d))return!0;if(d)return!1;if(null!==c)switch(c.type){case 3:return!b;case 4:return!1===b;case 5:return isNaN(b);case 6:return isNaN(b)||1>b}return!1}function L(a,
b,c,d,e,f){this.acceptsBooleans=2===b||3===b||4===b;this.attributeName=d;this.attributeNamespace=e;this.mustUseProperty=c;this.propertyName=a;this.type=b;this.sanitizeURL=f}function xd(a,b,c,d){var e=E.hasOwnProperty(b)?E[b]:null;var f=null!==e?0===e.type:d?!1:!(2<b.length)||"o"!==b[0]&&"O"!==b[0]||"n"!==b[1]&&"N"!==b[1]?!1:!0;f||(qi(b,c,e,d)&&(c=null),d||null===e?ni(b)&&(null===c?a.removeAttribute(b):a.setAttribute(b,""+c)):e.mustUseProperty?a[e.propertyName]=null===c?3===e.type?!1:"":c:(b=e.attributeName,
d=e.attributeNamespace,null===c?a.removeAttribute(b):(e=e.type,c=3===e||4===e&&!0===c?"":""+c,d?a.setAttributeNS(d,b,c):a.setAttribute(b,c))))}function zb(a){if(null===a||"object"!==typeof a)return null;a=zf&&a[zf]||a["@@iterator"];return"function"===typeof a?a:null}function ri(a){if(-1===a._status){a._status=0;var b=a._ctor;b=b();a._result=b;b.then(function(b){0===a._status&&(b=b.default,a._status=1,a._result=b)},function(b){0===a._status&&(a._status=2,a._result=b)})}}function na(a){if(null==a)return null;
if("function"===typeof a)return a.displayName||a.name||null;if("string"===typeof a)return a;switch(a){case Ma:return"Fragment";case gb:return"Portal";case kc:return"Profiler";case Af:return"StrictMode";case lc:return"Suspense";case yd:return"SuspenseList"}if("object"===typeof a)switch(a.$$typeof){case Bf:return"Context.Consumer";case Cf:return"Context.Provider";case zd:var b=a.render;b=b.displayName||b.name||"";return a.displayName||(""!==b?"ForwardRef("+b+")":"ForwardRef");case Ad:return na(a.type);
case Df:return na(a.render);case Ef:if(a=1===a._status?a._result:null)return na(a)}return null}function Bd(a){var b="";do{a:switch(a.tag){case 3:case 4:case 6:case 7:case 10:case 9:var c="";break a;default:var d=a._debugOwner,e=a._debugSource,f=na(a.type);c=null;d&&(c=na(d.type));d=f;f="";e?f=" (at "+e.fileName.replace(si,"")+":"+e.lineNumber+")":c&&(f=" (created by "+c+")");c="\n    in "+(d||"Unknown")+f}b+=c;a=a.return}while(a);return b}function va(a){switch(typeof a){case "boolean":case "number":case "object":case "string":case "undefined":return a;
default:return""}}function Ff(a){var b=a.type;return(a=a.nodeName)&&"input"===a.toLowerCase()&&("checkbox"===b||"radio"===b)}function ti(a){var b=Ff(a)?"checked":"value",c=Object.getOwnPropertyDescriptor(a.constructor.prototype,b),d=""+a[b];if(!a.hasOwnProperty(b)&&"undefined"!==typeof c&&"function"===typeof c.get&&"function"===typeof c.set){var e=c.get,f=c.set;Object.defineProperty(a,b,{configurable:!0,get:function(){return e.call(this)},set:function(a){d=""+a;f.call(this,a)}});Object.defineProperty(a,
b,{enumerable:c.enumerable});return{getValue:function(){return d},setValue:function(a){d=""+a},stopTracking:function(){a._valueTracker=null;delete a[b]}}}}function mc(a){a._valueTracker||(a._valueTracker=ti(a))}function Gf(a){if(!a)return!1;var b=a._valueTracker;if(!b)return!0;var c=b.getValue();var d="";a&&(d=Ff(a)?a.checked?"true":"false":a.value);a=d;return a!==c?(b.setValue(a),!0):!1}function Cd(a,b){var c=b.checked;return M({},b,{defaultChecked:void 0,defaultValue:void 0,value:void 0,checked:null!=
c?c:a._wrapperState.initialChecked})}function Hf(a,b){var c=null==b.defaultValue?"":b.defaultValue,d=null!=b.checked?b.checked:b.defaultChecked;c=va(null!=b.value?b.value:c);a._wrapperState={initialChecked:d,initialValue:c,controlled:"checkbox"===b.type||"radio"===b.type?null!=b.checked:null!=b.value}}function If(a,b){b=b.checked;null!=b&&xd(a,"checked",b,!1)}function Dd(a,b){If(a,b);var c=va(b.value),d=b.type;if(null!=c)if("number"===d){if(0===c&&""===a.value||a.value!=c)a.value=""+c}else a.value!==
""+c&&(a.value=""+c);else if("submit"===d||"reset"===d){a.removeAttribute("value");return}b.hasOwnProperty("value")?Ed(a,b.type,c):b.hasOwnProperty("defaultValue")&&Ed(a,b.type,va(b.defaultValue));null==b.checked&&null!=b.defaultChecked&&(a.defaultChecked=!!b.defaultChecked)}function Jf(a,b,c){if(b.hasOwnProperty("value")||b.hasOwnProperty("defaultValue")){var d=b.type;if(!("submit"!==d&&"reset"!==d||void 0!==b.value&&null!==b.value))return;b=""+a._wrapperState.initialValue;c||b===a.value||(a.value=
b);a.defaultValue=b}c=a.name;""!==c&&(a.name="");a.defaultChecked=!!a._wrapperState.initialChecked;""!==c&&(a.name=c)}function Ed(a,b,c){if("number"!==b||a.ownerDocument.activeElement!==a)null==c?a.defaultValue=""+a._wrapperState.initialValue:a.defaultValue!==""+c&&(a.defaultValue=""+c)}function ui(a){var b="";ea.Children.forEach(a,function(a){null!=a&&(b+=a)});return b}function Fd(a,b){a=M({children:void 0},b);if(b=ui(b.children))a.children=b;return a}function hb(a,b,c,d){a=a.options;if(b){b={};
for(var e=0;e<c.length;e++)b["$"+c[e]]=!0;for(c=0;c<a.length;c++)e=b.hasOwnProperty("$"+a[c].value),a[c].selected!==e&&(a[c].selected=e),e&&d&&(a[c].defaultSelected=!0)}else{c=""+va(c);b=null;for(e=0;e<a.length;e++){if(a[e].value===c){a[e].selected=!0;d&&(a[e].defaultSelected=!0);return}null!==b||a[e].disabled||(b=a[e])}null!==b&&(b.selected=!0)}}function Gd(a,b){if(null!=b.dangerouslySetInnerHTML)throw Error(k(91));return M({},b,{value:void 0,defaultValue:void 0,children:""+a._wrapperState.initialValue})}
function Kf(a,b){var c=b.value;if(null==c){c=b.children;b=b.defaultValue;if(null!=c){if(null!=b)throw Error(k(92));if(Array.isArray(c)){if(!(1>=c.length))throw Error(k(93));c=c[0]}b=c}null==b&&(b="");c=b}a._wrapperState={initialValue:va(c)}}function Lf(a,b){var c=va(b.value),d=va(b.defaultValue);null!=c&&(c=""+c,c!==a.value&&(a.value=c),null==b.defaultValue&&a.defaultValue!==c&&(a.defaultValue=c));null!=d&&(a.defaultValue=""+d)}function Mf(a,b){b=a.textContent;b===a._wrapperState.initialValue&&""!==
b&&null!==b&&(a.value=b)}function Nf(a){switch(a){case "svg":return"http://www.w3.org/2000/svg";case "math":return"http://www.w3.org/1998/Math/MathML";default:return"http://www.w3.org/1999/xhtml"}}function Hd(a,b){return null==a||"http://www.w3.org/1999/xhtml"===a?Nf(b):"http://www.w3.org/2000/svg"===a&&"foreignObject"===b?"http://www.w3.org/1999/xhtml":a}function nc(a,b){var c={};c[a.toLowerCase()]=b.toLowerCase();c["Webkit"+a]="webkit"+b;c["Moz"+a]="moz"+b;return c}function oc(a){if(Id[a])return Id[a];
if(!ib[a])return a;var b=ib[a],c;for(c in b)if(b.hasOwnProperty(c)&&c in Of)return Id[a]=b[c];return a}function Jd(a){var b=Pf.get(a);void 0===b&&(b=new Map,Pf.set(a,b));return b}function Na(a){var b=a,c=a;if(a.alternate)for(;b.return;)b=b.return;else{a=b;do b=a,0!==(b.effectTag&1026)&&(c=b.return),a=b.return;while(a)}return 3===b.tag?c:null}function Qf(a){if(13===a.tag){var b=a.memoizedState;null===b&&(a=a.alternate,null!==a&&(b=a.memoizedState));if(null!==b)return b.dehydrated}return null}function Rf(a){if(Na(a)!==
a)throw Error(k(188));}function vi(a){var b=a.alternate;if(!b){b=Na(a);if(null===b)throw Error(k(188));return b!==a?null:a}for(var c=a,d=b;;){var e=c.return;if(null===e)break;var f=e.alternate;if(null===f){d=e.return;if(null!==d){c=d;continue}break}if(e.child===f.child){for(f=e.child;f;){if(f===c)return Rf(e),a;if(f===d)return Rf(e),b;f=f.sibling}throw Error(k(188));}if(c.return!==d.return)c=e,d=f;else{for(var g=!1,h=e.child;h;){if(h===c){g=!0;c=e;d=f;break}if(h===d){g=!0;d=e;c=f;break}h=h.sibling}if(!g){for(h=
f.child;h;){if(h===c){g=!0;c=f;d=e;break}if(h===d){g=!0;d=f;c=e;break}h=h.sibling}if(!g)throw Error(k(189));}}if(c.alternate!==d)throw Error(k(190));}if(3!==c.tag)throw Error(k(188));return c.stateNode.current===c?a:b}function Sf(a){a=vi(a);if(!a)return null;for(var b=a;;){if(5===b.tag||6===b.tag)return b;if(b.child)b.child.return=b,b=b.child;else{if(b===a)break;for(;!b.sibling;){if(!b.return||b.return===a)return null;b=b.return}b.sibling.return=b.return;b=b.sibling}}return null}function jb(a,b){if(null==
b)throw Error(k(30));if(null==a)return b;if(Array.isArray(a)){if(Array.isArray(b))return a.push.apply(a,b),a;a.push(b);return a}return Array.isArray(b)?[a].concat(b):[a,b]}function Kd(a,b,c){Array.isArray(a)?a.forEach(b,c):a&&b.call(c,a)}function pc(a){null!==a&&(Ab=jb(Ab,a));a=Ab;Ab=null;if(a){Kd(a,wi);if(Ab)throw Error(k(95));if(hc)throw a=pd,hc=!1,pd=null,a;}}function Ld(a){a=a.target||a.srcElement||window;a.correspondingUseElement&&(a=a.correspondingUseElement);return 3===a.nodeType?a.parentNode:
a}function Tf(a){if(!wa)return!1;a="on"+a;var b=a in document;b||(b=document.createElement("div"),b.setAttribute(a,"return;"),b="function"===typeof b[a]);return b}function Uf(a){a.topLevelType=null;a.nativeEvent=null;a.targetInst=null;a.ancestors.length=0;10>qc.length&&qc.push(a)}function Vf(a,b,c,d){if(qc.length){var e=qc.pop();e.topLevelType=a;e.eventSystemFlags=d;e.nativeEvent=b;e.targetInst=c;return e}return{topLevelType:a,eventSystemFlags:d,nativeEvent:b,targetInst:c,ancestors:[]}}function Wf(a){var b=
a.targetInst,c=b;do{if(!c){a.ancestors.push(c);break}var d=c;if(3===d.tag)d=d.stateNode.containerInfo;else{for(;d.return;)d=d.return;d=3!==d.tag?null:d.stateNode.containerInfo}if(!d)break;b=c.tag;5!==b&&6!==b||a.ancestors.push(c);c=Bb(d)}while(c);for(c=0;c<a.ancestors.length;c++){b=a.ancestors[c];var e=Ld(a.nativeEvent);d=a.topLevelType;var f=a.nativeEvent,g=a.eventSystemFlags;0===c&&(g|=64);for(var h=null,m=0;m<jc.length;m++){var n=jc[m];n&&(n=n.extractEvents(d,b,f,e,g))&&(h=jb(h,n))}pc(h)}}function Md(a,
b,c){if(!c.has(a)){switch(a){case "scroll":Cb(b,"scroll",!0);break;case "focus":case "blur":Cb(b,"focus",!0);Cb(b,"blur",!0);c.set("blur",null);c.set("focus",null);break;case "cancel":case "close":Tf(a)&&Cb(b,a,!0);break;case "invalid":case "submit":case "reset":break;default:-1===Db.indexOf(a)&&w(a,b)}c.set(a,null)}}function xi(a,b){var c=Jd(b);Nd.forEach(function(a){Md(a,b,c)});yi.forEach(function(a){Md(a,b,c)})}function Od(a,b,c,d,e){return{blockedOn:a,topLevelType:b,eventSystemFlags:c|32,nativeEvent:e,
container:d}}function Xf(a,b){switch(a){case "focus":case "blur":xa=null;break;case "dragenter":case "dragleave":ya=null;break;case "mouseover":case "mouseout":za=null;break;case "pointerover":case "pointerout":Eb.delete(b.pointerId);break;case "gotpointercapture":case "lostpointercapture":Fb.delete(b.pointerId)}}function Gb(a,b,c,d,e,f){if(null===a||a.nativeEvent!==f)return a=Od(b,c,d,e,f),null!==b&&(b=Hb(b),null!==b&&Yf(b)),a;a.eventSystemFlags|=d;return a}function zi(a,b,c,d,e){switch(b){case "focus":return xa=
Gb(xa,a,b,c,d,e),!0;case "dragenter":return ya=Gb(ya,a,b,c,d,e),!0;case "mouseover":return za=Gb(za,a,b,c,d,e),!0;case "pointerover":var f=e.pointerId;Eb.set(f,Gb(Eb.get(f)||null,a,b,c,d,e));return!0;case "gotpointercapture":return f=e.pointerId,Fb.set(f,Gb(Fb.get(f)||null,a,b,c,d,e)),!0}return!1}function Ai(a){var b=Bb(a.target);if(null!==b){var c=Na(b);if(null!==c)if(b=c.tag,13===b){if(b=Qf(c),null!==b){a.blockedOn=b;Pd(a.priority,function(){Bi(c)});return}}else if(3===b&&c.stateNode.hydrate){a.blockedOn=
3===c.tag?c.stateNode.containerInfo:null;return}}a.blockedOn=null}function rc(a){if(null!==a.blockedOn)return!1;var b=Qd(a.topLevelType,a.eventSystemFlags,a.container,a.nativeEvent);if(null!==b){var c=Hb(b);null!==c&&Yf(c);a.blockedOn=b;return!1}return!0}function Zf(a,b,c){rc(a)&&c.delete(b)}function Ci(){for(Rd=!1;0<fa.length;){var a=fa[0];if(null!==a.blockedOn){a=Hb(a.blockedOn);null!==a&&Di(a);break}var b=Qd(a.topLevelType,a.eventSystemFlags,a.container,a.nativeEvent);null!==b?a.blockedOn=b:fa.shift()}null!==
xa&&rc(xa)&&(xa=null);null!==ya&&rc(ya)&&(ya=null);null!==za&&rc(za)&&(za=null);Eb.forEach(Zf);Fb.forEach(Zf)}function Ib(a,b){a.blockedOn===b&&(a.blockedOn=null,Rd||(Rd=!0,$f(ag,Ci)))}function bg(a){if(0<fa.length){Ib(fa[0],a);for(var b=1;b<fa.length;b++){var c=fa[b];c.blockedOn===a&&(c.blockedOn=null)}}null!==xa&&Ib(xa,a);null!==ya&&Ib(ya,a);null!==za&&Ib(za,a);b=function(b){return Ib(b,a)};Eb.forEach(b);Fb.forEach(b);for(b=0;b<Jb.length;b++)c=Jb[b],c.blockedOn===a&&(c.blockedOn=null);for(;0<Jb.length&&
(b=Jb[0],null===b.blockedOn);)Ai(b),null===b.blockedOn&&Jb.shift()}function Sd(a,b){for(var c=0;c<a.length;c+=2){var d=a[c],e=a[c+1],f="on"+(e[0].toUpperCase()+e.slice(1));f={phasedRegistrationNames:{bubbled:f,captured:f+"Capture"},dependencies:[d],eventPriority:b};Td.set(d,b);cg.set(d,f);dg[e]=f}}function w(a,b){Cb(b,a,!1)}function Cb(a,b,c){var d=Td.get(b);switch(void 0===d?2:d){case 0:d=Ei.bind(null,b,1,a);break;case 1:d=Fi.bind(null,b,1,a);break;default:d=sc.bind(null,b,1,a)}c?a.addEventListener(b,
d,!0):a.addEventListener(b,d,!1)}function Ei(a,b,c,d){Oa||vd();var e=sc,f=Oa;Oa=!0;try{eg(e,a,b,c,d)}finally{(Oa=f)||ud()}}function Fi(a,b,c,d){Gi(Hi,sc.bind(null,a,b,c,d))}function sc(a,b,c,d){if(tc)if(0<fa.length&&-1<Nd.indexOf(a))a=Od(null,a,b,c,d),fa.push(a);else{var e=Qd(a,b,c,d);if(null===e)Xf(a,d);else if(-1<Nd.indexOf(a))a=Od(e,a,b,c,d),fa.push(a);else if(!zi(e,a,b,c,d)){Xf(a,d);a=Vf(a,d,null,b);try{uf(Wf,a)}finally{Uf(a)}}}}function Qd(a,b,c,d){c=Ld(d);c=Bb(c);if(null!==c){var e=Na(c);if(null===
e)c=null;else{var f=e.tag;if(13===f){c=Qf(e);if(null!==c)return c;c=null}else if(3===f){if(e.stateNode.hydrate)return 3===e.tag?e.stateNode.containerInfo:null;c=null}else e!==c&&(c=null)}}a=Vf(a,d,c,b);try{uf(Wf,a)}finally{Uf(a)}return null}function fg(a,b,c){return null==b||"boolean"===typeof b||""===b?"":c||"number"!==typeof b||0===b||Kb.hasOwnProperty(a)&&Kb[a]?(""+b).trim():b+"px"}function gg(a,b){a=a.style;for(var c in b)if(b.hasOwnProperty(c)){var d=0===c.indexOf("--"),e=fg(c,b[c],d);"float"===
c&&(c="cssFloat");d?a.setProperty(c,e):a[c]=e}}function Ud(a,b){if(b){if(Ii[a]&&(null!=b.children||null!=b.dangerouslySetInnerHTML))throw Error(k(137,a,""));if(null!=b.dangerouslySetInnerHTML){if(null!=b.children)throw Error(k(60));if(!("object"===typeof b.dangerouslySetInnerHTML&&"__html"in b.dangerouslySetInnerHTML))throw Error(k(61));}if(null!=b.style&&"object"!==typeof b.style)throw Error(k(62,""));}}function Vd(a,b){if(-1===a.indexOf("-"))return"string"===typeof b.is;switch(a){case "annotation-xml":case "color-profile":case "font-face":case "font-face-src":case "font-face-uri":case "font-face-format":case "font-face-name":case "missing-glyph":return!1;
default:return!0}}function oa(a,b){a=9===a.nodeType||11===a.nodeType?a:a.ownerDocument;var c=Jd(a);b=rd[b];for(var d=0;d<b.length;d++)Md(b[d],a,c)}function uc(){}function Wd(a){a=a||("undefined"!==typeof document?document:void 0);if("undefined"===typeof a)return null;try{return a.activeElement||a.body}catch(b){return a.body}}function hg(a){for(;a&&a.firstChild;)a=a.firstChild;return a}function ig(a,b){var c=hg(a);a=0;for(var d;c;){if(3===c.nodeType){d=a+c.textContent.length;if(a<=b&&d>=b)return{node:c,
offset:b-a};a=d}a:{for(;c;){if(c.nextSibling){c=c.nextSibling;break a}c=c.parentNode}c=void 0}c=hg(c)}}function jg(a,b){return a&&b?a===b?!0:a&&3===a.nodeType?!1:b&&3===b.nodeType?jg(a,b.parentNode):"contains"in a?a.contains(b):a.compareDocumentPosition?!!(a.compareDocumentPosition(b)&16):!1:!1}function kg(){for(var a=window,b=Wd();b instanceof a.HTMLIFrameElement;){try{var c="string"===typeof b.contentWindow.location.href}catch(d){c=!1}if(c)a=b.contentWindow;else break;b=Wd(a.document)}return b}
function Xd(a){var b=a&&a.nodeName&&a.nodeName.toLowerCase();return b&&("input"===b&&("text"===a.type||"search"===a.type||"tel"===a.type||"url"===a.type||"password"===a.type)||"textarea"===b||"true"===a.contentEditable)}function lg(a,b){switch(a){case "button":case "input":case "select":case "textarea":return!!b.autoFocus}return!1}function Yd(a,b){return"textarea"===a||"option"===a||"noscript"===a||"string"===typeof b.children||"number"===typeof b.children||"object"===typeof b.dangerouslySetInnerHTML&&
null!==b.dangerouslySetInnerHTML&&null!=b.dangerouslySetInnerHTML.__html}function kb(a){for(;null!=a;a=a.nextSibling){var b=a.nodeType;if(1===b||3===b)break}return a}function mg(a){a=a.previousSibling;for(var b=0;a;){if(8===a.nodeType){var c=a.data;if(c===ng||c===Zd||c===$d){if(0===b)return a;b--}else c===og&&b++}a=a.previousSibling}return null}function Bb(a){var b=a[Aa];if(b)return b;for(var c=a.parentNode;c;){if(b=c[Lb]||c[Aa]){c=b.alternate;if(null!==b.child||null!==c&&null!==c.child)for(a=mg(a);null!==
a;){if(c=a[Aa])return c;a=mg(a)}return b}a=c;c=a.parentNode}return null}function Hb(a){a=a[Aa]||a[Lb];return!a||5!==a.tag&&6!==a.tag&&13!==a.tag&&3!==a.tag?null:a}function Pa(a){if(5===a.tag||6===a.tag)return a.stateNode;throw Error(k(33));}function ae(a){return a[vc]||null}function pa(a){do a=a.return;while(a&&5!==a.tag);return a?a:null}function pg(a,b){var c=a.stateNode;if(!c)return null;var d=td(c);if(!d)return null;c=d[b];a:switch(b){case "onClick":case "onClickCapture":case "onDoubleClick":case "onDoubleClickCapture":case "onMouseDown":case "onMouseDownCapture":case "onMouseMove":case "onMouseMoveCapture":case "onMouseUp":case "onMouseUpCapture":case "onMouseEnter":(d=
!d.disabled)||(a=a.type,d=!("button"===a||"input"===a||"select"===a||"textarea"===a));a=!d;break a;default:a=!1}if(a)return null;if(c&&"function"!==typeof c)throw Error(k(231,b,typeof c));return c}function qg(a,b,c){if(b=pg(a,c.dispatchConfig.phasedRegistrationNames[b]))c._dispatchListeners=jb(c._dispatchListeners,b),c._dispatchInstances=jb(c._dispatchInstances,a)}function Ji(a){if(a&&a.dispatchConfig.phasedRegistrationNames){for(var b=a._targetInst,c=[];b;)c.push(b),b=pa(b);for(b=c.length;0<b--;)qg(c[b],
"captured",a);for(b=0;b<c.length;b++)qg(c[b],"bubbled",a)}}function be(a,b,c){a&&c&&c.dispatchConfig.registrationName&&(b=pg(a,c.dispatchConfig.registrationName))&&(c._dispatchListeners=jb(c._dispatchListeners,b),c._dispatchInstances=jb(c._dispatchInstances,a))}function Ki(a){a&&a.dispatchConfig.registrationName&&be(a._targetInst,null,a)}function lb(a){Kd(a,Ji)}function rg(){if(wc)return wc;var a,b=ce,c=b.length,d,e="value"in Ba?Ba.value:Ba.textContent,f=e.length;for(a=0;a<c&&b[a]===e[a];a++);var g=
c-a;for(d=1;d<=g&&b[c-d]===e[f-d];d++);return wc=e.slice(a,1<d?1-d:void 0)}function xc(){return!0}function yc(){return!1}function R(a,b,c,d){this.dispatchConfig=a;this._targetInst=b;this.nativeEvent=c;a=this.constructor.Interface;for(var e in a)a.hasOwnProperty(e)&&((b=a[e])?this[e]=b(c):"target"===e?this.target=d:this[e]=c[e]);this.isDefaultPrevented=(null!=c.defaultPrevented?c.defaultPrevented:!1===c.returnValue)?xc:yc;this.isPropagationStopped=yc;return this}function Li(a,b,c,d){if(this.eventPool.length){var e=
this.eventPool.pop();this.call(e,a,b,c,d);return e}return new this(a,b,c,d)}function Mi(a){if(!(a instanceof this))throw Error(k(279));a.destructor();10>this.eventPool.length&&this.eventPool.push(a)}function sg(a){a.eventPool=[];a.getPooled=Li;a.release=Mi}function tg(a,b){switch(a){case "keyup":return-1!==Ni.indexOf(b.keyCode);case "keydown":return 229!==b.keyCode;case "keypress":case "mousedown":case "blur":return!0;default:return!1}}function ug(a){a=a.detail;return"object"===typeof a&&"data"in
a?a.data:null}function Oi(a,b){switch(a){case "compositionend":return ug(b);case "keypress":if(32!==b.which)return null;vg=!0;return wg;case "textInput":return a=b.data,a===wg&&vg?null:a;default:return null}}function Pi(a,b){if(mb)return"compositionend"===a||!de&&tg(a,b)?(a=rg(),wc=ce=Ba=null,mb=!1,a):null;switch(a){case "paste":return null;case "keypress":if(!(b.ctrlKey||b.altKey||b.metaKey)||b.ctrlKey&&b.altKey){if(b.char&&1<b.char.length)return b.char;if(b.which)return String.fromCharCode(b.which)}return null;
case "compositionend":return xg&&"ko"!==b.locale?null:b.data;default:return null}}function yg(a){var b=a&&a.nodeName&&a.nodeName.toLowerCase();return"input"===b?!!Qi[a.type]:"textarea"===b?!0:!1}function zg(a,b,c){a=R.getPooled(Ag.change,a,b,c);a.type="change";sf(c);lb(a);return a}function Ri(a){pc(a)}function zc(a){var b=Pa(a);if(Gf(b))return a}function Si(a,b){if("change"===a)return b}function Bg(){Mb&&(Mb.detachEvent("onpropertychange",Cg),Nb=Mb=null)}function Cg(a){if("value"===a.propertyName&&
zc(Nb))if(a=zg(Nb,a,Ld(a)),Oa)pc(a);else{Oa=!0;try{ee(Ri,a)}finally{Oa=!1,ud()}}}function Ti(a,b,c){"focus"===a?(Bg(),Mb=b,Nb=c,Mb.attachEvent("onpropertychange",Cg)):"blur"===a&&Bg()}function Ui(a,b){if("selectionchange"===a||"keyup"===a||"keydown"===a)return zc(Nb)}function Vi(a,b){if("click"===a)return zc(b)}function Wi(a,b){if("input"===a||"change"===a)return zc(b)}function Xi(a){var b=this.nativeEvent;return b.getModifierState?b.getModifierState(a):(a=Yi[a])?!!b[a]:!1}function fe(a){return Xi}
function Zi(a,b){return a===b&&(0!==a||1/a===1/b)||a!==a&&b!==b}function Ob(a,b){if(Qa(a,b))return!0;if("object"!==typeof a||null===a||"object"!==typeof b||null===b)return!1;var c=Object.keys(a),d=Object.keys(b);if(c.length!==d.length)return!1;for(d=0;d<c.length;d++)if(!$i.call(b,c[d])||!Qa(a[c[d]],b[c[d]]))return!1;return!0}function Dg(a,b){var c=b.window===b?b.document:9===b.nodeType?b:b.ownerDocument;if(ge||null==nb||nb!==Wd(c))return null;c=nb;"selectionStart"in c&&Xd(c)?c={start:c.selectionStart,
end:c.selectionEnd}:(c=(c.ownerDocument&&c.ownerDocument.defaultView||window).getSelection(),c={anchorNode:c.anchorNode,anchorOffset:c.anchorOffset,focusNode:c.focusNode,focusOffset:c.focusOffset});return Pb&&Ob(Pb,c)?null:(Pb=c,a=R.getPooled(Eg.select,he,a,b),a.type="select",a.target=nb,lb(a),a)}function Ac(a){var b=a.keyCode;"charCode"in a?(a=a.charCode,0===a&&13===b&&(a=13)):a=b;10===a&&(a=13);return 32<=a||13===a?a:0}function q(a,b){0>ob||(a.current=ie[ob],ie[ob]=null,ob--)}function y(a,b,c){ob++;
ie[ob]=a.current;a.current=b}function pb(a,b){var c=a.type.contextTypes;if(!c)return Ca;var d=a.stateNode;if(d&&d.__reactInternalMemoizedUnmaskedChildContext===b)return d.__reactInternalMemoizedMaskedChildContext;var e={},f;for(f in c)e[f]=b[f];d&&(a=a.stateNode,a.__reactInternalMemoizedUnmaskedChildContext=b,a.__reactInternalMemoizedMaskedChildContext=e);return e}function N(a){a=a.childContextTypes;return null!==a&&void 0!==a}function Fg(a,b,c){if(B.current!==Ca)throw Error(k(168));y(B,b);y(G,c)}
function Gg(a,b,c){var d=a.stateNode;a=b.childContextTypes;if("function"!==typeof d.getChildContext)return c;d=d.getChildContext();for(var e in d)if(!(e in a))throw Error(k(108,na(b)||"Unknown",e));return M({},c,{},d)}function Bc(a){a=(a=a.stateNode)&&a.__reactInternalMemoizedMergedChildContext||Ca;Ra=B.current;y(B,a);y(G,G.current);return!0}function Hg(a,b,c){var d=a.stateNode;if(!d)throw Error(k(169));c?(a=Gg(a,b,Ra),d.__reactInternalMemoizedMergedChildContext=a,q(G),q(B),y(B,a)):q(G);y(G,c)}function Cc(){switch(aj()){case Dc:return 99;
case Ig:return 98;case Jg:return 97;case Kg:return 96;case Lg:return 95;default:throw Error(k(332));}}function Mg(a){switch(a){case 99:return Dc;case 98:return Ig;case 97:return Jg;case 96:return Kg;case 95:return Lg;default:throw Error(k(332));}}function Da(a,b){a=Mg(a);return bj(a,b)}function Ng(a,b,c){a=Mg(a);return je(a,b,c)}function Og(a){null===qa?(qa=[a],Ec=je(Dc,Pg)):qa.push(a);return Qg}function ha(){if(null!==Ec){var a=Ec;Ec=null;Rg(a)}Pg()}function Pg(){if(!ke&&null!==qa){ke=!0;var a=0;
try{var b=qa;Da(99,function(){for(;a<b.length;a++){var c=b[a];do c=c(!0);while(null!==c)}});qa=null}catch(c){throw null!==qa&&(qa=qa.slice(a+1)),je(Dc,ha),c;}finally{ke=!1}}}function Fc(a,b,c){c/=10;return 1073741821-(((1073741821-a+b/10)/c|0)+1)*c}function aa(a,b){if(a&&a.defaultProps){b=M({},b);a=a.defaultProps;for(var c in a)void 0===b[c]&&(b[c]=a[c])}return b}function le(){Gc=qb=Hc=null}function me(a){var b=Ic.current;q(Ic);a.type._context._currentValue=b}function Sg(a,b){for(;null!==a;){var c=
a.alternate;if(a.childExpirationTime<b)a.childExpirationTime=b,null!==c&&c.childExpirationTime<b&&(c.childExpirationTime=b);else if(null!==c&&c.childExpirationTime<b)c.childExpirationTime=b;else break;a=a.return}}function rb(a,b){Hc=a;Gc=qb=null;a=a.dependencies;null!==a&&null!==a.firstContext&&(a.expirationTime>=b&&(ia=!0),a.firstContext=null)}function W(a,b){if(Gc!==a&&!1!==b&&0!==b){if("number"!==typeof b||1073741823===b)Gc=a,b=1073741823;b={context:a,observedBits:b,next:null};if(null===qb){if(null===
Hc)throw Error(k(308));qb=b;Hc.dependencies={expirationTime:0,firstContext:b,responders:null}}else qb=qb.next=b}return a._currentValue}function ne(a){a.updateQueue={baseState:a.memoizedState,baseQueue:null,shared:{pending:null},effects:null}}function oe(a,b){a=a.updateQueue;b.updateQueue===a&&(b.updateQueue={baseState:a.baseState,baseQueue:a.baseQueue,shared:a.shared,effects:a.effects})}function Ea(a,b){a={expirationTime:a,suspenseConfig:b,tag:Tg,payload:null,callback:null,next:null};return a.next=
a}function Fa(a,b){a=a.updateQueue;if(null!==a){a=a.shared;var c=a.pending;null===c?b.next=b:(b.next=c.next,c.next=b);a.pending=b}}function Ug(a,b){var c=a.alternate;null!==c&&oe(c,a);a=a.updateQueue;c=a.baseQueue;null===c?(a.baseQueue=b.next=b,b.next=b):(b.next=c.next,c.next=b)}function Qb(a,b,c,d){var e=a.updateQueue;Ga=!1;var f=e.baseQueue,g=e.shared.pending;if(null!==g){if(null!==f){var h=f.next;f.next=g.next;g.next=h}f=g;e.shared.pending=null;h=a.alternate;null!==h&&(h=h.updateQueue,null!==h&&
(h.baseQueue=g))}if(null!==f){h=f.next;var m=e.baseState,n=0,k=null,ba=null,l=null;if(null!==h){var p=h;do{g=p.expirationTime;if(g<d){var t={expirationTime:p.expirationTime,suspenseConfig:p.suspenseConfig,tag:p.tag,payload:p.payload,callback:p.callback,next:null};null===l?(ba=l=t,k=m):l=l.next=t;g>n&&(n=g)}else{null!==l&&(l=l.next={expirationTime:1073741823,suspenseConfig:p.suspenseConfig,tag:p.tag,payload:p.payload,callback:p.callback,next:null});Vg(g,p.suspenseConfig);a:{var q=a,r=p;g=b;t=c;switch(r.tag){case 1:q=
r.payload;if("function"===typeof q){m=q.call(t,m,g);break a}m=q;break a;case 3:q.effectTag=q.effectTag&-4097|64;case Tg:q=r.payload;g="function"===typeof q?q.call(t,m,g):q;if(null===g||void 0===g)break a;m=M({},m,g);break a;case Jc:Ga=!0}}null!==p.callback&&(a.effectTag|=32,g=e.effects,null===g?e.effects=[p]:g.push(p))}p=p.next;if(null===p||p===h)if(g=e.shared.pending,null===g)break;else p=f.next=g.next,g.next=h,e.baseQueue=f=g,e.shared.pending=null}while(1)}null===l?k=m:l.next=ba;e.baseState=k;e.baseQueue=
l;Kc(n);a.expirationTime=n;a.memoizedState=m}}function Wg(a,b,c){a=b.effects;b.effects=null;if(null!==a)for(b=0;b<a.length;b++){var d=a[b],e=d.callback;if(null!==e){d.callback=null;d=e;e=c;if("function"!==typeof d)throw Error(k(191,d));d.call(e)}}}function Lc(a,b,c,d){b=a.memoizedState;c=c(d,b);c=null===c||void 0===c?b:M({},b,c);a.memoizedState=c;0===a.expirationTime&&(a.updateQueue.baseState=c)}function Xg(a,b,c,d,e,f,g){a=a.stateNode;return"function"===typeof a.shouldComponentUpdate?a.shouldComponentUpdate(d,
f,g):b.prototype&&b.prototype.isPureReactComponent?!Ob(c,d)||!Ob(e,f):!0}function Yg(a,b,c){var d=!1,e=Ca;var f=b.contextType;"object"===typeof f&&null!==f?f=W(f):(e=N(b)?Ra:B.current,d=b.contextTypes,f=(d=null!==d&&void 0!==d)?pb(a,e):Ca);b=new b(c,f);a.memoizedState=null!==b.state&&void 0!==b.state?b.state:null;b.updater=Mc;a.stateNode=b;b._reactInternalFiber=a;d&&(a=a.stateNode,a.__reactInternalMemoizedUnmaskedChildContext=e,a.__reactInternalMemoizedMaskedChildContext=f);return b}function Zg(a,
b,c,d){a=b.state;"function"===typeof b.componentWillReceiveProps&&b.componentWillReceiveProps(c,d);"function"===typeof b.UNSAFE_componentWillReceiveProps&&b.UNSAFE_componentWillReceiveProps(c,d);b.state!==a&&Mc.enqueueReplaceState(b,b.state,null)}function pe(a,b,c,d){var e=a.stateNode;e.props=c;e.state=a.memoizedState;e.refs=$g;ne(a);var f=b.contextType;"object"===typeof f&&null!==f?e.context=W(f):(f=N(b)?Ra:B.current,e.context=pb(a,f));Qb(a,c,e,d);e.state=a.memoizedState;f=b.getDerivedStateFromProps;
"function"===typeof f&&(Lc(a,b,f,c),e.state=a.memoizedState);"function"===typeof b.getDerivedStateFromProps||"function"===typeof e.getSnapshotBeforeUpdate||"function"!==typeof e.UNSAFE_componentWillMount&&"function"!==typeof e.componentWillMount||(b=e.state,"function"===typeof e.componentWillMount&&e.componentWillMount(),"function"===typeof e.UNSAFE_componentWillMount&&e.UNSAFE_componentWillMount(),b!==e.state&&Mc.enqueueReplaceState(e,e.state,null),Qb(a,c,e,d),e.state=a.memoizedState);"function"===
typeof e.componentDidMount&&(a.effectTag|=4)}function Rb(a,b,c){a=c.ref;if(null!==a&&"function"!==typeof a&&"object"!==typeof a){if(c._owner){c=c._owner;if(c){if(1!==c.tag)throw Error(k(309));var d=c.stateNode}if(!d)throw Error(k(147,a));var e=""+a;if(null!==b&&null!==b.ref&&"function"===typeof b.ref&&b.ref._stringRef===e)return b.ref;b=function(a){var b=d.refs;b===$g&&(b=d.refs={});null===a?delete b[e]:b[e]=a};b._stringRef=e;return b}if("string"!==typeof a)throw Error(k(284));if(!c._owner)throw Error(k(290,
a));}return a}function Nc(a,b){if("textarea"!==a.type)throw Error(k(31,"[object Object]"===Object.prototype.toString.call(b)?"object with keys {"+Object.keys(b).join(", ")+"}":b,""));}function ah(a){function b(b,c){if(a){var d=b.lastEffect;null!==d?(d.nextEffect=c,b.lastEffect=c):b.firstEffect=b.lastEffect=c;c.nextEffect=null;c.effectTag=8}}function c(c,d){if(!a)return null;for(;null!==d;)b(c,d),d=d.sibling;return null}function d(a,b){for(a=new Map;null!==b;)null!==b.key?a.set(b.key,b):a.set(b.index,
b),b=b.sibling;return a}function e(a,b){a=Sa(a,b);a.index=0;a.sibling=null;return a}function f(b,c,d){b.index=d;if(!a)return c;d=b.alternate;if(null!==d)return d=d.index,d<c?(b.effectTag=2,c):d;b.effectTag=2;return c}function g(b){a&&null===b.alternate&&(b.effectTag=2);return b}function h(a,b,c,d){if(null===b||6!==b.tag)return b=qe(c,a.mode,d),b.return=a,b;b=e(b,c);b.return=a;return b}function m(a,b,c,d){if(null!==b&&b.elementType===c.type)return d=e(b,c.props),d.ref=Rb(a,b,c),d.return=a,d;d=Oc(c.type,
c.key,c.props,null,a.mode,d);d.ref=Rb(a,b,c);d.return=a;return d}function n(a,b,c,d){if(null===b||4!==b.tag||b.stateNode.containerInfo!==c.containerInfo||b.stateNode.implementation!==c.implementation)return b=re(c,a.mode,d),b.return=a,b;b=e(b,c.children||[]);b.return=a;return b}function l(a,b,c,d,f){if(null===b||7!==b.tag)return b=Ha(c,a.mode,d,f),b.return=a,b;b=e(b,c);b.return=a;return b}function ba(a,b,c){if("string"===typeof b||"number"===typeof b)return b=qe(""+b,a.mode,c),b.return=a,b;if("object"===
typeof b&&null!==b){switch(b.$$typeof){case Pc:return c=Oc(b.type,b.key,b.props,null,a.mode,c),c.ref=Rb(a,null,b),c.return=a,c;case gb:return b=re(b,a.mode,c),b.return=a,b}if(Qc(b)||zb(b))return b=Ha(b,a.mode,c,null),b.return=a,b;Nc(a,b)}return null}function p(a,b,c,d){var e=null!==b?b.key:null;if("string"===typeof c||"number"===typeof c)return null!==e?null:h(a,b,""+c,d);if("object"===typeof c&&null!==c){switch(c.$$typeof){case Pc:return c.key===e?c.type===Ma?l(a,b,c.props.children,d,e):m(a,b,c,
d):null;case gb:return c.key===e?n(a,b,c,d):null}if(Qc(c)||zb(c))return null!==e?null:l(a,b,c,d,null);Nc(a,c)}return null}function t(a,b,c,d,e){if("string"===typeof d||"number"===typeof d)return a=a.get(c)||null,h(b,a,""+d,e);if("object"===typeof d&&null!==d){switch(d.$$typeof){case Pc:return a=a.get(null===d.key?c:d.key)||null,d.type===Ma?l(b,a,d.props.children,e,d.key):m(b,a,d,e);case gb:return a=a.get(null===d.key?c:d.key)||null,n(b,a,d,e)}if(Qc(d)||zb(d))return a=a.get(c)||null,l(b,a,d,e,null);
Nc(b,d)}return null}function q(e,g,h,m){for(var n=null,k=null,l=g,r=g=0,C=null;null!==l&&r<h.length;r++){l.index>r?(C=l,l=null):C=l.sibling;var O=p(e,l,h[r],m);if(null===O){null===l&&(l=C);break}a&&l&&null===O.alternate&&b(e,l);g=f(O,g,r);null===k?n=O:k.sibling=O;k=O;l=C}if(r===h.length)return c(e,l),n;if(null===l){for(;r<h.length;r++)l=ba(e,h[r],m),null!==l&&(g=f(l,g,r),null===k?n=l:k.sibling=l,k=l);return n}for(l=d(e,l);r<h.length;r++)C=t(l,e,r,h[r],m),null!==C&&(a&&null!==C.alternate&&l.delete(null===
C.key?r:C.key),g=f(C,g,r),null===k?n=C:k.sibling=C,k=C);a&&l.forEach(function(a){return b(e,a)});return n}function w(e,g,h,n){var m=zb(h);if("function"!==typeof m)throw Error(k(150));h=m.call(h);if(null==h)throw Error(k(151));for(var l=m=null,r=g,C=g=0,O=null,v=h.next();null!==r&&!v.done;C++,v=h.next()){r.index>C?(O=r,r=null):O=r.sibling;var q=p(e,r,v.value,n);if(null===q){null===r&&(r=O);break}a&&r&&null===q.alternate&&b(e,r);g=f(q,g,C);null===l?m=q:l.sibling=q;l=q;r=O}if(v.done)return c(e,r),m;
if(null===r){for(;!v.done;C++,v=h.next())v=ba(e,v.value,n),null!==v&&(g=f(v,g,C),null===l?m=v:l.sibling=v,l=v);return m}for(r=d(e,r);!v.done;C++,v=h.next())v=t(r,e,C,v.value,n),null!==v&&(a&&null!==v.alternate&&r.delete(null===v.key?C:v.key),g=f(v,g,C),null===l?m=v:l.sibling=v,l=v);a&&r.forEach(function(a){return b(e,a)});return m}return function(a,d,f,h){var m="object"===typeof f&&null!==f&&f.type===Ma&&null===f.key;m&&(f=f.props.children);var n="object"===typeof f&&null!==f;if(n)switch(f.$$typeof){case Pc:a:{n=
f.key;for(m=d;null!==m;){if(m.key===n){switch(m.tag){case 7:if(f.type===Ma){c(a,m.sibling);d=e(m,f.props.children);d.return=a;a=d;break a}break;default:if(m.elementType===f.type){c(a,m.sibling);d=e(m,f.props);d.ref=Rb(a,m,f);d.return=a;a=d;break a}}c(a,m);break}else b(a,m);m=m.sibling}f.type===Ma?(d=Ha(f.props.children,a.mode,h,f.key),d.return=a,a=d):(h=Oc(f.type,f.key,f.props,null,a.mode,h),h.ref=Rb(a,d,f),h.return=a,a=h)}return g(a);case gb:a:{for(m=f.key;null!==d;){if(d.key===m)if(4===d.tag&&d.stateNode.containerInfo===
f.containerInfo&&d.stateNode.implementation===f.implementation){c(a,d.sibling);d=e(d,f.children||[]);d.return=a;a=d;break a}else{c(a,d);break}else b(a,d);d=d.sibling}d=re(f,a.mode,h);d.return=a;a=d}return g(a)}if("string"===typeof f||"number"===typeof f)return f=""+f,null!==d&&6===d.tag?(c(a,d.sibling),d=e(d,f),d.return=a,a=d):(c(a,d),d=qe(f,a.mode,h),d.return=a,a=d),g(a);if(Qc(f))return q(a,d,f,h);if(zb(f))return w(a,d,f,h);n&&Nc(a,f);if("undefined"===typeof f&&!m)switch(a.tag){case 1:case 0:throw a=
a.type,Error(k(152,a.displayName||a.name||"Component"));}return c(a,d)}}function Ta(a){if(a===Sb)throw Error(k(174));return a}function se(a,b){y(Tb,b);y(Ub,a);y(ja,Sb);a=b.nodeType;switch(a){case 9:case 11:b=(b=b.documentElement)?b.namespaceURI:Hd(null,"");break;default:a=8===a?b.parentNode:b,b=a.namespaceURI||null,a=a.tagName,b=Hd(b,a)}q(ja);y(ja,b)}function tb(a){q(ja);q(Ub);q(Tb)}function bh(a){Ta(Tb.current);var b=Ta(ja.current);var c=Hd(b,a.type);b!==c&&(y(Ub,a),y(ja,c))}function te(a){Ub.current===
a&&(q(ja),q(Ub))}function Rc(a){for(var b=a;null!==b;){if(13===b.tag){var c=b.memoizedState;if(null!==c&&(c=c.dehydrated,null===c||c.data===$d||c.data===Zd))return b}else if(19===b.tag&&void 0!==b.memoizedProps.revealOrder){if(0!==(b.effectTag&64))return b}else if(null!==b.child){b.child.return=b;b=b.child;continue}if(b===a)break;for(;null===b.sibling;){if(null===b.return||b.return===a)return null;b=b.return}b.sibling.return=b.return;b=b.sibling}return null}function ue(a,b){return{responder:a,props:b}}
function S(){throw Error(k(321));}function ve(a,b){if(null===b)return!1;for(var c=0;c<b.length&&c<a.length;c++)if(!Qa(a[c],b[c]))return!1;return!0}function we(a,b,c,d,e,f){Ia=f;z=b;b.memoizedState=null;b.updateQueue=null;b.expirationTime=0;Sc.current=null===a||null===a.memoizedState?dj:ej;a=c(d,e);if(b.expirationTime===Ia){f=0;do{b.expirationTime=0;if(!(25>f))throw Error(k(301));f+=1;J=K=null;b.updateQueue=null;Sc.current=fj;a=c(d,e)}while(b.expirationTime===Ia)}Sc.current=Tc;b=null!==K&&null!==K.next;
Ia=0;J=K=z=null;Uc=!1;if(b)throw Error(k(300));return a}function ub(){var a={memoizedState:null,baseState:null,baseQueue:null,queue:null,next:null};null===J?z.memoizedState=J=a:J=J.next=a;return J}function vb(){if(null===K){var a=z.alternate;a=null!==a?a.memoizedState:null}else a=K.next;var b=null===J?z.memoizedState:J.next;if(null!==b)J=b,K=a;else{if(null===a)throw Error(k(310));K=a;a={memoizedState:K.memoizedState,baseState:K.baseState,baseQueue:K.baseQueue,queue:K.queue,next:null};null===J?z.memoizedState=
J=a:J=J.next=a}return J}function Ua(a,b){return"function"===typeof b?b(a):b}function Vc(a,b,c){b=vb();c=b.queue;if(null===c)throw Error(k(311));c.lastRenderedReducer=a;var d=K,e=d.baseQueue,f=c.pending;if(null!==f){if(null!==e){var g=e.next;e.next=f.next;f.next=g}d.baseQueue=e=f;c.pending=null}if(null!==e){e=e.next;d=d.baseState;var h=g=f=null,m=e;do{var n=m.expirationTime;if(n<Ia){var l={expirationTime:m.expirationTime,suspenseConfig:m.suspenseConfig,action:m.action,eagerReducer:m.eagerReducer,eagerState:m.eagerState,
next:null};null===h?(g=h=l,f=d):h=h.next=l;n>z.expirationTime&&(z.expirationTime=n,Kc(n))}else null!==h&&(h=h.next={expirationTime:1073741823,suspenseConfig:m.suspenseConfig,action:m.action,eagerReducer:m.eagerReducer,eagerState:m.eagerState,next:null}),Vg(n,m.suspenseConfig),d=m.eagerReducer===a?m.eagerState:a(d,m.action);m=m.next}while(null!==m&&m!==e);null===h?f=d:h.next=g;Qa(d,b.memoizedState)||(ia=!0);b.memoizedState=d;b.baseState=f;b.baseQueue=h;c.lastRenderedState=d}return[b.memoizedState,
c.dispatch]}function Wc(a,b,c){b=vb();c=b.queue;if(null===c)throw Error(k(311));c.lastRenderedReducer=a;var d=c.dispatch,e=c.pending,f=b.memoizedState;if(null!==e){c.pending=null;var g=e=e.next;do f=a(f,g.action),g=g.next;while(g!==e);Qa(f,b.memoizedState)||(ia=!0);b.memoizedState=f;null===b.baseQueue&&(b.baseState=f);c.lastRenderedState=f}return[f,d]}function xe(a){var b=ub();"function"===typeof a&&(a=a());b.memoizedState=b.baseState=a;a=b.queue={pending:null,dispatch:null,lastRenderedReducer:Ua,
lastRenderedState:a};a=a.dispatch=ch.bind(null,z,a);return[b.memoizedState,a]}function ye(a,b,c,d){a={tag:a,create:b,destroy:c,deps:d,next:null};b=z.updateQueue;null===b?(b={lastEffect:null},z.updateQueue=b,b.lastEffect=a.next=a):(c=b.lastEffect,null===c?b.lastEffect=a.next=a:(d=c.next,c.next=a,a.next=d,b.lastEffect=a));return a}function dh(a){return vb().memoizedState}function ze(a,b,c,d){var e=ub();z.effectTag|=a;e.memoizedState=ye(1|b,c,void 0,void 0===d?null:d)}function Ae(a,b,c,d){var e=vb();
d=void 0===d?null:d;var f=void 0;if(null!==K){var g=K.memoizedState;f=g.destroy;if(null!==d&&ve(d,g.deps)){ye(b,c,f,d);return}}z.effectTag|=a;e.memoizedState=ye(1|b,c,f,d)}function eh(a,b){return ze(516,4,a,b)}function Xc(a,b){return Ae(516,4,a,b)}function fh(a,b){return Ae(4,2,a,b)}function gh(a,b){if("function"===typeof b)return a=a(),b(a),function(){b(null)};if(null!==b&&void 0!==b)return a=a(),b.current=a,function(){b.current=null}}function hh(a,b,c){c=null!==c&&void 0!==c?c.concat([a]):null;
return Ae(4,2,gh.bind(null,b,a),c)}function Be(a,b){}function ih(a,b){ub().memoizedState=[a,void 0===b?null:b];return a}function Yc(a,b){var c=vb();b=void 0===b?null:b;var d=c.memoizedState;if(null!==d&&null!==b&&ve(b,d[1]))return d[0];c.memoizedState=[a,b];return a}function jh(a,b){var c=vb();b=void 0===b?null:b;var d=c.memoizedState;if(null!==d&&null!==b&&ve(b,d[1]))return d[0];a=a();c.memoizedState=[a,b];return a}function Ce(a,b,c){var d=Cc();Da(98>d?98:d,function(){a(!0)});Da(97<d?97:d,function(){var d=
X.suspense;X.suspense=void 0===b?null:b;try{a(!1),c()}finally{X.suspense=d}})}function ch(a,b,c){var d=ka(),e=Vb.suspense;d=Va(d,a,e);e={expirationTime:d,suspenseConfig:e,action:c,eagerReducer:null,eagerState:null,next:null};var f=b.pending;null===f?e.next=e:(e.next=f.next,f.next=e);b.pending=e;f=a.alternate;if(a===z||null!==f&&f===z)Uc=!0,e.expirationTime=Ia,z.expirationTime=Ia;else{if(0===a.expirationTime&&(null===f||0===f.expirationTime)&&(f=b.lastRenderedReducer,null!==f))try{var g=b.lastRenderedState,
h=f(g,c);e.eagerReducer=f;e.eagerState=h;if(Qa(h,g))return}catch(m){}finally{}Ja(a,d)}}function kh(a,b){var c=la(5,null,null,0);c.elementType="DELETED";c.type="DELETED";c.stateNode=b;c.return=a;c.effectTag=8;null!==a.lastEffect?(a.lastEffect.nextEffect=c,a.lastEffect=c):a.firstEffect=a.lastEffect=c}function lh(a,b){switch(a.tag){case 5:var c=a.type;b=1!==b.nodeType||c.toLowerCase()!==b.nodeName.toLowerCase()?null:b;return null!==b?(a.stateNode=b,!0):!1;case 6:return b=""===a.pendingProps||3!==b.nodeType?
null:b,null!==b?(a.stateNode=b,!0):!1;case 13:return!1;default:return!1}}function De(a){if(Wa){var b=Ka;if(b){var c=b;if(!lh(a,b)){b=kb(c.nextSibling);if(!b||!lh(a,b)){a.effectTag=a.effectTag&-1025|2;Wa=!1;ra=a;return}kh(ra,c)}ra=a;Ka=kb(b.firstChild)}else a.effectTag=a.effectTag&-1025|2,Wa=!1,ra=a}}function mh(a){for(a=a.return;null!==a&&5!==a.tag&&3!==a.tag&&13!==a.tag;)a=a.return;ra=a}function Zc(a){if(a!==ra)return!1;if(!Wa)return mh(a),Wa=!0,!1;var b=a.type;if(5!==a.tag||"head"!==b&&"body"!==
b&&!Yd(b,a.memoizedProps))for(b=Ka;b;)kh(a,b),b=kb(b.nextSibling);mh(a);if(13===a.tag){a=a.memoizedState;a=null!==a?a.dehydrated:null;if(!a)throw Error(k(317));a:{a=a.nextSibling;for(b=0;a;){if(8===a.nodeType){var c=a.data;if(c===og){if(0===b){Ka=kb(a.nextSibling);break a}b--}else c!==ng&&c!==Zd&&c!==$d||b++}a=a.nextSibling}Ka=null}}else Ka=ra?kb(a.stateNode.nextSibling):null;return!0}function Ee(){Ka=ra=null;Wa=!1}function T(a,b,c,d){b.child=null===a?Fe(b,null,c,d):wb(b,a.child,c,d)}function nh(a,
b,c,d,e){c=c.render;var f=b.ref;rb(b,e);d=we(a,b,c,d,f,e);if(null!==a&&!ia)return b.updateQueue=a.updateQueue,b.effectTag&=-517,a.expirationTime<=e&&(a.expirationTime=0),sa(a,b,e);b.effectTag|=1;T(a,b,d,e);return b.child}function oh(a,b,c,d,e,f){if(null===a){var g=c.type;if("function"===typeof g&&!Ge(g)&&void 0===g.defaultProps&&null===c.compare&&void 0===c.defaultProps)return b.tag=15,b.type=g,ph(a,b,g,d,e,f);a=Oc(c.type,null,d,null,b.mode,f);a.ref=b.ref;a.return=b;return b.child=a}g=a.child;if(e<
f&&(e=g.memoizedProps,c=c.compare,c=null!==c?c:Ob,c(e,d)&&a.ref===b.ref))return sa(a,b,f);b.effectTag|=1;a=Sa(g,d);a.ref=b.ref;a.return=b;return b.child=a}function ph(a,b,c,d,e,f){return null!==a&&Ob(a.memoizedProps,d)&&a.ref===b.ref&&(ia=!1,e<f)?(b.expirationTime=a.expirationTime,sa(a,b,f)):He(a,b,c,d,f)}function qh(a,b){var c=b.ref;if(null===a&&null!==c||null!==a&&a.ref!==c)b.effectTag|=128}function He(a,b,c,d,e){var f=N(c)?Ra:B.current;f=pb(b,f);rb(b,e);c=we(a,b,c,d,f,e);if(null!==a&&!ia)return b.updateQueue=
a.updateQueue,b.effectTag&=-517,a.expirationTime<=e&&(a.expirationTime=0),sa(a,b,e);b.effectTag|=1;T(a,b,c,e);return b.child}function rh(a,b,c,d,e){if(N(c)){var f=!0;Bc(b)}else f=!1;rb(b,e);if(null===b.stateNode)null!==a&&(a.alternate=null,b.alternate=null,b.effectTag|=2),Yg(b,c,d),pe(b,c,d,e),d=!0;else if(null===a){var g=b.stateNode,h=b.memoizedProps;g.props=h;var m=g.context,n=c.contextType;"object"===typeof n&&null!==n?n=W(n):(n=N(c)?Ra:B.current,n=pb(b,n));var l=c.getDerivedStateFromProps,k="function"===
typeof l||"function"===typeof g.getSnapshotBeforeUpdate;k||"function"!==typeof g.UNSAFE_componentWillReceiveProps&&"function"!==typeof g.componentWillReceiveProps||(h!==d||m!==n)&&Zg(b,g,d,n);Ga=!1;var p=b.memoizedState;g.state=p;Qb(b,d,g,e);m=b.memoizedState;h!==d||p!==m||G.current||Ga?("function"===typeof l&&(Lc(b,c,l,d),m=b.memoizedState),(h=Ga||Xg(b,c,h,d,p,m,n))?(k||"function"!==typeof g.UNSAFE_componentWillMount&&"function"!==typeof g.componentWillMount||("function"===typeof g.componentWillMount&&
g.componentWillMount(),"function"===typeof g.UNSAFE_componentWillMount&&g.UNSAFE_componentWillMount()),"function"===typeof g.componentDidMount&&(b.effectTag|=4)):("function"===typeof g.componentDidMount&&(b.effectTag|=4),b.memoizedProps=d,b.memoizedState=m),g.props=d,g.state=m,g.context=n,d=h):("function"===typeof g.componentDidMount&&(b.effectTag|=4),d=!1)}else g=b.stateNode,oe(a,b),h=b.memoizedProps,g.props=b.type===b.elementType?h:aa(b.type,h),m=g.context,n=c.contextType,"object"===typeof n&&null!==
n?n=W(n):(n=N(c)?Ra:B.current,n=pb(b,n)),l=c.getDerivedStateFromProps,(k="function"===typeof l||"function"===typeof g.getSnapshotBeforeUpdate)||"function"!==typeof g.UNSAFE_componentWillReceiveProps&&"function"!==typeof g.componentWillReceiveProps||(h!==d||m!==n)&&Zg(b,g,d,n),Ga=!1,m=b.memoizedState,g.state=m,Qb(b,d,g,e),p=b.memoizedState,h!==d||m!==p||G.current||Ga?("function"===typeof l&&(Lc(b,c,l,d),p=b.memoizedState),(l=Ga||Xg(b,c,h,d,m,p,n))?(k||"function"!==typeof g.UNSAFE_componentWillUpdate&&
"function"!==typeof g.componentWillUpdate||("function"===typeof g.componentWillUpdate&&g.componentWillUpdate(d,p,n),"function"===typeof g.UNSAFE_componentWillUpdate&&g.UNSAFE_componentWillUpdate(d,p,n)),"function"===typeof g.componentDidUpdate&&(b.effectTag|=4),"function"===typeof g.getSnapshotBeforeUpdate&&(b.effectTag|=256)):("function"!==typeof g.componentDidUpdate||h===a.memoizedProps&&m===a.memoizedState||(b.effectTag|=4),"function"!==typeof g.getSnapshotBeforeUpdate||h===a.memoizedProps&&m===
a.memoizedState||(b.effectTag|=256),b.memoizedProps=d,b.memoizedState=p),g.props=d,g.state=p,g.context=n,d=l):("function"!==typeof g.componentDidUpdate||h===a.memoizedProps&&m===a.memoizedState||(b.effectTag|=4),"function"!==typeof g.getSnapshotBeforeUpdate||h===a.memoizedProps&&m===a.memoizedState||(b.effectTag|=256),d=!1);return Ie(a,b,c,d,f,e)}function Ie(a,b,c,d,e,f){qh(a,b);var g=0!==(b.effectTag&64);if(!d&&!g)return e&&Hg(b,c,!1),sa(a,b,f);d=b.stateNode;gj.current=b;var h=g&&"function"!==typeof c.getDerivedStateFromError?
null:d.render();b.effectTag|=1;null!==a&&g?(b.child=wb(b,a.child,null,f),b.child=wb(b,null,h,f)):T(a,b,h,f);b.memoizedState=d.state;e&&Hg(b,c,!0);return b.child}function sh(a){var b=a.stateNode;b.pendingContext?Fg(a,b.pendingContext,b.pendingContext!==b.context):b.context&&Fg(a,b.context,!1);se(a,b.containerInfo)}function th(a,b,c){var d=b.mode,e=b.pendingProps,f=D.current,g=!1,h;(h=0!==(b.effectTag&64))||(h=0!==(f&2)&&(null===a||null!==a.memoizedState));h?(g=!0,b.effectTag&=-65):null!==a&&null===
a.memoizedState||void 0===e.fallback||!0===e.unstable_avoidThisFallback||(f|=1);y(D,f&1);if(null===a){void 0!==e.fallback&&De(b);if(g){g=e.fallback;e=Ha(null,d,0,null);e.return=b;if(0===(b.mode&2))for(a=null!==b.memoizedState?b.child.child:b.child,e.child=a;null!==a;)a.return=e,a=a.sibling;c=Ha(g,d,c,null);c.return=b;e.sibling=c;b.memoizedState=Je;b.child=e;return c}d=e.children;b.memoizedState=null;return b.child=Fe(b,null,d,c)}if(null!==a.memoizedState){a=a.child;d=a.sibling;if(g){e=e.fallback;
c=Sa(a,a.pendingProps);c.return=b;if(0===(b.mode&2)&&(g=null!==b.memoizedState?b.child.child:b.child,g!==a.child))for(c.child=g;null!==g;)g.return=c,g=g.sibling;d=Sa(d,e);d.return=b;c.sibling=d;c.childExpirationTime=0;b.memoizedState=Je;b.child=c;return d}c=wb(b,a.child,e.children,c);b.memoizedState=null;return b.child=c}a=a.child;if(g){g=e.fallback;e=Ha(null,d,0,null);e.return=b;e.child=a;null!==a&&(a.return=e);if(0===(b.mode&2))for(a=null!==b.memoizedState?b.child.child:b.child,e.child=a;null!==
a;)a.return=e,a=a.sibling;c=Ha(g,d,c,null);c.return=b;e.sibling=c;c.effectTag|=2;e.childExpirationTime=0;b.memoizedState=Je;b.child=e;return c}b.memoizedState=null;return b.child=wb(b,a,e.children,c)}function uh(a,b){a.expirationTime<b&&(a.expirationTime=b);var c=a.alternate;null!==c&&c.expirationTime<b&&(c.expirationTime=b);Sg(a.return,b)}function Ke(a,b,c,d,e,f){var g=a.memoizedState;null===g?a.memoizedState={isBackwards:b,rendering:null,renderingStartTime:0,last:d,tail:c,tailExpiration:0,tailMode:e,
lastEffect:f}:(g.isBackwards=b,g.rendering=null,g.renderingStartTime=0,g.last=d,g.tail=c,g.tailExpiration=0,g.tailMode=e,g.lastEffect=f)}function vh(a,b,c){var d=b.pendingProps,e=d.revealOrder,f=d.tail;T(a,b,d.children,c);d=D.current;if(0!==(d&2))d=d&1|2,b.effectTag|=64;else{if(null!==a&&0!==(a.effectTag&64))a:for(a=b.child;null!==a;){if(13===a.tag)null!==a.memoizedState&&uh(a,c);else if(19===a.tag)uh(a,c);else if(null!==a.child){a.child.return=a;a=a.child;continue}if(a===b)break a;for(;null===a.sibling;){if(null===
a.return||a.return===b)break a;a=a.return}a.sibling.return=a.return;a=a.sibling}d&=1}y(D,d);if(0===(b.mode&2))b.memoizedState=null;else switch(e){case "forwards":c=b.child;for(e=null;null!==c;)a=c.alternate,null!==a&&null===Rc(a)&&(e=c),c=c.sibling;c=e;null===c?(e=b.child,b.child=null):(e=c.sibling,c.sibling=null);Ke(b,!1,e,c,f,b.lastEffect);break;case "backwards":c=null;e=b.child;for(b.child=null;null!==e;){a=e.alternate;if(null!==a&&null===Rc(a)){b.child=e;break}a=e.sibling;e.sibling=c;c=e;e=a}Ke(b,
!0,c,null,f,b.lastEffect);break;case "together":Ke(b,!1,null,null,void 0,b.lastEffect);break;default:b.memoizedState=null}return b.child}function sa(a,b,c){null!==a&&(b.dependencies=a.dependencies);var d=b.expirationTime;0!==d&&Kc(d);if(b.childExpirationTime<c)return null;if(null!==a&&b.child!==a.child)throw Error(k(153));if(null!==b.child){a=b.child;c=Sa(a,a.pendingProps);b.child=c;for(c.return=b;null!==a.sibling;)a=a.sibling,c=c.sibling=Sa(a,a.pendingProps),c.return=b;c.sibling=null}return b.child}
function $c(a,b){switch(a.tailMode){case "hidden":b=a.tail;for(var c=null;null!==b;)null!==b.alternate&&(c=b),b=b.sibling;null===c?a.tail=null:c.sibling=null;break;case "collapsed":c=a.tail;for(var d=null;null!==c;)null!==c.alternate&&(d=c),c=c.sibling;null===d?b||null===a.tail?a.tail=null:a.tail.sibling=null:d.sibling=null}}function hj(a,b,c){var d=b.pendingProps;switch(b.tag){case 2:case 16:case 15:case 0:case 11:case 7:case 8:case 12:case 9:case 14:return null;case 1:return N(b.type)&&(q(G),q(B)),
null;case 3:return tb(),q(G),q(B),c=b.stateNode,c.pendingContext&&(c.context=c.pendingContext,c.pendingContext=null),null!==a&&null!==a.child||!Zc(b)||(b.effectTag|=4),wh(b),null;case 5:te(b);c=Ta(Tb.current);var e=b.type;if(null!==a&&null!=b.stateNode)ij(a,b,e,d,c),a.ref!==b.ref&&(b.effectTag|=128);else{if(!d){if(null===b.stateNode)throw Error(k(166));return null}a=Ta(ja.current);if(Zc(b)){d=b.stateNode;e=b.type;var f=b.memoizedProps;d[Aa]=b;d[vc]=f;switch(e){case "iframe":case "object":case "embed":w("load",
d);break;case "video":case "audio":for(a=0;a<Db.length;a++)w(Db[a],d);break;case "source":w("error",d);break;case "img":case "image":case "link":w("error",d);w("load",d);break;case "form":w("reset",d);w("submit",d);break;case "details":w("toggle",d);break;case "input":Hf(d,f);w("invalid",d);oa(c,"onChange");break;case "select":d._wrapperState={wasMultiple:!!f.multiple};w("invalid",d);oa(c,"onChange");break;case "textarea":Kf(d,f),w("invalid",d),oa(c,"onChange")}Ud(e,f);a=null;for(var g in f)if(f.hasOwnProperty(g)){var h=
f[g];"children"===g?"string"===typeof h?d.textContent!==h&&(a=["children",h]):"number"===typeof h&&d.textContent!==""+h&&(a=["children",""+h]):db.hasOwnProperty(g)&&null!=h&&oa(c,g)}switch(e){case "input":mc(d);Jf(d,f,!0);break;case "textarea":mc(d);Mf(d);break;case "select":case "option":break;default:"function"===typeof f.onClick&&(d.onclick=uc)}c=a;b.updateQueue=c;null!==c&&(b.effectTag|=4)}else{g=9===c.nodeType?c:c.ownerDocument;"http://www.w3.org/1999/xhtml"===a&&(a=Nf(e));"http://www.w3.org/1999/xhtml"===
a?"script"===e?(a=g.createElement("div"),a.innerHTML="<script>\x3c/script>",a=a.removeChild(a.firstChild)):"string"===typeof d.is?a=g.createElement(e,{is:d.is}):(a=g.createElement(e),"select"===e&&(g=a,d.multiple?g.multiple=!0:d.size&&(g.size=d.size))):a=g.createElementNS(a,e);a[Aa]=b;a[vc]=d;jj(a,b,!1,!1);b.stateNode=a;g=Vd(e,d);switch(e){case "iframe":case "object":case "embed":w("load",a);h=d;break;case "video":case "audio":for(h=0;h<Db.length;h++)w(Db[h],a);h=d;break;case "source":w("error",a);
h=d;break;case "img":case "image":case "link":w("error",a);w("load",a);h=d;break;case "form":w("reset",a);w("submit",a);h=d;break;case "details":w("toggle",a);h=d;break;case "input":Hf(a,d);h=Cd(a,d);w("invalid",a);oa(c,"onChange");break;case "option":h=Fd(a,d);break;case "select":a._wrapperState={wasMultiple:!!d.multiple};h=M({},d,{value:void 0});w("invalid",a);oa(c,"onChange");break;case "textarea":Kf(a,d);h=Gd(a,d);w("invalid",a);oa(c,"onChange");break;default:h=d}Ud(e,h);var m=h;for(f in m)if(m.hasOwnProperty(f)){var n=
m[f];"style"===f?gg(a,n):"dangerouslySetInnerHTML"===f?(n=n?n.__html:void 0,null!=n&&xh(a,n)):"children"===f?"string"===typeof n?("textarea"!==e||""!==n)&&Wb(a,n):"number"===typeof n&&Wb(a,""+n):"suppressContentEditableWarning"!==f&&"suppressHydrationWarning"!==f&&"autoFocus"!==f&&(db.hasOwnProperty(f)?null!=n&&oa(c,f):null!=n&&xd(a,f,n,g))}switch(e){case "input":mc(a);Jf(a,d,!1);break;case "textarea":mc(a);Mf(a);break;case "option":null!=d.value&&a.setAttribute("value",""+va(d.value));break;case "select":a.multiple=
!!d.multiple;c=d.value;null!=c?hb(a,!!d.multiple,c,!1):null!=d.defaultValue&&hb(a,!!d.multiple,d.defaultValue,!0);break;default:"function"===typeof h.onClick&&(a.onclick=uc)}lg(e,d)&&(b.effectTag|=4)}null!==b.ref&&(b.effectTag|=128)}return null;case 6:if(a&&null!=b.stateNode)kj(a,b,a.memoizedProps,d);else{if("string"!==typeof d&&null===b.stateNode)throw Error(k(166));c=Ta(Tb.current);Ta(ja.current);Zc(b)?(c=b.stateNode,d=b.memoizedProps,c[Aa]=b,c.nodeValue!==d&&(b.effectTag|=4)):(c=(9===c.nodeType?
c:c.ownerDocument).createTextNode(d),c[Aa]=b,b.stateNode=c)}return null;case 13:q(D);d=b.memoizedState;if(0!==(b.effectTag&64))return b.expirationTime=c,b;c=null!==d;d=!1;null===a?void 0!==b.memoizedProps.fallback&&Zc(b):(e=a.memoizedState,d=null!==e,c||null===e||(e=a.child.sibling,null!==e&&(f=b.firstEffect,null!==f?(b.firstEffect=e,e.nextEffect=f):(b.firstEffect=b.lastEffect=e,e.nextEffect=null),e.effectTag=8)));if(c&&!d&&0!==(b.mode&2))if(null===a&&!0!==b.memoizedProps.unstable_avoidThisFallback||
0!==(D.current&1))F===Xa&&(F=ad);else{if(F===Xa||F===ad)F=bd;0!==Xb&&null!==U&&(Ya(U,P),yh(U,Xb))}if(c||d)b.effectTag|=4;return null;case 4:return tb(),wh(b),null;case 10:return me(b),null;case 17:return N(b.type)&&(q(G),q(B)),null;case 19:q(D);d=b.memoizedState;if(null===d)return null;e=0!==(b.effectTag&64);f=d.rendering;if(null===f)if(e)$c(d,!1);else{if(F!==Xa||null!==a&&0!==(a.effectTag&64))for(f=b.child;null!==f;){a=Rc(f);if(null!==a){b.effectTag|=64;$c(d,!1);e=a.updateQueue;null!==e&&(b.updateQueue=
e,b.effectTag|=4);null===d.lastEffect&&(b.firstEffect=null);b.lastEffect=d.lastEffect;for(d=b.child;null!==d;)e=d,f=c,e.effectTag&=2,e.nextEffect=null,e.firstEffect=null,e.lastEffect=null,a=e.alternate,null===a?(e.childExpirationTime=0,e.expirationTime=f,e.child=null,e.memoizedProps=null,e.memoizedState=null,e.updateQueue=null,e.dependencies=null):(e.childExpirationTime=a.childExpirationTime,e.expirationTime=a.expirationTime,e.child=a.child,e.memoizedProps=a.memoizedProps,e.memoizedState=a.memoizedState,
e.updateQueue=a.updateQueue,f=a.dependencies,e.dependencies=null===f?null:{expirationTime:f.expirationTime,firstContext:f.firstContext,responders:f.responders}),d=d.sibling;y(D,D.current&1|2);return b.child}f=f.sibling}}else{if(!e)if(a=Rc(f),null!==a){if(b.effectTag|=64,e=!0,c=a.updateQueue,null!==c&&(b.updateQueue=c,b.effectTag|=4),$c(d,!0),null===d.tail&&"hidden"===d.tailMode&&!f.alternate)return b=b.lastEffect=d.lastEffect,null!==b&&(b.nextEffect=null),null}else 2*Y()-d.renderingStartTime>d.tailExpiration&&
1<c&&(b.effectTag|=64,e=!0,$c(d,!1),b.expirationTime=b.childExpirationTime=c-1);d.isBackwards?(f.sibling=b.child,b.child=f):(c=d.last,null!==c?c.sibling=f:b.child=f,d.last=f)}return null!==d.tail?(0===d.tailExpiration&&(d.tailExpiration=Y()+500),c=d.tail,d.rendering=c,d.tail=c.sibling,d.lastEffect=b.lastEffect,d.renderingStartTime=Y(),c.sibling=null,b=D.current,y(D,e?b&1|2:b&1),c):null}throw Error(k(156,b.tag));}function lj(a,b){switch(a.tag){case 1:return N(a.type)&&(q(G),q(B)),b=a.effectTag,b&4096?
(a.effectTag=b&-4097|64,a):null;case 3:tb();q(G);q(B);b=a.effectTag;if(0!==(b&64))throw Error(k(285));a.effectTag=b&-4097|64;return a;case 5:return te(a),null;case 13:return q(D),b=a.effectTag,b&4096?(a.effectTag=b&-4097|64,a):null;case 19:return q(D),null;case 4:return tb(),null;case 10:return me(a),null;default:return null}}function Le(a,b){return{value:a,source:b,stack:Bd(b)}}function Me(a,b){var c=b.source,d=b.stack;null===d&&null!==c&&(d=Bd(c));null!==c&&na(c.type);b=b.value;null!==a&&1===a.tag&&
na(a.type);try{console.error(b)}catch(e){setTimeout(function(){throw e;})}}function mj(a,b){try{b.props=a.memoizedProps,b.state=a.memoizedState,b.componentWillUnmount()}catch(c){Za(a,c)}}function zh(a){var b=a.ref;if(null!==b)if("function"===typeof b)try{b(null)}catch(c){Za(a,c)}else b.current=null}function nj(a,b){switch(b.tag){case 0:case 11:case 15:case 22:return;case 1:if(b.effectTag&256&&null!==a){var c=a.memoizedProps,d=a.memoizedState;a=b.stateNode;b=a.getSnapshotBeforeUpdate(b.elementType===
b.type?c:aa(b.type,c),d);a.__reactInternalSnapshotBeforeUpdate=b}return;case 3:case 5:case 6:case 4:case 17:return}throw Error(k(163));}function Ah(a,b){b=b.updateQueue;b=null!==b?b.lastEffect:null;if(null!==b){var c=b=b.next;do{if((c.tag&a)===a){var d=c.destroy;c.destroy=void 0;void 0!==d&&d()}c=c.next}while(c!==b)}}function Bh(a,b){b=b.updateQueue;b=null!==b?b.lastEffect:null;if(null!==b){var c=b=b.next;do{if((c.tag&a)===a){var d=c.create;c.destroy=d()}c=c.next}while(c!==b)}}function oj(a,b,c,d){switch(c.tag){case 0:case 11:case 15:case 22:Bh(3,
c);return;case 1:a=c.stateNode;c.effectTag&4&&(null===b?a.componentDidMount():(d=c.elementType===c.type?b.memoizedProps:aa(c.type,b.memoizedProps),a.componentDidUpdate(d,b.memoizedState,a.__reactInternalSnapshotBeforeUpdate)));b=c.updateQueue;null!==b&&Wg(c,b,a);return;case 3:b=c.updateQueue;if(null!==b){a=null;if(null!==c.child)switch(c.child.tag){case 5:a=c.child.stateNode;break;case 1:a=c.child.stateNode}Wg(c,b,a)}return;case 5:a=c.stateNode;null===b&&c.effectTag&4&&lg(c.type,c.memoizedProps)&&
a.focus();return;case 6:return;case 4:return;case 12:return;case 13:null===c.memoizedState&&(c=c.alternate,null!==c&&(c=c.memoizedState,null!==c&&(c=c.dehydrated,null!==c&&bg(c))));return;case 19:case 17:case 20:case 21:return}throw Error(k(163));}function Ch(a,b,c){"function"===typeof Ne&&Ne(b);switch(b.tag){case 0:case 11:case 14:case 15:case 22:a=b.updateQueue;if(null!==a&&(a=a.lastEffect,null!==a)){var d=a.next;Da(97<c?97:c,function(){var a=d;do{var c=a.destroy;if(void 0!==c){var g=b;try{c()}catch(h){Za(g,
h)}}a=a.next}while(a!==d)})}break;case 1:zh(b);c=b.stateNode;"function"===typeof c.componentWillUnmount&&mj(b,c);break;case 5:zh(b);break;case 4:Dh(a,b,c)}}function Eh(a){var b=a.alternate;a.return=null;a.child=null;a.memoizedState=null;a.updateQueue=null;a.dependencies=null;a.alternate=null;a.firstEffect=null;a.lastEffect=null;a.pendingProps=null;a.memoizedProps=null;a.stateNode=null;null!==b&&Eh(b)}function Fh(a){return 5===a.tag||3===a.tag||4===a.tag}function Gh(a){a:{for(var b=a.return;null!==
b;){if(Fh(b)){var c=b;break a}b=b.return}throw Error(k(160));}b=c.stateNode;switch(c.tag){case 5:var d=!1;break;case 3:b=b.containerInfo;d=!0;break;case 4:b=b.containerInfo;d=!0;break;default:throw Error(k(161));}c.effectTag&16&&(Wb(b,""),c.effectTag&=-17);a:b:for(c=a;;){for(;null===c.sibling;){if(null===c.return||Fh(c.return)){c=null;break a}c=c.return}c.sibling.return=c.return;for(c=c.sibling;5!==c.tag&&6!==c.tag&&18!==c.tag;){if(c.effectTag&2)continue b;if(null===c.child||4===c.tag)continue b;
else c.child.return=c,c=c.child}if(!(c.effectTag&2)){c=c.stateNode;break a}}d?Oe(a,c,b):Pe(a,c,b)}function Oe(a,b,c){var d=a.tag,e=5===d||6===d;if(e)a=e?a.stateNode:a.stateNode.instance,b?8===c.nodeType?c.parentNode.insertBefore(a,b):c.insertBefore(a,b):(8===c.nodeType?(b=c.parentNode,b.insertBefore(a,c)):(b=c,b.appendChild(a)),c=c._reactRootContainer,null!==c&&void 0!==c||null!==b.onclick||(b.onclick=uc));else if(4!==d&&(a=a.child,null!==a))for(Oe(a,b,c),a=a.sibling;null!==a;)Oe(a,b,c),a=a.sibling}
function Pe(a,b,c){var d=a.tag,e=5===d||6===d;if(e)a=e?a.stateNode:a.stateNode.instance,b?c.insertBefore(a,b):c.appendChild(a);else if(4!==d&&(a=a.child,null!==a))for(Pe(a,b,c),a=a.sibling;null!==a;)Pe(a,b,c),a=a.sibling}function Dh(a,b,c){for(var d=b,e=!1,f,g;;){if(!e){e=d.return;a:for(;;){if(null===e)throw Error(k(160));f=e.stateNode;switch(e.tag){case 5:g=!1;break a;case 3:f=f.containerInfo;g=!0;break a;case 4:f=f.containerInfo;g=!0;break a}e=e.return}e=!0}if(5===d.tag||6===d.tag){a:for(var h=
a,m=d,n=c,l=m;;)if(Ch(h,l,n),null!==l.child&&4!==l.tag)l.child.return=l,l=l.child;else{if(l===m)break a;for(;null===l.sibling;){if(null===l.return||l.return===m)break a;l=l.return}l.sibling.return=l.return;l=l.sibling}g?(h=f,m=d.stateNode,8===h.nodeType?h.parentNode.removeChild(m):h.removeChild(m)):f.removeChild(d.stateNode)}else if(4===d.tag){if(null!==d.child){f=d.stateNode.containerInfo;g=!0;d.child.return=d;d=d.child;continue}}else if(Ch(a,d,c),null!==d.child){d.child.return=d;d=d.child;continue}if(d===
b)break;for(;null===d.sibling;){if(null===d.return||d.return===b)return;d=d.return;4===d.tag&&(e=!1)}d.sibling.return=d.return;d=d.sibling}}function Qe(a,b){switch(b.tag){case 0:case 11:case 14:case 15:case 22:Ah(3,b);return;case 1:return;case 5:var c=b.stateNode;if(null!=c){var d=b.memoizedProps,e=null!==a?a.memoizedProps:d;a=b.type;var f=b.updateQueue;b.updateQueue=null;if(null!==f){c[vc]=d;"input"===a&&"radio"===d.type&&null!=d.name&&If(c,d);Vd(a,e);b=Vd(a,d);for(e=0;e<f.length;e+=2){var g=f[e],
h=f[e+1];"style"===g?gg(c,h):"dangerouslySetInnerHTML"===g?xh(c,h):"children"===g?Wb(c,h):xd(c,g,h,b)}switch(a){case "input":Dd(c,d);break;case "textarea":Lf(c,d);break;case "select":b=c._wrapperState.wasMultiple,c._wrapperState.wasMultiple=!!d.multiple,a=d.value,null!=a?hb(c,!!d.multiple,a,!1):b!==!!d.multiple&&(null!=d.defaultValue?hb(c,!!d.multiple,d.defaultValue,!0):hb(c,!!d.multiple,d.multiple?[]:"",!1))}}}return;case 6:if(null===b.stateNode)throw Error(k(162));b.stateNode.nodeValue=b.memoizedProps;
return;case 3:b=b.stateNode;b.hydrate&&(b.hydrate=!1,bg(b.containerInfo));return;case 12:return;case 13:c=b;null===b.memoizedState?d=!1:(d=!0,c=b.child,Re=Y());if(null!==c)a:for(a=c;;){if(5===a.tag)f=a.stateNode,d?(f=f.style,"function"===typeof f.setProperty?f.setProperty("display","none","important"):f.display="none"):(f=a.stateNode,e=a.memoizedProps.style,e=void 0!==e&&null!==e&&e.hasOwnProperty("display")?e.display:null,f.style.display=fg("display",e));else if(6===a.tag)a.stateNode.nodeValue=d?
"":a.memoizedProps;else if(13===a.tag&&null!==a.memoizedState&&null===a.memoizedState.dehydrated){f=a.child.sibling;f.return=a;a=f;continue}else if(null!==a.child){a.child.return=a;a=a.child;continue}if(a===c)break;for(;null===a.sibling;){if(null===a.return||a.return===c)break a;a=a.return}a.sibling.return=a.return;a=a.sibling}Hh(b);return;case 19:Hh(b);return;case 17:return}throw Error(k(163));}function Hh(a){var b=a.updateQueue;if(null!==b){a.updateQueue=null;var c=a.stateNode;null===c&&(c=a.stateNode=
new pj);b.forEach(function(b){var d=qj.bind(null,a,b);c.has(b)||(c.add(b),b.then(d,d))})}}function Ih(a,b,c){c=Ea(c,null);c.tag=3;c.payload={element:null};var d=b.value;c.callback=function(){cd||(cd=!0,Se=d);Me(a,b)};return c}function Jh(a,b,c){c=Ea(c,null);c.tag=3;var d=a.type.getDerivedStateFromError;if("function"===typeof d){var e=b.value;c.payload=function(){Me(a,b);return d(e)}}var f=a.stateNode;null!==f&&"function"===typeof f.componentDidCatch&&(c.callback=function(){"function"!==typeof d&&
(null===La?La=new Set([this]):La.add(this),Me(a,b));var c=b.stack;this.componentDidCatch(b.value,{componentStack:null!==c?c:""})});return c}function ka(){return(p&(ca|ma))!==H?1073741821-(Y()/10|0):0!==dd?dd:dd=1073741821-(Y()/10|0)}function Va(a,b,c){b=b.mode;if(0===(b&2))return 1073741823;var d=Cc();if(0===(b&4))return 99===d?1073741823:1073741822;if((p&ca)!==H)return P;if(null!==c)a=Fc(a,c.timeoutMs|0||5E3,250);else switch(d){case 99:a=1073741823;break;case 98:a=Fc(a,150,100);break;case 97:case 96:a=
Fc(a,5E3,250);break;case 95:a=2;break;default:throw Error(k(326));}null!==U&&a===P&&--a;return a}function ed(a,b){a.expirationTime<b&&(a.expirationTime=b);var c=a.alternate;null!==c&&c.expirationTime<b&&(c.expirationTime=b);var d=a.return,e=null;if(null===d&&3===a.tag)e=a.stateNode;else for(;null!==d;){c=d.alternate;d.childExpirationTime<b&&(d.childExpirationTime=b);null!==c&&c.childExpirationTime<b&&(c.childExpirationTime=b);if(null===d.return&&3===d.tag){e=d.stateNode;break}d=d.return}null!==e&&
(U===e&&(Kc(b),F===bd&&Ya(e,P)),yh(e,b));return e}function fd(a){var b=a.lastExpiredTime;if(0!==b)return b;b=a.firstPendingTime;if(!Kh(a,b))return b;var c=a.lastPingedTime;a=a.nextKnownPendingLevel;a=c>a?c:a;return 2>=a&&b!==a?0:a}function V(a){if(0!==a.lastExpiredTime)a.callbackExpirationTime=1073741823,a.callbackPriority=99,a.callbackNode=Og(Te.bind(null,a));else{var b=fd(a),c=a.callbackNode;if(0===b)null!==c&&(a.callbackNode=null,a.callbackExpirationTime=0,a.callbackPriority=90);else{var d=ka();
1073741823===b?d=99:1===b||2===b?d=95:(d=10*(1073741821-b)-10*(1073741821-d),d=0>=d?99:250>=d?98:5250>=d?97:95);if(null!==c){var e=a.callbackPriority;if(a.callbackExpirationTime===b&&e>=d)return;c!==Qg&&Rg(c)}a.callbackExpirationTime=b;a.callbackPriority=d;b=1073741823===b?Og(Te.bind(null,a)):Ng(d,Lh.bind(null,a),{timeout:10*(1073741821-b)-Y()});a.callbackNode=b}}}function Lh(a,b){dd=0;if(b)return b=ka(),Ue(a,b),V(a),null;var c=fd(a);if(0!==c){b=a.callbackNode;if((p&(ca|ma))!==H)throw Error(k(327));
xb();a===U&&c===P||$a(a,c);if(null!==t){var d=p;p|=ca;var e=Mh();do try{rj();break}catch(h){Nh(a,h)}while(1);le();p=d;gd.current=e;if(F===hd)throw b=id,$a(a,c),Ya(a,c),V(a),b;if(null===t)switch(e=a.finishedWork=a.current.alternate,a.finishedExpirationTime=c,d=F,U=null,d){case Xa:case hd:throw Error(k(345));case Oh:Ue(a,2<c?2:c);break;case ad:Ya(a,c);d=a.lastSuspendedTime;c===d&&(a.nextKnownPendingLevel=Ve(e));if(1073741823===ta&&(e=Re+Ph-Y(),10<e)){if(jd){var f=a.lastPingedTime;if(0===f||f>=c){a.lastPingedTime=
c;$a(a,c);break}}f=fd(a);if(0!==f&&f!==c)break;if(0!==d&&d!==c){a.lastPingedTime=d;break}a.timeoutHandle=We(ab.bind(null,a),e);break}ab(a);break;case bd:Ya(a,c);d=a.lastSuspendedTime;c===d&&(a.nextKnownPendingLevel=Ve(e));if(jd&&(e=a.lastPingedTime,0===e||e>=c)){a.lastPingedTime=c;$a(a,c);break}e=fd(a);if(0!==e&&e!==c)break;if(0!==d&&d!==c){a.lastPingedTime=d;break}1073741823!==Yb?d=10*(1073741821-Yb)-Y():1073741823===ta?d=0:(d=10*(1073741821-ta)-5E3,e=Y(),c=10*(1073741821-c)-e,d=e-d,0>d&&(d=0),d=
(120>d?120:480>d?480:1080>d?1080:1920>d?1920:3E3>d?3E3:4320>d?4320:1960*sj(d/1960))-d,c<d&&(d=c));if(10<d){a.timeoutHandle=We(ab.bind(null,a),d);break}ab(a);break;case Xe:if(1073741823!==ta&&null!==kd){f=ta;var g=kd;d=g.busyMinDurationMs|0;0>=d?d=0:(e=g.busyDelayMs|0,f=Y()-(10*(1073741821-f)-(g.timeoutMs|0||5E3)),d=f<=e?0:e+d-f);if(10<d){Ya(a,c);a.timeoutHandle=We(ab.bind(null,a),d);break}}ab(a);break;default:throw Error(k(329));}V(a);if(a.callbackNode===b)return Lh.bind(null,a)}}return null}function Te(a){var b=
a.lastExpiredTime;b=0!==b?b:1073741823;if((p&(ca|ma))!==H)throw Error(k(327));xb();a===U&&b===P||$a(a,b);if(null!==t){var c=p;p|=ca;var d=Mh();do try{tj();break}catch(e){Nh(a,e)}while(1);le();p=c;gd.current=d;if(F===hd)throw c=id,$a(a,b),Ya(a,b),V(a),c;if(null!==t)throw Error(k(261));a.finishedWork=a.current.alternate;a.finishedExpirationTime=b;U=null;ab(a);V(a)}return null}function uj(){if(null!==bb){var a=bb;bb=null;a.forEach(function(a,c){Ue(c,a);V(c)});ha()}}function Qh(a,b){var c=p;p|=1;try{return a(b)}finally{p=
c,p===H&&ha()}}function Rh(a,b){var c=p;p&=-2;p|=Ye;try{return a(b)}finally{p=c,p===H&&ha()}}function $a(a,b){a.finishedWork=null;a.finishedExpirationTime=0;var c=a.timeoutHandle;-1!==c&&(a.timeoutHandle=-1,vj(c));if(null!==t)for(c=t.return;null!==c;){var d=c;switch(d.tag){case 1:d=d.type.childContextTypes;null!==d&&void 0!==d&&(q(G),q(B));break;case 3:tb();q(G);q(B);break;case 5:te(d);break;case 4:tb();break;case 13:q(D);break;case 19:q(D);break;case 10:me(d)}c=c.return}U=a;t=Sa(a.current,null);
P=b;F=Xa;id=null;Yb=ta=1073741823;kd=null;Xb=0;jd=!1}function Nh(a,b){do{try{le();Sc.current=Tc;if(Uc)for(var c=z.memoizedState;null!==c;){var d=c.queue;null!==d&&(d.pending=null);c=c.next}Ia=0;J=K=z=null;Uc=!1;if(null===t||null===t.return)return F=hd,id=b,t=null;a:{var e=a,f=t.return,g=t,h=b;b=P;g.effectTag|=2048;g.firstEffect=g.lastEffect=null;if(null!==h&&"object"===typeof h&&"function"===typeof h.then){var m=h;if(0===(g.mode&2)){var n=g.alternate;n?(g.updateQueue=n.updateQueue,g.memoizedState=
n.memoizedState,g.expirationTime=n.expirationTime):(g.updateQueue=null,g.memoizedState=null)}var l=0!==(D.current&1),k=f;do{var p;if(p=13===k.tag){var q=k.memoizedState;if(null!==q)p=null!==q.dehydrated?!0:!1;else{var w=k.memoizedProps;p=void 0===w.fallback?!1:!0!==w.unstable_avoidThisFallback?!0:l?!1:!0}}if(p){var y=k.updateQueue;if(null===y){var r=new Set;r.add(m);k.updateQueue=r}else y.add(m);if(0===(k.mode&2)){k.effectTag|=64;g.effectTag&=-2981;if(1===g.tag)if(null===g.alternate)g.tag=17;else{var O=
Ea(1073741823,null);O.tag=Jc;Fa(g,O)}g.expirationTime=1073741823;break a}h=void 0;g=b;var v=e.pingCache;null===v?(v=e.pingCache=new wj,h=new Set,v.set(m,h)):(h=v.get(m),void 0===h&&(h=new Set,v.set(m,h)));if(!h.has(g)){h.add(g);var x=xj.bind(null,e,m,g);m.then(x,x)}k.effectTag|=4096;k.expirationTime=b;break a}k=k.return}while(null!==k);h=Error((na(g.type)||"A React component")+" suspended while rendering, but no fallback UI was specified.\n\nAdd a <Suspense fallback=...> component higher in the tree to provide a loading indicator or placeholder to display."+
Bd(g))}F!==Xe&&(F=Oh);h=Le(h,g);k=f;do{switch(k.tag){case 3:m=h;k.effectTag|=4096;k.expirationTime=b;var A=Ih(k,m,b);Ug(k,A);break a;case 1:m=h;var u=k.type,B=k.stateNode;if(0===(k.effectTag&64)&&("function"===typeof u.getDerivedStateFromError||null!==B&&"function"===typeof B.componentDidCatch&&(null===La||!La.has(B)))){k.effectTag|=4096;k.expirationTime=b;var H=Jh(k,m,b);Ug(k,H);break a}}k=k.return}while(null!==k)}t=Sh(t)}catch(cj){b=cj;continue}break}while(1)}function Mh(a){a=gd.current;gd.current=
Tc;return null===a?Tc:a}function Vg(a,b){a<ta&&2<a&&(ta=a);null!==b&&a<Yb&&2<a&&(Yb=a,kd=b)}function Kc(a){a>Xb&&(Xb=a)}function tj(){for(;null!==t;)t=Th(t)}function rj(){for(;null!==t&&!yj();)t=Th(t)}function Th(a){var b=zj(a.alternate,a,P);a.memoizedProps=a.pendingProps;null===b&&(b=Sh(a));Uh.current=null;return b}function Sh(a){t=a;do{var b=t.alternate;a=t.return;if(0===(t.effectTag&2048)){b=hj(b,t,P);if(1===P||1!==t.childExpirationTime){for(var c=0,d=t.child;null!==d;){var e=d.expirationTime,
f=d.childExpirationTime;e>c&&(c=e);f>c&&(c=f);d=d.sibling}t.childExpirationTime=c}if(null!==b)return b;null!==a&&0===(a.effectTag&2048)&&(null===a.firstEffect&&(a.firstEffect=t.firstEffect),null!==t.lastEffect&&(null!==a.lastEffect&&(a.lastEffect.nextEffect=t.firstEffect),a.lastEffect=t.lastEffect),1<t.effectTag&&(null!==a.lastEffect?a.lastEffect.nextEffect=t:a.firstEffect=t,a.lastEffect=t))}else{b=lj(t);if(null!==b)return b.effectTag&=2047,b;null!==a&&(a.firstEffect=a.lastEffect=null,a.effectTag|=
2048)}b=t.sibling;if(null!==b)return b;t=a}while(null!==t);F===Xa&&(F=Xe);return null}function Ve(a){var b=a.expirationTime;a=a.childExpirationTime;return b>a?b:a}function ab(a){var b=Cc();Da(99,Aj.bind(null,a,b));return null}function Aj(a,b){do xb();while(null!==Zb);if((p&(ca|ma))!==H)throw Error(k(327));var c=a.finishedWork,d=a.finishedExpirationTime;if(null===c)return null;a.finishedWork=null;a.finishedExpirationTime=0;if(c===a.current)throw Error(k(177));a.callbackNode=null;a.callbackExpirationTime=
0;a.callbackPriority=90;a.nextKnownPendingLevel=0;var e=Ve(c);a.firstPendingTime=e;d<=a.lastSuspendedTime?a.firstSuspendedTime=a.lastSuspendedTime=a.nextKnownPendingLevel=0:d<=a.firstSuspendedTime&&(a.firstSuspendedTime=d-1);d<=a.lastPingedTime&&(a.lastPingedTime=0);d<=a.lastExpiredTime&&(a.lastExpiredTime=0);a===U&&(t=U=null,P=0);1<c.effectTag?null!==c.lastEffect?(c.lastEffect.nextEffect=c,e=c.firstEffect):e=c:e=c.firstEffect;if(null!==e){var f=p;p|=ma;Uh.current=null;Ze=tc;var g=kg();if(Xd(g)){if("selectionStart"in
g)var h={start:g.selectionStart,end:g.selectionEnd};else a:{h=(h=g.ownerDocument)&&h.defaultView||window;var m=h.getSelection&&h.getSelection();if(m&&0!==m.rangeCount){h=m.anchorNode;var n=m.anchorOffset,q=m.focusNode;m=m.focusOffset;try{h.nodeType,q.nodeType}catch(sb){h=null;break a}var ba=0,w=-1,y=-1,B=0,D=0,r=g,z=null;b:for(;;){for(var v;;){r!==h||0!==n&&3!==r.nodeType||(w=ba+n);r!==q||0!==m&&3!==r.nodeType||(y=ba+m);3===r.nodeType&&(ba+=r.nodeValue.length);if(null===(v=r.firstChild))break;z=r;
r=v}for(;;){if(r===g)break b;z===h&&++B===n&&(w=ba);z===q&&++D===m&&(y=ba);if(null!==(v=r.nextSibling))break;r=z;z=r.parentNode}r=v}h=-1===w||-1===y?null:{start:w,end:y}}else h=null}h=h||{start:0,end:0}}else h=null;$e={activeElementDetached:null,focusedElem:g,selectionRange:h};tc=!1;l=e;do try{Bj()}catch(sb){if(null===l)throw Error(k(330));Za(l,sb);l=l.nextEffect}while(null!==l);l=e;do try{for(g=a,h=b;null!==l;){var x=l.effectTag;x&16&&Wb(l.stateNode,"");if(x&128){var A=l.alternate;if(null!==A){var u=
A.ref;null!==u&&("function"===typeof u?u(null):u.current=null)}}switch(x&1038){case 2:Gh(l);l.effectTag&=-3;break;case 6:Gh(l);l.effectTag&=-3;Qe(l.alternate,l);break;case 1024:l.effectTag&=-1025;break;case 1028:l.effectTag&=-1025;Qe(l.alternate,l);break;case 4:Qe(l.alternate,l);break;case 8:n=l,Dh(g,n,h),Eh(n)}l=l.nextEffect}}catch(sb){if(null===l)throw Error(k(330));Za(l,sb);l=l.nextEffect}while(null!==l);u=$e;A=kg();x=u.focusedElem;h=u.selectionRange;if(A!==x&&x&&x.ownerDocument&&jg(x.ownerDocument.documentElement,
x)){null!==h&&Xd(x)&&(A=h.start,u=h.end,void 0===u&&(u=A),"selectionStart"in x?(x.selectionStart=A,x.selectionEnd=Math.min(u,x.value.length)):(u=(A=x.ownerDocument||document)&&A.defaultView||window,u.getSelection&&(u=u.getSelection(),n=x.textContent.length,g=Math.min(h.start,n),h=void 0===h.end?g:Math.min(h.end,n),!u.extend&&g>h&&(n=h,h=g,g=n),n=ig(x,g),q=ig(x,h),n&&q&&(1!==u.rangeCount||u.anchorNode!==n.node||u.anchorOffset!==n.offset||u.focusNode!==q.node||u.focusOffset!==q.offset)&&(A=A.createRange(),
A.setStart(n.node,n.offset),u.removeAllRanges(),g>h?(u.addRange(A),u.extend(q.node,q.offset)):(A.setEnd(q.node,q.offset),u.addRange(A))))));A=[];for(u=x;u=u.parentNode;)1===u.nodeType&&A.push({element:u,left:u.scrollLeft,top:u.scrollTop});"function"===typeof x.focus&&x.focus();for(x=0;x<A.length;x++)u=A[x],u.element.scrollLeft=u.left,u.element.scrollTop=u.top}tc=!!Ze;$e=Ze=null;a.current=c;l=e;do try{for(x=a;null!==l;){var F=l.effectTag;F&36&&oj(x,l.alternate,l);if(F&128){A=void 0;var E=l.ref;if(null!==
E){var G=l.stateNode;switch(l.tag){case 5:A=G;break;default:A=G}"function"===typeof E?E(A):E.current=A}}l=l.nextEffect}}catch(sb){if(null===l)throw Error(k(330));Za(l,sb);l=l.nextEffect}while(null!==l);l=null;Cj();p=f}else a.current=c;if(ld)ld=!1,Zb=a,$b=b;else for(l=e;null!==l;)b=l.nextEffect,l.nextEffect=null,l=b;b=a.firstPendingTime;0===b&&(La=null);1073741823===b?a===af?ac++:(ac=0,af=a):ac=0;"function"===typeof bf&&bf(c.stateNode,d);V(a);if(cd)throw cd=!1,a=Se,Se=null,a;if((p&Ye)!==H)return null;
ha();return null}function Bj(){for(;null!==l;){var a=l.effectTag;0!==(a&256)&&nj(l.alternate,l);0===(a&512)||ld||(ld=!0,Ng(97,function(){xb();return null}));l=l.nextEffect}}function xb(){if(90!==$b){var a=97<$b?97:$b;$b=90;return Da(a,Dj)}}function Dj(){if(null===Zb)return!1;var a=Zb;Zb=null;if((p&(ca|ma))!==H)throw Error(k(331));var b=p;p|=ma;for(a=a.current.firstEffect;null!==a;){try{var c=a;if(0!==(c.effectTag&512))switch(c.tag){case 0:case 11:case 15:case 22:Ah(5,c),Bh(5,c)}}catch(d){if(null===
a)throw Error(k(330));Za(a,d)}c=a.nextEffect;a.nextEffect=null;a=c}p=b;ha();return!0}function Vh(a,b,c){b=Le(c,b);b=Ih(a,b,1073741823);Fa(a,b);a=ed(a,1073741823);null!==a&&V(a)}function Za(a,b){if(3===a.tag)Vh(a,a,b);else for(var c=a.return;null!==c;){if(3===c.tag){Vh(c,a,b);break}else if(1===c.tag){var d=c.stateNode;if("function"===typeof c.type.getDerivedStateFromError||"function"===typeof d.componentDidCatch&&(null===La||!La.has(d))){a=Le(b,a);a=Jh(c,a,1073741823);Fa(c,a);c=ed(c,1073741823);null!==
c&&V(c);break}}c=c.return}}function xj(a,b,c){var d=a.pingCache;null!==d&&d.delete(b);U===a&&P===c?F===bd||F===ad&&1073741823===ta&&Y()-Re<Ph?$a(a,P):jd=!0:Kh(a,c)&&(b=a.lastPingedTime,0!==b&&b<c||(a.lastPingedTime=c,V(a)))}function qj(a,b){var c=a.stateNode;null!==c&&c.delete(b);b=0;0===b&&(b=ka(),b=Va(b,a,null));a=ed(a,b);null!==a&&V(a)}function Ej(a){if("undefined"===typeof __REACT_DEVTOOLS_GLOBAL_HOOK__)return!1;var b=__REACT_DEVTOOLS_GLOBAL_HOOK__;if(b.isDisabled||!b.supportsFiber)return!0;try{var c=
b.inject(a);bf=function(a,e){try{b.onCommitFiberRoot(c,a,void 0,64===(a.current.effectTag&64))}catch(f){}};Ne=function(a){try{b.onCommitFiberUnmount(c,a)}catch(e){}}}catch(d){}return!0}function Fj(a,b,c,d){this.tag=a;this.key=c;this.sibling=this.child=this.return=this.stateNode=this.type=this.elementType=null;this.index=0;this.ref=null;this.pendingProps=b;this.dependencies=this.memoizedState=this.updateQueue=this.memoizedProps=null;this.mode=d;this.effectTag=0;this.lastEffect=this.firstEffect=this.nextEffect=
null;this.childExpirationTime=this.expirationTime=0;this.alternate=null}function Ge(a){a=a.prototype;return!(!a||!a.isReactComponent)}function Gj(a){if("function"===typeof a)return Ge(a)?1:0;if(void 0!==a&&null!==a){a=a.$$typeof;if(a===zd)return 11;if(a===Ad)return 14}return 2}function Sa(a,b){var c=a.alternate;null===c?(c=la(a.tag,b,a.key,a.mode),c.elementType=a.elementType,c.type=a.type,c.stateNode=a.stateNode,c.alternate=a,a.alternate=c):(c.pendingProps=b,c.effectTag=0,c.nextEffect=null,c.firstEffect=
null,c.lastEffect=null);c.childExpirationTime=a.childExpirationTime;c.expirationTime=a.expirationTime;c.child=a.child;c.memoizedProps=a.memoizedProps;c.memoizedState=a.memoizedState;c.updateQueue=a.updateQueue;b=a.dependencies;c.dependencies=null===b?null:{expirationTime:b.expirationTime,firstContext:b.firstContext,responders:b.responders};c.sibling=a.sibling;c.index=a.index;c.ref=a.ref;return c}function Oc(a,b,c,d,e,f){var g=2;d=a;if("function"===typeof a)Ge(a)&&(g=1);else if("string"===typeof a)g=
5;else a:switch(a){case Ma:return Ha(c.children,e,f,b);case Hj:g=8;e|=7;break;case Af:g=8;e|=1;break;case kc:return a=la(12,c,b,e|8),a.elementType=kc,a.type=kc,a.expirationTime=f,a;case lc:return a=la(13,c,b,e),a.type=lc,a.elementType=lc,a.expirationTime=f,a;case yd:return a=la(19,c,b,e),a.elementType=yd,a.expirationTime=f,a;default:if("object"===typeof a&&null!==a)switch(a.$$typeof){case Cf:g=10;break a;case Bf:g=9;break a;case zd:g=11;break a;case Ad:g=14;break a;case Ef:g=16;d=null;break a;case Df:g=
22;break a}throw Error(k(130,null==a?a:typeof a,""));}b=la(g,c,b,e);b.elementType=a;b.type=d;b.expirationTime=f;return b}function Ha(a,b,c,d){a=la(7,a,d,b);a.expirationTime=c;return a}function qe(a,b,c){a=la(6,a,null,b);a.expirationTime=c;return a}function re(a,b,c){b=la(4,null!==a.children?a.children:[],a.key,b);b.expirationTime=c;b.stateNode={containerInfo:a.containerInfo,pendingChildren:null,implementation:a.implementation};return b}function Ij(a,b,c){this.tag=b;this.current=null;this.containerInfo=
a;this.pingCache=this.pendingChildren=null;this.finishedExpirationTime=0;this.finishedWork=null;this.timeoutHandle=-1;this.pendingContext=this.context=null;this.hydrate=c;this.callbackNode=null;this.callbackPriority=90;this.lastExpiredTime=this.lastPingedTime=this.nextKnownPendingLevel=this.lastSuspendedTime=this.firstSuspendedTime=this.firstPendingTime=0}function Kh(a,b){var c=a.firstSuspendedTime;a=a.lastSuspendedTime;return 0!==c&&c>=b&&a<=b}function Ya(a,b){var c=a.firstSuspendedTime,d=a.lastSuspendedTime;
c<b&&(a.firstSuspendedTime=b);if(d>b||0===c)a.lastSuspendedTime=b;b<=a.lastPingedTime&&(a.lastPingedTime=0);b<=a.lastExpiredTime&&(a.lastExpiredTime=0)}function yh(a,b){b>a.firstPendingTime&&(a.firstPendingTime=b);var c=a.firstSuspendedTime;0!==c&&(b>=c?a.firstSuspendedTime=a.lastSuspendedTime=a.nextKnownPendingLevel=0:b>=a.lastSuspendedTime&&(a.lastSuspendedTime=b+1),b>a.nextKnownPendingLevel&&(a.nextKnownPendingLevel=b))}function Ue(a,b){var c=a.lastExpiredTime;if(0===c||c>b)a.lastExpiredTime=b}
function md(a,b,c,d){var e=b.current,f=ka(),g=Vb.suspense;f=Va(f,e,g);a:if(c){c=c._reactInternalFiber;b:{if(Na(c)!==c||1!==c.tag)throw Error(k(170));var h=c;do{switch(h.tag){case 3:h=h.stateNode.context;break b;case 1:if(N(h.type)){h=h.stateNode.__reactInternalMemoizedMergedChildContext;break b}}h=h.return}while(null!==h);throw Error(k(171));}if(1===c.tag){var m=c.type;if(N(m)){c=Gg(c,m,h);break a}}c=h}else c=Ca;null===b.context?b.context=c:b.pendingContext=c;b=Ea(f,g);b.payload={element:a};d=void 0===
d?null:d;null!==d&&(b.callback=d);Fa(e,b);Ja(e,f);return f}function cf(a){a=a.current;if(!a.child)return null;switch(a.child.tag){case 5:return a.child.stateNode;default:return a.child.stateNode}}function Wh(a,b){a=a.memoizedState;null!==a&&null!==a.dehydrated&&a.retryTime<b&&(a.retryTime=b)}function df(a,b){Wh(a,b);(a=a.alternate)&&Wh(a,b)}function ef(a,b,c){c=null!=c&&!0===c.hydrate;var d=new Ij(a,b,c),e=la(3,null,null,2===b?7:1===b?3:0);d.current=e;e.stateNode=d;ne(e);a[Lb]=d.current;c&&0!==b&&
xi(a,9===a.nodeType?a:a.ownerDocument);this._internalRoot=d}function bc(a){return!(!a||1!==a.nodeType&&9!==a.nodeType&&11!==a.nodeType&&(8!==a.nodeType||" react-mount-point-unstable "!==a.nodeValue))}function Jj(a,b){b||(b=a?9===a.nodeType?a.documentElement:a.firstChild:null,b=!(!b||1!==b.nodeType||!b.hasAttribute("data-reactroot")));if(!b)for(var c;c=a.lastChild;)a.removeChild(c);return new ef(a,0,b?{hydrate:!0}:void 0)}function nd(a,b,c,d,e){var f=c._reactRootContainer;if(f){var g=f._internalRoot;
if("function"===typeof e){var h=e;e=function(){var a=cf(g);h.call(a)}}md(b,g,a,e)}else{f=c._reactRootContainer=Jj(c,d);g=f._internalRoot;if("function"===typeof e){var m=e;e=function(){var a=cf(g);m.call(a)}}Rh(function(){md(b,g,a,e)})}return cf(g)}function Kj(a,b,c){var d=3<arguments.length&&void 0!==arguments[3]?arguments[3]:null;return{$$typeof:gb,key:null==d?null:""+d,children:a,containerInfo:b,implementation:c}}function Xh(a,b){var c=2<arguments.length&&void 0!==arguments[2]?arguments[2]:null;
if(!bc(b))throw Error(k(200));return Kj(a,b,null,c)}if(!ea)throw Error(k(227));var ki=function(a,b,c,d,e,f,g,h,m){var n=Array.prototype.slice.call(arguments,3);try{b.apply(c,n)}catch(C){this.onError(C)}},yb=!1,gc=null,hc=!1,pd=null,li={onError:function(a){yb=!0;gc=a}},td=null,rf=null,mf=null,ic=null,cb={},jc=[],qd={},db={},rd={},wa=!("undefined"===typeof window||"undefined"===typeof window.document||"undefined"===typeof window.document.createElement),M=ea.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.assign,
sd=null,eb=null,fb=null,ee=function(a,b){return a(b)},eg=function(a,b,c,d,e){return a(b,c,d,e)},vd=function(){},vf=ee,Oa=!1,wd=!1,Z=ea.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.Scheduler,Lj=Z.unstable_cancelCallback,ff=Z.unstable_now,$f=Z.unstable_scheduleCallback,Mj=Z.unstable_shouldYield,Yh=Z.unstable_requestPaint,Pd=Z.unstable_runWithPriority,Nj=Z.unstable_getCurrentPriorityLevel,Oj=Z.unstable_ImmediatePriority,Zh=Z.unstable_UserBlockingPriority,ag=Z.unstable_NormalPriority,Pj=Z.unstable_LowPriority,
Qj=Z.unstable_IdlePriority,oi=/^[:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD][:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\-.0-9\u00B7\u0300-\u036F\u203F-\u2040]*$/,wf=Object.prototype.hasOwnProperty,yf={},xf={},E={};"children dangerouslySetInnerHTML defaultValue defaultChecked innerHTML suppressContentEditableWarning suppressHydrationWarning style".split(" ").forEach(function(a){E[a]=
new L(a,0,!1,a,null,!1)});[["acceptCharset","accept-charset"],["className","class"],["htmlFor","for"],["httpEquiv","http-equiv"]].forEach(function(a){var b=a[0];E[b]=new L(b,1,!1,a[1],null,!1)});["contentEditable","draggable","spellCheck","value"].forEach(function(a){E[a]=new L(a,2,!1,a.toLowerCase(),null,!1)});["autoReverse","externalResourcesRequired","focusable","preserveAlpha"].forEach(function(a){E[a]=new L(a,2,!1,a,null,!1)});"allowFullScreen async autoFocus autoPlay controls default defer disabled disablePictureInPicture formNoValidate hidden loop noModule noValidate open playsInline readOnly required reversed scoped seamless itemScope".split(" ").forEach(function(a){E[a]=
new L(a,3,!1,a.toLowerCase(),null,!1)});["checked","multiple","muted","selected"].forEach(function(a){E[a]=new L(a,3,!0,a,null,!1)});["capture","download"].forEach(function(a){E[a]=new L(a,4,!1,a,null,!1)});["cols","rows","size","span"].forEach(function(a){E[a]=new L(a,6,!1,a,null,!1)});["rowSpan","start"].forEach(function(a){E[a]=new L(a,5,!1,a.toLowerCase(),null,!1)});var gf=/[\-:]([a-z])/g,hf=function(a){return a[1].toUpperCase()};"accent-height alignment-baseline arabic-form baseline-shift cap-height clip-path clip-rule color-interpolation color-interpolation-filters color-profile color-rendering dominant-baseline enable-background fill-opacity fill-rule flood-color flood-opacity font-family font-size font-size-adjust font-stretch font-style font-variant font-weight glyph-name glyph-orientation-horizontal glyph-orientation-vertical horiz-adv-x horiz-origin-x image-rendering letter-spacing lighting-color marker-end marker-mid marker-start overline-position overline-thickness paint-order panose-1 pointer-events rendering-intent shape-rendering stop-color stop-opacity strikethrough-position strikethrough-thickness stroke-dasharray stroke-dashoffset stroke-linecap stroke-linejoin stroke-miterlimit stroke-opacity stroke-width text-anchor text-decoration text-rendering underline-position underline-thickness unicode-bidi unicode-range units-per-em v-alphabetic v-hanging v-ideographic v-mathematical vector-effect vert-adv-y vert-origin-x vert-origin-y word-spacing writing-mode xmlns:xlink x-height".split(" ").forEach(function(a){var b=
a.replace(gf,hf);E[b]=new L(b,1,!1,a,null,!1)});"xlink:actuate xlink:arcrole xlink:role xlink:show xlink:title xlink:type".split(" ").forEach(function(a){var b=a.replace(gf,hf);E[b]=new L(b,1,!1,a,"http://www.w3.org/1999/xlink",!1)});["xml:base","xml:lang","xml:space"].forEach(function(a){var b=a.replace(gf,hf);E[b]=new L(b,1,!1,a,"http://www.w3.org/XML/1998/namespace",!1)});["tabIndex","crossOrigin"].forEach(function(a){E[a]=new L(a,1,!1,a.toLowerCase(),null,!1)});E.xlinkHref=new L("xlinkHref",1,
!1,"xlink:href","http://www.w3.org/1999/xlink",!0);["src","href","action","formAction"].forEach(function(a){E[a]=new L(a,1,!1,a.toLowerCase(),null,!0)});var da=ea.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED;da.hasOwnProperty("ReactCurrentDispatcher")||(da.ReactCurrentDispatcher={current:null});da.hasOwnProperty("ReactCurrentBatchConfig")||(da.ReactCurrentBatchConfig={suspense:null});var si=/^(.*)[\\\/]/,Q="function"===typeof Symbol&&Symbol.for,Pc=Q?Symbol.for("react.element"):60103,gb=Q?Symbol.for("react.portal"):
60106,Ma=Q?Symbol.for("react.fragment"):60107,Af=Q?Symbol.for("react.strict_mode"):60108,kc=Q?Symbol.for("react.profiler"):60114,Cf=Q?Symbol.for("react.provider"):60109,Bf=Q?Symbol.for("react.context"):60110,Hj=Q?Symbol.for("react.concurrent_mode"):60111,zd=Q?Symbol.for("react.forward_ref"):60112,lc=Q?Symbol.for("react.suspense"):60113,yd=Q?Symbol.for("react.suspense_list"):60120,Ad=Q?Symbol.for("react.memo"):60115,Ef=Q?Symbol.for("react.lazy"):60116,Df=Q?Symbol.for("react.block"):60121,zf="function"===
typeof Symbol&&Symbol.iterator,od,xh=function(a){return"undefined"!==typeof MSApp&&MSApp.execUnsafeLocalFunction?function(b,c,d,e){MSApp.execUnsafeLocalFunction(function(){return a(b,c,d,e)})}:a}(function(a,b){if("http://www.w3.org/2000/svg"!==a.namespaceURI||"innerHTML"in a)a.innerHTML=b;else{od=od||document.createElement("div");od.innerHTML="<svg>"+b.valueOf().toString()+"</svg>";for(b=od.firstChild;a.firstChild;)a.removeChild(a.firstChild);for(;b.firstChild;)a.appendChild(b.firstChild)}}),Wb=function(a,
b){if(b){var c=a.firstChild;if(c&&c===a.lastChild&&3===c.nodeType){c.nodeValue=b;return}}a.textContent=b},ib={animationend:nc("Animation","AnimationEnd"),animationiteration:nc("Animation","AnimationIteration"),animationstart:nc("Animation","AnimationStart"),transitionend:nc("Transition","TransitionEnd")},Id={},Of={};wa&&(Of=document.createElement("div").style,"AnimationEvent"in window||(delete ib.animationend.animation,delete ib.animationiteration.animation,delete ib.animationstart.animation),"TransitionEvent"in
window||delete ib.transitionend.transition);var $h=oc("animationend"),ai=oc("animationiteration"),bi=oc("animationstart"),ci=oc("transitionend"),Db="abort canplay canplaythrough durationchange emptied encrypted ended error loadeddata loadedmetadata loadstart pause play playing progress ratechange seeked seeking stalled suspend timeupdate volumechange waiting".split(" "),Pf=new ("function"===typeof WeakMap?WeakMap:Map),Ab=null,wi=function(a){if(a){var b=a._dispatchListeners,c=a._dispatchInstances;
if(Array.isArray(b))for(var d=0;d<b.length&&!a.isPropagationStopped();d++)lf(a,b[d],c[d]);else b&&lf(a,b,c);a._dispatchListeners=null;a._dispatchInstances=null;a.isPersistent()||a.constructor.release(a)}},qc=[],Rd=!1,fa=[],xa=null,ya=null,za=null,Eb=new Map,Fb=new Map,Jb=[],Nd="mousedown mouseup touchcancel touchend touchstart auxclick dblclick pointercancel pointerdown pointerup dragend dragstart drop compositionend compositionstart keydown keypress keyup input textInput close cancel copy cut paste click change contextmenu reset submit".split(" "),
yi="focus blur dragenter dragleave mouseover mouseout pointerover pointerout gotpointercapture lostpointercapture".split(" "),dg={},cg=new Map,Td=new Map,Rj=["abort","abort",$h,"animationEnd",ai,"animationIteration",bi,"animationStart","canplay","canPlay","canplaythrough","canPlayThrough","durationchange","durationChange","emptied","emptied","encrypted","encrypted","ended","ended","error","error","gotpointercapture","gotPointerCapture","load","load","loadeddata","loadedData","loadedmetadata","loadedMetadata",
"loadstart","loadStart","lostpointercapture","lostPointerCapture","playing","playing","progress","progress","seeking","seeking","stalled","stalled","suspend","suspend","timeupdate","timeUpdate",ci,"transitionEnd","waiting","waiting"];Sd("blur blur cancel cancel click click close close contextmenu contextMenu copy copy cut cut auxclick auxClick dblclick doubleClick dragend dragEnd dragstart dragStart drop drop focus focus input input invalid invalid keydown keyDown keypress keyPress keyup keyUp mousedown mouseDown mouseup mouseUp paste paste pause pause play play pointercancel pointerCancel pointerdown pointerDown pointerup pointerUp ratechange rateChange reset reset seeked seeked submit submit touchcancel touchCancel touchend touchEnd touchstart touchStart volumechange volumeChange".split(" "),
0);Sd("drag drag dragenter dragEnter dragexit dragExit dragleave dragLeave dragover dragOver mousemove mouseMove mouseout mouseOut mouseover mouseOver pointermove pointerMove pointerout pointerOut pointerover pointerOver scroll scroll toggle toggle touchmove touchMove wheel wheel".split(" "),1);Sd(Rj,2);(function(a,b){for(var c=0;c<a.length;c++)Td.set(a[c],b)})("change selectionchange textInput compositionstart compositionend compositionupdate".split(" "),0);var Hi=Zh,Gi=Pd,tc=!0,Kb={animationIterationCount:!0,
borderImageOutset:!0,borderImageSlice:!0,borderImageWidth:!0,boxFlex:!0,boxFlexGroup:!0,boxOrdinalGroup:!0,columnCount:!0,columns:!0,flex:!0,flexGrow:!0,flexPositive:!0,flexShrink:!0,flexNegative:!0,flexOrder:!0,gridArea:!0,gridRow:!0,gridRowEnd:!0,gridRowSpan:!0,gridRowStart:!0,gridColumn:!0,gridColumnEnd:!0,gridColumnSpan:!0,gridColumnStart:!0,fontWeight:!0,lineClamp:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,tabSize:!0,widows:!0,zIndex:!0,zoom:!0,fillOpacity:!0,floodOpacity:!0,stopOpacity:!0,
strokeDasharray:!0,strokeDashoffset:!0,strokeMiterlimit:!0,strokeOpacity:!0,strokeWidth:!0},Sj=["Webkit","ms","Moz","O"];Object.keys(Kb).forEach(function(a){Sj.forEach(function(b){b=b+a.charAt(0).toUpperCase()+a.substring(1);Kb[b]=Kb[a]})});var Ii=M({menuitem:!0},{area:!0,base:!0,br:!0,col:!0,embed:!0,hr:!0,img:!0,input:!0,keygen:!0,link:!0,meta:!0,param:!0,source:!0,track:!0,wbr:!0}),ng="$",og="/$",$d="$?",Zd="$!",Ze=null,$e=null,We="function"===typeof setTimeout?setTimeout:void 0,vj="function"===
typeof clearTimeout?clearTimeout:void 0,jf=Math.random().toString(36).slice(2),Aa="__reactInternalInstance$"+jf,vc="__reactEventHandlers$"+jf,Lb="__reactContainere$"+jf,Ba=null,ce=null,wc=null;M(R.prototype,{preventDefault:function(){this.defaultPrevented=!0;var a=this.nativeEvent;a&&(a.preventDefault?a.preventDefault():"unknown"!==typeof a.returnValue&&(a.returnValue=!1),this.isDefaultPrevented=xc)},stopPropagation:function(){var a=this.nativeEvent;a&&(a.stopPropagation?a.stopPropagation():"unknown"!==
typeof a.cancelBubble&&(a.cancelBubble=!0),this.isPropagationStopped=xc)},persist:function(){this.isPersistent=xc},isPersistent:yc,destructor:function(){var a=this.constructor.Interface,b;for(b in a)this[b]=null;this.nativeEvent=this._targetInst=this.dispatchConfig=null;this.isPropagationStopped=this.isDefaultPrevented=yc;this._dispatchInstances=this._dispatchListeners=null}});R.Interface={type:null,target:null,currentTarget:function(){return null},eventPhase:null,bubbles:null,cancelable:null,timeStamp:function(a){return a.timeStamp||
Date.now()},defaultPrevented:null,isTrusted:null};R.extend=function(a){function b(){return c.apply(this,arguments)}var c=this,d=function(){};d.prototype=c.prototype;d=new d;M(d,b.prototype);b.prototype=d;b.prototype.constructor=b;b.Interface=M({},c.Interface,a);b.extend=c.extend;sg(b);return b};sg(R);var Tj=R.extend({data:null}),Uj=R.extend({data:null}),Ni=[9,13,27,32],de=wa&&"CompositionEvent"in window,cc=null;wa&&"documentMode"in document&&(cc=document.documentMode);var Vj=wa&&"TextEvent"in window&&
!cc,xg=wa&&(!de||cc&&8<cc&&11>=cc),wg=String.fromCharCode(32),ua={beforeInput:{phasedRegistrationNames:{bubbled:"onBeforeInput",captured:"onBeforeInputCapture"},dependencies:["compositionend","keypress","textInput","paste"]},compositionEnd:{phasedRegistrationNames:{bubbled:"onCompositionEnd",captured:"onCompositionEndCapture"},dependencies:"blur compositionend keydown keypress keyup mousedown".split(" ")},compositionStart:{phasedRegistrationNames:{bubbled:"onCompositionStart",captured:"onCompositionStartCapture"},
dependencies:"blur compositionstart keydown keypress keyup mousedown".split(" ")},compositionUpdate:{phasedRegistrationNames:{bubbled:"onCompositionUpdate",captured:"onCompositionUpdateCapture"},dependencies:"blur compositionupdate keydown keypress keyup mousedown".split(" ")}},vg=!1,mb=!1,Wj={eventTypes:ua,extractEvents:function(a,b,c,d,e){var f;if(de)b:{switch(a){case "compositionstart":var g=ua.compositionStart;break b;case "compositionend":g=ua.compositionEnd;break b;case "compositionupdate":g=
ua.compositionUpdate;break b}g=void 0}else mb?tg(a,c)&&(g=ua.compositionEnd):"keydown"===a&&229===c.keyCode&&(g=ua.compositionStart);g?(xg&&"ko"!==c.locale&&(mb||g!==ua.compositionStart?g===ua.compositionEnd&&mb&&(f=rg()):(Ba=d,ce="value"in Ba?Ba.value:Ba.textContent,mb=!0)),e=Tj.getPooled(g,b,c,d),f?e.data=f:(f=ug(c),null!==f&&(e.data=f)),lb(e),f=e):f=null;(a=Vj?Oi(a,c):Pi(a,c))?(b=Uj.getPooled(ua.beforeInput,b,c,d),b.data=a,lb(b)):b=null;return null===f?b:null===b?f:[f,b]}},Qi={color:!0,date:!0,
datetime:!0,"datetime-local":!0,email:!0,month:!0,number:!0,password:!0,range:!0,search:!0,tel:!0,text:!0,time:!0,url:!0,week:!0},Ag={change:{phasedRegistrationNames:{bubbled:"onChange",captured:"onChangeCapture"},dependencies:"blur change click focus input keydown keyup selectionchange".split(" ")}},Mb=null,Nb=null,kf=!1;wa&&(kf=Tf("input")&&(!document.documentMode||9<document.documentMode));var Xj={eventTypes:Ag,_isInputEventSupported:kf,extractEvents:function(a,b,c,d,e){e=b?Pa(b):window;var f=
e.nodeName&&e.nodeName.toLowerCase();if("select"===f||"input"===f&&"file"===e.type)var g=Si;else if(yg(e))if(kf)g=Wi;else{g=Ui;var h=Ti}else(f=e.nodeName)&&"input"===f.toLowerCase()&&("checkbox"===e.type||"radio"===e.type)&&(g=Vi);if(g&&(g=g(a,b)))return zg(g,c,d);h&&h(a,e,b);"blur"===a&&(a=e._wrapperState)&&a.controlled&&"number"===e.type&&Ed(e,"number",e.value)}},dc=R.extend({view:null,detail:null}),Yi={Alt:"altKey",Control:"ctrlKey",Meta:"metaKey",Shift:"shiftKey"},di=0,ei=0,fi=!1,gi=!1,ec=dc.extend({screenX:null,
screenY:null,clientX:null,clientY:null,pageX:null,pageY:null,ctrlKey:null,shiftKey:null,altKey:null,metaKey:null,getModifierState:fe,button:null,buttons:null,relatedTarget:function(a){return a.relatedTarget||(a.fromElement===a.srcElement?a.toElement:a.fromElement)},movementX:function(a){if("movementX"in a)return a.movementX;var b=di;di=a.screenX;return fi?"mousemove"===a.type?a.screenX-b:0:(fi=!0,0)},movementY:function(a){if("movementY"in a)return a.movementY;var b=ei;ei=a.screenY;return gi?"mousemove"===
a.type?a.screenY-b:0:(gi=!0,0)}}),hi=ec.extend({pointerId:null,width:null,height:null,pressure:null,tangentialPressure:null,tiltX:null,tiltY:null,twist:null,pointerType:null,isPrimary:null}),fc={mouseEnter:{registrationName:"onMouseEnter",dependencies:["mouseout","mouseover"]},mouseLeave:{registrationName:"onMouseLeave",dependencies:["mouseout","mouseover"]},pointerEnter:{registrationName:"onPointerEnter",dependencies:["pointerout","pointerover"]},pointerLeave:{registrationName:"onPointerLeave",dependencies:["pointerout",
"pointerover"]}},Yj={eventTypes:fc,extractEvents:function(a,b,c,d,e){var f="mouseover"===a||"pointerover"===a,g="mouseout"===a||"pointerout"===a;if(f&&0===(e&32)&&(c.relatedTarget||c.fromElement)||!g&&!f)return null;f=d.window===d?d:(f=d.ownerDocument)?f.defaultView||f.parentWindow:window;if(g){if(g=b,b=(b=c.relatedTarget||c.toElement)?Bb(b):null,null!==b){var h=Na(b);if(b!==h||5!==b.tag&&6!==b.tag)b=null}}else g=null;if(g===b)return null;if("mouseout"===a||"mouseover"===a){var m=ec;var n=fc.mouseLeave;
var l=fc.mouseEnter;var k="mouse"}else if("pointerout"===a||"pointerover"===a)m=hi,n=fc.pointerLeave,l=fc.pointerEnter,k="pointer";a=null==g?f:Pa(g);f=null==b?f:Pa(b);n=m.getPooled(n,g,c,d);n.type=k+"leave";n.target=a;n.relatedTarget=f;c=m.getPooled(l,b,c,d);c.type=k+"enter";c.target=f;c.relatedTarget=a;d=g;k=b;if(d&&k)a:{m=d;l=k;g=0;for(a=m;a;a=pa(a))g++;a=0;for(b=l;b;b=pa(b))a++;for(;0<g-a;)m=pa(m),g--;for(;0<a-g;)l=pa(l),a--;for(;g--;){if(m===l||m===l.alternate)break a;m=pa(m);l=pa(l)}m=null}else m=
null;l=m;for(m=[];d&&d!==l;){g=d.alternate;if(null!==g&&g===l)break;m.push(d);d=pa(d)}for(d=[];k&&k!==l;){g=k.alternate;if(null!==g&&g===l)break;d.push(k);k=pa(k)}for(k=0;k<m.length;k++)be(m[k],"bubbled",n);for(k=d.length;0<k--;)be(d[k],"captured",c);return 0===(e&64)?[n]:[n,c]}},Qa="function"===typeof Object.is?Object.is:Zi,$i=Object.prototype.hasOwnProperty,Zj=wa&&"documentMode"in document&&11>=document.documentMode,Eg={select:{phasedRegistrationNames:{bubbled:"onSelect",captured:"onSelectCapture"},
dependencies:"blur contextmenu dragend focus keydown keyup mousedown mouseup selectionchange".split(" ")}},nb=null,he=null,Pb=null,ge=!1,ak={eventTypes:Eg,extractEvents:function(a,b,c,d,e,f){e=f||(d.window===d?d.document:9===d.nodeType?d:d.ownerDocument);if(!(f=!e)){a:{e=Jd(e);f=rd.onSelect;for(var g=0;g<f.length;g++)if(!e.has(f[g])){e=!1;break a}e=!0}f=!e}if(f)return null;e=b?Pa(b):window;switch(a){case "focus":if(yg(e)||"true"===e.contentEditable)nb=e,he=b,Pb=null;break;case "blur":Pb=he=nb=null;
break;case "mousedown":ge=!0;break;case "contextmenu":case "mouseup":case "dragend":return ge=!1,Dg(c,d);case "selectionchange":if(Zj)break;case "keydown":case "keyup":return Dg(c,d)}return null}},bk=R.extend({animationName:null,elapsedTime:null,pseudoElement:null}),ck=R.extend({clipboardData:function(a){return"clipboardData"in a?a.clipboardData:window.clipboardData}}),dk=dc.extend({relatedTarget:null}),ek={Esc:"Escape",Spacebar:" ",Left:"ArrowLeft",Up:"ArrowUp",Right:"ArrowRight",Down:"ArrowDown",
Del:"Delete",Win:"OS",Menu:"ContextMenu",Apps:"ContextMenu",Scroll:"ScrollLock",MozPrintableKey:"Unidentified"},fk={8:"Backspace",9:"Tab",12:"Clear",13:"Enter",16:"Shift",17:"Control",18:"Alt",19:"Pause",20:"CapsLock",27:"Escape",32:" ",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"ArrowLeft",38:"ArrowUp",39:"ArrowRight",40:"ArrowDown",45:"Insert",46:"Delete",112:"F1",113:"F2",114:"F3",115:"F4",116:"F5",117:"F6",118:"F7",119:"F8",120:"F9",121:"F10",122:"F11",123:"F12",144:"NumLock",145:"ScrollLock",
224:"Meta"},gk=dc.extend({key:function(a){if(a.key){var b=ek[a.key]||a.key;if("Unidentified"!==b)return b}return"keypress"===a.type?(a=Ac(a),13===a?"Enter":String.fromCharCode(a)):"keydown"===a.type||"keyup"===a.type?fk[a.keyCode]||"Unidentified":""},location:null,ctrlKey:null,shiftKey:null,altKey:null,metaKey:null,repeat:null,locale:null,getModifierState:fe,charCode:function(a){return"keypress"===a.type?Ac(a):0},keyCode:function(a){return"keydown"===a.type||"keyup"===a.type?a.keyCode:0},which:function(a){return"keypress"===
a.type?Ac(a):"keydown"===a.type||"keyup"===a.type?a.keyCode:0}}),hk=ec.extend({dataTransfer:null}),ik=dc.extend({touches:null,targetTouches:null,changedTouches:null,altKey:null,metaKey:null,ctrlKey:null,shiftKey:null,getModifierState:fe}),jk=R.extend({propertyName:null,elapsedTime:null,pseudoElement:null}),kk=ec.extend({deltaX:function(a){return"deltaX"in a?a.deltaX:"wheelDeltaX"in a?-a.wheelDeltaX:0},deltaY:function(a){return"deltaY"in a?a.deltaY:"wheelDeltaY"in a?-a.wheelDeltaY:"wheelDelta"in a?
-a.wheelDelta:0},deltaZ:null,deltaMode:null}),lk={eventTypes:dg,extractEvents:function(a,b,c,d,e){e=cg.get(a);if(!e)return null;switch(a){case "keypress":if(0===Ac(c))return null;case "keydown":case "keyup":a=gk;break;case "blur":case "focus":a=dk;break;case "click":if(2===c.button)return null;case "auxclick":case "dblclick":case "mousedown":case "mousemove":case "mouseup":case "mouseout":case "mouseover":case "contextmenu":a=ec;break;case "drag":case "dragend":case "dragenter":case "dragexit":case "dragleave":case "dragover":case "dragstart":case "drop":a=
hk;break;case "touchcancel":case "touchend":case "touchmove":case "touchstart":a=ik;break;case $h:case ai:case bi:a=bk;break;case ci:a=jk;break;case "scroll":a=dc;break;case "wheel":a=kk;break;case "copy":case "cut":case "paste":a=ck;break;case "gotpointercapture":case "lostpointercapture":case "pointercancel":case "pointerdown":case "pointermove":case "pointerout":case "pointerover":case "pointerup":a=hi;break;default:a=R}b=a.getPooled(e,b,c,d);lb(b);return b}};(function(a){if(ic)throw Error(k(101));
ic=Array.prototype.slice.call(a);nf()})("ResponderEventPlugin SimpleEventPlugin EnterLeaveEventPlugin ChangeEventPlugin SelectEventPlugin BeforeInputEventPlugin".split(" "));(function(a,b,c){td=a;rf=b;mf=c})(ae,Hb,Pa);pf({SimpleEventPlugin:lk,EnterLeaveEventPlugin:Yj,ChangeEventPlugin:Xj,SelectEventPlugin:ak,BeforeInputEventPlugin:Wj});var ie=[],ob=-1,Ca={},B={current:Ca},G={current:!1},Ra=Ca,bj=Pd,je=$f,Rg=Lj,aj=Nj,Dc=Oj,Ig=Zh,Jg=ag,Kg=Pj,Lg=Qj,Qg={},yj=Mj,Cj=void 0!==Yh?Yh:function(){},qa=null,
Ec=null,ke=!1,ii=ff(),Y=1E4>ii?ff:function(){return ff()-ii},Ic={current:null},Hc=null,qb=null,Gc=null,Tg=0,Jc=2,Ga=!1,Vb=da.ReactCurrentBatchConfig,$g=(new ea.Component).refs,Mc={isMounted:function(a){return(a=a._reactInternalFiber)?Na(a)===a:!1},enqueueSetState:function(a,b,c){a=a._reactInternalFiber;var d=ka(),e=Vb.suspense;d=Va(d,a,e);e=Ea(d,e);e.payload=b;void 0!==c&&null!==c&&(e.callback=c);Fa(a,e);Ja(a,d)},enqueueReplaceState:function(a,b,c){a=a._reactInternalFiber;var d=ka(),e=Vb.suspense;
d=Va(d,a,e);e=Ea(d,e);e.tag=1;e.payload=b;void 0!==c&&null!==c&&(e.callback=c);Fa(a,e);Ja(a,d)},enqueueForceUpdate:function(a,b){a=a._reactInternalFiber;var c=ka(),d=Vb.suspense;c=Va(c,a,d);d=Ea(c,d);d.tag=Jc;void 0!==b&&null!==b&&(d.callback=b);Fa(a,d);Ja(a,c)}},Qc=Array.isArray,wb=ah(!0),Fe=ah(!1),Sb={},ja={current:Sb},Ub={current:Sb},Tb={current:Sb},D={current:0},Sc=da.ReactCurrentDispatcher,X=da.ReactCurrentBatchConfig,Ia=0,z=null,K=null,J=null,Uc=!1,Tc={readContext:W,useCallback:S,useContext:S,
useEffect:S,useImperativeHandle:S,useLayoutEffect:S,useMemo:S,useReducer:S,useRef:S,useState:S,useDebugValue:S,useResponder:S,useDeferredValue:S,useTransition:S},dj={readContext:W,useCallback:ih,useContext:W,useEffect:eh,useImperativeHandle:function(a,b,c){c=null!==c&&void 0!==c?c.concat([a]):null;return ze(4,2,gh.bind(null,b,a),c)},useLayoutEffect:function(a,b){return ze(4,2,a,b)},useMemo:function(a,b){var c=ub();b=void 0===b?null:b;a=a();c.memoizedState=[a,b];return a},useReducer:function(a,b,c){var d=
ub();b=void 0!==c?c(b):b;d.memoizedState=d.baseState=b;a=d.queue={pending:null,dispatch:null,lastRenderedReducer:a,lastRenderedState:b};a=a.dispatch=ch.bind(null,z,a);return[d.memoizedState,a]},useRef:function(a){var b=ub();a={current:a};return b.memoizedState=a},useState:xe,useDebugValue:Be,useResponder:ue,useDeferredValue:function(a,b){var c=xe(a),d=c[0],e=c[1];eh(function(){var c=X.suspense;X.suspense=void 0===b?null:b;try{e(a)}finally{X.suspense=c}},[a,b]);return d},useTransition:function(a){var b=
xe(!1),c=b[0];b=b[1];return[ih(Ce.bind(null,b,a),[b,a]),c]}},ej={readContext:W,useCallback:Yc,useContext:W,useEffect:Xc,useImperativeHandle:hh,useLayoutEffect:fh,useMemo:jh,useReducer:Vc,useRef:dh,useState:function(a){return Vc(Ua)},useDebugValue:Be,useResponder:ue,useDeferredValue:function(a,b){var c=Vc(Ua),d=c[0],e=c[1];Xc(function(){var c=X.suspense;X.suspense=void 0===b?null:b;try{e(a)}finally{X.suspense=c}},[a,b]);return d},useTransition:function(a){var b=Vc(Ua),c=b[0];b=b[1];return[Yc(Ce.bind(null,
b,a),[b,a]),c]}},fj={readContext:W,useCallback:Yc,useContext:W,useEffect:Xc,useImperativeHandle:hh,useLayoutEffect:fh,useMemo:jh,useReducer:Wc,useRef:dh,useState:function(a){return Wc(Ua)},useDebugValue:Be,useResponder:ue,useDeferredValue:function(a,b){var c=Wc(Ua),d=c[0],e=c[1];Xc(function(){var c=X.suspense;X.suspense=void 0===b?null:b;try{e(a)}finally{X.suspense=c}},[a,b]);return d},useTransition:function(a){var b=Wc(Ua),c=b[0];b=b[1];return[Yc(Ce.bind(null,b,a),[b,a]),c]}},ra=null,Ka=null,Wa=
!1,gj=da.ReactCurrentOwner,ia=!1,Je={dehydrated:null,retryTime:0};var jj=function(a,b,c,d){for(c=b.child;null!==c;){if(5===c.tag||6===c.tag)a.appendChild(c.stateNode);else if(4!==c.tag&&null!==c.child){c.child.return=c;c=c.child;continue}if(c===b)break;for(;null===c.sibling;){if(null===c.return||c.return===b)return;c=c.return}c.sibling.return=c.return;c=c.sibling}};var wh=function(a){};var ij=function(a,b,c,d,e){var f=a.memoizedProps;if(f!==d){var g=b.stateNode;Ta(ja.current);a=null;switch(c){case "input":f=
Cd(g,f);d=Cd(g,d);a=[];break;case "option":f=Fd(g,f);d=Fd(g,d);a=[];break;case "select":f=M({},f,{value:void 0});d=M({},d,{value:void 0});a=[];break;case "textarea":f=Gd(g,f);d=Gd(g,d);a=[];break;default:"function"!==typeof f.onClick&&"function"===typeof d.onClick&&(g.onclick=uc)}Ud(c,d);var h,m;c=null;for(h in f)if(!d.hasOwnProperty(h)&&f.hasOwnProperty(h)&&null!=f[h])if("style"===h)for(m in g=f[h],g)g.hasOwnProperty(m)&&(c||(c={}),c[m]="");else"dangerouslySetInnerHTML"!==h&&"children"!==h&&"suppressContentEditableWarning"!==
h&&"suppressHydrationWarning"!==h&&"autoFocus"!==h&&(db.hasOwnProperty(h)?a||(a=[]):(a=a||[]).push(h,null));for(h in d){var k=d[h];g=null!=f?f[h]:void 0;if(d.hasOwnProperty(h)&&k!==g&&(null!=k||null!=g))if("style"===h)if(g){for(m in g)!g.hasOwnProperty(m)||k&&k.hasOwnProperty(m)||(c||(c={}),c[m]="");for(m in k)k.hasOwnProperty(m)&&g[m]!==k[m]&&(c||(c={}),c[m]=k[m])}else c||(a||(a=[]),a.push(h,c)),c=k;else"dangerouslySetInnerHTML"===h?(k=k?k.__html:void 0,g=g?g.__html:void 0,null!=k&&g!==k&&(a=a||
[]).push(h,k)):"children"===h?g===k||"string"!==typeof k&&"number"!==typeof k||(a=a||[]).push(h,""+k):"suppressContentEditableWarning"!==h&&"suppressHydrationWarning"!==h&&(db.hasOwnProperty(h)?(null!=k&&oa(e,h),a||g===k||(a=[])):(a=a||[]).push(h,k))}c&&(a=a||[]).push("style",c);e=a;if(b.updateQueue=e)b.effectTag|=4}};var kj=function(a,b,c,d){c!==d&&(b.effectTag|=4)};var pj="function"===typeof WeakSet?WeakSet:Set,wj="function"===typeof WeakMap?WeakMap:Map,sj=Math.ceil,gd=da.ReactCurrentDispatcher,
Uh=da.ReactCurrentOwner,H=0,Ye=8,ca=16,ma=32,Xa=0,hd=1,Oh=2,ad=3,bd=4,Xe=5,p=H,U=null,t=null,P=0,F=Xa,id=null,ta=1073741823,Yb=1073741823,kd=null,Xb=0,jd=!1,Re=0,Ph=500,l=null,cd=!1,Se=null,La=null,ld=!1,Zb=null,$b=90,bb=null,ac=0,af=null,dd=0,Ja=function(a,b){if(50<ac)throw ac=0,af=null,Error(k(185));a=ed(a,b);if(null!==a){var c=Cc();1073741823===b?(p&Ye)!==H&&(p&(ca|ma))===H?Te(a):(V(a),p===H&&ha()):V(a);(p&4)===H||98!==c&&99!==c||(null===bb?bb=new Map([[a,b]]):(c=bb.get(a),(void 0===c||c>b)&&bb.set(a,
b)))}};var zj=function(a,b,c){var d=b.expirationTime;if(null!==a){var e=b.pendingProps;if(a.memoizedProps!==e||G.current)ia=!0;else{if(d<c){ia=!1;switch(b.tag){case 3:sh(b);Ee();break;case 5:bh(b);if(b.mode&4&&1!==c&&e.hidden)return b.expirationTime=b.childExpirationTime=1,null;break;case 1:N(b.type)&&Bc(b);break;case 4:se(b,b.stateNode.containerInfo);break;case 10:d=b.memoizedProps.value;e=b.type._context;y(Ic,e._currentValue);e._currentValue=d;break;case 13:if(null!==b.memoizedState){d=b.child.childExpirationTime;
if(0!==d&&d>=c)return th(a,b,c);y(D,D.current&1);b=sa(a,b,c);return null!==b?b.sibling:null}y(D,D.current&1);break;case 19:d=b.childExpirationTime>=c;if(0!==(a.effectTag&64)){if(d)return vh(a,b,c);b.effectTag|=64}e=b.memoizedState;null!==e&&(e.rendering=null,e.tail=null);y(D,D.current);if(!d)return null}return sa(a,b,c)}ia=!1}}else ia=!1;b.expirationTime=0;switch(b.tag){case 2:d=b.type;null!==a&&(a.alternate=null,b.alternate=null,b.effectTag|=2);a=b.pendingProps;e=pb(b,B.current);rb(b,c);e=we(null,
b,d,a,e,c);b.effectTag|=1;if("object"===typeof e&&null!==e&&"function"===typeof e.render&&void 0===e.$$typeof){b.tag=1;b.memoizedState=null;b.updateQueue=null;if(N(d)){var f=!0;Bc(b)}else f=!1;b.memoizedState=null!==e.state&&void 0!==e.state?e.state:null;ne(b);var g=d.getDerivedStateFromProps;"function"===typeof g&&Lc(b,d,g,a);e.updater=Mc;b.stateNode=e;e._reactInternalFiber=b;pe(b,d,a,c);b=Ie(null,b,d,!0,f,c)}else b.tag=0,T(null,b,e,c),b=b.child;return b;case 16:a:{e=b.elementType;null!==a&&(a.alternate=
null,b.alternate=null,b.effectTag|=2);a=b.pendingProps;ri(e);if(1!==e._status)throw e._result;e=e._result;b.type=e;f=b.tag=Gj(e);a=aa(e,a);switch(f){case 0:b=He(null,b,e,a,c);break a;case 1:b=rh(null,b,e,a,c);break a;case 11:b=nh(null,b,e,a,c);break a;case 14:b=oh(null,b,e,aa(e.type,a),d,c);break a}throw Error(k(306,e,""));}return b;case 0:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),He(a,b,d,e,c);case 1:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),rh(a,b,d,e,c);
case 3:sh(b);d=b.updateQueue;if(null===a||null===d)throw Error(k(282));d=b.pendingProps;e=b.memoizedState;e=null!==e?e.element:null;oe(a,b);Qb(b,d,null,c);d=b.memoizedState.element;if(d===e)Ee(),b=sa(a,b,c);else{if(e=b.stateNode.hydrate)Ka=kb(b.stateNode.containerInfo.firstChild),ra=b,e=Wa=!0;if(e)for(c=Fe(b,null,d,c),b.child=c;c;)c.effectTag=c.effectTag&-3|1024,c=c.sibling;else T(a,b,d,c),Ee();b=b.child}return b;case 5:return bh(b),null===a&&De(b),d=b.type,e=b.pendingProps,f=null!==a?a.memoizedProps:
null,g=e.children,Yd(d,e)?g=null:null!==f&&Yd(d,f)&&(b.effectTag|=16),qh(a,b),b.mode&4&&1!==c&&e.hidden?(b.expirationTime=b.childExpirationTime=1,b=null):(T(a,b,g,c),b=b.child),b;case 6:return null===a&&De(b),null;case 13:return th(a,b,c);case 4:return se(b,b.stateNode.containerInfo),d=b.pendingProps,null===a?b.child=wb(b,null,d,c):T(a,b,d,c),b.child;case 11:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),nh(a,b,d,e,c);case 7:return T(a,b,b.pendingProps,c),b.child;case 8:return T(a,
b,b.pendingProps.children,c),b.child;case 12:return T(a,b,b.pendingProps.children,c),b.child;case 10:a:{d=b.type._context;e=b.pendingProps;g=b.memoizedProps;f=e.value;var h=b.type._context;y(Ic,h._currentValue);h._currentValue=f;if(null!==g)if(h=g.value,f=Qa(h,f)?0:("function"===typeof d._calculateChangedBits?d._calculateChangedBits(h,f):1073741823)|0,0===f){if(g.children===e.children&&!G.current){b=sa(a,b,c);break a}}else for(h=b.child,null!==h&&(h.return=b);null!==h;){var m=h.dependencies;if(null!==
m){g=h.child;for(var l=m.firstContext;null!==l;){if(l.context===d&&0!==(l.observedBits&f)){1===h.tag&&(l=Ea(c,null),l.tag=Jc,Fa(h,l));h.expirationTime<c&&(h.expirationTime=c);l=h.alternate;null!==l&&l.expirationTime<c&&(l.expirationTime=c);Sg(h.return,c);m.expirationTime<c&&(m.expirationTime=c);break}l=l.next}}else g=10===h.tag?h.type===b.type?null:h.child:h.child;if(null!==g)g.return=h;else for(g=h;null!==g;){if(g===b){g=null;break}h=g.sibling;if(null!==h){h.return=g.return;g=h;break}g=g.return}h=
g}T(a,b,e.children,c);b=b.child}return b;case 9:return e=b.type,f=b.pendingProps,d=f.children,rb(b,c),e=W(e,f.unstable_observedBits),d=d(e),b.effectTag|=1,T(a,b,d,c),b.child;case 14:return e=b.type,f=aa(e,b.pendingProps),f=aa(e.type,f),oh(a,b,e,f,d,c);case 15:return ph(a,b,b.type,b.pendingProps,d,c);case 17:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),null!==a&&(a.alternate=null,b.alternate=null,b.effectTag|=2),b.tag=1,N(d)?(a=!0,Bc(b)):a=!1,rb(b,c),Yg(b,d,e),pe(b,d,e,c),Ie(null,
b,d,!0,a,c);case 19:return vh(a,b,c)}throw Error(k(156,b.tag));};var bf=null,Ne=null,la=function(a,b,c,d){return new Fj(a,b,c,d)};ef.prototype.render=function(a){md(a,this._internalRoot,null,null)};ef.prototype.unmount=function(){var a=this._internalRoot,b=a.containerInfo;md(null,a,null,function(){b[Lb]=null})};var Di=function(a){if(13===a.tag){var b=Fc(ka(),150,100);Ja(a,b);df(a,b)}};var Yf=function(a){13===a.tag&&(Ja(a,3),df(a,3))};var Bi=function(a){if(13===a.tag){var b=ka();b=Va(b,a,null);Ja(a,
b);df(a,b)}};sd=function(a,b,c){switch(b){case "input":Dd(a,c);b=c.name;if("radio"===c.type&&null!=b){for(c=a;c.parentNode;)c=c.parentNode;c=c.querySelectorAll("input[name="+JSON.stringify(""+b)+'][type="radio"]');for(b=0;b<c.length;b++){var d=c[b];if(d!==a&&d.form===a.form){var e=ae(d);if(!e)throw Error(k(90));Gf(d);Dd(d,e)}}}break;case "textarea":Lf(a,c);break;case "select":b=c.value,null!=b&&hb(a,!!c.multiple,b,!1)}};(function(a,b,c,d){ee=a;eg=b;vd=c;vf=d})(Qh,function(a,b,c,d,e){var f=p;p|=4;
try{return Da(98,a.bind(null,b,c,d,e))}finally{p=f,p===H&&ha()}},function(){(p&(1|ca|ma))===H&&(uj(),xb())},function(a,b){var c=p;p|=2;try{return a(b)}finally{p=c,p===H&&ha()}});var mk={Events:[Hb,Pa,ae,pf,qd,lb,function(a){Kd(a,Ki)},sf,tf,sc,pc,xb,{current:!1}]};(function(a){var b=a.findFiberByHostInstance;return Ej(M({},a,{overrideHookState:null,overrideProps:null,setSuspenseHandler:null,scheduleUpdate:null,currentDispatcherRef:da.ReactCurrentDispatcher,findHostInstanceByFiber:function(a){a=Sf(a);
return null===a?null:a.stateNode},findFiberByHostInstance:function(a){return b?b(a):null},findHostInstancesForRefresh:null,scheduleRefresh:null,scheduleRoot:null,setRefreshHandler:null,getCurrentFiber:null}))})({findFiberByHostInstance:Bb,bundleType:0,version:"16.13.1",rendererPackageName:"react-dom"});I.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=mk;I.createPortal=Xh;I.findDOMNode=function(a){if(null==a)return null;if(1===a.nodeType)return a;var b=a._reactInternalFiber;if(void 0===
b){if("function"===typeof a.render)throw Error(k(188));throw Error(k(268,Object.keys(a)));}a=Sf(b);a=null===a?null:a.stateNode;return a};I.flushSync=function(a,b){if((p&(ca|ma))!==H)throw Error(k(187));var c=p;p|=1;try{return Da(99,a.bind(null,b))}finally{p=c,ha()}};I.hydrate=function(a,b,c){if(!bc(b))throw Error(k(200));return nd(null,a,b,!0,c)};I.render=function(a,b,c){if(!bc(b))throw Error(k(200));return nd(null,a,b,!1,c)};I.unmountComponentAtNode=function(a){if(!bc(a))throw Error(k(40));return a._reactRootContainer?
(Rh(function(){nd(null,null,a,!1,function(){a._reactRootContainer=null;a[Lb]=null})}),!0):!1};I.unstable_batchedUpdates=Qh;I.unstable_createPortal=function(a,b){return Xh(a,b,2<arguments.length&&void 0!==arguments[2]?arguments[2]:null)};I.unstable_renderSubtreeIntoContainer=function(a,b,c,d){if(!bc(c))throw Error(k(200));if(null==a||void 0===a._reactInternalFiber)throw Error(k(38));return nd(a,b,c,!1,d)};I.version="16.13.1"});
</script>
    <script>const e = React.createElement;

function pathToString(path) {
  if (path[0] === '/') {
    return '/' + path.slice(1).join('/');
  } else {
    return path.join('/');
  }
}

function findCommonPath(files) {
  if (!files || !files.length) {
    return [];
  }

  function isPrefix(arr, prefix) {
    if (arr.length < prefix.length) {
      return false;
    }
    for (let i = prefix.length - 1; i >= 0; --i) {
      if (arr[i] !== prefix[i]) {
        return false;
      }
    }
    return true;
  }

  let commonPath = files[0].path.slice(0, -1);
  while (commonPath.length) {
    if (files.every(file => isPrefix(file.path, commonPath))) {
      break;
    }
    commonPath.pop();
  }
  return commonPath;
}

function findFolders(files) {
  if (!files || !files.length) {
    return [];
  }

  let folders = files.filter(file => file.path.length > 1).map(file => file.path[0]);
  folders = [...new Set(folders)]; // unique
  folders.sort();

  folders = folders.map(folder => {
    let filesInFolder = files
      .filter(file => file.path[0] === folder)
      .map(file => ({
        ...file,
        path: file.path.slice(1),
        parent: [...file.parent, file.path[0]],
      }));

    const children = findFolders(filesInFolder); // recursion

    return {
      is_folder: true,
      path: [folder],
      parent: files[0].parent,
      children,
      covered: children.reduce((sum, file) => sum + file.covered, 0),
      coverable: children.reduce((sum, file) => sum + file.coverable, 0),
      prevRun: {
        covered: children.reduce((sum, file) => sum + file.prevRun.covered, 0),
        coverable: children.reduce((sum, file) => sum + file.prevRun.coverable, 0),
      },
    };
  });

  return [...folders, ...files.filter(file => file.path.length === 1)];
}

class App extends React.Component {
  constructor(...args) {
    super(...args);

    this.state = {
      current: [],
    };
  }

  componentDidMount() {
    this.updateStateFromLocation();
    window.addEventListener('hashchange', () => this.updateStateFromLocation(), false);
  }

  updateStateFromLocation() {
    if (window.location.hash.length > 1) {
      const current = window.location.hash.slice(1).split('/');
      this.setState({current});
    } else {
      this.setState({current: []});
    }
  }

  getCurrentPath() {
    let file = this.props.root;
    let path = [file];
    for (let p of this.state.current) {
      file = file.children.find(file => file.path[0] === p);
      if (!file) {
        return path;
      }
      path.push(file);
    }
    return path;
  }

  render() {
    const path = this.getCurrentPath();
    const file = path[path.length - 1];

    let w = null;
    if (file.is_folder) {
      w = e(FilesList, {
        folder: file,
        onSelectFile: this.selectFile.bind(this),
        onBack: path.length > 1 ? this.back.bind(this) : null,
      });
    } else {
      w = e(DisplayFile, {
        file,
        onBack: this.back.bind(this),
      });
    }

    return e('div', {className: 'app'}, w);
  }

  selectFile(file) {
    this.setState(
      ({current}) => {
        return {current: [...current, file.path[0]]};
      },
      () => this.updateHash(),
    );
  }

  back(file) {
    this.setState(
      ({current}) => {
        return {current: current.slice(0, current.length - 1)};
      },
      () => this.updateHash(),
    );
  }

  updateHash() {
    if (!this.state.current || !this.state.current.length) {
      window.location = '#';
    } else {
      window.location = '#' + this.state.current.join('/');
    }
  }
}

function FilesList({folder, onSelectFile, onBack}) {
  let files = folder.children;
  return e(
    'div',
    {className: 'display-folder'},
    e(FileHeader, {file: folder, onBack}),
    e(
      'table',
      {className: 'files-list'},
      e('thead', {className: 'files-list__head'}, e('tr', null, e('th', null, 'Path'), e('th', null, 'Coverage'))),
      e(
        'tbody',
        {className: 'files-list__body'},
        files.map(file => e(File, {file, onClick: onSelectFile})),
      ),
    ),
  );
}

function File({file, onClick}) {
  const coverage = file.coverable ? (file.covered / file.coverable) * 100 : -1;
  const coverageDelta =
    file.prevRun && (file.covered / file.coverable) * 100 - (file.prevRun.covered / file.prevRun.coverable) * 100;

  return e(
    'tr',
    {
      className:
        'files-list__file' +
        (coverage >= 0 && coverage < 50 ? ' files-list__file_low' : '') +
        (coverage >= 50 && coverage < 80 ? ' files-list__file_medium' : '') +
        (coverage >= 80 ? ' files-list__file_high' : '') +
        (file.is_folder ? ' files-list__file_folder' : ''),
      onClick: () => onClick(file),
    },
    e('td', null, e('a', null, pathToString(file.path))),
    e(
      'td',
      null,
      file.covered + ' / ' + file.coverable + (coverage >= 0 ? ' (' + coverage.toFixed(2) + '%)' : ''),
      e(
        'span',
        {title: 'Change from the previous run'},
        coverageDelta ? ` (${coverageDelta > 0 ? '+' : ''}${coverageDelta.toFixed(2)}%)` : '',
      ),
    ),
  );
}

function DisplayFile({file, onBack}) {
  return e('div', {className: 'display-file'}, e(FileHeader, {file, onBack}), e(FileContent, {file}));
}

function FileHeader({file, onBack}) {
  const coverage = (file.covered / file.coverable) * 100;
  const coverageDelta = file.prevRun && coverage - (file.prevRun.covered / file.prevRun.coverable) * 100;

  return e(
    'div',
    {className: 'file-header'},
    onBack ? e('a', {className: 'file-header__back', onClick: onBack}, 'Back') : null,
    e('div', {className: 'file-header__name'}, pathToString([...file.parent, ...file.path])),
    e(
      'div',
      {className: 'file-header__stat'},
      'Covered: ' + file.covered + ' of ' + file.coverable + (file.coverable ? ' (' + coverage.toFixed(2) + '%)' : ''),
      e(
        'span',
        {title: 'Change from the previous run'},
        coverageDelta ? ` (${coverageDelta > 0 ? '+' : ''}${coverageDelta.toFixed(2)}%)` : '',
      ),
      e('input', {id: 'theme-toggle', type: 'checkbox', hidden: true}),
      e('label', {for: 'theme-toggle', id: 'theme-toggle-label'}, ''),
    ),
  );
}

function FileContent({file}) {
  return e(
    'pre',
    {className: 'file-content'},
    file.content.split(/\r?\n/).map((line, index) => {
      const trace = file.traces.find(trace => trace.line === index + 1);
      const covered = trace && trace.stats.Line;
      const uncovered = trace && !trace.stats.Line;
      const nbHit = covered? trace.stats.Line: 0;
      return e(
        'div',
        { className: 'code-text-container' },
        e(
          'code',
          {
            className: 'code-line' + (covered ? ' code-line_covered' : '') + (uncovered ? ' code-line_uncovered' : ''),
          },
          line
        ),
        e(
          'div',
          { className: 'cover-indicator' + (covered? ' check-cover': '') + (uncovered? ' no-cover': '')},
          e(
            'div',
            { className: (covered? 'stat-line-hit': '')},
            covered? nbHit: ""
          )
        )
      );
    }),
  );
}

(function () {
  const commonPath = findCommonPath(data.files);
  const prevFilesMap = new Map();

  previousData &&
    previousData.files.forEach(file => {
      const path = file.path.slice(commonPath.length).join('/');
      prevFilesMap.set(path, file);
    });

  const files = data.files.map(file => {
    const path = file.path.slice(commonPath.length);
    const {covered = 0, coverable = 0} = prevFilesMap.get(path.join('/')) || {};
    return {
      ...file,
      path,
      parent: commonPath,
      prevRun: {covered, coverable},
    };
  });

  const children = findFolders(files);

  const root = {
    is_folder: true,
    children,
    path: commonPath,
    parent: [],
    covered: children.reduce((sum, file) => sum + file.covered, 0),
    coverable: children.reduce((sum, file) => sum + file.coverable, 0),
    prevRun: {
      covered: children.reduce((sum, file) => sum + file.prevRun.covered, 0),
      coverable: children.reduce((sum, file) => sum + file.prevRun.coverable, 0),
    },
  };

  ReactDOM.render(e(App, {root, prevFilesMap}), document.getElementById('root'));

  const toggle = document.getElementById('theme-toggle');
  const label = document.getElementById('theme-toggle-label');
  label.textContent = '';

  toggle.addEventListener('change', () => {
    if (toggle.checked) {
      document.documentElement.setAttribute('data-theme', 'dark');
      label.textContent = '';
    } else {
      document.documentElement.removeAttribute('data-theme');
      label.textContent = '';
    }
  });
})();
</script>
</body>
</html>